{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Court\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Court\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Court\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import proc_func\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk.tokenize as tok\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words') \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "main_directory = r'C:\\Users\\Court\\Downloads\\physics'\n",
    "\n",
    "# Select categories that will fall into binary categories for technical and non-technical\n",
    "non_technical_folders = ['physics.pop-ph','physics.ed-ph','physics.gen-ph','physics.hist-ph',\n",
    "                         'physics.soc-ph']\n",
    "technical_folders = ['physics.acc-ph','physics.ao-ph', 'physics.atm-clus','physics.atom-ph',\n",
    "                    'physics.bio-ph','physics.chem-ph','physics.class-ph','physics.comp-ph',\n",
    "                    'physics.data-an','physics.flu-dyn','physics.geo-ph','physics.ins-det',\n",
    "                    'physics.med-ph', 'physics.optics','physics.plasm-ph','physics.acc-ph']\n",
    "\n",
    "# Create a DataFrames of the Technical and Non-Technical Categories\n",
    "count = 0\n",
    "for folder in non_technical_folders:\n",
    "    spec_dir = main_directory + '\\\\'+folder\n",
    "    df = proc_func.NewDataFrame(spec_dir, 'files')\n",
    "    if count == 0:\n",
    "        df_nontech = df\n",
    "    else:\n",
    "        df_nontech = pd.concat([df_nontech, df])\n",
    "    count = count + 1\n",
    "\n",
    "count = 0      \n",
    "for folder in technical_folders:\n",
    "    spec_dir = main_directory + '\\\\'+folder\n",
    "    df = proc_func.NewDataFrame(spec_dir, 'files')\n",
    "    if count == 0:\n",
    "        df_tech = df\n",
    "    else:\n",
    "        df_tech = pd.concat([df_tech, df])\n",
    "    count = count + 1\n",
    "    \n",
    "# Relabel the category of each document as Technical or Non-Technical\n",
    "\n",
    "df_nontech = df_nontech.drop(columns=['Category'])\n",
    "df_nontech.insert(1, \"Category\", 'non-technical')\n",
    "df_tech = df_tech.drop(columns=['Category'])\n",
    "df_tech.insert(1, \"Category\", 'technical')\n",
    "\n",
    "# Ensure there is an equal number of data points in the non-technical and technical categories\n",
    "# This assumes that the technical category origionally has more data points\n",
    "\n",
    "df_tech_sub = df_tech.sample(n=len(df_nontech)) # get a random sampling of the dataframe\n",
    "\n",
    "# Merge the df_nontech and df_tech_sub dataframes\n",
    "df_total = pd.concat([df_nontech, df_tech_sub])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aa aa', 'aa aa Ë†n', 'aa ab', 'aa b', 'aa ba', 'aa bb', 'aa bb cc', 'aa c', 'aa cc']\n"
     ]
    }
   ],
   "source": [
    "# System for Tokenizing Text\n",
    "reg = tok.RegexpTokenizer(r'\\w+') #Tokenizes without punctuation\n",
    "lemmatizer = WordNetLemmatizer()  #\n",
    "\n",
    "\n",
    "english_words = set(nltk.corpus.words.words())\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(['phys', 'rev', 'pop', 'mi', 'al'])\n",
    "\n",
    "\n",
    "def LemmaTokenizer(text):\n",
    "    tokens = reg.tokenize(text) # tokenize the text\n",
    "    lemmas = list()\n",
    "    for token in tokens:\n",
    "        if token.isalpha() and token not in stop_words:\n",
    "            lemma = lemmatizer.lemmatize(token)\n",
    "            lemmas.append(lemma)\n",
    "        if token == 'References':\n",
    "            break\n",
    "    return lemmas\n",
    "# Compile a list of the text values and corresponing categories from the dataframe\n",
    "txts = list()\n",
    "categories = list()\n",
    "for index, row in df_total.iterrows():\n",
    "    txt = row['Text']\n",
    "    cat = row['Category']\n",
    "    txts.append(txt)\n",
    "    categories.append(cat)\n",
    "# Separate the data randomly into training and testing sets, the defult of the train_test_splits\n",
    "# is a random selection using np.random.Setting the test_size or train_size determines what precentage of the\n",
    "# data is put in the test or training data sets. For example, 0.25 repressents 25%\n",
    "txt_train, txt_test, cat_train, cat_test = train_test_split(txts, categories, stratify=categories,\n",
    "                                                            test_size = 0.25)\n",
    "\n",
    "# The CountVerctorizer() takes the text tokenizes it with the LemmaTokenizer defined above,\n",
    "# Removes any tokens that do not occur in a minimum of three documents and in this case the\n",
    "# n-grams stored are those less that or equal to three. Additionally stop words which has been\n",
    "# defined above are removed. The count vectorizer stores the text as vectors which represent the \n",
    "# number of occurances of a given token within a document.\n",
    "count_vect = CountVectorizer(tokenizer = LemmaTokenizer, min_df=3, ngram_range = (1,3), stop_words = stop_words)\n",
    "\n",
    "# Transform the txt from the training set and test set into the matrix representation of the frequency of their tokens\n",
    "Txt_train = count_vect.fit_transform(txt_train) # Also preform a fit on the txt_train which creates a dictionary of all the tokens in the documents\n",
    "Txt_test = count_vect.transform(txt_test)\n",
    "\n",
    "\n",
    "\n",
    "print(feature_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.91728401184082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# When setting a parameter to loop through the form is: function name + __ + parameter\n",
    "n_parameters  = {'countvectorizer__ngram_range': [(1, 1),(1, 2), (1, 3)]}\n",
    "\n",
    "# Linear regression output scores vs ngram method\n",
    "# The pipeline allows for one function to be preformed before another and the GridSearch \n",
    "# iterates through the parameters\n",
    "\n",
    "count_vect_1 = CountVectorizer(tokenizer = LemmaTokenizer, min_df=30, ngram_range = (1,1), stop_words = stop_words)\n",
    "Txt_train_1 = count_vect_1.fit_transform(txt_train) # Also preform a fit on the txt_train which creates a dictionary of all the tokens in the documents\n",
    "Txt_test_1 = count_vect_1.transform(txt_test)\n",
    "\n",
    "count_vect_2 = CountVectorizer(tokenizer = LemmaTokenizer, min_df=30, ngram_range = (1,2), stop_words = stop_words)\n",
    "Txt_train_2 = count_vect_2.fit_transform(txt_train) # Also preform a fit on the txt_train which creates a dictionary of all the tokens in the documents\n",
    "Txt_test_2 = count_vect_2.transform(txt_test)\n",
    "\n",
    "count_vect_3 = CountVectorizer(tokenizer = LemmaTokenizer, min_df=30, ngram_range = (1,3), stop_words = stop_words)\n",
    "Txt_train_3 = count_vect_3.fit_transform(txt_train) # Also preform a fit on the txt_train which creates a dictionary of all the tokens in the documents\n",
    "Txt_test_3 = count_vect_3.transform(txt_test)\n",
    "\n",
    "gnb_1 = GaussianNB()\n",
    "gnb_1.fit(Txt_train_1.toarray(), cat_train)\n",
    "gnb_2 = GaussianNB()\n",
    "gnb_2.fit(Txt_train_2.toarray(), cat_train)\n",
    "gnb_3 = GaussianNB()\n",
    "gnb_3.fit(Txt_train_3.toarray(), cat_train)\n",
    "\n",
    "lr_1 = LogisticRegressionCV()\n",
    "lr_1.fit(Txt_train_1.toarray(), cat_train)\n",
    "lr_2 = LogisticRegressionCV()\n",
    "lr_2.fit(Txt_train_2.toarray(), cat_train)\n",
    "lr_3 = LogisticRegressionCV()\n",
    "lr_3.fit(Txt_train_3.toarray(), cat_train)\n",
    "\n",
    "\n",
    "# The TF-IDF vectorizer is applied then the LogisticRegression algorithm is applied\n",
    "\n",
    "count_vect_1_tf = TfidfVectorizer(tokenizer = LemmaTokenizer, min_df=30, ngram_range = (1,1), stop_words = stop_words)\n",
    "Txt_train_1_tf = count_vect_1_tf.fit_transform(txt_train) # Also preform a fit on the txt_train which creates a dictionary of all the tokens in the documents\n",
    "Txt_test_1_tf = count_vect_1_tf.transform(txt_test)\n",
    "\n",
    "count_vect_2_tf = TfidfVectorizer(tokenizer = LemmaTokenizer, min_df=30, ngram_range = (1,2), stop_words = stop_words)\n",
    "Txt_train_2_tf = count_vect_2_tf.fit_transform(txt_train) # Also preform a fit on the txt_train which creates a dictionary of all the tokens in the documents\n",
    "Txt_test_2_tf = count_vect_2_tf.transform(txt_test)\n",
    "\n",
    "count_vect_3_tf = TfidfVectorizer(tokenizer = LemmaTokenizer, min_df=30, ngram_range = (1,3), stop_words = stop_words)\n",
    "Txt_train_3_tf = count_vect_3_tf.fit_transform(txt_train) # Also preform a fit on the txt_train which creates a dictionary of all the tokens in the documents\n",
    "Txt_test_3_tf = count_vect_3_tf.transform(txt_test)\n",
    "\n",
    "gnb_1_tf = GaussianNB()\n",
    "gnb_1_tf.fit(Txt_train_1_tf.toarray(), cat_train)\n",
    "gnb_2_tf = GaussianNB()\n",
    "gnb_2_tf.fit(Txt_train_2_tf.toarray(), cat_train)\n",
    "gnb_3_tf = GaussianNB()\n",
    "gnb_3_tf.fit(Txt_train_3_tf.toarray(), cat_train)\n",
    "\n",
    "lr_1_tf = LogisticRegressionCV()\n",
    "lr_1_tf.fit(Txt_train_1_tf.toarray(), cat_train)\n",
    "lr_2_tf = LogisticRegressionCV()\n",
    "lr_2_tf.fit(Txt_train_2_tf.toarray(), cat_train)\n",
    "lr_3_tf = LogisticRegressionCV()\n",
    "lr_3_tf.fit(Txt_train_3_tf.toarray(), cat_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8652246256239601, 0.8993344425956739, 0.8993344425956739]\n",
      "[0.9009983361064892, 0.9051580698835274, 0.9093178036605657]\n",
      "[0.9059900166389351, 0.9201331114808652, 0.9259567387687188]\n",
      "[0.9126455906821963, 0.9201331114808652, 0.9284525790349417]\n"
     ]
    }
   ],
   "source": [
    "#Calculate the accuracy of each method\n",
    "gnb_1_s = gnb_1.score(Txt_test_1.toarray(), cat_test)\n",
    "gnb_2_s = gnb_2.score(Txt_test_2.toarray(), cat_test)\n",
    "gnb_3_s = gnb_3.score(Txt_test_3.toarray(), cat_test)\n",
    "gnb_1_tf_s = gnb_1_tf.score(Txt_test_1_tf.toarray(), cat_test)\n",
    "gnb_2_tf_s = gnb_2_tf.score(Txt_test_2_tf.toarray(), cat_test)\n",
    "gnb_3_tf_s = gnb_3_tf.score(Txt_test_3_tf.toarray(), cat_test)\n",
    "lr_1_s = lr_1.score(Txt_test_1.toarray(), cat_test)\n",
    "lr_2_s = lr_2.score(Txt_test_2.toarray(), cat_test)\n",
    "lr_3_s = lr_3.score(Txt_test_3.toarray(), cat_test)\n",
    "lr_1_tf_s = lr_1_tf.score(Txt_test_1_tf.toarray(), cat_test)\n",
    "lr_2_tf_s = lr_2_tf.score(Txt_test_2_tf.toarray(), cat_test)\n",
    "lr_3_tf_s = lr_3_tf.score(Txt_test_3_tf.toarray(), cat_test)\n",
    "\n",
    "\n",
    "gnb_scores = [gnb_1_s, gnb_2_s, gnb_3_s]\n",
    "lr_scores = [lr_1_s, lr_2_s, lr_3_s]\n",
    "lr_tf_scores = [lr_1_tf_s, lr_2_tf_s, lr_3_tf_s]\n",
    "gnb_tf_scores = [gnb_1_tf_s, gnb_2_tf_s, gnb_3_tf_s]\n",
    "print('Accuracy as a function of n-gram range')\n",
    "print('Gaussian Naive Bayes Accuracy:', gnb_scores)\n",
    "print('Gaussian Naive Bayes TF-IDF Weighted Accuracy:',gnb_tf_scores)\n",
    "print('Logistic Regression Accuracy:', lr_scores)\n",
    "print('Logistic Regression TF-IDF Weighted Accuracy:',lr_tf_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "algorithm_typ = ['Gaussian Naive Bayes','Gaussian TF-IDF Naive Bayes' 'Logistic', 'TF-IDF Logistic',]\n",
    "n = ['N=1', 'N=2','N=3']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x = n, y = gnb_scores, name = 'Gaussian Naive Bayes', marker_color = 'lightblue', width = 0.2, text = gnb_scores))\n",
    "fig.add_trace(go.Bar(x = n, y = gnb_tf_scores, name = 'TF-IDF Gaussian Naive Bayes', marker_color = 'blue', width = 0.2, text = gnb_tf_scores))\n",
    "\n",
    "fig.add_trace(go.Bar(x = n, y = lr_scores, name = 'Logistic Regression', marker_color = 'plum', width = 0.2, text = lr_scores))\n",
    "fig.add_trace(go.Bar(x = n, y = lr_tf_scores, name = 'TF-IDF Logistic Regression', marker_color = 'purple', width = 0.2, text = lr_tf_scores))\n",
    "fig.update_traces(texttemplate = '%{text:.3f}', textposition = 'outside', textfont_size = 12)\n",
    "fig.update_layout(title='Accuracy of Machine Learning Algorithms vs N-Gram Value',\n",
    "                  uniformtext_minsize = 12,\n",
    "    xaxis_tickfont_size = 12, yaxis = dict(title = 'Accuracy (%)', titlefont_size = 13, tickfont_size = 12),\n",
    "    legend = dict(x = 1, y = 1), barmode = 'group', bargap = .1, bargroupgap = .3)\n",
    "\n",
    "fig.write_image('fig1.png',scale=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the effect of the C value on the Logistic Regression Accuracy\n",
    "parameters  = {\"logisticregression__C\": [0.01, 0.1, 1, 10, 100],\n",
    "              \"tfidfvectorizer__ngram_range\": [(1, 1),(1, 2), (1, 3)]} #, (1, 2), (1, 3)\n",
    "\n",
    "# The pipeline allows for one function to be preformed before another\n",
    "# The TF-IDF vectorizer is applied then the LogisticRegression algorithm is applied\n",
    "pipeline = make_pipeline(TfidfVectorizer(tokenizer = LemmaTokenizer, min_df=30, stop_words = stop_words), LogisticRegression())\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters)\n",
    "grid_search.fit(txt_train, cat_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "\n",
    "# extract scores from grid_search\n",
    "scores = grid_search.cv_results_['mean_test_score'].reshape(-1, 3).T\n",
    "print(scores)\n",
    "ordered_scores = [scores[0],scores[2],scores[1]]\n",
    "print(ordered_scores)\n",
    "s_text = np.around(ordered_scores, decimals=4) # Only show rounded value (full value on hover)\n",
    "\n",
    "\n",
    "# visualize heat map\n",
    "fig0 = ff.create_annotated_heatmap(s_text, showscale=True,\n",
    "               y = ['n-grams = (1, 1)','n-grams = (1, 2)', 'n-grams = (1, 3)'], \n",
    "                                  x = ['C = 0.01','C = 0.1','C = 1','C = 10','C = 100'])\n",
    "\n",
    "fig0.write_image('heatmap.png',scale=5)\n",
    "fig0.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most effective C value:  21.54434690031882\n",
      "0.9284525790349417\n"
     ]
    }
   ],
   "source": [
    "# Return what the sklearn toolkit found as the best value of the C parameter for the (1,3)\n",
    "# n-gram model\n",
    "print('Most effective C value: ',  lr_3_tf.C_[0])\n",
    "c_eff = lr_3_tf.C_[0]\n",
    "lr_3_tf_eff = LogisticRegression(C=c_eff)\n",
    "lr_3_tf_eff.fit(Txt_train_3_tf.toarray(), cat_train)\n",
    "print(lr_3_tf_eff.score(Txt_test_3_tf.toarray(), cat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = count_vect_3_tf.get_feature_names()\n",
    "term_imp = lr_3_tf_eff.coef_.ravel() #Gives the term importance after ifidf weighting\n",
    "tech_imp = np.argsort(term_imp)[-20:]\n",
    "tech_imp = [int(x) for x in tech_imp]\n",
    "feature_names_tech = [feature_names[x] for x in tech_imp]\n",
    "nontech_imp = np.argsort(term_imp)[:20]\n",
    "feature_names_nontech = [feature_names[x] for x in nontech_imp]\n",
    "\n",
    "tot_imp = np.concatenate([nontech_imp,tech_imp])\n",
    "tot_features = np.concatenate([feature_names_nontech,feature_names_tech])\n",
    "\n",
    "\n",
    "fig2 = go.Figure()\n",
    "\n",
    "fig2.add_trace(go.Bar(x = tot_features,\n",
    "                     y = term_imp[tot_imp], \n",
    "                      width = 0.4, text = gnb_scores))\n",
    "fig2.update_layout(title='Coefficient Value for 40 Most Influential Terms',\n",
    "                      xaxis_tickfont_size = 10,uniformtext_mode='show')\n",
    "fig2.write_image('fig3.png',scale=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing tokens with length one the accuracy is: 0.9168053244592346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Court\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def LemmaTokenizer_altered(text):\n",
    "    tokens = reg.tokenize(text) # tokenize the text\n",
    "    lemmas = list()\n",
    "    for token in tokens:\n",
    "        if token.isalpha() and token not in stop_words and len(token)>1:\n",
    "            lemma = lemmatizer.lemmatize(token)\n",
    "            lemmas.append(lemma)\n",
    "        if token == 'References':\n",
    "            break\n",
    "    return lemmas\n",
    "count_vect_3_tf_alt = TfidfVectorizer(tokenizer = LemmaTokenizer_altered, min_df=30, ngram_range = (1,3), stop_words = stop_words)\n",
    "Txt_train_3_tf_alt = count_vect_3_tf_alt.fit_transform(txt_train) # Also preform a fit on the txt_train which creates a dictionary of all the tokens in the documents\n",
    "Txt_test_3_tf_alt = count_vect_3_tf_alt.transform(txt_test)\n",
    "lr_3_tf_alt_eff = LogisticRegression(C=c_eff)\n",
    "lr_3_tf_alt_eff.fit(Txt_train_3_tf_alt.toarray(), cat_train)\n",
    "print('After removing tokens with length one the accuracy is:',\n",
    "      lr_3_tf_alt_eff.score(Txt_test_3_tf_alt.toarray(), cat_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
