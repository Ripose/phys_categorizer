6
0
0
2
 
v
o
N
 
7
1
 
 
]
h
p
-
t
s
i
h
.
s
c
i
s
y
h
p
[
 
 
1
v
2
7
1
1
1
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Probability as typicality

S´ergio B. Volchan

26 October 2006

Abstract

The concept of typicality refers to properties holding for the “vast ma-
jority” of cases and is a fundamental idea of the qualitative approach to dy-
namical problems. We argue that measure-theoretical typicality would be the
adequate viewpoint of the role of probability in classical statistical mechan-
ics, particularly in understanding the micro to macroscopic change of levels
of description.

Keywords: Statistical mechanics; Typicality; Probability.

1. Introduction

The year 2006 marked the 100th anniversary of Ludwig Boltzmann’s death. He
is justly celebrated as one of the greatest theoretical physicists of the XIXth century
and a founding father of statistical mechanics (for a perspective, see Cercignani,
1998 and Uﬃnk, 2004). Besides, his work inﬂuenced (directly or indirectly) the
development of important ﬁelds of pure and applied mathematics: foundations of
probability theory, the theory of stochastic processes (Brownian motion), ergodic
theory and functional analysis (integral-diﬀerential equations).

He also had a signiﬁcant impact on the philosophy of science. Firstly, he con-
tributed to the unity of physics by attempting to reconcile the atomistic-mechanical
view of microscopic dynamics with the macroscopic world of thermodynamics in
the context of kinetic gas theory. Secondly, in that endeavor he had a clear view
that progress in physics involves hypothesizing unobservable (but not inscrutable)
“simple” material entities in order to explain the behavior of “complex” systems. 1
Thence his role in the “battle over the reality of the atom” (Wick, 1995), which was
the cornerstone of that “uniﬁcation” program and which served as a prelude to the

1In stark contrast to the somewhat barren positivist stance of the “energeticists” (according to
which energy was a kind of “primordial” entity) for which unobservables had no place in physics.
Curiously, they regarded thermodynamics as their ideal, a theory which is full of unobservables (as
in any deep physical theory, Bunge, 1967), entropy being one of the most intangible.

1

future unraveling of the structure of matter (see Brush, 1994). Thirdly, and closer
to the focus of this article, in facing the sharp criticisms (the so-called “reversibil-
ity paradoxes”) against his program, he brought (with the contribution of Gibbs)
probabilistic arguments to the center of stage in physics.

However, the use probabilistic concepts in kinetic theory 2 has generated a lot of
controversy and misunderstanding, even after so many discussions and clariﬁcations.
For, how come that starting from Newton’s equations of motion for discrete particles
one suddenly conjures up a continuous probability density in phase-space? 3 What
exactly is the role and status of probability in classical statistical mechanics? Is it
a concept totally alien to mechanics?

The diﬃculties Boltzmann had to face were not only conceptual but also tech-
nical due to the lack of adequate mathematical tools necessary to tackle (and even
formulate) such hard questions in a clear, rigorous and meaningful way. For exam-
ple, one must bear in mind that a probability theory proper was not yet available
and there was (and still is!) some confusion regarding its status, as many people
viewed it as a peculiar blend of physics and mathematics. 4 As von Plato’s (1991)
pointed out, Boltzmann “was a XIXth-century theoretical physicist, not a XXth-
century mathematician. Even so, he has been judged and interpreted according to
mathematical concepts and standards that were not his. The mathematics of prob-
ability of the previous century being what it was, he was still able to achieve his end
by reasoning that later developments conﬁrmed” (p. 87).

That the problems of kinetic theory were deemed highly challenging (in fact,
they are still open today) and important can be gauged by their inclusion as part of
the 6th problem in David Hilbert’s famous list. It deals with the axiomatization of
physical theories (Corry, 1997) and, in particular, probability theory. 5 In his words
(quoted in Wightman, 1976):

The investigations on the foundations of geometry suggest the following
problem: To treat in the same manner, by means of axioms, those phys-
ical sciences in which mathematics plays an important part; in the ﬁrst
rank are the theory of probabilities and mechanics.

2Interestingly, the use of statistics in kinetic gas theory was inspired by the astronomer and

demographer Adolphe Quˆetelet, see Torretti, (1999), p. 180 and von Plato (1998), p. 73.

3It seems that the idea of studying a mechanical systems by means of a probability density on
the set of initial data was pioneered by Poincar´e in his “method of arbitrary functions”, see von
Plato, 1983.

4According to Kac (1949), Poincar´e used to joke about the confusing status of the central limit
theorem, saying that “there must be something mysterious about the normal law since mathemati-
cians think it is a law of nature whereas physicists are convinced it is a mathematical theorem”
(p. 52) (the physicists were right here!). Maybe a trace of this confusion remains as many of
the theorems of probability theory are labeled as “laws”, as in the “law of large numbers”, “the
normal law”, “Kolmogorov 0-1 law”, etc. Incidentally, in 2006 a Fields Medal (the Nobel prize of
mathematics) was awarded for the ﬁrst time ever to a probabilist.

5Note that Hilbert considered probability (like geometry) as part of physics, not an uncommon

view at the time.

2

As to axioms of the theory of probability, it seems to me desirable that
their logical investigation should be accompanied by a rigorous and sat-
isfactory development of the method of mean values in mathematical
physics and in particular in the kinetic theory of gases.

In this paper we argue that typicality would be the adequate viewpoint of the role
of probability in classical statistical mechanics. 6 Instead of indicating the presence
of a random ingredient in the system, it is taken as a yardstick in probing the
relative size of some sets of micro-states of interest (in particular, initial conditions)
in the geometrical arena of phase-space. As discussed in section 2, this view is at
the very heart of modern axiomatic probability theory, which is based on Borel and
Lebesgue’s measure theory. Now, as the initial data are an integral part of any
mechanical system, the use of probability to size up such data makes it less foreign
to mechanics.

Generally speaking, a set is typical if it contains an “overwhelming majority” of
points according to some notion of “size”. In classical statistical mechanics there is
a “natural” notion of size: phase-space volume, i.e., Lebesgue-measure 7, which is
invariant (by Liouville’s theorem) and that, when “cut to the energy surface”, can be
normalized to a probability measure. We suggest that the focus on such (measure-
theoretical) typical micro-states leading to the system’s macroscopic behavior (in
an appropriate limit) underlines the role of probability in bridging the micro-macro
levels of description, which is a basic aim of statistical mechanics. Besides, as
discussed in section 3, probability as typicality has a long history of success, from
celestial mechanics to the modern theory of dynamical systems.

We also think that, from this perspective, the use of probabilistic reasoning in
classical statistical mechanics is more understandable. It could be conceived as part
of the zeitgeist of the last decades of the XIXth when a revolutionary trend from
quantitative to qualitative methods was taking place, pioneered by Poincar´e, more
or less at the same time as Boltzmann’s work in kinetic theory 8 (a ﬁeld in which,
by the way, Poincar´e had a keen interest, his paper on the subject dating from 1894,
see von Plato, 1991, p. 83).

Finally, in section 4 we discuss the use of probability as typicality in a remarkable
achievement in non-equilibrium statistical mechanics, namely, Lanford’s theorem on
the validity problem for Boltzmann’s equation.

2. Probability and Measure Theory

A. N. Kolmogorov solved part of Hilbert’s 6th problem in 1933 by his axiomatiza-
tion of probability theory in his Grundbegriﬀe (Kolmogorov, 1957). The fundamental

6The notion of typicality also plays a crucial role in the revamped version of Bohmian quantum

mechanics, see for instance D¨urr (2001).

7More generally, an absolutely continuous measure with respect to Lebesgue-measure.
8This would deserve a more thorough historical investigation. It is fascinating to wonder what
these two quite diﬀerent characters would had to say to each other as they most probably met at
the 1904 St. Louis world fair (Cercignani, 1998, p. 145).

3

insight was that probability theory, going beyond its “elementary” part which deals
with discrete sample spaces and reduces essentially to combinatorics, could be seen
as a branch of the newly created measure theory of Lebesgue.

Although measure theory developed from internal problems in mathematical
analysis,
linked to the need to generalize Riemann’s integral in the context of
Fourier’s series (Kahane, 2001, Hoare and Lord, 2002), it also had ancient geomet-
ric roots. As made clear in Lebesgue’s 1902 doctoral dissertation, titled Int´egrale,
longueur, aire, measure theory is conceived as a (very abstract) generalization of
basic geometrical notions of size: length, area and volume (Choquet, 2004).

Recall that in modern mathematical language a measure space is a triple (Ω,
, µ)
where: Ω is an arbitrary set (usually equipped with some natural topology);
is
a collection of subsets of Ω, called measurable subsets, carrying the structure of a
σ-algebra (i.e., it is closed under denumerable set-theoretical operations); and µ is
. 9 Kolmogorov noticed that
a non-negative countably additive set function on
probability theory could be perfectly couched in this framework. A probability space
is deﬁned as a triple (Ω,
the collection of
“events” and P is a ﬁnite measure normalized to one, P(Ω) = 1. If A is an “event” (a
measurable set) 10, then P(A) is its probability “of occurrence”. Also, “random vari-
ables” are identiﬁed to measurable functions and expectations to Lebesgue-integrals
with respect to the given probability measure. 11

, P), where Ω is the “sample space”,

F
F

F

F

F

Kolmogorov’s axiomatization (which today reached almost universal acceptance)
has an enormous signiﬁcance: not only it gave the seal of maturity and mathematical
respectability to the discipline, which has been expanding relentlessly since then, as
it greatly clariﬁed its nature. Most importantly, it became clear, once and for all,
that probability theory is a branch of pure mathematics, like group theory, geometry,
linear algebra, etc. Hence it has many models in the set-theoretic sense so that the
expression “taken at random” has diﬀerent meanings depending on the speciﬁed
probability space. This helped dissolving many paradoxes that plagued probability
theory, like Bertrand’s, which were linked to a careless use of that phrase. Freed
from any previous commitment to an “interpretation” (be it frequentist, subjectivist,
propensity, etc) the theory could be developed autonomously. Moreover, once its
nature is so elucidated one can examine and criticize any proposed interpretation or
application of probability theory to the real-world.

For the better or worse, probability theory has kept the old jargon of its pre-
axiomatized era. Though it is debatable whether such notions as “sample”, “event”,

9A pair (Ω,
10Notice that, as

F

F

) is called a measurable space, meaning that it can carry diﬀerent measures.

is usually strictly smaller than the set of all subsets of Ω, some subsets of

the sample space may have no probability at all.

11Of course, Kolmogorov’s legacy in probability theory is much wider: he clariﬁed the concept
of independence (there is a joke saying that probability theory is “just” measure theory plus
the concept of independence in the same way that complex analysis as “just” analysis in two-
variables plus √
1) and conditioning; established a host of now-classical limit theorems for sums
of independent random variables; and made seminal contributions to the theory of continuous-time
stochastic processes (see Mazliak, Chaumont and Yor, 2004).

−

4

“occurrence”, “trials”, “favorable event”, “experiment”, etc may or not have some
heuristic or pedagogic value, the fact is that they are not, strictly speaking, part of
probability theory. In particular, there is nothing intrinsically random about “ran-
dom variables”: they are just real-valued measurable functions, those one expects
to ﬁnd in real analysis (for instance, the continuous functions).

The old phraseology has to be used with great care, particularly in applications.
For instance, coin-tossing is usually taken as the epitome of a random phenomenon.
However, real coin-tossing is a purely mechanical process that should in principle be
modeled using rigid-body Newtonian dynamics plus the initial conditions; and its
relation to randomness and unpredictability is a non-trivial matter (see Diaconis,
Holmes and Montgomery, 2005).

3. Negligible sets

As a measure on a set can be viewed as giving the size of some of its subsets, so
a probability measure can be conceived as giving their relative sizes. Moreover, a
measure allows us to take some sets as being “small”, “exceptional”, “atypical” or
“negligible” and hence ignored in some speciﬁc contexts.

For the record, we note that there are at least two other common notions of size
(and hence, of typicality) in mathematics: cardinality, giving the number of points
(or power) of a set and a topological notion, called genericity, particularly useful
in dynamical systems theory. We won’t discuss them here as our focus is on the
measure-theoretical notion of typicality. 12 Roughly speaking, a property
on a
measure space is typical if the set ℘c = Ω
℘ of its exceptions has “small” measure
(in particular, ℘c has to be a measurable set) that is, µ(℘c)
ǫ for some “tolerance”
0
. It is important to bear in mind that, as
Goldstein (2001) observed, typicality “plays solely the role of informing us when a
set E of exceptions is suﬃciently small that we may in eﬀect ignore it” (p. 53),
so one could conceive of some weaker notion of typicality, without the additional
measure-theoretical structure. 13

1, where ℘ =

(ω)

Ω :

≪

≤

≤

−

P

P

∈

ω

{

}

ǫ

An important and natural example are sets of measure zero (also call null sets),
corresponding to ǫ = 0. 14 In measure theory it is known that changing a measurable
function on a null set (which can be uncountable) won’t aﬀect the Lebesgue integral
of that function. This suggests the notion of a property holding almost-everywhere,
meaning that it holds outside a set of measure zero. In the analogous situation in
probability theory one says it holds almost-surely or with probability one.

Thus, in measure/probability theory a property is said to hold even if it has
inﬁnitely (even uncountably) many exceptions, as long as these form a set of small
measure/probability. For instance, in 1909 Borel obtained the ﬁrst proof of a strong

12The relationships between these three notions are quite complex, see Oxtoby, 1971.
13A possibility that comes to mind is outer measure, which is only sub-additive and deﬁned on

all subsets of Ω.

14This is the strongest measure-theoretical notion of typicality and historically the concept of

null set predates measure theory proper, see von Plato (1983), p.44.

5

law of large numbers by showing that Lebesgue almost every real number in [0, 1]
is normal to base 10, meaning that any block of k digits appears with asymptotic
frequency 10−k in its decimal expansion (and the same holds for any base). So,
though there are uncountably many non-normal numbers, as seen through the lenses
of Lebesgue measure (so to speak), “all” real numbers are normal. However, as
remarked by Kac (1949), “as is often the case, it is much easier to prove that an
overwhelming majority of objects possess a certain property than to exhibit even
one such object” (p. 18) and to this day no one knows whether such fundamental
constants as π, e, √2 are normal (to any base!). 15 We stress though, that the whole
point of typicality arguments is that, for certain purposes, one would not need such
detailed information.

The relation of typicality to probability is subtle, as the following example il-
lustrates. Consider the set of all binary strings of say, 200 bits. For example, one
could think of it as the sample space associated to the tossing 200 ideal fair coins
(heads=1, tail=0). Now, in the overwhelming majority of strings the total number
of heads is between 50 and 150 (i.e., within 50 of the mean 100) and we may declare
such strings as typical. Of course, the string 11...11, consisting of 200 heads, is not
typical. However, it has the very same (and very small) probability, namely 2−200,
as each and every one of the 2200 possible strings. 16

It seems that the ﬁrst typicality-like arguments appeared in the ﬁeld of celestial
mechanics, in connection with the classical problem of the stability of the solar
system. This came about after the rather slow realization that one could not expect
to “explicitly” solve most diﬀerential equations and, moreover, that such a solution
might be uninformative. A clear illustration of this state of aﬀairs is the Newtonian
gravitational three-body problem. Though this is not an integrable system (in the
precise sense of Hamiltonian mechanics) it has an “explicit” or “analytic” solution,
which was found by Sundman in 1909. 17 He obtained a convergent series solution,
valid for all times, but whose rate of convergence is so slow as to render it virtually
useless to extract interesting information about the long-time behavior of the system
(see Henkel, 2001).

In that long historical trend in mathematical-physics, which eventually led to the
switch from quantitative to qualitative methods pioneered by Poincar´e, Lyapunov
and others (see Laskar, 1992 and Chenciner, 1999), the focus changes from a detailed
analysis of individual solutions of a given system to the study of whole families
of them (and of families of systems). As the 1994 Fields medalist J.-C. Yoccoz
puts it: “Broadly speaking, the goal of the theory of dynamical systems is, as it

15By the way, normality was initially taken to be a reasonable deﬁnition of randomness for
sequences of digits. However, it was abandoned as it was proven by Champernowne in 1933 that
the number 0.12345678910111213... (the concatenation of the positive integers) is normal to base
10. For a discussion of randomness for sequences, see Volchan, 2002.

16This is a version of the so-called “paradox of randomness”, see Volchan, 2002.
17And which fulﬁlls precisely the requirements stated in the celebrated king Oscar II prize

problem, see Barrow-Green, 1997.

6

should be, to understand most of the dynamics of most systems.” (Yoccoz, 1995,
p.247). Note that as Sundman’s example shows, resorting to qualitative methods
(including statistics) is not necessarily linked to the huge number of equations one is
dealing with nor to ignorance (or imprecision) of initial conditions, notwithstanding
a common claim in statistical mechanics textbooks.

One of the earliest examples of the qualitative approach to dynamical problems
is the famous Poincar´e’s recurrence theorem which Poincar´e himself called “stabilit´e
a la Poisson” (and is also known as “Poincar´e-reversibility”). This remarkably sim-
ple result, which appeared in his memoir on the three-body problem (1890), is a
forerunner of the ergodic theorems and is one of the few global results in dynamical
systems theory.

Its measure-theoretical version (not the original one, as measure theory was not
yet available) says the following. Consider a ﬂow Tt (e.g., associated to the solutions
of a diﬀerential equation) on a set Ω and µ a ﬁnite invariant measure. Then, almost
all points of Ω are recurrent, that is, the orbit of every initial condition x outside a
set of µ-measure zero will eventually come arbitrarily close to x (such orbits were
called “stable”).

Now, by normalizing µ to a probability measure the theorem can be rephrased
thus: the ﬂow is recurrent with probability one or that an initial data “taken at
random” is recurrent. According to von Plato (1991), in this result “for the ﬁrst
time, a property is ascribed to mechanical systems with probability one. Exceptions
to the problem are not impossible but have probability zero” (p. 83). 18 However,
as there is no intrinsic randomness in the dynamics nor in the initial data, what the
theorem really seems to convey is that the property of recurrence is typical with
respect to the measure µ. In other words, it holds for “the vast majority” of initial
states. Poincar´e himself seems to corroborate this view as, according to Barrow-
Green (1997), he claimed that “stable trajectories would outnumber the unstable,
in direct analogy with the irrational and rational numbers” (p. 87, our emphasis).
The power of Poincar´e’s theorem stems from its being a very general global
result that does not require detailed knowledge of the motion. Of course, it does
presuppose the long-time existence of solutions! This can be a matter of concern due
to the possible existence of initial data leading to “singularities”, that is, obstructions
to the extension of solutions. For instance, in the Newtonian gravitational N-body
system the planets (idealized as point particles) can collapse or even disperse to

18Incidentally, from discussions of earlier work of Gyld´en (1888) on the related problem of plan-
etary mean motion came out the ﬁrst clearly articulated methodological principle linked to the
negligibility of null sets, due to Felix Bernstein (1912). He called it “the axiom of the limited
arithmetizability of observations” according to which (quoted in von Plato, 1998):

When one relates the values of an experimentally measured quantity to the scale of
all the reals, one can exclude from the latter in advance any set of measure zero.
One should expect only such consequences of the observed events which are main-
tained when the observed value is represented by another one within the interval of
observation.

7

inﬁnity in ﬁnite time. Here again, a typicality argument comes to the rescue as one
hopes to prove that such “catastrophes” are rare, 19 in the sense that the set of
initial conditions leading to them is negligible (a very hard problem which is open
in the general case, see Saari, 2005). 20

The analogous problem in kinetic theory is fortunately much simpler. Consider
the usual “billiard-balls” model of a classical gas as made of hard impenetrable
spheres (free ﬂow plus elastic shocks). There is an ambiguity here as how to extend
the ﬂow past an instant where three or more particles collide. However, the initial
conditions leading to such situation form a measurable subset of lower dimension in
phase-space, being therefore of Lebesgue measure zero (a corresponding result holds
for initial data leading to inﬁnitely many collisions in ﬁnite time). Therefore the
dynamics is well deﬁned (for all time) for Lebesgue almost every initial condition
(Cercignani, Gerasimenko and Petrina, 1997).

As is well known, the recurrence theorem was used by Poincar´e and Zermelo as a
formidable objection to Boltzmann’s attempt to reconcile the irreversible character
of macroscopic phenomena with the reversible nature of the microscopic Newtonian
dynamics of a gas. 21 In fact, it applies to a classical gas of N particles in an isolated
bounded container. But a gas initially restricted to half of the container will, if left
to itself, diﬀuse until it occupies the whole volume while one never observes it
return spontaneously to that initial situation. This is a version of the “reversibility
paradox” which even nowadays is a source of contention among physicists. 22
4. Typicality in Statistical Mechanics

The crucial point in coming to terms with the reversibility conundrum is the
realization that one is examining a system at two very diﬀerent levels. In this sense,
Poincar´e’s theorem is a clue indicating that any hope to derive in a mathematically
rigorous way the macroscopic irreversible equations (like Boltzmann’s, Euler’s or
Navier-Stokes) from a microscopic reversible dynamics will involve some kind of
idealized limit in which the number of particles goes to inﬁnity and under which
there is a “loss of Poincar´e-reversibility”.

That some limit procedure is necessarily involved here was clearly stated in
Hilbert’s formulation of the 6th problem which, while recognizing Boltzmann’s in-
tuition, reads:

19This also exempliﬁes the fact that what is taken as negligible in some contexts may not be so
in others: such “singularities” as collisions of celestial bodies are obviously of considerable astro-
nomical interest. Another example are phase-transition points in equilibrium statistical mechanics.
20We should mention yet another famous (and much harder) qualitative result in Hamiltonian
mechanics: the KAM theorem also can be seen as a typicality result. Roughly, it says that for
a suﬃciently small perturbation of an integrable Hamiltonian system (plus technical hypothesis)
the set of initial conditions leading to quasi-periodic orbits is a set whose complement has small
Lebesgue measure, which tends to zero as the perturbation tends to zero (P¨oschel, 2000).

21Particularly against his “H-theorem”, see Illner, 1988.
22The author had the opportunity to witness the extant disagreements on the occasion of a
round table on irreversibility at the STATPHYS-20 conference in Paris (1998), having professors
Ruelle, Lebowitz, Prigogine and Klein as panelists.

8

Thus Boltzmann’s work on the principles of mechanics suggests the prob-
lem of developing mathematically the limiting processes, there merely
indicated, which lead from the atomistic view to the laws of motion of
continua (cited in Wightman, 1976).

A related observation is that under such change of levels of description there is a
dramatic “decimation” of degrees of freedom: while the micro-state has 6N (of the
order of 1023 for a gas in normal conditions) degrees of freedom (all the particle’s
positions and velocities) the macro-state usually involves few variables (say, density,
pressure and temperature). 23

This reduction suggests that some kind of averaging procedure should be involved
and which, together with the large N limit, points to the role of statistics. However,
as there is no intrinsic randomness in the system at hand the use of statistics and
probability might be better understood through typicality. In particular, the taking
of averages does not necessarily implies any randomness:
it could just mean that
details are not important (Bunge, 1988) which is, after all, the basic philosophy
behind the qualitative approach. Once more, it highlights

...what the statistical aspect of statistical mechanics really is, namely,
the assertion of circumstances which may be neglected (Truesdell, 1966,
p.77).

∈

It then seems that the general procedure needed to realize Boltzmann’s program
in the lines envisioned by Hilbert goes as follows (Guerra, 1993, Lanford, 1976).
Consider a “physically signiﬁcant” macroscopic state-function F (usually linked to
locally conserved quantities). A fundamental insight of Boltzmann is that there are
ΩΛ,N compatible with the same macrostate F in the
many diﬀerent micro-states ω
following sense. One partitions the one-particle phase-space into macroscopically
small but microscopically large cells ∆α and speciﬁes the number nα of particles
lying in each cell when the system is in macro-state F (and maybe with additional
speciﬁcations, like energy, etc, according to desired macroscopic description of the
system, be it kinetic, hydrodynamic, etc ). The micro-states corresponding to those
ΩΛ,N .
speciﬁcations will have similar density/velocity proﬁles and deﬁne the set ΓF
Let now F(t) be the macro-state at time t evolved from F according to the
macroscopic phenomenological equations (kinetic, hydrodynamic, etc) while ω(t) is
the micro-state at time t evolved according to Hamilton’s equations from an ω
ΓF.
Then, one would like to prove that for the overwhelming majority of initial micro-
ΓF and in an appropriate limit (kinetic, hydrodynamical, etc) one obtains
states ω
ΓF(t). It turns out that this is very hard to do in “realistic” 24 scenarios. In the
ω(t)
following we restrict our discussion to a case in which a spectacular breakthrough

⊂

∈

∈

∈

23However, in non-equilibrium cases one deals with corresponding ﬁelds, which are strictly speak-

ing, inﬁnite dimensional vectors.

24That is, taking classical mechanics as the microscopic model. The analogous problem is much

more complete for stochastic lattice systems, see Spohn, 1991 and Boldrighini, 1996.

9

was achieved namely, Lanford’s theorem on the validity problem for Boltzmann’s
equation.

Recall that Boltzmann (building on previous work of Maxwell) wrote down his
equation in 1872 to describe the time evolution of the single-particle distribution
function ft(r, v) = f (r, v, t) for a dilute gas of N identical hard impenetrable spheres
R3. It is a non-linear integral-diﬀerential
of mass m and diameter a in a region Λ
equation which reads (with no external force ﬁeld)

⊂

∂
∂t

ft(r, v) + v

rft(r, v) = Q(ft, ft) =

· ∇
d3v1 Zˆn·(v−v1)≥0

Na2

ZR3

dˆn ˆn

(v
·

−

v1)[ft(r, v1

′) ft(r, v′)

ft(r, v1) ft(r, v)]

−

′) are, respectively, the incoming and outgoing velocities;

where (v, v1) and (v′, v1
and the so-called collision operator Q(

), summarizes the eﬀects of the shocks.

,

·

·

This is one of the most successful equations of physics, with a broad range
In particular, and
of applications and a challenging subject for mathematicians.
despite some remarkable recent advances, the global existence and uniqueness of
well-behaved solutions is still an open problem. However, Boltzmann “derived”
his equation by a straightforward heuristic analysis of the collision process using
some bold simplifying assumptions. Notably, he only considered binary uncorrelated
collisions (no two particles collide more than once), 25 which boils down to the famous
“molecular chaos hypothesis” or Stosszahlansatz.

But, how can a discrete N-particle classical gas be described by a continuous
one-particle distribution function? Sometimes one reads that N f (r, v, t) d3v d3r is
the number of particles of the gas in the inﬁnitesimal region d3v d3r around the
one-particle phase-space point (v, r) at time t. But that cannot be: when the
gas is in the micro-state ω(t) = Tt(ω(0)) = (q1(t), v1(t), . . . , qN (t), vN (t)), the
R3, is given by
number of particles in, say, a rectangular parallelepiped ∆
N

×

⊂

Λ

I∆(qi(t), vi(t)), which is an integer.

Xi=1

So, instead of introducing a random ingredient in the system, usually justiﬁed
on the basis of “ignorance” or “imprecision” on the initial data, one could take
the viewpoint that ft(
) gives a macroscopic description of the gas as a con-
tinuum medium, from which one gets, for instance, the hydrodynamic ﬁelds of
ftd3v,

mass, momentum and kinetic energy densities respectively: ρ(r, t) = mN

·

·

,

ZR3

ρu(r, t) = mN

vftd3v and e(r, t) = mN

v2ftd3v. 26

ZR3

1
2

ZR3

25Ternary and higher order collisions are of two kinds: “genuine” (i.e., simultaneous) which, as
we have seen, are negligible; and “correlated successive binary collisions” carrying memory eﬀects,
which are crucial in the study of dense ﬂuids, see Cohen, 1993.

26Incidentally, the derivation of hydrodynamic (Euler, Navier-Stokes) equations from Boltz-

10

In other words, f gives an approximate (“coarse-grained” or “reduced”) descrip-
tion of the system which in Lanford’s analysis is made precise as follows (Lanford,
1983): a micro-state ω = (q1, v1, . . . , qN , vN ) is said to be “close” to f (r, v) when

F∆(ω) =

I∆(qi, vi)

f (r, v)d3r d3v,

≈ Z∆

1
N

N

Xi=1

which approximation becomes exact only in an appropriate limit. It was H. Grad
who suggested that the limit involved here should reﬂect (in idealized form) the
physical situation of a dilute gas where the diameter of the particles is much smaller
than the mean free path, so that particles rarely meet. This translates to N
→ ∞
0 with Na2 converging to a ﬁxed non-zero constant, called the kinetic limit
and a
or, as suggested by Lanford (1976), Boltzmann-Grad limit (p. 79). Note the total
volume occupied by the particles is of order Na3 which goes to zero, such that one
is dealing with an “inﬁnitely diluted gas”.

→

Now, as one cannot expect the approximation condition to hold for all micro-
states, one resorts to a typicality argument to at least guarantee that it will hold
for the “vast majority” of them. Introduce then the following notion: a sequence
N ≥1 of probability measures on phase-space 27 is an approximating sequence
PN
{
for f if, for all ǫ > 0,

}

PN

ω

ΩΛ,N :

F∆(ω)

f (r, v)d3r d3v

> ǫ

0,

∈

(cid:2)

|

− Z∆

|

(cid:3) →

in the Boltzmann-Grad limit. This renders precise the micro to macroscopic change
of description. 28

We can now state Lanford’s theorem, in a very simpliﬁed form, as follows:

Let ft(r, v) be a mild solution of Boltzmann’s equation with initial data
f0(r, v). Under some technical hypotheses, if
N ≥1 is an approxi-
mating sequence for f0, then there exits a t0 > 0 such that the time-
evolved (under the hard sphere dynamics) sequence
N ≥1 is
approximating for ft(r, v), for all t

T−t

[0, t0].

PN

PN

}

◦

}

{

{

It is important to realize that Lanford’s theorem does not say that Boltzmann’s
equation holds “on the average” but that it describes the macroscopic behavior of

mann’s equation has a long tradition going back to Hilbert and is nowadays quite complete (see
Esposito, Lebowitz and Marra, 1999). The much harder problem of deriving them from New-
ton’s equations, pioneered by Morrey’s work in the ﬁfties, is still essentially open. Recently, Olla,
Yau and Varadhan (1993) were able to get it but at the cost of introducing some unwarranted
assumptions (of technical nature), such as adding a small stochastic noise to Newton’s equations.
27Each PN is deﬁned on the corresponding phase-space ΩΛ,N which should also be modiﬁed to

exclude overlapping of the particles.

28The concept of approximating sequence also has built-in the molecular chaos property, see

Cercignani, Illner and Pulvirenti, 1994, p. 92.

∈

11

the gas (in the Boltzmann-Grad limit) for the “vast majority” of micro-states which
are initially close to f0, at least for some small time interval. The result can be
seen as a law of large numbers as the conclusion is that for all ǫ > 0 and in the
Boltzmann-Grad limit, for t

[0, t0]:

∈

|

PN

ω
(cid:2)

∈

ΩΛ,N :

F∆(Tt(ω))

ft(r, v)d3r d3v

> ǫ

0.

− Z∆

|

(cid:3) →

The rather technical proof, based on a careful analysis of Liouville’s equation
and the BBGKY-hierarchy (see Cercignani, Illner and Pulvirenti, 1994 or Spohn,
1991), requires a “proper balance between dynamics and probability” (Grad, 1949).
As it turns out, Lanford’s proof is a local result, that is, valid only for a very
short (but strictly positive) time-interval, of the order of one-ﬁfth of a mean free
path. Though this is a severe shortcoming for applications, it does not diminish the
great conceptual impact of the result. As remarked by Illner (1988) “the limiting
evolution given by the Boltzmann equation is irreversible even on such a small time
interval” (p.158). Of course a major open problem is to improve the time scale of
the theorem. 29 As for the more realistic case of dense ﬂuids the situation is much
harder (for a discussion, see Cohen, 1997).

Lanford’s theorem is thus the ﬁrst and “remains the only rigorous result on the
scaling limits of many-body Hamiltonian systems with no unproven assumptions”
(Yau, 1998, p.194).
It can be seen, even with all its restrictions, as the realiza-
tion, after nearly a hundred years, of Boltzmann’s intuitions as made precise by
Hilbert, Grad, Morrey and many others. According to Gallavotti (1999), “this is
an important conﬁrmation, mathematically rigorous, of Boltzmann’s point of view
according to which reversibility, and the corresponding recurrence times, is not in
contradiction with the experimental observation of irreversibility” (p. 35).
4. Conclusions

The standard textbook justiﬁcation for the use of probability in classical statis-
tical mechanics follows an operationalistic view. First, as the microscopic dynamics
itself is non-random, any randomness is shifted to the initial conditions. Then, goes
the argument, due to our inability to either solve the huge number of equations or
measure with precision the initial data, we have to resort to statistics.
In other
words, human limitations are the basis for the justiﬁcation.

We ﬁnd that untenable and we argued in favor of an alternative viewpoint based
on the notion of typicality. This is not to say that other viewpoints would not
be more adequate in other contexts, but that in the case of classical statistical
mechanics typicality seems to be more natural. It does not invoke any randomness
(ontological or epistemological), which is consistent with the kind of classical system
at hand. Also, as we have seen, measure-theoretical typicality arguments have been
used successfully in the qualitative study of Hamiltonian systems in many other

29Results in this direction were obtained for a rareﬁed gas in all space, under additional hypoth-

esis on the initial data of Boltzmann’s equation (see Illner and Neunzert, 1989).

12

contexts. The idea is to obtain results valid for the “overwhelming majority” of
initial conditions.
In this sense, as the initial conditions are an integral part of
mechanical systems, probability-as-typicality is not that foreign to mechanics.

Of course, one does need an ingredient “outside of mechanics” when trying to
bridge the micro and macro levels of description which is the main goal of statistical
mechanics. Boltzmann had the intuition that some idealized limit would be involved
and, as Lanford’s analysis illustrates, in classical statistical mechanics probability
measures enter as crucial level-connecting concepts in realizing that goal in a rigorous
way. Also, we think that his proof does not mean that the macroscopic laws are valid
with exceptions. On the contrary, we think that probability-as-typicality is a way
to express, in a mathematically precise (albeit idealized) way, the universal validity
of those laws and their compatibility with the atomistic-mechanical microscopic
In fact, as mentioned before, in measure theory or probability theory, a
model.
result is taken to be valid when the set of exceptions is rare in the sense of having
very small measure/probability. So, even if the set of exceptions is large when seen,
so to speak, through diﬀerent lenses (for instance, using set cardinality), it is still
negligible as seen though the measure-theoretic yardstick.

As usual in mathematical-physics, the idealizations are the unavoidable price to
pay in exchange for rigorous analysis. Another example: in equilibrium statistical
mechanics in order to deﬁne phase-transitions points as singularities of the partition
functions one has to take the thermodynamic limit. This does not mean that real
(ﬁnite) physical systems do not exhibit phase-transitions but that the idealization
expressed by the limit N
helps in better handling the problem mathematically
than with a ﬁnite system. 30

→ ∞

Many tough questions are still to be addressed. For example, as typicality is
relative to the measure used, how one justiﬁes a particular choice? Under what
criteria? Moreover, what about other notions of typicality? Also, as we mentioned,
typicality is not enough to decide when a given initial data belong to a desired
subset, which is very important regarding the trend to equilibrium issue. And of
course, typicality does not avoid the need of rigorous analysis and proof.

Finally, though the notion of probability-as-typicality is not new, it is seldom
articulated clearly and it should be allowed more space in the debates on the foun-
dations of statistical mechanics. We also think that the appearance of that notion
at approximately the same time in the theory of dynamical systems and statistical
mechanics deserves a deeper investigation as it could be seen as a symptom of that
broad historical transition from quantitative to the qualitative methods.

ACKNOWLEDGMENTS

Work partially supported by FINEP (Pronex, “Fenˆomenos Cr´ıticos em Proba-

bilidade e Processos Estoc´asticos”) and FAPERJ.

30As remarked by the late mathematical-physicist R. Dobrushin (1997), “inﬁnity is a better

approximation to the number 1023 than the number 100” (p.227).

13

REFERENCES

Barrow-Green, J. (1997). Poincar´e and the three-body problem. History of Mathe-
matics, vol. 11, American Mathematical Society and London Mathematical Society.

Boldrighini, C. (1996). Macroscopic limits of microscopic systems. Rediconti di
Matematica, Serie VII, Vol. 16, p. 1-107.

Brush, S. G. (1994). The kind of motion we call heat. A history of the kinetic theory
of gases in the 19th century. 1. Physics and the Atomists, 3rd. ed., North Holland,
New York.

Bunge, M. (1967). Foundations of Physics, Springer-Verlag, New York.

Bunge, M. (1988). Two faces and three masks of probability. In E. Agazzi (ed.),
Probability in the Sciences, Kluwer Academic Publishers, 27-50

Cercignani, C. (1998). The man who trusted atoms, Oxford University Press, Ox-
ford.

Cercignani, C., Gerasimenko, V.I. and Petrina, D. Ya. (1997). Many-particle dy-
namics and kinetic equations, Kluwer Academic Publishers, Dordrecht, Boston.

Chenciner, A. (1999). De la M´ecanique C´eleste `a la th´eorie des Syst`emes Dy-
namiques, aller et retour.
www.imcce.fr/Equipes/ASD/person/chenciner/chen preprint.php

Choquet, G. (2004). Borel, Baire, Lebesgue. In Autour du centennaire Lebesgue-
Panoramas & Synth´eses, 18, 23-37.

Cohen, E.G.D. (1993). Kinetic theory: understanding nature through collisions,
Am. J. Phys. 61 (6), 524-533.

Cohen, E. G. D. (1997). Bogolubov and kinetic theory: the Bogolubov equations.,
Mathematical models and methods in applied sciences, vol. 7, no. 7, 909-933.

Corry, L. (1997). David Hilbert and the axiomatization of physics, Arch. Hist.
Exact Sci., 51, 83-198.

Diaconis, P., Holmes, S. and Montgomery, R. (2004). Dynamical Bias in the Coin
Toss. www.count.ucsc.edu/ rmont/papers/headswithJ.pdf

Dobrushin, R. L. (1997). A mathematical approach to foundations of statistical
mechanics. In Boltzmann’s legacy 150 years after his birth, Atti dei Convegni Lincei
131, Academia Nacionale dei Lincei, Roma, 227-243.

D¨urr. D. (2001). Bohmian Mechanics. In Bricmont, J., D¨urr, D., Gallavotti, M.C.,
Ghirardi, G., Petruccione, F. and Zangh`ı (eds.), Chance in Physics, Springer, New
York, pp. 115-131.

14

Esposito, R., Lebowitz, J. L. and Marra, R. (1999). On the Derivation of Hydro-
dynamics from the Boltzmann Equation. Physics of Fluids, 11, 2354-2366, 1999.
DIMACS TR 2000-05.

Gallavotti, G. (1999). Statistical Mechanics: A Short Treatise, Theoretical and
Mathematical Physics, Springer, New York.

Goldstein, S. (2001). Boltzmann’s approach to statistical mechanics. In Bricmont,
J., D¨urr, D., Gallavotti, M.C., Ghirardi, G., Petruccione, F. and Zangh`ı (eds.),
Chance in Physics, Springer, New York, pp.39-54.

Grad, H. (1967). Levels of description in statistical mechanics and thermodynam-
In M. Bunge (ed.) Delaware seminar on foundations of physics, Studies in
ics.
Foundations, Methodology, vol. 1, 46-79.

Guerra, F. (1993). Reversibilidade/Irreversibilidade. In Enciclop´edia Einaudi, no.
24, Imprensa Nacional-Casa da Moeda, Portugal, pp.345-384.

Henkel, M. (2001). Sur la solution de Sundman du probl`eme des trois corps,
Philosophia Scientiae 5 (2), 161-184.

Hoare, G. T. Q. and Lord, N. J. (2002). ‘Int´egrale, longueur, aire’ the centenary of
the Lebesgue integral. The mathematical gazette, march. 3-27.

Illner, R. (1988). Derivation and validity of the Boltzmann equation: some remarks
in reversibility concepts, the H-functional and coarse-graining. In Material instabil-
ities in continuum mechanics and related mathematical problems, J. M. Ball (ed.),
Clarendon Press, Oxford, pp.147-174.

Illner, R. and Neunzert, H. (1989). Global validity of the Boltzmann equation for
a two- and three-dimensional rare gases in vacuum: Erratum and improved results.
Commun. Math. Phys., 121, 143-146.

Kac, M. (1949). Statistical independence in probability, analysis and number theory,
The Carus Mathematical Monographs, no. 12, MAA.

Kahane, J.-P. (2001). Naissance et posterit´e de l’int´egrale de Lebesgue., Gaz. Math.
89, p.5-20.

Kolmogorov, A. N. (1956). Foundations of the Theory of Probability, 2nd ed., Chelsea
Pub., New York.

Laskar, J. (1992). La stabilit´e du syst`eme solaire. In Dalmedico, A.D., Chabert,
J.-L. and Chemla, K. (eds.) Chaos et d´eterminisme, ´Editions du Seuil, 171-211.

Lanford, O. E. (1983). On a derivation of the Boltzmann equation. In J. L. Lebowitz
and E. W. Montroll (eds.), Non-equilibrium Phenomena I, Chapter 1, North-Holland
Publishing Company, 3-17.

15

Lanford, O. E. (1976). Time evolution of large classical systems. In J. Moser (ed.),
Lecture notes in physics, 38, Springer, Berlin, Heidelberg, p. 1-111.

Mazliak, L., Chaumont, L. and Yor, M. (2004). Kolmogorov: Quelques aspects
de l’oeuvre probabiliste. In L’h´eritage de Kolmogorov en math´ematiques, Editions
Belin.

Olla, S., Varadhan, S. R. S. and Yau, H. T. (1993). Hydrodynamical limit for a
Hamiltonian system with weak noise. Comm. Math. Phys., 61, 119-148.

Oxtoby, J. L. (1971). Measure and Category, Springer-Verlag, New York.

P¨oschel, J. (2000). A lecture on the classical KAM theorem. Proc. Symp. Pure
Math., 69, 707-732.

Saari, D. G. (2005). Collisions, Rings and Other Newtonian N-Body Problems,
CBMS, Regional Conference Series in Mathematics, Number 104, American Math-
ematical Society, Rhode Island.

Spohn, H. (1991). Large scale dynamics of interacting particles, Springer-Verlag,
Berlin.

Torretti, R. (1999). The philosophy of physics, Cambridge University Press.

Truesdell, C. A. (1966). The ergodic problem in classical statistical mechanics. In
Six Lectures on Modern Natural Philosophy, Springer-Verlag, New York, pp. 65-82.

Uﬃnk, J. (2004). Boltzmann’s work in statistical physics. In Stanford Encyclopedia
of Philosophy.

Volchan, S. B. (2002). What is a random sequence? Am. Math. Monthly 109, No.1,
January, pp 46-63.

von Plato, J. (1983). The method of arbitrary functions. Brit. J. Phil. Sci. 34,
37-47.

von Plato, J. (1991). Boltzmann’s Ergodic Hypothesis. Archive for History of Exact
Sciences, 42, pp. 71-89.

von Plato, J. (1998) Creating Modern Probability, Cambridge University Press.

Yau, H.-T. (1998). Scaling Limit of Particle Systems, Incompressible Navier-Stokes
Equation and Boltzmann Equation. Doc.Math.J.DMV. Extra Volume ICM III, 193-
202.

In Proceedings of the
Yoccoz, J.-C., (1995). Recent developments in dynamics.
International Congress of Mathematicians, 1, 247-265, Birkh¨auser Verlag, Zurich,
Basel.

Wick, D. (1995). The infamous boundary. Copernicus, Springer-Verlag, New York.

16

Wightman, A. S. (1976). Hilbert’s sixth problem: mathematical treatment of the
axioms of physics. In Proceedings of Symposia in Pure Mathematics, vol. 28, AMS,
pp.147-240

S´ERGIO B. VOLCHAN
Departamento de Matem´atica, Pontif´ıcia Universidade Cat´olica do Rio de Janeiro,
Rua Marquˆes de S˜ao Vicente 225, G´avea, 22453-900 Rio de Janeiro, Brasil
volchan@mat.puc-rio.br

17

