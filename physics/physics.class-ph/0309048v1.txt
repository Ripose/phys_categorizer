3
0
0
2
 
p
e
S
 
0
1
 
 
]
h
p
-
s
s
a
l
c
.
s
c
i
s
y
h
p
[
 
 
1
v
8
4
0
9
0
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

]

Feynman Rules for Brownian Motion

S. T. Hatamian1
1Mathematicus Laboratories, Suite 1296, 25 New York Ave, Sound Beach, NY 11789-0972 ∗
(Dated: February 15, 2014)

We present a perturbation theory extending a prescription due to Feynman for computing the
probability density function in brownian-motion. The method used, can be applied to a wide variety
of otherwise diﬃcult circumstances in brownian-motion. The exact moments and kurtosis, if not
the distribution itself, for many important cases can be summed for arbitrary times. As expected,
the behavior at early time regime deviate signiﬁcantly from the usual diﬀusion theory; a fact with
important consequences in various applications such as ﬁnancial physics. A new class of functions
dubbed “Damped-exponential-integrals” are also identiﬁed.

PACS numbers: 02.50.Ey, 05.40.-a, 36.20.Ey, 42.68.Ay, 89.65.Gh

I.

INTRODUCTION

The understanding of Brownian-motion has been of
import on many levels in pure and ap-
fundamental
plied physics. For example, the propagation of light in
gaseous media has long been important in atmospheric
and stellar physics[1]. In chemical-physics the topology of
polymers[2] is of great interest. Yet, unlike topics of com-
parable ubiquity, Brownian-motion has immediate appli-
cations in the human realm, ranging from the physics
of ﬁnance[3, 4], to medical
imaging[5], and military-
reconnaissance.

The diversity of the applicants has resulted in a
plethora of methodologies which have delineated the evo-
lution of this ubiquitous topic. Among these techniques
the path integral formulation of the stochastic move-
ment, while often more imaginative, is grossly under-
represented if not under-utilized. This assessment applies
rather equally to path integral applications in quantum
mechanics; though in both cases much more so in peda-
gogy than in research.

Particularly in the case of stochastic motion, the stan-
dard methodologies based on diﬀerential equations, lead
to diﬃcult and unintuitive equations as soon as one gets
away from the limiting situations such as inﬁnitesimal
scattering lengths, long-time regimes, or central limits.

In this missive we present a technique based on an
a method invented by Feynman[6], allowing notions of
Feynman diagrams for the non-thermalized stochastic
movement. The technique of path integration, also
known as sum over histories, is particularly attractive in
the case of stochastic motion because of the vivid imagery
it is associated with, literally illustrating the mathemat-
ical process[7].

In section-II we summarize the groundwork[6] on which
we will build our method. In section-III we present the
full solution to an illustrative problem set up in[6] but

∗Electronic address: tsh@MathematicusLabs.com

only solved for small displacements. Section-IV illus-
trates how extraneous features such as noise or force ﬁelds
can easily be integrated in the “propagator”. Section-V
presents the solution of an important variation on the
same problem which is relevant to ﬁnancial physics. The
ensuing two sections, consider the problem of random
ﬂights under invariant speed. We then conclude with
two speciﬁc applications of the results in modelling ﬂex-
ible (polymer) chains and stock prices.

II. FEYNMAN’S PRESCRIPTION FOR
STOCHASTIC PROCESSES

In this section we review the prescription[6] for com-
puting the probability density function for a random pro-
cess using functional integrals. Suppose that f (t) de-
scribes a realization of a random process as function of
time. Called a “probability functional”, P [f (t)], then
gives the probability density of a given realization.
If
we think of f (t) as an ordered collection of discrete val-
ues f1, f2, ..., fn in the limit of n
, the probability
of ﬁnding a realization f (t) is given by P [f (t)]
≡
limn
P (f1)P (f2)...P (fn)df1df2..dfn within a hyper-
neighborhood given by the latter expression. The con-
jugate “characteristic functional” is computed by:

→ ∞

f (t)

→∞

D

Φ[k(t)]

≡ R

ei
R

k(t)f (t)dtP [f (t)]
f (t)

P [f (t)]

D

f (t)

.

D

(1)

R

D

Feynman[6] showed that despite the challenging appear-
ance of this expression, it might be possible that un-
der certain practical conditions the discretized form of
f (t) can yield to either term by term integration,
P [f (t)]
or known forms of path-integrals. Suppose that each ran-
dom event has a time signature given by g(t). Then the
full realization of n-events over a ﬁxed time interval T is
simply f (t) =
tj). If the events are randomly
distributed in time, then the probability of each event
occurring within the interval dt is dt/T . Inserting f (t)
and P [f (t)] into Eq.(1) and noting the identical form of

n
j=1 g(t

P

−

2

each integral we get:

Φng[k(t)] =

T

ei
R

 Z
0

k(t+τ )g(t)dt dτ

n

T !

(2)

where we have used τ as a stand in for any given tj.
For typical applications, the shape or at-least the am-
plitude of each event is often not ﬁxed. We therefore
consider the case g(t)
au(t) where the shape u(t) of
the event is ﬁxed but its amplitude a varies according
to some probability density p(a). We must now average
Φng[k(t)] over all values of a. Being that the latter is of
form (φg[k(t)])n, and that the events are independently
distributed, we can carry out this average separately for
each component φg:

≡

φ

< φg >g=

≡

T

dτ
T

0
Z

Z

ia
Z

(cid:20)

exp

k(t)u(t

τ )dt

p(a)da.

−

(cid:21)

(3)
The inner expression is a fourier transform of p(a) where
the frequency variable is the integral in the exponent.
The fourier-transform being a characteristic-function,
will be designated as W [
τ )dt]. Finally, if the
number of events over T is governed by a Poisson dis-
tribution, we can readily average over all possibilities of
n:

k(t)u(t

−

R

spread. In between events, the movement of the particle
is governed by its appropriate equation of motion. Our
objective is to ﬁnd the resulting spatial distribution of
particles after a given time T .

At every event the particle acquires a change in mo-
mentum which is a random selection from a gaussian
distribution of spread s and zero mean. The characteris-
tic function W (ω) of the gaussian random force-function
proﬁle is simply another gaussian. When inserted into
Eq.(6) we have:

Φ[k(t)] = e−

λT exp

λ

e−

k(t)2s2/2dt

(7)

T

"

0

Z

.

#

As discussed in the previous section, the probability
density of the force function P [f (t)] is given by the fourier
transform of Φ[k(t)]:

P [f (t)] =

Φ[k(t)]e−

i

k(u)f (u)du

Z
eλ

T

0

R
−k(t)2 s2/2dte−

i

e

T

0

λT

e−

Z

R

R

k =

D

k(u)f (u)du

k.

(8)

D

In order to proceed we discretize the time interval [0, T ]
into N , regular small intervals η. With the understanding
that N

:
→ ∞

Φ[k(t)] =

φn ¯nn
n!

e−

¯n.

(4)

P [fi] = e−

λT

exp

ληe−

ki

2s2/2dt

e−

iηikifi .

n
X
Here ¯n = λT is the average number of events expected
over T . The sum is simply an exponential:

(9)
Finally, we expand the ﬁrst exponential in a Taylor series
and carry out the individual fourier transforms:

h

i

N

i Z
Y

dk
2π

Φ[k(t)] = e−

(1

φ)¯n =

−

T

exp

"−

λ

1
0 (cid:18)
Z

−

(cid:20)Z

W

k(t)u(t

τ )dt

dτ

. (5)

−

(cid:21)(cid:19)

#

An important special case of the process described by
Eq.(5) is when the signal-event has an extremely short
duration in time: u(t) = δ(t). Then the characteristic
functional becomes:

Φ[k(t)] = exp

λ

(1

W [k(τ )]) dτ

.

(6)

T

"−

0
Z

−

#

III. THE GAUSSIAN SCATTERING PROCESS

Using the characteristic Eq.(6) we can compute vari-
ous moments of the signal proﬁle f (t). However, the true
utility of this approach is to discover the resulting distri-
butions of dependent variables which are driven by the
events in f (t). In this, and the following two sections,
we will investigate cases of movement of free particles of
unit mass, which undergo a prescribed change in their ve-
locity for every event in f (t). Initially the particles have
a delta-function distribution in both speed and spatial

N

P [fi] = e−

λT

δ(fiη) +

λη
s√2π

e−

(fiη)2/2s2

+ . . .

Y

i (cid:20)

(cid:21)
(10)
whereupon we recognize fiη
Ii as the impulse imparted
≡
at time ti. The leading (zeroth-)order in η is a product
of δ-functions which we’ll call a δ-functional δ[I(t)]. The
value of the functional is zero unless the function I(t) is
zero for all t. The zeroth-order term

P0[I(t)] = δ[I(t)]

(11)

corresponds to the ballistic path where the particle expe-
riences no collisions and hence experiences no impulses.
The O(η) terms are comprised of all δ’s, except at time
ti where a single term of O(η) contributes. There are N
such terms (one for each ti) comprising a Riemann sum.
In the limit of large N this sum becomes the integral:

P1[I(t)] =

dt e−

I(t)2/2s2 ¯δ[I(t)].

(12)

1
s√2π

T

0
Z

The functional ¯δ[I(t)] is deﬁned as the (limN
) product
of δ(I(ti)) for all ti except ti = t. This term describes the
path where there is only a single collision at time t. It is
easy to show that if the scattering proﬁle had an oﬀset,

→∞

3

then it would change the exponent of the integrand to
I(t)

I0. Higher order terms in η are easily obtained:

−

Pn[I(t)] =

n

ti+1

1
s√2π

0
Z

dtie−

I(ti)2/2s2 ¯δ[I(t1), ..., I(tn)]

i=1
Y
where tn+1 ≡
expression for the probability density functional:

(13)
T . Upon collecting the orders we get the

x

t

P [I(t)] = e−

λT ∞

λnPn[I(t)].

(14)

n=0
X

In order to obtain the probability density of a given
output position P (X) we must ﬁrst derive P [x(t)] from
P [I(t)]. We then will sum over all paths x(t) which sat-
isfy the boundary conditions: x(t = 0) = x0 ; x(t = T )
X; ˙x(t = 0) = v0; ˙x(t = T ) = V .

≡

The ﬁnal sum over paths can easily be done because
of the insight we have acquired by recognizing the vari-
ous orders in the series of Eq.(14) as paths with a given
number of events. The zeroth order term is the easiest;
it is simply the sum over all paths which experience no
impulses, of which there is only one. However, to proceed
more formally we will utilize the following observation[6].
As long as the relation between I and x is linear (e.g.
I
¨x), we can be sure that any Jacobian resulting from
the change of variable:

∝

Pn[I(t)]

I = Pn[x(t)]

x

D

D

(15)

is a constant, and if skipped, aﬀects only the normal-
ization of the ﬁnal answer. The normalization of the
resultant distribution must be ensured regardless. Thus,
from Eq.(13), and (15):

P0(X, T ) =

δ[I(t)]

I =

δ[¨x(t)]

x = δ(X

v0T ).

Z

D

Z

D

−

(16)
The above relation (arguably the easiest path integral
known) establishes the “propagator” for the process. Us-
ing Eqs.(13), (15), and two applications of Eq.(16), the
ﬁrst order term is the sum over all paths with a single
event and is given by:

T

P1(X, T ) =
1
s√2π
0
Z
δ (X
−
1 /2s2
I 2

×

e−

×

+

∞

dx1

+

∞

dI1

dt1

Z
−∞
t1) + x1))

−∞

Z
((v0 + I1)(T
δ(x1 −

−
v0t1 −

x0).

(17)

This expression is easy enough to evaluate using the rule
δ(ax) = δ(x)/

and we will do so shortly.

a
|

|

FIG. 1: The diagrammatic representation of brownian mo-
tion through a medium.

can be represented by (Feynman) diagrams. The dia-
grams comprise propagators and interaction points and
the necessary factors to integrate over intermediate vari-
ables. In one-dimension the nth term is given by:

Pn(X, T ) =

d2xn . . .

d2x1Kf nVn . . . K21V1K1i

Z

Z
d2xi =

(18)
ti+1
dti. The speciﬁcs of the
where
0
problem are contained in the propagator K and the in-
teraction proﬁle V . Each term in the above equation,
and the ﬁnal summation thereof can be represented dia-
grammatically as in ﬁgure-1.

∞
−∞
R

dxi

R

R

For the case of a free particle undergoing a scattering
process (which conserves momentum), the propagator is:

i

+
∞
dIi δ

K s

1
ti+1 −

xi+1 −
ti+1 −

xi
ti −

(

 

−∞

tiZ

Ii −

i+1,i =

v0)
!
(19)
(Note: we will only treat the case of free particles here, so
we will not clutter the super/subscript notation to that
eﬀect.) The interaction points V g
contain
the gaussian proﬁle of the ith event.

√2πs2 eI 2

i = 1

Ik −

i /2s2

Xk=1

.

The propagator can be generalized to other types of
motion between collisions by simply replacing the classi-
cal equation of motion as the argument of the δ-function
or other appropriate kernel.

At higher orders, the computation gets increasingly
diﬃcult and a recursion relation between orders of Pn
does not exist in general. This is true in the present case
of gs-process. For example to get P gs
3 we must repeat the
integration over x2 because K s
f 3 involves x2. Therefore
a more complicated integral over x2 must be performed
before the integration over x3 is done. Despite this com-
plication, the computation of P gs
n (X, T ) can be carried
out for arbitrary n, giving:

P gs

n (X, T ) =

1
ξgs
n

×

exp

1
√2π
(x

0
Z

−

−

(cid:18)

T

t2

dtn . . .

dt1

0
Z

(x0 + v0T ))2
2
2 ξgs
n

(cid:19)
2, is given by:

ξgs
n

2 = s2

ti)2.

(T

−

n

i=1
X

(20)

(21)

A. Feynman Rules

where the “interim variance” ξgs
n

Upon writing the sequence of terms P1, P2, ... we can
see the that the unevaluated integrals (such as Eq.(17))

n=0

l

n
o
i
t
a
u
p
o
P

0.8

0.6

0.4

0.2

0.0

n=1

n=2

n=3

n=4

50

Time

10

30

70

90

FIG. 2: The relative population Eq.(22) of generations n,
being the number of events they have experienced. Curves
shown here are for λ = 0.1. The peaks occur at T = λ/n.

As we will see below, the summation over the orders can
be easily carried out in the fourier domain.

Should for some reason, the eﬀect of scattering medium
be artiﬁcially stopped after a ﬁxed number of events,
then the probability distribution is given by a new class
of functions which we have named: “Damped exponen-
tial Functions”. These functions are described in the
appendix-A.

B. Normalization

We can directly demonstrate the proper normalization
of P gs(X, T ) by integrating Eq.(20) over all X, and in-
serting the resulting terms in Eq.(14). Moreover, it is
interesting to note the temporal population of each “gen-
eration” given by:

Nn(T ) =

Pn(X, T )dX =

e−

λT .

(22)

(λT )n
n!

e−

λT λn
n!

Z

Reﬂecting our initial assumption, this is simply the Pois-
son distribution. Summing over all n shows normaliza-
tion. The population of each generation n will rise and
fall according to the above relation each with a peak at
T = λ/n (ﬁgure-2).

Another way to verify the normalization of the
gaussian-scatter solution is as follows. The quantities
Nn(T ) must satisfy the simple coupled rate equations:

˙N0 =
−
˙N1 = λN0 −

λN0
λN1
. . .
λNn.

˙Nn = λNn
−

1 −

4

It easily veriﬁed that the solution for these equations is
given by Eq.(22)

C. Moments and Kurtosis

We will shortly demonstrate that the exact characteris-
tic function for the gs-process Φgs(k, T ) can be obtained.
Therefore all moments can be readily obtained by simple
diﬀerentiation. However, the ability to obtain the char-
acteristic function for a given process in closed form is
not guaranteed. Hence we will demonstrate the direct
computation of the moments by summing the moments
of each order. We shall specialize to the case where all
initial settings x0, v0, I0 are zero. we compute The mth
moment of the nth order distribution and then sum them
according to Eq.(14). For the second moment this is:

< X 2>gs

n =

s2
n!

T

T

. . .

dnτ

n

τ 2
i =

0

Z

0
Z

1
X

s2T n+2
1)!
3(n

−

(23)

ti). The discrete sum is nτ 2 by symmetry,
where τi = (T
−
1,
1 integrals of measure unity giving T n
there are n
and one more integral on τ 2 producing T 3/3. Inserting
the result in Eq.(14) gives:

−

−

νgs ≡

< X 2>gs=

s2T 2e−

λT ∞

1
3

(λT )n
1)!
(n

−

=

s2λT 3,

1
3

n=1
X

(24)

in agreement with the ﬁrst order computation in [6].

∝

Based on the statement of the problem we can expect
< V 2>
s2T . Traditionally the computation of Brown-
ian motion is within a system in equilibrium with a well
deﬁned temperature. In that case [1, 7] the thermal equi-
librium constrains the parameter s to the coeﬃcient of
friction and the temperature, and all three to < V 2>. In
the present case, no friction exists, therefore nor a ﬁnite
temperature as evidenced by the ever increasing < V 2>.
A similar but more tedious computation for the fourth

moment produces:

χgs ≡

< X 4>gs= s4λT 5(

+

3
5

λT
3

).

(25)

The ﬁrst term is the result of cross-terms like (T
−
tj)2 in the time integrals, whereas the second term is the
ti)4. Ostensibly, it is the
result of direct-terms like(T
presence of the interference terms that cause deviations
from a normal distribution. Although as expected (from
the central-limit-theorem) the deviation is transient. To
quantify this we compute the kurtosis for the process:

−

−

ti)2(T

κgs ≡

χgs
3νgs

2 −

1 =

9
5λT

.

(26)

Thus the distribution approaches normality in time. It
is, moreover, worth noting that this result is independent
of the parameter s.

5

104.0 Pgs(X,T=10)

103.0

102.0

101.0

100.0

10-1.0

/

X
d
N
d

104
7
5
4
3

2

103
7
5
4
3

2

102
7
5
4
3

2

101
7
5
4
3

2

100

200

150

100

50

-50

-100

-150

-400

-200

200

400

0

X

Gaussian Fit

0

X

FIG. 3: Demonstration of The Kurtosis(Fat-tails) as calcu-
lated for the gs-process at λT = 10 versus the ﬁt of the same
to a normal distribution. As expected from the central-limit
theorem, the ﬁt to a normal distribution progresses in time
from the peak to the tails.

D. The Characteristic Function

Having arrived at a solution for P gs

n (X, T ) (Eq(20)),
the characteristic function is easily found by exploiting
the symmetry in ξgs in the fourier transform of each P gs
n .
The symmetry allows us to convert the sequence of con-
nected integrals into the nth power of a single integral
from 0 to T with an added 1/n! pre-factor. We can then
sum them according to Eq.(14). The result is:

Φgs(k, T ) = e−

λT exp

(cid:18)r
Both the second and fourth moments can readily be veri-
ﬁed by repeated diﬀerentiation of Φgs(k, T ) with respect
to k. The distribution Pgs(X, T ) is shown in ﬁgure-4
versus a computer simulation.

(cid:18)

∝

If it should happen that the equation of motion is of
v0tα(0 < α
the general type, x(t)
1), then the result
is a simple redeﬁnition of Eq.(21) and for certain ratio-
nal values of α the characteristic function can be easily
computed. The result is that the variance will be pro-
portional to T 1+2α and fourth order will be such that the
kurtosis remains proportional to 1/T , independently of
both α and s.

≤

FIG. 4: Pgs(X, T ) as calculated by a numerical simulation of
the gs-process. The one-dimensional distribution is shown at
diﬀerent observation times T . For comparison, at the corre-
sponding time, the prediction of the theory (numeric inverse
transform Eq.(27)) is superposed on the widest distribution.
Only the amplitude of the theoretical curve has been adjusted
to match the simulation. The spike at X = 0 is the ballistic
peak corresponding to the zeroth order theory (not shown).

is easy to verify starting from the fundamentals of the
theory, that the answer is found by replacing the scalar
wave-number k, with the magnitude of the wave-vector.
In case such rotational symmetry exists, applying the
inverse fourier transform, we arrive at the probability
density integrated over a D-dimensional spherical shell
at R:

X
, and J(D/2
|
|

1, kR) is the Bessel function
where, R =
−
1). Thus, if the
of the ﬁrst kind and of order (D/2
gs-process is applicable, we can insert the Dth power of
the characteristic function Φgs directly into the above
relation.

−

Alas the gs-process is not applicable to photons be-
cause the postulate of relativity is not satisﬁed by the
inﬁnite tail of the Gaussian interaction kernel and the
change in momentum after each scattering event is not
independent of those along other dimensions. We will
treat such constrained interactions separately.

π
2

λ
ks

erf

ksT
√2

.
(cid:19)(cid:19)

(27)

P (R) =

R
(2πR)D/2

∞
J(D/2

−

0
Z

1, kR) Φ(k) kD/2dk. (28)

E. Higher Dimensions

IV. THE EFFECT OF NOISE

For the case of a homogeneous and isotropic medium,
and where the scattering proﬁle has no preferred axis, it

If it should be that instead of simple traversal of the
medium the particle diﬀuses in between collisions (“noisy

paths”). We can show that insight provided by the im-
agery of paths allows us to easily incorporate this added
eﬀect into the solution. Suppose Pgsd(y, T ) is the prob-
ability density of arriving at (y, T ) when diﬀusion is
present. arriving at position y can proceed along an in-
ﬁnite number of paths which would have culminated at
diﬀerent x’s if diﬀusion were not present. If we let y = x+z
then z is the component of motion due to noise. Thus
the Pgsd(y, T ) is the sum of all pairs (x, z) which satisfy
the above constraint:

Pgsd(y, T ) =

dx

dz Pgs(x, T )Pd(z, T )δ(y

(x + z))

−

Z

Z

Z

=

dx Pgs(x, T )Pd(y

x, T ).

(29)

−

From here it can be easily shown that the eﬀect can
wholly be incorporated into a new propagator K sd. This
is what we would have expected based on the previously
alluded path imagery. The new propagator (itself obtain-
able by the path integral method [8]) is simply a broad-
ened form of K s

K sd

i+1,i =

exp

 −

dIi

+

∞

σ
(Ii −
p

1
2π(ti+1 −
ti)
( xi+1−
xi
ti+1−
ti −
2σ2/(ti+1 −
P

−∞
i

Z

v0))2

k=1 Ik −
ti)

(30)

!

where σ2 is the diﬀusion coeﬃcient. The computation
of Pgsd(y, T ) proceeds as before. Computation will show
that in presence of diﬀusive movement between scatter-
ing events, the diﬀusion acts in parallel to the process
and thus simply adds a net term to the variance of the
process. Thus, the “interim variance” is:

2

ξgsd
n

= ξgs
n

2 + σ2T.

(31)

And we ﬁnd for the full variance:

νgsd ≡

< y2 >gsd=

s2λT 3 + σ2T ;

(32)

1
3

the fourth moment:

χgsd ≡

< y4 >gsd
3
5

= s4λT 5(

+

λT
3

and the kurtosis:

) + σ2T 2(3σ2 + 2s2λ2T 2); (33)

9s4λT

κgsd =

5(λs2T 2 + 3σ2)2 −−−→Tlarge

9
5λT

.

(34)

We observe that over long times, the eﬀect of diﬀusion
(noise) becomes insigniﬁcant. Finally the characteristic
function is found to be:

Φgsd(k, T ) = e−

(λ+σ2k2/2)T exp

π
2

λ
ks

ksT
√2

erf

(cid:18)

(cid:18)r

.
(cid:19)(cid:19)

(35)

6

In this section we have seen that diﬀusive intra-event
movement can be represented by a change in the func-
tional form of the propagator. Other eﬀects such as that
of an external force ﬁeld can be added to the theory by
incorporating the equation of motion in the argument of
the propagator. For an absorptive medium, a damping
factor in the propagator will be necessary.

V. THE GAUSSIAN RESET PROCESS

Consider if instead of scattering, we characterize the
events as “resets” in the particle’s momentum. It would
be as if the previous momentum is lost at each event and
a new one selected from a gaussian distribution of width
s. This change implies only a diﬀerent propagator:

K r

i+1,i =

dIn
ti+1 −

Z

ti

Ii −
δ
(cid:18)

xi+1 −
ti+1 −

xi
ti (cid:19)

.

(36)

Utilizing this propagator in the Eq.(18), and other rules
we ﬁnd the probability density function P gr
n (X, T ) to be
the same form as the Eq.(20) if only we use a diﬀerent
“interim variance” function as given by:

n

ξgr
n

2 = s2

(ti+1 −

ti)2.

(37)

i=1
X
Following the same steps as in the gs-process, we can
show that in presence of diﬀusive movement between re-
set events the diﬀusion acts in parallel to the process and
thus simply adds a net term to the “interim variance”:

2

ξgrd
n

= ξgr
n

2 + σ2T.

(38)

Unfortunately, for this process, ξgr
n

2 does not posses
the necessary symmetry which allowed us to compute the
characteristic-function in closed form for the gs-process.
Thus we must compute the various moments by summing
the moments of each P gr
n (X, T ) according to Eq.(14).
This task while a little tedious for higher moments, is
straightforward. The variance is found to be:

< X 2 >gr=

νgr ≡

2s2
λ2

λT

2(e−

1) + λT (e−

λT + 1)

.

−

(cid:0)

(39)
(cid:1)
Thus for this process the variance becomes linearly pro-
portional to T in the long time limit (λT
In
very early times the variance increases as s2λT 3/3 which
matches νgs. Later, the momentum non-conservation in
this process manifests its diﬀerent character resulting in
slower spreading of the distribution.

1).

≫

The fourth moment is:

χgr ≡
=

< X 4 >gr
4s4
λ4 [e−
6λT + 3λ2T 2].

−

λT (12 + 18λT + 9λ2T 2 + 2λ3T 3)

12

−

(40)

Variance: gr-Process

5000

4000

3000

2000

1000

0

0

5

10

15

20

25

Time

FIG. 5: The comparison of the variance as calculated from
a simulation of the gr -process (dots), compared to Eq.(39).
The oﬀset solid line is that of 2s2T which is the traditional
assumption of the progression of variance in applications such
as Black-Scholes options-valuation, etc. At early times, the
traditional assumption grossly overestimates the variance.

At early times, the fourth moment also behaves like χgs
increasing proportionally to T 5, but later it settles into a
parabolic increase. The kurtosis for the gr -process has a
steep fall oﬀ at early times, but then settles into
1/λT
descent, like the gs-process:

∼

κgr

−−−→Tlarge

2

λT
(λT

4
2)2 .
−
−

(41)

We conclude by stating the moral of this section. Even
if the probability distribution (or its characteristic func-
tion) may not be computable in closed form, in many
cases, our method allows access to the exact moments of
the distribution.

VI. THE SHOOTING GALLERY

To further demonstrate the power of this method we
will take on a problem where a solution by the “tradi-
tional” approach of stochastic diﬀerential equations is dif-
ﬁcult. Consider the carnival game of “Shooting Gallery”.
A “target-duck” starts moving at the center of a plank
with a ﬁxed speed c to the right. The player is required
to shoot the duck. On every hit the duck reverses direc-
tion and continues to retrace its path with speed c. After
a time T , we need to know the probability distribution
of ﬁnding the duck at a given position X within dX.

The scattering proﬁle (i.e. the distribution from which
the next momentum change is selected) is now comprised

7

of two δ-functions, each oﬀset by the amount
c, respec-
tively. Each lobe of the scattering proﬁle is used in alter-
nate order. Because there is a binary alternation between
left-right symmetric proﬁles we will call this process the
“symmetric-binary-delta-scattering”, or sbds-process.

±

The propagator for this problem is the same as that of
gs-process (Eq.(19)). Furthermore the result for the P gs
1
= 0 (Eq(17)) applies if we replace the interaction
when v0 6
kernel (gaussian proﬁle) with δ(I1 + 2c). Higher orders
can easily be written using the Feynman-rules for this
case. Integration over intermediate positions can proceed
as before and the analog to of Eq(20) is found to be:

P sbds
n

(X, T ) =

T

t2

dtn . . .

dt1

0
Z

0
Z

×

δ

X

 

(v0 −

−

c)T

c

−

(
−

1)n(ti+1 −

ti)

(42)

!

n

i=0
X

where t0 = 0, and tn+1 = T . We consider only the initial
condition v0 = c which results in cancellation the second
term. Although higher orders of the above integral re-
quire a good bit of bookkeeping, the actual integration
are straightforward if aided by computer. By extensive
use of the rule,
t)],
we ﬁnd P sbds

b
a dτ δ(τ
−
(X, T ) to be:

t)f (τ ) = f (t)[Θ(b

Θ(a

−

−

−

t)

n

R

X 2)

n−1
2

(c2T 2
−
2 cn (n

n−2
2

−
X 2)
2)!!

−
−

(X + c T )(c2T 2
2 cn n!! (n

δ(X

cT )

−

n = 0;

1)!!2 B(X, cT ) n = 1, 3, 5, ...;

B(X, cT ) n = 2, 4, 6, ...;

(43)

where n!! = (n/2)! 2n/2 (n-even, e.g. 6!! = 6
2).
The “light cone” is maintained by the “box-car” func-
cT ). Finally, the
tion: B(X, cT ) = Θ(X + cT )
observed probability density is found by summing P sbds
according to Eq.(14). To aid the summation process we
can shift the dummy index n
2n + 2 for even terms
and n

→
2n + 1 for the odds. The summed result is:

Θ(X

−

−

4

n

·

·

→

Psbds(X, T ) = e−

cT ) + B(X, cT )

λT δ(X
−
(X + cT )
ρc/λ

λT

e−
2c/λ

×

(cid:18)

I(1, ρ) + I(0, ρ)

(44)

(cid:19)

where I(k, ρ) is the modiﬁed Bessel function of the ﬁrst
kind and of order k. ρ is a measure of position within
the light-cone, given by:

c2T 2

X 2

−
(c/λ)2

1/2

(cid:19)

ρ

≡

(cid:18)

(45)

We note that this is in agreement with [9] derived
by the laborious method of “telegrapher’s equation”.
Figure-6 shows samples of Psbds over a relatively early
time range for λ = 1 and c = 1.

1

0.8

0.6

0.4

0.2

0

–4

–2

2

x

4

FIG. 6: The time evolution of the sbds-process for c = 1, λ =
1. Here The zeroth order (δ(X −cT ) in Eq.(44)) ballistic peaks
have been artiﬁcially broadened for plotting.

The solution above and that in the ﬁgure pertain to
P (v0 = c) = 1.
= 0 then the
solution can easily be constructed by the superposition
P (v0 = c)Psbds(X, T ) + P (v0 =

In the event P (v0 =

c)Psbds(

X, T ).

c)

−

Finally, we could have modelled the problem with a
reset type propagator as in Eq(36). It is easy to show
that the resulting sbdr -process will give the same answer
as long as the initial condition v0 =
c applies but not
otherwise.

±

−

−

VII. RANDOM FLIGHT IN D-DIMENSIONS AT
AN INVARIANT SPEED

Extending the previous section’s model to higher di-
mensions is of great practical interest in physical systems.
Our method facilitates the setup without diﬃculty. We
shall denote the unit vector along the dth component of
motion after the ith scattering event as eid. As before,
we assume that the particle moves at a constant speed
c, and use the propagator of Eq.(19) for a free, momen-
tum conserving particle. After the easy integration over
intermediate positions we obtain for the end-to-end prop-
agator of the dth component of the position:

N

i=0
X

δ

 

Rd −

(v0d −

ce0d)T

c

−

eid(ti+1 −

ti)

!

(46)

where t0 = 0, and tn+1 = T . The above integrand is
quite plain in its statement about the free particle, and
could have been written without the need for integra-
tion over many intermediate coordinates. We can con-
sider two possible initial conditions: 1.an incident beam
where v0 = c, and 2.a source emitter where v0 = 0.
In the former case we can select v0 = ce0 resulting
in cancelling the middle term, but we must maintain
e0 = (0, 0, ..., 1). Alternatively, we can shift the sum

8

−

to start from 1 but remember that the position vector is
given by R = (x, y, ..., z
ct1). The latter case is sim-
pler because we have e0 = 0 which simply eliminates the
middle term, the sum remains as is, and R = (x, y, ..., z).
Either way, the computations do not depend on the ab-
solute value of the index i, hence this distinction between
initial conditions does not come into play until the very
end whence integrating over interaction times.

According to the Feynman rules we must now add the
interaction kernels and sum over all allowable interme-
diate directions eid as well as times ti. The allowable
states for the particle include only those which maintain
a constant speed c. Therefore, for movement in Euclidean
id = 1
space, we must implement the constraint
for all i. Thus the full diagram for the N th order for the
D-dimensional scattering (Dds-)process is:

D
d=1 e2

P

P Dds

N D (X, T ) =

N

ti+1

D

dti

∞

deid

0
i=0 Z
Y
V (e) δ

×

c

Rd −
 
D

i=0
X

N

−∞

Yd=1Z
eid(ti+1 −

ti)

!

δ

1
 

×

−

e2
id

.

!

Xd=1

(47)

(48)

As a consequence of the nonlinearity of the unit vec-
tor constraints, additional normalization factors will be
needed depending on the explicit dimensionality. Here we
will consider isotropic scattering and thus set V (e) = 1.

In performing these summations we employ a tech-
nique which could also apply to most of the problems
we considered previously but did not for the sake of il-
lustration of the possibility of direct integration. The
δ-function can be represented as an unweighted super-
position of plane waves. This action, amounting to a
fourier transformation of the integrand, results in the end
in the computation of the characteristic function instead
the probability density. However, in this case the de-
composition is especially necessary. Once decomposed,
terms involving a single eid are collected and integrated
separately. There is, however, one further complication:
An integration over eid diverges unless the wave number
corresponding to the second δ-function is always positive.
For this reason we choose an alternate (if obscure) plane
wave superposition given by, δ(x) = Re
−
i/πx, where the second term is understood as the princi-
ple value. Together with the ordinary decomposition of
the ﬁrst δ-function, the integrals over eid involving terms
like i/πx will all vanish. The remainder of terms with eid
dc2(ti+1 −
ik2
each result in
where
the nested products over i and d apply. In order to carry
(cid:0)
out the integration over the κi we perform the product
over i. This conveniently results in the square of the
magnitude of the D-vector k in the exponent. Thus we

0 eiκxdκ/π

π/iκi exp

ti)2/4κi

p

(cid:0)R

∞

(cid:1)

(cid:1)

6
ΦDdis

N (k) =

Re(φD(k, ti))dti.

(50)

FIG. 7: The diagrams that are included in the 1dis-process.
The mirror images must also be included, but are not shown

N

ti+1

0
i=0 Z
Y

arrive at:

+κ2
s2
i
i
iκi

∞

1
π

φD(k, ti) =

e−
(iκi/π)D/2 dκi
k
. Applying the
where, si ≡
|
|
product over i to Re(φD), and the integration over all in-
teraction times ti, we arrive at the characteristic function
for the isotropic scattering after N -events:

kc(ti+1 −

ti)/2 and k =

(49)

0
Z

Before proceeding, we note an important property of φD:

φD+2 =

1
2s

∂φD
∂s

.

−

(51)

That is, the respective characteristic functions for all odd
and separately, all even dimensions are recursively re-
lated. For this reason we need to evaluate the expression
in Eq.(49) for D=1, and 2 only, viz.,

φ1(s) = e2is;

(52)

and after normalization (i.e. φ(0) = 1),

φ2(s) =

K(0, 2s/i);

(53)

1
2iπ

where K(0, x) is the zeroth-order modiﬁed Bessel func-
tion of the second kind.

The probability density is found by performing a D-
dimensional inverse fourier transform on ΦDdis
N . How-
ever, because the ΦDdis
N (k) possesses rotational symme-
try, the angular integrals can be performed and the
fourier inversion reduces to Eq.(28).

A. One-dimensional Isotropic Scattering

Although the motivation for computing the Ddis-
process was the generalization of the shooting-gallery
problem to higher dimensions, it turns out that the latter
is not the same as the one-dimensional (1dis-) process.
This can be most readily seen via the characteristic func-
tion (inserting Eq.(52) into Eq.(50)):

Φ1dis

N (k, T ) =

cos(kc(ti+1 −

ti)) dti.

(54)

N

ti+1

0
i=0 Z
Y

By setting N = 1 in the above and fourier transform-
ing the ﬁrst order function, we can readily see that the
δ-function found after the integration over the interim
coordinates in the sbds-process (Eq.42) is only one of
four we obtain here. We further note that one of the
extra terms corresponds to a ﬁrst-order process where
no velocity ﬂip takes place at the event time t1. The
X) conjugates of
remaining two are the parity (X

→ −

9

0.3

0.2

0.1

–4

–2

2

x

4

FIG. 8: P1dis at λT =1, 3, and 5. The ballistic peaks have
been artiﬁcially broadened for plotting.

the latter two terms. These features reﬂect exactly the
characteristics which produced Eq.(47). That is we only
required that the magnitude of the speed to remain con-
stant at all times, but allowed all possible directions. We
also allowed isotropic initial conditions which added the
parity conjugate terms. Schematically, the 1dis-process
encompasses all diagrams in ﬁgure-7 (plus their parity
conjugates), whereas at each order, the sbds-process in-
cludes only the left most diagram in the ﬁgure. It is as if
after each hit, the duck in the shooting-gallery ﬂips a coin
to decide whether to move forward or reverse direction.
While there are 2N diagrams at each order, there are
only (N+1) distinct results. Other than the ballistic term
present at every order, the remaining N are labelled by
the index j below. Explicit computation of the these
diagram sub-collections yields:

P 1dis

N (X, T ) =

T N
2N N !
1
N

−

×

j=0
X

δ(cT

X) +

−

B(X, cT )N !
(4c)N

(cT + X)j(cT
j)j!2(N

(n

−

X)N
j

j

1

−

−

1)!2 .

−

−
−

(55)

B(X, cT ) is the “Box-car” function deﬁned previously,
which maintains the light-cone. We can now insert this
result in the summation formula of Eq.(14), and add the

parity conjugate, resulting in:

P 1dis(X, T ) =

e−

λT /2δ(cT

X)+

1
2 {

e−

λT B(X, cT )

∞

−
λ
4c

N +1 (cT

X)N

−
N !

(cid:19)
XN =0 (cid:18)
N ], [1], ρ)
}
−
X

.

×

−

+

1,

N

X

F ([
−
1
2 {
Here ρ
X , and F ([α, β], [γ], ρ) is the hypergeomet-
ric function of the continuous variable ρ. Sample be-
havior of this probability density function is shown in
ﬁgure-8.

cT +X
cT

→ −

(56)

≡

}

−

If accuracy is not detrimental, the following simpler
expression for the partial probabilities has the same sec-
ond moment, and approximates the fourth moment of
P 1dis

N (X, T ) to within 5%,
4 + 3
2 )
Γ( N
4 )

N (X, T )

4
√π

Γ( N

≃

P 1dis

T N

−

1

N !(N +2)

1
(cid:18)

−

X 2
T 2

(cid:19)

N/4

1

−

≥

(57)
applicable for N
1. The full solution (Eq.(56)) without
the ballistic term, may also be closely approximated (in
units λ = 1, and c = 1 ) with the form: const
(T +
exp
{
.0022/T 2. The
3)(1
approximation can be very good if one is interested only
in small variations in T for which the precise value of the
const is found by mere eyeball ﬁtting.

X 2/(T + 3)2)1/4

, where const

−

∼

}

·

B. Two-dimensional Isotropic Scattering

In two dimensions, the characteristic function is found

by inserting Eq.(53) into Eq.(50):

N

ti+1

0
i=0 Z
Y

Φ2dis

N (k, T ) =

J(0, kc(ti+1 −

ti)) dti

(58)

where J(0, x) is the zeroth order Bessel function of the
ﬁrst kind. The fourier inversion is made possible via
Eq.(28) with the kernel kJ(0, kR)/2π. For the source
emitter conﬁguration, explicit computation yields:

P 2dis

N (R, T ) =

Θ(cT
−
2πcN (N

R)

1)!

−

c2T 2

R2

(N

2)/2

−

(59)

−

applicable for N
mation rule Eq.(14) yields the full probability density.

1. Summation of orders via the sum-

≥

(cid:0)

(cid:1)

P 2dis(X, T ) =

λT

e−
2πR

δ(cT

Θ(cT

(c2T 2

−

R)+

−
R)
R2)1/2 e
−

e−

λT λ
2πc

λ
c

√c2T 2

R2.

−

(60)

Note here, that the diﬀusion limit is found when cT

≫
R rather than the usually assumed limit of λT
1. The
former, however, is in line with the implications of the
central limit theorem, whereas the latter is more of a
“rule of thumb”, which must be used with some care.

≫

10

C. Three-dimensional Isotropic Scattering

The 3-dimensional process is likely of greatest practi-
cal interest. Below we specialize to the case of the source
emitter. Using Eq.(51) we ﬁnd Re(φ3) = sin(si)/si. In-
serting this in Eq.(50) and then into Eq.(28) results in:

P 3dis

N (R, T ) =

N

ti+1

1
2π2Rc

0
i=0Z
Y
(ti+1 −

dti
τi Z

0

∞

sin(kR)sin(ckτi)
(ck)N

dk (61)

ti). As expected the zeroth order in-
where τi ≡
tegral produces the ballistic peak: P 3dis
R).
The ﬁrst order integrals can be found by convolution of
φ3 with P 3dis

or, by direct integration to give:

δ(cT

∝

±

0

0

P 3dis

1 =

Θ(cT

R)

−

4πc2RT

cT + R
R
cT

−

(cid:19)

.

ln

(cid:18)

(62)

The result of the sine-transform in Eq.(61), proves in-
accessible for N > 1. However, the moments of the distri-
bution are easily calculated to arbitrary order. While all
odd moments are zero, the even moments are found by
k)m/2 to Φ3dis
2
N , for m = 0, 2, 4, ....
the application of (
∇
For m = 0 normalization can be veriﬁed as M 3dis
N (0) =
T N /(4πN !). For m

2 The mth moment is given by:

M 3dis

N (m) =

≥

T (N +m)
4 π2cm

2m/2 (N + 1)

(N + m)! (m

1)!!

m/2

−

1
aj(m)N j

−

j=0
X

1)!! =2m/2Γ( m+1

(63)
2 )/√π for even-m (e.g. 5!! =
where (m
1). Only the set a0(m) = m!2/(2m(m/2)!) yields
5
to analytic description. The coeﬃcients aj(m) for up to
the eighth moment are listed in the table below.

−

3

·

·

j =1

j =2 j =3

j =0
1
18

aj(m)
m=2
5
m=4
m=6
1350 1715/3 175/3
m=8 264600 137018 22785 1225

For N > 1, Paasschens[10] has proposed the expression:

P 3dis

N (R, T )

Θ(cT

R)

−
π3/2c3

≃

Γ( 3N

4 + 1
2 )
Γ( 3N
4 )

3

T N
−
N !

R2
c2T 2

(cid:19)

1
(cid:18)

−

3N
1
4 −

(64)
for the probability density of the 3dis-process. This ex-
pression produces the required second moment exactly,
the fourth to within 0.5%, and the sixth moment is ap-
proximated to within 1.5%. Hence an excellent approxi-
mation for many practical purposes. The total probabil-
ity density function (via Eq.(14)) has also been approxi-
mated by [10]:

P 3dis(R)

λT

e−
4πR2 δ(cT

−

≃

R) + e−

λT Θ(cT

R)

−

R2/c2T 2)1/8
(1
(4πc2T /3λ)3/2 eρ3d
−

×

p

where, ρ3d ≡

−

λT (1

R2/c2T 2)3/4.

1 + 2.026/ρ3d

(65)

VIII. APPLICATIONS

The transmission of photons in turbid media is of in-
terest in medical imaging. During the 1990’s increas-
ingly more successful attempts have been made to model
the stochastic movement of the photons in turbid media
[11, 12, 13, 14, 15, 16]. Some of these have involved forms
of path-integration methods while others not. However,
all of these reports have been limited by varying forms
of approximation, limited dimensionality, and the like.
Some of these approximations pertain to truncated orders
of computation or other more subtle ones such as main-
taining the photons’ light-cone[11] only on average. Nev-
ertheless, for practical purposes, computations of highly
forward-scattering seem suitable for applications involv-
ing biological tissues. As such, the ﬁndings are in rea-
sonably good agreement within the precision of measure-
ments as reported in [11, 17].

The characteristics of these works have been recounted
in a chronological narrative in [16]. For the case of
isotropic scattering, graphical comparisons of several of
these works to certain exact results can be found in ﬁg-3.3
of [10].

Here we will not consider the mathematically intri-
cate anisotropic scattering application. We will however,
consider two simpler popular applications of our results:
polymer chains, and stock option valuation.

A. Flexible Polymer Chains

A minimal model of a ﬂexible polymer is a chain of
links of constant length. By “ﬂexible” we mean that
each bond is free to assume any orientation in space as
long as it remains linked to its two neighbors. Therefore
the probability density distribution of the such chains is
a special case of what we have already considered in the
ti) = L = cT /(n + 1), such
Ddis-process where c(ti+1 −
that L is the ﬁxed length of the ﬂexible chain, and n, the
order of computation, is the number of joints. This also
means that the often-diﬃcult time-ordered integration
becomes unnecessary, and is thus replaced by a factor
T n in Eq.(2). Moreover, because of the discovery of the
recursion rule in Eq.(51) we need only work out the char-
acteristic function for only one and two dimensions. All
higher dimensions can then be derived from these using
the recursion relation.

The one-dimensional case is likely of limited interest
but we provide the results here for reference. The char-
acteristic function for a chain of ℓ links is the ℓth power
of cos(kL), and the eﬀective fourier kernel is cos(kx) for
). Writing the cosine as
,
(
k
−∞

,
(
−∞

) and, x

∞

∞

∈

∈

11

0.16

0.14

0.12

0.1

0.08

0.06

0.04

0.02

0

–1.5

–1

–0.5

0.5

1

1.5

x

FIG. 9: The probability density distribution of Eq.(66)) for
ℓ = 21 links and L = 0.1. The peaks have been artiﬁcially
broadened out for plotting.

exponentials, the transform is easily found as a collection
of δ-functions weighted by binomial coeﬃcients:

P 1dfc
ℓ

(x) =

ℓ+1
2

ℓ
ℓ+1
2 −

i

(cid:17)

i=1 (cid:16)
X

1
2ℓ

1
2ℓ

ℓ
ℓ/2

δ(x) +

(cid:16)

(cid:17)

ℓ
2

1
2ℓ

ℓ

i

ℓ
2 −

i=1(cid:16)
X

(cid:17)

(δ(x

L(2i

1)) + δ(x+L(2i

1)));

−

−

−

ℓ = 1, 3, ...

(δ(x

2Li) + δ(x+2Li));

−

ℓ = 2, 4, ....
(66)

It should be apparent that the binomial coeﬃcients will
tend to a Normal distribution enveloping the discrete
spikes (Fig-9).

∞

In two-dimensions, the characteristic function for a
chain of ℓ links is the ℓth power of J(0, kL), and the
eﬀective fourier kernel is kJ(0, kr) for both k and, r
∈
[0,
). Despite the fact that the same transformation
in conjunction with the time-ordered integration could
be worked out in the case of 2dis process, we cannot
obtain the probability density function for the end-to-
end distance for higher than second order (ℓ > 3). The
zeroth order contains only a single link and obviously
r)/2πr, and the ﬁrst order is found
corresponds to δ(L
r2. The second order (3-
to be, Θ(2L
−
link) chain has the probability density for the end-to-
end distance, K(A/√L3r)/π2√L3r, for r
[L, 3L], and,
∈
[0, L]. Here, K is the com-
K(√L3r/A)/π2A, for r
plete elliptic integral of the ﬁrst kind, and A = (L +
r)
r)/4 is the same as the area subtended
by the quadrilateral formed by the the links in the chain
and the end-to-end vector of length r. As alluded, higher
order distributions remain analytically inaccessible. But
since we have the exact characteristic function, comput-
ing the exact moments at any order is straightforward.

r)/π2r√4L2

L + r)(3L

p

−

−

−

∈

3

2

1

0

102
8
7
6
5

101
8
7
6
5

2

4

3

2

4

3

2

100

Below we provide up to the eight moment, for chains of
up to ﬁve links.

M/Lm m=2 m=4 m=6 m=8
1
n=0
6
n=1
15
n=2
28
n=3
45
n=4

1
1
70
20
639
93
256 2716
545 7885

1
2
3
4
5

The most useful case clearly being that of 3-dimension
has been worked out by Kleinert[2]. We ﬁnd agreement
with this result as follows. Specializing the Eq.(61) to the
problem at hand we ﬁnd the the characteristic function
for a chain of ℓ links is the ℓth power of sin(kL)/kL,
and the eﬀective fourier kernel is ksin(kr)/2π2r for both
k and, r
). Because the characteristic function is
even in k we can convert the kernel to an exponential and
. If we write sinℓ(kL)
then extend the lower limit to
as combination of exponentials we ﬁnd an integrand of
1. The full integral can then performed
form eikx/kℓ
using contour integration resulting in[2]:

−∞

[0,

∞

∈

−

P 3dfc
ℓ

(r) =

2ℓ+1(ℓ

2)!πL2r

1

−

ℓ/2

×

i=0
X

1)i

(
−

ℓ
i

(cid:1) (cid:16)

(cid:0)

ℓ

2i

−

−

r
L

2
ℓ
−

(cid:17)

Θ(L(ℓ

2i)

r).

−

−

(67)

B. Financial Options Valuation

The problems considered here are especially relevant
to the price movements of ﬁnancial assets. Economists
traditionally assume that the logarithm of prices have
a normal distribution[18], yet it has always been known
this is only true for very large λ. While this assumption
is ﬁne for the intended typical gaseous medium where
1020/sec, the equivalent reset rate for a liquid mar-
λ
ket is of order inverse days[19]. Figure-10, showing the
observation-time dependence of the kurtosis over 32 years
of S&P log-returns, clearly indicates a ﬁnite λ and hence
the inappropriateness of the diﬀusion approximation.

∼

The fact that one cannot ﬁt a single λ for diﬀerent
observation-periods (T ) (ranging from minutes to many
weeks), suggests that more than one process govern dif-
ferent time scales[20], a notion taken for granted by
traders. With more than one Pgr curve one can repro-
duce the necessary fat-tails without resort to Levy-like
distributions (ﬁgure-11).

In order to see some of the implications of ﬁnite λ we
present, brieﬂy, the valuation of “options” under the gr -
process. The computation of the worth of an (European-
type) call-option for a non-dividend paying underlying
asset was ﬁrst computed by Black and Scholes [21]. A
call-option is a contractual right purchased for an agreed

12

S&P Kurtosis 

0

20

40

60

80

100

T (days)

FIG. 10: Comparison of the kurtosis for the daily (Jan-1970
to March-2002) log-returns of the S&P500 index vs. a ﬁt of
our typical κ ≃ 2/λT . For 1/λ = 13.7days the agreement is
good for periods less than 30 days.

-300

-200

-100

0

Log Returns

100

200

300

FIG. 11: The distribution of log-returns daily (Jan-1970 to
March-2002) S&P500 index vs. Pgr, and Levy distributions.
While the Levy curve ﬁts the fat tails better, a superposi-
tion of Pgr’s can also ﬁt the fat-tails. Conversely, the Levy-
distribution does not have the ballistic peak; a feature extant
in observation though conveniently ignored by many investi-
gators. The correct relative amplitude of the ballistic peak to
the smooth curve in Pgr has not been force-ﬁt.

upon premium C, which gives the buyer a right to pur-
chase a ﬁxed amount of some asset at a later time T from
the seller at an agreed upon (“strike”) price S. This is re-
gardless of what the prevailing market value of the asset
might be at T .

Black and Scholes(BS) ﬁrst assumed that the loga-
rithms of the asset’s price follow pure diﬀusion, with
an undetermined diﬀusion coeﬃcient σ2 (a.k.a., volatil-
lnP0) reﬂects the full cer-
ity).The distribution δ(lnP

−

13

One such puzzle is the pricing of options is the phe-
nomenon of “option-skew”. In options trading practice
the price of an option cannot really be calculated us-
ing the BS formula, even after eliminating µ, since the
“volatility” (σ2) is not known. This parameter may be
inferred from the variance of the detrended price series
of the underlying but using it does not give option prices
that match the observation. Conversely, if the observed
option values are inserted into the BS formula, the im-
plied volatility σ2 , resulting from solving:

Cobs = CBS(S, T, P0, r; σ),

(69)

is not the same as that inferred from observation.
In
fact, using the observations from diﬀerent option series
(expirations T or strike prices S) one gets diﬀerent values
for σ, whereas CBS only allows a unique value for all op-
tions. Ostensibly, there are many more variables which
aﬀect Cobs in the real world. The existence of any addi-
tional variables or control parameters then immediately
implies that for any given Cobs the solution for σ is no
longer unique. Indeed the brownian gr -process provides
just such a parameter in the form of λ.

We will now compute the option skew implied by the
gr -process. We will do so only in an approximate way
so that we need not compute the full Pgr. We also do
this to clearly illustrate that the “fat-tail” of the distri-
bution resulting from ﬁnite values of λ is directly linked
to the option-skew phenomenon. We will emulate Pgr by
matching its kurtosis to that of a superposition of two
gaussians (gausslets):

G2(x, ν1, ν2) =

x2
2ν1

e−
2√2πν1

x2
2ν2

e−
2√2πν2

.

+

(70)

We can now solve for
by setting equal the vari-
ν1, ν2}
ance and the fourth moment of G2 to that of Pgr.
For illustration sake we can take the intermediate time
(λT > 10) limit of νgr Eq. (39), and χgr Eq. (40). In
this approximation the solutions are:

{

s2
λ2

(cid:16)

ν1,2 =

2λT

4

2

(2λT

8)

.

(71)

−

∓

p

−

(cid:17)

We can see that if we attempt (as traders do in relying
on the BS-model) to ﬁt a single gaussian to the observa-
tion we are likely to be accepting only one of the above
variances. It is manifest that the implied volatility has a
dependence on the time to expiration T other than the
traditional linear term. To demonstrate the same for the
strike price S we use the full form of νgr and χgr and solve
. This reﬁned
for the implied gausslet variances
procedure allows us to get to times as low as λT
2, but
to go further we must match more moments. We produce
an option valuation formula as the half the sum of two
Black-Scholes type expressions but using
as vari-
ances. Settings this approximation to CBS and solving
for σ for diﬀerent strikes gives us the the skew curve as
shown in the ﬁgure-13.

ν1, ν2}

ν1, ν2}

≃

{

{

µT 1

 µT 2

σ T 1/2
1

pay-off

σ T1/2
2

P0

log-Price

Strike

FIG. 12: The progression of price distribution according to
Black and Scholes

tainty that the current price is P0. Thus the distribution
will spread out in time into a Gaussian of variance σ2T .
They also assumed the log-price to drift linearly (but no
faster) in time with an undetermined rate µ (ﬁgure-12).
In this way they thought they ﬁxed the price probability
density projected for the time T into the future.

The payoﬀ of an option for the buyer would come about
if PT (the market price at time T ), is higher than the
agreed strike S; the option expires worthless otherwise.
If PT > S, the buyer could exercise the said right and
immediately sell the asset on the open market for a proﬁt
S. Thus a fair price to ask of the buyer is the
of PT −
weighted average of all possible payoﬀs:

CBS =

rT

e−
√2πσ2T Z

∞
dx (ex

ln S

S)e−

−

(x−ln P0

−µT )2

2σ2T

(68)

where r is the prevailing interest rate. The reason for the
rT is that the buyer loses money by missing
pre-factor e−
out on a steady interest payment since he has given up
the cash to buy the call-option. BS then argued if it is
true that no-one can win consistently at speculating, the
drift rate µ must exactly be equal[22] to the guaranteed
interest rate r. In this way one of the two arbitrarily in-
troduced parameters was eliminated. The integral can be
written with limits x
], if we write the integrand
,
[
∞
−∞
with a step-function. Eq.(68) can then be integrated by
parts resulting in an erfc (called N in ﬁnance texts). The
ﬁnal expression is known as the Black-Scholes formula.

∈

Ostensibly, there are assumptions in the BS hypothe-
sis which are not supported by observation. Conversely,
there are many observations which are not incorporated
in the BS model, such as Levy-like fat tails[4, 23, 24] in
the probability distribution. The resulting discrepancies
have become deep puzzles in the realm of ﬁnance[25].

0.114

0.112

0.11

0.108

20

30

40

50

60

70

FIG. 13: The implied volatility vs. Strike price. The two-
gausslet (G2) representation of Pgr is used in place of Cobs
in Eq(69). Parameter settings are: λT = 10, P0 = 50, s =
0.1, µ = 0, r = 0.05. While the features of skew plot remains
the same, their location and span vary to a large extent for
diﬀerent parameters. For this reason one could get a smile,
frown, or smirk relative to the at-the-money point S = P0.
The easiest way to obtain a smirk or a frown is to allow µ 6= 0,
this is consistent with the ﬁndings in [26].

The application of the method of path-integrals to ﬁ-
nancial derivatives’ valuations is a very natural approach.
Unlike the case of European (path-independent) options
treated above, many options have values which are path-
dependent. Hence the valuation must take place as part
of the path-integration itself [27].

The author gratefully acknowledges M.J.G.Veltman
for inspiration for this work on more levels than method-
ology; K.Osband for encouraging the investigation of
problems in ﬁnance; and I.M.B.Oﬀen for support and
encouragement to complete the work.

14

APPENDIX A: DAMPED EXPONENTIAL
INTEGRALS

If it should happen that the gs(d)-process is terminated
after a ﬁxed number of events n, then the distribution (for
the truncated-gaussian-scattering with diﬀusion) is given
by a set of integral functions:

P tgsd(x, T ) = Dein(x, t; σ)

1
N Dei
n

≡

0
Z

1
ξgsd
n

×

T

e−

λtn dtn

tn

0
Z

x2
2ξgsd
n

2

!

exp

 −

t2

dt1

dtn

1 . . .

−

0
Z

(A1)

where Dei represents the name “Damped Exponential
Integral”. The “interim variance” is deﬁned as before in
Eq.(21). The normalization factor is given by:

N Dei

n =

√2π
λn

λT

e−

1
"

−

n

1

−

(λT )k

 

Xk=0

k! !#

.

(A2)

Thus Dei0 is the familiar normalized Gaussian of width
√σ2T . Further for example:

T

dt

2π(1

e−
λt

−
e−

λT )

0

Z

t)2 + σ2T )

λ

−
1
2

p
(s2(T

p
exp

×

×

−

(cid:18)

s2(T

−

x2
t)2 + σ2T

.
(cid:19)

(A3)

IX. ACKNOWLEDGEMENTS

Dei1(x, T ; σ, s, λ) =

[1] S. Chandrasekhara, Rev. Mod. Phys. 15, 1 (1943).
[2] H.Kleinert, Path Integrals in Quantum and Polymer
Physics, 3rd ed. (World Scientiﬁc, New York 2003),
chap.15.

[3] M.F.M. Osborne, Operations Research. VII, 145 (1959)
[4] Physica A 269 (1999). The entire volume is dedicated to

interesting outstading problems in Econophysics.

[5] B. Chance, R. R.Alfano, and A. Katzir, eds., Optical To-
mography, Photon Migration, and Spectroscopy of Tissue
and Model Media: Theory, Human Studies, and Instru-
mentation, Proc. SPIE 2389 (1995).

[6] R.P. Feynman and R.A. Hibbs, Quantum Mechanics and
Path Integrals, (McGraw-Hill New York 1965), ch. 12.
[7] G.J. Papadopulous, Path-Integrals and Their Appli-
cations, eds. G.J.Papadopulous, and J.T. Deversee,
(Plenum Press, New York 1978), pp. 1-71.

[8] F.W.Wiegel, Introduction to Path-Integral Methods in
Physics and Polymer Science, (World Scientiﬁc, Singa-
pore 1986), ch. 1.

[9] S. Goldstein, Quarterly J. Mechanics & Appl. Math. &
Math. IV, 129(1951). Another author has obtained the
same result without apparent knowledge of the latter,
though reported a decade later: P.C. Hemmer, Physica
27, 79 (1961).

[10] J.C.J. Paasschens, Doctoral Thesis, Philips Research
Laboratories, ch.3, (1997) unpublished. Can be found at:
www.lorentz.leidenuniv.nl/beenakker/theses/paasschens/
paasschens.pdf.

[11] L.T. Perelman, J.Wu, Y. Wang, I. Itzkan, R.R. Dasari

and M.S. Feld, Phys. Rev. E 51, 6134, (1995).

[12] A.Ya.Polishchuk, M.Zevallos, F.Liu and R.R. Alfano,

Phys. Rev., E 53, 5523 (1996).

[13] S.D. Miller, J. Math. Phys., 39, 5307, (1998).
[14] D. J. Durian and J. Rudnick, J. Opt. Soc.Am. A 14, 235

(1997); and 14, 940 (1997).

[15] J. Kaltenbach and M. Kaschke, in Medical Optical To-
mography: Functional Imaging and Monitoring, edited
by G. Muller (SPIE,Washington DC, 1993).

15

[16] S.A. Ramakrishna and N. Kumar, Phys. Rev. E 60, 1381

ance σ2 (op.cit.[18]).

(1999)

[23] R.N. Mantegna, and H.E. Stanley, Nature, 383, 587

[17] J. N. Winn, L. T. Perelman, K. Chen, J. Wu, R. R.
Dasari, and M. S. Feld, Appl. Optics, 37, 8085 (1998)
[18] J. Hull, Options, Futures and Other Derivatives, 3rd ed,

(Prentice Hall, New Jersey 1996), ch. 10.

[19] L. Kullmann, J.Toyli, J.Lertesz, A.Kanto, and K.Kaski,

op.cit.[4], p98.

[20] We hasten to add that none of the processes exposed here
encompass several of the important observations about ﬁ-
ancial markets. Most notably the serially correlated abso-
lute values of returns. These features remain as potential
applications of the present method.

[21] F. Black, and M. Scholes, J. Political Economy, 81, 637

(1973).

[22] The actual relationship is µ = r − σ2/2 since there is a
lower return rate if the asset price is drifting with vari-

(1996)

[24] P.Gopikrishnan, L.A.N. Amaral, Y. Liu, M. Meyer, V.
in Unresolved
Plerou, B. Rosenow, and H.E. Stanley,
Problems of Noise and Fluctuations, eds.: D. Abbot, and
L.B. Kish (AIP, New York, 2000), p.233.

[25] Like other disciplines branching only recently from phi-
losophy, tradiational theories of ﬁnance are founded more
on gospelized conjectures, than empirical observations.
As such, many of these “puzzles” are more semantic illu-
sions, than genuine mysteries.

[26] J.-P. Bouchaud, M. Potters, Phil. Trans.: Math.
at:

Phys. Engin. Sci. 357,
http://xxx.lanl.gov/cond-mat/9808206.

(1999). Also

2019

[27] V. Linetsky, Computational Economics 11, 129 (1998).

