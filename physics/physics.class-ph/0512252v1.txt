5
0
0
2
 
c
e
D
 
7
2
 
 
]
h
p
-
s
s
a
l
c
.
s
c
i
s
y
h
p
[
 
 
1
v
2
5
2
2
1
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Nonequilibrium Statistical Mechanics and Thermodynamics from Darwinian
Dynamics: a Primer

P. Ao
Department of Mechanical Engineering, University of Washington, Seattle, WA 98195, USA
(Dated: December 27 (2005))

We present here an exploration on on the physical implications of the Darwinian dynamics. We
ﬁrst show that how the nonequilibrium statistical mechanics emerges naturally. We then show that
the ﬁrst three laws of the thermodynamics, the Zeroth Law, the First Law and the Second Law can be
followed from the Darwinian dynamics, except the Third Law. The inability to derive the Third Law
indicates that the Darwinian dynamics belongs to the ”classical” domain. Speciﬁcally, the Second
Law is proved from the dynamical point of view. Two types of current dynamical equalities are
explicitly discussed in the paper: one is based on Feynman-Kac formula and one is a generalization
of the Einstein relation. Both are directly accessible to experimental tests. Our demonstration
indicates that the Darwinian dynamics is logically a simple and straightforward starting point to
get into thermodynamics and is complementary to the conservative dynamics dominated in physics.
PACS numbers:
05.70.Ln Nonequilibrium and irreversible thermodynamics
05.10.Gg; stochastic analysis methods (Fokker-Planck, Langevin, etc);
02.50.Fz; stochastic processes;
87.15.Ya Fluctuations

One of the principle objects of theoretical research in any department of knowledge is to ﬁnd the point of view from

which the subject appears in its greatest simplicity.

Josiah Willard Gibbs (1839-1903)

I.

INTRODUCTION

The theory proposed by Darwinian and Wallace1,2 on the evolution in biology has been the fundamental theoret-
ical structure to understand biological phenomena for nearly one and half centuries, referred to as the Darwinian
dynamics in the present paper. In its initial formulation, the theory was completely narrative. No single equation
was used. There have been continuous eﬀects to clarify its meaning and to make it into more quantitative hence
more predictive3,4,5,6,7,8. Tremendous progresses have made during past 100 years. Now the degree of its usage of
mathematics is comparable to any other mathematically sophisticated natural science. From the physics point of
view, this theory is a bona ﬁde nonequilibrium dynamical theory.

In physics there has been a sustained interest during past several decades in nonequilibrium processes9,10,11,12,13,14,15.
The important goals are to bridge its connection to equilibrium processes and to clarify the roles of entropy and
the Second Law of thermodynamics. Thanks to recent progresses in experimental technologies, particularly the
nanotechnololgy, many previous inaccessible regimes are now been actively explored. There have renewed interests
in this ﬁeld, ranging from physics16,17,18,19, chemistry20, material science21, biology8, and to many other ﬁelds22.
Quantitative experimental and theoretical studies ﬁnd their ways into the cellular and molecular processes of life.
There is a strong going interaction between physical and biological sciences. The purpose of the present paper is to
look at the fundamental issues in statistical mechanics and thermodynamics from the point of view of the Darwinian
dynamics and to gain a new insight.

There is even an active interest from philosophical point of view on the foundation of statistical mechanics and
thermodynamics. Relevant to the present paper, following three fundamental but controversial problems have been
formulated23 : 1) In what sense can thermodynamics said reduced to statistical mechanics? 2) How can one derive
equations that are not time-reversal invariant from a time-reversal invariant dynamics? 3) How to provide a theoretical
basis for the ”approach to equilibrium” or irreversible processes?

The Darwinian dynamics can answer all three questions in its own way. For the ﬁrst question, as long as the
statistical mechanics is formulated according to the Boltzmann-Gibbs distribution, the main structures of statistical
mechanics and thermodynamics are equivalent. For the second question, it is found that the thermodynamics is based
on the energy conservation and on the Carnot heat engine. It deals with quantities at equilibrium or steady state
without time. There is no direction of time. Hence, there is no conﬂict between the thermodynamics and the time-
reversal dynamics. For the last and third question, Darwinian dynamics comes with an adaptive behavior1,2,3,4,6,7,8
and with a built-in direction of time.
It naturally provides a framework to address the question of ”approaching
to equilibrium”. If one would insist, the third question might be transformed into another one: What would be the

2

(1)

(2)

(3)

implication that there is a mutual reduction between the Darwinian dynamics and the Newtonian dynamics8? Answer
to this last question will not be attempted in the present paper. The base to answer above three questions will be
discussed in next few sections.

The rest of the paper is organized as follows. In section II the Darwinian dynamics will be summarized in the
light of recent progress. In section III it will be shown that the statistical mechanics and canonical ensemble follows
naturally from the Darwinian dynamics. In section IV the connection to thermodynamics is explored. There it will
be shown that the Zeroth Law, the First Law, and the Second Law can follow from the Darwinian dynamics, not
the Third Law. In section V two types of simple but seemly profound dynamical equalities discovered recently, one
based on the Feynman-Kac formula and one a generalization of the Einstein relation, are discussed. In section VI the
present demonstration is put into perspective. No mathematical rigor is pursued in the present paper, but the care
has been taken to make the demonstrations as clear as possible. With the solid physical and biological foundations
behind, a rigorous mathematical formulation is possible.

II. DARWINIAN DYNAMICS, ADAPTIVE LANDSCAPE, AND F-THEOREM

This section summarizes the recent results on the Darwinian dynamics.

A.

Stochastic diﬀerential equation: the trajectory view

In the context of genetics the Darwin’s theory of evolution1,2 may be summarized verbally as that the evolution is
a result of genetic variation and its ordering through elimination and selection. Both randomness and selection are
equally important in this dynamical process. With an suitable time scale, the Darwinian dynamics may be represented
by the following stochastic diﬀerential equation5,8

˙q = f (q) + NI (q)ξ(t) ,

where f and q are n-dimensional vectors and f a nonlinear function of q. The genetic frequency of i-th trait is
represented by qi. Nevertheless, in the present paper it will be treated as a generic real function of time t. All
quantities in this paper are dimensionless. They are assumed to be measured in their own proper units unless
explicitly speciﬁed. The collection of all q forms a real n-dimensional phase space. The noise ξ is a standard Gaussian
white noise with l independent components: hξiiξ = 0 , and

and i, j = 1, 2, ..., l. Here h...iξ denotes the average over the noise variable {ξ(t)}, to be distinguished from the average
over the distribution in phage space below. The positive numerical constant θ describes the strength of noise.

A further description of the noise term in Eq.(1) is through the n × n diﬀusion matrix D(q), which is deﬁned by

the following matrix equation

hξi(t)ξj (t

)iξ = θ δijδ(t − t

) ,

′

′

NI (q)N τ

I (q) = 2D(q) ,

where NI is an n × l matrix, N τ
I is its the transpose, which describes how the system is coupled to the noisy source.
This is the ﬁrst type of the F-theorem8, a generalization of Fisher’s fundamental theorem of natural selection3 in
population genetics. According to Eq.(2) the n × n diﬀusion matrix D is both symmetric and nonnegative. For the
dynamics of state vector q, all what needed from the noisy term in Eq.(1) are the diﬀusion matrix D and the positive
numerical parameter θ. Hence, it is not necessary to require the dimension of the stochastic vector ξ be the same as
that of the state vector q. This implies that in general l 6= n.

It is known that a large class of nonequilibrium processes can be described by such a stochastic diﬀerential
equation9,10,11,12,13,14,15. There is a strong current interest on such stochastic and probability description ranging
from physics18,19, chemistry,20, material science21, biology8, and other ﬁelds22.

The Darwinian dynamics was conceived graphically by Wright in 1932 as the motion of the system in an adaptive
landscape4,6,7. Since then such a landscape has been known as the ﬁtness landscape in some part of literature.
However, there are a considerable amount of confusion on the deﬁnitions of ﬁtness6,8. In this paper a more neutral
term, the (Wright evolutionary) potential function, will be used to denote this landscape. The adaptive landscape
connecting both the individual dynamics and its ﬁnal destination is intuitively appealing. Nevertheless, it had been
diﬃcult to prove its existence in a general setting. The diﬃculty lies in the fact fact that typically the detailed
balance condition does not hold in Darwinian dynamics, that is, D−1(q)f (q) cannot be written as a gradient of scalar
function9,11,12,13,15.

Figure 1. Adaptive landscape with in potential contour representation. +:

local basin; −:

local peak; ×: pass

(saddle point).

During the study of the robustness of the genetic switch in a living organism24 a constructive method was discovered

to overcome this diﬃculty: Eq.(1) can be transformed into the following form of stochastic diﬀerential equation,

[R(q) + T (q)] ˙q = −∇φ(q; λ) + NII(q)ξ(t) ,

where the noise ξ is from the same source as that in Eq.(1). The parameter λ denotes the inﬂuence of non-dynamical
and external quantities. It should be pointed out that the potential function φ may also implicitly depends on θ. The
friction matrix R(q) is deﬁned through the following matrix equation

NII (q)N τ

II (q) = 2R(q) ,

which guarantees that R is both symmetric and nonnegative. This is the second type of the F-theorem8. The
F-theorem emphasizes the connection between the adaption and variation and is a reformulation of ﬂuctuation-
dissipation theorem in physics25,26. For simplicity we will assume det(R) 6= 0 in the rest of the paper. Hence
det(R + T ) 6= 027. The breakdown of detailed balance condition or the time reversal symmetry is represented by the
ﬁniteness of the transverse matrix, T 6= 0. The usefulness of the formulation of Eq.(4) is already manifested in the
successful solution of outstanding stable puzzle in gene regulatory dynamics24 and in a consistent formulation of the
Darwinian dynamics8.

The n × n symmetric non-negative friction matrix R and the transverse matrix T are related to the diﬀusion matrix

D:

Here A is an antisymmetric matrix determined by both the diﬀusion matrix D(q) and the deterministic force f (q)27,28.
One of more suggestive forms of above equation is

R(q) + T (q) =

1
D(q) + A(q)

.

[R(q) + T (q)]D[R(q) − T (q)] = R(q) .

This symmetric matrix equation implies n(n+1)/2 single equations from each of its element. The Wright evolutionary
potential function φ(q) is connected to the deterministic force f (q) by

Or its equivalent form,

−∇φ(q; λ) = [R(q) + T (q)]f (q) .

∇ × [[R(q) + T (q)]f (q)] = 0 .

Here the operation ∇× on an arbitrary n-dimensional vector v is a matrix generalization of the curl operation in
lower dimensions (n = 2, 3): (∇ × v)i,j = ∇ivj − ∇jvi . Above matrix equation is hence antisymmetric and gives
n(n − 1)/2 single equations from each of its element. From Eq.(6) and (7) the friction matrix R, the transverse matrix
T , and the potential function φ can be constructed in terms of the diﬀusion matrix D and the deterministic force
f . The local construction was demonstrated in detail in Ref.27. For a global construction an iterative method was
outlined in Ref.28 .

In the case the stochastic drive may be ignored, that is, θ = 0, the relationship between Eq.(1) and (4) remains

unchanged. Furthermore, Eq.(4) becomes a deterministic equation

Because of the non-negativeness of the friction matrix, one obtains

[R(q) + T (q)] ˙q = −∇φ(q; λ) .

d
dt

φ(q; λ) = ˙q · ∇φ(q; λ)

= − ˙qτ [R(q) + T (q)] ˙q
= − ˙qτ R(q) ˙q
≤ 0 .

3

(4)

(5)

(6)

(7)

(8)

(9)

It is immediately clear that the Wright evolutionary potential function φ(q; λ) is a Lyapunov function and the
deterministic dynamics makes it non-increasing: the tendency to approach the nearby potential minimum to achieve
the maximum probability. This is precisely what conceived by Wright. The adaptive dynamics has been actively
exploring in biology7.

The conservative Newtonian dynamics may be regarded as a further limit of zero friction matrix, R = 0. Hence,

from Eq.(8), the Newtonian dynamics may be expressed as,

Here the value of potential function is evidently conserved during the dynamics:
moves along the equal potential contour in the adaptive landscape.

˙q · ∇φ(q; λ) = 0, that is, the system

T (q) ˙q = −∇φ(q; λ) .

B. Fokker-Planck equation: the ensemble view

It was heuristically argued28 that the steady state distribution ρ(q) in the state space is, if exists,

ρ(q, t = ∞) ∝ e

−βφ(q;λ) .

Here β = 1/θ.
acquires both the dynamical meaning through Eq.(4) and the steady state meaning through Eq.(11).

It takes the form of Boltzmann-Gibbs distribution function. Therefore, the potential function φ

It was further demonstrated that such a heuristical argument can be translated into an explicit procedure such
that there is an explicit Fokker-Planck equation whose steady state solution is indeed given by Eq.(11)29. Starting
for the the generalized Klein-Kramers equation, taking the limiting procedure of the zero mass limit, the desired
Fokker-Planck equation corresponding to Eq.(4) is

∂ρ(q, t)
∂t

= ∇τ [D(q) + A(q)][θ∇ + ∇φ(q; λ)]ρ(q, t) .

This equation is also a statement of conservation of probability. It can be rewritten as the probability continuity
equation:

with the probability current density j

j(q, t) ≡ −[D(q) + A(q)][θ∇ + ∇φ(q; λ)]ρ(q, t) .

∂ρ(q, t)
∂t

+ ∇ · j(q, t) = 0 ,

The reduction of dynamical variables has often been done by the well-known Smoluchowski limit.
In the above
derivation we take the mass to be zero, keeping other parameters, including the friction and transverse matrices,
to be ﬁnite. Nevertheless, in the Smoluchowski limit it is the friction matrix to be taken as inﬁnite, keep all other
parameters to be ﬁnite. Those two limits are in general not exchangeable.

The steady state conﬁguration solution of Eq.(12) is indeed given by Eq.(11). It would be interested to point out
that the steady state distribution function, Eq.(11), is independent of both friction matrix R and the transverse matrix
T . Furthermore, we emphasize that no detailed balance condition is assumed in reaching this result. In addition,
both the additive and multiplicative noises are treated here on equal footing.

Finally, it can be veriﬁed that above construction leading to Eq.(12) is valid and remains unchanged when there is
an explicit time dependent in R, T , and/or φ. In this case though there may not exist a steady state distribution if
the Wright evolutionary potential function φ is time dependent.

III.

STATISTICAL MECHANICS

A. Central Relations in Statistical Mechanics

As discussed above, if treating the parameter θ as temperature, the steady state distribution function in phase space
is indeed the familiar Boltzmann-Gibbs distribution, Eq.(11). The partition function, or the normalization constant,
is then

Zθ(λ) ≡

dq e

−βφ(q;λ) .

Z

4

(10)

(11)

(12)

(13)

(14)

(15)

The integral

dq denotes the summation over whole phase space. The normalized steady state distribution is

R

ρθ(q) ≡

e−βφ(q;λ)
Zθ

.

For a given observable quantity O(q), its average or expectation value is

hOiq ≡

dq O(q) ρθ (q)

=

Z
1
Zθ Z

dq O(q) e

−βφ(q;λ) .

The subscript q denoted that the average is over phage space, not over the noise in Eq.(1) or (4). Eq.(17) is the
summit of statistical mechanics.

B. Stochastic process and canonical ensemble

A main question is that for a given Fokker-Planck equation, can the corresponding stochastic diﬀerential equation
in the form of Eq.(4) be recovered? The answer is aﬃrmative and the procedure to carry it out is already contained
in Eq.(12), which will be brieﬂy demonstrated below.

A generic form for the Fokker-Planck equation may be expressed as follows:

∂ρ(q, t)
∂t

= ∇τ [θD(q)∇ − f (q)]ρ(q, t) .

Here D(q) is the diﬀusion matrix and f (q) the drift force. The main motivation to take such a form is simple: In the
case detailed balance condition is satisﬁed, i.e., A(q) = 0 (and T (q) = 0), the potential function φ can be directly
f . It puts the diﬀusion eﬀect in a very prominent position. Any other form of
read from above equation: ∇φ = D
Fokker-Planck equations can be easily transformed into above form. This generic form of the Fokker-Planck equation
is less tangible to additional complications such as the noise induced ﬁrst order transitions caused by the q-dependent
diﬀusion constant.

−1

A potential function φ(q) can always be deﬁned from the steady state distribution. There is an extensive mathe-
matical literature addressing this problem30. After this is done, though it can be a diﬃcult mathematical problem,
the procedure to relate the genetic Fokker-Planck equation to Eq.(12) is particularly straightforward. Eq.(12) can be
rewritten as

∂ρ(q, t)
∂t

= ∇τ [θD(q)∇ + θ(∇τ A(q)) − [D(q) + A(q)]∇φ(q)]ρ(q, t) .

The antisymmetric property of the matrix A(q) has been used in reaching Eq.(19). Thus, comparing between Eq.(18)
and (19), we have

In reaching Eq.(22) we have used the relation

D(q) = D(q) ,
φ(q) = φ(q) ,
f (q) = f (q) + θ∇τ A(q) .

−[D(q) + A(q)]∇φ(q) = f (q) .

The explicit equation for the anti-symmetric matrix A is

θ∇τ A(q) + [D(q) + A(q)]∇φ(q; λ) = f (q) ,

which is a ﬁrst order linear inhomogeneous partial diﬀerential equation. The solution for A can be formally written
down

A(q) =

dq′

[f (q′

) − D(q′

′
)∇

φ(q′

; λ)]eβ(φ(q;λ)−φ(q′

;λ)) + A0(q)eβφ(q;λ) .

q

1
θ

Z

5

(16)

(17)

(18)

(19)

(20)
(21)
(22)

(23)

(24)

6

(25)

Here A0(q) is a solution of the homogenous equation θ∇τ A(q) = 0 and the two parallel vectors in the integrand, such
as dq′ f (q), forms a matrix. This completes our answer to the converse question.

It is interesting to note that the shift between the zero’s of the potential gradient and the drift is given by, from

Eq.(22),

∆f = θ∇τ A(q) ,

that is, the extremals of the steady state distribution are not necessary determined by the zero’s of drift. This is the
formula for such a shift shown extensively in numerical studies31. This shift can occur even when D = constant.

Thus, the zero-mass limit approach to the stochastic diﬀerential equation is consistent in itself. The meaning of the
potential φ is explicitly manifested in both local trajectory according to Eq.(4) and ensemble distribution according to
Eq.(12). In particular, no detailed balance condition is assumed. There is no need to diﬀerentiate between the additive
and multiplicative noises. This zero mass limit procedure which leads to Eq.(4) from Eq.(12) may be regarded as
another prescription for the stochastic integration, in addition to those of Ito and Stratonovich11,12,15. The connection
to those methods of treating stochastic diﬀerential equation is suggested through Eqs.(18) and (12) (or Eq.(19) ).
The Ito’s method puts an emphasis on the martingale property of stochastic processes, which may be viewed as a
prescription from mathematics. The Stronotovich method stresses the diﬀerentiability such that the usual diﬀerential
chain-rule can be formally applied, which may be viewed as the prescription from engineering. The present approach
emphasizes the role played by the potential function in both trajectory and ensemble descriptions. It may be regarded
as the prescription from natural sciences.

We may conclude that the stochastic process, regardless of Ito, Stratonovich, the present method, or others, leads

to the canonical ensemble with a temperature and a Boltzmann-Gibbs type distribution function.

C. Discrete stochastic dynamics

There is another kind of modelling predominant in population genetics and other ﬁelds which is discrete in phage
space and/or time. Here we would not get into it in any detail, except quoting results when necessary. The reasons
of being able to do so are: 1) It is known mathematically any discrete model can be represented by a continuous one
exactly, though sometimes such a process may turn a ﬁnite dimension problem into an inﬁnite dimension one; 2) By a
coarse graining average the discrete dynamics in population genetics can often be simpliﬁed to continuous ones such
as diﬀusion equations or Fokker-Planck equations5,11,15. It is generally acknowledged in population genetics and in
other ﬁelds that the diﬀusion approximation is a good start and usually accurate.

For the steady state distribution, all one needs to know is the Wright evolutionary potential function φ and the
positive numerical constant θ which in many cases can be set to be unity: θ = 1. Hence, discrete or continuous
representation is not a physically or biologically relevant point.

IV. THERMODYNAMICS

Given the Boltzmann-Gibbs distribution, the partition function can be evaluated according to Eq.(15). Hence, at
the steady state, all observable quantities are in principle known according to Eq.(17). One may wonder then what
would be the value of thermodynamics. First, there is a practical reason. In many cases the calculation of the partition
function is a hard problem, if possible. It would be desirable if there are alternatives. Thermodynamics gives us a
set of useful relations between observable quantities based on general properties of the system such as symmetries.
Useful and precise information on one phenomenon can be inferred from the information on other quantities. Second,
there is a theoretical reason. The thermodynamics has a scope far more general than most other ﬁelds in physics. It
is the only ﬁeld in classical physics whose foundation and structure not only have survived quantum mechanics and
relativity shakeups, but become stronger. Furthermore, thermodynamics has a formal elegance which is exceedingly
satisfying aesthetically. Its inﬂuence is far beyond physical sciences.

There exists already numerous excellent books exposing the thermodynamics from statistical mechanics point of
view. A thorough treatment can be found in Callen34. A reader-friendly treatment can be found in Ma35. Concise
and elementary treatments from thermodynamics point of view were given by Pippard36 and by Reiss37.
In the
light of those superb expositions, the present discussion may appear incomplete as well as arbitrary. For a systematic
discussion on thermodynamics the reader is sincerely encouraged to consult those books and/or any of her/his favorites
not listed here. The main objective here is to show that the Darwinian dynamics indeed implies the main structure of
thermodynamics, though at a ﬁrst glance it seems to have no connection. The Darwinian dynamics is at the extreme
end of nonequilibrium processes.

Even given a limited scope of presentation there are already excellent and recent papers. The paper by Oono
and Panconi38 is such an example. It gave a comprehensive review on the problems from the point of view steady
state thermodynamics. There are overlaps at various places. Nevertheless, there is one main diﬀerence: The role of
”temperature” is emphasized here, instead. The paper by Sekimoto39 gave a detailed discussion on the connection
between thermodynamics and Langevin dynamics. The main diﬀerence is that in the present paper the detailed
balance condition is not needed.

A. Zeroth Law

From the Darwinian dynamics, the steady state distribution is given by a Boltzmann-Gibbs type distribution,
Eq.(11), determined by the Wright evolutionary potential function φ of the system and a positive parameter θ of
the noise strength. Hence, the analogy of the Zeroth Law of thermodynamics is implied by the Darwinian dynamics:
There exists a temperature-like quantity, represented by the positive parameter θ. This ”temperature” θ is absolute
in that it does not depend on the system’s material details.

From the partition function Zθ, we may deﬁne a quantity

We may also deﬁne the average Wright evolutionary potential function,

From the distribution function we may further deﬁne a positive quantity

B. First Law

Fθ ≡ −θ ln Zθ .

Uθ ≡

dq φ(q; λ) ρθ(q) .

Z

Z

Sθ ≡ −

dq ρθ(q) ln ρθ(q) .

Fθ = Uθ − θ Sθ ,

It is then straightforward to verify that

precisely the fundamental relation in thermodynamics satisﬁed by free energy, internal energy, and entropy. Hence
we have the free energy Fθ, the internal energy Uθ, and the entropy Sθ. The subscript θ emphasizes the steady state
nature of those quantities. Due to the ﬁnite strength of stochasticity, that is, θ > 0, not all Uθ is readily usable: Fθ
is always smaller than Uθ. A part of θ Sθ called ”heat” cannot be utilized.

It can also be veriﬁed from deﬁnitions that if the system consists of several non-interacting parts, Fθ, Uθ, and Sθ
are sum of those corresponding parts. Hence, they are extensive quantities. No attention is paid here to the ﬁne
diﬀerence between additive and extensive properties. Instead, the ”temperature” θ is an intensive quantity: it must
be the same for all those parts because they are contacting the same noisy source. Therefore, we conclude that the
analogy of the First Law of thermodynamics is implied in the Darwinian dynamics.

The fundamental relation for the free energy, Eq.(29), as well as the internal energy, Eq.(27), may be expressed in
their diﬀerential forms. Considering an inﬁnitesimal process which causes changes in both the Wright evolutionary
potential function via parameter λ and in the steady state distribution function, the change in the internal energy
according to Eq.(27) is

dUθ =

dq

dλ ρθ(q) +

dq φ(q; λ) dρθ(q)

φ(q; λ)
∂λ

Z

= µ dλ + θdSθ .

Z

This is the diﬀerential form for the internal energy. Here the steady state entropy deﬁnition of Eq.(28) has been used,
along with

dq dρθ(q) = 0, and

R

µ ≡

∂Uθ
∂λ

.

θ

(cid:12)
(cid:12)
(cid:12)
(cid:12)

7

(26)

(27)

(28)

(29)

(30)

(31)

Eq.(30) can be written in the usual form in thermodynamics:

dUθ = ¯dW + ¯dQ .

The part corresponding to the change in entropy is the ”heat” exchange: ¯dQ = θ dS and the part corresponding to
the change in the Wright evolutionary potential function is the ”work” ¯dW = µ dλ. The conservation of ”energy” is
most clearly represented by Eq.(30). For the free energy,

dFθ = dUθ − dθ Sθ − θdSθ
= µ dλ − Sθ dθ .

Eq.(30) and (32) may be useful in some applications. For example, the ”temperature” can be found via Eq.(30):

∂Uθ
∂Sθ (cid:12)
(cid:12)
(cid:12)
This relation may be used to ﬁnd the ”temperature” in a nonequilibrium process if it is not obvious to identify a
(cid:12)
priori40.

(33)

θ =

λ

.

The convexity of a thermodynamical quantity is naturally incorporated by the Boltzmann-Gibbs distribution. There
is no restriction on the size of the system. Even for a ﬁnite system, phase transitions can occur, because singular
behaviors can be built into the potential function, and controlled by external quantities.

C. Second Law

First, we remind the reader of a few more important deﬁnitions.

A reversible process is such a process that all the relation between quantities and parameters in question is deﬁned
through the Boltzmann-Gibbs distribution, Eq.(11). From the Darwinian dynamics point of view, the reversible
process in reality is necessarily a slow or quasi-static process in order to ensure the relevancy of steady state distribution
for its any practical realization.
An isothermal process is a reversible process in which ”temperature” θ remains unchanged, θ = constant. No confusion
with the thermostated processes, which are in general nonequilibrium dynamical processes, should arises.
An adiabatic process is a reversible process in which the coupling between the system and the noise source is switched
oﬀ and the system vary in such a way the distribution function remains unchanged along the dynamics trajectory
when following each point in phase space. This implies that the entropy remains unchanged, Sθ = constant. The
adiabatic process has often been used in irreversible processes in that there is no heat exchange between the system
and the noisy environment, hence S(t) = constant (c.f. Eq.(42)).

Now we discuss the analogy of Carnot cycle on which the Carnot heat engine is based. The Carnot cycle consists
of four reversible processes: two isothermal processes and two adiabatic processes (Fig. 1.a,b). The eﬃciency ν of the
Carnot heat engine is deﬁned as the ratio of the total net work performed over the heat absorbed at high temperature:

ν ≡

∆Wtotal
∆Q12

.

Figure 2. Carnot cycle. (a). The µ − λ representation. (b). The θ − S representation. In this temperature-entropy

(a)

(b)

representation, the Carnot cylce is a rectangular.

absorbed at the high isothermal process 1 → 2,

The total net work done by the system is represented by the shaded area enclosed by the cycle. For the heat

For the adiabatic process 2 → 3, an external constraint represented by λ is released (or applied),

∆Q12 = θhigh∆Sθ,12 .

∆Sθ,23 = 0 , ∆Q23 = 0 .

8

(32)

(34)

(35)

(36)

9

(37)

(38)

(39)

(40)

(41)

For the heat absorbed (rather, released) at the low isothermal process 3 → 4,

For the adiabatic process 4 → 1, an external constraint is applied (released),

∆Q34 = θlow∆Sθ,34 = −∆Q43 .

∆Sθ,41 = 0 , ∆Q41 = 0 .

∆Ftotal = ∆Qtotal − ∆Wtotal

= 0 .

Using the First Law, Eq.(29) and the fact that the free energy is a state function

The minus sign in front of the total work represents that it is the work done by the system, not to the system. The
total heat absorbed by the system is

∆Qtotal = ∆Q12 + ∆Q34 = ∆Q12 − ∆Q43 = ∆Wtotal .

We further have

From Eq.( ), ( ) and ( ) the Carnot heat engine eﬃciency is then

∆Sθ,12 = ∆Sθ,43 .

ν = 1 −

= 1 −

∆Q43
∆Q12
θlow
θhigh

,

precisely the form in thermodynamics. The beauty of Carnot heat engine is that its eﬃciency is completely independent
of any material details. It brings out the most fundamental property of thermodynamics and is a direct consequence
of the Boltzmann-Gibbs distribution function and the First Law. It reveals a property of Nature which may not be
contained in a conservative dynamics, at least it is still not obviously to many people from the Newtonian dynamics
point after more than 150 years of intensive studies. The Second Law of thermodynamics may be stated as that for
all heat engines operating between two temperatures, Carnot heat engine is the most eﬃcient. The Second Law is
implied in the Darwinian dynamics.

There are many other versions of the Second Law, on which the reader is suggested to consult the books listed at
the beginning of this section. Here we mentioned two equivalent versions from the stability point of view, which frame
following discussions.
Minimum free energy statement: For given the potential function and the temperature, the free energy achieves its
lowest possible value if the distribution is the Boltzmann-Gibbs distribution.
Maximum entropy statement: For given potential function and its average, the entropy attains its maximum value
when the distribution is the Boltzmann-Gibbs distribution. This version of the Second Law is the most inﬂuential.
Its inverse statement, the so-called maximum entropy principle, has been extensively employed in the probability
inference32 both within and beyond physical and biological sciences.

It is attempting to generalize the entropy deﬁnition to the arbitrary time dependent distribution in analogy to

Eq.(28):

S(t) ≡ −

dq ρ(q, t) ln ρ(q, t) .

(42)

Z

There are two apparent drawbacks for such deﬁnition, however. First, even if the evolution of the distribution function
ρ(q, t) is governed by the Fokker-Planck equation, Eq.(12), in general the sign of its time derivative, dS(t)/dt = ˙S(t),
cannot be determined, whether or not it is close to the steady state distribution. Though ˙S(t) might indeed be
divided into an always positive part and the rest, such a partition is arbitrary. More seriously, in general S(t) can be
either larger or smaller than Sθ, which makes such a deﬁnition lose its appealing in the view of the maximum entropy
statement of the Second Law. We will return to S(t) later.

Nevertheless, if taking the lesson from the potential function that only the relative value is important, we may
introduce a reference point in the functional space into a general entropy deﬁnition. One deﬁnition for the referenced
entropy is33

Sr(t) ≡ −

dq ρ(q, t) ln

+ Sθ .

ρ(q, t)
ρθ(q)

Z

(43)

With the aid of inequality ln(1 + x) ≤ x and the normalization condition
immediately veriﬁed that

dq ρ(q, t) =

dq ρθ(q) = 1, it can be

R
ρθ(q) − ρ(q, t)
ρ(q, t)

+ Sθ ,

(cid:19)

R

Sr(t) =

dq ρ(q, t) ln

1 +

Z

(cid:18)
dq (ρθ(q) − ρ(q), t) + Sθ ,

≤

Z
≤ Sθ .

The equality holds when ρ(q, t) = ρθ(q). This inequality is independent of the details of the dynamics and is evidently
a maximum entropy statement. Furthermore, with the aid of the Fokker-Planck equation, Eq.(12), the time derivative
of this referenced entropy, dSr(t)/dt = ˙Sr(t) is always non-negative:

˙Sr(t) = −

dq

(q, t) ln

∂ρ
∂t

ρ(q, t)
ρθ(q)

= −

dq (∇τ [D(q) + A(q)][θ∇ + ∇φ(q; λ)]ρ(q, t)) ln

ρ(q, t)
ρθ(q)

ρ(q, t)
ρθ(q)

τ

(cid:19)

[D(q) + A(q)][θ∇ + ∇φ(q; λ)]ρ(q, t)

([θ∇ + ∇φ(q; λ)]ρ(q, t))τ [D(q) + A(q)][θ∇ + ∇φ(q; λ)]ρ(q, t)

([θ∇ + ∇φ(q; λ)]ρ(q, t))τ D(q) [θ∇ + ∇φ(q; λ)]ρ(q, t)

jτ (q, t) R(q) j(q, t)

Z

Z
dq

dq

dq

dq

=

=

=

=

Z

Z

Z

Z
≥ 0 .

∇ ln

(cid:18)

1
θρ(q, t)
1
θρ(q, t)
1
θρ(q, t)

Hence, this referenced entropy Sr(t) has all the desired properties for the maximum entropy statement.

We remark that by the probability current density deﬁnition of Eq.(14) j is zero at the steady state. This may
diﬀer from the usual probability current density deﬁnition which may be based on Eq.(18) and takes the form
¯j(q, t) ≡ −[θD∇ − ¯f (q)]ρ(q, t), which is not zero at the steady state. Instead, ∇ · ¯j = 0 at the steady state.

Though the general deﬁnition of entropy of Eq.(42) may not be appealing, a general deﬁnition of free energy is
consistent with the Second Law. We demonstrate it here. First, a general deﬁnition for the internal energy may be:

Given the distribution and the potential function, quantities deﬁned in Eq.(42) and (46) can be evaluated. Following
the form of Eq.(26) a general deﬁnition of free energy would be, with the ”temperature” θ,

˙F (t) ≤ 0. So deﬁned time dependent
It can be veriﬁed that F (t) ≥ Fθ and its time derivative is always non-positive,
free energy indeed satisﬁes the minimum free energy statement of the Second Law. It diﬀers from the referenced
entropy Sr(t) by a minus sign and by a constant:

U (t) ≡

dq φ(q; λ) ρ(q, t) .

Z

F (t) ≡ U (t) − θ S(t) .

F (t) = −θSr(t) + Uθ .

The generalized entropy S(t) has one desired property regarding to the adiabatic processes (either reversible or
irreversible) in that D = 0 during the adiabatic process. Hence,

˙S(t) = −

dq

(q, t) ln ρ(q, t)

∂ρ
∂t

Z

Z

Z
= 0 .

= −

dq [∇τ A(q) ∇φ(q; λ)ρ(q, t)] ln ρ(q, t)

= −

dq [(A(q) ∇φ(q; λ)) · ∇]

ρ(q,t)

′

dρ

ln ρ

′

Z

10

(44)

(45)

(46)

(47)

(48)

11

(49)

(50)

(51)

(52)

This is the known result in conservative Newtonian dynamics that the entropy remains unchanged.
In deriving
above equation we have used two properties: 1) the no-coupling to the noisy environment has been translated into
the fact that the terms associated with the diﬀusion matrix D and ”temperature” θ are set to be zero in Eq.(12),
because they are related to the noisy source whose information is not available during an adiabatic process; and 2)
the incompressible condition of ∇ · [A(q) ∇φ(q; λ)] = 0, which is typically satisﬁed in the Newtonian dynamics. In
this conservative case, it can be veriﬁed that ˙Sr(t) = 0, too, for any adiabatic process.

It may be worthwhile to mention another referenced entropy Sr2(t) which approaches the steady state entropy Sθ

from above. It’s form is simple:

It can be veriﬁed that Sr2(t) ≥ Sθ and ˙Sr2(t) ≤ 0.

Sr2(t) ≡ −

dq ρθ(q) ln ρ(q, t) .

Z

D. Third Law

Now we consider the behavior near zero ”temperature”, θ → 0. To be speciﬁc we assume the system is dominated
by a stable ﬁxed point. As suggested by the Boltzmann-Gibbs distribution, Eq.(11), only the regime of phase space
near this stable ﬁxed point will be important. Hence the Wright evolutionary potential function can be expanded
around this point, taking as q = 0:

Here we have also assumed that the number of independent modes is the same as the dimension of the phase space,
though it may not necessary be so. This assumption will not aﬀect our conclusion below. Those independent modes
are represented by qj without loss of generality. The ”spring coeﬃcients” {kj} are functions of external parameters
represented by λ.

The partition function according to Eq.(15) can be readily evaluated in this situation:

φ(q; λ) = φ(0; λ) +

kj (λ)q2

j .

1
2

n

j=1
X

Zθ = e

−βφ(0;λ)

n

j=1 s
Y

2πθ
kj

.

Sθ = n

θ −

ln θ

+

(cid:20)

(cid:21)

1
2

1
2

n

j
X

kj
2π

.

So is the entropy according according to Eq.(28):

The ﬁrst term does not depend on external parameters, but the second term does. This suggests that the entropy
depends on control process in a ﬁnite manner at low enough temperature. Hence, the Darwinian dynamics does not
imply the Third Law in which it states that in the limit of zero temperature the diﬀerence in entropy between diﬀerent
processes is zero.

One should not be surprised by above conclusion, because the Darwinian dynamics is essentially a classically
dynamics. Same a conclusion could also be reached from classical physics. With quantum mechanics, the agreement
to the Third Law is found and a stronger conclusion has been reached: Not only the diﬀerence in entropy should be
zero, the entropy itself is zero at zero temperature.

We may conclude that a complete neglecting noise is not viable choice in general. When noise is small enough, new

phenomena would happen. Phrasing diﬀerently, there appears to exist a bottom near which there is something.

To summarize, in this section we have shown that except the Third Law, all other Laws of thermodynamics would
follow from Darwinian dynamics. The concern39 on which stochastic integration method, Ito, Stratonovitch, or others,
is consistent with the Second Law is dissolved: Any of them can be made to be consistent with the Second Law. We
also note that based on the thermodynamical relations, the fundamental relation of Eq.(29), the conservation of energy
of Eq.(30), the universal heat engine eﬃciency of Eq.(41), supplemented by the additive of extensive quantities and
the temperature of Eq.(33), the Boltzmann-Gibbs distribution is implied. In this sense the statistical mechanics and
the thermodynamics are equivalent.

Thermodynamics deals with the steady state properties. The key property is determined by the Boltzmann-Gibbs
distribution of Eq.(11) which only depends on the Wright evolutionary potential function φ and the ”temperature”

θ. The rest relations are determined by the various symmetries of the system. No dynamical information can be
inferred from them. In particular, there is no way to recover the information on two quantities determine the local
time scales, the friction matrix R and the transverse matrix T , from thermodynamics. In this sense the time is lost in
thermodynamics. With this consideration, it is evident that thermodynamics contains no direction of time and hence
is consistent with the time-reversal conservative Newtonian dynamics.

V. DYNAMICAL EQUALITIES

We have explored the steady state consequences of the Darwinian dynamics in statistical mechanics and in ther-
modynamics. In this section we explore its general dynamical consequences. Two types of recently found dynamical
equalities will be discussed: one based on the Feynman-Kac formula and other a generalization of the Einstein relation.

Previous discussions demonstrate that the Boltzmann-Gibbs distribution plays a dominant role. It is naturally to
work in a representation in which Boltzmann-Gibbs distribution appears in a most straightforward manner, or, as
close as possible. The standard approach in this spirit is as follows. First, choose the dominant part of evolution
operator L. The remaining part is denoted as δL. In this subsection a general methodology to carry out this procedure
is summarized.

The Fokker-Planck equation, Eq.(12), can be rewritten as

A. Feynman-Kac formula

∂
∂t

ρ(q, t) = L(∇, q; λ)ρ(q, t) ,

with L = ∇τ [D(q) + A(q)][θ∇ + ∇φ(q)]. It’s solution can be expressed in various ways. The most suggestive form in
the present context is that given by Feynman’s path integral41: If at time t′ the system is at q′, the probability for
system at time t and at q is given by summation of all trajectories allowed by Eq.(4) connection those two points:

In terms of the summation over the trajectories, the solution to Eq.(53) (and Eq.(12)) may be expressed as

π(q, t; q′

′

, t

) =

q(t) = q; q(t

′

) = q′

.

trajectories
X











ρ(q, t) =

dq′

π(q, t; q′

′

, t

) ρ(q, t = 0)

Z

≡ hδ(q(t) − q)i|trajectory .

The delta function δ(q(t) − q) is used to explicitly specify the end point. There is a summation over initial points q′
weighted by the initial distribution function ρ(q′, t = 0).

Now, considering that the system is perturbed by δL(q; λ), represented, for example, by a change in control

parameter λ. The new evolution equation is

∂
∂t

ρnew(q, t) = [L(∇, q; λ) + δL(q; λ)]ρnew(q, t) .

The perturbation may act as a source or sink for the probability distribution. The probability is no longer conserved:
dq ρnew(q, t = 0). According to the Feynman-Kac formula22, its solution to this new
dq ρnew(q, t) 6=
in general
equation can be expressed as
R

R

ρnew(q, t) =

δ(q(t) − q) e

′
dt

′
δL(q(t

))

t

0

,

trajectory

R
with ρnew(q′, t = 0) = ρ(q′, t = 0) and the trajectories following the dynamics of Eq.(4), the same as that in Eq.(55).
Thus, the evolution of the new density can be expressed by the evolution of the original dynamics. The corresponding
procedure in quantum mechanics is that in the interaction picture42. Eq.(57) is a powerful equality. Various dynamical
equalities can be obtained starting from Eq.(57). Indeed, its direct and indirect consequences have been extensively
explored43,44.

(cid:28)

(cid:29)(cid:12)
(cid:12)
(cid:12)
(cid:12)

12

(53)

(54)

(55)

(56)

(57)

B. Dynamical work and free energy diﬀerence

We have noticed the special role played by the Botlzmann-Gibbs distribution, Eq.(11). In particular, it is indepen-
dent of the friction and transverse matrices R, T . Evidently the instantaneous Botlzmann-Gibbs distribution with
λ = λ(t) is

ρθ(q; λ(t)) =

e−βφ(q;λ(t))
Zθ(λ(0))

.

Here we have explicitly indicated that the parameter is time-dependent. This distribution function is no longer the
solution of the Fokker-Planck equation of Eq.(12). There will be transitions out of this instantaneous Boltzmann-
Gibbs distribution function due to the time-dependence of the parameter λ. While such transitions may be hard to
conceive in classical mechanics, they can be easily identiﬁed in quantum mechanics, because of discreteness of states42.
One of such well studied models is the dissipative Landau-Zener transition45.

The interesting question is that whether the transitions can be reversed such that the instantaneous distribution is
indeed an explicit solution for another but closely related evolution equation. This means that the original Fokker-
Planck equation has to be modiﬁed in a special way to become a new equation.
Indeed, this modiﬁed evolution
equation can be found for any function ¯ρ(q, t), which reads,

ρnew(q, t) =

L(∇, q, t) −

(L(∇, q, t)¯ρ(q, t)) +

ρnew(q, t) .

(59)

∂
∂t

(cid:20)

1
¯ρ(q, t)

∂ ln |¯ρ(q, t)|
∂t

(cid:18)

(cid:19)(cid:21)

It can be veriﬁed ρnew(q, t) = ¯ρ(q, t) is indeed a solution of above equation. Treating

δL = −

L(∇, q, t)¯ρ(q, t) +

1
¯ρ(q, t)

∂ ln |¯ρ(q, t)|
∂t

and the Feynman-Kac formula Eq.(57) may be applied. The analogous procedure is well studied on the transitions
during adiabatic processes in interaction picture of quantum mechanics42,45 and of statistical mechanics41.
Now, let ¯ρ be the instantaneous Boltzmann-Gibbs distribution of Eq.(58): ¯ρ = ρθ(q; λ(t)). We have

δL = −β ˙λ

∂φq; λ)
∂λ

.

Eq(59) can be solved by summing over all trajectories using the Feynman-Kac formula, Eq.(57). At the same time,
we know the instantaneous Boltzmann-Gibbs distribution of Eq.(58) is its solution. Hence equal those two solutions
to the same equation, we have following equality

Following Jarzynski46 we deﬁne the dynamical work

R

e−βφ(q;λ(t))
dq e−βφ(q;λ(0)) =

(cid:28)

δ(q − q(t)) e

−β

t

0

dt

′
′ ˙λ(t

′
) ∂φ(q(t

∂λ

′
);λ(t

))

R

trajectory
(cid:29)(cid:12)
(cid:12)
(cid:12)
(cid:12)

t

′

′ ˙λ(t

)

dt

∂φ(q(t′); λ(t′))
∂λ

Wt =

0
Z

−β∆Fθ =

e

−βWt

e

trajactory

The equality between the free energy diﬀerence ∆Fθ = Fθ(t) − Fθ(0)) and the dynamical work Wt is, after summation
over all ﬁnal points of the trajectories in Eq.(60),

(cid:10)

(cid:11)(cid:12)
(cid:12)

This elegant equality connects the steady state quantities ∆Fθ to the work done in a dynamical process. It was ﬁrst
discovered by Jarzynski46. It should be emphasized that there is no assumption of steady state state at time t for
the system governed by Eq.(12). In fact, it is known, for example, in case of the Landau-Zener transition that it
is not45. This equality has been discussed and extended by various authors from various perspectives47,48,49,50,51,52.
The connection of this equality to the Fyenman-Kac formula was ﬁrst explicitly pointed out in Ref.48. There have
been experimental veriﬁcations of this equality53.

The Jarzynski equality places the Boltzmann-Gibbs distribution hence the canonical ensemble in a central position.
They are simply natural consequences from the Darwinian dynamics. However, if starting from the conservative
Newtonian dynamics, the appropriate ensemble is the micro-canonical ensemble. Any distribution function which

13

(58)

(60)

(61)

(62)

is a function of the potential function or Hamiltonian would be the solution of the Liouville equation. From this
point of view the Boltzmann-Gibbs distribution and the associated temperature appear arbitrary: It is just one
among inﬁnite possibilities. This concern has been raised in literature54 regarding to the generality of the equality of
Eq.(62). No satisfactory treatment of this concern within Newtonian dynamics has been given. Rather, it has been
an ”experimental attitude”: If one does this and makes sure the procedure is correct one gets that, and it works.
Instead, the Darwinian dynamics provides one a priori reason to justify the use of Boltzmann-Gibbs distribution in
the derivation of the Jarzynski equality.

C. Generalized Einstein relation

In deriving the Boltzmann-Gibbs distribution from the Darwinian dynamics, a generalization of the Einstein rela-

tion, Eq.(6):

[R(q) + T (q)] D(q) [R(q) − T (q)] = R(q) ,

has been used28. This is another general and simple dynamical equality. In the presence of detailed balance condition,
that is, T = 0, this relation reduces to RD = 1, which was discovered a century ago by Einstein55 and since known as
the Einstein relation. Variants of the Einstein relation in diﬀerent settings were obtained earlier and independently by
Nernst56, Townsend57, Sutherland58. Similar to the Jarzynski equality, the generalized Einstein relation is connected
to the Boltzmann-Gibbs distribution.

Experimentally, all those quantities in Eq.(6) can be measured. Hence, this generalized Einstein relation should be

subjected to experimental tests in the absence of detailed balance, that is, when T 6= 0.

For simplicity, we consider a situation realizable with current technology: a charged nanoparticle or macromolecule,
an electron or a proton, with charge denoted by e, in the presence a strong uniform magnetic ﬁeld B and emersed in a
viscous liquid with friction coeﬃcient η. We restrict our attention to two dimensional case (n = 2). The corresponding
Darwinian dynamical equation of Eq.(4) in this case is the Langevin equation with the Lorentz force for a ”massless”
charged particle59:

The friction matrix is

The transverse matrix is

η ˙q +

B ˆz × ˙q = −∇φ(q) + NII ξ(t)

e
c

S = η

1 0
0 1

(cid:18)

(cid:19)

T =

B

e
c

0
1
−1 0

(cid:18)
and the ”temperature” is θ = kBTBG, the Boltzmann constant and the thermal equilibrium temperature. The
corresponding Fokker-Planck equation following Eq.(12) is

(cid:19)

∂ρ(q, t)
∂t

= ∇[Dθ ∇ + [D + A]∇φ(q)]ρ(q, t) .

This is a precisely a diﬀusion equation with diﬀusion matrix D. Both D and A can be obtained via the generalized
Einstein relation, Eq.(6):

D =

η

η2 +

2

e
c B

(cid:18)

1 0
0 1

(cid:19)

(cid:1)

2

(cid:0)
e
c B
e
c B

0 −1
1 0

(cid:18)

(cid:19)

A =

η2 +

(cid:1)
In a typical classical situation, though all quantities can be measured experimentally, the friction coeﬃcient is likely
less sensitive to the magnetic ﬁeld. Then the experimentally one may need to focus on the diﬀusion in the present

(cid:0)

14

(63)

(64)

(65)

(66)

(67)

(68)

15

(69)

of magnetic ﬁeld without any potential ﬁeld. In this case the evolution of distribution is governed by the standard
diﬀusion equation:

with

The solution to Eq.(69) with ρ(q, t = 0 = δq(t = 0) − q is standard (two dimension, n = 2):

∂ρ(q, t)
∂t

= θdB ∇2ρ(q, t) ,

dB =

.

η2 +

2

e
c B

η

(cid:0)

i

(cid:1)

h

1
2π t

ρ(q, t) =

exp

−

q2
2dBθ t

(cid:27)

(cid:26)

Averaging over trajectories governed by Eq.(69), hq(t) − q(t = 0)i|trajectory = 0 and

(q(t) − q(t = 0))2

trajectory = 4dBθ t .

(cid:10)

(cid:11)(cid:12)
The readily experimental system may be that by injection of electrons into a semiconductor one measures their diﬀusion
(cid:12)
in the presence of a magnetic ﬁeld. Every quantity in the generalized Einstein relation of Eq.(6) can be measured and
controlled experimentally. Such experiments may has already been done (????). Another experimental system may
be on ionized hydrogen or deuterium. For charged macromolecules and nano-particles, the friction coeﬃcient may
be too large to allow a measurable magnetic ﬁeld eﬀect accessible by current magnets. As a numerical example, for
the zero magnetic ﬁeld diﬀusion constant of dB=0kBTBG ∼ 104 cm2/sec, which amounts to diﬀuse about 100cm in 1
second, the friction coeﬃcient is η = 1/dB=0 ∼ 4 × 10−16dyne/(cm/sec) at temperature TBG = 300K. Assuming one
net electron charge, for magnetic ﬁeld B = 1 T elsa , we have eB/c ∼ 1.6 × 10−16dyne/(cm/sec), comparable to the
friction coeﬃcient.

VI. PROSPECT

In the present paper we have presented the statistical mechanics and thermodynamics as natural consequences of
the Darwinian dynamics. Two types of recently found general dynamical equalities have been explored. Both can be
directly tested experimentally. Everything appears in its right place except one: From the physics point of view it
is the conservative dynamics from which we should start, not that of the Darwinian. This physics view has indeed
tremendous of experimental supports. Remarkable progresses have been made along this line of reasoning during past
150 years. It is still the subject of current intensive research focus16,17,54. The physics eﬀort may be condensed to
one question. The natural consequence of the conservative dynamics is the micro-canonical ensemble, from which the
canonical ensemble just appears to be one of its inﬁnite possibilities. How and why does Nature choose the canonical
ensemble and the Second Law? There is no consensus yet on the answer .

The diﬃculty in reaching the Second Law from the conservative dynamics may give a boost to consider the Darwinian
dynamics. There is, however, a genuine and compelling reason to to do so: the Darwinian dynamics is the most
fundamental and successful dynamical theory in biological sciences. Furthermore, as having demonstrated above,
from it the Second Law and other nonequilibrium properties follow naturally. Logically it provides a simple starting
point. It must contain an element of truth.

The conservative dynamics and the Darwinian dynamics appear to occupy the two opposite ends of the theoretical
description of Nature. Both have been extremely successful.
In many aspects they appear to be complementary
to each other. Wether or not there is a hidden reason such that they are truly related to each other is not known
presently. It waits to be discovered by further experimental and theoretical studies. The present deliberation may
provide a certain utility for this endeavor.

acknowledgement. We thank M. Dykman, J. Felsenstein, H. Qian, D.J. Thouless, J. Wang, L. Yin, X.M. Zhu
for constructive discussions at various stages of this work. There is a vast body of work done on statistical mechanics
and thermodynamics. No single paper can do justice to the relevant literature. Admittedly very incomplete, it is my
hope a useful fraction of literature has been covered and a spirit of current research activities has been captured. In
addition, this work is a critical discussion of two fundamental ﬁelds based on an emerging dynamical formulation.

Biases and prejudices are unavoidable. I apologize to those whose important works are not mentioned here, likely the
result of my own oversight. I would appreciate the reader’s eﬀort very much to bring her/his or other’s important
works to my attention (e-mail: aoping@u.washington.edu). This work was supported in part by USA NIH grant under
HG002894.

16

Berlin (2004).

(2005) 43-48.

21502-21515.

1 Darwin, C. and Wallace, A., On the tendency of species to form varieties; and on the perpetuation of varieties and species

by natural means of selection. Journal of the Proceedings of the Linnean Society of London, Zoology 3: 45-62 (1858).

2 Darwin, C., On the Origin of Species by Means of Natural Selection, or the preservation of favoured races in the struggle for

life. Penguin, New York, 1958.

3 Fisher, R.A., The Genetical Theory of Natural Selection. Clarendon, Oxford, 1930.
4 Wright, S., The roles of mutation, inbreeding, crossbreeding and selection in evolution. Proceedings of the Sixth International

Congress of Genetics. 1: 356-366 (1932).

5 W.H. Li (ed) Stochastic Modeles in Population Genetics. Dowden, Hutchison and Ross, Stroudsburg, 1977.
6 R.E. Michod, Darwinian Dynamics: evolutionary transitions in ﬁtness and individuality. Princeton University Press, Prince-

ton, 1999.

7 D. Waxman and S. Gavrilets, 20 questions on adaptive dynamics. J. Evol. Biol. 18 (2005) 1139-1154.
8 P. Ao, Laws in Darwinian evolutionary theory. Physics of Life Reviews 2 (2005) 117-156.
9 G. Nicolis and I. Prigogine, Self-Organization in Nonequilibrium Systems. Wiley, New York, 1977.
10 J. Keizer, Statistical Thermodynamics of Nonequilibrium Processes. Springer, Berlin, 1987.
11 N.G. van Kampen, Stochastic Processes in Physics and Chemistry. Elsevier, Amsteredam, 1992.
12 H. Risken, The Fokker-Planck Equation: methods of solution and applications. Springer, Berlin, 1992.
13 M.C. Cross and P.C. Hohenberg, Rev. Mod. Phys. 65 (1993) 851.
14 J.S. Langer, in Critical Problems in Physics. pp11-27. edited by V.L. Fitch, D.R. Marlow, and M.A.E. Dementi. Princeton

University Press, Princeton, 1997.

15 C. W. Gardiner, Handbook of of Stochastic Methods. third edition. Springer, Berlin, 2004.
16 J.L. Lebowitz, Statistical mechanics: a selective review of two central issues. Rev. Mod. Phys. 71 (1999) S346-S357.
17 Gallavatti, G., Bonetto, F., and Gentile, G., Aspects of Ergodic, Qualitative and Statistical Theory of Motion. Springer,

18 C. Bustamante, J. Liphardt, and F. Ritort, The nonequilibrium thermodynamics of small systems. Physics Today 58 (7)

19 P. Hanggi, Introduction: 100 years of Brownian motion. Chaos 15 (2005) 026101.
20 D. Reguera, J.M. Rubi, J.M.G. Vilar, The mesoscopic dynamics of thermodynamic systems. J. Phys. Chem. B109 (2005)

21 H.C. Ottinger, Beyong Equilibrium Thermodynamics. Wiley and Sons. New York, 2005.
22 P. del Moral, Feynman-Kac Formula: genealogical and interacting particle systems with applications. Springer, Berlin, 2004.
23 J. Uﬃnk, Studies in History and Philosophy of Modern Physics 36 (2005) 219.
24 X.-M. Zhu, L. Yin, L. Hood, and P. Ao, Func. Integr. Genomics 4 (2004) 188;

J. Bioinf. Comput. Biology 2 (2004) 785.

25 R. Kubo, M. Toda, and N. Hashitsume, Statistical Physics: nonequilibrium statistical mechanics. v. 2. Second edition.

Springer, Berlin, 1992.

26 R. Zwanzig, Nonequilibrium Statistical Mechanics. Oxford University Press, New York, 2001.
27 C. Kwon, P. Ao, and D.J. Thouless, Proc. Natl. Acad. Sci. (USA) 102 (2005) 13029-34.
28 P. Ao, J. Phys. A37 (2004) L25.
29 L. Yin and P. Ao (2005) (submitted for publication, available upon request.)
30 J.L. Doob. Classical Potential Theory and its Probabilistic Counterpart. Springer-Verlag, New York, 1984.
31 B. Lindner, J. Garcia-Ojalvo, A. Neiman, and L. Schimansky-Geier, Phys. Rep. 392 (2004) 321.
32 E.T. Jaynes, Probability Theory: the logic of science. Cambridge University Press, Cambridge, 2003.
33 S.R. de Groot and P. Mazur, Non-Equilibrium Thermodynamics. Dover, New York, 1984.
34 H.B. Callen, Thermodynamics and an Introduction to Thermostatistics, 2nd edition. Wiley and Sons, New York, 1985.
35 S.K. Ma, Statistical Mechanics. World Scientiﬁc, Singapore, 1985.
36 A.B. Pippard, The Elements of Classical Thermodynamics. Cambridge University Press, Cambridge, 1964.
37 H. Reiss, Methods of Thermodynamics. Dover, New York, 1996.
38 Y. Oono and M. Paniconi, Steady state thermodynamics. Prog. Theor. Phys. (suppl.) 130 (1998) 29-44.
39 K. Sekimoto, Langevin equation and thermodynamics. Prog. Theor. Phys. (suppl.) 130 (1998) 17-27.
40 J. Casas-Vazquez and D. Jou, Temperature in non-equilibrium states: a review of open problems and current proposals.

Rep. Prog. Phys. 66 (2003) 1937-2023.

41 R.P. Feynman, Statitiscal Mechanics: a set of lectures . W.A. Benjamin, Reading, 1972.
42 L.I. Schiﬀ, Quantum Mechanics, 3rd edition. McGraw-Hill, New York, 1968.
43 G.N. Bochkov and Y.E. Kuzaovlov, General theory of thermal ﬂuctuations in nonlinear systems. Sov. Phys. JETP 45 (1977)

125-130.

17

44 D.J. Evans and D.J. Searles, The ﬂuctuation theorem. Adv. Phys. 51 (2002) 1529-1585.
45 P. Ao and J. Rammer, Inﬂuence of dissipation on the Landau-Zener transition, Phys. Rev. Lett. 62 (1989) 3004-3007.

Quantum dynamics of a 2-state system in a dissipative environment, Phys. Rev. B43 (1991) 5397-5418.
46 C. Jarzynski, Nonequilibrium equality for free energy diﬀerence. Phys. Rev. Lett. 78 (1997) 2690-2693.
47 G.E. Crooks, Entropy production ﬂuctuation theorem and the nonequilibrium work relation for free energy diﬀerences. Phys.

48 G. Hummer and A. Szabo, Free energy reconstruction from nonequilibrium single-molecule pulling experiments. Proc. Natl.

Rev. E 60 (1999) 2721-2726.

Acad. Sci. (USA) 98 (2001) 3658-3661.

49 T. Hatano and S.I. Sasa, Phys. Rev. Lett. 86 (2001) 3463.
50 S. Park and K. Schulten, J. Chem. Phys. 120 (2004) 5946-5961.
51 V. Chernyak, M. Chertkov, and C. Jarzynski, Phys. Rev. E71 (2005) 025102.
52 H. Qian, Nonequilibrium potential function of cmemically dirven single macromolecules via Jarzynski-type log-mean-

exponential heat. J. Phys. Chems. B109 (2005) 23624-23628.

53 D. Collin, F. Ritort, C. Jarzynski, S.B. Smith, I. Tinoco Jr. and C. Bustamante, Veriﬁcation of the Crooks ﬂuctuation

theorem and recovery of RNA folding free energies. Nature 437 (2005) 231-234.

54 E.G.D. Cohen and D. Mauzerall, The Jarzynski equality and the Boltzmann factor. Mol. Phys. 103 (2005) 2923-2926.
55 A. Einstein, On the movement of small particles suspened in stationary liquids required by the molecular kinetic theory of

heat. Ann. Physik 17 (1905) 549-560.

56 W.H. Nernst, Z. Phys. Chem. 2 (1888) 613- .
57 J.S. Townsend, Philos. Trans. R. Soc. London A193 (1899) 129- .
58 W. Sutherland, A dynamical theory of diﬀusion for non-electrolytes and the molecular mass of Albumin. Phil. Mag. 9 (1905)

781-785.

59 N.W. Ashcroft and N.D. Mermin, Solid State Physics. Saunders College, Philadelphia, 1976.

