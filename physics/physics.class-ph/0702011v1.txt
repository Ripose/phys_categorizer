7
0
0
2
 
b
e
F
 
1
 
 
]
h
p
-
s
s
a
l
c
.
s
c
i
s
y
h
p
[
 
 
1
v
1
1
0
2
0
7
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

An Application of Reversible Entropic Dynamics
on Curved Statistical Manifolds1

Carlo Cafaro2, Saleem A. Ali3 and Adom Gifﬁn4

Department of Physics, University at Albany–SUNY, Albany, NY 12222, USA

Abstract. Entropic Dynamics (ED) [1] is a theoretical framework developed to investigate the
possibility that laws of physics reﬂect laws of inference rather than laws of nature. In this work, a
RED (Reversible Entropic Dynamics) model is considered. The geometric structure underlying the
curved statistical manifold Ms is studied. The trajectories of this particular model are hyperbolic
curves (geodesics) on Ms. Finally, some analysis concerning the stability of these geodesics on Ms
is carried out.

Keywords: Inductive inference, information geometry, statistical manifolds, relative entropy.

1. INTRODUCTION

We use Maximum relative Entropy (ME) methods [2, 3] to construct a RED model. ME
methods are inductive inference tools. They are used for updating from a prior to a pos-
terior distribution when new information in the form of constraints becomes available.
We use known techniques [1] to show that they lead to equations that are analogous
to equations of motion. Information is processed using ME methods in the framework
of Information Geometry (IG) [4]. The ED model follows from an assumption about
what information is relevant to predict the evolution of the system. We focus only on
reversible aspects of the ED model. In this case, given a known initial state and that
the system evolves to a ﬁnal known state, we investigate the possible trajectories of the
system. Reversible and irreversible aspects in addition to further developments on the
ED model are presented in a forthcoming paper [5]. Given two probability distributions,
how can one deﬁne a notion of "distance" between them? The answer to this question is
provided by IG. Information Geometry is Riemannian geometry applied to probability
theory. As it is shown in [6, 7], the notion of distance between dissimilar probability
distributions is quantiﬁed by the Fisher-Rao information metric tensor.

1 Presented at MaxEnt 2006, the 26th International Workshop on Bayesian Inference and Maximum
Entropy Methods (July 8-13, 2006, Paris, France)
2 E-mail: carlocafaro2000@yahoo.it
3 E-mail: alis@alum.rpi.edu
4 E-mail: physics101@gmail.com

2. THE RED MODEL

,

∈

∈

R+ and x2

We consider a RED model whose microstates span a 2D space labelled by the variables
R. We assume the only testable information pertaining to the quantities
x1
and the variance D x2. These three
x1 and x2 consists of the expectation values
x2
x1
h
expected values deﬁne the 3D space of macrostates of the system. Our model may be
extended to more elaborate systems where higher dimensions are considered. However,
for the sake of clarity, we restrict our consideration to this relatively simple case. A
measure of distinguishability among the states of the ED model is achieved by assigning
a probability distribution p(tot)
. The process of assigning a
probability distribution to each state provides MS with a metric structure. Speciﬁcally,
the Fisher-Rao information metric deﬁned in (6) is a measure of distinguishability
among macrostates. It assigns an IG to the space of states.

to each macrostate ~q

~q
|

(cid:17)

(cid:16)

~x

i

i

h

2.1. The Statistical Manifold MS

Consider a hypothetical physical system evolving over a two-dimensional space.
The variables x1 and x2 label the 2D space of microstates of the system. We assume
that all information relevant to the dynamical evolution of the system is contained in
the probability distributions. For this reason, no other information is required. Each
macrostate may be thought as a point of a three-dimensional statistical manifold with
coordinates given by the numerical values of the expectations q (1)
,
x2
i
h
q (2)
2 = D x2. The available information can be written in the form of the following
constraint equations,

, q (2)

1 =

1 =

x1
h

i

rD
x1

+¥

0

Z

x1

=

h

i

+¥
0

R

D x2 =

dx1x1 p1

q (1)
1

x1

|

(cid:16)
)2

(x2

x2

− h

i

=

,

x2

=

h

i

(cid:17)
+¥
¥ dx2 (x2

−

−
R

+¥
¥ dx2x2 p2

1 , q (2)
q (2)

2

,

x2

|

x2

)2 p2

− h

i

1 , q (2)
q (2)

2

(cid:16)

x2

|

(1)

(cid:17)
1
2 ,

where q (1)
are constrained by the conditions of normalization,

, q (2)
i

1 =

1 =

x2

h

h

i

hR
E
(cid:16)
and q (2)
2 = D x2. The probability distributions p1 and p2

(cid:17)i

+¥

Z

dx1 p1

q (1)
1

x1

|

= 1,

dx2 p2

1 , q (2)
q (2)

2

x2

|

= 1.

(2)

(cid:16)

(cid:17)

(cid:16)

−
Information theory identiﬁes the exponential distribution as the maximum entropy dis-
tribution if only the expectation value is known. The Gaussian distribution is identiﬁed
as the maximum entropy distribution if only the expectation value and the variance are
known. ME methods allow us to associate a probability distribution p(tot)
to each
1 , q (2)
q (1)
point in the space of states ~q
. The distribution that best reﬂects
the information contained in the prior distribution m (~x) updated by the information

1 , q (2)

~q
~x
|

≡

(cid:17)

(cid:17)

(cid:16)

2

(cid:17)

(cid:16)

¥
,

(

x1
h

i

h

x2

i

, D x2) is obtained by maximizing the relative entropy

~q

S

=

(cid:16)

(cid:17)

+¥

+¥

−

0

Z

Z

−

dx1dx2 p(tot)

log

~x

~q
|

(cid:16)

(cid:17)





p(tot)

~q
~x
|
m (~x) 

(cid:17)

(cid:16)

,



(3)

≡

m is the uniform prior probability distribution. The prior m (~x) is set to
where m(~x)
be uniform since we assume the lack of prior available information about the system
(postulate of equal a priori probabilities). Upon maximizing (3), given the constraints
(1) and (2), we obtain

p(tot)

~q
~x
|

= p1

q (1)
1

x1

|

(cid:16)

(cid:17)

(cid:16)

p2

x2

|

(cid:17)

(cid:16)

1 , q (2)
q (2)

2

(cid:17)

1

x1
m
1

e−

=

m

1

1
2ps

2
2

2)2
m
(x2−
2s 2
2

,

e−

(4)

q

1 = m

1 = m

1, q (2)

2 and q (2)

where q (1)
2 = s 2. The probability distribution (4) encodes
the available information concerning the system. Note that we have assumed uncoupled
constraints between the microvariables x1 and x2. In other words, we assumed that in-
formation about correlations between the microvariables need not to be tracked. This
assumption leads to the simpliﬁed product rule (4). Coupled constraints however, would
lead to a generalized product rule in (4) and to a metric tensor (7) with non-trivial off-
diagonal elements (covariance terms). Correlation terms may be ﬁctitious. They may
arise for instance from coordinate transformations. On the other hand, correlations may
arise from external ﬁelds in which the system is immersed. In such situations, correla-
tions between x1 and x2 effectively describe interaction between the microvariables and
the external ﬁelds. Such generalizations would require more delicate analysis.

3. THE METRIC STRUCTURE OF Ms

We cannot determine the evolution of microstates of the system since the available
information is insufﬁcient. Not only is the information available insufﬁcient but we
also do not know the equation of motion. In fact there is no standard "equation of
motion". Instead we can ask: how close are the two total distributions with parameters
(m
2, s 2 + ds 2)? Once the states of the system have
been deﬁned, the next step concerns the problem of quantifying the notion of change
to the state ~q + d~q . A convenient measure of change is distance. The
from the state ~q
measure we seek is given by the dimensionless "distance" ds between p(tot)
and

2, s 2) and (m

1 + dm

2 + dm

1, m

1, m

p(tot)

~q + d~q
~x
|

(cid:16)

(cid:17)

[4] :

where

ds2 = gi jdq

idq

j,

gi j =

d~xp(tot)

Z

~q
~x
|

(cid:16)

(cid:17)

¶ log p(tot)

¶ log p(tot)

~q
~x
|

~x

~q
|

¶q

i

(cid:16)

(cid:17)

¶q

j

(cid:16)

(cid:17)

~q
~x
|

(cid:16)

(cid:17)

(5)

(6)

¥
is the Fisher-Rao metric [6, 7]. Substituting (4) into (6), the metric gi j on Ms becomes,

From (7), the "length" element (5) reads,

1
m 2
1
0

0

0
1
s 2
2
0

0

0
2
s 2
2

gi j = 







.





2
s 2
2

ds2 =

dm 2

1 +

dm 2

2 +

ds 2
2.

1
m 2
1

1
s 2
2

We bring attention to the fact that the metric structure of Ms is an emergent (not funda-
mental) structure. It arises only after assigning a probability distribution p(tot)
to
each state ~q .

~q
~x
|

(cid:16)

(cid:17)

3.1. The Statistical Curvature of Ms

We study the curvature of Ms. This is achieved via application of differential geome-
try methods to the space of probability distributions. As we are interested speciﬁcally in
the curvature properties of Ms, recall the deﬁnition of the Ricci scalar R,

R = gi jRi j,

where gikgk j = d
by,

i
j so that gi j =

1
−

gi j

= diag(m 2

1,s 2
2,

s 2
2 ). The Ricci tensor Ri j is given
2

Ri j = ¶ kG k

(cid:0)

¶

(cid:1)
i j −

jG k

ik + G k
i j

G n
kn −

G m
ik

G k

jm.

The Christoffel symbols G k
way,

i j appearing in the Ricci tensor are deﬁned in the standard

1
2

−

G k

i j =

gkm

¶ igm j + ¶

jgim

¶ mgi j

.

Using (7) and the deﬁnitions given above, the non-vanishing Christoffel symbols are
23 = G 2
G 1

. The Ricci scalar becomes

32 =

11 =

, G 3

, G 3

33 =

22 = 1
2s 2

1
s 2

1
s 2

m

(cid:0)
and G 2

(cid:1)

1
1

−

−
From (12) we conclude that Ms is a 3D curved manifold of constant negative (R =
curvature.

R =

1 < 0.

−

−

(7)

(8)

(9)

(10)

(11)

(12)

1)

−

4. CANONICAL FORMALISM FOR THE RED MODEL

We remark that RED can be derived from a standard principle of least action
(Maupertuis- Euler-Lagrange-Jacobi-type) [1, 8]. The main differences are that the
dynamics being considered here, namely Entropic Dynamics, is deﬁned on a space of
probability distributions Ms, not on an ordinary vectorial space V and the standard
coordinates q j of the system are replaced by statistical macrovariables q

j.

Given the initial macrostate and that the system evolves to a ﬁnal macrostate, we
investigate the expected trajectory of the system on Ms. It is known [8] that the classical
dynamics of a particle can be derived from the principle of least action in the form,

d JJacobi [q] = d

dsF

q j,

, s, H

= 0,

(13)

s f

si

Z

dq j
ds

(cid:18)

(cid:19)

where q j are the coordinates of the system, s is an arbitrary (unphysical) parameter
along the trajectory. The functional F does not encode any information about the time
dependence and it is deﬁned by,

dq j
ds

F

q j,

(cid:18)

, s, H

[2 (H

≡

(cid:19)

1
2

U )]

−

a jk

dq j
ds

dqk
ds !

 

j,k

1
2

,

where the energy of the particle is given by

H

E = T +U (q) =

a jk (q) ˙q j ˙qk +U (q) .

≡

1
2

j,k

The coefﬁcients a jk (q) are the reduced mass matrix coefﬁcients and ˙q = dq
ds . We now
seek the expected trajectory of the system assuming it evolves from the given ini-
m
1 (si) , m
tial state q
≡
, m
m
s f
. It can be shown that the system moves along a geodesic in
the space of states [1]. Since the trajectory of the system is a geodesic, the RED-action
(cid:0)
(cid:1)
is itself the length:

2 (si) , s 2 (si)) to a new state q

m
old = q
s f
2

m
new = q

+ dq

, s 2

≡
s f

(cid:1)(cid:1)

(m

(cid:1)

(cid:0)

(cid:0)

(cid:0)

1

m

m

JRED [q ] =

ds

gi j

s f

dq

dq

i (s)
ds

j (s)
ds

1
2

where ˙q = dq

≡ Z
si
ds and L (q , ˙q ) is the Lagrangian of the system,

si
Z

(cid:19)

(cid:18)

s f

dsL

q , ˙q

(cid:0)

(cid:1)

L (q , ˙q ) = (gi j ˙q

i ˙q

j

1
2 .

)

The evolution of the system can be deduced from a variational principle of the Jacobi
type. A convenient choice for the afﬁne parameter s is one satisfying the condition
dq
dt = 1. Therefore we formally identify s with the temporal evolution parameter
gi j
t . Performing a standard calculus of variations, we obtain,

dq
dt

i

j

d JRED [q ] =

dt

Z

(cid:18)

¶ gi j
¶q
k

1
2

˙q

i ˙q

j

d ˙q k
dt

−

dq

k = 0,

k.

dq
∀

(cid:19)

(14)

(15)

(16)

(17)

(18)

(cid:229)
(cid:229)
¶ gi j
¶q
k

dt = 1
2

Note that from (18), d ˙q k
. This "equation of motion" is interesting because
k = 0 for a particular k then the corresponding ˙q k is conserved. This
it shows that if
suggests to interpret ˙q k as momenta. Equations (18) and (11) lead to the geodesic
equations,

¶ gi j
¶q

i ˙q

˙q

j

d2q k(t )
dt 2 + G k

i(t )
dt
Observe that (19) are second order equations. These equations describe a dynamics
that is reversible and they give the trajectory between an initial and ﬁnal position. The
trajectory can be equally well traversed in both directions.

j(t )
dt

= 0.

(19)

dq

dq

i j

4.1. Geodesics on Ms

We seek the explicit form of (19) for the statistical coordinates (m

2, s 2)
Ms : ~q satisﬁes (19)
parametrizing the submanifold ms of Ms, ms =
.
Substituting the explicit expression of the connection coefﬁcients found in subsection
o
(2.3) into (19), the geodesic equations become,

p(tot)

1, m

~q
|

n

∈

(cid:17)

(cid:16)

~x

This is a set of coupled ordinary differential equations, whose solutions have been
obtained by use of mathematics software (Maple) and analytical manipulation:

1

d2m
dt 2 −

1
1

m

dm
dt

1

2

= 0, d2m

2

dt 2 −

dm
dt

2

ds 2
dt = 0,

2
s 2

(cid:16)

d2s 2
dt 2 −

1
s 2

(cid:17)
ds 2
dt

2

+ 1
2s 2

dm
dt

2

2

= 0.

(cid:16)

(cid:17)

(cid:16)

(cid:17)

m

1 (t ) = A1 (cosh (a 1t )

sinh (a 1t )) ,

−

m

2 (t ) =

A2
2
2a 2

cosh (2a 2t )

−

1
sinh (2a 2t ) +

A2
2
8a 2
2

+ B2,

s 2 (t ) = A2

cosh (a 2t )

cosh (2a 2t )

−

sinh (a 2t )
−
sinh (2a 2t ) +

.

A2
2
8a 2
2

(20)

(21)

j

1
2

j ˙q

= 1). The coupling between the parameters m

The quantities A1, A2, B2, a 1 and a 2 are the ﬁve integration constants (5 = 6
˙q

1,
2 and s 2 is reﬂected by the
fact that their respective evolution equations in (21) are deﬁned in terms of the same
(cid:16)
integration constants A2 and a 2. Equations (21) parametrize the evolution surface of the
Ms. By eliminating the parameter t , s 2 can be expressed
statistical submanifold ms

−

(cid:17)

⊂

FIGURE 1. The Statistical Submanifold Evolution Surface

explicitly as a function of m

1 and m

2,

s 2 (m

1, m

2) =

a
a

2
1

1 (m

m

2a 2

a
a

2
1

A

1 A2

B2) .

2 −

(22)

This equation describes the submanifold evolution surface. To give a qualitative sense of
this surface, we plot (22) in Figure 1 for a special choice of a 1d set of initial conditions
(a 2 = 2a 1 while A1, A2 and B2 are arbitrary). Equations (20) are used to evolve this
1d line to generate the 2d surface of ms. This ﬁgure is indicative of the instability of
geodesics under small perturbations of initial conditions.

5. ABOUT THE STABILITY OF GEODESICS ON Ms

We brieﬂy investigate the stability of the trajectories of the RED model considered on
Ms. It is known [8] that the Riemannian curvature of a manifold is closely connected
with the behavior of the geodesics on it. If the Riemannian curvature of a manifold is
negative, geodesics (initially parallel) rapidly diverge from one another. For the sake of
simplicity, we assume very special initial conditions: a = a 1 = a 2
1; A1 and
B2 are arbitrary. However, the conclusion we reach can be generalized to more arbitrary
initial conditions. Recall that Ms is the space of probability distributions p(tot)
labeled by parameters m
p(tot), and in these coordinates a volume element dVMs reads,

2, s 2. These parameters are the coordinates for the point
(cid:17)

4, A2
8a 2

1, m

2 ≪

~q
|

≪

(cid:16)

~x

1

dVMs = g

1
2

~q

d3~q

√gdm

1dm

2ds 2

≡

(cid:16)

(cid:17)

(23)

where g =
of Ms is,

|

det

gi j

= 2
m 2
1

s 4
2

|

(cid:0)

(cid:1)

. Hence, using (23), the volume of an extended region D VMs

D VMs (t ; a ) = VMs (t )

VMs (0) =

−

√gdm

1dm

2ds 2.

(24)

m

1(t )

m

2(t )

s 2(t )

Zm

1(0)

Zm

2(0)

Zs 2(0)

Finally, using (21) in (24), the temporal evolution of the volume D VMs becomes,

D VMs (t ; a ) =

A2t
√2

at
e

.

Equation (25) shows that volumes D VMs (t ; a ) increase exponentially with t . Con-
sider the one-parameter (a ) family of statistical volume elements FVMs (a )
≡
a 1 =
D VMs (t ; a )
> 0. The stability of the geodesics
{
of the RED model may be studied from the behavior of the ratio rVMs
of neighboring
) and D VMs (t ; a ),
volumes D VMs (t ; a + da

a . Note that a

dm
dt

t =0

1
1

≡

−

(cid:16)

(cid:17)

}

1

m

rVMs

def
=

D VMs (t ; a + da
D VMs (t ; a )

)

.

is considered. The quantity rVMs
for volume elements with parameters a and a + da

describes the relative volume changes in
. Substituting (25) in (26), we

Positive da
t
obtain

Equation (27) shows that the relative volume change ratio diverges exponentially un-
der small perturbations of the initial conditions. Another useful quantity that encodes
relevant information about the stability of neighbouring volume elements might be the
entropy-like quantity S deﬁned as,

da
rVMs = e

t

·

.

S

def
= logVMs

where VMs is the average statistical volume element deﬁned as,

VMs ≡ h

D VMsi

t

def
=

1
t

t

Z0

D VMs

t ′; a

dt ′.

(cid:0)

(cid:1)

Indeed, substituting (25) in (29), the asymptotic limit of (28) becomes,

S

at

.

≈
Doesn’t equation (30) resemble the Zurek-Paz chaos criterion [9, 10] of linear entropy
increase under stochastic perturbations? This question and a detailed investigation of
the instability of neighbouring geodesics on different curved statistical manifolds are

(25)

(26)

(27)

(28)

(29)

(30)

addressed in [12] by studying the temporal behaviour of the Jacobi ﬁeld intensity [11] on
such manifolds.

Our considerations suggest that suitable RED models may be constructed to describe
chaotic dynamical systems and, furthermore, that a more careful analysis may lead to
the clariﬁcation of the role of curvature in inferent methods for physics [12, 13].

6. FINAL REMARKS

A RED model is considered. The space of microstates is 2D while all information nec-
essary to study the dynamical evolution of such a system is contained in a 3D space of
macrostates Ms. It was shown that Ms possess the geometry of a curved manifold of
constant negative curvature (R =
1). The geodesics of the RED model are hyperbolic
curves on the submanifold ms of Ms. Furthermore, considerations of statistical volume
elements suggest that these entropic dynamical models might be useful to mimic ex-
ponentially unstable systems. Provided the correct variables describing the true degrees
of freedom of a system be identiﬁed, ED may lead to insights into the foundations of
models of physics.
Acknowledgements: The authors are grateful to Prof. Ariel Caticha for very useful
comments.

−

REFERENCES

1. A. Caticha, "Entropic Dynamics", Bayesian Inference and Maximum Entropy Methods in Science

and Engineering, ed. by R.L. Fry, AIP Conf. Proc. 617, 302 (2002).

2. A. Caticha, "Relative Entropy and Inductive Inference", Bayesian Inference and Maximum Entropy
Methods in Science and Engineering,ed. by G. Erickson and Y. Zhai, AIP Conf. Proc. 707, 75 (2004).
3. A. Caticha and A. Gifﬁn, "Updating Probabilities", presented at MaxEnt 2006, the 26th In-
ternational Workshop on Bayesian Inference and Maximum Entropy Methods (Paris, France),
arXiv:physics/0608185; A. Caticha, "Maximum entropy and Bayesian data analysis: Entropic prior
distributions", Physical Review E 70, 046127 (2004).
S. Amari and H. Nagaoka, Methods of Information Geometry, American Mathematical Society,
Oxford University Press, 2000.

4.

5. C. Cafaro, S. A. Ali, A. Gifﬁn, "Irreversibility and Reversibility in Entropic Dynamical Models",

paper in preparation.

6. R.A. Fisher, "Theory of statistical estimation" Proc. Cambridge Philos. Soc. 122, 700 (1925).
7. C.R. Rao, "Information and accuracy attainable in the estimation of statistical parameters", Bull.

Calcutta Math. Soc. 37, 81 (1945).

8. V.I. Arnold, Mathematical Methods of Classical Physics, Springer-Verlag, 1989.
9. W. H. Zurek and J. P. Paz, "Decoherence, Chaos, and the Second Law", Phys. Rev. Lett. 72, 2508

10. C. M. Caves and R. Schack, "Unpredictability, Information, and Chaos", Complexity 3, 46-57 (1997).
11. F. De Felice and C. J. S. Clarke, Relativity on Curved Manifolds, Cambridge University Press (1990).
12. C. Cafaro, S. A. Ali, "Entropic Dynamical Randomness on Curved Statistical Manifolds", paper in

(1994).

preparation.

13. B. Efron, "Deﬁning the curvature of a statistical problem", Annals of Statistics 3, 1189 (1975).

