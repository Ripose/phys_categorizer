Parametric instability of linear oscillators with colored time-dependent noise

F.M.Izrailev 1, V. Dossetti-Romero 1, A.A.Krokhin1,2, and L.Tessieri 3
1 Instituto de F´ısica, Universidad Aut´onoma de Puebla, Apdo. Postal J-48, Puebla, Pue. 72570, M´exico
2 Center for Nonlinear Science, University of North Texas, P.O. Box 311427, Denton, Texas 76203-1427, USA
3 Instituto de F´isica y Matem´aticas, Universidad Michoacana de San Nicol´as de Hidalgo,
Ciudad Universitaria, 58060 Morelia, Mich. M´exico
(February 2, 2008)

The goal of this paper is to discuss the link between the quantum phenomenon of Anderson local-
ization on the one hand, and the parametric instability of classical linear oscillators with stochastic
frequency on the other. We show that these two problems are closely related to each other. On the
base of analytical and numerical results we predict under which conditions colored parametric noise
suppresses the instability of linear oscillators.

I. INTRODUCTION

Let us consider the one-dimensional (1D) model described by the Schr¨odinger equation

¯h2
2m

−

′′

ψ

(x) + U (x)ψ(x) = Eψ(x).

(1)

−

Here the ψ
function is a stationary solution for a particle of energy E moving in a random potential U (x). To simplify
the form of the analytical expressions, in what follows we use energy units such that ¯h2/2m = 1, and we set the zero
= 0. Here the angular brackets
of the energy scale so that the mean value of the disordered potential is zero,
denote the average over the disorder (i.e., over diﬀerent realizations of U (x)). We restrict our considerations to
...
h
i
U 2(x)
the case of weak disorder, deﬁned by the condition ε2 =
In the analysis of the model (1) one of the main questions is about global structure of the eigenstates ψ(x) in
. Of a particular interest is the problem of whether the eigenstates
an inﬁnite conﬁguration space,
are localized or extended for x
. As was shown in Ref. [1], in 1D models any amount of disorder (even an
inﬁnitesimal one) results in the localization of all eigenstates (with the exception of a zero-measure set) provided that
the potential U (x) is completely random. This means that the amplitude of every eigenstate decays exponentially
towards inﬁnity, therefore, far away from the localization center x0, one can write,

−∞
→ ±∞

U (x)
i

< x < +

≪

∞

1.

(cid:10)

(cid:11)

h

ψ(x)
|

exp (

x

x0

/l (E)) .

− |
Here l (E) is the so-called localization length that characterizes, in average, the decrease of the amplitude of the
eigenstate corresponding to the energy E. Analytical expression of l (E) that is relatively easy to obtain for a weak
disorder, for which it is known that the localization length is inversely proportional to the square of the disorder
strength, l

1/ε2, see below.

Taking into account that the energy of a free electron is E = k2 , the equation (1) can be written in the form of

| ∼

−

∼

|

wave equation,

that describes wave propagation in diﬀerent classical systems. One example is the propagation of electromagnetic
waves in single-mode waveguides with a rough surface [2]. In this application the potential U (x) is determined by the
horizontal proﬁle ξ(x) = εϕ(x/Rc), where Rc is the correlation length of the proﬁle, ε
d is the amplitude of the
proﬁle with d being the transverse size of the waveguide. Note that in this case the parameter k in Eq.(2) has the
meaning of the longitudinal wave number k =

(π/d)2 where ω is the frequency of the wave.

(ω/c)2

≪

4
0
0
2
 
r
a

M
 
4
 
 
]
h
p
-
s
s
a
l
c
.
s
c
i
s
y
h
p
[
 
 
1
v
5
3
0
3
0
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

When the potential is constituted by a succession of delta scatterers, the model (2) takes the speciﬁc form

′′

ψ

(x) + k2ψ(x) = U (x)ψ(x)

−

p

II. DISCRETE MODELS

′′

ψ

(x) + k2ψ(x) =

Unψ(xn)δ(x

xn).

−

n=∞

n=−∞
X

1

(2)

(3)

Here Un is the amplitude of the nth delta-scatterer situated at x = xn. In experiments, potentials of this kind are quite
easy to construct; in particular, one can obtain a realization of delta scatterers by inserting an array of screws with
predetermined lengths and appropriate positions in a single-mode waveguide [3]. Typically, one considers two limit
cases. The ﬁrst one occurs when all amplitudes Un are random variables, while the scatterers are periodically spaced,
i.e., xn = an . In this case one can speak of amplitude disorder. The second case is represented by the opposite
situation in which the amplitudes of the scatterers are constant, Un = U0 while the positions xn are randomly
a2 . Clearly, in the latter case
distributed around their mean values, i.e., xn = an + ηn with
the mean value of the potential is not zero; however one can handle this case within the framework of zero-mean
potentials by making use of the special transformation to new variables, see details in Ref [4]. This second limit case
can be referred to as positional disorder.

= 0 and

ηni

η2
n

≪

(cid:11)

(cid:10)

h

Due to the delta-like form of a random potential, the model (3) can be considered as a discrete one.

In fact,
its analysis can be reduced to the study of an equivalent classical two-dimensional map which can be obtained by
integrating Eq. (3) between two successive kicks of the scattering potential [4],

qn sin µn,
pn+1 = (pn + An qn) cos µn −
qn+1 = (pn + An qn) sin µn + qn cos µn .

Here qn and pn are conjugate coordinates and momenta deﬁned by the identities

qn = ψnandpn = (ψn cos µn−1

ψn−1)/ sin µn−1

−

where ψn is the value of the ψ
between two scatters,

−

function at the position x = xn. The parameter µn is the phase shift of the ψ

function

−

and the amplitude An of the nth kick is given by the the value of the potential at the position xn,

µn = k(xn+1

xn)

−

An = Un/k.

Free rotation in (4) between two successive kicks corresponds to free propagation between scatterers, and each kick is
due to the scattering from a δ spike of the potential.

In the case of amplitude disorder, the phase shift between two successive scatterers is the same, µn = µ = ka, and
the model (3) is known as the Kronig-Penney model. In this case the two-dimensional map (4) is equivalent to the
following relation between ψn+1, ψn−1 and ψn,

One can see that the relation (7) has the same form as discrete Schr¨odinger equation for the standard 1D Anderson
tight-binding model,

ψn+1 + ψn−1 =

2 cos µ +

sin µ

ψn,

(cid:18)

(cid:19)

Un
k

ψn+1 + ψn−1 = (E + ǫn) ψn,

(4)

(5)

(6)

(7)

(8)

and describes electrons on a discrete lattice with the site energies ǫn. Therefore, many of the results for the Kronig-
Penney model can be obtained by a formal comparison with the Anderson model, as discussed below.

III. THE HAMILTONIAN MAP APPROACH

One of the tools to ﬁnd the localization length for discrete disordered models, either analytically or numerically, is
based on the transfer matrix method. In this approach the localization length can be expressed as the inverse of the
Lyapunov exponent λ which characterizes the growth of the eigenstates ψ(x) of the stationary Schr¨odinger equation
for increasing x. An alternative approach can be obtained by interpreting the stationary Schr¨odinger equation as the
equation of motion of a classical particle (in this scheme the space coordinate x of the disordered model is to be seen
as the time coordinate for its dynamical counterpart). In particular, in the case of discrete disordered models, this
approach leads to the study of classical maps.

It is instructive to illustrate this approach by discussing its application to the simplest case of the Anderson model
(8). Comparing Eq. (8) with Eq. (4), one can obtain that there is an exact correspondence between them by letting
µn = µ and

2

(9)

(10)

(11)

(12)

(13)

E = 2 cos µ; An =

ǫn/ sin µ.

−

It is clear that for weak disorder the energy spectrum of the Anderson model (8) is close to the unperturbed one
which is deﬁned by the condition

2; this legitimates the ﬁrst equality in Eq. (9).

To analyze the dynamics of the two-dimensional map (4), it is convenient to introduce the action-angle variables
(rn, θn) according to the standard transformation, q = r sin θ, p = r cos θ. As a result, the map gets the following
form,

E
|

| ≤

where

sin θn+1 = D−1
cos θn+1 = D−1

n (sin(θn −
n (cos(θn −

An sin θn sin µ)

µ)
µ) + An sin θn cos µ) ,

−

Dn =

rn+1
rn

q

=

1 + An sin(2θn) + A2

nsin2θn .

cot(θn+1 + µ) = cot θn + An.

Note that the following results for the localization length do not depend on the sign of µ. It is important that the
equation for the angle θn can be written in the form of the one-dimensional map,

This fact simpliﬁes the analysis of the distribution of θn. The localization length l is deﬁned as the inverse Lyapunov
exponent, and the latter is determined by the standard relation [5]

−1 = λ = lim

l

N→∞h

1
N

N −1

n=0
X

ln

qn+1
qn (cid:12)
i
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

ln
h

.

i

qn+1
qn (cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Here the overbar stays for time average and the brackets for the average over diﬀerent disorder realizations. The
expression for l−1 can be splitted in two terms

−1 =

l

ln
h

rn+1
rn (cid:19)
i

(cid:18)

+

ln
h

.

i

sin θn+1
sin θn (cid:12)
(cid:12)
(cid:12)
(cid:12)
2 or µ

(cid:12)
(cid:12)
(cid:12)
(cid:12)
E
|

is negligible because it is the average of a bounded quantity. It becomes important
The second term on the r.h.s.
0. Thus, apart from this speciﬁc case,
only when the ﬁrst term is also small, i.e. at the band edge
the localization length can be evaluated from the map (10) using only the dependence of the radius rn on discrete
time tn = n. It is important to note that the ratio rn+1/rn depends only on the angle θn and not on the radius rn;
as a consequence, one can compute the localization length just by averaging the ﬁrst term in (12) over the invariant
measure ρ(θ) associated with the 1D angular map (11).
In a direct analytical evaluation of (12) one can write,

| ≈

≈

−1 =

l

P (ǫ)

ln(D(ǫ, θ)) ρ(θ) dθdǫ ,

2π

Z

0
Z

where P (ǫ) is the density of the distribution of ǫn, and ρ(θ) is the invariant measure for the angle variable. We
use here the fact that ρ(θ) does not depend on the speciﬁc sequence ǫn, but can depend on the moments of P (ǫ),
particularly on its second moment σ2 (see discussion in [6]). As one can see, in order to evaluate the expression (13),
ﬁrst one has to determine the invariant measure ρ(θ).

In the case of weak disorder and not close to the band edges we have

1 and one can use the standard

perturbation theory. This allows one to cast Eq. (13) in the form

−1 =

l

1
2 sin 2µ

ǫ2P (ǫ) dǫ

ρ(θ)

Z

Z0

(cid:18)

1
4 −

1
2

2π

cos(2θ) +

cos(4θ)

dθ .

(14)

This expression is valid for all energies within the band, but fails at the band edges, where one must include the
contribution of the second term of Eq. (12) in the computation of the inverse localization length (see Ref. [6]). One
can also see from Eq. (11) that in the limit of weak disorder the map for θn has the approximate form,

θn+1 = θn −

µ

−

An sin 2θn + A2

n sin 3θn cos θn

mod 2π

.

}

{

(15)

An| ≪
|

1
4

(cid:19)

3

Therefore, in the ﬁrst approximation the invariant measure for θn is ﬂat and this makes possible an explicit evaluation
of the expression (14). Thus, one easily obtains

−1 =

l

σ2
8 sin2 µ

=

σ2

E2
4

−

8

1

q

(cid:10)

(cid:11)

ǫ2
n

where σ2 =
is the variance of the disorder. It is interesting to note that the expression (16) is not correct at the
band center, i.e., for E = 0 (see discussion and references in Ref [6]). The reason is that for this energy the standard
perturbation theory fails and one must use speciﬁc methods to obtain the correct expression of l−1. As was found,
the anomaly at the band center originates from the fact that for E = 0 the density ρ(θ) is not ﬂat, instead, it has a
slight modulation with θ. This additional θ-dependence of the invariant measure is due to the special circumstance
that the case E = 0 corresponds to µ = π/2 so that the map (15) becomes approximatively periodic of period four.
As a consequence, ρ(θ) has a weak modulation of period π/2 and, therefore, the fourth harmonic cos(4θ) in the
expression (14) also gives a contribution.

Due to the analogy between the Anderson model (8) (A-model) and the Kronig-Penney model (3) (KP-model) with

µn = µ, one can derive from the result (16) the expression for the localization length of the KP-model

Here the phase γ ( 0

γ

π) is given by the equation,

≤

≤

−1(E) =

l

ε2
0
8k2

sin2(ka)
sin2 γ

.

2 cos(ka) +

sin(ka) = 2 cos γ.

ε
k

This equation is the well-known dispersion relation for the periodic Kronig-Penney model; the parameter γ plays the
role of the Bloch number.

IV. ANDERSON LOCALIZATION AND PARAMETRIC INSTABILITY

It is easy to see that the Schr¨odinger equation (3) for the quantum 1D disordered model can be interpreted as
the dynamical equation of a linear classical oscillator with a parametric perturbation constituted by a succession
of delta-kicks at times tn = xn. In particular, the map (4) corresponding to the Kronig-Penney model (µn = µ)
can be obtained by integrating the dynamical equations between two successive kicks for a stochastic oscillator with
Hamiltonian of the form

H = ω

q2
2

+

p2
2

+

q2
2  

(cid:19)

(cid:18)

∞

n=−∞
X

Anδ(t

nT )

.

−

!

Therefore, qn and pn in Eq. (4) stand for the position and momentum of the oscillator immediately before the nth
kick of amplitude An occurring at the time t = nT . Correspondingly, the phase shift between two successive kicks is
given by µ = ωT where ω is the unperturbed frequency of the oscillator and T is the period between the kicks.

In this description the exponential localization of the eigenstates of Eq. (3) corresponds to a parametric instability
of the stochastic oscillator (17). The instability manifests itself as an exponential divergence of initially nearby orbits
(orbit instability) and, correspondingly, as an exponential growth of the average energy of the parametric oscillator
(energy instability). The Lyapunov exponent λ, which gives the inverse localization length in the solid-state the
divergence of classical trajectories (or, the rate of the energy growth).

In the previous section we have considered the case of a weak uncorrelated disorder which is characterized by
its variance σ2 only. In application to classical oscillators this corresponds to a white noise perturbation.
In the
following, we consider the general case of colored noise and show that noise correlations can lead to a quite unexpected
phenomenon. To discuss the eﬀects of correlated noise in parametric oscillators, we apply the approach of Ref. [7] to
the continuous model described by the Hamiltonian,

(16)

(17)

(18)

where ξ(t) is a continuous and stationary noise. This model is slightly diﬀerent from the one deﬁned by Eq. (17)
because the noise ξ(t) is a continuous function of time rather than a succession of δ-kicks. We assume that the noise
ξ(t) has zero average and that its binary correlator is a known function,

H = ω

q2
2

+

p2
2

(cid:18)

(cid:19)

+

ξ(t)

q2
2

4

ξ(t)
i
h
in contrast to previous sections the symbol

ξ(t)ξ(t + τ )
i
h

= 0 and

= χ(τ ).

. . .
i
h

T0
0 f (t)dt, which is assumed to coincide with the ensemble average for the process ξ(t).

will refer to the time average,

Here and below,
limT0→∞

1
T0

R

We deﬁne the Lyapunov exponent as follows,

Z
As in the previous section, we introduce polar coordinates via the standard relations q = r sin θ, p = r cos θ. This
allows us to represent Eq. (20) in the form

λ = lim

T0→∞

lim
δ→0

1
T0

1
δ

T0

0

ln

q(t + δ)
q(t)

dt.

(19)

f (t)
i
h

=

(20)

To proceed further, we consider the equations for the random oscillator in polar coordinates

λ = lim

T0→∞

T0

˙r
r

dt.

1
T0

0
Z

˙θ = ω + ξ(t) sin2 θ,

˙r =

rξ(t) sin 2θ.

1
2

−

Using the last equation, the expression for the Lyapunov exponent can be ﬁnally written in the form

λ = lim

T0→∞

T0

1
2T0

0
Z

ξ(t) sin (2θ(t)) dt =

ξ(t) sin (2θ(t))

.
i

1
2 h

Therefore, the problem of computing the Lyapunov exponent (20) is reduced to that of calculating the noise-angle
correlator that appears in Eq. (21). This was done in Ref. [7] by extending the procedure, originally introduced in
Ref. [8] for discrete models, to the continuum case. As a result, the expression for the Lyapunov exponent takes the
simple but non-trivial form,

One can see that the Lyapunov exponent for the stochastic oscillator (18) is proportional to the Fourier transform
˜χ(2ω) of the correlation function at twice the frequency of the unperturbed oscillator.

A similar result can be obtained for the parametric oscillator (17) with discrete noise.

In this case the inverse

localization length can be written as [8]

(21)

(22)

(23)

λ =

−∞ h

ξ(t)ξ(t + τ )
i

cos(2ωτ ) dτ .

+∞

1
8

Z

λ = h

ϕ (ωT ) .

A2
ni
8T

ϕ (ωT ) = 1 + 2

ζ(k) cos (2ωT k)

Here the function ϕ (ωT ) is the Fourier transform,

of the binary correlator

An+kAni
A2
ni
h
of the colored noise. Therefore, the ﬁnal expression is given by the product of two factors, namely, the Lyapunov
exponent for the white noise case and the function ϕ(ωT ), which describes the eﬀect of the noise correlations (the
color). In the case of white noise we have ϕ(ωT ) = 1.

ζ(k) = h

(24)

+∞

Xk=1

5

V. SUPPRESSION OF THE PARAMETRIC INSTABILITY

Expressions (22) and (23) of the Lyapunov exponent for stochastic oscillators with weak frequency noise give a
remarkable result: within the limits of the second-order approximation the rate of parametric instability depends
only on the binary correlator of the noise.
In application to solid state models this fact has suggested a way to
construct random potentials with speciﬁc spatial correlations that result in “windows of transparency” in the energy
spectrum. Indeed, if the Lyapunov exponent vanishes within some range of the energy (or, the wave number k), then
the corresponding eigenstates are extended in that energy interval. When one considers ﬁnite samples, this means
that the transmission coeﬃcient has to be one in the energy windows where the Lyapunov exponent vanishes.

The possibility of engineering random potentials in order to obtain Lyapunov exponents with predeﬁned energy
dependence can be deduced from the expression (22) for continuous model, or from Eq. (23) for the discrete one. Both
expressions show that if the Lyapunov exponent is known, the two-point correlator of the corresponding noise can be
computed with an inverse Fourier transform. Since a stochastic process is not completely determined by its two-point
correlator, one can conclude that there is actually an inﬁnite set of noises which give rise to the same Lyapunov
exponent because they have an identical binary correlator.

As one can see, in order to have suppression of the parametric instability in classical oscillators with colored noise,
one needs to have λ(ω) = 0 in some range of ω. Although at ﬁrst sight the construction of a random potential An or
ξ(t) with a given binary correlator seems a diﬃcult task, a rather simple method to solve this problem was presented
in Ref. [8] for discrete models. This method was subsequently extended to oscillators with continuous noise. Here we
describe how the method works for both classes of oscillators. Let us consider the continuous model (18) ﬁrst. The
starting point is the correlation function χ(τ ) that can be easily obtained by inverting formula (22),

Once the correlation function χ(τ ) is known, we can obtain a stochastic process ξ(t) satisfying the conditions (19) by
means of the convolution product,

where the function β(t) is related to the Fourier transform ˜χ(ω) of the noise correlation function through the formula

with η(t) as any stochastic process such that

Formula (25) deﬁnes the family of noises corresponding to a speciﬁc form λ(ω) of the frequency-dependent Lyapunov
exponent and gives the solution of the “inverse problem” (i.e., determination of a noise ξ(t) that generates a pre-deﬁned
Lyapunov exponent).

As an example, we consider the Lyapunov exponent

whose frequency dependence implies that the random oscillator undergoes a sharp transition for
= 1/2, passing
from an energetically stable condition to an unstable one. Following the described procedure, it is easy to see that
the Lyapunov exponent (27) is generated by a noise of the form

ω
|

|

χ(τ ) =

λ(ω)e2iωτ dω.

8
π

∞

−∞

Z

ξ(t) = (β

η) (t) =

β(s)η(s + t) ds,

∗

+∞

−∞

Z

β(t) =

+∞

−∞

Z

p

˜χ(ω)eiωt dω
2π

,

η(t)
i
h

= 0 and

η(t)η(t′)
i
h

= δ(t

t′).

−

λ(ω) =

(cid:26)

1 if
0

< 1/2

ω
|

|
otherwise

,

ξ(t) =

η(s + t) ds,

√8
π

+∞

−∞

Z

sin(s)
s

6

with η(t) being any random process with the statistical properties (26). Working along these lines, it is easy to see
that one can also construct the frequency noises such that the parametric oscillator is stable for all values of ω except
those contained in a narrow frequency window.

(25)

(26)

(27)

We now turn our attention to discrete models of the form (17). To show how the expression that is equivalent to
Eq. (25) can be worked out for this class of systems, we refer to the case of the Anderson model (8) with correlated
disorder. Since this model can be put into one-to-one correspondence with the kicked oscillator (17), it is perfectly
legitimate to analyse each of the two models in terms of the other; this approach has also the advantage of enhancing
the physical understanding of the problem because it allows one to interpret the parametric instability of a stochastic
oscillator in terms of localization of electronic states for the Anderson model.

When we transpose the result (23) to the case of the Anderson model (8), we obtain that the expression for the

localization length has the form,

Xk=1
Here ζ(k) is the binary correlator (24) which can be written in terms of the site energies ǫn of the Anderson model as
ζ(k) =

If the Lyapunov exponent (28) (therefore, the function ϕ(µ)) is known, the binary correlators (24) can be derived

/
ǫnǫn+ki
h

ǫ2
.
ni
h

with an inverse Fourier transform,

As for the continuous model, the sequence of site energies ǫn with the correlator of the speciﬁc form (29) can then be
constructed with the convolution product,

−1 =

l

ǫ2
n
8 sin2 µ
(cid:11)
(cid:10)

ϕ(µ),

∞

ϕ(µ) = 1 + 2

ζ(k) cos(2µk).

ζ(k) =

ϕ(µ) cos(2µk) dµ.

π/2

2
π

0

Z

∞

ǫn =

ǫ2
ni
h
p

Xk=−∞

βkZn+k,

βk =

ϕ(µ) cos(2µk) dµ

π/2

2
π

0
Z

p

where

where

(28)

(29)

(30)

and Zn are random numbers with the zero mean and unitary variance. It is easy to check that the correlators of the
site potential (30) coincide with the Fourier coeﬃcients (29).

As an illustration of the method, we construct the random potential which results in the following function ϕ(µ)

for the Lyapunov exponent of the discrete Anderson model,

ϕ(µ) =

C2
0
0

(cid:26)

if µ1 < µ < µ2,
if 0 < µ < µ1 or µ2 < µ < π/2.

0 = π/2(µ2

Here, C2
µ1) is the normalization constant that results from the condition ζ0 = 1. The corresponding
localization length exhibits two sharp mobility edges at the values E1 = 2 cos µ1 and E2 = 2 cos µ2. Speciﬁcally, in the
energy window E1 < E < E2 the eigenstates are strongly localized, while they are extended outside of this window.
The binary correlators ζ(k) for a random potential resulting in such a situation, are given by

−

ζ(k) =

[sin(2kµ2)

sin(2kµ1)] .

As a result, the expression for the inverse localization length reads

where σ2 =

ǫ2
n

. If the energy window ∆E = E1

(cid:1)(cid:3)
(cid:1)
E2 is narrow, one can write,

(cid:0)

(cid:0)

(cid:2)

λ = l

−1 =

16 sin2 µ

acos

acos

E1
2

−

(cid:10)

(cid:11)

C2
0
πk

−

−

π σ2
E2
2

7

arccos

arccos

E2
2

(cid:18)

−

(cid:19)

E1
2

(cid:18)

≈

(cid:19)

∆E .

One can see that the narrower the window ∆E, the sharper the transition which occurs at the mobility edges. This
eﬀect can be easily observed numerically, and it may have interesting applications for parametric oscillators. Indeed,
small localization lengths correspond to large values of the Lyapunov exponent. Therefore, for values of the frequency
of the kicked oscillator (17) which correspond to energy values within the localization window in the related Anderson
model, the instability of the oscillator is very strong and one can speak of a kind of “parametric stochastic resonance”.

VI. DISCUSSION

In the previous section we have shown how a proper choice of colored noise (random potentials in the solid state
models) can suppress the parametric instability of a stochastic oscillator in a prescribed frequency range. One should
note, however, that the theoretical analysis has been focused on the case of weak noise and that almost all analytical
results have been obtained using perturbative approach. Therefore, the conclusion that the Lyapunov exponent can
vanish within some frequency region is valid only within the framework of second-order perturbation theory. Going
beyond the second-order approximation, it is possible to estimate the correction to the present results for the inverse
localization lenght and to show that the correction is represented by a term of order O(σ4) (with σ2 =
). It is not
clear whether one can make this fourth-order correction vanish with an appropriate choice of the statistical properties
of the noise [9]; from a practical point of view, however, in the case of weak noise there is a well-deﬁned separation
1/σ2 over which the suppression of instability holds, and the much longer time scale
between the time scale t
1/σ4 over which the eﬀects of fourth-order corrections become relevant. When the second-order results for the
t
inverse localization length are applied to wave-guides or solid state models, fourt-order eﬀects can also be generally
avoided by a proper choice of size of an experimental device [3].

ǫ2
ni
h

∼

∼

The transfer matrix method in the Hamiltonian form described above is also very useful for ﬁnite times.
In
application to solid state models this question refers to transport properties through ﬁnite samples of size L. As is
known [5,10], all transport properties can be directly related to the classical trajectories of the Hamiltonian map (4).
Speciﬁcally, by studying general properties of these trajectories, one can ﬁnd statistical properties of the transmission
coeﬃcient or the resistance. The transmission coeﬃcient through a L-site sample can be expressed in terms of
dynamical variables of the classical map (4) as

TL =

4
1 + r2
2 + r2
2

where r1 and r2 represent the radii at the Lth step of the map trajectories starting from the phase-space points
P1 = (x0 = 1, p0 = 0) and P2 = (x0 = 0, p0 = 1), respectively. As for the resistance RL, it is deﬁned as the inverse of
−1
L . The key feature of these formulae is that they express the transport properties
the transmission coeﬃcient RL = T
of a disordered sample in terms of the radii of map trajectories in the phase space. On the other hand, the square
radius r2 of a map trajectory is a quadratic function of the coordinate and momentum of the corresponding kicked
oscillator, r2 = p2 + q2, and is therefore proportional to the energy of the latter. This fact makes possible to relate
transport properties of quantum models with the time dependence of the energy of classical parametric oscillators.

It is possible to obtain quite easily the moments of the energy r2 of the parametric oscillator described by the
Hamiltonian (17), see details in Refs. [7,11]. In particular, one can obtain that in the asymptotic limit (i.e., for times
t

λ−1) the mean value of the energy grows exponentially as

≫

r2(t)
i
h

= r2(0) exp(4λt)

where λ is the Lyapunov exponent (23). This formula shows that the exponential rate of the energy growth for the
parametric oscillator is four times the Lyapunov exponent, i.e., the rate of exponential separation of nearby orbits [7].
Another important question concerns the ﬂuctuations of r2(t) for ﬁxed times t depending on diﬀerent realizations
of the noise. Using the results of Ref. [7,11], one should distinguish between two diﬀerent situations. The ﬁrst one
corresponds to small times when the value of r(t) is close to the initial value r(0). In solid state models this case is
known as the ballistic transport for which the localization length l = λ−1 is much larger than the size L = t of the
sample, λt
1, or to the strongly localized regime in quantum
models. One of the most interesting eﬀects is that in this case the ﬂuctuations of the energy of the classical oscillator
(resistance in quantum models) are huge and the quantity R = r2 is not self-averaging. To deal with a well-behaved
(that is, self-averaging) statistical property, one has to consider the logarithm of the oscillator energy, which has a
Gaussian distribution for large times. It turns out that the energy r2 has log-normal distribution:

1. Another limit case corresponds to large times, λt

≫

≪

8

This distribution implies that the energy of parametric oscillator, or the resistance R = r2 of disordered samples,
satisfy the relations

P (r2, t) =

1
√8πλt

exp

ln r2

2

2λt

−
8λt

.

(cid:1)

#

"− (cid:0)

ln R
h

i

= 2Λ;

ln2 R
h

i

= 4Λ + 4Λ2 ,

Var (ln R) =

ln2 R
h

ln R

2 = 2
i

ln R
h

.
i

i − h

where Λ = λt.

In conclusion, we have discussed the analogy between properties of quantum 1D models with random potentials and
classical linear oscillators governed by parametric noise. We have shown that many results known for quantum models
can be mapped unto corresponding properties of classical oscillators. One of the important questions is about the
time-dependence of the energy of stochastic oscillators with frequency perturbed by a white noise. Another, even more
exciting problem, is the behavior of the oscillators when the frequency noise has long-range correlations. It was shown
that in the case of weak noise all statistical properties of the classical trajectories depend on the binary correlator
of the noise only. This fact opens the door to the construction of colored noises with speciﬁc long-range correlations
which result in a sharp change in the dynamical behavior of the parametric oscillator at some threshold value of
the unperturbed frequency. Speciﬁcally, the characteristic instability of parametric oscillators can be suppressed in
a certain frequency range (with a brisk transition), thanks to long-range temporal correlations of the noise. These
results may ﬁnd diﬀerent applications in the ﬁeld of classical systems with colored noise.

The authors are very thankful to N.M.Makarov for fruitful discussions and valuable comments.

ACKNOWLEDGMENTS

[1] K. Ishii, Suppl. Progr. Theor. Phys. 53, p. 77, 1973.
[2] F. M. Izrailev and N. M. Makarov, Optics Lett. 26, p. 1604, 2001.
[3] U. Kuhl, F. M. Izrailev, A. A. Krokhin, and H.-J. St¨ockmann, Appl. Phys. Lett. 77, p. 633, 2000; A. A. Krokhin, F. M.

Izrailev, U. Kuhl, H.-J. St¨ockmann, and S. Ulloa, Physica E 13, p. 695, 2002.
[4] F. M. Izrailev, A. A. Krokhin, and S. E. Ulloa, Phys. Rev. E. 63, p. 041102, 2001.
[5] I. M. Lifshitz, S. Gredeskul, and L. Pastur, Introduction to the Theory of Disordered Systems, Wiley, New York, 1988.
[6] F. M. Izrailev, S. Ruﬀo and L. Tessieri, J. Phys. A: Math. Gen. 31, p. 5263, 1998.
[7] L. Tessieri and F. M. Izrailev, Phys. Rev. E 64, p. 66120, 2001.
[8] F. M. Izrailev and A. A. Krokhin, Phys. Rev. Lett. 82, p. 4062, 1999.
[9] L. Tessieri, J. Phys. A: Math. Gen. 35, p. 9585, 2002.
[10] T. Kottos, G. P. Tsironis and F. M. Izrailev, J. Phys.: Condens. Matter 9, p. 1777 , 1997.
[11] V. Dossetti, F. M. Izrailev, and A. A. Krokhin, Phys. Lett. A 320, p. 276, 2004.

9

