arXiv:physics/0304043v1  [physics.comp-ph]  10 Apr 2003

1

1

Energy minimization using Sobolev
gradients: application to phase separation
and ordering

S. Sial∗, J. Neuberger†, T. Lookman∗,‡ and A. Saxena‡
∗ University of Western Ontario, Department of Applied Mathematics, London,

Ontario, Canada N6A 5B7 ,

† University of North Texas, Department of

Mathematics, Denton, Texas 76203-1430

‡ Theoretical Division, Los Alamos

National Laboratory, MS B262, New Mexico 87545
E-mail: ss@cmrg.apmaths.uwo.ca, jwn@unt.edu, txl@viking.lanl.gov,
abs@viking.lanl.gov

Version: July 12, 2011

A common problem in physics and engineering is the calculation of the minima of
energy functionals. The theory of Sobolev gradients provides an eﬃcient method for
seeking the critical points of such a functional. We apply the method to functionals
describing coarse-grained Ginzburg-Landau models commonly used in pattern formation
and ordering processes.

Key Words: Sobolev gradients, Ginzburg-Landau theory, phase separation

1.

INTRODUCTION

Many problems in mathematical physics are formulated in terms of ﬁnding crit-
ical points of energy functionals. The recent theory of Sobolev gradients [1] pro-
vides a uniﬁed point of view on such problems, both in function spaces and in ﬁnite
dimensional approximations to such problems. The aim of this work is to demon-
strate the use and eﬃciency of Sobolev gradient techniques in minimising energy
functionals associated with Ginzburg-Landau models for studying phase transitions
in alloys and complex ﬂuids. These equations are prototypical for studying pat-
tern formation or ordering, such as nucleation and spinodal decomposition, that
are accompanied by instabilities. We illustrate our work with models A and B in
the Halperin-Hohenberg taxonomy, in which the coarse-grained ﬁeld or the order
parameter (OP ) is either not conserved (model A) or conserved (model B) [2].

A gradient of a functional gives the direction of greatest change per unit change
in the argument of the functional. Often overlooked is that the direction of a gra-
dient strongly depends on how the size of arguments of a functional are measured.
Functionals of interest in physics, particularly energy functionals, commonly in-
clude derivatives of the arguments. Such arguments have to be considered large
if some of its derivatives are large. Theoretical considerations of such functionals
must take this into account but is often overlooked in numerical approximations.
The theory of Sobolev gradients [1] is an organized account of how to choose a
metric for a ﬁnite dimensional problem that matches that required for the corre-
sponding theoretical problem. It is found that a proper matching leads to gradients
(Sobolev gradients) which are considerably smoother than those normally used [3].
The result is that the approach to a minimum energy conﬁguration becomes much

2

more eﬃcient. In fact, the improvement in performance using Sobolev gradients
becomes inﬁnite as mesh size goes to zero. This paper illustrates this phenomenon
in some typical problems of interest in phase separation and pattern formation.
The layout of the paper is as follows: An introduction to Sobolev gradients in Sec-
tion 2 is followed by a description in Section 3 of Ginzburg-Landau models and
how Sobolev gradient techniques may be employed. In Section 4 we compare the
results for minimization using ordinary gradients (functional derivatives) and in an
appropriate Sobolev space in 1, 2, and 3 dimensions, with diﬀerent grid spacings
and with diﬀerent boundary conditions. If we consider steepest descent as being a
time evolution from a higher energy state to a lower energy state, then a theoretical
bound on how large our time step can be is given by the Courant-Freiderichs-Lewy
(CFL) condition [4]. Beyond this limit, the numerical scheme for steepest descent
will magnify errors in each step. This implies that for the traditional steepest
descent schemes the step size will have to be decreased as grid spacing becomes
ﬁner, the dimension of the problem is increased or the order of the derivatives in
the problem increases. The Sobolev gradient technique avoids these problems [3].
When we use ordinary gradients we label our results ”L2” runs since ordinary gra-
dients are closely related to attempts at deﬁning a gradient in L2(Ω), the space of
square integrable functions in a region Ω. In Section 5 we consider model A′, which
is model A with a constraint, namely, the average value of the OP is conserved.
This model has a diﬀerent Sobolev gradient than model A and is an alternative to
the Cahn-Hilliard equation (model B) when dynamics is not of interest. We com-
pare results for minimization in L2 using the Cahn-Hilliard approach to model A′
minimization in the appropriate Sobolev space in 1, 2, and 3 dimensions with dif-
ferent grid spacings and with diﬀerent boundary conditions. In Section 6 we extend
model A′ to models of surfactant systems which have higher order derivatives. For
the models we have studied, the Sobolev gradient technique becomes increasingly
atttractive as grid spacing is reﬁned, dimension is increased, or the order of the
derivatives in the problem becomes higher.

2. THE SOBOLEV GRADIENT APPROACH

Sobolev gradients essentially provide an organized numerical procedure of de-

termining preconditioners. An energy functional can be generically written as:

J(u) =

F (Du),

(1)

ZΩ

where Ω is a domain in Euclidean space, u is a member of an appropriate function
space and Du is a list of (length n, say) consisting of u and all partial derivatives
of u which are relevant to the problem at hand. F is a function on an appropriate
Euclidean space. For example, consider Ω to be a rectangular region in R2, F is a
function on R3 so that

F (w, r, s) =

(r2 + s2)
2

+

−

w4
4

w2
2

for all numbers w, r, s and D is the transformation Du = (u, ux, uy) for all u on Ω
with well-deﬁned partial derivatives. Equation (1) then takes the form

J(u) =

F (Du) =

ZΩ

(u2

x + u2
y)
2

u4
4

+

−

dr,

u2
2 #

Z "

3

which is one of the functionals we will deal with in this paper. Returning to our
general considerations of (1), we perform a ﬁrst variation

′

J

(u)h =

′

F

(Du)Dh.

ZΩ
At this point we depart from custom and do not integrate by parts to obtain the
Euler-Lagrange equations. Instead, we write

′

J

(u)h =

′

F

(Du)Dh = hDh, (∇F )(Du)iL2(Ω)n .

(2)

We note that

Z

hDh, DgiL2(Ω)3 =

(hg + hxgx + hygy),

the inner product in the Sobolev space H 1,2(Ω) [1] [5].

By L2(Ω) we mean the Hilbert space of real functions on Ω in which

By H 1,2(Ω) we mean the subspace of L2(Ω) consisting of all f so that the norm

||f ||2

L2(Ω) =

f 2

ZΩ

||f ||2

H1,2(Ω) =

(f 2 + f 2

x + f 2
y )

is deﬁned.

We introduce a transformation P which is essential to our presentation. Take
P to be the orthogonal projection of L2(Ω)n onto the subspace of all elements of
the form Du. Such a transformation can be dealt with in a concrete way computa-
tionally. From (2),

′

J

(u)h = hDh, (∇F )(Du)iL2(Ω)n = hP Dh, (∇F )(Du)iL2(Ω)n = hDh, P (∇F )(Du)iL2(Ω)n .

These are legitimate steps since P Dh = Dh and orthogonal projections may be
passed form one side of an inner product to the other. We need one more inner
product:

hg, hiS = hDg, DhiL2(Ω)n .

In terms of this inner product,

′

J

(u)h = hDh, P (∇F )(Du)iL2(Ω)n = hh, (∇SJ)(u)iS,

where (∇SJ)(u) is deﬁned as the ﬁrst element in the list

P (∇F )(Du).

The function (∇SJ)(u) is called the Sobolev gradient of J at the element u. To
make the above calculations useful the projection P must be presented in a suitable
form and the relevant details are given later. In a number of previous applications
of the methods (e.g., transonic ﬂow [1], Ginzburg-Landau functionals for supercon-
ductivity [1]) it has been known that Sobolev gradients give vastly superior results
to those obtained with ordinary gradients. In what follows, slight variations of the
above will be used, these variations take into account a variety of boundary and
other external conditions.

ZΩ

ZΩ

4

3. APPLICATION TO GINZBURG-LANDAU MODELS

∂t = − δJ

δu and ∂u

∂t = ∇2 δJ

Models A and B are deﬁned by the equations ∂u

δu respec-
tively, where J is a free energy functional. The static and dynamical properties of
these models have been extensively studied, primarily in numerical work related to
coarsening and growth of domains [2, 6]. The functional J(u) usually has a poly-
nomial form that depends on the nature of the phase transition as the coeﬃcient
of the quadratic term changes sign (as a function of temperature, pressure or some
other thermodynamic variable). The widely used form with terms in u2 and u4 is
associated with a second order or continuous transition, where there is no jump
discontinuity such as latent heat.

We seek to minimize the model A free energy functional

J(u) =

u4 −

u2 +

|∇u|2

dr

1
4

Z (cid:20)

1
2

κ
2

(cid:21)

over some volume subject to certain boundary conditions. The coeﬃcient κ deter-
mines the energy penalty for interfaces.

In one dimension the problem can be reformulated as minimization of

J(u0, u1) =

1
4

Z (cid:20)

u4
0 −

u2
0 +

1
2

κ
2

u2
1

(cid:21)

dx

subject to the constraint that the L2(Ω) functions u0 and u1 are of the form

(u0, u1) = (f, fx)
for some H (1,2)(Ω) function f . We seek a projection operator that maps (u0, u1) in
L2(Ω) × L2(Ω) to the closest point in the subspace consisting of points of the form
(f, fx). This is given by minimizing the integral

I =

(f − u0)2 + (fx − u1)2

dx

over the interval subject to speciﬁed constraints. Minimizing I gives the condition

(cid:3)

Z

(cid:2)

(1 − ∂2

x)f = u0 − ∂xu1.

A steepest descent scheme in L2(Ω) would be of the form

u → u − λ∇J(u),

where λ is some scalar and ∇J(u) is the variation of J with respect to u subject
to boundary conditions. We instead perform a steepest descent in the space where
the gradient is given by the projection we already found:

∇J(u0, u1) = (1 − ∂2
x)

−1

∂J(u0, u1)
∂u0

(cid:18)

− ∂x

∂J(u0, u1)
∂u1

.

(cid:19)

This is equivalent to changing the norm of candidate functions from

to

||f ||2 =

f 2dx

Z

5

again subject to appropriate constraints such as boundary conditions.

||f ||2 =

f 2dx +

f 2
x dx

Z

Z

4. RESULTS FOR MODEL A

In this section we report results for model A in one dimension with periodic and
Dirichlet boundary conditions. The coeﬃcient κ was set to 1.0 for all the numerical
trials. For periodic boundary conditions, systems of M nodes with spacing h were
set up with random initial values for the order parameter u such that the avaerage
value hui = 0.05 at t = 0. The ﬁnal minimum energy conﬁguration should have
u = 1.0 everywhere. The number of iterations, the largest step λ that could be
used, and the CPU time to obtain u > 0.99 everywhere in the system are noted in
the Tables. The next three entries in the Tables are the number of iterations, step,
and CPU time required when using the Sobolev gradient technique. For Dirichlet
boundary conditions the order parameter u was set to 0.01 everywhere except at the
ends where u was ﬁxed at zero. The program was terminated when the magnitude
of the L2 gradient was less than 10−5 everywhere in the system.

When minimizing in L2(Ω) we note that the largest step size that can be used
for each minimization step decreases as the grid spacing is halved, as is implied by
the CFL condition. However, steepest descent using the Sobolev gradient does not
suﬀer from this limitation. At each minimization step we ﬁrst estimate the usual
L2 gradient, using ﬁnite diﬀerences to estimate derivatives. Thus, for model A we
estimate ∇F = u3−u−∇2u. Using the Sobolev gradient the energy is minimized by
a step u → u − λ ∗ ∇SF , where ∇SF is the Sobolev gradient we want to use. Thus,
at each minimization step we need to ﬁnd the Sobolev gradient, given the usual L2
gradient. This Sobolev gradient satisﬁes the linear equation (1 − ∇2)∇SF = ∇F .
This is solved iteratively. The ﬁrst time we need to calculate the Sobolev gradient
we do not have a good initial guess, however, in subsequent iterations the Sobolev
gradient serves as a good initial guess. The Sobolev gradients vary smoothly as the
minimization progresses and so an iterative procedure is less costly computationally
than using a direct solver each time. Since the operator (1 − ∇2) is symmetric,
positive deﬁnite, we use a conjugate gradient solver. Steepest descent and Jacobi
iteration result in longer run times.

Results are reported for a single Dec Alpha EV68 CPU. The diﬀerence in codes
for the L2 minimization and the Sobolev space minimization is that in the case
of the Sobolev space minimization a call to a solver that estimates the Sobolev
gradient, given the L2 gradient, is made and then the Sobolev gradient is used
instead of the L2 gradient.

6

One dimensional model A

Periodic boundary conditions (BCs):

Nodes M spacing h

step λ (L2) CPUs ( L2 )

1.0
0.5
0.25
0.125
0.0625
0.03125

1.0
0.5
0.25
0.125
0.0625
0.03125

iterations (L2)
18
48
173
665
2674
10514

iterations (L2)
38
115
425
1660
6730
26643

0.32
0.11
0.030
0.0077
0.0019
0.00048

0.32
0.11
0.030
0.0077
0.0019
0.00048

0.00391
0.0127
0.0859
0.682
5.87
51.22

0.00586
0.0244
0.166
1.32
11.64
105.33

iterations
10
10
10
10
10
10

step λ CPUs
0.0195
0.0684
0.325
1.08
3.07
9.75

0.6
0.6
0.6
0.6
0.6
0.6

iterations
30
33
52
136
370
1029

step λ CPUs
0.0146
0.0361
0.159
0.906
5.04
29.69

0.6
0.6
0.6
0.6
0.6
0.6

Dirichlet BCs:

Nodes M spacing h

step λ (L2) CPUs (L2)

210
211
212
213
214
215

210
211
212
213
214
215

For small systems with large spacings the time taken by the solver negates the
advantage of being able to use a much larger step λ when using a Sobolev gradient.
However, as the system becomes larger and the spacing ﬁner, the Sobolev gradient
technique is more eﬃcient.

Two dimensional model A

Systems now have M 2 nodes.
Periodic BCs:

M
25
26
27
28
29

M
25
26
27
28
29

h
1.00
0.50
0.25
0.125
0.0625

h
1.00
0.50
0.25
0.125
0.0625

Dirichlet BCs:

iterations (L2)
27
90
332
985
3846

λ (L2) CPUs (L2)
0.005859
0.19
0.0576
0.056
0.939
0.015
14.58
0.0038
301
0.00097

iterations
10
10
10
10
10

iterations (L2)
77
263
989
3909
15306

λ (L2) CPUs (L2)
0.19
0.056
0.015
0.0038
0.00097

0.0127
0.15
2.58
53.09
1210.78

iterations
36
39
83
207
640

λ
0.6
0.6
0.6
0.6
0.6

λ
0.6
0.6
0.6
0.6
0.6

CPUs
0.0107
0.0693
0.709
7.52
77.7

CPUs
0.0263
0.181
2.46
28.38
387.78

Again we note that the ﬁner the spacing the less CPU time the Sobolev gradient
technique uses in comparison to the usual steepest descent. For model A results in
two dimensions the same step size λ can be used for all spacings h when minimizing
in the appropriate Sobolev space. The step size for minimization in L2 has to

7

decrease as the spacing is reﬁned, we note that it has to decrease much faster in
two dimensions than in one.

Three dimensional model A

Systems now have M 3 nodes.
Periodic BCs:

M h
25
26
27

1.00
0.50
0.25

iterations (L2)
36
124
494

λ (L2) CPUs (L2)
0.14
0.40
0.010

0.303
7.99
429.16

iterations
8
8
14

Dirichlet BCs:

M h
25
26
27

1.00
0.50
0.25

iterations (L2)
119
417
2115

λ (L2) CPUs (L2)
0.14
0.040
0.010

0.857
27.57
1395.67

iterations
41
55
171

λ
0.6
0.6
0.6

λ
0.6
0.6
0.6

CPUs
0.676
7.55
91.64

CPUs
2.32
25.12
591.31

The three dimensional models also show that as the spacing becomes ﬁner it is
advantageous to use the Sobolev gradient technique. We also note from the pre-
ceding Tables that as the dimension of the problem increases the Sobolev gradient
technique becomes more eﬃcient.
In one dimension Sobolev gradients are more
eﬃcient for a spacing h = 0.25, as compared to three dimensions where they are
more eﬃcient for spacing h = 0.5.

5. CONSERVATION CONSTRAINT

For Model A type systems the order parameter u is not conserved. A Cahn-
Hilliard [7] or Model B system which would conserve the order parameter is given
by

ut = Γ∇2

δJ(u)
δu

.

(cid:20)
Suppose we wish to ﬁnd the minima of some Model A type functional and we
require conservation of the order parameter u during the course of the simulation,
without regard to the actual dynamics. We can use a second projection operator
to enforce conservation rather than increase the order of our evolution equation by
two.

(cid:21)

In order that

udu not change, we need to project our gradient onto the sub-

space of L2(Ω) functions with integral zero. This is achieved for a function f by

R

We will use the term model A′ for model A with this constraint as we do not solve
for Model B dynamics. The order parameter u is now taken to be a relative concen-
tration of two ﬂuids A and B with concentrations ρA, ρB, such that ρ = ρA + ρB
and u = ρA − ρB

.

ρ
We use the free energy

f → f −

f
V
R

8

J =

[ α
4 (1 − u2) − T + T

2 (1 + u) log(1/2 + u/2) + T

2 (1 − u) log(1/2 − u/2) +

(3)

R

κ
2 |∇u|2]

This free energy contains the entropy of mixing. Phase separation depends on the
temperature T . When T is greater than the critical temperature Tc = α/2 the two
phases mix completely. When T is less than Tc there will be domains of positive
and negative u. The lower T is, the greater can be the possible maximum values
of |u| at equilibrium. That is, phase separation between ﬂuids A and B is more
complete at lower T values.

The model B approach would result in an increase in the order of the derivatives
of the evolution scheme by two. Imposing conservation through a projection means
that this can be avoided. As a result, a Sobolev gradient approach for modeling
systems with conservation constraints is even more eﬃcient in comparison to the
usual approach. The step size need not be reduced for ﬁner spacings when using
a Sobolev gradient scheme. Minimization was performed on systems with random
initial conditions and hui = 0.05, and α = 2, T = 0.8, κ = 1.0 until the magnitude
of the L2 gradient was less than 10−5 everywhere. By comparing results in two
and three dimensions we noticei from the Tables that the Sobolev gradient scheme
is even more eﬃcient in three dimensions than it is in two when compared to the
traditional approach.

Two dimensional binary system with periodic BCs:

M
25
26
27

h
1.00
0.50
0.250

iterations (L2)
680 000
2 516 565
4 420 185

λ (L2) CPUs (L2)
0.027
0.0018
0.00012

50.34
740
5187

iterations
314
645
1937

λ
0.95
0.95
0.95

CPUs
0.433
5.26
98.63

Three dimensional binary system with periodic BCs:

1.00
0.50

M h
25
26

iterations
418 515
594 233

CPUs
6291
68523
These numerical experiments with model A′ demonstrate that it is considerably
more eﬃcient to use a projection to enforce conservation of the order parameter if
the ﬁnal equilibrium conﬁguration is all that is important.

iterations
323
214

λ
0.012
0.00086

CPUs
33.23
418

λ
0.95
0.95

6. SURFACTANT SYSTEMS

The addition of a surfactant to an oil-water system can be modeled by allowing
κ become negative [8] in the free energy (3). This favors the presence of interfaces
between the two components of the mixture and thus mimics the action of surfactant
in allowing the oil and water to “mix” with the formation of bicontinuous domains
separating the oil and water. We also add a curvature dependent term for a bending
energy of the form

γ
2
to the binary system free energy. By changing γ one can change the shape of
domains from circular to oval. The surfactant model enables us to examine how
the Sobolev gradient approach and the traditional schemes compare when the order

(∇2u)2

Eb =

9

of the derivatives increases. The coeﬃcient γ was set to 1.0 and other parameters
and initial conditions were as given in Section 5.

Two dimensional surfactant system with periodic BCs:

M
25
26
27

h
1.00
0.50
0.250

iterations (L2)
4 853 277
27 103 876
96 649 780

λ (L2)
0.0043
0.000062
0.00000096

CPUs (L2)
4 696
45 250
97 327

iterations
43 234
4 798
5 450

λ
0.5
0.5
0.5

CPUs
336
449
2038

Three dimensional surfactant system with periodic BCs
It is clear that a model B minimization with sixth order derivatives will be much
slower than using model A′. We report results for the Sobolev gradient technique
only.

M h
25
26

1.00
0.50

iterations
30 320
55 268

λ
0.5
0.5

CPUs
6 636
630 839

7. SUMMARY AND CONCLUSIONS

We have presented minimization schemes for model A Ginzburg-Landau func-
tionals based on the Sobolev gradient technique [1, 5]. The Sobolev gradient tech-
nique is computationally more eﬃcient than the usual steepest descent method as
the spacing of the numerical grid is made ﬁner, the dimension of the problem is in-
creased, the order of the derivatives in the functional is increased, or a conservation
constraint is imposed. Our results indicate that Sobolev gradient techniques may
oﬀer distinct advantages in certain cases, particularly for problems involving func-
tionals that contain spatial gradients such as strain based elasticity problems [9],
least square formulations of partial diﬀerential equations, and electrostatic prob-
lems that require solving the Poisson-Boltzmann equation.

An interesting question is whether there exists an optimal metric with respect
to which the Sobolev gradient works best. It is an open research problem to try to
ﬁnd such an optimal metric, even though the optimal one would likely not make
a large diﬀerence computationally in all cases. An example of where there is a
great diﬀerence is in near-singular problems where a weighted Sobolev gradient,
weighted with the singularity in question, works vastly better [10]. The likely fact
that we cannot yet ﬁnd an optimal metric may well be responsible for the nonlinear
dependence of run time on number of grid points noted in this work.

REFERENCES

[1] J.W. Neuberger, Sobolev Gradients and Diﬀerential Equations, Springer Lec-

ture Notes in Mathematics 1670 (Springer-Verlag, New York, 1997).

[2] P.C. Hohenberg, B.I. Halperin, Theory of dynamic critical phenomena , Rev.

Mod. Phys. 49, 435-479 (1977).

[3] W. B. Richardson, Steepest descent using smoothed gradients, Applied Math-

ematics and Computation 112, 241-254 (2000).

10

[4] R. Courant, K. O. Friedrichs, H. Lewy, Uber die Partiellen Diﬀerenzengle-

ichungen der Mathematisches Physik, Math. Ann. 100, 32-74 (1928).

[5] R.A. Adams, Sobolev Spaces (Academic Press, New York, 1975).

[6] T.M. Rogers, K.R. Elder, R.C. Desai, Numerical study of the late stages of

spinodal decomposition, Phys. Rev. B. 37, (1988) 9638-9649.

[7] J.W. Cahn, J.E. Hilliard, Free Energy of a Nonuniform System. I. Interfacial

Free Energy, J. Chem. Phys. 28, (1958) 258.

[8] G. Gompper, M. Schick, Correlation between structural and interfacial prop-

erties of amphiphilic systems, Phys. Rev. Lett. 65, (1990) 1116.

[9] S.R. Shenoy, T. Lookman, A. Saxena, A.R. Bishop, Martensitic Textures:
Multiscale Consequences of elastic compatibility, Phys. Rev. B, v 60(18) pp.
R12537-R12541 (1999).

[10] W.T. Mahavier, A Numerical Method Utilizing Weighted Sobolev Descent to

Solve Singular Diﬀerential Equations, Nonlinear World 4, (1997) 4.

11

