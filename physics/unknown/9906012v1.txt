arXiv:physics/9906012v1  [physics.data-an]  7 Jun 1999

1
9
9
8

b
y

C
o
p
y
r
i
g
h
t

C
h
r
i
s
t
o
p
h
e
r

G
o
r
d
o
n

Artiﬁcial Neural Network Modeling of Forest
Tree Growth

by

Christopher Gordon

Research Report

Presented to the Faculty of Science of

The University of the Witwatersrand

in Partial Fulﬁllment

of the Requirements

for the Degree of

Master of Science

The University of the Witwatersrand

June 1998

Declaration

I declare that this research report is my own, unaided work.
It is being submitted for
the Degree of Master of Science in the University of the Witwatersrand, Johannesburg,
South Africa. It has not been submitted before for any degree or examination in any other
University.

Christopher Gordon

The University of the Witwatersrand
June 1998

iii

Acknowledgments

Firstly I would like to thank my supervisor Neil Pendock for introducing me to Bayesian
statistics and for the many opportunities he has made available to me. I would also like to
acknowledge Dr. Falkenhagen for providing me with the forest tree growth data and several
useful references. The data were originally from the Council for Scientiﬁc and Industrial
Research (CSIR) in South Africa.

Of the many friends and colleagues that have provided me with encouragement and ad-
vice I would in particular like to thank Mirella Danaila, Gheorghita Ghinea, Steve Hirschowitz
and Lester Masher.

A special thanks to Sue Gordon who made it all possible. Finally, I would like to

express my appreciation to Geraldine Leong for all her support and encouragement.

Christopher Gordon

The University of the Witwatersrand
June 1998

iv

Abstract

The problem of modeling forest tree growth curves with an artiﬁcial neural network (NN)
is examined. The NN parametric form is shown to be a suitable model if each forest tree
plot is assumed to consist of several diﬀerently growing sub-plots. The predictive Bayesian
approach is used in estimating the NN output.

Data from the correlated curve trend (CCT) experiments are used. The NN predictions
are compared with those of one of the best parametric solutions, the Schnute model. Analysis
of variance (ANOVA) methods are used to evaluate whether any observed diﬀerences are
statistically signiﬁcant. From a Frequentist perspective the diﬀerences between the Schnute
and NN approach are found not to be signiﬁcant. However, a Bayesian ANOVA indicates
that there is a 93% probability of the NN approach producing better predictions on average.

v

Contents

iii

iv

v

viii

ix

1
2
2
2
3
3

Declaration

Acknowledgments

Abstract

List of Tables

List of Figures

Chapter 1 Introduction

1.1 Artiﬁcial Neural Network Parameter Estimation . . . . . . . . . . . . . . . .
1.2 Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2.1 Correlated Curve Trend Experiments . . . . . . . . . . . . . . . . . . .
1.3 Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.4 Outline

Chapter 2 Forest Tree Growth Modeling

4
4
2.1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.2 Correlated Curve Trend Experiments . . . . . . . . . . . . . . . . . . . . . . .
7
2.3 Growth Curve Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.3.1 Linear Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.3.2 Autocorrelated Errors . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.3 Nonlinear Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.3.4 Estimation Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
2.4 Modeling of Pinus Roxburghii Data . . . . . . . . . . . . . . . . . . . . . . . . 12

Chapter 3 Bayesian Statistics

14
3.1 Foundations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
3.2 The Rules of Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
3.3 Bayes’ Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
3.4 The Predictive Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
3.5 Eliminating Nuisance Parameters . . . . . . . . . . . . . . . . . . . . . . . . . 17
. . . . . . . . . . . . . . . . . . . . . . . 18
3.6 Prior Probability Density Functions

vi

3.6.1 Non-Informative Priors
. . . . . . . . . . . . . . . . . . . . . . . . . . 18
3.6.2 Conjugate Priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
3.6.3 Empirical Bayes
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
3.6.4 Hierarchical Priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
3.6.5 Exchangeable Parameter Priors . . . . . . . . . . . . . . . . . . . . . . 24
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
3.7 Loss Functions
3.8 Bayesian Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
3.8.1 Monte Carlo Integration . . . . . . . . . . . . . . . . . . . . . . . . . . 26
3.8.2 Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

Chapter 4 Artiﬁcial Neural Networks

29
4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
4.2 Multilayer Perceptron Structure . . . . . . . . . . . . . . . . . . . . . . . . . . 30
4.3 Nonlinear Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
4.4 Multilayer Perceptron Training . . . . . . . . . . . . . . . . . . . . . . . . . . 32
4.5 The Bias/Variance Dilemma . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
4.6 Methods of Avoiding Overﬁtting . . . . . . . . . . . . . . . . . . . . . . . . . 35
. . . . . . . . . . . . . . . . . . . . . . . 36
4.7 Bayesian Artiﬁcial Neural Networks
4.7.1 Neural Network Priors . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
4.7.2 Computational Techniques
. . . . . . . . . . . . . . . . . . . . . . . . 38
4.7.3 Markov Chain Monte Carlo Integration . . . . . . . . . . . . . . . . . 39
4.8 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

Chapter 5 Methods of Comparison

43
5.1 Criteria for Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
5.2 Hierarchical Analysis of Variance . . . . . . . . . . . . . . . . . . . . . . . . . 44
5.2.1 Frequentist Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
5.2.2 Bayesian Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

Chapter 6 Results and Discussion

47
6.1 Experimental Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
Implementation Details
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
6.2
6.2.1 Bayesian Neural Networks . . . . . . . . . . . . . . . . . . . . . . . . . 48
6.2.2 Maximum Likelihood Neural Network Solution . . . . . . . . . . . . . 52
Schnute Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . 52
6.2.3
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53

6.3 Extrapolation Results

Chapter 7 Conclusion

Appendix A Data

67

69

vii

List of Tables

2.1 Geographical information of Border forest plantation in Kwa-Zulu Natal, South

Africa (After Falkenhagen (1997).) . . . . . . . . . . . . . . . . . . . . . . . . .

6

6.1 Table of test MSEs in units of mm2
6.2 Table of Frequentist and Bayesian ANOVA analysis. Where not speciﬁed, units

. . . . . . . . . . . . . . . . . . . . . . . . 53

are in mm2.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

A.1 The average diameter at breast height (DBH) data. The age is measured in years

and the DBH in mm.

A.2 The number of trees within a plot. The age is measured in years.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
. . . . . . . . 70

viii

List of Figures

Individual growth curves for trees in plot 2.

2.1
2.2 Forest tree mean density at breast height growth samples for plots 1 to 10. The
×’s represent the mean DBH measurements and the vertical lines, the number
of trees.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . .

2.3 Forest tree mean density at breast height growth samples for plots 11 to 18. The
×’s represent the mean DBH measurements and the vertical lines, the number
of trees.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

8

9

4.1 A feed forward multilayer perceptron artiﬁcial neural network (NN). It has two
input layer neurons, one hidden layer with three neurons and an output layer with
two neurons. The squares represent the bias neurons. See the accompanying text
for an explanation of the notation.

. . . . . . . . . . . . . . . . . . . . . . . . . 31

6.1 Markov chain of hidden layer to output layer hyperparameter for plot 2.
6.2 Markov chain of hidden layer to output layer hyperparameter for plot 1.
6.3 Markov chain of hidden layer to output layer hyperparameter for plot 1.
6.4 Markov chain of average training MSE for plot 1.
6.5 ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 1. The
Schnute prediction is displayed as a dotted line. The × are the training data and
the + are the testing data.

. . . . . 50
. . . . . 50
. . . . . 51
. . . . . . . . . . . . . . . . . 51

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56

6.6 ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 2. The
Schnute prediction is displayed as a dotted line. The × are the training data and
the + are the testing data.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

6.7 ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 4. The
Schnute prediction is displayed as a dotted line. The × are the training data and
the + are the testing data.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58

6.8 ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 6. The
Schnute prediction is displayed as a dotted line. The × are the training data and
the + are the testing data.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59

6.9 ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 8. The
Schnute prediction is displayed as a dotted line. The × are the training data and
the + are the testing data.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60

ix

6.10 ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 9. The
Schnute prediction is displayed as a dotted line. The × are the training data and
the + are the testing data.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61

6.11 ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 11.
The Schnute prediction is displayed as a dotted line. The × are the training data
and the + are the testing data. . . . . . . . . . . . . . . . . . . . . . . . . . . . 62

6.12 ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 12.
The Schnute prediction is displayed as a dotted line. The × are the training data
and the + are the testing data. . . . . . . . . . . . . . . . . . . . . . . . . . . . 63

6.13 ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 15.
The Schnute prediction is displayed as a dotted line. The × are the training data
and the + are the testing data. . . . . . . . . . . . . . . . . . . . . . . . . . . . 64

6.14 ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 16.
The Schnute prediction is displayed as a dotted line. The × are the training data
and the + are the testing data. . . . . . . . . . . . . . . . . . . . . . . . . . . . 65

6.15 ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 18.
The Schnute prediction is displayed as a dotted line. The × are the training data
and the + are the testing data. . . . . . . . . . . . . . . . . . . . . . . . . . . . 66

x

Chapter 1

Introduction

Growth curves are found in many diﬀerent areas of study, e.g. in animals, plants, bacteria,
ﬁshes and populations. Their study is important in understanding what they are aﬀected
by and in predicting future values.

In the ﬁeld of forestry much eﬀort has been expended in ﬁnding mathematical models
to describe the growth of trees (Bredenkamp and Gregoire 1988, Seber and Wild 1989,
Falkenhagen 1997). Models such as the logistic function have been proposed for predicting
the average tree diameter at breast height (DBH) for a plot of forest trees:

y(t) =

v
1 − exp(−ut + a)
= logistic(t; u, v, a)

where y(t) is the average DBH at age t and u, v and a are the model parameters. For the
model to be physically realistic:

(1.1)

v, t ≥ 0.

An advantage of such parametric models is that their parameters are easy to interpret, e.g.
v will be the maximum average DBH attainable. The disadvantage of such models is that
they are only appropriate for modeling a very limited family of input/output mappings.

Multilayer perceptron artiﬁcial neural networks (NNs) (Haykin 1994) provide a more
ﬂexible method of nonlinear regression. A general functional form of a NN for a one dimen-
sional input to output mapping is given by:

(1.2)

y(t) =

logistic(t; ui, vi, ai) + b.

The larger Nh is chosen to be, the more ﬂexible the model. Hornik et al. (1990) have
shown that equation (1.2) has fairly general function approximation qualities. In the case
of modeling average forest tree growth, the NN model has a particularly suitable form. If
the forest tree plot can be assumed to consist of Nh groups of diﬀerently growing trees and
each group’s average is modeled using the logistic function, then the NN functional form

Nh

i=1
X

1

follows. However, the NN model does not usually contain the physical constraints mentioned
in equation (1.1).

Thus, the NN model provides for heterogeneity in the growth of a forest tree plot.
Unlike most NN applications, in mean forest tree growth modeling the NN functional form
has some justiﬁcation.

1.1 Artiﬁcial Neural Network Parameter Estimation

In order for the NN to have enough ﬂexibility to ﬁt a wide range of growth curves, Nh has
to be made fairly large. But a large Nh implies many model parameters. The more model
parameters, the more sensitive the solution is to any statistical variability in the data. This
is known as the bias/variance dilemma.

Bayesian estimation provides a way of achieving a low bias without paying the price of a
high variance. Predictions of unmeasured growth values are made by taking a weighted ‘sum’
of the predictions provided by all possible values of the parameters. Given N input/output
pairs, D = {t1, y1; . . . ; tN , yN }, a new measurement, yN +1, is estimated by:

yN +1 =

y(tN +1; θ)p(θ|D) dθ

ZDθ

where θ is the set of NN parameters and Dθ is their domain. The weight of each prediction
is given by the probability density function (pdf) of the network parameters given the data,
p(θ|D). This pdf can factorized as follows:

p(θ|D) ∝ p(D|θ)p(θ)

where p(θ|D) is known as the likelihood and expresses how the pdf is aﬀected by the available
data. The p(θ) component is known as the prior and expresses data (D) independent
knowledge about the model parameters. The prior can be used to include appropriate
smoothness constraints which reduce the variance of the estimate.

1.2 Model Evaluation

When deciding which model is better at describing the process that generated a particular
set of data, it is preferable to test the model on diﬀerent data than it was trained on.
Otherwise, the performance of each model is likely to be optimistically biased.

Using only one training set and test set to compare regression methods can be mis-
leading. How well each method does will depend on the particular training and test cases
used. The methods should be compared using many diﬀerent training sets and test cases.
Statistical hypothesis testing can then be used to determine which method is on average the
best.

1.2.1 Correlated Curve Trend Experiments

A set of forest tree growth data suitable for the comparison of regression methods can
be obtained from the results of what are known as the “correlated curve trend” (CCT)

2

experiments (O’Connor 1935). The growth of several diﬀerent plots of trees with diﬀerent
initial and growing conditions was monitored. The growth measurements for the diﬀerent
plots can be used to provide an estimate of how well the NN approach performs on average
in comparison with a parametric regression approach.

1.3 Objectives

In this report a survey of the available methods of forest tree growth curve modeling and
Bayesian artiﬁcial neural networks (BNN) will be given. Statistical hypothesis testing will
be used to compare the BNN approach with standard parametric models on the forest tree
growth modeling problem.

Another of the aims of this research report is to evaluate the BNN approach on a

practical, real world problem where a relatively small amount of data is available.

1.4 Outline

In Chapter 2 the previous literature on forest tree growth curve modeling is reviewed. The
CCT experimental data are examined and the objectives of the curve ﬁtting procedure are
deﬁned. The Schnute solution proposed by Falkenhagen (1997) is also discussed.

In Chapter 3 the Bayesian methodology used in the rest of the report is reviewed.
Many of the relevant results are derived from ﬁrst principles. The problems of deﬁning
prior distributions and the derivation of predictive distributions are discussed.

Chapter 4 surveys the relevant NN literature. The bias/variance dilemma is explained.
The Bayesian treatment of Neal (1996) is summarized. A new justiﬁcation for the prior
distribution assigned to the network weights is given.

Chapter 5 reviews an analysis of variance (ANOVA) scheme, introduced by Rasmussen
(1996), for comparing regression methods. A Bayesian hierarchical solution is also discussed.
In Chapter 6 the Bayesian neural network (BNN) scheme is applied to extrapolating
the CCT data. The Frequentist ANOVA approach of Rasmussen (1996) and a hierarchical
Bayesian ANOVA are used to compare the statistical signiﬁcance of the Schnute and BNN
results.

An overview of the results obtained in this research report is presented in Chapter 7.

The scope and limitations of the results are discussed.

3

Chapter 2

Forest Tree Growth Modeling

If physics has its laws, biology has its variety. – G. A. Dover.

2.1 Background

There is a long history of forest tree growth modeling, from the ﬁrst yield tables published
over 200 years ago, to the recent Bayesian treatments of growth and yield models (Vanclay
1995, Green and Strawderman 1996). Models help in forecasting timber yields, identifying
appropriate treatments, planning how densely to plant trees together, deciding when to
harvest and in monitoring the current state of a forest. They also help in determining the
sustainability of various silviculture practices.

Vanclay (1995) has given a synthesis of the models and methods for tropical forests.
An important aspect of tropical forest modeling is whether the timber harvesting is sustain-
able (Vanclay 1994). Oshu (1991) uses a matrix model to predict long term tropical rain
forest growth, in which matrix eigenvalues are used to estimate the intrinsic rate of natural
increase. Methods of assessing the usefulness of permanent sample site databases are given
in Vanclay et al. (1995).

Bayesian techniques have been used to estimate the parameters of a growth and yield
model for slash pine plantations (Green and Strawderman 1996). Posterior probability
distributions were found for parameters such as number, volume and diameter of plantation
trees. Zellner’s (1996) Bayesian method of moments was used to avoid having to make
any assumptions about the form of the likelihood function. Another Bayesian paper is
Green et al. (1994) where Bayesian estimation is used to ﬁt the three parameter Weibull
distribution to some tree diameter data. It is shown that the Bayesian solution avoids the
negative location parameter estimates which plague the maximum likelihood solutions.

In a series of articles, Guan and Gertner (1991a;b;c; 1995) used an artiﬁcial neural
network (see Chapter 4) to model forest tree mortality in terms of diameter at breast height
(DBH) and the annual increment in DBH.

4

2.2 Correlated Curve Trend Experiments

The growth of a tree can be aﬀected by competition from neighbouring trees for the available
resources of sunlight, moisture, root space and soil nutrients (Vanclay 1995). The degree of
crowding has a considerable eﬀect on the mean tree size.

O’Connor (1935) has examined the question of how the crowding of trees eﬀects their

growth. There are two components to this problem:

1. How closely the trees are planted together, known as the espacement.

2. What thinning 1 strategies are employed.

There are a number of diﬀerent qualities that a forester might consider when determining
the optimum strategy:

1. The total volume of production, e.g. for pulp production.

2. How quickly the trees will grow.

3. The distribution of tree sizes.

The eﬀects of diﬀerent thinning regimes can be determined by keeping all other relevant
factors constant and just varying the thinning regime. Generally the main factors in de-
termining tree growth are the species of tree and the location or site where the trees are
growing. Thus to compare diﬀerent thinning regimes, the same forest tree species is planted
on a site which is as uniform as possible.

The Correlated Curve Trend (CCT) experiments were based on the concepts of O’Connor

(1935). A more modern view is given by Bredenkamp (1984). In the CCT experiments, the
desired stand density2 is achieved by thinning in advance of competition. An analysis of
one of these experiments, based on the growth of Eucalyptus grandis (Hill) Maiden, is given
by Bredenkamp and Burkhart (1990). In their paper they evaluate the use of various ways
of quantifying the degree of crowding within a plot.

Data from a CCT experiment established at the Border forest plantation in what is
now known as Kwa-Zulu Natal, South Africa were used. In November 1936, test plots of
Pinus roxburghii Sargent, a pine native to the Himalayas, were planted at an espacement
of 1.80 × 1.80 m (Falkenhagen 1997). The area of each plot was 0.08 ha (800 m2). A 29 m
wide buﬀer zone of trees was planted around each plot. The geographical details of the plots
are given in Table 2.1.

Twenty measurements of the diameter at breast height3 (DBH) of each tree were taken,
see Appendix A. Measurements were usually taken during the summer months: October to
March. At age 14, two measurements were taken, one in February and one in December. For
this study these were averaged to give one measurement for that year. Height measurements
were also made, but only diameter measurements will be examined in this report.

In Figure 2.1 all the tree measurements for plot 2 are displayed. The mean of the
measurements is also plotted. Each mean point is joined to its neighbouring mean points
by piece-wise straight line segments.

1Thinning is the artiﬁcial removal of trees by the forester.
2Tree stems per unit area.
3The diameter at the breast height of the forester.

5

Latitude (S)
Longitude (E)
Altitude
Average annual rainfall
Length of dry seasona
Mean annual temperature

30◦33′
29◦45′
1067 m
945 mm
3 months
16.1◦C

aNumber of months with rainfall less than 30 mm.

Table 2.1: Geographical information of Border forest plantation in Kwa-Zulu Natal, South
Africa (After Falkenhagen (1997).)

Indvidual tree

Mean tree

)

m
c
(
 

H
B
D

50

40

30

20

10

0

0

5

10

30

35

40

15

20
Age (years)

25

Figure 2.1:

Individual growth curves for trees in plot 2.

6

The average DBH vs. time curves will be modeled for each plot. Figures 2.2 and 2.3
show the mean of the measured DBHs plotted against age for each plot used in this study.
The number of trees in a plot at each measurement is also displayed as a vertical line at
the age of each measurement. As can be seen in some of the plots, a particularly drastic
thinning can cause a discontinuity in the growth curve. This is particularly noticeable in
plot 15.

In plot 1 the last few years of measurements actually show an increase in the rate of
growth. This may be due to the natural decrease in trees within plot 1. Bredenkamp and
Gregoire (1988) note a similar kind of behaviour in the Eucalyptus data which they studied.

2.3 Growth Curve Modeling

For modeling growth curve data, a large variety of models have been proposed. A review is
given in Chapter 7 of Seber and Wild (1989). Approaches to growth curve modeling can be
put into several diﬀerent categories.

2.3.1 Linear Approach

This usually entails ﬁtting polynomials to growth curves (Kshirsagar 1976). Some of the
polynomial coeﬃcients can be assumed to be common for several diﬀerent growth curves.
Polynomial interpolation has been criticized as being biologically unreasonable (Seber and
Wild 1989). It is not commonly used in the forestry growth curve literature.

2.3.2 Autocorrelated Errors

Data which are collected from the same subjects at diﬀerent times is known as longitudinal
or time series data. Such data are often considered to have autocorrelated errors, (Seber
and Wild 1989). For example in modeling the growth in the weight of an animal, there
might be a series of negative errors over a period of time that the animal was sick. For
trees, correlated errors might be due to long periods of abnormal climatic conditions such
as drought.

Presumably, the autocorrelation in errors is going to depend on the frequency of mea-
surements. If the measurements are far enough apart there is unlikely to be any autocorre-
lation in errors. Also, stochastic analysis is easiest when there are equally spaced measure-
ments, but there are ways of overcoming this restriction (McDill and Amateis 1991).

In stochastic analysis, a diﬀerence function of the data is generally modeled by some
diﬀerential form. In the next section, ways of modeling the data directly will be looked at.
The basic diﬀerential forms the models are based on will also be discussed.

2.3.3 Nonlinear Models

Many nonlinear models have been proposed for growth curves. Some of them are based on
biological principles. However, these biological motivations are not generally accepted as

7

Plot 1

Plot 2

Plot 4

Plot 6

Plot 9

Plot 10

s
e
e
r
t
 
0
1
 
/
 
r
e
b
m
u
N

 
r
o
 
m
c
 
/
 

H
B
D
 
n
a
e
M

50

40

30

20

10

0

50

40

30

20

10

0

50

40

30

20

10

0

 
0

  
0

0

30
20
10
Age / years

0
 

40

0

10

20

30

40

Figure 2.2: Forest tree mean density at breast height growth samples for plots 1 to 10. The
×’s represent the mean DBH measurements and the vertical lines, the number of trees.

8

Plot 11

Plot 12

Plot 15

Plot 16

0 

0

10

20

30

40

Plot 18

s
e
e
r
t
 
0
1
 
/
 
r
e
b
m
u
N

 
r
o
 
m
c
 
/
 

H
B
D
 
n
a
e
M

50

40

30

20

10

0

50

40

30

20

10

0

50

40

30

20

10

0

 
0

  
0

0

30
20
10
Age / years

40

Figure 2.3: Forest tree mean density at breast height growth samples for plots 11 to 18. The
×’s represent the mean DBH measurements and the vertical lines, the number of trees.

9

being compelling. Other models are purely empirical. The parameters of nonlinear growth
curves can often be interpretable in terms of physical growth.

Exponential and Monomolecular Growth Curves

In the simplest of organisms, growth takes place by the binary splitting of cells. From which
it follows that the rate of growth will be proportional to the current size of the organism, f :

which leads to the exponential growth curve:

where γ is a constant. Many growth models are exponential for small time, t. However
an exponential growth curve model leads to unlimited growth, whereas growth is known to
stabilize:

df
dt

= κf, where κ > 0

f (t) = eκ(t−γ)

α = lim
t→∞

f (t),

df
dt

→ 0 as t → ∞.

which implies

A simple way of achieving this is by assuming that the growth rate is proportional to the
remaining size:

df
dt

= κ(α − f ) with κ > 0,

which has the general solution:

(2.1)

f (t) = α − (α − β)e−κt.

If the function is used to describe monotonically increasing growth then

α > β > 0.

In this parameterization, α will be the ﬁnal size, β = f (0) is the initial size and κ governs
the rate of growth. Equation 2.1 is generally known as the monomolecular growth model.
Often in growth data, the growth ﬁrst accelerates and then decelerates to a plateau.
This gives rise to the “sigmoid” shaped growth curves. The point of inﬂection is the time
when the growth rate is greatest.

The logistic model has the following diﬀerential equation:

df
dt

κ
α

=

f (α − f ), where κ > 0 and 0 < f < α.

Here the f in the numerator represents the tendency for the tree to grow indeﬁnitely and
the α − f represents the limiting component of the growth. Zeide (1993) shows how most

10

growth equations can be broken up into an expansion and decline component. The general
solution of the logistic model is

(2.2)

α

f (t) =

1 + e−κ(t−γ) , −∞ < t < ∞.

The point of inﬂection occurs at t = γ and the growth curve is symmetrical about this point.

The Richards Model

This restriction of the growth curve being symmetric about the point of inﬂection is not
present in the Richards model (Richards 1959). The diﬀerential equation for this model is
given by:

δ−1

df
dt

=

κ
1 − δ

f

f
α

"(cid:18)

(cid:19)

− 1

,

δ 6= 1,

#

which leads to the model given by:

f (t) = α[1 + (δ − 1)e−κ(t−γ)]1/(1−δ),

δ 6= 1.

This equation has enjoyed extensive use in forest tree growth modeling. However, it has
also been subject to much criticism. Ratowsky (1983) shows that its parameter estimates
are unstable.

The Richards equation has an upper asymptote. Bredenkamp and Gregoire (1988)
note that tree diameter growth can start to increase again after reaching what appears to
be an upper asymptote, due to tree mortality.

The Schnute Model

An equation which is more stable than the Richards model and also allows the possibility
of non-asymptotic growth was introduced by Schnute (1981). Unlike most other growth
models, the Schnute model is based on the acceleration of growth:

The integrated version of the Schnute model is given by:

d2f
dt2 =

k1 +

(cid:18)

k2
f

(cid:19)

df
dt

.

(2.3)

(2.4)

where

f (t) =

1 + (f b
f b
(cid:20)

2 − f b
1 )

1 − e−a(t−τ1)
1 − e−a(τ2−τ1)

1/b

(cid:21)

t = age of interest

τ1 = youngest measured age

τ2 = oldest measured age

f1 = f (τ1)

f2 = f (τ2)

a = constant acceleration in growth rate

b = incremental acceleration in growth rate.

11

In ﬁtting the Schnute model the initial guesses for f1 and f2 are the initial and ﬁnal measured
size values.

2.3.4 Estimation Methods

Usually each growth measurement is assumed to have been drawn from a Normal distribu-
tion:

(2.5)

yi|ti, θ ∼ Normal(f (ti, θ), σ2).

If data, {yi, ti} ≡ {(y1, t1); (y2, t2); . . . ; (yN , tN )}, are available then the maximum likelihood
estimate (mle) of the parameters θ is given by:

θmle = max

p({yi}|{ti}, θ)

= max

exp −

(yi − f (ti, θ))2

N

i=1
X

θ

θ

N

i=1
X

(2.6)

= min

θ

(yi − f (ti, θ))2

i.e. in this case the maximum likelihood parameter estimates are found by minimizing the
mean square error (MSE) of the predicted diameters by iterative numerical methods.

Given θ, the errors, ei = yi − f (ti, θ), are assumed to be independent. Thus, one
diagnostic of the model ﬁt is given by plotting the residuals and seeing if there is any
unusual pattern of runs of positive and negative residuals, (Draper and Smith 1981).

2.4 Modeling of Pinus Roxburghii Data

Falkenhagen (1997) has studied nine diﬀerent growth models for the diameter growth of the
Pinus Roxburghii data discussed in Section 2.2. He found that the Schnute model, equation
(2.4) had the least problems with convergence and gave the overall minimum mean square
error.

Zeide (1993) noted that the diﬀerential form of Schnute’s model (equation (2.3)) does
not provide a good ﬁt for a Norway spruce tree data set. However, as the objective is to ﬁt
the integrated form of Schnute’s model (2.4), this is not strictly relevant.

A good ﬁt is obtained when all the data in each plot’s data set is used (Falkenhagen
1997). Thus the Schnute model adequately interpolates the data. (Falkenhagen 1997) also
found the errors in the interpolation showed little autocorrelation (i.e. there were no unusu-
ally long runs of positive and negative residuals), thus indicating that stochastic analysis
(Section 2.3.2) may be unnecessary. A more diﬃcult problem would be to see how well the
model extrapolates the data. Thinning continued in some cases until the age of 24. It is
pointless trying to extrapolate the tree growth while thinning is still taking place as then
the model would have to predict the occurrence of any future thinning. As only age will
be used as an explanatory variable, this would not be possible. Thus it will be required

12

that the model extrapolate from age 30 years onwards. By which time the tree has resumed
normal growth.

As will be seen in Chapter 6, the Schnute model provides poor extrapolations for some

plots and thus other modeling techniques need to be investigated.

13

Chapter 3

Bayesian Statistics

Probability, then, can be thought of as the mathematical language of uncertainty.

R. L. Winkler

In this report Bayesian Statistics will be used in Neural Network Modeling, see Chapter
4, and in comparing the performance of diﬀerent regression techniques, see Chapter 5. In
this chapter all the Bayesian theory which is relevant to later work will be reviewed. Many
aspects of Bayesian Statistics which will not be relevant to the rest of this report will not
be discussed. Some of the results of examples in this chapter will be relevant to later
developments.

There are many text books on Bayesian Statistics, for example those written by Berger
(1985), Press (1989), Box and Tiao (1992), Bernardo and Smith (1994), Gelman et al. (1995)
and Jaynes (1996). Several, such as the book written by Jaynes (1996), assume very little
statistical training. The books by Box and Tiao (1992) and Jaynes (1996) are more oriented
towards the natural sciences.

3.1 Foundations

Broadly speaking there are two schools of Statistics, Bayesian and Frequentist (also known
as Classical or Orthodox). The Bayesian school is a minority, but has seen rapid growth in
the last few decades.

Frequentists generally only use probabilities to describe the proportion of times an
event will occur in a given population. For example, if a rod is measured, a Frequentist will
not consider its true length as a random variable. However, if there is a whole assembly
line of rods then the length of the diﬀerent rods within the assembly line can be assigned a
random variable. A Classical view of the Bayesian / Frequentist debate is given by Papoulis
(1990).

Bayesians on the other hand use probability to express all types of uncertainty. A
probability of zero corresponds to an impossible event and a probability of one to a certain
event. Probabilities between zero and one express the degree of uncertainty. So in the

14

Bayesian framework it is possible to pose questions such as “What is the probability of a
theory being true?”

In a Bayesian sense, random variables are used to express uncertainty. Probabilities
In Bayesian Statistics, model

can be given for diﬀerent proposed values of the variable.
parameters are treated as random variables.

3.2 The Rules of Probability

A system for dealing with uncertainty that satisﬁes a certain number of reasonable desired
properties, must be consistent with the following two rules (Jaynes 1996):

(3.1)

P (AB|C) = P (A|BC)P (B|C) = P (B|AC)P (A|C).

Product Rule :

Sum Rule :

(3.2)

P (A|B) + P ( ¯A|B) = 1

where A, B and C are propositions, e.g.

A = A measurement of a quantity X will lie somewhere between xl and xu.

B = The samples {x1, x2, . . . , xn} are measurements of X.

C = A Gaussian probability distribution function should be used for X.

The notation P (AB|C ¯D) reads the probability of A and B being true given that C is
true and D is false. A proposition is a statement that can be either true or false. Prior
information will generally be denoted by an I.

Since a continuous variable can take on an inﬁnite number of values, its probability of
being any particular number is inﬁnitely small. Thus when dealing with random variables
it is useful to work with a probability density function (pdf). The pdf for a variable X is
deﬁned as:

(3.3)

p(x|I) ≡

P (X ≤ x|I).

d
dx

Multivariate pdfs are deﬁned in a similar way:

p(x, y|I) ≡

P (X ≤ x, Y ≤ y|I).

∂
∂y

∂
∂x

The pdf, p(x|I), is just a function of x. Note that it could well have a diﬀerent functional
form to p(y|I). To distinguish the functional form, a subscript will be used. E.g. pX (x2|I),
which is just the same function as p(x|I) except with all the x’s replaced by x2’s. A random
variable X has been distinguished from an instance of that variable, x. However, the same
symbol will usually be used for the random variable and for an instance of that variable,
but the meaning should be clear from the context.

15

It follows from the deﬁnition of pdfs, equation (3.3), that they must always be positive.
The probability of a variable taking on a value contained in D′, which is a subset of the
whole domain of the variable, D, is given by

From the sum rule, equation (3.2), it follows that

P (X ∈ D′) =

Zx∈D′ p(x) dx.

P (X ∈ D′) + P (X 6∈ D′) = 1.

From which it follows that

(3.4)

p(x) dx = 1.

Zx∈D

In the above, the probabilities have not been conditioned on any prior information, however
all probabilities are based on some prior information and when it is not explicitly stated, it is
assumed. Jaynes (1996) discussed the importance of bearing in mind the prior information
a probability is based on.

3.3 Bayes’ Rule

Using the product rule, equation (3.1), Bayes’ rule can easily be deduced:

P (A|B) =

P (B|A)P (A)
P (B)

.

Many problems solved by Bayesian analysis take on the following form:

1. Some data x = {x1, . . . , xn} are available.

2. A pdf, p(x|θ) is proposed, where θ = {θ1, θ2}, are a number of unknown model pa-
rameters. This pdf is known as the likelihood. It contains all the information about
how the parameters are related to the data.

3. A prior pdf, p(θ), which reﬂects the available prior information, is chosen.

(3.5)

(3.6)

Writing Bayes rule in terms of the above pdfs, gives:

p(θ|x) =

p(x|θ)p(θ)
p(x)

.

The pdf, p(θ|x) is known as the posterior distribution of θ.

3.4 The Predictive Distribution

The posterior pdf p(θ|x) must be normalized, i.e.

p(θ|x) dθ = 1.

Zθ∈Dθ

16

Using Bayes rule, equation (3.6), in the above equation, it follows that

p(x|θ)p(θ)
p(x)

dθ = 1.

Zθ∈Dθ

From which the marginal pdf, p(x) can be evaluated:

(3.7)

p(x) =

p(x|θ)p(θ) dθ.

Zθ∈Dθ

Note that p(x) depends on the form chosen for the likelihood and the prior. One should
write p(x|I), where the I speciﬁes the functional forms chosen for p(θ|x, I) and p(θ|I). So
given diﬀerent prior information (assumptions), I1 and I2, the functional forms of p(x|I1)
and p(x|I2) can be very diﬀerent.

The pdf, p(x|I), is usually known as the predictive distribution, as it gives the prob-
ability density function of any new measurement of data. When conditioned only on the
prior information, p(x|I) is the prior pdf for the data. To get the pdf of some new data,
xn+1, given some old data {x1, . . . , xn}, the predictive distribution is as follows:

(3.8)

p(xn+1|{x1, . . . , xn}, I) =

p(xn+1|θ, I)p(θ|{x1, . . . , xn}, I) dθ.

Zθ

The pdf, p(x|I) is also referred to as the evidence, (see MacKay 1992a;b). The reason for
this is that it can be used to compare hypotheses. Say you have two hypotheses (theories)
H1 and H2, and some data x. In order to compare the two hypotheses, in light of the data
x = {x1, . . . , xn}, the posterior odds ratio can be evaluated:

P (H1|x, I)
P (H2|x, I)

=

p(x|H1, I)P (H1|I)
p(x|H2, I)P (H2|I)

.

So p(x|H, I) indicates how much the data contribute to the probability of H being true,
i.e. what evidence it provides for H. An interesting example is given in Jeﬀerys and Berger
(1992), where a fudged Newtonian theory and Einstein’s Theory of General Relativity are
compared in this manner.

3.5 Eliminating Nuisance Parameters

If one is interested in all the parameters, θ, then the posterior pdf of equation (3.6) gives all
the available information about θ given the prior information and the data. For instance,
the probability of the parameters being in a particular region D′ is given by

P (θ ∈ D′|x, I) =

Zθ∈D′ p(θ|x, I) dθ.

This will not usually coincide with Frequentist conﬁdence intervals. However, if only a
portion of the parameters, θ1, are of interest and the rest of the parameters, θ2, are nuisance

17

parameters, then the pdf for the parameters of interest can be obtained by

(3.9)

=

p(θ1|θ2, x, I)p(θ2|x, I) dθ2.

p(θ1|x, I) =

p(θ1, θ2|x, I) dθ2

Zθ2∈Dθ2

Zθ2∈Dθ2

This relationship follows from the general form of equation (3.7).

3.6 Prior Probability Density Functions

In this section, methods of choosing the prior p(θ) are discussed. There are many ways of
choosing the prior, and Berger (1985) has given a comprehensive review. Only those that
will be relevant to the problems that will be solved in this research report will be looked at.

3.6.1 Non-Informative Priors

Often in scientiﬁc work, it is considered desirable not to include any information in the prior
pdf, p(θ). The interest is in what the data imply about p(θ|x). Also there may simply be
no useful prior information about the values of the parameters.

From Bayes’ rule,

p(θ|x) ∝ p(θ)p(x|θ).

The posterior is only eﬀected by the data via the likelihood function, p(x|θ). So if one
does not in any way want to distort the eﬀect of the likelihood, the prior should be as ﬂat
as possible in the areas where the likelihood has an appreciable value and not have any
relatively large ﬂuctuations outside that area. For instance, if the prior had a peak in the
tails of the likelihood, that could lead to an appreciable peak in the posterior. Also, if
the prior was varying rapidly across the area where the likelihood had most of its mass,
this would distort the shape of the likelihood. So, qualitatively speaking, non-informative
priors should be as broad and featureless as possible. For a more detailed discussion on the
qualities a prior should have see Berger (1985).

In cases where little or no prior information will be used, many Orthodox Statisticians
In the Maximum Likelihood method,

argue that Bayesian methods are not appropriate.
parameters are chosen which maximize the probability of the data, e.g.

(3.10)

(3.11)

However, this is the same as making a maximum a posterior (MAP) estimate and choosing
a uniform prior for the parameters. The uniform prior is given by

where a is some constant. This prior cannot be normalized as in equation (3.4), it is therefore
said to be improper. A uniform prior can be thought of as the limit of a Gaussian prior as

θmle = max

θ

p(x|θ).

p(θ) = a

18

the variance goes to inﬁnity. Improper priors can still lead to proper posteriors:

(3.12)

p(θ|x) =

p(x|θ)
p(x|θ) dθ

where the constant, a, cancels out in the denominator and numerator.

R

In the Bayesian approach, equation (3.12), the whole pdf of θ is obtained. To obtain
a point estimate, as in the Maximum Likelihood case, equation (3.10), a loss function is
needed, see Section 3.7.

The Problem with Uniform Priors.

One diﬃculty in assuming that p(θ) is uniform, is that if some one to one function of θ is of
interest, φ = f (θ), then p(φ) will not in general be uniform. In order to determine the pdf
of a function of a parameter, the following formula can be used (Papoulis 1990):

(3.13)

pφ(φ) = pθ(φ)

where f −1(φ) denotes the inverse function of f (φ). For clarity, subscripts are being used to
distinguish the diﬀerent functional forms of p(·). For example, if φ = θ−1 then

df −1(φ)
dφ

,

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

pφ(φ) = φ−2pθ(φ).

So, if pθ(θ) = 1, then pφ(φ) = φ−2. Thus, by assuming complete uncertainty about where θ
is, it is assumed that θ−1 is more likely to be closer to zero than further away. If, instead,
θ−1 was initially the parameter of interest, then the reverse would hold. Thus, the priors
assigned to all the diﬀerent functions of θ are completely determined by which function of
θ the uniform prior is assigned to. This is undesirable, since the choice of which function of
θ to assign the uniform prior to is fairly arbitrary.

Jeﬀreys’ Priors

As soon as a prior is assigned to some function of θ, this automatically implies what priors
are assigned to all other one to one functions of θ, via equation (3.13). To make this whole
family of priors invariant to which function of θ was initially selected, the Jeﬀreys’ prior
can be used:

(3.14)

p(θ) ∝ [J (θ)]1/2,

where J (θ) is the Fisher Information for θ (Bernardo and Smith 1994):

(3.15)

J (θ) = −

p(x|θ) dx

d2 log(p(x|θ))
dθ2
d2 log(p(x|θ))
dθ2

Zx
= −E

(cid:20)

θ

,

(cid:21)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

19

where E[·|·] is the conditional expectation. Once the Jeﬀreys’ prior has been assigned to θ,
then any one to one function of θ, such as φ = f (θ) is also assigned a Jeﬀreys’ prior:

[pJ (φ)]2 ∝ J (φ)

= −E

= −E

d2 log p(x|φ)
dφ2

φ

(cid:21)

(cid:12)
(cid:12)
d2 log p(x|θ = f −1(φ))
(cid:12)
(cid:12)
dθ2

(cid:20)

"

by defn. equation (3.14)

by equation (3.15)

φ

#

dθ
dφ

(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

by the chain rule

by equation (3.15) ,

= J (θ)

2

dθ
dφ

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

from which it follows that

pJ (φ) = pJ (θ)

dθ
dφ

,

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

where the J subscript is used to indicate that the prior was formed by Jeﬀreys’ procedure,
equation (3.14). As can be seen from equation (3.13), this is how pdfs should transform
when a function of a parameter is taken. Thus, by choosing Jeﬀreys’ prior for one function
of θ, all other functions of θ are assigned their own Jeﬀreys’ priors.

Box and Tiao (1992) and Bernardo and Smith (1994) give further justiﬁcations for

assigning Jeﬀreys’ priors.

As an example, if the likelihood is a Gaussian, p(x|θ) = Normal(µ, σ2), and σ is
assumed known, then using equation (3.14) it can be seen that the Jeﬀreys’ prior for µ
is p(µ) = 1.
If instead the mean, µ, is assumed known then the Jeﬀreys’ prior for σ is
p(σ) = σ−1.

Jeﬀreys’ prior can also be extended to multi-parameter problems:

where |J|

is the determinant of the Fisher information matrix deﬁned by:

(3.16)

(3.17)

p(θ) = |J| 1/2

∂2p(θ|x)
∂θi∂θj

dx,

Ji,j =

Zx

where θi is the ith parameter of the vector of parameters θ.

There are cases when Jeﬀreys’ priors do not give good results for multi-parameter
models. For instance in the case of a Gaussian distribution, p(x|θ) = Normal(µ, σ2), where
both µ and σ are unknown, the Jeﬀreys’ prior is p(µ, σ) = 1/σ2. This leads to a posterior
with undesirable properties, as shown on pg. 361 of the book by Bernardo and Smith (1994).
One ad-hoc procedure that has been proposed for overcoming such problems, is to
assume some of the parameters are a priori independent. So in the case of the prior for
p(µ, σ), for a normal likelihood:

p(µ, σ) = p(µ|σ)p(σ)

= p(µ)p(σ)

= 1/σ

20

where the single parameter Jeﬀreys’ priors, equation (3.14), are used for p(µ) and p(σ). This
prior leads to a posterior with more acceptable properties.

Another approach called reference priors has been developed, (Bernardo and Smith
1994), which reduces to a Jeﬀreys’ prior in the single continuous parameter case and does
not have some of the problems associated with Jeﬀreys priors in the multi-parameter case.
However, reference priors are beyond the scope of this report.

3.6.2 Conjugate Priors

In general, the posterior, p(θ|x), and the evidence, p(x), are not easy to evaluate. Thus, it
can be desirable to choose the prior, p(θ), such that the necessary calculations will be made
easier. Usually any prior knowledge that is available is of a vague form and so the form
of the prior pdf is fairly arbitrary, provided its properties are consistent with the available
prior knowledge.

One suggestion is to ﬁnd a prior pdf which when combined with the likelihood function
leads to a posterior pdf with the same form as the prior pdf. These are called conjugate
priors. They have the added advantage that they lead to a more interpretable posterior.

Example 3.1 Consider the case where x is normally distributed with a known mean µ and
a standard deviation of σ, i.e. x ∼ Normal(µ, σ2). Instead of working with the standard
deviation, the precision τ = 1/σ2 will be used.
It doesn’t matter what function of the
parameter is used because one can always transform back to the function of interest using
equation (3.13). If x consists of N measurements, then the likelihood is given by:

p(x|µ, σ) = p(x1, x2, . . . , xN |µ, σ)

N

p(xi|µ, σ)

=

=

i=1
Y
2πσ2

(cid:0)

(cid:1)

−N/2

exp

−

 

i
X

(xi − µ)2/(2σ2)

,

!

where in equation (3.18) it is assumed that each measurement is independent of every other
measurement, given that µ and σ are known. Expressing the likelihood in terms of the
precision, τ , gives:

p(x|µ, τ ) ∝ τ N/2 exp

−τ

(xi − µ)2/2

∝ τ N/2 exp

 
i
X
−τ N s2/2

!

,

(cid:1)

s2 =

1
N

(xi − µ)2

(cid:0)

21

i
X
is the sample variance. Note that any constants of proportionality in the likelihood are not
necessary because the posterior will be normalized at a later stage anyway. If the functional

(3.18)

(3.19)

where

(3.20)

form of the pdf in equation (3.19) is looked at with τ as the variable and everything else
as constants, then it is a Gamma distribution in τ . Assume the prior for τ is a Gamma
distribution:

p(τ |α, ω) =

(α/2ω)α/2
Γ(α/2)

τ α/2−1 exp(−τ α/(2ω))I(0,∞)(τ ),

I(0,∞)(τ ) =

1,
0,

τ ∈ (0, ∞)
τ 6∈ (0, ∞)

(cid:26)

ensures the probability is only non-zero for positive values of τ . The parameters α and ω
must satisfy α > 0 and ω > 0. The mean of the Gamma distribution is given by

and the variance is given by

E(τ |α, ω) = ω

Var(τ |α, ω) = 2ω2/α.

(3.21)

where

(3.22)

(3.23)

(3.24)

The parameters α and ω can be chosen to correspond to the desired prior mean and variance.
Using equation (3.21) for the prior, the posterior of τ is given by:

(3.25)

p(τ |x, µ, α, ω) ∝ τ (N +α−2)/2 exp

−

τ (α/ω + N s2)

.

1
2

(cid:18)

(cid:19)

The posterior is also a Gamma pdf. Thus equation (3.21) is a conjugate prior to the
likelihood given in equation (3.19). One advantage of conjugate priors is that it is easy to
interpret the role played by the prior in the posterior. As can be seen in equation (3.25),
α plays the same role as N and 1/ω plays the same role as s2. Thus one could interpret
the prior, p(τ |α, ω), as being equivalent to α measurements which have a sample variance
of 1/ω. From which it follows that a natural interpretation for 1/ω is the prior variance of
x.

In Section 4.7 of Chapter 4 a Gamma prior will be used for the precision of some model

parameters and model noise.

3.6.3 Empirical Bayes

In empirical Bayes methods the data are used in estimating the prior. In Section 3.4 it was
shown how the marginal distribution of the data, p(x|H, I), contributes to the probability
of the hypothesis being true:

p(H|x, I) ∝ p(H|I)p(x|H, I).

The hypothesis, H, consists of two components: the likelihood, L, and the prior, π. The
type II maximum likelihood (ML-II) prior is obtained by maximizing the likelihood of the
prior:

π = max

p(x|π, L, I).

π

22

Usually the maximization is done over some restricted family of priors. Using ML-II priors
violates Bayes’ rule since the prior is no longer independent of the data. However they can
be used as an approximation to a true Bayesian approach. Berger (1985) elaborates on this
distinction.

Example 3.2 Given the prior, p(θ|τ ) = Normal(0, 1/τ ), then a suitable value of τ has to
be chosen. Using the ML-II method,

(3.26)

τ = max

p(x|τ, I)

τ

= max
τ

Zθ

p(x|θ, I)p(θ|τ, I) dθ.

Parameters, like τ , which determine the prior distribution are known as hyperparameters.

One of the problems with the ML-II method is that it does not acknowledge any
uncertainty there may be in choosing the hyperparameters of a prior distribution. In the
next section it will be shown how this additional uncertainty can be included.

3.6.4 Hierarchical Priors

Given the functional form for a prior distribution, p(θ|τ, I) without known values for the
hyperparameters, τ , then a prior can be assigned to τ which reﬂects any uncertainty about
its value.

Example 3.3 Using the same prior as in Example 3.2, but instead of assigning the ML-II
value for τ , a prior is assigned to τ . Choosing a conjugate prior gives

p(τ |I) = Gamma(α, ω).

Values now have to be assigned for α and ω which reﬂect the prior uncertainty in τ .

The following derivation shows the relationship between the hierarchical and ML-II

priors:

(3.27)

p(θ|x) =

p(θ, τ |x) dτ

=

=

Zτ

Zτ

Zτ

p(θ|τ, x)p(τ |x) dτ

p(θ|τ, x)

p(τ )p(x|τ )
p(x)

dτ.

p(x|τ ) ≈ cδ(τ − τmle),

23

From which can be seen that the ML-II method is equivalent to making the following
approximation:

where τmle is the maximum likelihood estimate of τ and c = p(τmle)/p(x) is a scaling factor.
Thus the ML-II method only uses the maximum of the likelihood, p(x|τ ), while hierarchical
priors make use of the whole likelihood function.

It is always possible to integrate out the hierarchical prior to get a single level prior:

p(θ) =

p(θ|τ )p(τ ) dτ.

Zτ

One advantage of using hierarchical priors is that they generally are equivalent to single
level priors which have very ﬂat tails. This means they are robust, i.e. the ﬁnal posterior
does not depend strongly on the precise form, e.g. the mean and variance, of the hyperprior
(Berger 1985). So the ﬁnal result should not be too sensitive to the values chosen for α and
ω in Example 3.3.

3.6.5 Exchangeable Parameter Priors

Another use for hierarchical priors is when one has several parameters which are exchange-
able. By exchangeable it is meant that one has no prior knowledge for distinguishing or
grouping one or more of the parameters from the others. Probabilistically, this can be rep-
resented as the prior, p(θ1, θ2, . . . , θN ), being invariant to permutations of the parameters
(Gelman et al. 1995). The simplest form of an exchangeable distribution is to have each
parameter, θi, independently and identically drawn from a distribution which has hyperpa-
rameters τ :

(3.28)

N

p(θ|τ ) =

p(θi|τ ).

i=1
Y
In general the hyperparameter τ is not known and so it is necessary to integrate over the
uncertainty in τ :

p(θ) =

p(θi|τ )p(τ ) dτ,

N

Zτ

i=1
Y

where p(τ ) is a hierarchical prior. After integrating out the hyperparameter τ , the param-
eters in p(θ) will not in general be independent, i.e.

p(θi|θ1, . . . , θi−1, θi+1, . . . , θN ) 6= p(θi).

This provides a good remedy to the problem of overﬁtting, which will be discussed in Section
4.5 of Chapter 4.

Example 3.4 Consider the weighted sum,

y(t) =

uifi(t) + ǫ

i
X

where ǫ is the component of y(t) which is not explained by t, otherwise known as the noise.
If the prior values of fi(t) are independent of i then the weights ui can be modeled as
exchangeable. Therefore the posterior pdf is given by:

p(θ|{y, t}) =

p(θ|{y, t}, τ )p(τ |{y, t}) dτ.

Zτ

Since τ will determine the dependence between the weights, and τ will be determined by the
data through p(τ |{y, t}), it follows that the dependence between the weights is determined
by the data.

24

3.7 Loss Functions

Generally a Bayesian analysis will result in a posterior pdf, either for a parameter of interest
or for a future data value. It may be desirable to just report a single guess for the parameter
rather than the whole posterior pdf. In which case it is necessary to decide which value to
report. There is an extensive Bayesian theory on how to make these decisions (Berger 1985).
In Bayesian decision theory a loss is associated with any decision. For instance, if one
is trying to guess the value of some parameter θ, then the loss associated with a guess, θ∗, is
a function, l(θ, θ∗). There are many possible choices for l(·, ·) depending on the application.
A common choice is the square error loss function:

Another common choice is to use the absolute error. In Bayesian decision theory the opti-
mum decision is given by choosing the value, θ∗, which minimizes the expected loss:

l(θ, θ∗) = (θ − θ∗)2.

θ∗ = min

θ∗ E[l(θ, θ∗)].

θ∗ = min

θ∗ E[(θ − θ∗)2]

(θ − θ∗)2p(θ) dθ

= min
θ∗

Zθ

(θ − θ∗)2p(θ) dθ = 0

Zθ
(θ − θ∗)p(θ) dθ = 0

∂
∂θ∗

Zθ

θ∗ =

θp(θ) dθ.

Zθ

For the square error loss function:

from which it follows:

(3.29)

Thus when a square error loss function is used, the optimum value to choose is the posterior
mean of the parameter.

The zero-one loss function, is zero if the guess is correct, θ∗ = θ, and one otherwise.
Its minimum expected loss is evaluated by setting θ∗ = maxθ p(θ|x), i.e. the maximum a
posteriori value. It follows that the maximum likelihood method is a special case of Bayesian
estimation, with uniform priors and a zero-one loss function. It seems advantageous that the
Bayesian approach makes use of the whole likelihood function when making point estimates,
while the Frequentist approach only uses the maximum of the likelihood function.

3.8 Bayesian Computation

As has been shown, many Bayesian calculations involve solving integrals, for example:

25

1. Obtaining posterior pdfs can involve integrating out nuisance parameters (see Section

3.5), e.g.

(3.30)

p(τ |x) =

p(τ, γ|x) dγ,

where γ could be one or more nuisance parameters.

2. To obtain point estimates, moments of functions of a parameter need to be found

(Section 3.7), e.g.

(3.31)

f ∗(θ) =

f (θ)p(θ|x) dθ

where f ∗(θ) is the best point estimate for a function f (θ), using the square error loss
function.

It often happens that these integrals are not analytically tractable. In such cases, numerical
approximations have to be resorted to.
If the integral is of low dimension then numeri-
cal quadrature techniques can be used. However, for high dimension integrals, numerical
quadrature is too time consuming due to the curse of dimensionality , i.e. the computation
time increases exponentially with dimension (Evans and Swartz 1995). In order to approx-
imate high dimensional integrals, numerical methods which make use of the probabilistic
structure of the integrals are employed.

3.8.1 Monte Carlo Integration

Equation (3.31) is the mean value of the function f (θ) with respect to the pdf p(θ|x). One
way of approximating a mean value, is to take samples from the distribution p(θ|x) and
then work out the sample mean of the function of interest, i.e.

f (θ)p(θ|x) dθ ≈

f (θ(i))

Zθ

1
N

N

i=1
X

where the θ(i) are drawn from the pdf p(θ|x). Here the superscript is being used to denote
the sample number, e.g. θ(2) is the second sample. As the number of samples, N , increases
the more accurate this approximation will be.

To approximate the integral in equation (3.30), samples can be drawn from p(τ, γ|x).
Each of these samples will contain values for τ and γ. To get samples for p(τ |x), one just
discards the γ values. Although, this procedure does not give an analytical expression for
p(τ |x), the samples will allow any quantities such as moments, quantiles, etc. of p(τ |x) to
be approximated.

In order to employ these approximation methods, it is necessary to be able to draw
samples from pdfs such as p(θ|x). For simple distributions, such as Normal and Gamma,
there are standard routines for eﬃciently drawing samples. For example many computer
programs have commands for generating univariate normal distributions (Gelman et al.
1995). However, for more complicated distributions, it is often necessary to resort to Markov
Chain techniques.

Zγ

Zθ

26

3.8.2 Markov Chains

Gilks et al. (1996) give a comprehensive treatment of Markov chains in Monte Carlo inte-
gration. Markov chains are a sequence of values θi where

p(θ(i)|θ(i−1), θ(i−2), . . . , θ(0)) = p(θ(i)|θ(i−1)),

i.e. the pdf of any value in the Markov chain depends only on the previous value.

Markov chains can be used to simulate the drawing of samples from a pdf. If a Markov
chain can be constructed so as its values converge to samples from a pdf of interest, say
p(θ), then it can be used in Monte Carlo integration. By deﬁnition the values generated
by a Markov Chain are not independent. This usually means more samples are needed to
obtain the same accuracy as would be obtained with independent samples (Neal 1996).

Markov chains can take a number of iterations before they start to converge to the
probability distribution of interest. Thus it is common practice to discard a certain number
of the initial iterations. Deciding how many samples to take from a Markov chain is often a
matter of practical expediency. A number of convergence criteria are given by Cowles and
Carlin (1995). Some common techniques for constructing Markov chains are now discussed.

Gibbs Sampling

Although it might not be possible to sample directly from a pdf, p(θ), it might be possible
to sample from a subset of θ based on the rest of θ, i.e. draw θi from p(θi|θ−i), where θ−i is
the set of parameters θ without the subset θi. If the parameters are split up into s subsets,
then the Gibbs sampling algorithm proceeds as follows:

1. Draw θ(i+1)

from p(θ1|θ(i)

−1).

2. Draw θ(i+1)

from p(θ2|θ(i)

−1,−2, θ(i+1)

1

).

1

2

3. · · ·

4. Draw θ(i+1)

s

from p(θs|θ(i+1)

−s

).

5. Let θ(i+1) = {θ(i+1)

, . . . , θ(i+1)

s

}.

1

6. Let i = i + 1.

7. Goto 1.

Then, the draws of θi can be considered approximate draws from p(θ).

It may happen that it is not possible to draw from any of the conditional distributions,

in which case Gibbs sampling cannot be used.

The Metropolis Algorithm

In the Metropolis algorithm there is a proposal distribution, pt(θ(i+1)|θ(i)). The pdf pt(θ(i+1)|θ(i))
does not necessarily have to have any relationship with p(θ), but must satisfy

pt(θ(i+1)|θ(i)) = pt(θ(i)|θ(i+1)).

27

One example could be a Gaussian distribution whose mean is centered on θi.

An iteration of the Metropolis algorithm proceeds as follows:

1. Draw ˆθ from pt(θ(i+1)|θ(i)).

2. Set

θ(i+1) =

(

ˆθ
θ(i)

with probability min(p(ˆθ)/p(θ), 1)
otherwise.

The values of θ(i) will then be approximate samples from p(θ).

If the proposal distribution is centered on θ(i) then the Metropolis algorithm can be
seen as proposing a new value θ(i+1) = θ(i) + ǫ, where ǫ is a random vector in the space of
θ. Thus the values of θ(i) will follow a random walk.

An analogy can be made by considering the p(θ) to be a surface where the areas of
high probability are low and those of low probability high on the surface. If the position of
a ball on the surface represents θ then the Metropolis algorithm can be seen as randomly
shaking the surface. Sometimes the shakes will move the ball uphill but usually downhill
towards the areas of high probability. The position of the ball at regular intervals can then
represent the samples of θ.

This random walk behaviour can make the Metropolis algorithm ineﬃcient, especially

if some of the parameters in θ are correlated.

28

Chapter 4

Artiﬁcial Neural Networks

4.1

Introduction

The name artiﬁcial neural networks (NNs) covers a broad range of computational methods.
There is a whole branch of the subject, which tries to model real biological neural networks,
which will not be discussed in this report. A common feature of artiﬁcial NNs is that they
consist of many interconnected simple processing units. The basic philosophy behind many
artiﬁcial NNs is to use an algorithm that mimics the methods of information processing of
a biological NN .

NNs are usually used in classiﬁcation problems. Other applications include regression,

such as time series modeling (Weigend et al. 1991), and control (Miller III et al. 1990).

This report will be concerned only with feed forward multilayer perceptron artiﬁcial

NNs which are, arguably, the most popular type of NN.

There is a wide range of literature in the NN ﬁeld. The inﬂuential historical texts
include Minsky and Papart (1969; 1990) and Rumelhart et al. (1986). A good introductory
exposition is given by Haykin (1994). A more advanced treatment can be found in Kung
(1993). Statistical perspectives on NNs can be found in Ripley (1994) and Cheng and
Titterington (1994).

29

4.2 Multilayer Perceptron Structure

The multilayer perceptron neural network consists of layers of neurons. Figure 4.1 shows
a graphical representation. The ﬁrst layer is known as the input layer and the last as the
output layer. The other layers are known as hidden layers. The NN in Figure 4.1 has only
one hidden layer. This is the most common choice.

Neurons are connected from the left layers to the right layers. The number of neurons
in the input and output layers are dictated by the function being modeled. The number
of hidden layers and the number of neurons in each hidden layer is a choice made by the
modeler. The general function for a one hidden layer perceptron NN is given by

(4.1)

fi(x) = φo

vij φh

ujkxk + aj

+

Nh

p





j=1
X

 

Xk=1

p

Xl

!

.

wilxl + bi


The meaning of symbols in this equation are:

x : A p dimensional input into the NN.

The kth dimension of x is denoted by xk.

: The output of output neuron i.
: The activation function of the output neurons.
: The activation function of hidden layer neurons.
: The number of hidden layer neurons.
: The weight of the connection from hidden layer neuron j

(4.2)

to output layer neuron i.

: The weight of the connection from input layer neuron k to

: The weight of the connection from input layer neuron l to

hidden layer neuron j.

output layer neuron i.

: The weight of the connection from the hidden layer

bias neuron to hidden layer neuron k.

: The weight of the connection from the output layer

bias neuron to output layer neuron i.

fi(.)
φo
φh
Nh
vij

ujk

wil

ak

bi

In Figure 4.1 the bias neurons are represented as squares, they are like input neurons
with a constant +1 input. The NN in Figure 4.1 does not have any input to output layer
connections. Usually the hidden layer activation functions are chosen to be sigmoid logistic
or equivelantly, in terms of function approximation abilities, hyperbolic tangent functions.
The output layer activation functions are generally chosen to be the identity functions in
the case of function approximation. The input to output weights are often ﬁxed at zero, i.e.
they are deleted. When the output is one dimensional, only one output neuron is required.
This leads to a subset of the family of functions in equation (4.1):

(4.3)

f (x) =

vj tanh

ujkxk + aj

+ b

!

Nh

j=1
X

p

 

Xk=1

30

x1

......................................

....................................................................

......................................

x2

......................................

.....................................................................

......................................
u32

+1

......................................

......................................

u21

u11

u31
u12

.........................................................................................................................................................................................................................................................................................................................
....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.........................................................................................................................................................................................................................................................................................................................
.........................................................................................................................................................................................................................................................................................................................

..................................................................................................................................................................................................
..................................................................................................................................................................................................
..................................................................................................................................................................................................
..................................................................................................................................................................................................
..................................................................................................................................................................................................

u22

a1

a2

a3

......................................

....................................................................

......................................

......................................

....................................................................

......................................

......................................

....................................................................

......................................

v21

v12

v22

v11

..................................................................................................................................................................................................
..................................................................................................................................................................................................
..................................................................................................................................................................................................
..................................................................................................................................................................................................

.........................................................................................................................................................................................................................................................................................................................
....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.........................................................................................................................................................................................................................................................................................................................
.........................................................................................................................................................................................................................................................................................................................

v23
b1

b2

v13

+1

......................................

......................................

......................................

....................................................................

......................................

f1(x)

......................................

.....................................................................

......................................

f2(x)

Figure 4.1: A feed forward multilayer perceptron artiﬁcial neural network (NN). It has two
input layer neurons, one hidden layer with three neurons and an output layer with two neurons.
The squares represent the bias neurons. See the accompanying text for an explanation of the
notation.

where unnecessary subscripts have been dropped. The tanh function is linearly related to
the sigmoid logistic function, so in terms of function approximation it does not matter which
is used. Neal (1996) prefers the numerical properties of the tanh parameterization. For the
rest of the report, the family represented by equation (4.3) will be used. Any extensions to
multidimensional output NNs is usually straightforward.

4.3 Nonlinear Regression

The purpose of NNs in function approximation is to approximate some nonlinear mapping,
g(x). The range of functions which can be approximated by NNs was examined by Cybenko
(1989). He showed that one hidden layer NNs can approximate any continuous multivariate
function with support in the unit hypercube. That is with suﬃciently many hidden layers,
the error of approximation can be made arbitrarily small. Cybenko’s result only provides
an existence proof. It does not specify how to construct the network, nor how the error of
approximation is related to the number of hidden layer units.

When the function to be approximated has noise added to it, then the problem becomes
one of nonlinear regression. For an additive noise model, the corrupted function, y(x), is
given by

where g(x) is the original function and ǫ is a random noise component. The NN needs to

y(x) = g(x) + ǫ

31

approximate g(x) given y(x).

As can be seen from equation (4.1), NNs are just a family of nonlinear equations.
The architecture of the NN determines the precise form of the equation used. The main
user adjustable choice is the number of hidden layer units, Nh. NNs are often referred to
as ‘nonparametric’ as the values of the weights in equation (4.1) generally contain little
interpretable information.

4.4 Multilayer Perceptron Training

In order to determine the weights of the NN, training data are required. Denote N samples
of the input, output variables by

D = (x(i), y(i)),

i = 1, . . . , N

were a superscript is being used to denote the data sample number so as not to get confused
with the data dimension, which is denoted by a subscript in this chapter. Then the weights

θ = (u, v, a, b)

= (ujk, vj, aj, b)

j = 1 . . . Nh, k = 1 . . . p

can be inferred. The weights are usually chosen by least squares:

where θ∗ are the optimum weights and E(D, θ) is the sum of squares error (SSE):

(4.4)

(4.5)

θ∗ = min

E(D, θ),

θ

E(D, θ) =

(f (x(i), θ) − y(i))2.

N

i=1
X

This is equivalent to a maximum likelihood solution when the noise is assumed to be iden-
tically and independently drawn from a zero mean Gaussian distribution. From a Bayesian
perspective, it is a maximum a posteriori estimation with uniform priors for θ.

Usually, standard gradient descent is used to perform the minimization in equation

(4.4). The weights are randomly initialized and then updated

(4.6)

θ(j+1)
i

= θ(j)

i + δ

∂
∂θi

E(D, θ)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

θ=θ(j)

where δ is known as the learning rate and is chosen by the user. The jth iterations weights
are denoted by θ(j) and the ith component of the weights is denoted by θi. The derivatives
of the weights in equation (4.6) can be recursively calculated from output to input by using
the chain rule, a procedure known as back propagation (Rumelhart et al. 1986).

The weights are updated until some convergence criteria are met. The SSE, the rate
of change in the SSE and the number of iterations can all be used. Other techniques for
deciding when to stop training will be discussed in Section 4.6 of this chapter.

32

Gradient based techniques, such as equation (4.6), can be prone to being trapped in
local minima. Simulated annealing can be used to circumvent this problem (Kirpatrick et al.
1983).

Another technique which is used in order to try avoid local minima and to try to

decrease training time is to add a momentum term to equation (4.6):

θ(j+1)
i

= θ(j)

i + δ

E(D, θ)
(cid:12)
(cid:12)
(cid:12)
where α is a constant set by the user. The consequences of adding momentum have been
(cid:12)
investigated by Phansalkar and Sastry (1994).

E(D, θ)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

θ=θ(j−1)

θ=θ(j)

+ α

∂
∂θi

∂
∂θi

When there is a large number of redundant training samples, the pattern update method

can speed up convergence:

θ(j+1)
i

= θ(j)

i + δ

(f (x(k), θ) − y(k))2

.

∂
∂θi

θ=θ(j)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

As the iterations progress, the training samples are cycled through, with k = 1, . . . , N . See
Haykin (1994) for further discussion.

There have been many other techniques for improving the time it takes to train a
NN (Kung 1993). Second order methods such as conjugate gradients have been found to
decrease convergence time (Ripley 1994). However, Saarinen et al. (1993) show that the
Jacobian matrix of E with respect to the NN weights is generally rank deﬁcient making the
NN training numerically ill-conditioned. This can be the cause of the long training times
that are usually experienced.

33

4.5 The Bias/Variance Dilemma

In NN modeling a choice of the number of hidden units has to be made. The more hidden
units used, the better the NN will be able to ﬁt the data. However, it has been found (see
Haykin (1994) for an example) that the generalization ability of NN often starts to worsen
once too many hidden layer neurons are added. This phenomenon is known as overﬁtting.
It is sometimes described as ﬁtting some of the noise as well as the signal.

Geman et al. (1992) shows how any regression estimate can be broken up into a bias
and variance component. Some of their results are summarized below. The NN function’s
output, f (x), will depend on the possibly multivariate input, x. The true output, y, shall
be considered univariate. It will be assumed that the data samples (x, y) are drawn from a
multivariate distribution, p(x, y).

A reasonable measure of how well the NN predicts y, is the expected square error for

a ﬁxed x:

E[(y − f (x))2| x] =

(y − f (x, D))2p(y| x) dy

Zy

where the integral is taken over all possible values of y. The expected square error can be
decomposed as follows:

(4.7)

E[(y − f (x))2| x] = E[((y − E[y| x]) + (E[y| x] − f (x)))2| x]
= E[(y − E[y| x])2| x] + (E[y| x] − f (x))2

+ 2E[(y − E[y| x])| x] · (E[y| x] − f (x))
= E[(y − E[y| x])2| x] + (E[y| x] − f (x))2

+ 2(E[y| x] − E[y| x]) · (E[y| x] − f (x))
= E[(y − E[y| x])2| x] + (E[y| x] − f (x))2.

The ﬁrst term of the sum, E[(y − E[y| x])2| x], is the variance of y for a particular x and
is unrelated to the NN prediction. Thus, the second term is the appropriate measure to
evaluate the NN performance. The form of the NN function will depend on the training
data, D. This shall be indicated speciﬁcally by writing the function as f (x, D). Only for
some training data sets will the NN give a good approximation of y. To get a training data
set independent evaluation of how good f (x, D) is as an approximater, the expectation over
all possible training data sets (of a particular size) of the squared error can be examined:

ED[(f (x, D) − E[y| x])2].

34

The bias / variance decomposition due to Geman et al. (1992) is as follows:

ED[(f (x, D) − E[y| x])2]

= ED[((f (x, D) − ED[f (x, D)]) + (ED[f (x, D)] − E[y| x]))2]
= ED[(f (x, D) − ED[f (x, D)])2] + ED[(ED[f (x, D)] − E[y| x])2]
+2ED[(f (x, D) − ED[f (x, D)])(ED[f (x, D)] − E[y| x])]
= ED[(f (x, D) − ED[f (x, D)])2] + (ED[f (x, D)] − E[y| x]2
+2ED[f (x, D) − ED[f (x, D)]] · (ED[f (x, D)] − E[y| x])

= (ED[f (x, D)] − E[y| x])2 bias

+ED[(f (x, D) − ED[f (x, D)])2] variance.

If the expectation of the NN prediction is diﬀerent from the expectation of y given x then
it is said to be biased. An unbiased function may still have a large mean squared error by
having a high variance, i.e. by being very sensitive to the training data.

By increasing the number of hidden layer neurons, the bias is generally decreased
while the variance is increased. Therefore, choosing the number of hidden layers is a trade-
oﬀ between increasing the variance and decreasing the bias. The variance can be decreased
by introducing more training samples. Thus, the more training samples available, the more
hidden layer neurons can be introduced to decrease the bias.

4.6 Methods of Avoiding Overﬁtting

A method of determining the optimum number of hidden layers to use is to partition the
data into a test and training set. NNs with diﬀerent numbers of hidden units are trained on
the training data. The error that each NN makes on the test set is evaluated. The number
of hidden units that gave the smallest error is then taken as the correct choice. The NN
with that number of hidden layer units can then be retrained on the whole data set. The
drawback of this technique is that it makes ineﬃcient use of the available data. Also, the
user has to decide which data to set aside as a training set and which data to use as a test
set.

Automatic pruning techniques have also been developed for NNs (Le Cun et al. 1990,
Hassibi and Stork 1993). Initially a large number of hidden units are chosen and then as
training progresses an attempt is made to determine which hidden units are redundant and
remove them.

An alternative to ﬁnding the optimum number of hidden units is to choose a large
number of hidden units and then regularize the solution. Two widely used techniques for
doing this are weight decay and early stopping.

In early stopping, a portion of the data is set aside as a test set. As training progresses
the error on the test set is monitored. When the test set error reaches a minimum, train-
ing is stopped. Although early stopping is quite commonly used, it has little theoretical
justiﬁcation.

Weight decay on the other hand is a utilization of the general statistical procedure of
regularization. Instead of minimizing the sum of squared errors (SSE), as in equation (4.5),

35

a regularization term is also included:

(4.8)

E(D, θ) =

(f (x(i), θ) − y(i))2 + α

N

i=1
X

θ2
j

Nθ

j=1
X

where the larger α is the more ‘smoothing’ is performed. Other regularization functions
such as the ﬁrst or second derivatives of the NN with respect to the weights can also be
used. The optimum value of α can also be chosen by setting aside a test set.

4.7 Bayesian Artiﬁcial Neural Networks

In the previous sections a maximum likelihood solution to the learning problem was dis-
cussed. Several Bayesian approaches have also been suggested (Buntine and Weigend 1991,
MacKay 1992a, Sarle 1995, Neal 1996). A good introductory overview is given by Bishop
(1995).

As discussed in Chapter 3, when predicting a new output, y(N +1), given the N input
output training set pairs D and input x(N +1), a probability distribution can be obtained by
integrating over the model parameters:

p(y(N +1)| D, x(N +1)) =

p(y(N +1)| θ, x(N +1))p(θ| D)dθ.

Zθ

Zθ

Zθ

Using Bayes rule, the posterior of the parameters can be expressed in terms of its likelihood
and prior:

p(y(N +1)| D, x(N +1)) ∝

p(y(N +1)| θ, x(N +1))p(D| θ)p(θ)dθ.

To obtain a point estimate for y(N +1), a loss function has to be assigned. As discussed
in Section 3.7 of Chapter 3, assigning a mean square error loss function leads to a point
estimate given by the mean of the NN output:

(4.9)

ˆy(n+1) =

f (x(N +1), θ)p(θ| D) dθ.

Similarly, an absolute error loss function leads to the point estimate being given by the
median of p(y(N +1)| D, x(N +1)). Credibility intervals can be obtained from percentiles of
p(y(N +1)| D, x(N +1)).

4.7.1 Neural Network Priors

MacKay (1992a) suggested zero mean Gaussian based priors for the network weights:

p(θ) = p(u)p(v)p(a)p(b)

= p(v)p(a)p(b)

p(uk)

p

Yk=1

36

where the notation is deﬁned in equation (4.2) and the lack of a subscript denotes a group
of weights. For example:

Groups of the weights share a common precision:

uk = {u1k, . . . , uNhk}.

ujk ∼ Normal(0, τuk )
vj ∼ Normal(0, τv)

aj ∼ Normal(0, τa)

b ∼ Normal(0, τb)

where j varies from 1 to Nh and k varies from 1 to p. The symbols τuk , τv, τa, τb denote
hyperparameters. The prior for the NN weights conditioned on the hyperparameters is given
by:

p(θ| τu, τv, τa, τb) =

p(ujk| τuk )p(vj | τv)p(aj | τa)p(b| τb).

p

Nh

Yk=1

j=1
Y

This grouping of the weights is usually justiﬁed by the need to account for diﬀerent scalings
in the output and input data variables. However, the grouping of the variables with the
same hyperparameters follows directly from the principle of exchangeability, see Section
3.6.5. For example, the hidden to output weights, vj, all play the same role in equation
(4.3) and so are a priori exchangeable.

Neal (1996) has analyzed the relationship between the prior distribution on the net-
work weights with the prior distribution on the network output. Some of his results are
summarized below.

From equation (4.3) it can be seen that the contribution of hidden unit j to the network

function has the following properties:

The factorization of the expectation is possible since vj and hj(x) are a priori independent.
The prior expectation of vj is zero by deﬁnition and so

(4.10)

E[vj hj(x)] = E[vj ]E[hj(x)]

where hj(x) is the output of hidden layer neuron j:

hj(x) = tanh

aj +

ujixi

.

 

!

p

i=1
X

E[vj hj(x)] = 0.

The variance of the contribution of hidden unit j is given by

E[(vj hj(x))2] = E[v2

j ]E[h2

j (x)].

Deﬁne

V (x) ≡ E[h2

j (x)].

37

The limits of V (x) are given by the tanh function:

V (x) ∈ [0, 1].

As can be seen from equation 4.3, the output of the NN is equal to the sum of the contribu-
tions of the output’s of the hidden units and the output bias unit. As the number of hidden
units, NH , becomes larger, the Central Limit Theorem can be invoked to get

f (x) ∼ Normal(0, NH σ2

vV (x) + σ2

b ).

Thus, in order for the NN to have a stable variance as the number of hidden units increase,
the hidden to output weights have to be scaled:

where wv is the maximum variance the hidden to output layer weights are chosen to con-
tribute. With this rescaling it follows that:

σ2
v = wv/NH

f (x) ∼ Normal(0, wvV (x) + σ2

b ).

The prior variance of the output function will therefore remain stable as the number of
hidden layer neurons increases.

Neal (1996) argues that this rescaling will counteract the tendency of the NN to over
ﬁt the data as the number of hidden units increases. From which it follows the only limit
on the number of hidden layer units should be dictated by computational constraints.

Williams (1995) uses a maximum entropy approach to argue that a Laplace, rather
than a Gaussian prior, should be used for the network weights. He shows how this can be
used to implement a Bayesian pruning algorithm.

4.7.2 Computational Techniques

With the hyperparameter priors, the point estimation procedure of equation (4.9) becomes:

(4.11)

ˆy(n+1) =

f (x(N +1), θ)p(θ| D, γ)p(γ) dθdγ

Zθ,γ

where γ = {τu, τv, τa, τb, τn} with τn representing the precision of the noise added to the
data. Although the noise precision is not strictly a hyperparameter, it is grouped with the
hyperparameters as it is treated in a similar fashion. The integral required for the solution
of the posterior predictive solution in equation (4.11) is diﬃcult to solve and several diﬀerent
approaches have been proposed.

Maximum Posterior Density

Sarle (1995) advocates obtaining point estimates for the predictive NN result, equation
(4.11), by maximizing the posterior probability of the weights and the hyperparameters.
The hyperparameters are given slightly informative conjugate priors. Sarle (1995) gives

38

simulation results on which the maximum posterior approach outperforms maximum likeli-
hood and early stopping methods.

This approach has the advantage of being very computationally eﬃcient. However for
small data sets, evaluating the full posterior as in equation (4.11) will probably produce
better results as the mode may not be representative of the whole distribution.

Gaussian Approximations

The modes of the NN posterior can be approximated by Gaussians (Buntine and Weigend
1991, MacKay 1992a, Thodberg 1993). The modes of the posterior of the network weights
are found by optimization. Each node is approximated by a Gaussian whose covariance
matrix is chosen to match the second derivatives of the log posterior probability at the
mode. The posterior predictive distribution of the NN is found by the weighted sum of the
integrals of each of the modes.

In MacKay’s approach the network hyperparameters are estimated by ML-II type
methods (see Section 3.6.3 of Chapter 3). Buntine and Weigend (1991) advocate analyti-
cally marginalizing the hyperparameters instead. MacKay (1994) argues that this produces
less accurate results than the ML-II method as the modes of the marginalized posterior dis-
tribution of the network weights can be quite unrepresentative of the posterior distribution
of the weights as a whole.

4.7.3 Markov Chain Monte Carlo Integration

Neal (1996) advocates the use of Markov chain Monte Carlo (MCMC) techniques (see Section
3.8.2 of Chapter 3) to solve the integral in equation (4.11). This has the advantage of not
requiring any approximations to the parametric form of the posterior.

In this scheme samples need to be generated from the posterior for the weights, p(θ| D).
To do this, samples can be generated from the posterior of the weights and hyperparameters,
p(θ, γ| D). The integral in equation (4.11) can then be approximated by:

ˆy(n+1) =

f (x(n+1), θ(i))

1
Nθ

Nθ

i=1
X

where θ(i) is the ith sample of weights and Nθ is the total number of samples.

The posterior for the weights and hyperparameters is given by multiplying the prior

by the likelihood:

p(θ, γ| D) ∝ p(γ)p(θ| γ)

p(y(c)| x(c), θ, γ).

N

c=1
Y
Conjugate priors are used for the hyperparameters τuk , τb, τv and τa. A conjugate
prior can also be given to the noise precision, τn. All the hyperparameters are precisions of
the Gaussian distribution. Thus, their conjugate priors are given by Gamma distributions.
For example, the conjugate prior of τv is given by:

p(τv) =

(αv/2ωv)αv /2
Γ(αv/2)

τ αv /2−1
v

exp(−τvαv/2ωv)

39

where the mean, ωv, and shape parameter, αv, can be chosen by the user so as to give a
suitably noninformative hyperprior. Each of the other groups of parameters are assigned
their own hyperprior mean and shape parameter.

Gibbs Sampling Updating of Hyperparameters

In the scheme suggested by Neal (1996), the hyperparameters are updated by Gibbs sampling
(see Section 3.8.2 of Chapter 3.) The likelihood of a hyperparameter depends only on its
corresponding weights:

(4.12)

p(v1, . . . , vNH |τv) = (2π)−k/2τ k/2

exp

v

−τv

v2
i /2

.

!

 

i
X

Thus, for a given group of weights, v1, . . . , vNh , the pdf of the hyperparameter, τv, condi-
tioned on the weights is:

p(τv| v1, . . . , vNh, αv, ωv) ∝ τ (αv +Nh)/2−1

v

exp

−τv

αv/ωv +

 

 

v2
i

/2

.

!

!

i
X

From this expression it can be seen that the prior for τv can be interpreted as specifying αv
imaginary parameter values, whose average squared magnitude is 1/ωv. Vague priors for τv
can be speciﬁed using small values of αv.

As before the noise for each data point is assumed to be drawn from an identical
independently distributed zero mean Gaussian distribution with precision τn. The likelihood
of the noise is given by

(4.13)

p(y| x, θ, τn) = (2π)−N/2τ N/2

n

exp

−τn

(y(c) − f (x(c), θ))2/2

.

 

c
X

!

Using a conjugate Gamma prior,

p(τn) =

(α/2ω)α/2
Γ(α/2)

τ α/2−1
n

exp(−τnα/2ω)

the posterior is given by

p(τn| D, θ) ∝ τ (α+n)/2−1

n

exp

−τn(α/ω +

(y(c) − f (x(c), θ))2/2)

.

 

c
X

!

Using these conditional posteriors, the weight hyperparameters and noise precision can be
updated using Gibbs sampling.

Hybrid Monte Carlo Updating of Network Weights

The priors for the weights conditional on the hyperparameters are given by equations of the
same form as equation (4.12). The likelihood due to the training cases is given by equation

40

(4.13). The resulting minus log posterior is:

(4.14)

− log(p(θ| D, γ)) ∝

τuk

u2
ik + τa

a2
i + τv

v2
j +

Nh

i=1
X

Nh

j=1
X

p

Nh

Xk=1

i=1
X

N

c=1
X

τn

(y(c) − f (x(c), θ))2

The form of equation (4.14) is similar to the weight decay error function of equation (4.8).
However, here the objective is to average over the distribution of weight decay coeﬃcients
and network parameters, instead of simply maximizing the posterior. Also, the user does
not have to specify exact weight decay coeﬃcients, but can instead specify a broad prior
distribution. There is no need for a hold out set to evaluate the weight decay coeﬃcients.

Equation (4.14) is not amenable to Gibbs sampling as it is infeasible to sample from
the conditional network weight posterior. Thus a Markov chain Monte Carlo (MCMC) type
approach is more appropriate, see Section 3.8.2.

However, the standard MCMC method can be very slow to converge when there are
correlations between the parameters. Any proposed jumps which don’t have a similar cor-
relation structure will be likely to lead to improbable parameter values. To avoid this type
of behaviour a method which takes into account these correlations needs to be formulated.
Neal (1993; 1996) proposed the hybrid Monte Carlo method which was ﬁrst formulated
by Duane et al. (1987) in a Quantum Chromo Dynamics context. The hybrid MC method
consists of two steps. First a dynamical simulation is performed and then the ﬁnal result
is accepted with a certain probability. The dynamical simulation part involves associating
each network weight, θi, with a particle coordinate in a ﬁctitious physical system. With each
coordinate there is also an associated momentum parameter pi. For the ﬁctitious physical
system a potential energy is deﬁned:

The corresponding momentum components contribute to the kinetic energy of the system:

where the mi are the associated mass components. The Hamiltonian of the system is given
by:

The coordinates are made to evolve according to the equations of Hamiltonian dynamics:

E(θ) ∝ −log(p(θ| D, γ)).

K(p) =

p2
i
2mi

Nθ

i=1
X

H(θ, p) = E(θ) + K(p).

= +

dθi
dτ
dpi
dτ

=

pi
mi

∂E
∂θi

= −

= −

∂H
∂pi
∂H
∂θi

41

where τ is the ﬁctitious time. The dynamical simulation method is mathematically anal-
ogous to a ball on a surface whose height is deﬁned by −log(p(θ| D, γ)). The particle will
always “roll” back towards the valleys (posterior modes).

In order to simulate the Hamiltonian dynamics a discretization procedure is used:

ˆp(τ + ǫ/2) =ˆpi(τ ) −

ˆθi(τ + ǫ) =ˆθi(τ ) + ǫ

ˆpi(τ + ǫ) =ˆpi(τ + ǫ/2) −

∂E(ˆθ(τ ))
ǫ
2
∂θi
ˆpi(τ + ǫ/2)
mi
ǫ
2

∂E(ˆθ(τ + ǫ))
∂θi

where ǫ is the step length. One simulated dynamics iteration consists of L such steps.

In continuous Hamiltonian dynamics, the Hamiltonian does not depend on τ . However
in the discrete case, H will not be the same at the start and end of the iteration. The new
state is accepted with a probability

min[1, exp(−H(θf , pf ) + H(θi, pi))]

where θf and pf are values of the parameters and momentum at the end of a dynamical
iteration and θi and pi are the values at the beginning of the dynamical iteration.

After each dynamical iteration, the hyperparameters are updated by Gibbs sampling

and the momentum is updated by drawing from a multivariate Gaussian distribution.

The hybrid MC method avoids the random walk behaviour of ordinary MCMC sam-
pling and allows NN model parameters to be estimated in a reasonable amount of time.
Many other implementation details and variations are discussed by Neal (1996). Free soft-
ware implementing the above techniques is available from the URL
http://www.cs.utoronto.ca/∼radford.

4.8 Conclusion

Multilayer perceptron feed forward artiﬁcial neural networks (NN) provide a ﬂexible non-
parametric approach to nonlinear regression. The problem of overﬁtting can be solved by
regularization. The amount of regularization can be chosen by cross validation or Bayesian
techniques. The Bayesian technique can be implemented using maximum posterior tech-
niques, Gaussian approximations and ML-II techniques or by MCMC sampling. A hybrid
MC approach is required for practical computation times.

The Bayesian approach provides a natural way of incorporating regularization without
It also provides a whole distribution instead of just
the need for a hold out data set.
a point estimate and so credibility intervals can easily be generated.
In Chapter 6 the
MCMC Bayesian NN implementation will be used to extrapolate the forest tree growth
data discussed in Chapter 2.

42

Chapter 5

Methods of Comparison

In this chapter a statistical methodology for comparing two ﬁtting methods is discussed.
Speciﬁcally methods for comparing the Schnute and artiﬁcial neural network (NN) extrap-
olations of the forest tree growth data discussed in Chapter 2 are examined.

Frequently when two methods are compared in the NN literature only the diﬀerence
in the ﬁts is given, e.g. the diﬀerence in the mean square error (MSE) on a test data set.
However, it is also beneﬁcial to determine how signiﬁcant the observed diﬀerence is, i.e.
whether or not the observed diﬀerence is only due to random variation.

5.1 Criteria for Comparison

As discussed in previous chapters, the parameters of a regression method are determined
by training data. To test how well the method will predict other data drawn from the same
distribution as the training data, a test set of data is usually employed. This is because
the method will usually have an optimistically biased performance on the training set. It
is possible for a method to be tailored to work very well on a particular data set. However
this is no guarantee that the method will generalize well to other data sets drawn from
the same distribution. For example, when using a polynomial of the same degree as the
number of data points, the performance on the training set will be perfect but it is unlikely
to generalize well. This phenomenon is known as overﬁtting the data.

Following Rasmussen (1996), the factors that eﬀect the evaluated performance of a

regression method are deﬁned as follows:

1. The set of test data selected.

2. The set of training data selected.

3. The stochastic aspects of the method, e.g. random weight initialization and stochastic

1Rasmussen distinguished stochastic prediction (e.g. Monte Carlo estimation) from the stochastic training

training.1

element.

43

Thus an appropriate loss function (see Section 3.7 of Chapter 3) for a method trained on a
training data set of size n would be:

(5.1)

GF (n) =

L

Fri,rt(Dn, x), t

p(x, t)p(Dn)p(ri)p(rt) dx dt dDn dri drt.

Z

(cid:2)

(cid:3)

The functional form of the method is denoted by F . The L is the loss function for predictions
made using training set Dn, when the input is x and the correct test result is t. The ri and
rt denote the random initialization and training method. This is just the usual method of
integrating out nuisance parameters that was discussed in Section 3.5 of Chapter 3.

In practice, GF (n) can be approximated by averaging the loss over a large number of
diﬀerent experiments with diﬀerent training and test sets. The dependence of n could also
be removed by summing over experiments with diﬀerent numbers of training cases. How-
ever, the conditions of the experiments should be drawn from the probability distribution
p(x, t, D, n, ri, rt). In the next section a method of determining the statistical signiﬁcance
of the diﬀerences in G for two diﬀerent methods is discussed.

5.2 Hierarchical Analysis of Variance

Rasmussen (1996) proposed the hierarchical analysis of variance (ANOVA) method for em-
pirically comparing two regression methods. This technique will be applied in comparing
the MSE of the Schnute and Bayesian NN methods.

There are I = 11 forest tree plots available. Within each plot the last J = 4 points will
be left out as a test set. The functions are each trained individually on each plot and their
MSE is evaluated for each of the J test points. Let yij be the diﬀerence in the Schnute and
NN MSE for test case j in plot i. Following Example 7 given by Spiegelhalter et al. (1996),
the diﬀerence in residuals are modeled by

yij ∼ Normal(µi, τwithin)

µi ∼ Normal(θ, τbetween).

The within plot variance, σ2
within, is the inverse of τwithin. The between plot variance,
σ2
between, is the inverse of τbetween. The true mean diﬀerence between the techniques is given
by θ. The σ2
It can be interpreted as
the diﬀerence caused by the diﬀerent training sets in each plot. The σ2
within measures the
diﬀerence caused by estimating the MSEs from a ﬁnite number of test samples.

between measures the diﬀerence between the plots.

The main interest is to evaluate if one method is signiﬁcantly better than the other.

How this is done from both a Frequentist and Bayesian perspective is now described.

5.2.1 Frequentist Estimation

An unbiased estimator of θ is given by

ˆθ = y.. =

1
IJ

yij.

ij
X

44

In Frequentist terms one method is said to be signiﬁcantly better if the p-value, given by
p(ˆθ ≥ |y..| |θ = 0), is less than some threshold. That is, the probability of having the current
or more extreme data, assuming that the methods are the same on average, is examined.
The smaller the p-value the more signiﬁcant the observed diﬀerences are thought to be.

The t statistic is given by

where

t = y..

1
I(I − 1)

 

(yi. − y..)2

!

−1/2

i
X

1
J

j
X

yi. =

yij.

p(t) ∼

1 +

(cid:18)

−I/2

.

t2
I − 1

(cid:19)

p = 1 −

p(t′) dt′,

t

−t

It has a t distribution with I − 1 degrees of freedom:

From which it follows that the required p-value is given by

Z
where the integral can be evaluated numerically using the incomplete beta distribution.

Unbiased estimators are available for the variances:

ˆσ2
within =

1
I(J − 1)

ˆσ2
between =

J
I − 1

(cid:16)

i
X

(yij − yi.)2

j
X

i
X
(yi. − y..)2 − ˆσ2

within

/J.

(cid:17)

These can be used to evaluate the cause of the variation.

5.2.2 Bayesian Estimation

In the Bayesian case there are two distinct ways of determining whether the two methods
are producing signiﬁcantly diﬀerent results. The ratio of the hypothesis that θ = 0 (there
is no diﬀerence in the true MSEs) against θ 6= 0 can be examined:

where B(yij ) is the Bayes factor and is given by

p(θ = 0|yij)
p(θ 6= 0|yij)

=

p(θ = 0)
p(θ 6= 0)

B(yij)

B(yij) =

p(yij|θ = 0)
p(yij|θ 6= 0)

.

Assuming equal a priori probabilities for the two hypotheses, inference would be made using
the Bayes factor. The smaller the Bayes factor, the more probable that the two methods
are diﬀerent.

45

The second Bayesian method would be to evaluate p(θ > 0|yij). A Bayesian treatment
of hierarchical ANOVA is given in Chapter 5 of Box and Tiao (1992). They use the Jeﬀreys’
prior:

P (θ, σ2

between, σ2

within) = p(θ)p(σ2

between, σ2

within)

with p(θ) assumed uniform and

p(σ2

between, σ2

within) ∼ σ−2

betweenσ−2

within.

From which it follows that the posterior is given by:

p(θ|{yij}) ∼ a

−p2
2 Betaia2/(a1+a2)(p2, p1),

where Betai is the incomplete beta distribution and

a1 =

1
2

p1 =

j
i
X
X
I(J − 1)
2

(yij − yi.)2

a2 =

(yi. − θ)2

J
2

I
2

i
X

p2 =

.

The inferences drawn from Bayesian hierarchical ANOVA can be sensitive to the chosen
prior. This is because the likelihood does not contain much information about σ2
between (see
page 18 and 19 of Rasmussen (1996)).

Alternatively, hierarchical priors could be used (see Example 7 of Spiegelhalter et al.

1996):

θ ∼ Normal(µθ, τθ)

τwithin ∼ Gamma(αwithin, βwithin)

τbetween ∼ Gamma(αbetween, βbetween)

where the hyperparameters are chosen so as to be uninformative.
In Rasmussen (1996)
this approach is suggested but not implemented. Gibbs sampling needs to be used to make
inference about the parameters.

In the next Chapter, the hierarchical ANOVA technique will be applied in comparing

the results of the NN and Schnute extrapolations of the forest tree growth data.

46

Chapter 6

Results and Discussion

In this chapter I present the results of ﬁtting the artiﬁcial neural network (NN) and Schnute
functions to the forest tree growth data presented in Chapter 2. Graphical representations
of the NN and Schnute ﬁts for each of the forest tree plots are given. Credibility intervals
are also plotted for the NN ﬁts. An analysis of variance (ANOVA) is used to compare the
two methods.

6.1 Experimental Design

The main purpose is to determine which technique, the Schnute or Bayesian NN, is best at
extrapolating forest tree growth data. As discussed in the previous chapter, in order to do
this the results when diﬀerent training sets are used need to be compared. A number of test
cases are needed or else the variation due to sampling error, σ2

within, will be too high.

Eleven diﬀerent sets of forest tree data were available. Each plot is extrapolated sepa-
rately, i.e. for each plot the methods will be trained on a subset of the data and extrapolated
on the remaining subset.

Choosing how much data to use for training and how much to use for testing is a
diﬃcult problem. If too little data are used for training then the predictions will have a
high variance. This was the role of σ2
between in the last chapter. If too little data are used for
testing then the sampling error will be to high. Ideally, data for the whole function should
be tested, but for practical reasons only a small sample of the function’s points can usually
be checked.

So in deciding how much of the data to divide into test and training sets, the eﬀects
on σ2
within and σ2
between have to be considered. As discussed in Chapter 2, there is a limit to
the number of points which can be chosen as test data. The ﬁrst 15 data points are aﬀected
by the removal of trees. As the number of trees is not included as an explanatory variable,
this extra variation could not be taken into account by the prediction method. Therefore
it was decided to restrict the data points used, for testing, to the last four. For some of
the plots where thinning ended earlier, more data could be used. However, the statistical
analysis of the results is easier when the number of test points is the same for each plot.

47

Extrapolation can be useful to the forest manager in making predictions for future

growth.

In summary, the ﬁrst 15 points (ages 5 to 28 years) are used as training points and the

last 4 points (ages 30 to 37) as test points.

6.2

Implementation Details

In this section I discuss speciﬁcally how the Bayesian neural network (BNN) solution and
the Schnute solution were obtained for the forest tree growth extrapolation problem.

6.2.1 Bayesian Neural Networks

The NN will need one input layer neuron for the age and one output layer neuron for the
average density at breast height (DBH). This study was restricted to one hidden layer NNs,
as they are generally adequate for simple nonlinear regression problems.

As discussed in Chapter 4, the number of hidden layer neurons can be chosen as high
as computationally feasible in the Bayesian scheme, without the danger of overﬁtting. Eight
hidden layer neurons were chosen, as for the relatively uncomplicated curves I wish to ﬁt
they should be more than adequate. The hidden layer neurons were given tanh activation
functions and the output neurons were assigned linear activation functions.

Radford Neal’s Bayesian NN package, bnn, (see Chapter 4), was used to ﬁt the data.
In choosing the prior parameters and Markov chain Monte Carlo (MCMC) scheme, the
regression example distributed with the bnn package was used. The choices appear to be
fairly generally applicable. Although I did choose to normalize the training data to zero
mean and unit variance, so as to be more compatible with Neal’s regression example.

The noise variance was given an inverse Gamma prior with a mean precision corre-
sponding to a standard deviation of 0.05 and a shape parameter of 0.5. This corresponded
to a prior distribution which spans several orders of magnitude and so should easily en-
compass the noise level of the data. The hidden layer weights were assigned a zero mean
Gaussian prior. The variance of the Gaussian prior was given an inverse Gamma prior with
a scaled (see Chapter 4) mean equivalent to a standard deviation of 0.05 and a shape pa-
rameter of 0.5. The input to hidden layer weights and the hidden layer biases were given
equivalent priors but unscaled. The output layer bias was given a zero mean Gaussian with
a standard deviation ﬁxed at 100. Giving the output layer bias a hyperparameter was un-
necessary because hyperparameters are only needed when there is more than one parameter
in a group.

The MCMC was split into two phases. In both phases, for every iteration, the momen-
tum variables are updated by the heatbath method and the noise level is updated by Gibbs
sampling. The other details of each phase are as follows:

1. In the initial phase the objective was to get a fairly reasonable starting point. The
hyperparameters were all ﬁxed at the moderate value of 0.5 and the network param-
eters to 0. Then one iteration was performed with the following speciﬁcations. The
network parameters were updated using hybrid Monte Carlo with a trajectory of 100

48

leapfrog steps long, a stepsize adjustment factor of 0.2 and a window size of 10 (Neal
1996). The hyperparameters remained ﬁxed.

2. In the ﬁnal phase the actual MCMC sampling is performed. For each iteration, the
hyperparameters were updated using Gibbs sampling. The network parameters were
updated using a hybrid Monte Carlo method with a trajectory of 1000 leapfrog steps,
a window of size 10, and a stepsize adjustment factor of 0.4.

It was decided to do 1000 sampling iterations for each plot, while in the bnn regression
example only 100 iterations were performed.

On a 66 MHz Cx486DX2-S PC with the Linux 2.0 operating system, each plot took
approximately 50 minutes to train. Of course shorter times can be achieved by using less
iterations, but this will eﬀect the accuracy.

Convergence

For most of the plots, the Markov chains seemed quite homogeneous. Figure 6.1 shows
a plot of the hidden to output layer hyperparameter for a NN trained on forest tree plot
2. Although there are formal convergence tests (Cowles and Carlin 1995) visually the time
series looks fairly homogeneous. However there were some plots where this was not the case.
Figure 6.2 shows the same hyperparameter for plot 1. Here the last 300 points have a much
higher mean and variance than the ﬁrst 700. Examining 5000 iterations, Figure 6.3 shows
that the Markov chain seems to oscillate between these two ‘states’. Adjusting the step size
adjustment factor so as to modify the rejection rate did not seem to make much diﬀerence
to this problem. The posterior may be multi-modal and the Markov chain is oscillating
between the two modes. Examining the samples for the training MSE for plot 1, Figure
6.4, shows that the MSE seems to be the same for both modes and so averaging over the
diﬀerent modes may still be valid. Taking the ﬁrst 1000 iterations gave good results. Taking
only the ﬁrst 700 made no signiﬁcant diﬀerence.

Point Predictions and Credibility Intervals

Point predictions were made by taking the mean of all the Markov chain (MC) samples
for each point. As discussed previously, this implies a MSE loss function. The standard
deviation for each predicted point was also evaluated. If the predictions were assumed to
follow a Gaussian distribution then the true value to be predicted would have approximately
95% probability of being contained within two standard deviations of the mean.

The 95% credibility intervals of the predicted data can be estimated directly from the
MC samples, without any assumptions about the distribution.
I evaluate these for each
predicted point as well. These intervals are distinct from the credibility intervals of the
predicted mean in that they take into account the noise variance. The 95% credibility
intervals were obtained using the same scheme as was used for the median evaluation in
bnn. First the noise standard deviation σn is estimated by taking the mean of the Monte
Carlo samples of the noise standard deviation. Then to predict the 95% credibility interval
of the output, f (t) for an input t, each Monte Carlo estimate of f (t) is used to generate 200

49

r
e
t
e
m
a
r
a
p
r
e
p
y
h

r
e
t
e
m
a
r
a
p
r
e
p
y
h

1.6

1.2

0.8

0.4

0

20

15

10

5

0

0

200

800

1000

400
600
iterations

Figure 6.1: Markov chain of hidden layer to output layer hyperparameter for plot 2.

200

600
400
iterations

800

1000

Figure 6.2: Markov chain of hidden layer to output layer hyperparameter for plot 1.

50

r
e
t
e
m
a
r
a
p
r
e
p
y
h

20

15

10

5

0

1000

800

600

400

200

)
2
 
^
 
m
m

(
 

E
S
M
 
g
n
n
a
r
T

i

i

0

0

0

2000

iterations

4000

Figure 6.3: Markov chain of hidden layer to output layer hyperparameter for plot 1.

1000

2000

3000

4000

5000

Figure 6.4: Markov chain of average training MSE for plot 1.

iterations

51

samples from a Gaussian with mean f (t) and standard deviation σn. Then I evaluate the
value for which 2.5% of these samples lie below, and the value for which 2.5% of the samples
lie above. Ideally the 95% interval should be chosen so as to be as short as possible, see
page 85 of Box and Tiao (1992). However this would have been much more computationally
expensive.

Evaluating the standard deviation and 95% credibility intervals required modifying the

net-pred command in the bnn package.

6.2.2 Maximum Likelihood Neural Network Solution

The maximum likelihood or least squares optimization for the NN ﬁt (see Section 4.4 of
Chapter 4) was also tested. The Nevprop package1 (Goodman 1996) was used. The inputs
and outputs were normalized to unit variance and zero mean. Ordinary back propagation
performed better than many of the available alternatives, such as Quickprop, (Goodman
1996). The NN generally converged to the training data quite quickly, but many further
iterations were required to obtain good test results. The test error appeared to slowly
oscillate, with the oscillations gradually diminishing in amplitude. It was only after several
hours of iterations that comparable results to the Bayesian learning solution were achieved.
Increasing the learning rate lead to wild oscillations. Adding a momentum term was found
to be of little help.

Using a tanh output activation function improved the rate of convergence but required a
proportion of the training data to be set aside to test when the optimal ﬁt had been achieved
(Gordon 1994a;b). Leaving out a validation set did not help with the linear activation
function NN. Comparisons between Bayesian and least squares ﬁts are discussed in Sarle
(1995), Neal (1996) and MacKay (1992a). Generally, the Bayesian solution is found to
produce superior results.

Conﬁdence intervals can be produced for the least squares ﬁt using linearization and
other methods (Brittain and Haines 1997). It would be interesting to compare these with
the credibility intervals produced by the Bayesian method.

6.2.3 Schnute Implementation

For the Schnute function implementation, the ﬁts obtained in Falkenhagen (1997) were used.
To improve the rate of convergence to the least squares solution in ﬁtting the parameters
of equation (2.4), Falkenhagen set τ1 to the initial training age (5 years) and τ2 to the ﬁnal
training age (28 years). The initial values for the parameters y1 and y2 were set at the
corresponding initial and ﬁnal training average DBHs.

The secant method (Draper and Smith 1981) was used to ﬁt the parameters y1, y2, a,

b, separately for each plot.

1Available from ftp://unssun.scs.unr.edu/pub/goodman/nevpropdir/.

52

Plot
1
2
4
6
8
9
11
12
15
16
18
Mean
Std. Dev.

BNN Schnute
177
43
25
10
1346
25
523
11
8
86
38
208
406

61
1
21
3
3
101
13
19
19
6
61
28
32

Table 6.1: Table of test MSEs in units of mm2

6.3 Extrapolation Results

The BNN and Schnute techniques were applied to 11 plots. Plot 10 was not included in the
evaluation as the Schnute function failed to converge in that case. The results are displayed
in Figures 6.5 to 6.15. The × symbols are used for the training data for each plot and the +
symbols are used for the testing data. The Bayesian network prediction and 95% credibility
intervals are displayed as solid lines. The Schnute prediction is displayed as a dashed line.
For some plots the Schnute function became complex over t ∈ [0, 40]. It is not plotted
over these regions. The Bayesian credibility intervals appear to behave in the expected
manner in that as the prediction gets further away from the data points the credibility
intervals widen. This behaviour was also noted in the non-MCMC implementation described
by MacKay (1992a). The credibility intervals are not symmetric as would be the case if only
the standard deviation of the prediction was used to evaluate the credibility intervals.

The displayed intervals may appear to be too wide. In theory, each data point should
have a 95% probability of being contained within them. However, if the point (0, 0) is taken
as valid, then in 2 out of the 11 plots (plot 6 and 8) the origin is not contained between the
95% credibility intervals. This suggests in some sense the credibility intervals are not overly
wide.

The MSE test losses for both techniques are shown in Table 6.1. The results indicate
that the BNN method has a smaller MSE and is less variable. However, as the Schnute
method produces such variable results it is diﬃcult to be sure that on average its MSE isn’t
roughly equal to the BNN MSE, i.e. the diﬀerent mean MSEs may only be due to sampling
error. To test this, the ANOVA techniques discussed in Chapter 5 were used.

The results of the Frequentist and Bayesian ANOVA analysis are shown in Table 6.2.
The ‘Conjugate1’ column is the ANOVA result using Bayesian analysis with a conjugate
prior (see Section 5.2.2 of Chapter 5.) This analysis was performed using the Bugs software

53

θ
σ2
within
σ2
between
fbetween(%)
p(%)

Frequentist Conjugate1 Conjugate2
182
439
372
38
7

180
404
364
45
18

181
439
373
38
8

Jeﬀreys
261
-
-
-
11

Table 6.2: Table of Frequentist and Bayesian ANOVA analysis. Where not speciﬁed, units are
in mm2.

package2. The mean was given a normal distribution with mean 0 and precision 10−10.
The between and within variance prior precisions were both given gamma distributions, see
equation (3.21), with α = 2 × 10−10 and ω = 1

The ‘Conjugate2’ column was generated in exactly the same way as the ‘Conjugate1’
column except that α was 1000 times smaller. This makes the distributions roughly 1000
times more vague.

The ‘Jeﬀreys’ column is the Jeﬀreys prior Bayesian analysis (see Section 5.2.2 of Chap-

ter 5.) The σ2

between and σ2

within were not analyzed for the Jeﬀreys prior analysis.

The ‘fbetween’ row is the percentage of the variance explained by the between variance
component. The ‘p’ row is the p-value for the Frequentist analysis, with the null hypothesis
being that the two methods had equal expected MSEs. For the Bayesian analysis the ‘p’
row contains the probability of the Schnute model having a smaller MSE than the BNN
model.

The main concern of the Bayesian ANOVA approach is sensitivity of the results to the
between. However, as can be seen the results appear to be fairly insensitive

prior chosen for σ2
to making the priors more uninformative in the conjugate case.

The p-value obtained is the probability of obtaining the current data or a more extreme
version of it, if the two techniques were really identical under a mean square test error
loss function. The obtained value of 0.18 does not meet the usual 0.05 signiﬁcance level.
Hence, from a Frequentist perspective, the hypothesis that the two techniques have identical
expected test MSEs cannot be refuted. A contributing factor to this inconclusive result is
the high level of variation in the Schnute results. The BNN has an estimated standard
deviation an order of magnitude smaller than the Schnute method. This factor may also
prove important when choosing a method to use. As discussed by Rasmussen (1996), very
large data sets are usually needed to obtain signiﬁcant result from a Frequentist ANOVA.
The estimation of the mean test MSE diﬀerence for the conjugate priors shows good
agreement with the Frequentist estimate. Thus the conjugate prior analysis is taken as
the Bayesian result. The discrepancy in the noninformative analysis conﬁrms the negative
opinion of the approach discussed in Section 5.2.2.

The Bayes result indicates that there is a 93% probability of the BNN approach having
It is diﬃcult to directly compare the

a smaller test MSE than the Schnute approach.

2Available from http://www.mrc-bsu.cam.ac.uk/bugs/mainpage.html

54

Bayesian and Frequentist results as they use very diﬀerent criteria. It is my belief that the
Bayesian approach provides a more direct criterion for comparing the hypotheses. To make
a decision using Bayesian decision theory, the mean loss associated with each method is
compared. The method with the smallest mean loss is the one which will be chosen. If any
losses associated with computation time and storage are ignored, then the mean losses can
be treated as the corresponding mean MSE’s. Thus from a Bayesian perspective, the BNN
procedure would be chosen.

The Bayesian and Frequentist conclusions do not have to necessarily coincide. Berger
(1985) gives several examples where they diﬀer considerably. Thus the Bayes result can
strongly indicate that the methods are diﬀerent, while the Frequentist result may be incon-
clusive. I believe this is true in the current case.

Whether or not the techniques are signiﬁcantly diﬀerent is not the only relevant crite-
ria. A practically insigniﬁcant diﬀerence can still be deemed statistically signiﬁcant if there
are enough samples. To determine whether the observed MSE diﬀerence of 180 mm2 is
practically signiﬁcant, it can be converted it into a basal area error (BAE) diﬀerence. Mul-
tiplying by π/4 gives a BAE diﬀerence of 1.4 cm2. The average tree height for the study was
about 29 meters for the testing period (Falkenhagen 1997). The average stems per hectare
was approximately 600. Treating the volume as basal area times height, an approximate
improvement of 1.7 m3 per hectare (100 m2) is achieved. A plantation can be thousands of
hectares in size.

55

s
r
e
t
e
m

 
/
 

H
B
D

0.3

0.2

0.1

0

-0.1

-0.2

0

5

10

30

35

40

15

20
age / years

25

Figure 6.5: ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 1. The
Schnute prediction is displayed as a dotted line. The × are the training data and the + are the
testing data.

56

s
r
e
t
e
m

 
/
 

H
B
D

0.3

0.2

0.1

0

-0.1

-0.2

0

5

10

30

35

40

15

20
age / years

25

Figure 6.6: ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 2. The
Schnute prediction is displayed as a dotted line. The × are the training data and the + are the
testing data.

57

0.5

0.4

0.3

s
r
e
t
e
m

 
/
 

H
B
D

0.2

0.1

0

-0.1

-0.2

0

5

10

30

35

40

15

20
age / years

25

Figure 6.7: ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 4. The
Schnute prediction is displayed as a dotted line. The × are the training data and the + are the
testing data.

58

s
r
e
t
e
m

 
/
 

H
B
D

0.5

0.4

0.3

0.2

0.1

0

-0.1

-0.2

0

5

10

30

35

40

15

20
age / years

25

Figure 6.8: ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 6. The
Schnute prediction is displayed as a dotted line. The × are the training data and the + are the
testing data.

59

s
r
e
t
e
m

 
/
 

H
B
D

0.6

0.5

0.4

0.3

0.2

0.1

0

-0.1

-0.2

0

5

10

30

35

40

15

20
age / years

25

Figure 6.9: ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 8. The
Schnute prediction is displayed as a dotted line. The × are the training data and the + are the
testing data.

60

s
r
e
t
e
m

 
/
 

H
B
D

0.5

0.4

0.3

0.2

0.1

0

-0.1

-0.2

0

5

10

30

35

40

15

20
age / years

25

Figure 6.10: ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 9. The
Schnute prediction is displayed as a dotted line. The × are the training data and the + are the
testing data.

61

s
r
e
t
e
m

 
/
 

H
B
D

0.5

0.4

0.3

0.2

0.1

0

-0.1

-0.2

0

5

10

30

35

40

15

20
age / years

25

Figure 6.11: ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 11. The
Schnute prediction is displayed as a dotted line. The × are the training data and the + are the
testing data.

62

s
r
e
t
e
m

 
/
 

H
B
D

0.5

0.4

0.3

0.2

0.1

0

-0.1

-0.2

0

5

10

30

35

40

15

20
age / years

25

Figure 6.12: ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 12. The
Schnute prediction is displayed as a dotted line. The × are the training data and the + are the
testing data.

63

s
r
e
t
e
m

 
/
 

H
B
D

0.4

0.3

0.2

0.1

0

-0.1

-0.2

0

5

10

30

35

40

15

20
age / years

25

Figure 6.13: ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 15. The
Schnute prediction is displayed as a dotted line. The × are the training data and the + are the
testing data.

64

s
r
e
t
e
m

 
/
 

H
B
D

0.5

0.4

0.3

0.2

0.1

0

-0.1

-0.2

0

5

10

30

35

40

15

20
age / years

25

Figure 6.14: ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 16. The
Schnute prediction is displayed as a dotted line. The × are the training data and the + are the
testing data.

65

s
r
e
t
e
m

 
/
 

H
B
D

0.5

0.4

0.3

0.2

0.1

0

-0.1

-0.2

0

5

10

30

35

40

15

20
age / years

25

Figure 6.15: ADBH BNN (solid lines) prediction with 95% credibility intervals for plot 18. The
Schnute prediction is displayed as a dotted line. The × are the training data and the + are the
testing data.

66

Chapter 7

Conclusion

In this research report I have applied Bayesian artiﬁcial neural networks (BNNs) to the
problem of extrapolating mean forest tree growth curves. I have also used an analysis of
variance (ANOVA) to evaluate the BNN performance.

In Chapter 1, I showed how the functional form of a multilayer perceptron artiﬁcial
neural network (NN) could be interpreted as a sum of logistic functions. As the logistic
function is a common model for growth curves, the NN approach has some justiﬁcation in
terms of measuring the average growth of a plot of trees.

Reviews of forest tree growth curve modeling and Bayesian statistics were given in
Chapter 2 and 3. The emphasis was on providing the relevant context and background for
the theoretical and empirical developments in the rest of the report.

In Chapter 4, a survey of the relevant artiﬁcial neural network theory was given. Par-
ticular emphasis was placed on the Bayesian Markov Chain Monte Carlo (MCMC) approach.
It was shown that an alternative way of justifying the prior assigned to the NN weights was
to treat the weights as a priori exchangeable. Each group of weights that was assigned a
common hyper-prior, played a priori equivalent roles in the NN functional form. Previously,
the groupings in the NN prior were justiﬁed in terms of diﬀerent input and output scalings.
In Chapter 5, analysis of variance (ANOVA) based techniques for comparing two re-

gression methods were discussed.

The main results of the research report were given in Chapter 6. Eleven forest tree
average density at breast height (DBH) growth curves were modeled. From each forest tree
plot, nineteen age DBH pairs were available. Fifteen were used as training samples and four
as test samples. The Schnute and BNN techniques were applied separately to each plot.

The BNN technique had an average mean squared error (MSE) across the plots of 28
mm2 with a standard deviation of 32 mm2. The Schnute technique had an average MSE of
208 mm2 with a standard deviation of 406 mm2.

The Frequentist, Jeﬀreys and Conjugate prior ANOVA methods were applied. I do
not know of any other instances of the Conjugate prior ANOVA being used in this context.
The Frequentist and Conjugate ANOVA both yielded very similar parameter estimates.
The Conjugate ANOVA did not appear to be sensitive to changes in the prior. The Jeﬀreys
ANOVA parameter estimates were diﬀerent, which probably lends support to the misgivings

67

other workers have expressed about this technique.

The Frequentist ANOVA gave a p-value of 18%. This does not meet the usual 5%
requirement. Thus, from a Frequentist perspective, the null hypothesis, that the two tech-
niques will on average produce equal MSEs, cannot be rejected. This may be due to the
small sample size and high variance of the Schnute results.

The Conjugate ANOVA indicated that there was a 93% probability that the BNN
approach had a smaller expected MSE than the Schnute approach. The Conjugate ANOVA
estimated an expected MSE diﬀerence between the two techniques of 180 mm2. This trans-
lates to approximately 1.7 m3 of timber per hectare.

In the experiments conducted in this report, the factors that have been varied are
the initial tree density and thinning strategy. Other relevant factors that have remained
constant are the tree species, the forest plot location and sample ages that have been used
for the training and test plots. These factors would need to be varied to ascertain which
method was better in general.

Another extension to this report, that might be of interest, is a comparison of Bayesian
credibility intervals and Frequentist conﬁdence intervals for NN modeling. It also might be
of interest to compare how other ‘nonparametric’ methods, such as splines, would do at
forest tree growth curve modeling.

One of the broader issues addressed has been on the use of very complex techniques
such as BNNs for relatively simple nonlinear regression problems. As has been demonstrated
BNNs can compare favourably relative to more parametric, traditional approaches. The
availability of free software removes, to some extent, implementation diﬃculties. However,
it is my belief that for such complex techniques to gain more general acceptance, the choice
of hyper-priors and evaluation of MCMC convergence needs to be made more automatic.

68

Appendix A

Data

The data used in this research report consisted of 12 plots of Pinus roxburghii Sargent, a pine
native to the Himalayas. The plots were planted at an espacement of 1.8 by 1.8 m2 at the
Weza forest plantation in what is now known as Kwa-Zulu Natal, South Africa. Each plot
covered 0.08 ha and was surrounded by a 29 m wide buﬀer zone of trees (Falkenhagen 1997).
The plots were part of a series of correlated curve trend (CCT) experiments established by
O’Connor in 1935 (Bredenkamp 1984). Diﬀerent thinning regimes were used for each plot.
The average diameter at breast height (DBH) measurements for each plot are shown

in Table A.1. The number of trees within each plot is shown in Table A.2.

69

Age

5
6
8
9
10
11
12
14
16
18
20
22
24
26
28
30
32
34
37

1

32.2
52.1
87.0
99.3
111.5
120.3
124.7
135.1
142.7
149.8
157.2
164.1
166.4
172.0
176.3
180.4
183.2
189.2
202.8

2

39.3
64.2
109.0
127.1
142.7
155.9
161.7
179.0
194.1
205.0
213.4
221.4
227.6
234.2
240.4
243.9
248.6
251.8
256.2

4

46.4
74.1
125.8
152.5
173.3
190.1
200.4
226.4
250.7
267.7
284.5
297.9
308.4
317.9
328.5
334.8
339.9
348.6
352.6

6

40.2
66.5
119.3
140.7
166.6
191.3
200.8
231.6
262.1
286.5
308.5
327.2
341.7
354.6
367.5
377.5
384.9
395.6
401.7

8

40.6
68.1
119.3
143.7
170.9
195.1
208.4
273.9
292.1
324.6
354.1
387.1
413.5
437.1
461.0
477.3
495.3
513.4
530.6

Plot

9

27.8
49.0
85.6
101.6
116.5
127.5
130.3
161.4
176.7
206.5
223.5
254.5
272.0
303.5
325.1
343.7
358.4
385.2
403.2

10

27.4
47.8
85.8
109.8
126.9
140.3
144.0
179.2
201.9
242.0
262.7
298.2
319.2
338.3
358.3
373.0
384.4
385.4
402.0

11

33.1
59.3
104.1
133.0
154.4
170.4
177.6
218.9
248.9
281.9
308.7
335.8
357.1
377.2
397.5
413.0
428.4
442.8
459.2

12

47.9
75.7
125.5
145.3
182.1
202.4
211.8
258.3
295.8
322.3
347.6
370.7
385.4
400.9
417.2
425.4
435.2
441.7
452.5

15

43.9
67.7
107.7
121.9
135.2
144.7
147.5
206.4
236.2
257.7
281.0
299.7
314.9
328.3
342.0
349.9
357.7
366.0
374.7

16

58.3
87.8
143.7
163.0
184.5
201.9
207.8
244.1
276.9
302.0
320.6
338.7
353.0
366.0
378.4
385.2
394.7
405.6
412.3

18

49.0
73.5
116.9
145.3
166.2
185.9
192.9
223.0
250.3
265.7
279.5
293.2
305.6
318.8
333.4
342.9
353.2
364.9
377.3

Table A.1: The average diameter at breast height (DBH) data. The age is measured in years
and the DBH in mm.

Age

5
6
8
9
10
11
12
14
16
18
20
22
24
26
28
30
32
34
37

1

226
226
226
226
226
226
226
226
200
200
200
200
200
200
200
200
200
193
190

2

120
120
120
120
120
120
120
120
120
120
120
120
120
119
119
118
117
117
117

4

120
120
80
60
60
60
60
60
60
60
60
60
60
60
60
59
59
59
59

6

120
120
80
60
40
30
30
30
30
30
30
30
30
30
30
30
30
30
30

8

120
120
80
60
40
30
20
20
10
10
10
10
10
10
10
10
10
8
8

Plot
9

233
233
233
233
233
233
233
163
162
82
80
40
40
20
20
20
20
17
17

10

232
232
232
162
162
162
162
80
80
39
39
20
20
20
20
20
20
19
19

11

160
160
160
80
80
80
80
40
40
20
20
20
20
20
20
20
20
20
20

12

80
80
80
40
40
40
40
20
20
20
20
20
20
20
20
20
20
19
19

15

214
214
214
214
213
213
213
40
40
40
40
40
40
40
40
40
40
40
40

16

80
80
80
80
80
80
80
39
39
39
39
39
39
39
39
39
39
39
39

18

80
80
80
41
41
41
41
21
21
21
21
21
21
21
21
21
21
20
20

Table A.2: The number of trees within a plot. The age is measured in years.

70

Bibliography

J. Berger. Statistical Decision theory and Bayesian Analysis. Springer, 1985.

J. M. Bernardo and A. F. M. Smith. Bayesian Theory. John Wiley & Sons, 1994.

C. M. Bishop. Bayesian methods for neural networks. Technical Report NCR/95/009, De-
partment of Computer Science and Applied Mathematics, Aston University, Birmingham,
B4 7ET, U.K. http://www.ncrg.aston.ac.uk, 1995.

G. E. Box and G. C. Tiao. Bayesian Inference in Statistical Analysis. John Wiley and Sons,

Inc., 1992.

B. V. Bredenkamp. The C.C.T. concept in spacing research. In Symposium on Site and
Productivity of Fast Growing Plantations, pages 313–332, Pretoria and Pietermaritzburg,
South Africa, april 1984.

B. V. Bredenkamp and H. E. Burkhart. An examination of spacing indices for Eucalyptus

grandis. J. For. Res, 20:1909–1916, 1990.

B. V. Bredenkamp and T. G. Gregoire. A forestry application of Schnute’s generalized

growth function. Forest Science, 34(3):790–797, 1988.

S. Brittain and L. M. Haines. Nonlinear models for neural networks. In Mathematics of
Neural Networks: Models, Algorithms and Applications, pages 129–133. Kluwer, 1997.

W. Buntine and A. Weigend. Bayesian back–propagation. Complex Systems, 5:603–643,

1991.

B. Cheng and D. M. Titterington. Neural networks: A review from a statistical perspective.

Statistical Science, 9(1):2–54, 1994.

M. K. Cowles and B. P. Carlin. Markov chain Monte Carlo convergence diagnostics: A com-
parative review. Available from ftp://muskie.biostat.umn.edu/pub/1994/rr94-008.ps.Z,
1995.

G. Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics of

Control, Signals and Systems, 2:303–314, 1989.

R. L. Czaplewski, R. M. Reich, and W. A. Bechtold. Spatial autocorrelation in growth of
undisturbed natural pine stands across Georgia. Forest Science, 40(2):314–328, May 1994.

71

G. A. Dover. rDNA world falling to pieces. Nature, 336:623–624, 1988.

N. R. Draper and H. Smith. Applied regression analysis. John Wiley and Sons, New York,

1981.

S. Duane, A. D. Kennedy, B. J. Pendleton, and D. Roweth. Hybrid monte carlo. Physics

Letters B, 195:216–222, 1987.

M. Evans and T. Swartz. Methods for approximating integrals in statistics with special
emphasis on Bayesian integration problems. Statistical Science, 10(3):254–272, 1995.

E. R. Falkenhagen. Growth modeling of Pinus roxburghii in South Africa. Southern African

Forestry Journal, (178):31–38, March 1997.

A. Gelman, J. B. Carlin, H. S. Stern, and D. B. Rubin. Bayesian Data Analysis. Chapman
and Hall, 1995. Lots of detailed examples, including MCMC and hierarchical modeling.

S. Geman, E. Bienenstock, and R. Doursat. Neural networks and the bias/variance dilemma.

Neural Computation, 4:1–58, 1992.

W. R. Gilks, S. Richardson, and D. J. Spiegelhalter. Markov Chain Monte Carlo in Practice.

Chapman & Hall, 1996.

P. H. Goodman.

NevProp3 User Manual.

University of Nevada, URL:

ftp://unssun.scs.unr.edu/pub/goodman/nevpropdir/, 1996.

C. Gordon. Predicting forest tree growth using a neural network. In C. J. Wright, editor,
Proceedings of the Twentieth South African Symposium on Numerical Mathematics, pages
28–45. SANUM and the Department of Computer Science, University of Natal, Durban,
South Africa, Department of Computational and Applied Mathematics, University of the
Witwatersrand, Johannesburg, South Africa, July 1994a.

C. Gordon. The use of cross-validation in neural network extrapolation of forest tree growth.

In Proceedings of the Pattern Recognition Association of South Africa, 1994b.

E. J. Green, J. Francis A. Roesch, A. F. M. Smith, and W. E. Strawderman. Bayesian esti-
mation for the three-parameter Weibull distribution with tree diameter data. Biometrics,
50:254–269, March 1994.

E. J. Green and W. E. Strawderman. A comparison of hierarchical Bayes and empirical
Bayes methods with a forestry application. Forest Science, 38(2):350–366, April 1992.

E. J. Green and W. E. Strawderman. A Bayesian growth and yield model for slash pine

plantations. Journal of Applied Statistics, 23(2):285–299, 1996.

B. T. Guan and G. Z. Gertner. Machine learning and its possible roles in forest science.
Artiﬁcial Intelligence Applications in Natural Resource Management Journal, 5(2):39–52,
1991a.

72

B. T. Guan and G. Z. Gertner. Modeling red pine tree survival with an artiﬁcial neural

network. Forest Science, 37(5):1429–1440, 1991b.

B. T. Guan and G. Z. Gertner. Using a parallel distributed processing system to model

individual tree mortality. Forest Science, 37(3):871–885, 1991c.

B. T. Guan and G. Z. Gertner. Modeling individual tree survival probability with a random
optimization procedure: An artiﬁcial neural network approach. Artiﬁcial Intelligence
Applications in Natural Resource Management Journal, 9(2):39–52, 1995.

B. Hassibi and D. Stork. Second order derivatives for network pruning: Optimal brain
surgeon. In C. Giles, S. Hanson, and J. Cowan, editors, Advances in Neural Information
Processing Systems 5, pages 164–171, San Mateo, California, 1993. Morgan Kaufmann.

S. Haykin. Neural Networks: A Comprehensive Foundation. Macmillan College Publishing

Company, New York, 1994.

K. Hornik, M. Stichcombe, and H. White. Universal approximation of an unknown mapping
and its derivatives using multilayer feedforward networks. Neural Networks, 3:551–560,
1990.

E. T. Jaynes. Probability Theory: The Logic of Science. 1996. The latest version is available

by ftp from bayes.wustl.edu.

64–72, 1992.

W. Jeﬀerys and J. Berger. Ockham’s razor and Bayesian analysis. American Scientist, 80:

R. H. Jones and L. M. Ackerson. Serial correlation in unequally spaced longitudinal data.

Biometrika, 77(44):721–731, 1990.

S. Kirpatrick, C. D. Gelatt, and M. P. Vecchi. Optimization by simulated annealing. Science,

220:671–680, 1983.

R. L. Korol, K. S. Milner, and S. W. Running. Testing a mechanistic model for predicting

stand and tree growth. Forest Science, 42(2):139–153, 1996.

A. M. Kshirsagar. Multivariate Analysis. Marcel Dekker, inc. New York, 1976.

S. Y. Kung. Digital Neural Networks. PTR Prentice Hall, 1993.

P. Lambert. Modeling of nonlinear growth curve on series of correlated count data measured
at unequally spaced times: A full likelihood based approach. Biometrics, 52:50–55, Mar.
1996.

Y. Le Cun, J. S. Denker, and S. A. Solla. Optimal brain damage. In Advances in Neural
Information Processing Systems, pages 598–605. Morgan Kauﬀmann, San Mateo, CA,
1990.

D. J. C. MacKay. Bayesian Methods for Adaptive Models. PhD thesis, California Insti-
tute of Technology, Pasadena, California, 1992a. Can be obtained over the Internet at
ftp://131.111.48.8/pub/mackay/.

73

D. J. C. MacKay. A practical Bayesian framework for backpropagation networks. Neural

Computation, 4(3):448–472, 1992b.

D. J. C. MacKay. Hyperparameters: Optimise, or integrate out? In G. Heidbreder, editor,
Maximum Entropy and Bayesian Methods, Santa Barbara 1993, Dordrecht, 1994. Kluwer.

M. E. McDill and R. L. Amateis. Fitting discrete-time dynamic models having any time

interval. Forest Science, 39(3):499–519, 1991.

W. T. Miller III, R. S. Sutton, and P. J. Werbos, editors. Neural Networks for Control. MIT

Press, 1990.

M. L. Minsky and S. A. Papart. Perceptrons. MIT Press, 1969.

M. L. Minsky and S. A. Papart. Perceptrons. MIT Press, 2nd edition, 1990.

R. M. Neal. Probabilistic inference using Markov chain Monte Carlo methods. Technical

Report CRG–TR–93–1, Dept. of Computer Science, University of Toronto, 1993.

R. M. Neal. Bayesian Learning for Neural Networks. Lecture Notes in Statistics No. 118.

Springer-Verlag, New York, 1996.

J. A. Nelder. The ﬁtting of a generalization of the logistic curve. Biometrics, pages 89–110,

J. A. Nelder. Note: An alternative form of a generalized logistic equation. Biometrics, pages

Mar. 1961.

614–616, Dec. 1962.

A. J. O’Connor. Forest research with special reference to planting distances and thinning.

British Empire Forestry Conference, South Africa, 1935.

J. S. A. Oshu. Matrix model for tree population projection in a tropical rain forest of

South-Western Nigeria. Ecological Modeling, 59:247–255, 1991.

A. Papoulis. Probability & Statistics. Prentice Hall, 1990.

V. V. Phansalkar and P. S. Sastry. Analysis of the back–propogation algorithm with mo-

mentum. IEEE Transactions on Neural Networks, 5:505–510, 1994.

S. J. Press. Bayesian Statistics. Wiley, 1989.

K. J. Puettmann. Evaluation of the size-density relationships for pure red Alder and

Douglas-Fir stands. Forest Science, 39(1):7–27, Feb. 1993.

C. E. Rasmussen. Evaluation of Gaussian Processes and Other Methods for Non-linear

Regression. PhD thesis, University of Toronto, 1996.

D. A. Ratowsky. Nonlinear Regression Modeling. Marcel Dekker, 1983.

M. R. Reynolds, T. E. Burk, and W.-C. Huang. Goodness-of-ﬁt tests and model selection

procedures for diameter distribution models. Forest Science, 34(2):373–399, 1988.

74

F. J. Richards. A ﬂexible growth function for emperical use. Journal of Experimental

Botany, 10:290–300, 1959.

B. D. Ripley. Neural networks and related methods for classiﬁcation. Journal of the Royal

Statistical Society B, (3):409–456, 1994.

D. E. Rumelhart, J. L. McClelland, and the PDP Research Group. Parallel Distributed

Processing: Explorations in the Microstructure of Cognition. MIT Press, 1986.

S. Saarinen, R. Bramley, and G. Cybenko. Ill-conditioning in neural network training prob-

lems. SIAM Journal on Scientiﬁc Computing, 14(3):693–714, 1993.

W. S. Sarle. Stopped training and other remedies for overﬁtting. In Proceedings of the 27th

Symposium on the Interface, 1995.

J. Schnute. A versatile growth model with statistically stable parameters. Canadian Journal

of Fish and Aquatic Science, 38:1128–1140, 1981.

G. A. F. Seber and C. J. Wild. Nonlinear Regression. John Wiley & Sons, 1989.

P. Soares, M. Tome, J. P. Skovsgaard, and J. K. Vanclay. Evaluating a growth model for for-
est management using continuous forest inventory data. Forest Ecology and Management,
71:251–265, 1995.

D. Spiegelhalter, A. Thomas, N. Best, and W. Gilks. BUGS 0.5 Examples, Volume 1 (version
i). MRC Biostatistics Unit, Institute of Public Health, Robinson Way, Cambridge CB2
2SR, URL: http://www.mrc-bsu.cam.ac.uk/bugs/mainpage.html, 1996.

H. H. Thodberg. Ace of Bayes: application of neural networks with pruning. Technical

Report 1132 E, Danish meat research institute, 1993.

J. K. Vanclay. Sustainable timber harvesting: Simulation studies in the tropical rainforests

of North Queensland. Forest Ecology and Management, 69:299–320, 1994.

J. K. Vanclay. Growth models for tropical forests: A synthesis of models and methods.

Forest Science, 41(1):7–42, Feb. 1995.

J. K. Vanclay, J. P. Skovsgaard, and C. P. Hansen. Assessing the quality of permanent
sample plot databases for growth modeling in forest plantations. Forest Ecology and
Management, 71:177–186, 1995.

A. S. Weigend, D. E. Rumelhart, and B. A. Huberman. Generalization by weight–elimination
with applications to forecasting. In R. P. L. et. al., editor, Advances in Neural Information
Processing Systems 3, pages 875–882. Morgan Kaufmann, 1991.

P. M. Williams. Bayesian regulerization and pruning using a Laplace prior. Neural Compu-

tation, 7:117–143, 1995.

Winston, inc., 1972.

R. L. Winkler. An Introduction to Bayesian Inference and Decision. Holt, Rinehart and

75

B. Zeide. Analysis of growth equations. Forest Science, 39(3):594–616, Aug. 1993.

A. Zellner. The Bayesian method of moments (BMOM) theory and applications. Un-
published report, HGB Alexander Research Foundation, Graduate School of Business,
University of Chicago, 1996.

76

