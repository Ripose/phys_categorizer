Statistical model for intermittent plasma edge turbulence 

F. Sattin and N. Vianello 

Consorzio RFX, Corso Stati Uniti 4, 

35127 Padova, ITALY 

Abstract 

The  Probability  Distribution  Function  of  plasma  density  fluctuations  at  the  edge  of 

fusion devices is known to be skewed and strongly non-Gaussian. The causes of this 

peculiar  behaviour  are,  up  to  now,  largely  unexplored.  On  the  other  hand, 

understanding  the  origin  and  the  properties  of  edge  turbulence  is  a  key  issue  in 

magnetic  fusion  research.  In  this  work  we  show  that  a  stochastic  fragmentation 

model,  already  successfully  applied  to  fluid  turbulence,  is  able  to  predict  an 

asymmetric  distribution  that  closely  matches  experimental  data.  The  asymmetry  is 

found to be a direct consequence of intermittency. A discussion of our results in terms 

of recently suggested BHP universal curve [S.T. Bramwell, P.C.W. Holdsworth, J.-F. 

Pinton,  Nature  (London)  396,  552  (1998)],  that  should  hold  for  strongly  correlated 

and critical systems, is also proposed  

PACS: 52.25.Gj; 52.35.Ra; 05.40.-a 

 

 

 

 

 

 

1. Introduction 

The  investigation  of  the  mechanisms  underlying  turbulence  is  a  key  topic  in  fusion 

research  and,  more  broadly,  plasma  physics.  In  particular,  thanks  to  the  steady 

increase  in  computing  power,  the  direct  numerical  solving  of  fluid  or  kinetic 

equations is more and more widespread.  However,  direct  numerical  simulations  still 

have  some  drawbacks:  first  of  all,  one  can  hardly  hope  of  tackling  the  full  set  of 

equations;  rather,  must  truncate  them  by  choosing  a  priori  the  relevant  instabilities 

and  this,  of  course,  introduces  some  arbitrariness  as  well  as  loss  of  accuracy  and 

predictive  power.  Second,  turbulence  is  a  mechanism  involving  widely  differing 

spatial  and  temporal  scales,  and  this  is  demanding  for  numerical  computations. 

Finally,  a  difficult  task  with  numerical  simulations  is  how  to  abstract  basic  plasma 

properties from huge amount of data; that is, it is often difficult to grasp any intuitive 

picture  of  the  problem  at  hand.  For  these  reasons,  phenomenological  models  are 

valuable:  they  guess  from  the  outset  some  basic  properties  of  the  plasma,  and 

complement them with an intuitive (but hopefully accurate) picture of the microscopic 

dynamics.  The  result  is  a  model  with  good  interpretive  and  predictive  capabilities 

realized  with  an  economy  of  concepts,  mathematical  and  numerical  machinery.  The 

drawback being, usually, an agreement with experiment not exceedingly accurate.   

Within  this  class  of  models,  the  best  known  is  the  approach  based  upon  the  Self 

Organized  Criticality  (SOC)  paradigm,  put  forth  by  Carreras  and  co-workers  (see, 

e.g.,  [1,2]  for  its  description  and  application  to  plasmas),  which  has  enjoyed 

widespread  consideration.  However,  alongside  with  works  supporting  this  theory, 

there is also evidence suggesting that SOC alone is too simplified a picture to account 

for all of the complexity shown in real plasmas. In particular, a key element required 

by  SOC  is  self-similarity  of  plasma  behaviour  over  the  scale  of  lengths  relevant  for 

transport.  Although  this  requisite  was  claimed  to  be  satisfied  in  several  devices  [3], 

some  other  experimental  results  [4],  supplemented  also  by  simulations  [5],  suggest 

that  this  might  not  be  the  case,  at  least  in  a  number  of  other  cases.  For  this  reason, 

alternate approaches have been suggested, e.g., based upon shell models [6]. 

A  common  finding  of  the  studies  devoted  to  the  statistical  properties  of  plasma 

turbulence  is  that  many  of  its  features  are  universal:  independent  of  the  device  and, 

hence, of the details of the free energy driving the turbulence itself. This means that, 

in principle, one could develop a model based on very general principles, without any 

reference  to  specific  mechanisms  triggering  and  sustaining  turbulence  that,  instead, 

are necessary in traditional fully numerical methods, and that can be specific to each 

setting. In this work we present an attempt of edge plasma turbulence modelling based 

on  a  statistical  approach  à  la  Kolmogorov.  Intermittency-i.e.  departure  from  self 

similarity-is naturally embodied into the model and, indeed, constitutes a fundamental 

part of it. The model is patterned after the paper by Portelli et al [7] (hereafter referred 

to  as  I),  with  small  differences  due  to  the  different  settings  and  quantities  under 

observation.  We  will  show,  using  this  model,  that  the  experimental  Probability 

Distribution Functions (PDFs) for particle density fluctuations at the edge of a fusion 

device may be fairly well recovered. 

 

2. Model for intermittent turbulence  

The picture we are going to propose is the following: we suppose that particle density 

plays  the  role  of  a  passive  scalar  advected  by  eddies  of  various  sizes.  Mixing 

processes make density almost uniform within each eddy, while two eddies may have 

even  widely  differing  densities.  A  fragmentation  process,  which  preserve  the  total 

particle density, does exists splitting larges eddies into smaller ones. Also, molecular 

processes  contribute  to  further  fragment  eddies  into  a  gas  of  independent  particles 

and, in particular, such mechanisms are dominant at small lengths, i.e., no eddies are 
thought to exist below a given size (dissipative length) h

. At the other extreme, there 

is  instead  the  macroscopical  scale  L  that  sets  the  typical  size  over  which  actual 

measurements are performed. A comment is in order at this point. In fluid turbulence 

studies one has a clear-cut distinction between the medium (the fluid) and the passive 

scalar advected (usually, the flow velocity  or  acceleration).  In  this  case,  instead,  the 

medium and the passive scalar do appear to coincide (eddies are made of particles).  

Any  experimental  measurement  of  density  results  partially  from  this  gas  of 

independent  eddies  over  all  allowed  sizes,  and  partially  from  the  background  of 

single-particle  contributions.  Experimentally,  it  has  been  found  in  a  number  of 

devices that the relative weights of the two contributions are comparable, when not in 

favour  of  the  eddies  (this  statement  addresses,  to  be  precise,  to  particle  flux,  rather 

than  particle  density,  but  we  are  allowed  to  think  that  the  results  should  be  similar. 

See  papers  [3,4,8]).  The  independent-particle  part  alone  would  provide  a  purely 

Gaussian  PDF  of  density  fluctuations.  Adding  a  substantial  contribution  from  the 

coherent eddies will drastically modify the tails of this distribution. The central region 

around  the  maximum  will  be  modified  to  a  lesser  extent,  remaining  approximately 

Gaussian. The degree of the perturbation and the width of this region depend on the 

relative weights of the two contributions as well as on the details on the statistics.   

We use, as customary, a discrete set of scales l, labelled by the index n, 0 (cid:1) n (cid:1) (cid:2) ; 

adopt the standard convention of a constant ratio between two adjacent scale lengths, 

l
(

n

1

/

l

n

3

)

r

, and choose the largest  and smallest scale equal to the macroscopical 

and dissipation length respectively: 

l

0

,
LlL

h=

, thus 

r

=L

(

L

/

h

3)

Re

. With the 

latter definition we imply that (cid:3)(cid:2) plays the role of an effective Reynolds number. 
),(~
p
trn

Another key quantity is the instantaneous local density flux at scale ln, 

[units 

(length)-3(cid:4)(time)-1]  ,  i.e.  the  flux  of  matter  that  from  largest  scales  flows  into 

structures at scale ln. Experimentally, only the largest scales are likely to be directly 

measurable.  The  smaller  ones  will  be  averaged  by  the  measuring  device  and 

procedure. Hence, we cannot work directly with 

, rather the density flux must 

),(~
p
trn

be averaged over the macroscopical observation volume: 

p

=

)(
t

n

3
rd

(cid:1)

),(~
p
tr

n

 . 

 

1
3
L

 

 

(1) 

Notice  that  the  mathematical  averaging  (1)  has  an  exact  experimental  counterpart 

when the measurement is performed  over  a  large  volume,  if  compared  with  average 

eddies’ size. This could be the case of density fluctuations measured through Neutral 

Beam  Emission  Spectroscopy.  At  the  edge,  measurements  are  performed  through 

Langmuir probes, of moderate size even for plasma fluctuations. On the  other hand, 

the  typical  measurement  time  cannot  be  made  small  with  respect  to  all  time  scales. 

Hence,  the  average  (1)  is  experimentally  a  time  average,  translated  to  a  spatial  one 

through ergodicity or Taylor’s frozen turbulence hypothesis.  

At  each  scale  ln,  molecular  processes  will  remove  part  of  the  particles  from  the 
coherent behaviour within the eddy. We designate by m 0 this rate of consumption per 

unit volume. This quantity, by definition, cannot depend from scale l.  

We  introduce  now  the  excess  instantaneous  density:

tN
)(

=

(

tN
)(

N

)

.  It  is  the 

difference  between  the  instantaneous  density  at  time  t,  N(t),  and  its  long-time 

averaged  value  N .  The  excess  density  is  determined  by  the  net  difference  between 

source and loss terms at each length scale, summed over all scales: 

 

”
-
”
”
-
D
)(
tN

=

t

(
(cid:2) -
p

n

m

)

 

0

n

 

 

 

(2) 

The  time  scale  t ,  as  remarked  by  Portelli  et  al,  should  be  a  purely  macroscopical 

parameter, determined by density injection at the largest scales (fuelling mechanism). 

As such, it does not depend from scale l, nor it is likely it depends strongly from any 

microscopical detail within the present model. 

Rigorously  speaking,  a  fully  consistent  theory  must  provide  the  dynamics  of 

p

)(tn

 

and, thus, of (cid:5)N(t). Lacking of such a theory, we must disregard dynamics and turn to 

a statistical point of view, making the assumptions that the 

p
(

n

m

0

)

 are statistically 

independent  stochastic  variables.  Indeed,  both 

p

n

  and  m 0  individually  might  be 

stochastic  variables.  However,  even  though  m 0  may  fluctuate,  it  depends  from 
molecular  processes,  not  from  fluid  ones;  hence,  we  expect  that  rms(d m 0)  << 

rms(

d p

n

), and m 0 will be considered as a constant offset.  

It is Eq. (2) where intermittency comes into the model: in the standard Kolmogorov’s 

K41  turbulence  theory  (cid:5)N  is  not  a  stochastic  variable  but  a  constant.  Since,  by 

definition, its average value must be zero under stationary conditions, it must be null 

at all times as  well. Hence the rhs  of  (2)    must  be  postulated  to  be  identically  zero, 

too,  while  in  our  approach  it  is  only  in  a  statistical  sense:  <(cid:5)N>  =  0,  but    (cid:5)N  (cid:6)  0 

The  PDF  for  N,  P((cid:5)N),  can  be  written  starting  from  the  product  of  PDFs  for 

p
(

p

n

m

p
d
()

0

n

m

)

0

=

p

(cid:2)

p
(

n

m

)

0

p
(

d

n

m

)

  

0

 

(cid:8)
(cid:6)
(cid:7)

n

(cid:5)
(cid:3)
(cid:4)

n

stage, 

we 

make 

the 

replacement 

of 

variables 

m

),

x
1

0

=

p

1

m

,

...

,

x

0

=

p

m

0

,  thus  apart  for  a  trivial  volume 

element, we may identify 

(
NP

)

=

p
(

p

n

m

)

 

0

 

 

(3) 

n

This  is  the  standard  problem  of  computing  the  PDF  for  a  quantity  sum  of  a  finite 

number  of  other  stochastic  variables.  The  general  solution  is  reviewed  in  a  recent 

paper [9], although is fairly straightforward. We introduce the characteristic function 

 

 

almost always. 

p
(

n

m

)

 : 

0

At 

=

N

n

this 
(cid:2)

p
(

n

n

D
-
-
-
-
-
-
(cid:213)
(cid:213)
-
-
-
D
L
L
(cid:213)
-
D
(k): 

k
)(

(cid:213)=

)(~
n kp

n

yields 

 is the product of the Fourier transforms of p

p
(

n

m

0

)

. This 

NP
(

)

=

ikN

e

k
)(

 

 

 

 

(4) 

+¥

(cid:1)

dk
p
2

In  order  to  simplify  notation,  here  and  henceforth  we  will  normalize  data  to  unity 

standard deviation:

s

D N

(

1)

. 

The  fundamental  role  is  played  by  the  PDF  for  the  flux,  p(p n).  A  lot  of  effort  was 

devoted  in  turbulence  studies  to  provide  an  analytical  expression  for  this  quantity, 

starting  from  the  log-normal  expression  by  Kolmogorov  and  Obukhov  [10],  to  the 

log-Poisson by She and Levèque [11], just to mention some. Here,  we note that Eq. 

(1) can be discretized into a sum over small equal-volume cells: 

p

)(
t

n

(cid:2)

),(~
p
tr
i

n

 

V
3
L

i

 

 

 

(5) 

where i is an index labelling one generic cell, 

ir a point representative of the position 

of the cell, and (cid:5)V the volume of the cell. Each cell may be given the size of the eddy 
at that scale: (cid:5)V = l3. Hence, the total number of cells is given at each scale by n (ln) »
 
[(L/ln)3] = [r n]  (the square brackets [...] stand for the integer part). We carry further 

the statistical view, and consider the 

 stochastic variables. They are, by 

definition,  positive-definite  quantities: 

2
i

.  We  can  make  just  a  few 

independent variables; II) the average value of 

statements  about  the  stochastic  variables  Zi’s:  I)  they  are  indentical  statistically 
p~ (hence Z2) must coincide with (cid:7)0 . 
p~ )  also  to  be  a  reasonably  well  behaved  function,  vanishing  to 

We  expect  PDF(

n

(~
p

n

’s as n

tri
),
),(~
p
tr
i

n

infinity and at 

0

 (by continuity, taking into account that negative values are not 

permitted)  .  Finally,  dealing  with  macroscopic  systems,  it  is  reasonable  to  assume 
p~ ) to have a single maximum, practically identical with the average  value (cid:7)0. 

PDF(

n

All these requisites are fulfilled by a chi-squared PDF for 

2

iZ or, in other terms, by a 

normal distribution for Zi:: P(Zi) 
together with the relative independence of variables p~  :  

exp

2
iZ

s
2/(

2
Z

(

))

. Hence, we may write, using (5) 

p
(

p

=

p

)

n

(cid:2)

)(~
p
i

n

))(~(
p
i

p

n

=

(cid:8)
(cid:6)
(cid:7)

i

(cid:5)
=(cid:3)
(cid:4)

i

n
m

(cid:8)
(cid:6)(cid:6)
(cid:7)

0

p

n
(cid:5)
G(cid:3)(cid:3)
(cid:4)

1

n
n
n
)(

(cid:8)
(cid:6)(cid:6)
exp
(cid:7)

n

p
m

(cid:5)
(cid:3)(cid:3)
(cid:4)

 

n

0

 

(6) 

n

~ =
p

n

Y
Y
-
¥
-
Y
D
”
D
»
Z
”
-
(cid:181)
-
-
(cid:213)
where  we  have  already  taken  into  account  that  the  average  value  <p n>  =  m 0  .  The 

result (6) is a textbook exercise of composition of probability densities; the r.h.s. is a 
Gamma (or (cid:8)2) PDF.  

This is the same expression used  in  I,  guessed  there  just  on  the  basis  of  the  nice  fit 

with  experimental  data.  Here,  we  are  providing  also  some  theoretical  ground  for  it: 

even though it must remain clear that ours is not a first-principle derivation, and there 

is some  amount of arbitrariness, we think we have provided some sound reasons to 

suspect that Eq. (6) is a valid candidate to the true PDF.  
Since the PDF of p n(t) plays a major role, we spend some more  words about it. We 
found  that  it  is  important  to  guess  the  precise  analytical  form  of    p(p n),  but  is  not 

critical:  Portelli  et  al  showed  that  two  rather  different  analytical  expressions,  log-
normal  and  c -squared,  yield  predictions  that  are  hardly  distinguishable-within 

experimental  error  bars-over  the  available  range  of  variation  of  the  independent 
variable,  with  a  little  advantage  in  favour  of  the  c -squared  PDF;  also  theoretical 

reasons  are  known  since  long,  suggesting  that  the  log-normal  is  not  the  ideal 
candidate PDF [10]. Hence, from here on, we will limit to consider Eq. (6) for p(p n), 

knowing that even departures from this form-within some limits-are not likely to give 

remarkable differences. 
Notice that here we are speaking about PDFs for p n variables. They are different from 

the  PDF  for  (cid:5)N,  which  is  instead  the  physically  relevant  variable.  However,  it  is 

known that log-normal PDFs are often associated with fragmentation process, hence 

we may expect  P((cid:5)N), also, to be close to a log-normal curve. In the paper [12] we 

developed a semi-phenomenological model for density fluctuations. A model charge 

continuity  equation  was  written,  yielding  a  functional  dependence  between  density 

and  potential  fluctuations.  The  latter  ones  had  to  be  guessed  from  experiment.  The 

result was, approximately, a lognormal form for density fluctuations which fitted well 

data  over  most  of  their  range.  It  is  interesting  to  see  that  the  result  [1]  can  be 
accommodated  within  the  present  model  by  choosing  a  log-normal  form  for  p(p n), 
together with L =0.  
The Fourier transform of  p(p n –m 0) is, thus, 

)(~
kp

=

(
m
ik
m
k
n

exp
(cid:8) +
(cid:6)
1
(cid:7)

i

0

0

)

n
(cid:5)
(cid:3)
(cid:4)

 

 

 

 

 

 

(7) 

 This expression is straightforwardly generalized to the product over the index n, and 

one gets, from Eq. (3)  

NP
(

)

=

+¥

(cid:1)

dk
p
2

exp

(cid:14)
Nik
(cid:12)
(cid:13)

+

(cid:2)

n

(cid:8)
(cid:6)(cid:6)
(cid:7)

m
ik

0

n

(cid:8) +
(cid:6)
log
1
(cid:7)

i

m
k
n

0

(cid:5)
(cid:3)
(cid:4)

(cid:5)
(cid:3)(cid:3)
(cid:4)

(cid:11)
(cid:9)
(cid:10)

=

1
p m
2

0

¥+

x
d

(cid:1)

exp

x

(cid:14)
i
(cid:12)
(cid:13)

(cid:8) D
(cid:6)(cid:6)
(cid:7)

N

m

0

(cid:5)
(cid:3)(cid:3)
(cid:4)

+

(cid:2)

n

(cid:8)
(cid:6)(cid:6)
(cid:7)

x

i

n

(cid:8) +
(cid:6)
log
1
(cid:7)

x
n

i

(cid:5)
(cid:3)
(cid:4)

(cid:5)
(cid:3)(cid:3)
(cid:4)

(cid:11)
(cid:9)
(cid:10)

 

 

 

 

 

 
where we have written for compactness the sum over the index n

 

 

 

 

 

 

 

(8) 

, but remember that, 

  =  [r n].  Apart  from  a  trivial 
more  appropriately,  it  is  over  n  (
normalization factor, the fitting formula (8) depends upon three free parameters: m 0, r , 

),  and  n

£ n

0

 (or Re). The former two are likely to be related solely to the microscopic processes 

governing the turbulence. The third, playing the role of Reynolds number, should in 

principle depend upon the macroscopic setup as well. 

 

3. Testing against RFX data 

In  the  following,  we  will  test  our  model  against  experimental  data  from  RFX 

Reversed  Field  Pinch  [1].  The  data  were  taken  at  the  very  edge  plasma  using 

Langmuir probes with a sampling  frequency of  1 MHz, during the flat-top phase of 
pulses.  The  total  number  of  collected  points  ranges  between  2· 104  and  4· 104. 

Langmuir  probes  are  operated  in  RFX  only  with  low-current  low-temperature 

plasmas. Edge temperature is varying in the 10-30 eV range for these pulses, and is 

only weakly dependent upon core temperature. For the same conditions, edge density 
is less than 1· 1019 m-3. More details about experimental arrangements can be found in 

[1].   

Figure (1) is the main result of this work and features a few samples of the PDFs for 

density fluctuations, together with fits produced using Eq. (8). From top to bottom, we 

feature different probe insertions, for excursions differing up to about 1 cm. The best 

fitting  curves-the  solid  ones-yield  in  all  cases  an  excellent  interpolation  of 

experimental data. Error bars, of course, account for qualifying the goodness of a fit. 

We are not able to quantify the errors due to measurement. Limiting to those due to 

statistics (and assuming Poissonian statistics), we can state that they would be of the 
same size of the symbols as appearing in figure. The m 0 parameter has the meaning of 

a scaling factor and is important in deciding the slope of the PDF at high (cid:5)N’s The 

¥
-
¥
-
-
-
D
D
L
£
L
parameter  r

  has  typical  value  »

  40,  yields  a  fraction  between  3  and  4  for  relative 

linear  sizes  of  eddies  at  two  successive  scales.  As  for  L

,  from  the  structure  of  the 

function  (8)  it  is  expected  that  the  terms  with  higher  n ’s  give  smaller  and  smaller 

contributions.  In  Fig.  (1),  top  plot,  it is  shown  that  the  difference  between  retaining 
terms up to L

 = 6 (solid curve) is fairly small. On the other 

 = 3 (chain curve) or L

hand, small n ’s  gauge the importance of the departure of self-similarity, since this is 

expected  to  be  more  relevant  for  small  scales,  close  to  the  dissipative  ones:  let  us 
imagine,  in  the  sum  (8),  to  remove  the  lowest  terms,  leaving  only  higher  n ’s.  This 

corresponds  to  imposing  self-similarity  at  the  smallest  scales.  The  result  is  that  the 

PDF  P((cid:5)N)  approaches  a  Gaussian.  Hence,  this  stresses  again  that  departures  from 

self-similarity are essential to recover experimental data. The same result was found 

on RFX through a wavelet analysis of experimental data. Wavelets filtering allows to 

discern  contributions  from  differing  time  scales  (or  space  scales,  if  Taylor’s  frozen 

turbulence hypothesis holds). At the largest scales, all PDF’s were found to converge 

towards Gaussians, while departures from Gaussians became more and more relevant 

towards smaller scales [4].    

The issue of departure from self-similarity has been pointed out by several papers to 

be a key feature of plasma edge turbulence [4]. This fact was often used negatively, 

i.e., to rule out some models as unsuitable candidates for the description of turbulent 

transport. In this work we were able to use it a key element in a constructive fashion, 

as  an  ingredient  within  a  micoscopical  plasma  modelling.  The  physical  process  we 

have  built  is  basically  a  direct  transfer  of  particle  density,  from  larger  to  smaller 

scales. The issue of the existence of direct or inverse cascades is still an open-ended 

question in turbulence, both for neutral fluids as well as for plasmas. It is known, by 

example, that two-dimensional Magneto Hydrodynamics (MHD) predicts  an inverse 

cascade process for energy. The Reynold stress is the term in fluid or MHD equations 

that may interchange energy between different scales in plasmas. Indeed, theoretical 

speculations do exist since long supporting the idea that both kinds of cascades may 

exist  in  plasmas-possibly  depending  on  scales  [1].  Experimentally,  only  few  partial 

results  still  do  exist,  aimed  at  investigating  the  effects  of  this  term.  The  evidence 

coming from them, at present, is that such energy transfers do actually occur [1] and 

that may be functions not only of spatial scale but also of the position into the plasma 

[1].  Of  course,  since  no  straightforward  correspondence  may  be  envisaged  between 

energy and density behaviour, this can give just an insight of what may be expected 

for density. Hence, the whole question whether in this work we have been describing 

a  mechanism  truly  at  work  in  plasmas  is  largely  unanswered,  although  the  good 

agreement  obtained  here  may  seen  as  an  hint  in  favour  of  the  existence  of  direct 

cascades.  

 

Figure 1. Symbols, PDF of experimental density fluctuations. From top to bottom, deeper to shallower 
probe insertion. The density is normalized to the experimental mean square deviation, and shifted by an 
offset so that the maximum of the PDF is for (cid:5)N = 0. Statistical error bars are about the same size of 
the symbols. Curves, Eq. (8) for various values of parameters m 0, r , L
. Top plot: solid curve (m 0 =1.1, r  
= 45, L = 6); dashed curve  (m 0 =1.1, r  = 17, L = 6); dotted curve (m 0 =1.8, r  = 45, L = 6); chain curve 
(m 0 =1.1, r  = 45, L = 3). Chain curve is almost perfectly overlapping the solid curve. Middle plot: (m 0 
=0.95, r  = 45, L = 6). Because of the smaller number of counts, in order to keep statistics constant, this 
plot has been generated using lesser bins. Bottom plot: (m 0 =0.5, r  = 35, L = 6).  
 
 
4. Concluding remarks 

Summarizing,  we  think  we  have  been  able  to  give  a  fairly  good  account  of 

phenomenology within a single interpretive framework. Up to now, our approach has 

led practically to a fitting formula containing some arbitrary parameters that are just 

fixed by matching PDF data. It would be reassuring being able to relate the numerical 

values  of  these  parameters  with  corresponding  quantities  actually  found  in  plasmas. 

Let us try to do this step further: the most straightforward quantities to be dealt with 
are L and  h

, the characteristic length scales involved. An intuitive meaning  for L is 

the  typical  scale  at  which  coherent  structures  are  observed,  that  is  order  of 
centimeters. A bit more difficult is to attach a meaning to h

; however, a lower bound 

for it is naively found: h

the fluidlike description of plasma must break down. Hence, we may assume  h

 cannot be smaller than Debye length l D, since at this length 
 l D. 

 ‡

From previous paragraphs, and using typical values for r

, L

/L = r

-L

/3 £

 10-3, or h

 £

 10-5 m. This is comforting since-in RFX-l D»

 as arising from figure 1, 
 O(10-6 ‚

 

we get h
-5) m.  

To finish with, we address another important issue, correlated with the present work: 

a  considerable  interest  has  been  raised  in  the  past  (and  still  is)  in  searching  for 

unifying  features  from  disparate  turbulent  systems,  independently  from  specific 

models.  Undisclosing  universal  aspects,  common  to  all  or  to  a  class  of  turbulent 

systems, may shed light on the underlying physics, when lacking better information. 

Again,  we  limit  here  to  statistical  tools  dealing  with  PDFs.  In  recent  years,  some 

interesting works appeared concerning universal features of PDFs in several strongly 

correlated  systems  [1].  The  suggestion,  there,  was  that  PDFs  of  fluctuations  follow 

just one universal curve (BHP curve), a generalized form of the Gumbel’s distribution 

Ga(x). Gumbel’s curve is well known in statistics, giving the probability of picking the 

a-th largest value from an ensemble of uncorrelated variables. Connections between 

these systems and Extreme Value Distributions, hence, arise intuitively. BHP curve is 
peculiar in that a is universal and noninteger: a = p /2. It was suggested this value to 

represent  an  effective  number  of  degrees  of  freedom  for  a  system  of  correlated 

variables. Indeed, BHP curves apparently strongly resemble the skewed distributions 

we  have  found  in  Fig.  (1).  Hence,  the  question  whether  BHP  approach  could  be 
extended to our plasmas appears fairly interesting1.   

As  far  as  we  understand,  however,  the  matter  is  not  still  entirely  settled:  there  are 

claims that BHP functions could not be truly universal [20]; also, Watkins et al [21] 

pointed  out  that  long-range  correlations  could  not  be  the  only  ingredient  leading  to 

BHP curve, but also the finite-size of the system is. Finally, Rypdal and Ratynskaia 

[22] carried on recently an analysis of fluctuations in a magnetized (but not fusionist) 

plasma  using,  among  other  tools,  the  BHP  approach.  Although  their  results  were 

encouraging,  they  commented  that,  unless  one  has  a  very  good  statistics  spanning 

long  intervals,  there  are  several  possible  distributions  fitting  the  data  within 

approximately  the  same  accuracy.  Hence,  no  definite  claim  may  be  made  of  the 

                                                 
1 While this paper was finishing the reviewing stage, the paper [19] appeared, where Van Milligen et al 
tackled the same kind of analysis in tokamak plasmas. 

superiority  of  one  distribution  over  the  others  (We  made  a  similar  comment  in  the 

previous paragraphs after Eq. 6). Keeping in mind this caveat, we performed a fit of 

data  in  Fig.  (1)  using  generalized  Gumbel  distributions,  but  leaving  a  as  a  free 

parameter.  Our  results  do  not  appear  supporting  BHP  distributions:  the  accuracy 
imposed by our data was enough to definitely rule out the possibility a = p /2, while 

we found rather that a reasonable fit of data was obtained only for a »

 0.1. Chapman 

et  al  [23]  already  showed  that  a  must  be  a  system-dependent  parameter,  and  hence 

may depart slightly from BHP value (see, about this, also the paper by Noullez and 

Pinton in [1]), but we are not aware of any satisfactory interpretation of this parameter 

that may accommodate values lesser than unity.        

 

 

 

References 
 
[1] D.E. Newman, B.A. Carreras, P.H. Diamond, T.S. Hahm, Phys. Plasmas 3, 1858 

(1996); B.A. Carreras, D. Newman, V.E. Lynch, P.H. Diamond, Phys. Plasmas 3, 

2903 (1996); R.O. Dendy and P. Helander, Plasma Phys. Control. Fusion 39, 1947 

[2] V. Tangri, A. Das, P. Kaw, and R. Singh, Phys. Rev. Lett. 91, 025001 (2003).  

[3] B.A. Carreras et al, Phys. Plasmas 5, 3632 (1998); B.A. Carreras et al, Phys. Rev. 

Lett. 83, 3653 (1999); R. Trasarti-Battistoni, D. Draghi, C. Riccardi, H.E. Roman, 

Phys. Plasmas 9, 3369 (2002). 

[4] V. Carbone, G. Regnoli, E. Martines, V. Antoni, Phys. Plasmas 7, 445 (2000); V. 

Carbone,  L.  Sorriso-Valvo,  E.  Martines,  V.  Antoni,  P.  Veltri,  Phys.  Rev.  E  62, 

R49  (2000);  E.  Spada  et  al,  Phys.  Rev.  Lett.  86,  3032  (2001);  V.  Antoni  et  al, 

Phys.  Rev.  Lett.  87,  045001  (2001);  V.  Antoni  et  al,  Europhys.  Lett.  54,  51 

[5] V. Naulin, O.E. Garcia, A.H. Nielsen, J. Juul Rasmussen, Phys. Lett. A 321, 355 

(2004); N. Mahdizadeh et al, Phys. Plasmas 11, 3932 (2004). 

[6] G. Boffetta, V. Carbone, P. Giuliani, P. Veltri, A. Vulpiani, Phys. Rev. Lett. 83, 

4662  (1999);  V.  Carbone,  F.  Lepreti  and  P.  Veltri,  Phys.  Rev.  Lett.  90,  055001 

(1997). 

(2001). 

(2003). 

[7]  B.  Portelli,  P.C.W.  Holdsworth,  and  J.-F.  Pinton,  Phys.  Rev.  Lett.  90,  104501 

[8]  V.  Antoni,  in  Recent  Res.  Devel.  Plasmas  2  (Transworld  Research  Network, 

(2003). 

Trivandrum, India, 2002). 

[9] M.I. Tribelsky, Phys. Rev. Lett. 89, 070201 (2002). 

[10] U. Frisch, Turbulence (Cambridge University Press, 1995). 

[11] Z.-S. She and E. Levèque, Phys. Rev. Lett. 72, 336 (1994); Z.-S. She and E.C. 

Waymire, Phys. Rev. Lett. 74, 262 (1995). 

[1] F. Sattin, N. Vianello, M. Valisa, Phys. Plasmas 11, 5032 (2004). 

[1] G. Rostagni, Fus. Eng. Design 25, 301 (1995). 

[1] V. Antoni et al, Phys. Rev. Lett. 80, 4185 (1998). 

[1]  A.  Yoshizawa,  S.-I.  Itoh,  K.  Itoh,  Plasma  and  Fluid  Turbulence  (Institute  of 

[1]  P.H.  Diamond  et  al,  Phys.  Rev.  Lett.  84,  4842  (2000);  H.  Xia  and  M.G.  Shats, 

Physics Publishing,  2003).  

Phys. Plasmas 11, 561 (2004). 

[1]  E.  Sànchez  et  al,  “On  the  energy  transfer  between  flows  and  turbulence  in  the 
plasma  boundary  of  fusion  devices”,  poster  P-210,  presented  at  the  16th 

International  Conference  on  Plasma  Surface  Interactions  (Portland,  Maine, 

2004). To appear in Jour. Nucl. Mat.  

[1]  S.T.  Bramwell,  P.C.W.  Holdsworth,  J.-F.  Pinton,  Nature  (London)  396,  552 

(1998); S.T. Bramwell et al, Phys. Rev. Lett. 84, 3744 (2000); S.T. Bramwell et 

al,  Phys.  Rev.  E  63,  041106  (2001);  A.  Noullez  and  J.-F.  Pinton,  Eur.  Phys. 

Jour. B 28, 231 (2002). 

[19] B. Ph. Van Milligen et al, Phys. Plasmas 12, 052507 (2005). 

[20] V. Aji and N. Goldenfeld, Phys. Rev. Lett. 86, 1007 (2001). 

[21]  N.W.  Watkins,  S.C.  Chapman  and  G.  Rowlands,  Phys.  Rev.  Lett.  89,  208901 

(2002); S.T. Bramwell et al, Phys. Rev. Lett. 89, 208902 (2002). 

[22] K. Rypdal and S. Ratynskaia, Phys. Plasmas 10, 2686 (2003). 

[23] S.C. Chapman, G. Rowlands and N.W. Watkins, Nonlin. Proc. Geophys. 9, 409 

(2002). 

 

