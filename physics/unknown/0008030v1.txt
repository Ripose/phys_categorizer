RBF neural net based classifier for the AIRIX accelerator fault diagnosis

LAM - Université de Reims Champagne-Ardenne - F51687 REIMS cedex2

J.C. Ribes, G. Delaunay

J. Delvaux, E. Merle, M. Mouillet

CEA - PEM   F51490 Pontfaverger - France

Abstract

2. EXPERIMENTAL CONTEXT

is  a  high  current 

The  AIRIX  facility 
linear
accelerator (2-3.5kA) used for flash-radiography at
the  CEA  of  Moronvilliers  France.  The  general
background  of  this  study  is  the  diagnosis  and  the
predictive  maintenance  of  AIRIX.  We  will  present
a  tool  for  fault  diagnosis  and  monitoring  based  on
pattern  recognition  using  artificial  neural  network.
Parameters  extracted  from  the  signals  recorded  on
each  shot  are  used  to  define  a  vector  to  be
classified.  The  principal  component  analysis
permits  us  to  select  the  most  pertinent  information
and  reduce  the  redundancy.  A  three  layer  Radial
Basis  Function  (RBF)  neural  network  is  used  to
classify  the  states  of  the  accelerator.  We  initialize
the  network  by  applying  an  unsupervised  fuzzy
technique  to  the  training  base.  This  allows  us  to
determine the number of  clusters and real  classes,
which define the number of cells on the hidden and
output layers of the network. The weights between
the hidden and the output layers, realising the non-
convex  union  of  the  clusters,  are  determined  by  a
least  square  method.  Membership  and  ambiguity
rejection  enable  the  network  to  learn  unknown
failures,  and    to  monitor  accelerator  operations  to
predict  future  failures.  We  will  present  the  first
results obtained on the injector.

1. INTRODUCTION

interessed 

The    AIRIX  induction  accelerator  [1]  is  used  for
flash  radiography  .  The  single  shot  functioning
needs  to  be  optimal  at  the  desired  time.  We  try  to
define a supervision  method for fault diagnosis  for
the AIRIX facility.  The goal is to garanty optimal
functioning and to search precursors for the known
failures  in  developping  predictive  maintenance  .
We  are 
to  diagnosis  using  pattern
recognition  with  neural  network,  and  particularly
RBF  nets.  RBF  neural  nets  are  employed  for
supervised  classification.  We  propose  an  original
strategy  to  create  RBF  nets  for  unsupervised
classification.
First  we  present    the  experimental  context  and  the
goal  of  the  study.  In  the  following  paragraphs,  we
develop the strategy used for defining an adaptative
supervised  classifier  with  unsupervised  data.
Finally, we expose the first results obtained for the
injector  based  on  data  from  the  year  1999  to  the
first trimester 2000.

The AIRIX facility consists in an injector, 32  high
voltage  generators  and  64  induction  cells.  The
single  shot  functioning  imposes  to  obtain  the  best
performances at a  given time. We  try  to  develop  a
predictive  maintenance  based  on  signal  processing
and pattern recognition. Firstly this application is an
help  for  users,  principaly  to  have  a  most  precise
diagnosis and an automatic quick view of the state
of the accelerator during the experiments. Secondly
the  results  of  automatic  recognition  could  be  an
help to detect functioning drift to plan maintenance
operations.
About  300  signals  are  recorded  during  each
experiment.  The  complexity  of  the  installation
imposes  to  decompose  the  different  module  into
sub-systems  to  realize  a  precise  diagnosis.  Signal
processing  permits  to  caracterize  electrical  signals
of  the  machine.  Those  parameters  define  the  state
of    functioning  as  a  vector  to  be  classified.  We
focus  on  the  injector  to  develop  a  prototype  of
supervisor.  The  injector  [2],  which  creates  the
electron  beam,  can  be  separated  in  three  main
modules  :  the  prime  power,  the  laser  commanded
spark gaz and the vacuum diode. The electron beam
(4MeV,2kA,60ns)  is  created  by  applying  on  the
cathode  of  the  diode  a  pulse  of  4MV.  The  prime
power, which furnishes the primary high voltage,  is
caracterized by 8 parametres. For the sparks, which
allow  the  discharge  of  the  prime  power  into  the
diode  along  3  transfert  lines,  15  parametres  are
used.  The  firing  of  the  4  sparks  must  be  realized
simultaneously  with  approximativly 
the  same
current  level.  Finally  the  vacuum  diode,  in  which
the  electrons  are  emited  is  diagnosed  by  18
features.  Those  parameters  are  characteristical
values,  such  as  rise  time,  half  height,  temporal
position  of  the  different  peaks  and  frequency
values.  The  collected  data    are  used  to  define  a
supervised 
automatic
classification of failures.
The first step (part3) is to analyse the unsupervised
data  to  define  a  training  set  and  the  different
existing states. The second step (part 4) consists in
classifying  the  data  with  an  artificial  supervised
neural network.

training  base 

for 

an 

3. UNSUPERVISED DATA ANALYSIS

The  fuzzy-c-means  algorithm  [3]  allows  to  cluster
data by minimizing the following fuzzy criteria.

J

n

= m
∑ ∑
=
=
i

1

j

1

(
u

ij

)

p

2

.

d

(

x

,

g

)

i

j

m  is  the  number  of  classes  and  n  the  number  of
points. d is the euclidian distance and uij  the  fuzzy
membership of data xj to the class i. Each cluster is
defined  by  a  center  or  prototype  note  gi.  p  is  the
fuzzyfication  of  the  criteria  and  is  generally  taken
to 2.
The algorithm is composed of the following steps.
• 
initialise m, g and U.
• 
Start with an initial partition
•  Determine the center gi  with
g

)∑
(
u

(
u

)

=

x

.

n

p

n

p

ij

k

i

ij

=
1

j

∑
=
1

j

• 

update  U with 



∑


=
1
j

•  Cluster with the new centers

=

u

1

m

ki

1
−
1
p

−

−

g

k

g

j

x

i

x

i

2

2







to  determined 

The  algorithm  is  iterated  until  the  stability  of  the
prototypes.  The  principal  drawback  of  this  technic
is  that  we  impose  the  number  of  class.  The
compacity  criteria  allows 
the
sufficiant  number  of  protoype  to  cluster  the  data.
We  use  it  for  a  multiprototype  approach  of  the
clustering.  A  class  is  caracterized  by  multiple
centers.  The  number  of  real  class  in  the  data  is
determined  by  cutting  a  hierarchical  tree  calculate
on  the  centers.  We  used    the  minimization  of  the
function K as a criteria [4] to resolve the problem of
calculating the level of cutting.

−=

1

K

with 

co

gl

gl

co
co

moy
1
n

=

co

moy

=

1
m

m

∑
=
1

j

[

gxdu
ij

(.

,

j

]

2

)

i

gxdu
ij

(.

,

j

]

2

)

i

j

n

m

∑∑
= =
1 1
i
[
∑
=
1

n

i

n

∑
=
1

i

u

ij

co is the compacity in a multiprotoype approach.
This  method  has  permited  to  define  the  different
classes  and  a  supervised  training  data  set.  The
defined  classes    have  been  succesfully  physically
identified.

4. RBF NEURAL NET CLASSIFIER

They  are  constructed  with  3  layers  (fig  1).  The
hidden  neurons  use  a  non  linear  radial  basis
function activation [5]. We use a classical gaussian
form for this function.

ϕ

(x

)j

=

exp

−






2

d

)

i

(
,
j gx
22
σ






  where  d 

is 

the

euclidian  distance  between  an  observation  and  the
considered neuron and σ is the size of the gaussian.
The  weigths  between  the  hidden  and  the  output
layer are adjust during the training step.
The structure of the neural network is presented on
the next figure.

Figure 1 : RBF neural network

The  classification  is  realized  on  the  maximum
membership  principle  .  A  data  is  affected  to  the
class  with  the  maximal  output,  determined  by  :

y

k

(

x

)

j

=

m

∑

=
1

i

ϕ  avec k=1,2,…s.
(

x

)

j

w
ik

The  most  important  problem  is  to  define  the
number of cells on the hidden layer.
We  propose  to  use  the  results  of  the  precedent
section  to  define  the  number  of  neural  cells.  The
centers,  which  define 
the  clustering  can  be
interpreted as the hidden neurons and the cut of the
tree defined the number of output neural cells.
Each hidden neuron is now seen as a fuzzy set with
a gaussian membership function of size σ.
The  parametre σ is  calculated  with  the  following
formula.
=σ

−

min(

gd

(

g

li

))

kj

1
2

.l

k ≠

gkj  is  the  hidden  neuron  i  belonging  to  the  class  k
and gli the neuron i of a class l with k
Finally the network is trained with the known data
defined at the paragraph 3. The training consists in
resolving  a  linear  system  with  the  least  square
algorithm.  The  variables  to  determine  are  the
weight  of  the  last  layer  and  the  output  is  1  if  the
data belong to the class and 0 otherwise.
With  this  last  step,  we  dispose  of  a  model  able  to
classify  the  data  initialy  unsupervised,  without  the
knowledge  of  the  number  and  the  membership  of
data  to  class.  In  case  of  unknown  state  the  reject
options are used. They allow to detect observations
wich can't be reliably classified. An observation too
far  from  the  others  is  membership  rejected.  If  an
observation is too close from different classes, it is
ambiguity  rejected  The  first  reject    is  a  way  to
detect  knew  state  for  adaptation  of  the  classifier.
The second reject permits to detect the evolution of
the functioning from one class to another.

5. RESULTS

the 

We have defined an observation space for the three
subsystems  of 
injector.  The  unsupervised
analysis  of  the  data  permits  to  detect  and  to  learn
differents  state  of  the  injector's  functioning.  The
AIRIX facility is operational since the beginning of
the  year 2000. We know only few failures,  but  we
are  able  to  caracterize  the  different  levels  of
functioning.  The  injector  is  used  with  three  level
corresponding to the voltage applyed to the vacuum
diode  (initial  energy  of  the  beam),  2.3MeV  3MeV
and 4 MeV (nominal mode).
Each  sub  system  contains  at  the  initialization  3
classes,  one  for  each  level,  the  other  classes
corresponding to the known failures . The following
figures  present  the  space  of  decision  for  the
injector's subsystem (fig 2, 3 4).   We  note  that  the
differents  classes  are  well  discrimated  and  allow  a
good decision making.

5

0

-5

-10

-15

-20

-25

-30

-35

-40
20

0

-20

-40

1.5

1

0.5

0

-0.5

-1

-1.5

-2

-2.5
4

2

222

22

11

1
1111

33
33
3

5

5

Transition to class 4

Classe 4 :
Transformer failure.

-6

-4

-2

0

2

4

6

8

10

12

14

Figure 2 : prime power

3.8MeV

1

1

2

1
1
1
1

1
1

1
1

1

1

1
2
22

2

2

2

4

4
4

4

4

3

3

33

3

3

3

3

3MeV

2

0

-2

4

4

2.3MeV

-4

-7

-6

-5

-4

-3

-2

-1

0

1

2

Figure 3 : spark gaz

Etat initial

6

6

6

6
6

6

2
2

2

3MeV

2.3MeV
55

5

5

3

Electrical
breakdown

Reflected pulse
breakdown

6

1
1

3.8MeV

1
111

11

4

Failure

8

6

4

0

4

2

-6

-5

-4

-3

-2

-1

0

1

2

-6

3

-2

-4

4

2

0

-2

-4

-6

-8
-7

Figure 4 : vacuum diode

The  most  current  state  of  functioning  and  the
principal  failures  (electrical  breakdown  on  the
diode's pannel, dispersion on the spark functioning)
have been learned by the classifier.  We have obtain
the  following  results  of  good  recognition  with  our
prototype.

Table 1 : results of classification

System
Prime
spark
diode

Rejected
43
32
44

error
10
5
0

succes
380
402
390

The number of rejected point could be ameliorated
with  an  adaptation  of  the  classifier  to  new  states.
Mistake  in  decision  have  been  identified  as  a
confusion  between  levels  of    energy  and  never  as
the non detection of a failure.

A  prototype  of  classifier  with  RBF  neural  net  is
now  built.  The  good  properties  of  the  RBF  neural
net allow a good decision making, completetd with
the  reject  options,  which  improve  the  reliability  of
the  results.  This  strategy  permits  a  good  diagnosis
of the installation. We must extend the results to the
whole accelerator and use them for the maintenance
strategy.

[1]  Merle  E.  et  al  Installation  of  the  AIRIX
induction accelerator Proc. Of LINAC98, 1998.
[2]    Fockler  J.  et  al  A  4MV  ±1%  flat-top  electron
driver Proc. Of IEEE IPPC91, 1991.
[3]  Bezdek  J.C.  Pattern  recognition  with  fuzzy
objective  function  algorithms  Plenum  Press  New
York and London 1981.
[4]  Devillez  A.  Contribution  à  la  classification
floue de données comportant des classes de formes
quelconques  PHD thesis University of Reims 1999.
[5]  Looney  CG.  Pattern  recognition  using  neural
network,  theory  and  algorithms  for  engineers  and
scientists  Oxford  University  Press,  Oxford-New
York 1997.

4

6. CONCLUSION

Sparks  dispersion

7. REFERENCES

