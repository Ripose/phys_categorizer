8
9
9
1
 
b
e
F
 
1
2
 
 
]
h
p
-
h
t
a
m

[
 
 
1
v
1
4
0
2
0
8
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

The non-linear superposition principle

and the Wei–Norman method

J.F. Cari˜nena*, G. Marmo§ and J. Nasarre§§

*Depto. F´ısica Te´orica, Universidad de Zaragoza, 50009 Zaragoza, Spain.
§Dipto. di Scienze Fisiche, Universit´a di Napoli, 80125 Napoli, Italy.
§§Seminario de Matem´aticas, IES Miguel Catal´an, 50009 Zaragoza, Spain.

Abstract

Group theoretical methods are used to study some properties of the Riccati equation, which
is the only diﬀerential equation admitting a nonlinear superposition principle. The Wei–Norman
method is applied for obtaining the associated diﬀerential equation in the group SL(2, R). The
superposition principle for ﬁrst order diﬀerential equation systems and Lie-Scheﬀers theorem are
also analysed from this group theoretical perspective. Finally, the theory is applied in the solution
of second order diﬀerential equations like time independent Schr¨odinger equation.

1

Introduction

Nonlinear phenomena are having everyday more and more importance in almost all branches
of science, and in particular in Physics. One of the most important nonlinear diﬀerential
equation is the Riccati equation (see e.g.
[1] and references therein). This diﬀerential
equation has recently been shown to be related with the factorization method (see e.g.[2, 3,
4, 5]). The recent interest of this equation is steadly increasing since Witten’s introduction
of supersymmetric Quantum Mechanics [6, 7].

Two important features of this Riccati type diﬀerential equation are:
i) Even if we cannot ﬁnd the general solution by means of a ﬁnite number of quadratures

over elementary functions of the coeﬃcients ai(t) deﬁning the diﬀerential equation,

dx(t)
dt

= a0(t) + a1(t) x(t) + a2(t) x2(t),

once a particular solution x1(t) is known, the change of variable x = x1 + z leads to a new
diﬀerential equation of the Bernouilli (for n = 2) type:

(1.1)

(1.2)

dz
dt

= (2 a2 x1 + a1)z + a2 z2.

1

This is a particular instance of (1.1) for which a0 = 0. Notice that under the change of

variable w = 1/x the Riccati equation (1.1) becomes

dw(t)
dt

+ a0(t) w2(t) + a1(t) w(t) + a2(t) = 0.

(1.3)

In particular, the Bernouilli equation (1.2) can be reduced to a linear one just by intro-
ducing the new variable u = 1/z. In this way, if we know a particular solution the general
solution can be found through two quadratures.

ii) When three particular solutions, x1(t), x2(t), x3(t), of the diﬀerential equation (1.1)

are known, the general solution can be written with no quadrature at all:

x − x1
x − x2

:

x3 − x1
x3 − x2

= k,

(1.4)

where k is an arbitrary constant determining each particular solution.

In this sense we can say that there exists a nonlinear superposition principle for the Riccati
equation, because the general solution can be expressed as a function x = Φ(x1, x2, x3, k) of
three particular solutions and one arbitrary constant k.

Our aim is to explain these facts from a group theoretic viewpoint and present some new
ideas both about the Riccati equation itself and on the nonlinear superposition principle, for
which the Riccati equation is the simplest case.

The organization of this paper is as follows.

In Section 2 we review the problem of
reducing a second order linear diﬀerential equation to a nonlinear ﬁrst order Riccati equation,
what means that the original linear superposition principle for the second order equation
should be replaced by a nonlinear superposition principle. We also remark that this fact
is due to a relation of the Riccati equation with the SL(2, R) group to be explicited later.
In Section 3 we explain a method developed by Wei and Norman [8] for determining the
solution of a diﬀerential equation in a Lie group and we apply the method for the study of
the Riccati equation, ﬁnding in this way the explicit form of the superposition principle as
a consequence of some group theoretical computations. The superposition principle for ﬁrst
order diﬀerential equation systems and Lie–Scheﬀers theorem are studied in Section 4. It is
shown that for an important class of such systems the problem of ﬁnding the general solution
is reduced to the simpler problem of ﬁnding one particular solution of another system on a
Lie group G, and moreover, even without solving directly this new system the solution of the
original system can be easily found as soon as we know a fundamental set of solutions of it.
Once again the simplest case is Riccati equation and the superposition principle can be found
by determining the ﬁrst integral of a system. Finally in Section 5 we give as an example the
application of the Wei–Norman method in the solution of second order diﬀerential equations
taking as a propotype the Schr¨odinger equation for the harmonic oscillator.

2 The nonlinear superposition principle

There is a well known method of relating a linear second order diﬀerential equation with a
Riccati equation. Actually, given the linear second order diﬀerential equation

d2u
dt2 + b(t)

du
dt

+ c(t) u = 0,

2

(2.1)

the property of linearity means that the vector ﬁeld

X = u

∂
∂u

¯t(ǫ) = t,

¯u(ǫ) = eǫu.

generates a one–parameter Lie group of point symmetries of the equation (2.1)

Changing coordinate u to a new one v = ϕ(u) such that the vector ﬁeld X = u∂/∂u
becomes a translation generator (Straightening–out Theorem), i.e. X = ∂/∂v, and therefore
determined by the equation Xv = 1, leads to v = log u, i.e. u = ev, and then,

When written in terms of this new coordinate the equation (2.1) becomes

du
dt

= ev dv
dt

= u

dv
dt

.

d2v
dt2 + b(t)

dv
dt

+

2

dv
dt !

 

+ c(t) = 0.

The unknown function v does not appear in the preceding equation and therefore a
dt , and then

lowering of the order is obtained when introducing the change of variable x = dv
we will get a Riccati equation

as it was pointed out in [9].

Therefore, the linear superposition principle for solutions of (2.1) translates in a nonlinear

superposition principle for those of this Riccati equation, as it will be shown later.

Notice that (2.2) shows that

dx
dt

= −c − bx − x2,

x =

1
u

du
dt

.

The second order diﬀerential equation (2.1) is equivalent to the set of (2.3) and (2.4).
We should also remark that two solutions u1, u2 of (2.1) project on the same solution of
(2.3) if and only if there exists a nonzero real number λ ∈ R such that u2(0) = λu1(0) and
2(0) = λu′
u′

1(0).

From the geometric viewpoint, Riccati equation can be interpreted as the one determining

the integral curves of a time–dependent vector ﬁeld

Γ = (a0(t) + a1(t)x + a2(t)x2)

∂
∂x

.

Let us remark that this vector ﬁeld can be written as a linear combination with time

dependent coeﬃcients of the vector ﬁelds

L0 =

, L1 = x

∂
∂x

∂
∂x

, L2 = x2 ∂
∂x

,

which generate a three dimensional real Lie algebra with deﬁning relations

[L0, L1] = L0,

[L0, L2] = 2L1

[L1, L2] = L2,

3

(2.2)

(2.3)

(2.4)

(2.5)

(2.6)

and therefore isomorphic to sl(2, R). In fact, it is an easy matter to check that the (local)
one–parameter transformation Lie groups of R generated by L0, L1 and L2 are

x 7→ x + ǫ,

x 7→ eǫx,

x 7→

x
1 − xǫ

,

i.e., they are fundamental vector ﬁelds corresponding to the action of SL(2, R) on the real
line R extended with a point at the inﬁnity, ¯R, given by

Φ(A, x) =

αx + β
γx + δ

,

A =

α β
γ δ !

 

, if x 6= −

δ
γ

,

and

Φ(A, ∞) =

, Φ(A, −

) = ∞.

α
γ

δ
γ

3 The Wei–Norman method

Let us consider a diﬀerential equation system

which can be seen as the diﬀerential equation system whose solutions are the integral curves
of the time–dependent vector ﬁeld

dxi(t)
dt

= X i(x, t),

i = 1, . . . , n,

X = X i(x, t)

∂
∂xi .

The theorem for existence and uniqueness of solutions of the preceding diﬀerential equa-
tion tells us that, for small enough t, there exists a map Φt applying the initial condition
x(0) = (xi(0)) into the corresponding value xi(t). Correspondingly, functions f deﬁned in a
neigborhood of x(0) transform as

Φ−1
(cid:16)
and taking derivatives with respect to t we obtain

[U(t)f ](x) = f

t (x)

,

(cid:17)

dU(t)
dt

"

#

f

(x) =

d
dt
= X(f )

(cid:16)

=

dxi
dt

∂f
∂xi (Φ−1
(cid:17)
= [U(t)(Xf )](x).

t (x))

(f ◦ Φ−1

t )(x)

t (x)

Φ−1
(cid:16)

(cid:17)

This relation is valid for any diﬀerentiable function f , and therefore

(3.1)

(3.2)

(3.3)

(3.4)

We recall [8] that given such a diﬀerential equation for operators for X being a linear

combination of vector ﬁelds in Rn,

dU(t)
dt

= U(t)X.

X =

ak(t)Lk,

m

Xk=1

4

namely,

dU(t)
dt

=

ak(t)U(t)Lk,

U(t) =

exp(gi(t)Li),

m

Xk=1

m

Yi=1

where the Lk span a ﬁnite dimensional real Lie algebra, it is possible to write the general
solution in the form

where the functions gi(t) are given by the solution of the system obtained from the relation

ai(t)Li =

˙gi(t)

exp(−gj(t)adLj)

Li,

(3.7)

m

Xi=1

m

Xi=1

m


Yj=i+1






and the initial condition gi(0) = 0, i = 1, · · · , m.

This method proposed by Wei–Norman (see also [10]) can be used in the case of the Ric-
cati equation and the generalization for other diﬀerential equation system involving several
degrees of freedom is immediate. In fact, given the diﬀerential equation (1.1) there will be an
evolution operator U(t) which takes values in SL(2, R) and satisﬁes the diﬀerential equation

dU(t)
dt

= U(t)[a0(t)L0 + a1(t)L1 + a2(t)L2],

(3.8)

together with the initial condition U(0) = I, and where the vector ﬁelds Lk, for k = 0, 1, 2,
are fundamental vector ﬁelds associated to the left action of SL(2, R) on the extended real
line ¯R that are explicitly given in (2.5) and generate a Lie algebra isomorphic to sl(2, R).

According to the Wei–Norman method [8], there will be functions u0(t), u1(t), u2(t) such

that u0(0) = u1(0) = u2(0) = 0 and

U(t) = exp(u1L1) exp(u2L2) exp(u0L0).

(3.9)

Then, when using (3.7), we obtain

a0(t)L0 + a1(t)L1 + a2(t)L2 = ˙u1(t) exp(−u0(t)adL0) exp(−u2(t)adL2)L1

+ ˙u2(t) exp(−u0(t)adL0)L2 + ˙u0(t)L0
= ˙u1(L1 − u0L0 + u2L2 − 2u0u2L1 + u2
+ ˙u2(L2 − 2u0L1 + u2

0L0) + ˙u0L0,

0u2L0)

and therefore the system of diﬀerential equations for the functions ui

that can be written in normal form,

a0(t) = −u0 ˙u1 + u2
0u2 ˙u1 + u2
a1(t) = ˙u1 − 2u0u2 ˙u1 − 2u0 ˙u2
a2(t) = u2 ˙u1 + ˙u2,

0 ˙u2 + ˙u0

˙u0(t) = a0(t) + a1(t)u0(t) + a2(t)u2
˙u1(t) = a1(t) + 2a2(t)u0(t)
˙u2(t) = a2(t) − a1(t)u2(t) − 2a2(t)u0(t)u2(t).

0(t)

5

(3.5)

(3.6)

(3.10)

(3.11)

We remark that the ﬁrst equation for u0 is nothing but the original Riccati equation
and therefore it seems that there is no advantage at all. However when looking in the other
two equations, we see that provided that the appropriate solution for the ﬁrst equation,
the one determined by u0(0) = 0 has been found, the solution for the second one is almost
immediate and when introducing these values in the third equation this one becomes a ﬁrst
order diﬀerential equation and the solution reduces to a quadrature. In this sense we have
reduced the problem of ﬁnding the general solution of (1.1) to the one of ﬁnding the particular
solution such that u0(0) = 0. This is quite similar to the property i) we mentioned in the
Introduction.

Once the solution of (3.11) determined by u0(0) = u1(0) = u2(0) = 0 has been found,

the general solution of the diﬀerential equation will be written

x(t) = (U(t)x)(0) = [exp(u1L1) exp(u2L2) exp(u0L0)x]|t=0,

(3.12)

and therefore

where x0 = x(0).

x(t) =

eu1x0
1 − u2eu1x0

+ u0,

(3.13)

Let us now ﬁx three independent initial conditions. A possible set is the one given by
x1(0) → ∞, x2(0) = 0 y x3(0) = 1, (actually any other three diﬀerent initial conditions will
be transformed to this one under an appropriate transformation of the group SL(2, R)).

Having in mind the form (3.13) of the general solution, we see that the above mentioned

initial conditions determine the particular solutions

x1(t) = −

+ u0(t)

x2(t) = u0(t)

1
u2(t)

eu1(t)

x3(t) =

1 − u2(t)eu1(t) + u0(t),

and then the functions u0, u1, u2 are determined as

u0(t) = x2(t)

u1(t) = log

(x3(t) − x2(t))(x2(t) − x1(t))
(x3(t) − x1(t))

#

"

u2(t) = −

1
x2(t) − x1(t)

,

and therefore, when putting these values in (3.13), we ﬁnd that for the general solution

x(t) =

x0x1(t)(x3(t) − x2(t)) + x2(t)(x1(t) − x3(t))
x0(x3(t) − x2(t)) + (x1(t) − x3(t))

,

which is the well known superposition principle for Riccati equation (1.1) which can also be
written as

(3.14)

(3.15)

(3.16)

(3.17)

(3.18)

(3.19)

(x − x2)(x3 − x1)
(x − x1)(x3 − x2)

= x0.

6

The factorization (3.9) for the evolution operator is not the only possible one, but there
are other ﬁve alternative factorizations. We next present the results for all possible reorder-
ings:

II) When we consider the factorization

U(t) = exp(g0L0) exp(g1L1) exp(g2L2),

the associated system turns out to be

with g0(0) = g1(0) = g2(0) = 0, and then the solution is

the three particular solutions x1, x2, x3 being expressed as

˙g0 = a0e−g1
˙g1 = a1 − 2a0g2
˙g2 = a2 − a1g2 + a0g2
2,

x(t) =

eg1(x0 + g0)
1 − g2eg1(x0 + g0)

,

1
g2
g0eg1
1 − g0g2eg1

x1(t) = −

x2(t) =

x3(t) =

eg1(1 + g0)
1 − g2eg1(1 + g0)

,

x2(x1 − x3)
x1(x3 − x2)
x2
1(x3 − x2)
(x1 − x2)(x1 − x3) #

g0 =

g1 = log

g2 = −

"
1
x1

.

with the inverse relation

We should remark that the third equation in (3.20) is a new Riccati equation and that
once the solution for this new Riccati equation is found, we substitute its value in the second
one and integrate without any diﬃculty, and when this value for g1 is put in the ﬁrst equation
we can integrate it. Therefore the new result we have found here is the following:
if one
knows a solution of a related Riccati equation, given by the third one in (3.20) equation,
satisfying g2(0) = 0, the general solution of (1.1) can be found in a straightforward way.

III) The third possibility corresponds to the factorization

U(t) = exp(h2L2) exp(h1L1) exp(h0L0),

the associated system being

˙h0 = a0 + a1h0 + a2h2
0
˙h1 = a1 + 2a2h0
˙h2 = a2eh1,

7

(3.20)

(3.21)

(3.22)

(3.23)

(3.24)

(3.25)
(3.26)
(3.27)

Notice that in this approach the ﬁrst equation in (3.27) is the original equation (1.1).

IV) The fourth reordering leads to the factorization

U(t) = exp(f1L1) exp(f0L0) exp(f2L2),

(3.31)

and the general solution is then

The three particular solutions x1, x2, x3 will be written as

the inverse relations being

x(t) =

eh1x0
1 − h2x0

+ h0.

eh1
h2

x1(t) = −

+ h0

x2(t) = h0

x3(t) =

eh1
1 − h2

+ h0,

h0 = x2

h1 = log

h2 =

"
x2 − x3
x1 − x3

.

(x3 − x2)(x2 − x1)
(x3 − x1)

#

˙f0 = a0 + a1f0 − 2a0f0f2
˙f1 = a1 − 2a0f2
˙f2 = a2 − a1f2 + a0f 2
2 ,

x(t) =

ef1x0 + f0
1 − f2(ef1x0 + f0)

.

1
f2
f0
1 − f2f0

x1(t) = −

x2(t) =

x3(t) =

ef1 + f0
1 − f2(ef1 + f0)

,

f0 =

x1x2
x1 − x2

f1 = log

x2
1(x3 − x2)
(x1 − x2)(x1 − x3) #

"

8

associated system

and general solution

The three particular solutions are now

and the inverse relation

(3.28)

(3.29)

(3.30)

(3.32)

(3.33)

(3.34)

f2 = −

1
x1

.

We remark that now the third diﬀerential equation for f2 in (3.32) is the same as in
the case II) and it provides a new method of ﬁnding the general solution of (1.1) once the
particular solution satisfying f2(0) = 0 of the associated Riccati equation is found.

U(t) = exp(v0L0) exp(v2L2) exp(v1L1),

(3.36)

V) The ﬁfth possibility is

with associated system

and solution

with the inverse relation

the expressions for the three particular solutions x1, x2, x3 are

˙v0 = a0e−v1
˙v1 = a1 − 2a0v2e−v1
˙v2 = a2ev1 − a0v2

2e−v1,

x(t) =

ev1(x0 + v0)
1 − v2(x0 + v0)

;

ev1
v2
ev1v0
1 − v2v0

x1(t) = −

x2(t) =

x3(t) =

ev1(1 + v0)
1 − v2(1 + v0)

,

v0 =

v1 = log

v2 = −

(x3 − x1)x2
(x2 − x3)x1
x2
1(x2 − x3)
(x2 − x1)(x1 − x3) #
(x2 − x3)x1
(x2 − x1)(x3 − x1)

"

.

˙w0 = a0e−w1 − a2w2
˙w1 = a1 + 2a2w0ew1
˙w2 = a2ew1,

0ew1

x(t) =

ew1x0
1 − w2x0

+ w0ew1,

9

VI) The last possibility is the factorization

and then the associated system is

U(t) = exp(w2L2) exp(w0L0) exp(w1L1),

(3.41)

the general solution

(3.35)

(3.37)

(3.38)

(3.39)

(3.40)

(3.42)

(3.43)

(3.44)

(3.45)

(3.46)

(3.47)

(3.48)

(3.49)

and the expressions for x1, x2, x3,

with inverse relation

ew1
x1(t) = −
w2
x2(t) = w0ew1
ew1
x3(t) =
1 − w2

+ w0ew1

+ w0ew1,

w0 =

(x3 − x1)x2
(x2 − x1)(x3 − x2)

w1 = log

(x2 − x1)(x3 − x2)
(x3 − x1)

#

w2 =

"
(x3 − x2)
(x3 − x1)

.

Finally, we remark that in these two last approaches there is no uncoupled diﬀerential
equation of the Riccati type whose solution allows us to ﬁnd the solution of the two other
remaining equations in the system, and therefore the general solution of the original Riccati
equation, anymore. However, if in the third equation in (3.37) we deﬁne φ(t) = ˙v1 we will
get the Riccati equation

In a similar way, in the sixth case, taking derivatives in the second equation in (3.42)

and after some manipulations, the equation for ϕ = ˙w1 becomes a Riccati equation

with

where

˙φ =

φ2 + q(t)φ + p(t)

1
2

q(t) =

p(t) = ˙a1 − 2a0a2 −

˙a2 +

a1
a0

a2
1
2

.

˙ϕ = s(t) + r(t)ϕ +

1
2

ϕ2

r(t) =

s(t) = ˙a1 −

˙a2 + 2a0a2 −

a1
a2

1
2

a2
1.

˙a2
a0

,

˙a2
a2

,

Let us summarize the results we have got. We have reduced the problem of ﬁnding the
general solution of the Riccati equation to the one of determining a curve in SL(2, R) which
is deﬁned through its second class canonical coordinates, and this leads to a diﬀerential
equation system. Once the curve in SL(2, R) is known we are able to ﬁnd the general
solution of the Riccati equation. However, even if we are not able to ﬁnd the solution of the
corresponding diﬀerential equation system for the second class coordinates in the group, we
know the form (3.12) of the general solution of the original Riccati equation. Even more,
given a set of (three in the Riccati case) fundamental particular solutions we can determine
the function giving us the superposition principle (3.18).

We have seen that the general solution of Riccati equation is given by

x(t) =

x0x1(x3 − x2) + x2(x1 − x3)
x0(x3 − x2) + (x1 − x3)

,

(3.50)

10

where x0 is a constant depending on the initial conditions. We aim now to show how it
is possible to reconstruct the original diﬀerential equation once the superposition formula is
given. In the case of Riccati equation the superposition formula (3.50) is equivalent to

x0 =

a − c x
d x − b

and it is easy to check that taking derivatives in the preceding relation we ﬁnd

( ˙a − ˙cx − c ˙x)(d x − b) − (a − c x)( ˙d x + d ˙x − ˙b) = 0

from where we ﬁnd the following expression for ˙x

˙x =

( ˙cd − c ˙d)
(bc − ad)

x2 +

(− ˙ad + a ˙d + ˙bc − b ˙c)
(bc − ad)

x +

( ˙ab − a˙b)
(bc − ad)

,

that is a Riccati equation.

On the other side, if we assume that there is a superposition formula for Riccati equation
and we try to determine the function φ giving that formula, x = φ(x1, x2, x3, k), we will have

˙x = ˙φ =

˙x1 +

˙x2 +

˙x3 = a0 + a1φ + a2φ2

∂φ
∂x1

∂φ
∂x2

∂φ
∂x3

from where the following system of partial diﬀerential equations is found

∂φ
∂x1

+

∂φ
∂x2

+

∂φ
∂x3

= 1

x1

x2
1

∂φ
∂x1
∂φ
∂x1

+ x2

+ x2
2

∂φ
∂x2
∂φ
∂x2

+ x3

+ x2
3

∂φ
∂x3
∂φ
∂x3

= φ

= φ2.

x(t) =

kx1(x3 − x2) + x2(x1 − x3)
k(x3 − x2) + (x1 − x3)

.

Now a long computation leads to the following expression for φ:

(3.51)

(3.52)

4 The superposition principle for ﬁrst order diﬀeren-
tial equation systems and Lie-Scheﬀers theorem

We are now interested in studying the existence of a superposition principle for ﬁrst order
diﬀerential equation systems generalizing the one obtained for the Riccati equation. More
explicitly, given a system

dxi
dt

= X i(x, t),

i = 1, . . . , n,

(4.1)

we ask whether there exists a set {x(1), . . . , x(m)} of fundamental solutions and a function
Φ : Rn(m+1) → Rn such that the general solution of (4.1) can be expressed as

x = Φ(x(1), . . . , x(m); a1, . . . , an),

11

where a1, . . . , an are constants related with the initial conditions.

Before studying the general case, we remark that we know that, at least in the case where

the system is the autonomous linear system

dx
dt

= Ax, x ∈ Rn,

dφt
dt

= φt ◦ A

with A being a constant matrix, it deﬁnes a ﬂow φt which can be considered as a curve on
the general linear group GL(R, n) given by φt(x) = eAtx. The ﬂow satisﬁes

and it can be determined from a fundamental set of solutions, i.e., when the n × n matrix
X whose columns are the vectors deﬁning the solutions {x1(t), . . . , xn(t)},

is an invertible matrix, then the equation

X(t) = (x1(t), . . . , xn(t)),

X(t) = etAX(0)

shows that the evolution operator etA is determined as etA = X(t)X(0)−1, i.e., the funda-
mental system of solutions allows us to ﬁnd the ﬂow of our ﬁrst order diﬀerential equation
system. In other words, we have a possitive answer to our previous question with m = n
and Φ being the linear map Φ(x(1), . . . , x(n); a1, . . . , an) = a1 x(1) + · · · + an x(n).

From here it is clear that with any linear diﬀerential equation system on Rn we can

associate an equation on GL(n, R) by setting

or

The matrix A is an element of gl(n, R).

Moreover, this way of ﬁnding the resolvent can also be used for time–dependent systems

In this case if we have a fundamental set of solutions, denoted by X(t) = (x1(t), . . . , xn(t)),
from

X(t) = R(t, 0)X(0)

we get R(t, 0) = X(t)X(0)−1.

We could equally well associate a time–dependent equation on GL(n, R) by setting

˙g = gA,

g−1 dg
dt

= A.

dx
dt

= A(t)x.

g−1 dg
dt

= ai(t)Ai,

12

with Ai being elements of the natural basis of gl(n, R).

The point we want to remark is that if the evolution preserves some structure, then

A(t) = φ−1

t ◦

dφt
dt

lies in certain subalgebra of gl(R, n). The ﬂow now deﬁnes a one–parameter family of trans-
formations, and conversely, given a one–parameter family of transformations it will determine
a vector ﬁeld in Rn, the corresponding fundamental vector ﬁeld.

The critical fact is that the general solution is determined by a linear operator from a
set of fundamental solutions, and this is a linear superposition principle. It is very natural
to ask what happens when the vector ﬁeld is nonlinear. The answer is that, at least in some
cases, to be explicited shortly, there is a kind of non–linear superposition principle, as it was
proved by Lie ([11]). This nonlinear superposition principle is simply a generalization of the
previous construction to those cases where the action of the group is not linear and Rn is
replaced for a manifold M.

In the general case of the system (4.1), the Theorem for existence and uniqueness of
solutions of such systems tells us that there will be, for each small enough t, a local dif-
feomorphism of Rn which establishes the correspondence among the initial values and the
corresponding ones for the explicit value of the parameter t. In other words, the evolution is
described by a curve gt in the group of diﬀeomorphisms of Rn. We have seen that when we
consider a linear autonomous system this curve lies in the group GL(n, R) and is just the
exponential of the matrix A giving the system, g(t) = exp tA. In the linear time–dependent
case, we also have a curve gt in GL(n, R) but it is not the exponential anymore: the only
thing we can say is that

takes values in the Lie algebra gl(n, R). Actually, the solution is obtained by the Dyson,
time–ordered, exponential.

The point is that for other types of vector ﬁelds the curve described by gt belongs to
other Lie subgroups of the group of diﬀeomorphisms and these are just the cases for which
the idea of the nonlinear superposition principle is generalizable.

The result established by Lie and Scheﬀers [11] is that the general evolution deﬁned by
(4.1) can be expressed in terms of m fundamental solutions if there are r vector ﬁeds Y1, . . . ,
Yr, such that the vector ﬁeld X,

can be expressed as a linear combination

and furthermore the vector ﬁelds

X = a1(t)Y1 + · · · + ar(t)Yr

(4.2)

close a ﬁnite dimensional real (or complex) Lie algebra, with dimension r, i.e., there exist r3
real numbers cαβ

γ such that

Moreover, in this case mn ≥ r. When ξi
constants, the system is linear.

[Yα, Yβ] = cαβ

γ Yγ.
α(x) = ai

αjxj + bi

α, with ai

αj and bi

α arbitrary

(4.3)

A(t) = φ−1

t ◦

dφt
dt

X = X i(x, t)

∂
∂xi

Yα = ξi

α(x)

∂
∂xi

13

Let us consider an eﬀective action of a Lie group G of dimensi´on r on n-dimensional
diﬀerentiable manifold M, Φ : G × M → M, and Φg : M → M and Φx : G → M denote
the maps Φg(x) = Φx(g) = Φ(g, x), for g ∈ G, x ∈ M. Choosing an initial point x(0), every
curve g : I → G in the group determine a curve in the manifold M by

x(t) = Φ(g(t), x(0)) = Φg(t)(x(0)) = Φx(0)(g(t)),

and taking derivatives with respect to t we see that the tangent vectors to the curves g(t)
and x(t), respectively, are related by

Let us remark that ˙g(t) ∈ Tg(t)G and ˙x(t) ∈ Tx(t)M.
We can express ˙x(t) in terms of x(t): we recall that if x2 = Φg(x1), then

˙x(t) = Φx(0)∗g(t) ˙g(t).

Φx2 = Φx1 ◦ Rg,

where Rg denotes right translation in the Lie group G, because for any g′ ∈ G,

Φx2(g′) = Φ(g′, x2) = Φ(g′, Φ(g, x1)) = Φ(g′g, x1) = (Φx1 ◦ Rg)(g′).

Now, using the chain rule for computing the diﬀerentials we ﬁnd that

and then,

expression for ˙x(t):

Φx2∗ = Φx1∗ ◦ Rg∗,

Φx1∗ = Φx2∗ ◦ Rg−1∗.

˙x(t) = Φx(t)∗e(Rg−1(t)∗g(t) ˙g(t)).

We can use this relation for g = g(t) and x1 = x(0) and then we ﬁnd the following

Since Rg−1(t) is the right translation leading g(t) to the neutral element e ∈ G and
˙g(t) ∈ Tg(t)G, then Rg−1(t)∗g(t) ˙g(t) ∈ TeG and we know that TeG may be identiﬁed with the Lie
algebra of G, g. Moreover, for linear Lie groups, i.e., subgroups of GL(n, R), right translation
reduces to right multiplication by the corresponding matrix, and hence Rg−1(t)∗g(t) ˙g(t) is just
the product ˙g(t) g−1(t).

Let {eα}r

α=1 be a basis of the corresponding Lie algebra g with deﬁning relations

[eα, eβ] = cαβ

γeγ,

and denote Xα the corresponding fundamental vector ﬁelds deﬁned by

(Xαf )(m) =

[f (exp(−teα)m)]|t=0 ,

d
dt

for any diﬀerentiable function f . We recall that in this case

Now, if the time–dependent vector ﬁeld deﬁning the system (4.1) is of the form

[Xα, Xβ] = cαβ

γ Xγ.

X(t) = aα(t)Xα

14

we associate with it the following diﬀerential equation on the Lie group itself

g−1(t)

= aα(t)eα.

dg
dt

In this way the given system is replaced by a higher dimensional system of ﬁrst order
linear equations. Or in other words, we have replaced the original system of diﬀerential
equations with a new system on the group G, but the important point is that it is enough
to ﬁnd a particular solution, the one starting from the neutral element, for obtaining the
general solution of the system(4.1): the solution starting from x0 is given by Φ(g(t), x0).

Moreover, even if we do not know the solution g(t) of the new system, it is possible to
ﬁnd it from the knowledge of a convenient set of particular solutions of (4.1) such that (4.2)
with the additional condition (4.3). More explicitly, given a curve x1(t) that is a particular
solution of the given system, there are, in principle, diﬀerent possible choices for the curve
g(t) such that x1(t) = Φ(g(t), x1(0)), because the stability group of the point x1(0) may be
nontrivial. If we choose a diﬀerent particular solution, x2(t), then the ambiguity reduces to
the group intersection of the isotopy groups of x1(0) and x2(0). We can, if necessary iterate
the procedure until we arrive to a set of m particular solutions x1, . . . , xm allowing us the
determination of the curve g(t). Of course as we have r unknown functions, the second class
canonical coordinates, and we have mn conditions, it should be mn ≥ r.

More explicitly, a set of x1, . . . , xm of solutions is said to be a fundamental system of

solutions, if

x1(t) = Φ(g(t), x1(0))

. . . = . . . . . .

xm(t) = Φ(g(t), xm(0))

(4.4)

is a minimal set allowing us to solve for g(t) via the implicit function Theorem. If this can
be done we get

g(t) = F (x1(t), . . . , xm(t); x1(0), . . . , xm(0)),

and then any other solution can be written as

x(t) − Φ(F (x1(t), . . . , xm(t); x1(0), . . . , xm(0)), x(0)) = 0.

Therefore the left hand side of this relation deﬁnes a constant of the motion.
Starting with the action Φ : G × M → M we should ﬁnd the minimal integer number
m such that the isotopy group of the action of G on the product M m = M × · · · × M
(m times), extended from Φ by Φm(g, x1, . . . , xm) = (Φ(g, x1), . . . , Φ(g, xm)), reduces to the
neutral element for a point such that any two coordinates are diﬀerent.

We recall that the fundamental vector ﬁeld corresponding to an element of g generating
a one-parameter Lie subgroup contained in the isotopy group of a point, vanishes in such a
point, and conversely. Therefore, when expressed in terms of fundamental vector ﬁelds that
means that the extensions to M m of the fundamental vector ﬁelds Xα do not vanish in a a
point whose coordinates are diﬀerent. The general solution then is found by adding a new
component and looking for constants of motion.

15

The procedure is next illustrated with an example for the simplest case n = 1. According
to Lie’s Theorem we should look for a ﬁnite dimensional real Lie algebra of diﬀerential
operators

Xα = fα(x)

∂
∂x

.

It can be shown that the only ﬁnite dimensional Lie algebra that can be found from
vector ﬁelds in one real variable are sl(2, R) and its subalgebras. The uniquely deﬁned (up
to a change of variables) realization of sl(2, R) is given by

X0 = x

, X− =

∂
∂x

∂
∂x

, X+ = x2 ∂
∂x

.

These vector ﬁelds close the sl(2, R) Lie algebra

[X0, X−] = −X−, [X0, X+] = X+, [X−, X+] = 2X0.

Therefore, it suﬃces to consider the case in which the time–dependent vector ﬁeld X
deﬁning the equation can be written as a linear combination X = a1X0 + a2X+ + a0X− with
a0 = a0(t), a1 = a1(t) and a2 = a2(t) real functions. For simplicity we will consider the case
when a1, a2 and a3 are real numbers and then we obtain the diﬀerential equation

dx
dt

= X(x, t) = a0 + a1x + a2x2,

which is nothing but the well known Riccati equation.

First we note that the determinant

is generically diﬀerent from zero, while the system a + bx1 + cx2
always has a solution. Consequently, m = 3 in this case.

1 = 0, a + bx2 + cx2

2 = 0

Now, for obtaining the general solution we should deﬁne the vector ﬁelds

1 x1 x2
1
1 x2 x2
2
1 x3 x2
3

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (x1 − x2)(x2 − x3)(x3 − x1)

+ x1

+ x2

+ x3

V0 = x

∂
∂x
∂
V− =
+
∂x
V+ = x2 ∂
∂x

∂
∂x1
+ x2
1

∂
∂x1

+

∂
∂x2

+

,

∂
∂x2
∂
∂x3
∂
∂x2

∂
∂x1

+ x2
2

+ x2
3

∂
∂x3

∂
∂x3

,

(4.5)

and look for a solution of the system

V0f = V+f = V−f = 0.

This system of partial diﬀerential equations is integrable, because the vector ﬁelds V0,

V+ and V− close a Lie algebra, and therefore they deﬁne an integrable distribution.

The last equation V−f = 0 tell us that the function f depends only on the diﬀerences

u1 = x − x1, u2 = x1 − x2 and u3 = x2 − x3, because the characteristic system is

dx
1

=

dx1
1

=

dx2
1

=

dx3
1

,

16

and it has as ﬁrst integrals the diﬀerences u1 = x − x1, u2 = x1 − x2 and u3 = x2 − x3. Now,
if f (x, x1, x2, x3) = ϕ(u1, u2, u3), the condition V0f = 0 is written

u1

∂ϕ
∂u1

+ u2

+ u3

= 0,

∂ϕ
∂u2

∂ϕ
∂u3

i.e., the function ϕ should be homogeneous of degree zero, and therefore it only can depend
on the quotients v1 = u1/u2 and v2 = u3/u2, ϕ(u1, u2, u3) = φ(v1, v2). Finally, the condition
V+f = 0 can be written in these coordinates, after a long computation, as

v1(v1 + 1)

− v2(v2 + 1)

= 0.

∂φ
∂v1

∂φ
∂v2

The corresponding characteristic system is

and taking into account that

we obtain that the constant of motion f should be a function of

dv1
v1(v1 + 1)

= −

dv2
v2(v2 + 1)

dξ
ξ(ξ + 1)

= log

ξ
ξ + 1

,

Z

ζ =

v1
v1 + 1

v2
v2 + 1

,

(x − x1)(x2 − x3)
(x − x2)(x1 − x3)

= c

and therefore

provides the non–linear evolution principle giving x(t) as a function of three independent
solutions

x =

(x1 − x3)x2c + x1(x3 − x2)
(x1 − x3)c + (x3 − x2)

.

Let us remark that for n = 1 there is only one nonlinear diﬀerential equation family
satisfying Lie–Scheﬀers theorem: the Riccati equation. Of course, proper subalgebras of
sl(2, R) lead to the linear inhomogeneous equation when a2 = 0 or to a linear homogeneous
equation when a0 = a2 = 0. However, for n = 2 in addition to SL(3, R), O(3, 1) and O(2, 2),
we can realize families of Lie algebras with arbitrary large Abelian ideals.

5 Application in the solution of second order diﬀeren-

tial equations

Algebraic methods have very often been used in the search for eigenvalues of operators and
the corresponding eigenvector. The particular case of the harmonic oscillator is the prototype
and it is based on creation and annihilation operators, and therefore it is related with the
Heisenberg group. The possiblity of relating linear second order diﬀerential equations with a
Riccati equation, as indicated above, and the related group SL(2, R) has not been exploited
till now, as far as we know.

17

In this section we will explore the use of Wei–Norman method based on the SL(2, R)
group for studying the spectral problem of the second order diﬀerential operator determined
for the Hamiltonian of the Harmonic oscillator

where k is a constant.

We will use the following notation:

and then the Hamiltonian can be written

The eigenvectors ψ(ξ) of the preceding Hamiltonian operator corresponding to the eigen-

values λ ¯hω

2 are the normalizable solutions of the diﬀerencial equation

We proved in Section 2 that if ψ is a solution of (5.7), then the function z = 1
ψ

dψ
dξ will be

a solution of the following Riccati equation

As it was stated in Section 3, such equation admits a nonlinear superposition principle
based on the SL(2, R) group, and therefore the general solution can be found by means of
an appropriate factorization

z(ξ) = exp(g2L2) exp(g1L1) exp(g0L0)(z)|ξ=0.

(5.9)

The functions g0, g1, g2, are to be determined from the ﬁrst order diﬀerential equation

system

together with the initial conditions g0(0) = g1(0) = g2(0) = 0.

Let us ﬁrst remak that the Riccati equation

H =

P 2
2M

+

X 2,

k
2

ω =

k/M,

q

Mω/¯h,

α =
ξ = αx,
λ = 2E/¯hω,

q

H =

¯hω
2 "

−

d2
dξ2 + ξ2

.

#

−

d2ψ
dξ2 + ξ2ψ = λψ.

dz
dξ

= −z2 +

ξ2 − λ
(cid:16)

(cid:17)

.

˙g0 = ξ2 − λ − g2
0
˙g1 = −2g0
˙g2 = −eg1,

dz
dξ

+ z2 − ξ2 + λ = 0,

18

(5.1)

(5.2)

(5.3)
(5.4)
(5.5)

(5.6)

(5.7)

(5.8)

(5.10)

under the change of variables given by

z = 2ξv − ξ,

y = ξ2,

becomes a new Riccati equation,

dv
dy

+ v2 + v

1
2y

 

− 1

−

!

1 − λ
4y

= 0,

On the other side, the Riccati equation associated, according to the method described in

Section 2, with the linear second order conﬂuent hypergeometric diﬀerential equation

where a and b are constants and W ′ and W ′′ are the ﬁrst and second derivative, respectively,
of the function W (y), is

with

A simple comparison between (5.12) and (5.14) shows that both coincide when

yW ′′ + (b − y) W ′ − aW = 0,

dv
dy

+ v2 + v

− 1

−

= 0.

b
y

 

a
y

!

v =

W ′
W

.

a =

1 − λ
4

b =

1
2

.

It is well known that the general solution of (5.13) is given by

W (y) = AM

1 − λ
4

,

1
2

 

!

, y

+ By

2 M

1

3 − λ
4

,

3
2

 

, y

!

with A and B arbitrary constants, and M(a, b, y) is such that for large values of the variable
y,

M(a, b, y) =

eiǫπay−ag(a, a − b + 1, −y)

Γ(b)
Γ(b − a)
Γ(b)
Γ(a)

+

eyya−bg(1 − a, b − a, y),

where ǫ = 1 if −π/2 < Arg y < 3π/2 and ǫ = −1 when −3π/2 < Arg y ≤ −π/2 and g
denotes the function

g(a, b, y) =

a(a + 1) · · · (a + n − 1)b(b + 1) · · · (b + n − 1)
n! yn

∞

Xn=0

Therefore, the function W (y) behaves for large values of y as ey = eξ2

unless that

(5.11)

(5.12)

(5.13)

(5.14)

(5.15)

(5.16)

(5.17)

(5.18)

(5.19)

(5.20)

Γ

Γ

1
4
3
4

 

 

−

−

λ
4 !
λ
4 !

= ∞ and B = 0

= ∞ and A = 0,

19

Now, we recall that Gamma function is such that Γ(0) = −∞ and takes ﬁnite values
when −z is not a positive integer number, while Γ(−m) = ∞ for 0 < m ∈ Z. Therefore
if we want to have a solution of (5.13) with values a and b satisfying (5.15) being square
integrable, it is necessary that

= −m, and then λ = 2n + 1 with n = 2m = 2, 4, 6, · · ·

(5.21)

= −m, and then λ = 2n + 1 with n = 2m + 1 = 3, 5, 7, · · · ,

(5.22)

1
4
3
4

−

−

λ
4
λ
4

or,

1
4
3
4

−

−

λ
4
λ
4

= 0 and then λ = 2n + 1 with n = 0

= 0 and then λ = 2n + 1 with n = 1.

Consequently, a necessary condition for (5.13) with values a and b satisfying (5.15) to be

square integrable is

where n = 0, 1, 2, 3, . . . .

λ = 2n + 1,

Therefore, we will restrict ourselves to the case λ = 2n+1. We will show that the solution

for g0 can be obtained by induction on the index n.

We ﬁrst consider the case in which n is an even number. The ﬁrst equation reduces for

n = 0 to

and then it is an easy matter to check that the solution we are looking for is g0 = −ξ.

In the case n = 2 the equation becomes

and again it is easy to check that then the solution is

In a similar way, when studying the cases n = 4, 6, . . . we will see that for an even number

n the solution satisfying g0(0) = 0 is given by

with Hn being the Hermite polynomial of order n and H ′
respect to ξ. In fact, using several properties of Hermite polynomials, we see that

n means the derivative of Hn with

−

H ′′
n
Hn
nHn − (H ′

n)2
(H ′
H 2
n
n)2 − H 2

H ′′

− 1 = ξ2 − λ −

n =

ξ2 − λ

(cid:17)

(cid:16)

20

2

,

− ξ

H ′
n
Hn
!
n − Hnξ)2 ,
n − (H ′

 
H 2

˙g0 = ξ2 − 1 − g2
0,

˙g0 = ξ2 − 5 − g2
0,

g0 =

8ξ
4ξ2 − 2

− ξ.

g0 =

H ′
n(ξ)
Hn(ξ)

− ξ,

(5.23)

(5.24)

(5.25)

(5.26)

(5.27)

(5.28)

(5.29)

(5.30)

and taking into account that H ′
H ′′

n = 4n(n − 1)Hn−2, we will get

n = 2nHn−1 and the corresponding relation for the derivatives

4n(n − 1)Hn−2Hn − H 2

n = −λH 2

n + 2ξHnH ′
n,

4n(n − 1)Hn−2 − Hn = −λHn + 2ξH ′
n.

(5.31)
(5.32)

Now, the recurrence relation Hn = 2ξHn−1 − 2(n − 1)Hn−2, leads to

2(n − 1)Hn−2 (2n + 1 − λ) = 2ξHn−1 (2n + 1 − λ) ,

(5.33)

and the right hand side vanishes because of λ = 2n + 1.

In summary, we have checked that for any even number n the solution such that g0(0) = 0

is given by

new equation

g0 =

− ξ.

H ′
n
Hn

˙g1 = −2g0 = −2

H ′
n
Hn

 

− ξ

,

!

When introducing this value for g0 in the second equation (5.11) for g1 we obtain the

which can be easily integrated

g1 = −2

− ξ

dξ = −2 log Hn + ξ2 + C1 = − log

H ′
n
Hn

Z  

!

H 2

n + eξ2

+ C1,

(cid:16)

(cid:17)

and as g1(0) = 0, C1 takes the value C1 = log (H 2
n(0)) = log k1. From the relation Hn =
2ξHn−1 − 2(n − 1)Hn−2 we see that Hn(0) = −2(n − 1)Hn−2(0) and iterating this reasoning
we obtain the chain of relations

and therefore,

and then,

Hn−2(0) = −2(n − 3)Hn−4(0)
Hn−4(0) = −2(n − 5)Hn−6(0)

· · · = · · · · · ·

H2(0) = −2(n − n + 1)H0(0) = −2 · 1

Hn(0) = (−2(n − 1)) (−2(n − 3)) (−2(n − 5)) · · · (−2.1)

= (−2)n/2 (n − 3) (n − 5) · · · 1,

k1 = H 2

n(0) =

2n/2(n − 1)(n − 3)(n − 5) · · · 1
2n/2 n(n − 1)(n − 2)(n − 3) · · · 1

i

n(n − 2)(n − 4) · · · 2

h

"

2

=



n!
n
2 − 2

· · · 1 


(cid:17)



(cid:16)

(cid:17)

2

.

,

!





n
2 − 1

n
2





(cid:16)

2

2

#

n!
n
2

=

=

(cid:17) (cid:16)

21

(5.34)

(5.35)

(5.36)

(5.37)
(5.38)
(5.39)
(5.40)

(5.41)

(5.42)

So, the function g1 is given by the expression

Finally, the function g2 is to be determined from the diﬀerential equation

whose solution is

where k2 is to be chosen such that g2(0) = 0, i.e.,

g1 = − log

ne−ξ2

.

k1H 2
h

i

˙g2 = −

1
ne−ξ2 ,
k1H 2

g2 = −

Z

1
ne−ξ2 dξ + k2
k1H 2

k2 =

"Z

1
ne−ξ2
k1H 2

.

#(ξ=0)

Putting together all previous results we get for the general solution z(ξ) the following

expression:

z(ξ) =

[eg1z](ξ=0)
1 − [g2z](ξ=0)
1
k1H 2

+ g0

ne−ξ2 z

=

= 

1 +

(cid:20)(cid:20)

R

1 +





(cid:20)
R

(cid:20)

(cid:21)(ξ=0)
ne−ξ2 dξ − k2

1
k1H 2

z

1
k1H 2

ne−ξ2 z
ne−ξ2 dξ − k2

1
k1H 2

(cid:21)

(cid:21)(ξ=0)







z

(cid:21)

(ξ=0)

+

− ξ

H ′
n
Hn

+

− ξ.

H ′
n
Hn

We recall that the wave function ψ was given by

and from

we obtain

z(ξ)dξ,

ψ = e
R

z(ξ)dξ = log Hn −

Z

ψ = elog Hn− ξ

2 = Hne− ξ

2 .

2

ξ2
2

,

2

Notice that when ψ has a well deﬁned parity, the quotient z = 1
ψ

dψ
dξ is an odd function
and then the limit when ξ → 0 of z should be zero. However, when ψ is a continuous odd
dψ
function, then limξ→0 ψ = 0 and then the quotient 1
dξ cannot be ﬁnite. This was the reason
ψ
for leaving aside the case λ = 2n + 1 for an odd number n. In this last case it is convenient
ﬁrst to introduce the change of variable z = 1/v, and then the equation (5.8) becomes

dv
dξ

= 1 −

ξ2 − λ

v2,

(cid:17)

(cid:16)

22

(5.43)

(5.44)

(5.45)

(5.46)

(5.47)

(5.48)

(5.49)

(5.50)

(5.51)

(5.52)

(5.53)

(5.54)

(5.55)

(5.56)

(5.57)

(5.58)

and the corresponding system of diﬀerential equations
˙g0 = 1 − (ξ2 − λ) g2
0
˙g1 = −2 (ξ2 − λ) g0
˙g2 = − (ξ2 − λ) eg1.

with initial conditions g0(0) = g1(0) = g2(0) = 0.

It is now easy to check that the solution for g0 is

that g1 is given by

and that g2 is

where

g0 =

Hn
n − ξHn

,

H ′

g1 = ξ2 + log

k1

2

"

H ′

n − ξHn #

g2 = −

(ξ2 − λ) k1
n − ξHn)2 e−ξ2 dξ + k2,

(H ′

Z

2n!
n−1
2

,

!
(cid:17)

k1 =

k2 =

(cid:16)

"Z

(ξ2 − λ) k1
n − ξHn)2 e−ξ2 dξ

(H ′

#(ξ=0)

v(ξ) =

(eg1v)(ξ=0)
1 − (g2v)(ξ=0)

+ g0,

Then, under the change z = 1/v the general solution

becomes after some computations the expresion given by (5.47).

6 Conclusions

The analysis developed in this paper of the reduction process leading to the Riccati equation
starting from a second order linear diﬀerential equation just by a simple application of the
general Lie theory of symmetry of diﬀerential equations, now a well established subject
(see e.eg.
[12]), allows us a better understanding of the so called factorization method,
which is a method that have been used for ﬁnding new solvable potentials once one of such
problem is known and that motivated the study of supersymmetric quantum mechanics.
The Riccati equation was chosen here as the simplest example of ﬁrst order diﬀerential
equation systems admitting a nonlinear superposition principle and the deep reasons for the
existence of such principle have been clariﬁed in this paper. We hope that this will allow
a geometric interpretation of the converse part of Lie-Scheﬀers theorem. This nonlinear
superposition principle is very important and has played a very important role because
it provides an explicit expression for the solution of nonlinear equations admitting such
superposition principle. For a review see e.g. the review lecture given by Winternitz [13].
We have also developed many examples of the use of Wei–Norman method of computation of
the solution of diﬀerential equations in a Lie group and we have applied it as an academical
example for reobtaining the eigenvalues and eigenvectors of the harmonic oscillator problem.

23

References

[1] Davis H.T., Introduction to Nonlinear Diﬀerential and Integral Equations, Dover,

New York (1962).

[2] Stahlhofen A., The Riccati equation as comon basis for Supersymmetric Quantum

Mechanics and the Factorization method, Preprint Duke University (1988).

[3] Stahlhofen A. and Bleuler K., An algebraic form of the Factorization method, Nuovo

Cim. 104 B, 447–65 (1989).

[4] Socorro J. and Rosu H.C., Supersymmetric double Darboux method in quantum
cosmology, 2nd Mexican School of Gravitation and Mathematical Physics, Tlaxcala
(1996).

[5] Rosu H.C. and Socorro J., One parameter family of closed, radiation–ﬁlled
Friedmann–Robertson–Walker quantum universes, Phys. Lett. A 223, 28–30 (1996).

[6] Witten E., Dynamical breaking of Supersymmetry, Nucl. Phys. B 188, 513–55

(1981).

[7] Lahiri A., Roy P.K. and Bagchi B., Supersymmetry in Quantum Mechanics, Int. J.

Mod. Phys. A 5, 1383–456 (1990).

[8] Wei J. and Norman E., Lie algebraic solution of linear diﬀerential equations, J.

Math. Phys. 4, 575–81 (1963).

Review 29, 91–113 (1987).

[9] Smith D.R., Decoupling and order reduction via the Riccati tranformation, SIAM

[10] Dattoli G., Gallardo J.C. and Torre A., An algebraic view to Operatorial Ordering

and Its Applications to Optics, Riv. Nuovo Cim. 11, 1–79 (1988).

[11] Lie S., Theorie der transformationgruppen, Teubner, Leipzig (1893).

[12] Olver P.J. Applications of Lie Groups to Diﬀerential Equations, Graduate Texts in

Mathematics 107, Springer-Verlag, N. Y. (1986).

[13] Winternitz P., Lie groups and solutions of nonlinear diﬀerential equations, in Non-
linear Phenomena, K.B. Wolf Ed., Lecture Notes in Physics 189, Springer-Verlag
N.Y (1983).

24

