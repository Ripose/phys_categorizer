Statistical mechanics of neocortical interactions:

Canonical momenta indicators of electroencephalography

Lester Ingber

Lester Ingber Research, P.O. Box 857, McLean, VA 22101

ingber@ingber.com, ingber@alumni.caltech.edu

0
0
0
2

 

n
a
J
 

3
2

 
 
 

2
5
0
1
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A series  of  papers  has  developed  a  statistical  mechanics  of  neocortical  interactions  (SMNI),  deriving

aggregate  behavior  of  experimentally  observed  columns  of  neurons  from  statistical  electrical-chemical

properties of synaptic interactions. While not useful to yield insights at the single neuron level, SMNI has

demonstrated 

its  capability 

in  describing 

large-scale  properties  of  short-term  memory  and

electroencephalographic  (EEG)  systematics. The  necessity  of  including  nonlinear  and  stochastic

structures  in  this  development  has  been  stressed. Sets  of  EEG  and  evoked potential  data  were  ﬁt,

collected to investigate genetic predispositions to alcoholism and to extract brain “signatures” of short-

term  memory. Adaptive  Simulated  Annealing  (ASA),  a  global  optimization  algorithm,  was  used  to

perform  maximum  likelihood  ﬁts  of  Lagrangians  deﬁned  by  path  integrals  of  multivariate  conditional

probabilities.  Canonical momenta indicators (CMI) are thereby derived for individual’s EEG data. The

CMI  give  better  signal  recognition  than  the  raw data,  and  can  be  used  to  advantage  as  correlates  of

behavioral  states. These  results  give  strong  quantitative  support  for  an  accurate  intuitive  picture,

portraying neocortical interactions as having common algebraic or physics mechanisms that scale across

quite disparate spatial scales and functional or behavioral phenomena, i.e., describing interactions among

neurons, columns of neurons, and regional masses of neurons.

PA CS Nos.: 87.10.+e, 05.40.+j, 02.50.-r, 02.70.-c

Statistical Mechanics of Neocortical ...

-2- 

Lester Ingber

1.  INTRODUCTION

A model  of  statistical  mechanics  of  neocortical  interactions  (SMNI)  has  been  developed [1-20],

describing  large-scale  neocortical  activity  on  scales  of  mm  to  cm  as  measured  by  scalp  EEG,  with  an

audit trail back to minicolumnar interactions among neurons. There are several aspects of this modeling

that  should  be  further  investigated:  to  explore  the  robustness  of  the  model,  the  range  of  experimental

paradigms  to  which  it  is  applicable,  and  further  development  that  can  increase  its  spatial  resolution  of

EEG.

The  underlying  mathematical  physics  used  to  develop  SMNI  gives rise  to  a  natural  coordinate  system

faithful  to  nonlinear  multivariate  sets  of  potential  data  such  as  measured  by  multi-electrode  EEG,

canonical momenta indicators (CMI) [20-22].  Recent papers in ﬁnance [21,22] and in EEG systems [20]

have demonstrated that CMI give enhanced signal resolutions over raw data.

The  basic  philosophy of SMNI  is  that  good  physical  models  of  complex systems,  often  detailed  by

variables not directly measurable in many experimental paradigms, should offer superior descriptions of

empirical  data  beyond  that  available  from  black-box  statistical  descriptions  of  such  data. For example,

good nonlinear models often offer sound approaches to relatively deeper understandings of these systems

in terms of synergies of subsystems at ﬁner spatial-temporal scales.

In  this  context,  a  generic  mesoscopic  neural  network  (MNN)  has  been  developed  for  diffusion-type

systems using a conﬂuence of techniques drawn from the SMNI, modern methods of functional stochastic

calculus  deﬁning  nonlinear  Lagrangians,  adaptive  simulated  annealing  (ASA) [23],  and  parallel-

processing  computation,  to  develop  a  generic  nonlinear  stochastic  mesoscopic  neural  network

(MNN) [14,19]. MNN  increases  the  resolution  of  SMNI  to  minicolumnar  interactions  within  and

between  neocortical  regions,  a  scale  that  overlaps  with  other  studies  of  neural  systems,  e.g.,  artiﬁcial

neural networks (ANN).

In  order  to  interface  the  algebra  presented  by  SMNI  with  experimental  data,  several  codes  have  been

developed.  A key tool  is  adaptive  simulated  annealing  (ASA),  a  global  optimization  C-language

code [23-27]. Over  the  years,  this  code  has  evolved  to  a  high  degree  of  robustness  across  many

disciplines.  However, there are over 100 OPTIONS available for tuning this code; this is as expected for

any single  global  optimization  code  applicable  to  many classes  of  nonlinear  systems,  systems  which

Statistical Mechanics of Neocortical ...

-3- 

Lester Ingber

typically are non-typical.

Section 2 gives the background used to develop SMNI and ASA for the present study. Appendix A gives

more detail on ASA relevant to this paper. Section 3 gives the mathematical development required for

this study. Section 4 describes the procedures used. Section 5 presents conclusions.

2.  BACKGROUND

2.1.  EEG

The SMNI approach develops mesoscopic scales of neuronal interactions at columnar levels of hundreds

of neurons from the statistical mechanics of relatively microscopic interactions at neuronal and synaptic

scales,  poised  to  study  relatively  macroscopic  dynamics  at  regional  scales  as  measured  by  scalp

electroencephalography (EEG).  Relevant experimental conﬁrmation is discussed in the SMNI papers at

the mesoscopic scales as well as at macroscopic scales of scalp EEG. The derived ﬁrings of columnar

activity, considered  as  order  parameters  of  the  mesoscopic  system,  develop  multiple  attractors,  which

illuminate  attractors  that  may  be  present  in  the  macroscopic  regional  dynamics  of  neocortex.  SMNI

proposes  that  models  to  be  ﬁtted  to  data  include  models  of  activity  under  each  electrode,  e.g.,  due  to

short-ranged  neuronal  ﬁbers,  as  well  as  models  of  activity  across  electrodes,  e.g.,  due  to  long-ranged

ﬁbers.  These inﬂuences can be disentangled by SMNI ﬁts.

The SMNI approach is complementary to other methods of studying nonlinear neocortical dynamics at

macroscopic scales. For example, EEG and magnetoencephalography (MEG) data have been expanded in

a series  of  spatial  principal  components,  a  Karhunen-Loeve  expansion.  The coefﬁcients  in  such

expansions are identiﬁed as order parameters that characterize phase changes in cognitive studies [28,29]

and  epileptic  seizures [30,31].  However,  the  SMNI  CMI  may  be  considered  in  a  similar  context,  as

providing  a  natural  coordinate  system  that  can  be  sensitive  to experimental  data,  without  assuming

av erages over stochastic parts of the system that may contain important information.

Theoretical  studies  of  the  neocortical  medium  have  inv olved  local  circuits  with  postsynaptic  potential

delays [32-35], global studies in which ﬁnite velocity of action potential and periodic boundary conditions

are important [36-39], and nonlinear nonequilibrium SMNI. The local and the global theories combine

Statistical Mechanics of Neocortical ...

-4- 

Lester Ingber

naturally to form a single theory in which control parameters effect changes between more local and more

global  dynamic  behavior [39,40], in  a  manner  somewhat  analogous  to  localized  and  extended  wav e-

function states in disordered solids.

Plausible connections between the multiple-scale statistical theory and the more phenomenological global

theory have been proposed [12].  Experimental studies of neocortical dynamics with EEG include maps of

magnitude  distribution  over the  scalp [37,41],  standard  Fourier  analyses  of  EEG  time  series [37],  and

estimates  of  correlation  dimension [42,43].  Other studies  have  emphasized  that  many EEG  states  are

accurately  described  by 

a 

few coherent 

spatial  modes 

exhibiting 

complex

temporal

behavior [28-31,37,39]. These  modes  are  the  order  parameters  at  macroscopic  scales  that  underpin  the

phase changes associated with changes of physiological state.

For extracranial EEG, it is clear that spatial resolution, i.e., the ability to distinguish between two dipole

sources as their distance decreases, is different from dipole localization, i.e., the ability to locate a single

dipole [39]. The  development  of  methods  to  improve  the  spatial  resolution  of  EEG  has  made  it  more

practical  to  study  spatial  structure. For example,  high  resolution  methods  provide  apparent  spatial

resolution  in  the  2-3  cm  range [44].  Dipole resolution  may  be  as  good  as  several  mm [45].  Some

algorithms calculate the (generally non-unique) inverse-problem of determining cortical sources that are

weighted/ﬁltered  by  volume  conductivities  of  concentric  spheres  encompassing  the  brain,  cerebrospinal

ﬂuid, skull, and scalp. A straightforward approach is to calculate the surface Laplacian from spline ﬁts to

the  scalp  potential  distribution,  yielding  estimates  similar  to  those  obtained  using  concentric  spheres

models  of  the  head [44].  Other measuring  techniques,  e.g.,  MEG,  can  provide  complementary

information.  These methods have their strengths and weaknesses at various spatial-temporal frequencies.

These source localization methods typically do not include in their models the synergistic contributions

from short-ranged columnar ﬁrings of mm spatial extent and from long-ranged ﬁbers spanning cm spatial

extent.  The CMI  study  presented  here  models  these  synergistic  short-ranged  and  long-ranged

interactions.  This is elaborated on in the conclusion.

2.2.  Short-Term Memory (STM)

The  development  of  SMNI  in  the  context  of  short-term  memory  (STM)  tasks  leads  naturally  to  the

identiﬁcation of measured electric scalp potentials as arising from excitatory and inhibitory short-ranged

Statistical Mechanics of Neocortical ...

-5- 

Lester Ingber

and excitatory long-ranged ﬁbers as they contribute to minicolumnar interactions [12,13].  Therefore, the

SMNI CMI are most appropriately calculated in the context of STM experimental paradigms. It has been

been  demonstrated  that  EEG  data  from  such  paradigms  can  be  ﬁt  using  only  physical  synaptic  and

neuronal parameters that lie within experimentally observed ranges [13,20].

The  SMNI  calculations  are  of  minicolumnar  interactions  among  hundreds  of  neurons,  within  a

macrocolumnar extent of hundreds of thousands of neurons. Such interactions take place on time scales
of  several t , where t is  on  the  order  of  10  msec  (of  the  order  of  time  constants  of  cortical  pyramidal

cells).  This also is the observed time scale of the dynamics of STM. SMNI hypothesizes that columnar

interactions within and/or between regions containing many millions of neurons are responsible for these

phenomena  at  time  scales  of  several  seconds. That  is,  the  nonlinear  evolution  at  ﬁner  temporal  scales

gives a base of support for the phenomena observed at the coarser temporal scales, e.g., by establishing

mesoscopic attractors at many macrocolumnar spatial locations to process patterns in larger regions.

SMNI has presented a model of STM, to the extent it offers stochastic bounds for this phenomena during

focused  selective  attention [4,6,15,46-48], transpiring  on  the  order  of  tenths  of  a  second  to  seconds,
limited  to  the  retention  of  7 – 2 items [49]. These  constraints  exist  even for  apparently  exceptional

memory performers who, while they may be capable of more efﬁcient encoding and retrieval of STM, and

while  they may  be  more  efﬁcient  in  ‘‘chunking’’ larger  patterns  of  information  into  single  items,
nevertheless are limited to a STM capacity of 7 – 2 items [50]. Mechanisms for various STM phenomena

have been proposed across many spatial scales [51].  This “rule” is veriﬁed for acoustical STM, as well as

for  visual  or  semantic  STM,  which  typically  require  longer  times  for  rehearsal  in  an  hypothesized
articulatory loop of individual items, with a capacity that appears to be limited to 4 – 2 [52].  SMNI has

detailed these constraints in models of auditory and visual cortex [4,6,15,16].

Another  interesting  phenomenon  of  STM  capacity  explained  by  SMNI  is  the  primacy versus  recency

effect  in  STM  serial  processing [6],  wherein  ﬁrst-learned  items  are  recalled  most  error-free,  with  last-

learned items still more error-free than those in the middle [53].  The basic assumption being made is that
a pattern  of  neuronal  ﬁring  that  persists  for  many t cycles  is  a  candidate  to  store  the  ‘‘memory’’ of

activity that gav e rise to this pattern. If several ﬁring patterns can simultaneously exist, then there is the

capability of storing several memories. The short-time probability distribution derived for the neocortex

is the primary tool to seek such ﬁring patterns. The deepest minima are more likely accessed than the

Statistical Mechanics of Neocortical ...

-6- 

Lester Ingber

others of this probability distribution, and these valleys are sharper than the others. I.e., they are more

readily accessed and sustain their patterns against ﬂuctuations more accurately than the others. The more

recent  memories  or  newer  patterns  may  be  presumed  to  be  those  having  synaptic  parameters  more

recently tuned and/or more actively rehearsed.

It  has  been  noted  that  experimental  data  on  velocities  of  propagation  of  long-ranged  ﬁbers [37,39]  and

derived velocities  of  propagation  of  information  across  local  minicolumnar  interactions [2]  yield

comparable  times  scales  of  interactions  across  minicolumns  of  tenths  of  a  second. Therefore,  such

phenomena as STM likely are inextricably dependent on interactions at local and global scales.

2.2.1.  SMNI & ADP

A proposal  has  been  advanced  that  STM  is  processed  by  information  coded  in  approximately  40-Hz
(approximately 2.5 foldings of t ) bursts per stored memory, permitting up to seven such memories to be

processed serially within single wav es of lower frequencies on the order of 5 to 12 Hz [54].  To account

for the observed duration of STM, they propose that observed after-depolarization (ADP) at synaptic sites,

affected by the action of relatively long-time acting neuromodulators, e.g., acetylcholine and serotonin,

acts  to  regularly  “refresh”  the  stored  memories  in  subsequent  oscillatory  cycles.  A recent  study  of  the

action  of  neuromodulators  in  the  neocortex supports  the  premise  of  their  effects  on  broad  spatial  and

temporal  scales [55],  but  the  ADP  model  is  much  more  speciﬁc  in  its  proposed  spatial  and  temporal

inﬂuences.

SMNI does not detail any speciﬁc synaptic or neuronal mechanisms that might refresh these most-likely

states  to  reinforce  multiple  short-term  memories [18].  However,  the  calculated  evolution  of  states  is

consistent with the observation that an oscillatory subcycle of 40 Hz may be the bare minimal threshold of

self-sustaining minicolumnar ﬁrings before they begin to degrade [16].

The  mechanism  of  ADP  details  a  speciﬁc  synaptic  mechanism  that,  when  coupled  with  additional

proposals of neuronal oscillatory cycles of 5−12 Hz and oscillatory subcycles of 40 Hz, can sustain these

memories for longer durations on the order of seconds. By itself, ADP does not provide a constraint such
as the 7– 2 rule.  The ADP approach does not address the observed random access phenomena of these
memories,  the  4– 2 rule,  the  primacy versus  recency rule,  or  the  inﬂuence  of  STM  in  observed  EEG

patterns.

Statistical Mechanics of Neocortical ...

-7- 

Lester Ingber

SMNI and ADP models are complementary to the understanding of STM. MNN can be used to overlap

the spatial scales studied by the SMNI with the ﬁner spatial scales typically studied by other relatively

more microscopic neural networks.  At this scale, such models as ADP are candidates for providing an

extended duration of ﬁring patterns within the microscopic networks.

2.2.2.  PATHINT

A path-integral  C-language  code,  PATHINT, calculates  the  long-time  probability  distribution  from  the

Lagrangian, e.g., as ﬁt by the ASA code. A robust and accurate histogram-based (non-Monte Carlo) path-

integral  algorithm  to  calculate  the  long-time  probability  distribution  had  been  developed  to  handle

nonlinear  Lagrangians [56-58],  which  was  extended  to  two-dimensional  problems [59].  PATHINT  was

developed for use in arbitrary dimensions, with additional code to handle general Neumann and Dirichlet

conditions, as well as the possibility of including time-dependent potentials, drifts, and diffusions.  The

results  of  using  PATHINT  to  determine  the  evolution  of  the  attractors  of  STM  give  overall  results

consistent with previous calculations [15,16].

2.3.  ASA

In  order  to  maintain  some  audit  trail  from  large-scale  regional  activity  back  to  mesoscopic  columnar

dynamics,  desirable  for  both  academic  interest  as  well  as  practical  signal  enhancement,  as  few

approximations  as  possible  are  made  by  SMNI  in  developing  synaptic  interactions  up  to  the  level of

regional  activity  as  measured  by  scalp  EEG. This  presents  a  formidable  multivariate  nonlinear

nonequilibrium distribution as a model of EEG dynamics, a concept considered to be quite tentative by

research  panels  as  late  as  1990,  until  it  was  demonstrated  how ﬁts  to  EEG  data  could  be

implemented [13].

In order to ﬁt such distributions to real data, ASA has been developed, a global optimization technique, a

superior variant of simulated annealing [24].  This was tested using EEG data in 1991 [13], using an early

and  not  as  ﬂexible  version  of  ASA,  very  fast  reannealing  (VFSR) [24].  Here, this  is  tested  on  more

reﬁned EEG using more sensitive CMI to portray results of the ﬁts [20].

ASA [23] ﬁts short-time probability distributions to observed data, using a maximum likelihood technique

on the Lagrangian. This algorithm has been developed to ﬁt observed data to a theoretical cost function

Statistical Mechanics of Neocortical ...

-8- 

Lester Ingber

over a D-dimensional parameter space [24], adapting for varying sensitivities of parameters during the ﬁt.

Appendix A contains details of ASA relevant to its use in this paper.

2.4.  Complementary Research

2.4.1.  Chaos

Given the context of studies in complex nonlinear systems [60], the question can be asked: What if EEG

has chaotic mechanisms that overshadow the above stochastic considerations? The real issue is whether

the scatter in data can be distinguished between being due to noise or chaos [61].  In this regard, several

studies  have  been  proposed  with  regard  to  comparing  chaos  to  simple  ﬁltered  (colored)  noise [60,62].

Since the existence of multiplicative noise in neocortical interactions has been derived, then the previous

references must be generalized, and further investigation is required to decide whether EEG scatter can be

distinguished from multiplicative noise.

A recent study with realistic EEG wav e equations strongly suggests that if chaos exists in a deterministic

limit,  it  does  not  survive  in macroscopic  stochastic  neocortex [63].  I.e., it  is  important  to  include

stochastic  aspects,  as  arise  from  the  statistics  of  synaptic  and  columnar  interactions,  in  any realistic

description of macroscopic neocortex.

2.4.2.  Other Systems

Experience  using  ASA  on  such  multivariate  nonlinear  stochastic  systems  has  been  gained  by  similar

applications of the approach used for SMNI.

From 1986-1989, these methods of mathematical physics were utilized by a team of scientists and ofﬁcers

to develop mathematical comparisons of Janus computer combat simulations with exercise data from the

National  Training  Center  (NTC),  developing  a  testable  theory  of  combat  successfully  baselined  to

empirical data [59,64-68].

This methodology has been applied to ﬁnancial markets [21,69-71], developing speciﬁc trading rules for

S&P 500 to demonstrate the robustness of these mathematical and numerical algorithms.

Statistical Mechanics of Neocortical ...

-9- 

Lester Ingber

3.  MATHEMATICAL DEVELOPMENT

Fitting  a  multivariate  nonlinear  stochastic  model  to  data  is  a  necessary, but  not  sufﬁcient  procedure  in

developing new diagnostic software.  Even an accurate model ﬁt well to real data may not be immediately

useful  to  clinicians  and  experimental  researchers. To  ﬁll  this  void,  the  powerful  intuitive  basis  of  the

mathematical physics used to develop SMNI has been utilized to describe the model in terms of rigorous

CMI  that  provide  an  immediate  intuitive  portrait  of  the  EEG  data,  faithfully  describing  the  neocortical

system being measured. The CMI give an enhanced signal over the raw data, and give some insights into

the underlying columnar interactions.

3.1.  CMI, Information, Energy

In  the  ﬁrst  SMNI  papers,  it  was  noted  that  this  approach  permitted  the  calculation  of  a  true  nonlinear

nonequilibrium  “information”  entity  at  columnar  scales. With  reference  to  a  steady  state P( ˜M) for  a

short-time Gaussian-Markovian conditional probability distribution P of variables ˜M, when it exists, an
analytic deﬁnition of the information gain ˆ¡

in state ˜P( ˜M) over the entire neocortical volume is deﬁned

by [72,73]

ˆ¡ [ ˜P] = (cid:242)

. . . (cid:242) D ˜M ˜P ln( ˜P/P) , DM = (2p ˆg2
0D

t)- 1/2

(2p ˆg2
s

t)- 1/2dMs ,

u

s=1

(1)

where a path integral is deﬁned such that all intermediate-time values of

˜M appearing in the folded short-

time  distributions ˜P are  integrated  over.  This  is  quite  general  for  any system  that  can  be  described  as

Gaussian-Markovian [74], even if only in the short-time limit, e.g., the SMNI theory.

As  time  evolves,  the  distribution  likely  no  longer  behaves in a Gaussian  manner, and  the  apparent

simplicity  of  the  short-time  distribution  must  be  supplanted  by  numerical  calculations. The  Feynman

Lagrangian is written in the midpoint discretization, for a speciﬁc macrocolumn corresponding to

M(t s) = 1
2

[M(ts+1) + M(ts)] .

(2)

This discretization deﬁnes a covariant Lagrangian L F that possesses a variational principle for arbitrary

noise, and that explicitly portrays the underlying Riemannian geometry induced by the metric tensor gGG¢ ,
calculated to be the inverse of the covariance matrix gGG¢ . Using the Einstein summation convention,

P
D
Statistical Mechanics of Neocortical ...

-10- 

Lester Ingber

P = (cid:242)

. . . (cid:242) DM exp

u

s=0

t L Fs

,

DM = g1/2

0+ (2p D

t)-

u

/2

s=1

g1/2
s+

G=1

(2p D

t)- 1/2dM G
s

,

(cid:242) dM G

s

N G

i =1

D M G

i s , M G

0 = M G

t0 , M G

u+1 = M G

t

,

L F = 1
2

(dM G/dt - hG)gGG¢ (dM G¢ /dt - hG¢ ) + 1
2

hG

;G + R/6 - V ,

(. . .),G =

¶ (. . .)
¶ M G ,

hG = gG -

1

2

- 1/2(g1/2gGG¢ ),G¢

g

,

gGG¢ = (gGG¢ )- 1 ,

gs[M G(t s), t s] = det(gGG¢ )s , gs+ = gs[M G

s+1, t s] ,

hG

;G = hG

,G + G F

GF hG = g

- 1/2(g1/2hG),G ,

G F
JK ” gLF[JK, L] = gLF(gJL,K + gKL,J - gJK,L) ,

R = gJL RJL = gJL gJK RFJKL ,

RFJKL = 1
2

(gFK,JL - gJK,FL - gFL,JK + gJL,FK ) + gMN (G M

FKG N
JL -

G M

FLG N

JK ) ,  

(3)

where R is the Riemannian curvature, and the discretization is explicitly denoted in the mesh of M G
If M is  a  ﬁeld,  e.g.,  also  dependent  on  a  spatial  variable x discretized  by n , then  the  variables M G
s
increased  to M Gn
s

, e.g.,  as  prescribed  for  the  macroscopic  neocortex.  The term R/6  in L F includes  a

i s by i.
is

(cid:230)
Ł
-
S
D
(cid:246)
ł
Q
P
Q
P
ﬁ
S
Statistical Mechanics of Neocortical ...

-11- 

Lester Ingber

contribution of R/12 from the WKB approximation to the same order of (D

t)3/2 [75].

A prepoint discretization for the same probability distribution P gives a much simpler algebraic form,

M(t s) = M(ts) ,

L = 1
2

(dM G/dt - gG)gGG¢ (dM G¢ /dt - gG¢ ) - V ,

(4)

but the  Lagrangian L so  speciﬁed  does  not  satisfy  a  variational  principle  useful  for  moderate  to  large

noise; its associated variational principle only provides information useful in the weak-noise limit [76].

The neocortex presents a system of moderate noise. Still, this prepoint-discretized form has been quite

useful  in  all  systems  examined  thus  far, simply  requiring  a  somewhat  ﬁner  numerical  mesh. Note  that

although  integrations  are  indicated  over a huge  number  of  independent  variables,  i.e.,  as  denoted  by
dM Gn
s

, the physical interpretation afforded by statistical mechanics makes these systems mathematically

and physically manageable.

It  must  be  emphasized  that  the  output  need  not  be  conﬁned  to  complex algebraic  forms  or  tables  of

numbers.  Because L F possesses  a  variational  principle,  sets  of  contour  graphs,  at  different  long-time

epochs of the path-integral of P, integrated over all its variables at all intermediate times, give a visually

intuitive and accurate decision aid to view the dynamic evolution of the scenario. For example, as given

in Table 1, this Lagrangian approach permits a quantitative assessment of concepts usually only loosely

deﬁned.  These physical entities provide another form of intuitive, but quantitatively precise, presentation

of these analyses [68,77].  In this study, the above canonical momenta are referred to canonical momenta

indicators (CMI).

In  a  prepoint  discretization,  where  the  Riemannian  geometry  is  not  explicit  (but  calculated  in  the  ﬁrst

SMNI papers), the distributions of neuronal activities ps i is developed into distributions for activity under
an electrode site P in terms of a Lagrangian L and threshold functions F G,

P =

PG[M G(r; t + t )|M G(r¢ ; t)] =

d

s j

jE

s j - M E(r; t + t )

d

s j - M I (r; t + t )

jI

N

j

ps j

G

G

(2pt gGG)- 1/2 exp(- Nt LG) = (2pt )- 1/2g1/2 exp(- Nt L) ,

P
S
(cid:230)
(cid:231)
Ł
S
(cid:246)
(cid:247)
ł
(cid:230)
(cid:231)
Ł
S
(cid:246)
(cid:247)
ł
P
»
P
Statistical Mechanics of Neocortical ...

-12- 

Lester Ingber

Concept 

Lagrangian equivalent

Momentum P G =

¶ L F

¶ (¶ M G/¶ t)

Mass

Force

F = ma

gGG¢ =
¶ L F
¶ M G
d L F = 0 =

¶ L F

¶ (¶ M G/¶ t)¶ (¶ M G¢ /¶ t)

¶ L F
¶ M G

¶ L F

¶ (¶ M G/¶ t)

¶ t

TABLE  1. Descriptive  concepts  and  their  mathematical  equivalents  in  a  Lagrangian  repre-

sentation.

L = T - V , T = (2N)- 1( ˙M G - gG)gGG¢ ( ˙M G¢

- gG¢ ) ,

gG = - t - 1(M G + N G tanh F G) , gGG¢ = (gGG¢ )- 1 = d G¢

G t - 1 N Gsech2F G , g = det(gGG¢ ) ,

F G =

V G - v|G|
G¢ )2 + (f |G|

G¢ T |G|
G¢
G¢ )2]T |G|

G¢ ))1/2 ,

((p [(v|G|

G¢ = a|G|
T |G|

G¢ N G¢ + 1

2

G¢ M G¢ + a†|G|
A|G|

G¢ N †G¢ + 1

2

G¢ M †G¢ + a‡|G|
A†|G|

G¢ N ‡G¢ + 1

2

G¢ M ‡G¢
A‡|G|

,

G¢ = 1
a†G

2

G¢ + B†G
A†G
G¢

, A‡I
E

= A‡E
I

= A‡I
I

= B‡I
E

= B‡E
I

= B‡I
I

= 0 , a‡E
E

= 1
2

A‡E
E

+ B‡E
E ,

(5)

where no sum is taken over repeated |G|, AG

G¢ and BG

G¢ are macrocolumnar-averaged interneuronal synaptic

efﬁcacies, vG
G¢

and f G
G¢

are  averaged  means  and  variances  of  contributions  to  neuronal  electric

polarizations, N G are the numbers of excitatory and inhibitory neurons per minicolumn, and the variables

associated  with M G, M †G and M ‡G relate  to  multiple  scales  of  activities  from  minicolumns,  between

minicolumns  within  regions,  and  across  regions,  resp. The  nearest-neighbor  interactions V can  be

modeled in greater detail by a stochastic mesoscopic neural network [14]. The SMNI papers give more

-
¶
Statistical Mechanics of Neocortical ...

-13- 

Lester Ingber

detail on this derivation.

In terms of the above variables, an energy or Hamiltonian density H can be deﬁned,

H = T + V ,

(6)

in terms of the M G and P G variables, and the path integral is now deﬁned over all the DM G as well as
over the DP G variables.

3.2.  Nonlinear String Model

A mechanical-analog  model  the  string  model,  is  derived explicitly  for  neocortical  interactions  using

SMNI [12].

In  addition  to  providing  overlap  with  current  EEG  paradigms,  this  deﬁnes  a  probability

distribution  of  ﬁring  activity, which  can  be  used  to  further  investigate  the  existence  of  other  nonlinear

phenomena, e.g., bifurcations or chaotic behavior, in brain states.

Previous  SMNI  studies  have  detailed  that  maximal  numbers  of  attractors  lie  within  the  physical  ﬁring

space  of M G, consistent  with  experimentally  observed  capacities  of  auditory  and  visual  STM,  when  a

“centering”  mechanism  is  enforced  by  shifting  background  conductivities  of  synaptic  interactions,

consistent  with  experimental  observations  under  conditions  of  selective  attention [4,6,15,16,78]. This

leads  to  an  effect  of  having  all  attractors  of  the  short-time  distribution  lie  along  a  diagonal  line  in M G

space,  effectively  deﬁning  a  narrow parabolic  trough  containing  these  most  likely  ﬁring  states. This

essentially collapses the 2 dimensional M G space down to a 1 dimensional space of most importance.

Thus, the predominant physics of short-term memory and of (short-ﬁber contribution to) EEG phenomena

takes  place  in  a  narrow ‘‘parabolic  trough’’ in M G space,  roughly  along  a  diagonal  line [4].  Here, G

represents E or I, M E represents  contributions  to  columnar  ﬁring  from  excitatory  neurons,  and M I

represents contributions to columnar ﬁring from inhibitory neurons. The object of interest within a short
refractory time, t , approximately 5 to 10 msec, is the Lagrangian L for a mesocolumn, detailed above.

t L can  vary  by  as  much  as  a  factor  of  105 from  the  highest  peak  to  the  lowest  valley in M G space.

Therefore,  it  is  reasonable  to  assume  that  a  single  independent  ﬁring  variable  might  offer  a  crude
description of this physics.  Furthermore, the scalp potential F

can be considered to be a function of this

ﬁring variable.  (Here, ‘‘potential’’ refers to the electric potential, not the potential term in the Lagrangian

above.)  In an abbreviated notation subscripting the time-dependence,

Statistical Mechanics of Neocortical ...

-14- 

Lester Ingber

t- << F >>= F

(M E

t , M I

t ) » a(M E

t

- << M E >>) + b(M I

t - << M I >>) ,  

(7)

where a and b are constants, and << F >>  and << M G >>  represent typical minima in the trough. In the
context of ﬁtting data to the dynamic variables, there are three effective constants, { a, b, f } ,

t -

f = aM E

t + bM I

t

.

(8)

The mesoscopic probability distributions, P, are scaled and aggregated over this columnar ﬁring space to

obtain the macroscopic probability distribution over the scalp-potential space:

PF [F

] = (cid:242) dM E dM I P[M E, M I ]d [F

¢ (M E, M I )] .

In the prepoint discretization, the postpoint M G(t + D

t) moments are given by

m ” < F

n -

f >= a < M E > +b < M I >= agE + bgI ,

s 2 ” < (F

n -

f )2 > - < F

n -

f >2= a2gEE + b2gII ,

(9)

(10)

where the M G-space drifts gG, and diffusions gGG¢ , are given above. Note that the macroscopic drifts and
diffusions of the F
’s are simply linearly related to the mesoscopic drifts and diffusions of the M G’s. For
the prepoint M G(t) ﬁrings, the same linear relationship in terms of { f , a, b } is assumed.

For the  prepoint M E(t) ﬁrings,  advantage  is  taken  of  the  parabolic  trough  derived for  the  STM

Lagrangian, and

M I (t) = cM E(t) ,  

(11)

where  the  slope c is  set  to  the  close  approximate  value  determined  by  a  detailed  calculation  of  the

centering mechanism [15],

E M E - AE
AE

I M I » 0 .  

(12)

This permits a complete transformation from M G variables to F

variables.

Similarly, as appearing in the modiﬁed threshold factor F G, each regional inﬂuence from electrode site m
acting at electrode site n , giv en by afferent ﬁrings M ‡E, is taken as

F
F
-
F
Statistical Mechanics of Neocortical ...

-15- 

M ‡E
m ﬁ

n = dn M E

m (t - T m ﬁ

n ) ,  

Lester Ingber

(13)

where dn are constants to be ﬁtted at each electrode site, and T m ﬁ

n are the delay times estimated above

for inter-electrode signal propagation, based on anatomical knowledge of the neocortex and of velocities

of propagation of action potentials of long-ranged ﬁbers, typically on the order of one to several multiples
of t = 5 msec.  Some terms  in  which d directly  affects  the  shifts  of  synaptic  parameters BG

G¢ when
* E
E¢ .

calculating  the  centering  mechanism  also  contain  long-ranged  efﬁcacies  (inverse  conductivities) B

Therefore, the latter were kept ﬁxed with the other electrical-chemical synaptic parameters during these

ﬁts.  Future ﬁts will experiment taking the T ’s as parameters.

This deﬁnes the conditional probability distribution for the measured scalp potential F

n ,

Pn [F

n (t + D

t)|F

n (t)] =

1
2D

t)1/2 exp(- Ln D

t) ,

(2ps

Ln = 1

2s 2 ( ˙F

n - m)2 .

The probability distribution for all electrodes is taken to be the product of all these distributions:

P =

n

Pn

, L =

S Ln .

n

(14)

(15)

Note that the belief in the dipole or nonlinear-string model is being invoked.  The model SMNI, derived
for P[M G(t + D
reasonable approximation to represent a macrocolumn, scaled to its contribution to F

t)|M G(t)],  is  for  a  macrocolumnar-averaged  minicolumn;  hence  it  is  expected  to  be  a

n . Hence, L is used

to represent this macroscopic regional Lagrangian, scaled from its mesoscopic mesocolumnar counterpart

L. Howev er,  the  above  expression  for Pn uses  the  dipole  assumption  to  also  use  this  expression  to

represent several to many macrocolumns present in a region under an electrode: A macrocolumn has a

spatial  extent  of  about  a  mm. It  is  often  argued  that  typically  several  macrocolumns  ﬁring  coherently

account for the electric potentials measured by one scalp electrode [79].  Then, this model is being tested

to  see  if  the  potential  will  scale  to  a  representative  macrocolumn.  The results  presented  here  seem  to

conﬁrm that this approximation is in fact quite reasonable.

P
Statistical Mechanics of Neocortical ...

-16- 

Lester Ingber

The parabolic trough described above justiﬁes a form

PF = (2ps

2D

t)- 1/2 exp(-

t

2s 2 (cid:242) dx LF ) ,

LF = a
2

|¶

/¶ t|2 + b
2

|¶

/¶ x|2 + g
2

|F

|2 + F(F

) ,  

(16)

where F(F

) contains nonlinearities away from the trough, s 2 is on the order of N given the derivation of

L above, and the integral over x is taken over the spatial region of interest. In general, there also will be
terms linear in ¶
/¶ x. (This corrects a typo that appears in several papers [12,13,17,19],
incorrectly giving the order of s 2 as 1/N. The order N was ﬁrst derived [13] from s 2 being expressed as

/¶ t and in ¶

a sum over the E and I diffusions given above.)

Previous  calculations  of  EEG  phenomena [5],  show that  the  short-ﬁber  contribution  to  the a frequency

and  the  movement  of  attention  across  the  visual  ﬁeld  are  consistent  with  the  assumption  that  the  EEG
physics is derived from an average over the ﬂuctuations of the system, e.g., represented by s in the above

equation.  I.e., this  is  described  by  the  Euler-Lagrange  equations  derived from  the  variational  principle

possessed by LF

(essentially the counterpart to force equals mass times acceleration), more properly by

the ‘‘midpoint-discretized’’ Feynman LF

, with its Riemannian terms [2,3,11].

3.3.  CMI Sensitivity

In the SMNI approach, “information” is a concept well deﬁned in terms of the probability eigenfunctions

of  electrical-chemical  activity  of  this  Lagrangian. The  path-integral  formulation  presents  an  accurate

intuitive  picture  of  an  initial  probability  distribution  of  patterns  of  ﬁrings  being  ﬁltered  by  the

(exponential of the) Lagrangian, resulting in a ﬁnal probability distribution of patterns of ﬁring.

The utility of a measure of information has been noted by other investigators.  For example, there have

been attempts to use information as an index of EEG activity [80,81]. These attempts have focused on the

concept  of  “mutual  information”  to  ﬁnd  correlations  of  EEG  activity  under  different  electrodes. Other

investigators  have  looked  at  simulation  models  of  neurons  to  extract  information  as  a  measure  of

complexity  of  information  processing [82].  Some other  investigators  have  examined  the  utility  of  the

energy density as a viable measure of information processing STM paradigms [83].

D
F
F
F
F
Statistical Mechanics of Neocortical ...

-17- 

Lester Ingber

The SMNI approach at the outset recognizes that, for most brain states of late latency, at least a subset of

regions  being  measured  by  several  electrodes  is  indeed  to  be  considered  as  one  system,  and  their

interactions  are  to  be  explicated  by  mathematical  or  physical  modeling  of  the  underlying  neuronal

processes.  Then, it is not relevant to compare joint distributions over a  set of electrodes with marginal

distributions over individual electrodes.

In  the  context  of  the  present  SMNI  study,

the  CMI  transform  covariantly  under  Riemannian

transformations, but are more sensitive measures of neocortical activity than other invariants such as the

energy density, effectively the square of the CMI, or the information which also effectively is in terms of

the square of the CMI (essentially path integrals over quantities proportional to the energy times a factor

of an exponential including the energy as an argument).  Neither the energy or the information give details

of the components as do the CMI. EEG is measuring a quite oscillatory system and the relative signs of

such  activity  are  quite  important. The  information  and  energy  densities  are  calculated  and  printed  out

after ASA ﬁts along with the CMI.

4.  SMNI APPLICATIONS TO INDIVIDUAL EEG

4.1.  Data

EEG  spontaneous  and  evoked potential  (EP)  data  from  a  multi-electrode  array  under  a  variety  of

conditions  was  collected  at  several  centers  in  the  United  States,  sponsored  by  the  National  Institute  on

Alcohol  Abuse  and  Alcoholism  (NIAAA)  project. The  earlier  1991  study  used  only  averaged  EP

data [84]. These  experiments,  performed  on  carefully  selected  sets  of  subjects,  suggest  a  genetic

predisposition to alcoholism that is strongly correlated to EEG AEP responses to patterned targets.

It is clear that the author is not an expert in the clinical aspects of these alcoholism studies. It sufﬁces for

this study that the data used is clean raw EEG data, and that these SMNI, CMI, and ASA techniques can

and should be used and tested on other sources of EEG data as well.

Each set of results is presented with 6 ﬁgures, labeled as [{alcoholic | control}, {stimulus 1 | match | no-
match}, subject, {potential | momenta}], abbreviated to {a | c}_{1 | m | n}_subject.{pot | mom} where

match or no-match was performed for stimulus 2 after 3.2 sec of a presentation of stimulus 1 [84].  Data

Statistical Mechanics of Neocortical ...

-18- 

Lester Ingber

includes 10 trials of 69 epochs each between 150 and 400 msec after presentation. For each subject run,

after ﬁtting 28 parameters with ASA, epoch by epoch averages are developed of the raw data and of the

multivariate  SMNI  CMI.
mechanism [4,6], driving multiple attractors into the physical ﬁring regions bounded by M G £

It  was  noted  that  much  poorer  ﬁts  were  achieved when  the  “centering”

N G, was

turned off and the denominators in F G were set to constants, conﬁrming the importance of using the full

SMNI model. All stimuli were presented for 300 msec. For example, c_m_co2c0000337.pot is a ﬁgure.
Note that the subject number also includes the {alcoholic | control} tag, but this tag was added just to aid

sorting  of  ﬁles  (as  there  are  contribution  from  co2  and  co3  subjects). Each  ﬁgure  contains  graphs

superimposed  for  6  electrode  sites  (out  of  64  in  the  data)  which  have  been  modeled  by  SMNI  using  a

circuitry  given in Table  2  of  frontal  sites  (F3  and  F4)  feeding  temporal  (sides  of  head  T7  and  T8)  and

parietal (top of head P7 and P8) sites, where odd-numbered (even-numbered) sites refer to the left (right)

brain.

4.2.  ASA Tuning

A three-stage optimization was performed for each of 60 data sets in {a_n, a_m, a_n, c_1, c_m, c_n} of

10  subjects. As  described  previously, each  of  these  data  sets  had  3-5  parameters  for  each  SMNI
electrode-site model in {F3, F4, T7, T8, P7, P8}, i.e., 28 parameters for each of the optimization runs, to

be ﬁt to over 400 pieces of potential data.

For each state generated in the ﬁt, prior to calculating the Lagrangian, tests were performed to ensure that

all  short-ranged  and  long-ranged  ﬁrings  lay  in  their  physical  boundaries. When  this  test  failed,  the

generated  state  was  simply  excluded  from  the  parameter  space  for  further  consideration. This  is  a

standard simulated-annealing technique to handle complex constraints.

4.2.1.  First-Stage Optimization

The ﬁrst-stage optimization used ASA, version 13.1, tuned to give reasonable performance by examining

intermediate results of several sample runs in detail. Table 3 gives those OPTIONS changed from their

defaults.  (See Appendix A for a discussion of ASA OPTIONS.)

The  ranges  of  the  parameters  were  decided  as  follows.  The ranges  of  the  strength  of  the  long-range
connectivities dn were  from  0  to  1. The  ranges  of  the {a, b, c} parameters  were  decided  by  using

–
Statistical Mechanics of Neocortical ...

-19- 

Lester Ingber

Site  Contributions From Time Delays (3.906 msec)

F3 

F4 

T7 

T7 

T8 

T8 

P7 

P7 

P7 

P8 

P8 

P8 

−

−

F3

T8

F4

T7

T7

P8

F3

T8

P7

F4

−

−

1

1

1

1

1

1

2

1

1

2

TABLE  2. Circuitry  of  long-ranged  ﬁbers  across  most  relevant  electrode  sites  and  their

assumed time-delays in units of 3.906 msec.

minimum  and  maximum  values  of M G and M ‡G ﬁrings  to  keep  the  potential  variable  within  the

minimum and maximum values of the experimentally measured potential at each electrode site.

Using  the  above  ASA  OPTIONS  and  ranges  of  parameters,  it  was  found  that  typically  within  several

thousand  generated  states,  the  global  minimum  was  approached  within  at  least  one  or  two signiﬁcant

ﬁgures  of  the  effective  Lagrangian  (including  the  prefactor).  This estimate  was  based  on  ﬁnal  ﬁts

achieved with  hundreds  of  thousands  of  generated  states. Runs  were  permitted  to  continue  for  50,000

generated  states. This  very  rapid  convergence  in  these  30-dimensional  spaces  was  partially  due  to  the

invocation of the centering mechanism.

Some  tests  with  SMNI  parameters  off the  diagonal  in M G-space,  as  established  by  the  centering

mechanism,  conﬁrmed  that  ASA  converged  back  to  this  diagonal,  but  requiring  many more  generated

states.  Of course, an examination of the Lagrangian shows this trivially, as noted in previous papers [3,4],

Statistical Mechanics of Neocortical ...

-20- 

Lester Ingber

OPTIONS 

Default 

Stage 1 Use

Limit_Acceptances 

Limit_Generated 

Cost_Precision 

10000

99999

25000

50000

1.0E-18

1.0E-9

Number_Cost_Samples 

Cost_Parameter_Scale_Ratio 

5

1.0

Acceptance_Frequency_Modulus 

100

Generated_Frequency_Modulus 

10000

3

0.2

25

10

4

0

Reanneal_Cost 

Reanneal_Parameters 

SMALL_FLOAT 

ASA_LIB 

QUENCH_COST 

QUENCH_PARAMETERS 

COST_FILE 

NO_PARAM_TEMP_TEST 

NO_COST_TEMP_TEST 

TIME_CALC 

ASA_PRINT_MORE 

1

1

1.0E-18 

1.0E-30

FALSE 

FALSE 

FALSE 

TRUE 

FALSE 

FALSE 

FALSE 

FALSE 

TRUE

TRUE

TRUE

FALSE

TRUE

TRUE

TRUE

TRUE

TABLE 3. ASA OPTIONS changes from their defaults used in stage one optimization.

wherein  the  Lagrangian  values  were  on  the  order  of  105 t - 1, compared  to  10- 2−10- 3 t - 1 along  the

diagonal established by the centering mechanism.

4.2.2.  Second-Stage Optimization

The second-stage optimization was invoked to minimize the number of generated states that would have

been required if only the ﬁrst-stage optimization were performed. Table 4 gives the changes made in the

Statistical Mechanics of Neocortical ...

-21- 

Lester Ingber

OPTIONS from stage one for stage two.

OPTIONS 

Stage 2 Changes

Limit_Acceptances 

Limit_Generated 

User_Initial_Parameters 

5000

10000

TRUE

User_Quench_Param_Scale[.] 

30

TABLE 4. ASA OPTIONS changes from their use in stage one for stage two optimization.

The  ﬁnal  stage-one  parameters  were  used  as  the  initial  starting  parameters  for  stage  two.  (At high

annealing/quenching temperatures at the start of an SA run, it typically is not important as to what the

initial  values  of  the  the  parameters  are,  provided  of  course  that  they satisfy  all  constraints,  etc.) The

second-stage minimum of each parameter was chosen to be the maximum lower bound of the ﬁrst-stage

minimum  and  a  20%  increase  of  that  minimum. The  second-stage  maximum  of  each  parameter  was

chosen to be the minimum upper bound of the ﬁrst-stage maximum and a 20% decrease of that maximum.

Extreme  quenching  was  turned  on  for  the  parameters  (not  for  the  cost  temperature),  at  values  of  the

parameter dimension of 30, increased from 1 (for rigorous annealing). This worked very well, typically

achieving the global minimum with 1000 generated states. Runs were permitted to continue for 10000

generated states.

4.2.3.  Third-Stage Optimization

The  third-stage  optimization  used  a  quasi-local  code,  the  Broyden-Fletcher-Goldfarb-Shanno  (BFGS)

algorithm [85], to gain an extra 2 or 3 ﬁgures of precision in the global minimum. This typically took

several  hundred  states,  and  runs  were  permitted  to  continue  for  500  generated  states. Constraints  were

enforced by the method of penalties added to the cost function outside the constraints.

The  BFGS  code  typically  got  stuck  in  a  local  minimum  quite  early  if  invoked just  after  the  ﬁrst-stage

optimization.  (There never was  a  reasonable  chance  of  getting  close  to  the  global  minimum  using  the

Statistical Mechanics of Neocortical ...

-22- 

Lester Ingber

BFGS code as a ﬁrst-stage optimizer.)  These ﬁts were much more efﬁcient than those in a previous 1991

study [13], where VFSR, the precursor code to ASA, was used for a long stage-one optimization which

was then turned over to BFGS.

4.3.  Results

Figs.  1-3  compares  the  CMI  to  raw data  for  an  alcoholic  subject  for  the  a_1,  a_m  and  a_n  paradigms.

Figs. 4-6 gives similar comparisons for a control subject for the c_1, c_m and c_n paradigms. The SMNI

CMI  give  better  signal  to  noise  resolution  than  the  raw data,  especially  comparing  the  signiﬁcant

matching tasks between the control and the alcoholic groups, e.g., the c_m and a_m paradigms. The CMI

can be processed further as is the raw data, and also used to calculate “energy” and “information/entropy”

densities.

Statistical Mechanics of Neocortical ...

-23- 

Lester Ingber

F3
F4
P7
P8
T7
T8

0.30

0.25

0.20

0.15

0.10

0.05

0.00

-0.05

-0.10

-0.15

)

/

t

V
u
1
(
 
a
n
e
m
o
m

-0.20

0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

time (sec)

10.0

8.0

6.0

4.0

2.0

0.0

-2.0

-4.0

-6.0

-8.0

-10.0

-12.0

-14.0

-16.0

-18.0

)

V
u
(
 
s
a
i
t
n
e

l

t

o
p

F3
F4
P7
P8
T7
T8

-20.0

0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

time (sec)

FIG.  1. For the  initial-stimulus  a_1  paradigm  for  alcoholic  subject  co2a0000364,  plots  are

given of activities  under  6  electrodes  of  the  CMI  in  the  upper  ﬁgure,  and  of  the  electric

potential in the lower ﬁgure.

Statistical Mechanics of Neocortical ...

-24- 

Lester Ingber

F3
F4
P7
P8
T7
T8

0.20

0.15

0.10

0.05

0.00

-0.05

-0.10

-0.15

-0.20

-0.25

)

/

t

V
u
1
(
 
a
n
e
m
o
m

-0.30

0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

time (sec)

F3
F4
P7
P8
T7
T8

4.0

2.0

0.0

-2.0

-4.0

-6.0

-8.0

-10.0

-12.0

-14.0

-16.0

-18.0

)

V
u
(
 
s
a
i
t
n
e

l

t

o
p

-20.0

0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

time (sec)

FIG.  2. For the  match  second-stimulus  a_m  paradigm  for  alcoholic  subject  co2a0000364,

plots  are  given of activities  under  6  electrodes  of  the  CMI  in  the  upper  ﬁgure,  and  of  the

electric potential in the lower ﬁgure.

Statistical Mechanics of Neocortical ...

-25- 

Lester Ingber

F3
F4
P7
P8
T7
T8

0.40

0.30

0.20

0.10

0.00

-0.10

-0.20

-0.30

)

/

t

V
u
1
(
 
a
n
e
m
o
m

-0.40

0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

time (sec)

F3
F4
P7
P8
T7
T8

9.0

7.0

5.0

3.0

1.0

-1.0

-3.0

-5.0

-7.0

-9.0

-11.0

-13.0

)

V
u
(
 
s
a
i
t
n
e

l

t

o
p

-15.0

0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

time (sec)

FIG. 3. For the no-match second-stimulus a_n paradigm for alcoholic subject co2a0000364,

plots  are  given of activities  under  6  electrodes  of  the  CMI  in  the  upper  ﬁgure,  and  of  the

electric potential in the lower ﬁgure.

Statistical Mechanics of Neocortical ...

-26- 

Lester Ingber

F3
F4
P7
P8
T7
T8

0.20

0.15

0.10

0.05

0.00

-0.05

-0.10

-0.15

)

/

t

V
u
1
(
 
a
n
e
m
o
m

-0.20

0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

time (sec)

F3
F4
P7
P8
T7
T8

14.0

12.0

10.0

8.0

6.0

4.0

2.0

0.0

-2.0

-4.0

-6.0

-8.0

)

V
u
(
 
s
a
i
t
n
e

l

t

o
p

-10.0

0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

time (sec)

FIG.  4. For the  initial-stimulus  c_1  paradigm  for  control  subject  co2c0000337,  plots  are

given of activities  under  6  electrodes  of  the  CMI  in  the  upper  ﬁgure,  and  of  the  electric

potential in the lower ﬁgure.

Statistical Mechanics of Neocortical ...

-27- 

Lester Ingber

F3
F4
P7
P8
T7
T8

0.20

0.15

0.10

0.05

0.00

-0.05

-0.10

-0.15

)

/

t

V
u
1
(
 
a
n
e
m
o
m

-0.20

0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

time (sec)

F3
F4
P7
P8
T7
T8

4.0

2.0

0.0

-2.0

-4.0

-6.0

-8.0

-10.0

-12.0

-14.0

-16.0

-18.0

)

V
u
(
 
s
a
i
t
n
e

l

t

o
p

-20.0

0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

time (sec)

FIG. 5. For the match second-stimulus c_m paradigm for control subject co2c0000337, plots

are given of activities under 6 electrodes of the CMI in the upper ﬁgure, and of the electric

potential in the lower ﬁgure.

Statistical Mechanics of Neocortical ...

-28- 

Lester Ingber

F3
F4
P7
P8
T7
T8

0.30

0.25

0.20

0.15

0.10

0.05

0.00

-0.05

-0.10

-0.15

)

/

t

V
u
1
(
 
a
n
e
m
o
m

-0.20

0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

time (sec)

F3
F4
P7
P8
T7
T8

5.0

3.0

1.0

-1.0

-3.0

-5.0

-7.0

-9.0

-11.0

-13.0

)

V
u
(
 
s
a
i
t
n
e

l

t

o
p

-15.0

0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

time (sec)

FIG.  6. For the  no-match  second-stimulus  c_n  paradigm  for  control  subject  co2c0000337,

plots  are  given of activities  under  6  electrodes  of  the  CMI  in  the  upper  ﬁgure,  and  of  the

electric potential in the lower ﬁgure.

Statistical Mechanics of Neocortical ...

-29- 

Lester Ingber

Similar results are seen for other subjects. A compressed tarﬁle for 10 control and 10 alcoholic subjects,

a

total 

of 

120 

PostScript 

ﬁgures, 

can 

be 

retrieved

via  WWW 

from

http://www.ingber.com/MISC.DIR/smni97_eeg_cmi.tar.Z, or as ﬁle smni97_eeg_cmi.tar.Z via FTP from

ftp.ingber.com in the MISC.DIR directory.

5.  CONCLUSIONS

5.1.  CMI and Linear Models

It is clear that the CMI follow the measured potential variables closely. In large part, this is due to the

prominent attractors near the ﬁring states M G being close to their origins, resulting in moderate threshold

functions F G in these regions.  This keeps the term in the drifts proportional to tanh F G near its lowest

values, yielding values of the drifts on the order of the time derivatives of the potentials. The diffusions,

proportional to sechF G, also do not ﬂuctuate to very large values.

However,  when  the  feedback  among  potentials  under  electrode  sites  are  strong,  leading  to  enhanced

(nonlinear) changes in the drifts and diffusions, then these do cause relatively largest signals in the CMI

relative to those appearing in the raw potentials.  Thus, these effects are strongest in the c_m sets of data,

where the control (normal) subjects demonstrate more intense circuitry interactions among electrode sites

during the matching paradigm.

These results also support independent studies of primarily long-ranged EEG activity, that have concluded

that EEG many times appears to demonstrate quasi-linear interactions [39,86].  However, it must be noted

that  this  is  only  true  within  the  conﬁnes  of  an  attractor  of  highly  nonlinear  short-ranged  columnar

interactions.  It requires some effort, e.g., global optimization of a robust multivariate stochastic nonlinear

system to achieve ﬁnding this attractor. Theoretically, using the SMNI model, this is performed using the

ASA  code. Presumably, the  neocortical  system  utilizes  neuromodular  controls  to  achieve  this  attractor

state [55,78], as suggested in early SMNI studies [3,4].

5.2.  CMI Features

Essential  features  of  the  SMNI  CMI  approach  are:  (a)  A  realistic  SMNI  model,  clearly  capable  of

modeling  EEG  phenomena,  is  used,  including  both  long-ranged  columnar  interactions  across  electrode

Statistical Mechanics of Neocortical ...

-30- 

Lester Ingber

sites and short-ranged columnar interactions under each electrode site. (b) The data is used raw for the

nonlinear model, and only after the ﬁts are moments (averages and variances) taken of the derived CMI

indicators; this is unlike other studies that most often start with averaged potential data. (c) A novel and

sensitive measure, CMI, is used, which has been shown to be successful in enhancing resolution of signals

in  another  stochastic  multivariate  time  series  system,  ﬁnancial  markets [21,22]. As  was  performed  in

those  studies,  future  SMNI  projects  can  similarly  use  recursive  ASA  optimization,  with  an  inner-shell

ﬁtting CMI of subjects’ EEG, embedded in an outer-shell of parameterized customized clinician’s AI-type

rules acting on the CMI, to create supplemental decision aids.

Canonical momenta offers an intuitive yet detailed coordinate system of some complex systems amenable

to  modeling  by  methods  of  nonlinear  nonequilibrium  multivariate  statistical  mechanics. These  can  be

used as reasonable indicators of new and/or strong trends of behavior, upon which reasonable decisions

and  actions  can  be  based,  and  therefore  can  be  be  considered  as  important  supplemental  aids  to  other

clinical indicators.

5.3.  CMI and Source Localization

Global ASA optimization, ﬁtting the nonlinearities inherent in the synergistic contributions from short-

ranged columnar ﬁrings and from long-ranged ﬁbers, makes it possible to disentangle their contributions

to some speciﬁc electrode circuitries among columnar ﬁrings under regions separated by cm, at least to

the degree that the CMI clearly offer superior signal to noise than the raw data.  Thus this paper at least

establishes  the  utility  of  the  CMI  for  EEG  analyses,  which  can  be  used  to  complement  other  EEG

modeling techniques. In this paper, a plausible circuitry was ﬁrst hypothesized (by a group of experts),

and it remains to be seen just how many more electrodes can be added to such studies with the goal being

to have ASA ﬁts determine the optimal circuitry.

It  is  clear  that  future  SMNI  projects  should  integrate  current  modeling  technologies  together  with  the

CMI.  For example, one approach for adding CMI to this set of tools would be to use source-localization

techniques  to  generate  simulated  macrocolumnar  cortical  potentials  (effectively  a  best  ﬁt  of  source-

generated  potentials  to  raw scalp  data)  to  determine  the  CMI. The  CMI  then  can  provide  further

disentanglement of short-ranged and long-ranged interactions to determine most likely circuit dynamics.

Since source localization often is a non-unique process, this may provide an iterative approach to aid ﬁner

Statistical Mechanics of Neocortical ...

-31- 

Lester Ingber

source  localization. That  is,  SMNI  is  a  nonlinear  stochastic  model  based  on  realistic  neuronal

interactions, and it is reasonable to assume that the derived CMI add much additional information to these

localization analyses.

5.4.  SMNI Features

Sets  of  EEG  data  taken  during  selective  attention  tasks  have  been  ﬁt  using  parameters  either  set  to

experimentally observed values, or have  been ﬁt within experimentally observed values.  The ranges of

columnar ﬁrings are consistent with a centering mechanism derived for STM in earlier papers.

These results, in addition to their importance in reasonably modeling EEG with SMNI, also have a deeper

theoretical  importance  with  respect  to  the  scaling  of  neocortical  mechanisms  of  interaction  across

disparate spatial scales and behavioral phenomena: As has been pointed out previously, SMNI has given

experimental  support  to  the  derivation  of  the  mesoscopic  probability  distribution,  illustrating  common

forms  of  interactions  between  their  entities,  i.e.,  neurons  and  columns  of  neurons,  respectively. The

nonlinear threshold factors are deﬁned in terms of electrical-chemical synaptic and neuronal parameters

all lying within their experimentally observed ranges. It also was noted that the most likely trajectories of

the mesoscopic probability distribution, representing averages over columnar domains, give a description

of  the  systematics  of  macroscopic  EEG  in  accordance  with  experimental  observations.  It has  been

demonstrated  that  the  macroscopic  regional  probability  distribution  can  be  derived to hav e same

functional  form  as  the  mesoscopic  distribution,  where  the  macroscopic  drifts  and  diffusions  of  the
potentials  described  by  the F

’s  are  simply  linearly  related  to  the  (nonlinear)  mesoscopic  drifts  and

diffusions  of  the  columnar  ﬁring  states  given by the M G’s. Then,  this  macroscopic  probability

distribution gives a reasonable description of experimentally observed EEG.

The theoretical and experimental importance of speciﬁc scaling of interactions in the neocortex has been

quantitatively  demonstrated  on  individual  brains. The  explicit  algebraic  form  of  the  probability

distribution  for  mesoscopic  columnar  interactions  is  driven by a nonlinear  threshold  factor  of  the  same

form  taken  to  describe  microscopic  neuronal  interactions,  in  terms  of  electrical-chemical  synaptic  and

neuronal parameters all lying within their experimentally observed ranges; these threshold factors largely

determine the nature of the drifts and diffusions of the system. This mesoscopic probability distribution

has  successfully  described  STM  phenomena  and,  when  used  as  a  basis  to  derive  the  most  likely

Statistical Mechanics of Neocortical ...

-32- 

Lester Ingber

trajectories using the Euler-Lagrange variational equations, it also has described the systematics of EEG

phenomena.  In this paper, the mesoscopic form of the full probability distribution has been taken more

seriously for macroscopic interactions, deriving macroscopic drifts and diffusions linearly related to sums

of their (nonlinear) mesoscopic counterparts, scaling its variables to describe interactions among regional

interactions correlated with observed electrical activities measured by electrode recordings of scalp EEG,

with  apparent  success. These  results  give  strong  quantitative  support  for  an  accurate  intuitive  picture,

portraying neocortical interactions as having common algebraic or physics mechanisms that scale across

quite disparate spatial scales and functional or behavioral phenomena, i.e., describing interactions among

neurons, columns of neurons, and regional masses of neurons.

5.5.  Summary

SMNI  is  a  reasonable  approach  to  extract  more  ‘‘signal’’ out  of  the  ‘‘noise’’ in EEG  data,  in  terms  of

physical  dynamical  variables,  than  by  merely  performing  regression  statistical  analyses  on  collateral

variables.  To learn  more  about  complex systems,  inevitably  functional  models  must  be  formed  to

represent  huge  sets  of  data.

Indeed,  modeling  phenomena  is  as  much  a  cornerstone  of  20th  century

science as is collection of empirical data [87].

It  seems  reasonable  to  speculate  on  the  evolutionary  desirability  of  developing  Gaussian-Markovian

statistics at the mesoscopic columnar scale from microscopic neuronal interactions, and maintaining this

type  of  system  up  to  the  macroscopic  regional  scale.

I.e.,  this  permits  maximal  processing  of

information [73]. There  is  much  work  to  be  done,  but  modern  methods  of  statistical  mechanics  have

helped to point the way to promising approaches.

APPENDIX A: ADAPTIVE SIMULATED ANNEALING (ASA)

1.  General Description

Simulated  annealing  (SA)  was  developed  in  1983  to  deal  with  highly  nonlinear  problems [88],  as  an

extension  of  a  Monte-Carlo  importance-sampling  technique  developed  in  1953  for  chemical  physics

problems.  It helps to visualize the problems presented by such complex systems as a geographical terrain.

For example,  consider  a  mountain  range,  with  two “parameters,” e.g.,  along  the  North−South  and

Statistical Mechanics of Neocortical ...

-33- 

Lester Ingber

East−West directions, with the goal to ﬁnd the lowest valley in this terrain. SA approaches this problem

similar  to  using  a  bouncing  ball  that  can  bounce  over mountains  from  valley to valley.  Start  at  a  high

“temperature,” where the temperature is an SA parameter that mimics the effect of a fast moving particle

in a hot object like a hot molten metal, thereby permitting the ball to make very high bounces and being

able  to  bounce  over any  mountain  to  access  any valley,  giv en enough  bounces. As  the  temperature  is

made  relatively  colder, the  ball  cannot  bounce  so  high,  and  it  also  can  settle  to  become  trapped  in

relatively smaller ranges of valleys.

Imagine that a mountain range is aptly described by a “cost function.” Deﬁne probability distributions of

the  two directional  parameters,  called  generating  distributions  since  they generate  possible  valleys  or

states  to  explore.  Deﬁne another  distribution,  called  the  acceptance  distribution,  which  depends  on  the

difference of cost functions of the present generated valley to be explored and the last saved lowest valley.

The acceptance distribution decides probabilistically whether to stay in a new lower valley or to bounce

out of it. All the generating and acceptance distributions depend on temperatures.

In  1984 [89],  it  was  established  that  SA  possessed  a  proof  that,  by  carefully  controlling  the  rates  of

cooling  of  temperatures,  it  could  statistically  ﬁnd  the  best  minimum,  e.g.,  the  lowest  valley of our

example above. This was good news for people trying to solve hard problems which could not be solved

by other algorithms. The bad news was that the guarantee was only good if they were willing to run SA

forever.  In 1987,  a  method  of  fast  annealing  (FA)  was  developed [90], which  permitted  lowering  the

temperature exponentially faster, thereby statistically guaranteeing that the minimum could be found in

some  ﬁnite  time. However,  that  time  still  could  be  quite  long. Shortly  thereafter, Very  Fast  Simulated

Reannealing  (VFSR)  was  developed [24], now called  Adaptive  Simulated  Annealing  (ASA),  which  is

exponentially faster than FA.

ASA has been applied to many problems by many people in many disciplines [26,27,91]. The feedback

of  many users  regularly  scrutinizing  the  source  code  ensures  its  soundness  as  it  becomes  more  ﬂexible

and powerful.  The code is available via the world-wide web (WWW) as http://www.ingber.com/ which

also can be accessed anonymous FTP from ftp.ingber.com.

Statistical Mechanics of Neocortical ...

-34- 

Lester Ingber

2.  Mathematical Outline

ASA considers a parameter a i

k in dimension i generated at annealing-time k with the range

a i
k

˛ [Ai, Bi] ,  

calculated with the random variable yi,

k+1 = a i
a i

k

+ yi(Bi - Ai) ,

yi ˛ [- 1, 1] .

The generating function gT (y) is deﬁned,

gT (y) = D
i=1

1

2(|yi| + Ti) ln(1 + 1/Ti)

” D
i=1

gi
T (yi) ,  

(A.1)

(A.2)

(A.3)

where the subscript i on Ti speciﬁes the parameter index, and the k-dependence in Ti(k) for the annealing

schedule has been dropped for brevity. Its cumulative probability distribution is

GT (y) =

. . .

y1

- 1

yD

- 1

(cid:242) dy¢ 1 . . . dy¢ D gT (y¢ ) ” D

P Gi
i=1

T (yi) ,

T (yi) = 1
Gi
2

+ sgn (yi)

2

ln(1 + |yi|/Ti)
ln(1 + 1/Ti)

.

yi is generated from a ui from the uniform distribution

ui ˛ U[0, 1] ,

yi = sgn (ui -

1

2

)Ti[(1 + 1/Ti)|2ui- 1| - 1] .

It is straightforward to calculate that for an annealing schedule for Ti

Ti(k) = T0i exp(- ci k1/D) ,  

(A.4)

(A.5)

(A.6)

P
P
(cid:242)
Statistical Mechanics of Neocortical ...

-35- 

Lester Ingber

a global minima statistically can be obtained. I.e.,

gk »

k0

D

1

i=1

2|yi|ci

= ¥

]

1
k

[

k0

.

Control can be taken over ci, such that

T fi = T0i exp(- mi) when k f = exp ni ,

ci = mi exp(- ni/D) ,  

(A.7)

(A.8)

where mi and ni can be considered “free” parameters to help tune ASA for speciﬁc problems.

3.  ASA OPTIONS

ASA has over 100 OPTIONS available for tuning. A few are most relevant to this project.

3.1.  Reannealing

Whenever doing  a  multi-dimensional  search  in  the  course  of  a  complex nonlinear  physical  problem,
inevitably  one  must  deal  with  different  changing  sensitivities  of  the a i in  the  search. At  any giv en

annealing-time,  the  range  over which  the  relatively  insensitive  parameters  are  being  searched  can  be

“stretched  out”  relative  to the  ranges  of  the  more  sensitive  parameters.  This can  be  accomplished  by

periodically  rescaling  the  annealing-time k, essentially  reannealing,  every  hundred  or  so  acceptance-

ev ents (or at some user-deﬁned modulus of the number of accepted or generated states), in terms of the

sensitivities si calculated at the most current minimum value of the cost function, C,

si = ¶ C/¶ a i .

(A.9)

In terms of the largest si = smax, a default rescaling is performed for each ki of each parameter dimension,
whereby a new index k¢ i is calculated from each ki,

ki ﬁ

k¢ i ,

T¢ ik¢ = Tik(smax/si) ,

¥
S
¥
S
P
Statistical Mechanics of Neocortical ...

-36- 

k¢ i = ((ln(Ti0/Tik¢ )/ci))D .

Lester Ingber

(A.10)

Ti0 is set to unity to begin the search, which is ample to span each parameter dimension.

3.2.  Quenching

Another  adaptive  feature  of  ASA  is  its  ability  to  perform  quenching  in  a  methodical  fashion.  This is

applied by noting that the temperature schedule above can be redeﬁned as

Ti(ki) = T0i exp(- ci kQi/D

i

) ,

ci = mi exp(- niQi/D) ,  

in terms of the “quenching factor” Qi. The sampling proof fails if Qi > 1 as

DP

1/kQi/D =

1/kQi < ¥

.

k

k

(A.11)

(A.12)

This simple calculation shows how the “curse of dimensionality” arises, and also gives a possible way of

living  with  this  disease.

In  ASA,  the  inﬂuence  of  large  dimensions  becomes  clearly  focussed  on  the

exponential of the power of k being 1/D, as the annealing required to properly sample the space becomes

prohibitively  slow.  So,  if  resources  cannot  be  committed  to  properly  sample  the  space,  then  for  some

systems perhaps the next best procedure may be to turn on quenching, whereby Qi can become on the

order of the size of number of dimensions.

The scale of the power of 1/D temperature schedule used for the acceptance function can be altered in a

similar fashion.  However, this does not affect the annealing proof of ASA, and so this may used without

damaging the sampling property.

3.3.  Self Optimization

If not much information is known about a particular system, if the ASA defaults do not seem to work very

well, and if after a bit of experimentation it still is not clear how to select values for some of the ASA

OPTIONS, then the SELF_OPTIMIZE OPTIONS can be very useful. This sets up a top level search on

S
S
Statistical Mechanics of Neocortical ...

-37- 

Lester Ingber

the  ASA  OPTIONS  themselves,  using  criteria  of  the  system  as  its  own  cost  function,  e.g.,  the  best

attained optimal value of the system’s cost function (the cost function for the actual problem to be solved)

for  each  given set  of  top  level OPTIONS,  or  the  number  of  generated  states  required  to  reach  a  given

value  of  the  system’s cost  function,  etc. Since  this  can  consume  a  lot  of  CPU  resources,  it  is

recommended that only a few ASA OPTIONS and a scaled down system cost function or system data be

selected for this OPTIONS.

Even if good results are being attained by ASA, SELF_OPTIMIZE can be used to ﬁnd a more efﬁcient set

of  ASA  OPTIONS. Self  optimization  of  such  parameters  can  be  very  useful  for  production  runs  of

complex systems.

3.4.  Parallel Code

It  is  quite  difﬁcult  to  directly  parallelize  an  SA  algorithm [26],  e.g.,  without  incurring  very  restrictive

constraints on temperature schedules [92], or violating an associated sampling proof [93].  However,  the

fat tail  of  ASA  permits  parallelization  of  developing  generated  states  prior  to  subjecting  them  to  the

acceptance test [14].  The ASA_PARALLEL OPTIONS provide parameters to easily parallelize the code,

using various implementations, e.g., PVM, shared memory, etc.

The scale of parallelization afforded by ASA, without violating its sampling proof, is given by a typical

ratio of the number of generated to accepted states. Several experts in parallelization suggest that massive

parallelization  e.g.,  on  the  order  of  the  human  brain,  may  take place  quite  far  into  the  future,  that  this

might be somewhat less useful for many applications than previously thought, and that most useful scales

of parallelization might be on scales of order 10 to 1000. Depending on the speciﬁc problem, such scales

are common in ASA optimization, and the ASA code can implement such parallelization.

ACKNOWLEDGMENTS

Data  was  collected  by  Henri  Begleiter  and  associates  at  the  Neurodynamics  Laboratory  at  the  State

University of New York Health Center at Brooklyn, and prepared by David Chorlian. Calculations were

performed  on  a  Sun  SPARC  20  at  the  University  of  Oregon,  Eugene,  courtesy  of  the  Department  of

Psychology, consuming about 200 CPU-hours.

Statistical Mechanics of Neocortical ...

-38- 

Lester Ingber

REFERENCES

1. 

2. 

L. Ingber, Tow ards a uniﬁed brain theory, J. Social Biol. Struct. 4, 211-224 (1981).

L. Ingber, Statistical  mechanics  of  neocortical  interactions.  I.  Basic  formulation, Physica  D

5, 83-107 (1982).

3. 

L. Ingber, Statistical  mechanics  of  neocortical  interactions.  Dynamics  of  synaptic  modiﬁcation,

Phys. Rev. A 28, 395-416 (1983).

4. 

L. Ingber, Statistical  mechanics  of  neocortical  interactions.  Derivation  of  short-term-memory

capacity, Phys. Rev. A 29, 3346-3358 (1984).

5. 

L. Ingber, Statistical mechanics of neocortical interactions. EEG dispersion relations, IEEE Trans.

Biomed. Eng. 32, 91-94 (1985).

6. 

L. Ingber, Statistical mechanics of neocortical interactions: Stability and duration of the 7– 2 rule of

short-term-memory capacity, Phys. Rev. A 31, 1183-1186 (1985).

7. 

L. Ingber, Tow ards clinical applications of statistical mechanics of neocortical interactions, Innov.

Tech. Biol. Med. 6, 753-758 (1985).

8. 

9. 

L. Ingber, Statistical mechanics of neocortical interactions, Bull. Am. Phys. Soc. 31, 868 (1986).

L. Ingber, Applications  of  biological  intelligence  to  Command,  Control  and  Communications,  in

Computer  Simulation  in  Brain  Science:  Proceedings,  University  of  Copenhagen,  20-22  August

1986, (Edited by R. Cotterill), pp. 513-533, Cambridge University Press, London, (1988).

10.  L. Ingber, Statistical  mechanics  of  mesoscales  in  neocortex and  in  command,  control  and
communications  (C3):  Proceedings,  Sixth  International  Conference,  St.  Louis,  MO,  4-7  August

1987, Mathl. Comput. Modelling 11, 457-463 (1988).

11.  L. Ingber, Mesoscales in neocortex and in command, control and communications (C3) systems, in

Systems  with  Learning  and  Memory  Abilities:  Proceedings,  University  of  Paris  15-19  June  1987,

(Edited by J. Delacour and J.C.S. Levy), pp. 387-409, Elsevier, Amsterdam, (1988).

12.  L. Ingber  and  P.L.  Nunez,  Multiple  scales  of  statistical  physics  of  neocortex:  Application  to

electroencephalography, Mathl. Comput. Modelling 13 (7), 83-95 (1990).

Statistical Mechanics of Neocortical ...

-39- 

Lester Ingber

13.  L. Ingber, Statistical  mechanics  of  neocortical  interactions:  A  scaling  paradigm  applied  to

electroencephalography, Phys. Rev. A 44 (6), 4017-4060 (1991).

14.  L. Ingber, Generic  mesoscopic  neural  networks  based  on  statistical  mechanics  of  neocortical

interactions, Phys. Rev. A 45 (4), R2183-R2186 (1992).

15.  L. Ingber, Statistical  mechanics  of  neocortical  interactions:  Path-integral  evolution  of  short-term

memory, Phys. Rev. E 49 (5B), 4652-4664 (1994).

16.  L. Ingber and P.L. Nunez, Statistical mechanics of neocortical interactions: High resolution path-

integral calculation of short-term memory, Phys. Rev. E 51 (5), 5074-5083 (1995).

17.  L. Ingber, Statistical  mechanics  of  multiple  scales  of  neocortical  interactions,  in Neocortical

Dynamics  and  Human  EEG  Rhythms, (Edited  by  P.L.  Nunez),  pp.  628-681,  Oxford  University

Press, New York, NY, (1995).

18.  L. Ingber, Statistical mechanics of neocortical interactions: Constraints on 40 Hz models of short-

term memory, Phys. Rev. E 52 (4), 4561-4563 (1995).

19.  L. Ingber, Statistical  mechanics  of  neocortical  interactions:  Multiple  scales  of  EEG,  in Fr ontier

Science in EEG: Continuous Waveform Analysis (Electroencephal. clin. Neurophysiol. Suppl. 45),

(Edited by R.M. Dasheiff and D.J. Vincent), pp. 79-112, Elsevier, Amsterdam, (1996).

20.  L. Ingber, Data mining and knowledge discovery via statistical mechanics in nonlinear stochastic

systems, Virtual Physics [http://www.isisnet.com/MAX/vp.html] 15, 1-38 (1997).

21.  L. Ingber, Statistical  mechanics  of  nonlinear  nonequilibrium  ﬁnancial  markets:  Applications  to

optimized trading, Mathl. Computer Modelling 23 (7), 101-121 (1996).

22.  L. Ingber, Canonical momenta indicators of ﬁnancial markets and neocortical EEG, in International

Conference  on  Neural  Information  Processing  (ICONIP’96), pp.  777-784,  Springer, New  York,

(1996).

23.  L. Ingber, Adaptive  Simulated  Annealing  (ASA),  Global  optimization  C-code,  Lester  Ingber

Research, McLean, VA, (1993).

24.  L. Ingber, Very fast simulated re-annealing, Mathl. Comput. Modelling 12 (8), 967-973 (1989).

Statistical Mechanics of Neocortical ...

-40- 

Lester Ingber

25.  L. Ingber  and  B.  Rosen,  Genetic  algorithms  and  very  fast  simulated  reannealing:  A  comparison,

Mathl. Comput. Modelling 16 (11), 87-100 (1992).

26.  L.

Ingber, Simulated  annealing:  Practice  versus 

theory, Mathl.  Comput.  Modelling

18 (11), 29-57 (1993).

27.  L. Ingber, Adaptive  simulated  annealing  (ASA):  Lessons  learned, Control  and  Cybernetics

25 (1), 33-54 (1996).

28.  A. Fuchs,  J.A.S.  Kelso,  and  H.  Haken,  Phase  transitions  in  the  human  brain:  Spatial  mode

dynamics, Int. J. Bifurcation Chaos 2 (4), 917-939 (1992).

29.  V.K. Jirsa, R. Friedrich, H. Haken, and J.A.S. Kelso, A theoretical model of phase transitions in the

human brain, Biol. Cybern. 71, 27-35 (1994).

30.  R. Friedrich and C. Uhl, Synergetic analysis of human electroencephalograms: Petit-mal epilepsy,

in Evolution  of  Dynamical  Structures  in  Complex Systems, (Edited  by  R.  Friedrich  and  A.

Wunderlin), Springer, Berlin, (1992).

31.  R. Friedrich, A. Fuchs, and H. Haken, Spatio-temporal EEG patterns, in Rhythms in Physiological

Systems, (Edited by H. Haken and H.P. Koepchen), Springer, Berlin, (1991).

32.  H.R. Wilson  and  J.D.  Cowan,  A  mathematical  theory  of  the  functional  dynamics  of  cortical  and

thalamic nervous tissue, Kybernetik 13, 55-80 (1973).

33.  W.J. Freeman, Mass Action in the Nervous System, Academic Press, New York, NY, (1975).

34.  A. Van Rotterdam, F.H. Lopes da  Silva, J. van  der  Ende, M.A. Viergever,  and A.J. Hermans, A

model  of 

the  spatial-temporal  characteristics  of 

the  alpha  rhythm, Bull.  Math.  Biol.

44, 283-305 (1982).

35.  W.J. Freeman, Simulation of chaotic EEG patterns with a dynamic model of the olfactory system,

Biol. Cybern. 55, 139-150 (1987).

36.  P.L. Nunez, The brain wav e equation: A model for the EEG, Math. Biosci. 21, 279-297 (1974).

37.  P.L.  Nunez, Electric  Fields  of  the  Brain:  The  Neurophysics  of  EEG, Oxford  University  Press,

London, (1981).

Statistical Mechanics of Neocortical ...

-41- 

Lester Ingber

38.  R.D. Katznelson,  Deterministic  and  Stochastic  Field  Theoretic  Models  in  the  Neurophysics  of

EEG, Ph.D. Thesis, UC San Diego, La Jolla, CA, (1982).

39.  P.L. Nunez, Neocortical Dynamics and Human EEG Rhythms, Oxford University Press, New York,

NY, (1995).

40.  P.L.  Nunez,  Generation  of  human  EEG  rhythms  by  a  combination  of  long  and  short-range

neocortical interactions, Brain Topography 1, 199-215 (1989).

41.  D. Lehmann,  Human  scalp  EEG  ﬁelds:  Evoked,  alpha,  sleep,  and  spike-wav e patterns,  in

Synchronization  of  EEG  Activity  in  Epilepsies, (Edited  by  H.  Petsche  and  M.A.B.  Brazier),  pp.

301-325, Springer-Verlag, New York, NY, (1971).

42. 

J.P. Pijn,  J.  Van  Neerven,  A.  Noest,  and  F.H.  Lopes da  Silva,  Chaos  or  noise  in  EEG  signals:

Dependence on state and brain site, Electroencephal. clin. Neurophysiol. 79, 371-381 (1992).

43.  P.E. Rapp, T.R. Bashore, J.M. Marinerie, A.M. Albano, I.D. Zimmerman, and A.I. Mees, Dynamics

of brain electrical activity, Brain Topography 2, 99-118 (1989).

44.  P.L. Nunez, R.B. Silberstein, P.J. Cadusch, R.S. Wijesinghe, A.F. Westdorp, and R. Srinivasan, A

theoretical and experimental study of high resolution EEG based on surface Laplacians and cortical

imaging, Electroencephal. clin. Neurophysiol. 90, 40-57 (1994).

45.  D. Cohen,  B.N.  Cufﬁn,  K.  Yunokuchi,  R.  Maniewski,  C.  Purcell,  G.R.  Cosgrove, J. Ives,  J.

Kennedy, and  D.  Schomer, MEG  versus  EEG  localization  test  using  implanted  sources  in  the

human brain, Ann. Neurol. 28, 811-817 (1990).

46.  L. Ingber, Editorial: Learning to learn, Explore 7, 5-8 (1972).

47.  L. Ingber, Karate: Kinematics and Dynamics, Unique, Hollywood, CA, (1981).

48.  L. Ingber, Elements of Advanced Karate, Ohara, Burbank, CA, (1985).

49.  G.A. Miller, The magical number seven, plus or minus two, Psychol. Rev. 63, 81-97 (1956).

50.  K.A. Ericsson and W.G. Chase, Exceptional memory, Am. Sci. 70, 607-615 (1982).

51.  H. Eichenbaum, Thinking about brain cell assemblies, Science 261, 993-994 (1993).

Statistical Mechanics of Neocortical ...

-42- 

Lester Ingber

52.  G. Zhang and H.A. Simon, STM capacity for Chinese words and idioms: Chunking and acoustical

loop hypotheses, Memory & Cognition 13, 193-201 (1985).

53.  B.B. Murdock,  Jr.,  A  distributed  memory  model  for  serial-order  information, Psychol.  Rev.

90, 316-338 (1983).

54. 

J.E. Lisman  and  M.A.P. Idiart,  Storage  of  7 – 2 short-term  memories  in  oscillatory  subcycles,

Science 267 (5203), 1512-1515 (1995).

55.  R.N. Silberstein, Neuromodulation of neocortical dynamics, in Neocortical Dynamics and Human

EEG  Rhythms, (Edited  by  P.L.  Nunez),  pp.  628-681,  Oxford  University  Press,  New York,  NY,

(1995).

56.  M.F. Wehner  and  W.G.  Wolfer, Numerical  evaluation  of  path-integral  solutions  to  Fokker-Planck

equations. I., Phys. Rev. A 27, 2663-2670 (1983).

57.  M.F. Wehner  and  W.G.  Wolfer, Numerical  evaluation  of  path-integral  solutions  to  Fokker-Planck

equations. II. Restricted stochastic processes, Phys. Rev. A 28, 3003-3011 (1983).

58.  M.F. Wehner  and  W.G.  Wolfer, Numerical  evaluation  of  path  integral  solutions  to  Fokker-Planck

equations. III. Time and functionally dependent coefﬁcients, Phys. Rev. A 35, 1795-1801 (1987).

59.  L. Ingber, H. Fujio,  and  M.F. Wehner, Mathematical  comparison  of  combat  computer  models  to

exercise data, Mathl. Comput. Modelling 15 (1), 65-90 (1991).

60.  R. Pool, Is it chaos, or is it just noise?, Science 243, 25-28 (1989).

61.  H.D.I. Abarbanel, R. Brown, J.J. Sidorowich, and L.Sh. Tsimring, The analysis of observed chaotic

data in physical systems, Rev. Mod. Phys. 65 (4), 1331-1392 (1993).

62.  P. Grassberger, Do climatic attractors exist?, Nature 323, 609-612 (1986).

63.  L. Ingber, R. Srinivasan,  and  P.L.  Nunez,  Path-integral  evolution  of  chaos  embedded  in  noise:

Dufﬁng neocortical analog, Mathl. Computer Modelling 23 (3), 43-53 (1996).

64.  L. Ingber, Mathematical  comparison  of  computer  models  to  exercise  data,  in 1989  JDL  C2

Symposium: National Defense University, Washington, DC, 27-29 June 1989, pp. 169-192, SAIC,

McLean, VA, (1989).

Statistical Mechanics of Neocortical ...

-43- 

Lester Ingber

65.  L. Ingber, Mathematical comparison of JANUS(T) simulation to National Training Center, in The

Science of Command and Control: Part II, Coping With Complexity, (Edited by S.E. Johnson and

A.H. Levis), pp. 165-176, AFCEA International, Washington, DC, (1989).

66.  L. Ingber and D.D. Sworder, Statistical mechanics of combat with human factors, Mathl. Comput.

Modelling 15 (11), 99-127 (1991).

67.  L. Ingber, Statistical  mechanics  of  combat  and  extensions,  in Toward a Science  of  Command,

Control,  and  Communications,

(Edited  by  C.  Jones),  pp.  117-149,  American  Institute  of

Aeronautics and Astronautics, Washington, D.C., (1993).

68.  M. Bowman and L. Ingber, Canonical momenta of nonlinear combat, in Proceedings of the 1997

Simulation Multi-Conference, 6-10 April 1997, Atlanta, GA, Society for Computer Simulation, San

Diego, CA, (1997).

69.  L. Ingber, Statistical  mechanics  of  nonlinear  nonequilibrium  ﬁnancial  markets, Math.  Modelling

5 (6), 343-361 (1984).

70.  L.

Ingber, Statistical  mechanical  aids  to  calculating  term  structure  models, Phys.  Rev.  A

42 (12), 7057-7064 (1990).

71.  L. Ingber, M.F. Wehner, G.M.  Jabbour, and  T.M.  Barnhill,  Application  of  statistical  mechanics

methodology 

to 

term-structure 

bond-pricing  models, Mathl.  Comput.  Modelling

15 (11), 77-98 (1991).

72.  H. Haken, Synergetics, Springer, New York, (1983).

73.  R. Graham, Path-integral methods on nonequilibrium thermodynamics and statistics, in Stochastic

Processes  in  Nonequilibrium  Systems, (Edited  by  L.  Garrido,  P. Seglar, and  P.J.  Shepherd),  pp.

82-138, Springer, New York, NY, (1978).

74.  H. Haken, Information  and  Self-Organization:  A  Macroscopic  Approach to Complex Systems,

Springer, Berlin, (1988).

75.  F. Langouche,  D.  Roekaerts,  and  E.  Tirapegui, Functional  Integration  and  Semiclassical

Expansions, Reidel, Dordrecht, The Netherlands, (1982).

Statistical Mechanics of Neocortical ...

-44- 

Lester Ingber

76.  R. Graham, D. Roekaerts, and T. Te´l, Integrability of Hamiltonians associated with Fokker-Planck

equations, Phys. Rev. A 31, 3364-3375 (1985).

77.  L. Ingber, Statistical mechanical measures of performance of combat, in Proceedings of the 1991

Summer Computer Simulation Conference 22-24 July 1991, Baltimore,  MD, (Edited by D. Pace),

pp. 940-945, Society for Computer Simulation, San Diego, CA, (1991).

78.  V.B.  Mountcastle,  R.A.  Andersen,  and  B.C.  Motter, The  inﬂuence  of  attentive  ﬁxation  upon  the

excitability  of 

the 

light-sensitive  neurons  of 

the  posterior  parietal  cortex, J.  Neurosci.

1, 1218-1235 (1981).

79.  P.L. Nunez, Localization of brain activity with Electroencephalography,  in Advances in Neurology,

Vol.  54:  Magnetoencephalography, (Edited  by  S.  Sato),  pp.  39-65,  Raven Press,  New York,  NY,

(1990).

80.  W. Gersch,  Non-stationary  multichannel  time  series  analysis,  in Methods  of  Brain  Electrical  and

Magnetic Signals. EEG Handbook, (Edited by A.S. Gevins and A. Remond), pp. 261-296, Elsevier,

New York, NY, (1987).

81.  N.J.I. Mars  and  F.H.  Lopes da  Silva,  EEG  analysis  methods  based  on  information  theory, in

Methods of Brain Electrical and Magnetic Signals. EEG Handbook, (Edited by A.S. Gevins and A.

Remond), pp. 297-307, Elsevier, New York, NY, (1987).

82.  K.J. Friston, G. Tononi, O. Sporns, and G.M. Edelman, Characterising the complexity of neuronal

interactions, Human Brain Mapping 3 (302), 302-314 (1995).

83.  W. Wang, H. Begleiter, and B. Porjesz, Surface energy, its density and distance: New measures with

application to human cerebral potentials, Brain Topography 6 (3), 193-202 (1994).

84.  X.L. Zhang, H. Begleiter, B. Porjesz, W. Wang, and A. Litke, Event related potentials during object

recognition tasks, Brain Res. Bull. 38 (6), 531-538 (1995).

85.  D.F. Shanno  and  K.H.  Phua,  Minimization  of  unconstrained  multivariate  functions, ACM Trans.

Mathl. Software 2, 87-94 (1976).

86. 

J.J. Wright  and  D.T.J.  Liley,  Dynamics  of  the  brain  at  global  and  microscopic  scales:  Neural

networks and the EEG, Behavioral and Brain Sci. 19 (2), 285-295 (1996).

Statistical Mechanics of Neocortical ...

-45- 

Lester Ingber

87.  M. Jammer, The Philosophy of Quantum Mechanics, Wiley & Sons, New York, NY, (1974).

88.  S. Kirkpatrick,  C.D.  Gelatt,  Jr.,  and  M.P. Vecchi,  Optimization  by  simulated  annealing, Science

220 (4598), 671-680 (1983).

89.  S. Geman and D. Geman, Stochastic relaxation, Gibbs distribution and the Bayesian restoration in

images, IEEE Trans. Patt. Anal. Mac. Int. 6 (6), 721-741 (1984).

90.  H. Szu and R. Hartley, Fast simulated annealing, Phys. Lett. A 122 (3-4), 157-162 (1987).

91.  M. Wofsey,  Technology: Shortcut tests validity of complicated formulas, The Wall Street Journal

222 (60), B1 (1993).

92.  K. Kimura and K. Taki, Time-homogeneous parallel annealing algorithm, Report TR-673, Institute

for New Generation Computer Technology, Tokyo, Japan, (1991).

93.  R. Frost,  Ensemble  Based  Simulated  Annealing  (EBSA),  ftp.sdsc.edu:/pub/sdsc/math/Ebsa,

University of California San Diego, La Jolla, CA, (1993).

