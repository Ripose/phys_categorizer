 

 

 
 

 

Martingales, Detrending Data, and the Efficient 
Market Hypothesis  

Joseph L. McCauley+, Kevin E. Bassler++, and Gemunu H. 
Gunaratne+++  
 
Physics Department 
University of Houston 
Houston, Tx. 77204-5005 
jmccauley@uh.edu 
 
+Senior Fellow 
COBERA 
Department of Economics 
J.E.Cairnes Graduate School of Business and Public Policy 
NUI Galway, Ireland 

++Texas Center for Superconductivity 
University of Houston 
Houston, Texas 77204-5005 
 
+++Institute of Fundamental Studies 
Kandy, Sri Lanka 

Key Words: Martingales, Markov processes, detrending, 
long time memory, stationary and nonstationary increments, 
correlations, efficient market hypothesis. 
 

Abstract 
 
We  discuss  martingales,  detrending  data,  and  the  efficient 
market hypothesis for stochastic processes x(t) with arbitrary 
diffusion  coefficients  D(x,t).  Beginning  with  x-independent 
drift  coefficients  R(t)  we  show  that  Martingale  stochastic 

to 

(EMH) 

include 

processes  generate  uncorrelated,  generally  nonstationary 
increments.  Generally,  a  test  for  a  martingale  is  therefore  a 
test  for  uncorrelated  increments.  A  detrended  process  with 
an  x-  dependent  drift  coefficient 
is  generally  not  a 
martingale,  and  so  we  extend  our  analysis  to  include  the 
class  of  (x,t)-dependent  drift  coefficients  of  interest  in 
finance. We explain why martingales look Markovian at the 
level  of  both  simple  averages  and  2-point  correlations.  And 
while  a  Markovian  market  has  no  memory  to  exploit  and 
presumably  cannot  be  beaten  systematically,  it  has  never 
been shown that martingale memory cannot be exploited in 
3-point  or  higher  correlations  to  beat  the  market.  We 
generalize  our  Markov  scaling  solutions  presented  earlier, 
and  also  generalize  the  martingale  formulation  of  the 
(x,t)-
efficient  market  hypothesis 
dependent  drift  in  log  returns.  We  also  use  the  analysis  of 
this  paper  to  correct  a  misstatement  of  the  ‘fair  game’ 
condition  in  terms  of  serial  correlations  in  Fama’s  paper  on 
the EMH. 
 
 
1. Introduction 
 
Recently  [1]  we  focused  on  the  condition  for  long  time 
correlations,  which  is  stationarity  of  the  increments  in  a 
stochastic  process  x(t)  with  variance  nonlinear  in  the  time, 
and derived the 2-point, 1-point and transition rate densities 
for  fractional  Brownian  motion  (fBm).  Time  series  with 
stationary  increments  (like  fBm)  exhibit  long  time  memory 
that  can  be  seen  at  the  level  of  increment  autocorrelations. 
We  emphasized  that  neither  1-point  averages  nor  Hurst 
exponents can be used to identify the presence or absence of 
history-dependence  in  a  time  series,  or  to  identify  the 
underlying stochastic process (see [2] for the conclusion that 
an equation of motion for a 1-point density cannot be used to 
decide if a process is Markovian or not). In the same paper, 

generate 

coefficients 

uncorrelated, 

we  pointed  out  that  the  opposite  class,  systems  with  no 
memory  at  all  (Markov  processes)  and  with  x-independent 
typically 
drift 
nonstationary  increments.  The  conclusions  in  [1]  about 
Markov  processes  are  more  general  than  we  realized  at  the 
time.  Here,  we  generalize  that  work  by  focusing  on 
martingales.  
 
 In  applications  to  finance,  x(t)=ln(p(t)/pc)  where  pc  is  a 
reference  price,  the  consensus  price  or  ‘value’  [3].  The 
consensus  price  pc  is  simply  the  price  that  determines  the 
peak  of  the  1-point  returns  density  f1(x,t).  The  reason  why 
log  increments  x(t;T)=lnp(t+T)/p(t)  and  price  differences 
Δp=p(t+T)-p(t) generally cannot be taken as ‘good’ variables 
describing  a  stochastic  process  (either  theoretically  and  in 
data  analysis)  is  explained  below,  especially  in  part  4:  it  is 
impossible  for  a  martingale,  excepting  the  special  case  of  a 
variance  linear  in  the  time  t,  to  develop  either  stochastic 
dynamics or probability theory based on increments x(t;T) or 
Δp,  because  if  the  increments  are  nonstationary,  as  they 
generally  are, 
t  matters  and 
the  starting 
consequently  histograms  derived  empirically  from  time 
series assuming that the starting time doesn’t matter exhibit 
‘significant  artifacts’  like  fat  tails  and  spurious  Hurst 
exponents  [3,4].  In  contrast,  in  a  system  with  long  time 
increment 
autocorrelations 
x(t;T)=x(t+T)-x(t)=x(T),  ‘in  distribution’,  is  a  perfectly  good 
variable.  But  the  efficient  market  hypothesis,  and  real 
time 
markets  as  well 
autocorrelations. 
 
Next, we define the required underlying ideas. 
 
 
 
 

the  stationary 

rules  out 

fBm), 

such 

time 

long 

then 

(like 

[4], 

e.g. 

correlations, 

2. Conditional expectations with memory 
 
Imagine a collection of time series generated by an unknown 
stochastic  process  that  we  would  like  to  discover  via  data 
analysis.  Simple  averages  require  only  a  1-point  density 
f1(x,t), e.g., <xn(t)>=∫xnf1(x,t)dx. No dynamical process can be 
identified by specifying merely either the 1-point density or 
a scaling exponent [1]. Both conditioned and unconditioned 
<x(t)x(t+T)>=∫dydxyx 
two-point 
f2(y,t+T;x,t), require a two point density f2(y,t+T;x,t) for their 
description  and  provide  us  with  limited  information  about 
the class of dynamics under consideration.  
 
Consider  a  collection  of  time  series  representing  repeated 
runs  of  a  single  stochastic  process  x(t).  Empirically,  we  can 
only strobe the system finitely many times, so measurements 
of  x(t)  take  the  form  of  {x(tk)},  k=1,…,n  where  n  is  the 
number  of  measurements/observations  made  in  one  run. 
Many repeated runs are required in order to get histograms 
reflecting the statistics of the process. If we can extract good 
enough histograms from the collection of time series (if there 
are many runs, and if each run contains enough points), then 
we  can  then  try  to  extract  the  hierarchy  of  probability 
densities  f1(x,t),  f2(x2,t2;x1,t1),  …,  fk(xk,tk;…,x1,t1)  where  k<<n 
(where  f1  implicitly  reflects  a  specific  choice  of  initial 
condition in data analysis). To get adequate histograms for fn 
one  would  then  need  a  much  longer  time  series.  If  the 
memory in the process is discrete in size, then the minimum 
n  number  of  densities  that  one  needs  in  the  hierarchy 
depends  on  the  length  N  of  the  memory  sequence  in  the 
system  (for  a  Markov  process,  N=2).  In  what  follows 
fn(xn,tn;…;x1,t1)  denotes  the  probability  density  for  the 
sequence  (xn,…,x1)  at  observation  times  (tn,…,t1),  where  we 
generally take t1<…<tn.  
 

Conditional  probability  densities  pk,  or  transition  rate 
probability densities can then be defined as [5,6]: 
 
 
 

,  (1) 

, 
(2) 
 
and more generally as 
 

,  (3) 
 
where  pn  is  the  conditional  probability  density  to  find  xn  at 
time  tn,  given  the  specific  history  of  previous  observations 
(xn-1,tn-1;…;x1,t1).  The  terms  (xn-1,tn-1;…;x1,t1)  in  pn  represent 
memory of the past. When memory is present in the system 
then  one  cannot  use  the  2-point  transition  density  p2  to 
describe  the  complete  time  evolution  of  the  dynamical 
system that generates x(t).  
 
In a Markov process the picture is much simpler. A Markov 
process  [5,6]  has  no  memory  aside  from  the  last  observed 
point in the time series. In this case one loosely says that the 
system has no memory. There, we have 
 

, 

(4) 
 
because all transition rates pn, n>2, are built up as products 
of p2, 
 
 
(5) 

, 

  ! f2(x1,t1;x1,t1)=p2(x2,t2x1,t1)f1(x1,t1)  ! f3(x3,t3;x2,t2;x1,t1)=p3(x3,t3x2,t2,x1,t1)p2(x2,t2x1,t1)f1(x1,t1)  ! fn(xn,tn;...;x1,t1)=pn(xn,tnxn"1,tn"1;...x1,t1)...p2(x2,t2x1,t1)f1(x1,t1)  ! fn(xn,tn;...;x1,t1)=p2(xn,tnxn"1,tn"1)...p2(x2,t2x1,t1)f1(x1,t1)  ! pk(xk,tkxk"1,tk"1;...;x1,t1)=p2(xk,tkxk"1,tk"1) 
for  k=3,4,  ….  .Only  in  the  absence  of  memory  does  the  2-
point density p2 describe the complete time evolution of the 
dynamical  system.  E.g.,  we  can  prove  that  for  an  arbitrary 
process with or without memory 
 
 

 

, 

(6) 
 
and therefore that 
 
 
(7) 
 
whereas  the  Master  Equation  for  a  Markov  process  follows  
from pn=p2 for n=2,3,…, so that 
 
 
 
via  (7).  The  Markov  property  is  expressed  by  pn=p2  for  all 
n≥3,  the  complete  lack  of  memory  excepting  the  last 
observed point. The  Master  Equation (8) is  a necessary but not 
sufficient condition for a Markov process [7,8].  
 
A Markov process defines a 1-parameter semi-group U(t) of 
transformations  with  time  t  as  additive  group  parameter  (a 
one  parameter  group  expresses  path  independence,  or  lack 
of  memory).  The  semi-group  combination  law  is  given  by 
the Master Equation (8), which trivially can be used to prove 
law. 
associativity 
Associativity  expresses  path  independence  of  any  sequence 
transformations. The identity element is defined by the equal 
times transition rate density 
 

combination 

semi-group 

the 

(8) 

of 

 

  ! pk"1(xk,tkxk"2,tk"2;...;x1,t1)=dxk"1pk(xk,tkxk"1,tk"1;...;x1,t1)#pk"1(xk"1,tk"1xk"2,tk"2;...;x1,t1)  ! p2(x3,t3x1,t1)=dx2p3(x3,t3x2,t2;x1,t1)"p2(x2,t2x1,t1)  ! p2(x3,t3x1,t1)=dx2p2(x3,t3x2,t2)"p2(x2,t2x1,t1) 

 

.  

(9) 

 
 
Processes  with  memory  generally  do  not  admit  a  one 
parameter  semi-group  of  time  translations  (fBm  is  an 
example,  fBm  has  no  description  via  an  Ito  stochastic 
differential  equation).  Instead,  the  class  of  path-dependent 
time evolutions is defined by the entire hierarchy eqns. (3,6), 
for  n=2,3,4,…  .  The  Master  Equation  (8)  combined  with 
differentiability implies time evolution defined locally by an 
infinitesimal generator. For an Ito process without memory, 
the  infinitesimal  generator  of  the  semi-group  is  the  Fokker-
Planck  operator  [9],  from  which  we  obtain  the  pde  for  the 
transition  density.  We  expect  that  the  interesting  question 
for finance in the future will be the construction of models of 
dynamics  of  nonMarkovian  Ito  processes  with  memory 
encoded in the diffusion coefficient. 
 
Memory-dependent  processes  in  statistical  physics  have 
been  discussed  by  Hänggi  and  Thomas1  [10].  Memory 
cannot show up in a 1-point density [1], but as they point out 
the two-point tranition densities  
 

 

(10) 
 
are functionals of the initial state f1(x1,t1) in which the system 
was  prepared  at  the  initial  time  t1,  unless  the  system  is 
Markovian.  In  a  nonMarkov  system  one  can  superficially 
hide  this  dependence  on  state  preparation  by  choosing  the 
initial  condition  to  be  f1(x1,t1)=δ(x1)  (that  initial  condition  is 

                                          

1  It’s  assumed  without  proof  in  [10]  that  a  two  point  transition  density  for  a  system  with  memory  can 
always be used to define a generator and an equivalent Markov process,  but this is impossible for systems 
with  increment  autocorrelations  like  fBm.  In  the  1970s  fBm  was  largely  unknown  in  physics,  so  ‘memory’ 
was  associated  with  Mori-Zwanzig  processes,  meaning  a  Martingale  plus  a  memory-dependent  drift  term 
[2,10].  

  ! p2(y,tx,t)="(y#x)  ! p2(x3,t3x2,t2)=dx1p3(x3,t3x2,t2;x1,t1)p2(x2,t2x1,t1)f1(x1,t1)dx1"p2(x2,t2x1,t1)f1(x1,t1)dx1"If, 

[1]). 

inherent  in  the  standard  definition  of  fBm  with  initial  time 
t1=-∞ 
instead,  we  would  or  could  choose   
f1(x1,t1)=δ(x1-x’o)  at  t1=0,  e.g.,  then  we  obtain  p2(x3,t3;x2,t2)= 
p3(x3,t3;x2,t2,xo’), introducing a dependence on xo’ in both the 
drift and diffusion coefficients. So in this case, what appears 
superficially as p2 is really a special case of p3.  The authors 
of  [10]  point  out  that  the  origin  of  memory  in  statistical 
physics  is  often  a  consequence  of  averaging  over  other, 
slowly  changing,  variables.  We  will  return  to  this  point  in 
the section below on the efficient market hypothesis.  
 
Systems  with  memory  lack  translational  invariance  in  x 
and/or  time  t.  But  there  are  drift-free  Markov  systems  that 
lack  translational  invariance  in  both  x  and  t  because  of 
nonstationary  increments  arising  from  an  (x,t)  dependent 
diffusion  coefficient  [1].  Next,  we  exhibit  a  more  general 
class  of  Markov  systems  that  break  both  ‘space  and  time’ 
translational  invariance  than  those  with  Hurst  exponent 
scaling  of  the  1-point  density  f1(x,t)  and  the  diffusion 
coefficient  D(x,t)  discussed  earlier  in  ref.  [1,9].  In  general, 
scaling  of  the  1-point  density  f1  does  not  yield  scaling  of 
either  fn  or  pn  for  n≥2  (see  ref.  [1,9]  for  examples,  both 
nonMarkovian and Markovian). 
 
A  class  of  Markov  scaling  solutions  that  may  prove 
piecewise useful in data analysis, with scaling more general 
than Hurst exponent scaling [1,3,9], is given as follows: let  
 
 
 
with  initial  condition  f1(x,0)=δ(x),  where  u=x/σ1(t),  with 
variance 
 
 
 

(11) 

(12) 

   

. 

 

 

  ! f1(x,t)="1#1(t)F(u)  ! "2(t)=x2(t)="12(t)x2(1) 

 Then with the diffusion coefficient scaling as 
 
 
 
where  dσ1/dt>0  is  required,  f1(x,t)  satisfies  the  Fokker-
Planck pde 
 
 

(13) 

 

 

   

(14) 

 

 

 

 

 

 

 
and yields the scale invariant part of the solution 
 

.  

(15) 

 
 
An  example  is  given  by  Hurst  exponent  scaling  σ1(t)=tH, 
0<H<1.  A  piecewise  constant  drift  R(t)  can  be  included  in 
our result by replacing x by x-∫R(s)ds in u [1,9].  
 
The  Green  function  g(x,t;xo,to)  of  (14)  for  an  arbitrary  initial 
condition (xo,to)≠(0,0) does not scale [9], but then the 2-point 
transition density p2(x2,t2; x1,t1) for fBm does not scale either, 
reflecting  as  it  does  an  arbitrary  point  in  a  time  series 
(x1,t1)≠(xo,to)=(0,-∞).  In  all  cases  scaling,  when  it  occurs,  can 
only  be  seen  in  the  special  choice  of  conditional  density 
f1(x,t)=p2(x,t;0,to)  with  to=0  for  a  Markov  process,  and  to=-∞ 
for fBm. 
 
The same 1-point density f1(x,t) may describe nonMarkovian 
processes  independently  of  eqns.  (10,11)  because  a  1-point 
density  taken  alone,  without  the  information  provided  by 
the  dynamics  (10,11),  defines  no  specific  stochastic  process 
and  may  be  generated  by  many  different  completely 
unrelated  processses,  including  systems  with  long  time 

  ! D(x,t)=(d"12/dt)D (u)  ! "f1"t=12"2(Df1)"x2  ! F(u)=CD (u)e"udu/D (u)#increment autocorrelations like fBm [1]. We will show below 
that a 2-point density delineates fBM from a martingale, but 
pair  correlations,  which  require  only  a  2-point  density  for 
their  description, cannot be used to distinguish an arbitrary 
martingale from a drift-free Markov process. 
 
Finally, note also that 
 

 

(16) 

 

.  (17) 

 
so that 
 
 
 
 
3. Absence of trend and martingales  
 
By a trend, we  mean that d<x(t)>/dt≠0, conversely, by lack 
of  trend  we  mean  that  d<x(t)>/dt=0.  If  a  stochastic  process 
can  be  detrended,  then  d<x>/dt=0  is  possible  via  a 
transformation  of  variables  but  one  must  generally  specify 
which average is used. If the drift coefficient R(x,t) depends 
on  x,  then  detrending  with  respect  to  a  specific  average 
generally  will  not  produce  a  detrended  series  if  a  different 
average 
is  then  used  (e.g.,  one  can  choose  different 
conditional  averages,  or  an  absolute  average).  To  push  this 
problem under the rug until the end of the paper, we restrict 
in what follows to processes that can be detrended once and 
for  all  be  a  simple  subtraction.  I.e.,  we  assume  for  the  time 
being  a  trivial  drift  coefficient  but  allow  for  nontrivial 
diffusion coefficients. 
 

  ! fn"1(xn"1,tn"1;...;x1,t1)=dxnfn(xn,tn;...;x1,t1)#=dxnpn(xn,tnxn"1,tn"1;...;x1,t1)#fn"1(xn"1,tn"1;...;x1,t1)  ! dxnpn(xn,tnxn"1,tn"1;...;x1,t1)#=1A  trivial  drift  coefficient  R(t)  is  a  function  of  time  alone.  A 
nontrivial drift coefficient R(x,t) depends on x, on (x,t), or on 
(x,t) plus memory {x}, and is defined for Ito processes by 
 

  

(18)   

 
as  T  vanishes,  where  {x}  denotes  the  history  dependence  in 
pn,  e.g.  with  y=xn  and  x=xn-1 
(xn,tn;xn-1,tn-1,xn-2,tn-2,…,x1,t1)  with  y=xn  and  x=xn-1.  If  R(x,t)=0 
then  
 

(y,t+T,x,t;{x})  denotes          

 

 

 

, 

(19) 

in 

the 

the 

time 

is  essentially 

last  observed  point 

 
so that the conditional average over x at a later time is given 
series, 
by 
<x(t+T)>cond=x(t). This is the notion of a fair game: there is no 
systematic  change  in  x  on  the  average  as  t  increases, 
d<x(t)>cond/dt=0. The process x(t) is generally nonstationary, 
and  the  condition  (19)  is  called  a  local  martingale  [11].  The 
possibility  of  vanishing  trend,  d<x>/dt=0,  implies  a  local 
martingale x(t), and vice-versa.   
 
This 
the  Martingale 
Representation  Theorem  [12],  which  states  that  an  arbitrary 
martingale  can  be  built  up  from  a  Wiener  process  B(t),  the 
most  fundamental  martingale,  via  stochastic  integration  ala 
Ito, 
 
 
 
 
There  is  no  drift  term  in  (20),  in  the  stochastic  differential 
equation (sde) 
 

the  content  of 

(20) 

.  

!   ! R(x,t,{x})"1Tdy#$$%(y#x)pn(y,t+T;x,t,{x})  ! dy"##$ypn(y,t+T;x,t,{x})=x  ! x(t)=b(x(s),s;{x})dB(s)" 
 
the diffusion coefficient, 
 

  (21) 

 

 

(22) 

 
as T vanishes, is given by D=b2. In a Markov system the drift 
and  diffusion  coefficients  depend  on  (x,t)  alone,  have  no 
history  dependence.  Ito  calculus  based  on  martingales  has 
been  developed  systematically  by  Durrett,  including  the 
derivation  of  Girsanov’s  Theorem  for  arbitrary  diffusion 
coefficients  D(x,t)  [11].  Many  discussions  of  Girsanov’s 
Theorem  [12,13]  implicitly  rule  out  the  general  case  (19) 
where D(x,t) may depend on x as well as t. In this paper we 
do not appeal to Girsanov’s theorem because the emphasis is 
on  application  to  data  analysis,  to  detecting  martingales  in 
empirical  data.  A  new  and  simplified  proof  of  Girsanov’s 
theorem for  arbitrary  diffusion coefficients D(x,t;{x})  will be 
presented elsewhere [14]. 
 
If  the  drift  vanishes,  d<x>/dt=0,  then  simple  averages  like 
moments  <xn(t)>    are  unbiased  and  reflect  the  expectations 
of  a  fair  game.  But  there  are  stochastic  processes  that  are 
inherently biased, where there is no drift to subtract. In that case, 
and  fBm  is  an  example  [1],  d<x>/dt≠0  but  there  is  no  drift 
coefficient:  the  time  dependence  arises  instead  from  long  time 
correlations.  In  fBm  with  R(x,t)=0  one  obtains  as  conditional 
average [1]  
 
 
 
(19).  Here, 
instead 
is 
d<x>/dt=xdC/dt≠0  because 
proportional to the autocorrelation function <x(s)x(t)> where 
long  time 
the  stationarity  of 

increments  guaranteeing 

the  martingale 

factor  C(t,s)≠1 

condition 

(23) 

the 

of 

  

  ! dx(t)=b(x(t),t;{x})dB(t)  ! D(x,t,{x})"1Tdy(y#x)2pn(y,tx,t#T,{x})$  ! x(t)cond=dyyp2(x,sx,t)=C(t,s)x"in  [1].  Such  processes  cannot  be 
memory  was  built 
‘detrended’ (R(x,t)=0 by construction in fBm [1,15]) because 
what  appears  locally  to  be  a  trend  in  the  process  is  simply 
the strongly correlated behavior of the entire time series.  
 
Note  next  that  subtracting  an  average  drift  ∫<R>dt  from  a 
process  x(t)  defined  by  x-dependent  drift  term  plus  a 
Martingale, 
 

, 

(24) 

 
does  not  produce  a  martingale  (this  is  discussed  further  in 
the last section below). Here, if we replace x(t) by x(t)-∫<R>dt 
where  the  average  drift  term  defined  conditionally  from 
some initial condition (x1,t1),  
 
 
 
depends  on  t  alone  we  do  not  get  drift  free  motion,  and 
choosing  absolute  or  other  averages  of  R  will  not  change 
this. In financial analysis, e.g., <R> may represent an average 
from  the  opening  return  x1  at  opening  time  t1  up  to  some 
arbitrary intraday return x at time t. The subtraction yields 
 

(25) 

 

 

 

(26) 
 
and  is  not  a  martingale  unless  R  is  independent  of  x:  we 
obtain  <x(t)>c=x  iff.  x=xo.  The  general  problem  of  an  (x,t) 
dependent  drift  R(x,t)  in  financial  applications  will  be 
discussed in the last section of this paper.  
 
Again, in what follows we assume a trivial drift R(t) that  has 
been subtracted, so that by x(t) we really mean x(t)-∫R(t)dt.  

  ! x(t)=x(t"T)+R(x(s),s;{x})ds+b(x(s),s;{x}dB(s)#t"Tt#  ! R=dxR(x,t)p2"(x,tx1,t1)  ! x(t)=x(t"T)+R(x(s),s;{x})ds"Rt"Tt#ds+b(x(s),s;{x}dB(s)#t"Tt# 

 

, 

(27) 

 
So we can divide stochastic processes into those that satisfy 
the martingale condition 
 
 
 
where  <..>cond  denotes  the  conditional  average  (19),  and 
those  that  do  not.  Those  that  do  not  satisfy  (19)  can  be 
classified  further  into  processes  that  consist  of  a  nontrivial 
(i.e.,  (x,t)-dependent)  drift  plus  a  martingale  (20),  and  those 
like fBm that are not defined by an underlying martingale.  
 
Summarizing  the  idea  of  a  martingale,  given  any  set  of  n 
points in a time series, {x(tk)}, k=1,…,n, where tn>tn-1>…>t2>t1 
and  the  hierarchy  of  transition  densities  pn,  the  idea  of  a 
Martingale  is  that  the  best  systematic  forecast  of  the  future 
[16]  is  the  conditional  average  <x(tk)>cond=  x(tk-1).  I.e.,  our 
expectation of the future is determined by the last observed 
point in the time series,  
 
 

 

,  (28) 

 

 

 
all  previous  observations  (xn-1,…,x1)  don’t  contribute.  This 
feature makes a martingale as near as possible to a drift-free 
Markov  process  without  eliminating  the  possibility  of 
memory. The conditions that must be satisfied in order that 
a  martingale  follows  are  derived  in  the  next  section.  The 
point here is that at the level of simple averages the history 
dependence  cannot  be  detected.  We  will  show  in  the  next 
section  that  the  history  dependence  also  cannot  appear  in 
pair correlations, making any history in a martingale hard to 
detect  empirically.  We  understand  the  condition  for  a  local 
martingale (19) as the condition that bias-free motion occurs. 
 

  ! x(t)cond=x(to)  ! xn"pn(xn,tnxn#1,tn#1,...,x1,t1)dxn=xn#1The  simplest,  best  known  example  of  a  martingale  is  a 
Markov process where there is no memory at all, i.e., where 
R  and  D  depend  on  (x,t)  alone  completely  independent  of 
any  and  all  history  simply  because  (see  eqn.  (22)  above) 
p2(y,s;x,t)  depends  on  the  one,  single  past  state  (x,t)  alone, 
and on no other earlier states.  
 
 
4. Stationary vs. nonstationary increments 
 
In  this  section  we  generalize  an  argument  in  [1]  that 
assumed  Markov  processes  with  trivially  removable  drift 
R(t).  In  fact,  that  argument  applies  to  nonMarkovian 
martingales. In the analysis that follows, we assume a drift-
free  nonstationary  process  x(t)  with  the  initial  condition 
x(to)=0, so that the  variance is given by σ2=<x2(t)>=∫x2f1(x,t). 
By the increments of the process we mean x(t;T) = x(t+T)-x(t) 
and x(t;-T)=x(t)-x(t-T). 
 
Stationary increments are defined by 
 
 
 
‘in  distribution’,  and  by  nonstationary  increments  [1,3,4,5] 
we mean that 
 
 
 
in  distribution.  When  (29)  holds,  then  given  the  density  of 
density 
‘positions’ 
f1(x(T),T)=f1(x(t+T)-x(t),T)  of 
the 
increments  are  nonstationary  then  any  analysis  of  the 
increments 
two-point  density, 
f2(x(t+T),t+T;x(t),t).  From  the  standpoint  of  theory  there 
exists  no  1-point  density  of  increments  f(x;T),T)  depending 
independent  of  t,  and  spurious  1-point 
on  T  alone 

increments.  Whenever 

inherently  requires 

f1(x,t),  we 

know 

also 

(30) 

(29) 

the 

the 

. 

, 

 

 

 

 

  ! x(t+T)"x(t)=x(T)  ! x(t+T)"x(t)#x(T)typically 

increments  are 

constructed 
histograms  of 
empirically  by  assuming  that  the  converse  is  possible  [4]. 
Next,  we  place  an  important  restriction  on  the  class  of 
stochastic processes under consideration. 
 
According to Mandelbrot, so-called ‘efficient market’ has no 
memory  that  can  be  easily  exploited  in  trading  [16].  From 
this 
idea  we  obtain  the  necessary  but  not  sufficient 
condition, the absence of increment autocorrelations, 
 

, 

(31) 

 

 

 

the 

that 

increments  are 

 
when  there  is  no  time  interval  overlap,  t1<t2  and  T1,  T2>0. 
This  is  a  much  weaker  condition  and  far  more  interesting 
than  asserting 
statistically 
independent.  We  will  see  that  this  condition  leaves  the 
question  of  the  dynamics  of  x(t)  open,  except  to  rule  out 
processes  with  long  time  increment  autocorrelations  like 
fBm [1,17].  
 
Consider a stochastic process x(t) where the increments (31) 
are  uncorrelated.  From  this  condition  we  easily  obtain  the 
autocorrelation  function  for  positions  (returns),  sometimes 
called ‘serial autocorrelations’. If t>s then 
 

,  (32) 

 
since with x(to)=0 x(s)-x(to)=x(s), so that <x(s)x(t)>=<x2(s)> is 
simply 
(x(t), 
(32)  reflects  a 
….,x(s),…,x(0)),  or 
martingale property: 
 

in  x.  Given  a  history 

(x(tn),…x(tk),…,x(t1)), 

the  variance 

  ! (x(t1)"x(t1"T1))(x(t2+T2)"x(t2))=0  ! x(t)x(s)=(x(t)"x(s))x(s)+x2(s)=x2(s)>0 

(33) 

 

.  

(34) 

 
 
where 
 
 
 
Every  martingale  generates  uncorrelated  increments  and 
conversely, and so for a Martingale <x(t)x(s)>=<x2(s)> if s<t. 
 
In  a  martingale  process,  the  history  dependence  cannot  be 
detected  at  the  level  of  2-point  correlations,  memory  effects 
can  at  best  first  appear  at  the  level  3-point  correlations 
requiring the study of  a transition rate  density p3. Here, we 
have  not  postulated  a  martingale,  instead  we’ve  deduced 
that  property  from  the 
increment 
correlations. But this is  only part  of the story.  What follows 
next is crucial for avoiding mistakes in data analysis [4]. 
 
 Combining 
 

lack  of  pair  wise 

 

(35) 
 
with (34), we get 
 
 

   

(36) 

 
which  depends  on  both  t  and  T,  excepting  the  case  where 
<x2(t)>  is  linear  in  t.  Uncorrelated  increments  are  generally 
nonstationary. Therefore, martingales generate uncorrelated, 
typically  nonstationary  increments.  At  the  level  of  2-point 

  ! x(tn)x(tk)=dxn...dx1xn"xkpn(xn,tnxn,tn,...,xn,tn,...)pn#1(...)...pk+1(...)fk(...)=xk2"fk(xk,tk;...;x1,t1)dxk...dx1=x2"f1(x,t)dx=xk2(tk)  ! xmdxmpm(xm,tmxm"1,tm"1;...;x1,t1)=xm"1#  ! (x(t+T)"x(t))2=+(x2(t+T)+x2(t)"2x(t+T)x(t)  ! (x(t+T)"x(t))2=x2(t+T)"x2(t)the 

fBm 

time 

long 

increment 
[1,15,17],  whereas 

correlations  a  martingale  with  memory  cannot  be 
distinguished empirically from a  Markov process.  To see the 
memory  in  a  martingale  one  must  study  at  the  very  least  the  3-
point  correlations.  The 
increments  of  a  martingale  are 
stationary iff. the variance s linear in t (we restrict ourselves 
to the consideration of processes with finite variance). 
 
We’ve  emphasized  earlier  [1]  that  stationary  increments 
x(t,T)=x(t+T)-x(t)=x(T)  with  finite  variance  <x2(t)>  <  ∞ 
autocorrelations 
generate 
characteristic  of 
stationary 
uncorrelated increments with infinite variance occur in Levy 
processes [18,19].  
 
A martingale x(t) has no drift, and conditioned on the return 
x(to) yields <x(t)>cond=x(to). That is, x(t) not only has no trend 
but  the  conditional  average  is  in  addition  ‘stuck’  at  the  last 
observed point in a time series, 
 
 
 
Since x(t) represents the return or ‘gain’, one further toss of 
the coin produces no expected gain.  
 
Summarizing,  we’ve  shown  explicitly  that  fBm  is  not  a 
martingale [1], while every Markov process with trivial drift 
R(t)  can  be  transformed  into  a  (local)  Martingale  via  the 
substitution of x(t)-∫Rdt for x(t): Ito sdes with vanishing drift 
describe  local  martingales  [11].  A  martingale  may  have 
memory, but we lack a simple, clarifying model  continuous 
in  both  x  and  t  to  illustrate  the  effect  of  memory.  We’ve 
increments  are  nonstationary 
shown  that  uncorrelated 
unless the variance is linear in t. This means that looking for 
memory in two point correlations is useless: at that  level of 
description a martingale with memory will look Markovian. 
To  find  the  memory  in  a  martingale  one  must  study  the 

(37) 

. 

  ! xnpn"(xn,tnxn#1,tn#1;...;x1,t1)dxn=xn#1 

transition rates pn and correlations for n≥3. This has not been 
discussed in the literature, so far as we know.  
 
As  a  preliminary  step  to  discussing  the  EMH,  consider  a 
Martingale process x(t). The best forecast of any later return 
is the expected return  
 
 
 
so  that  no  gain  is  expected  in  sequential  time  intervals,  no 
matter how much you know about the past. I.e., if the same 
sequence (xn-1, …, x1) was observed at some other time in the 
past  and  a  return  xn>>xn-1  had  then  occured,  we  have  no 
reason  to  expect  that  accident/fluctuation  to  be  repeated. 
The  best  forecast  of  xn  is  still  <xn>cond=xn-1.  Since  we  can 
average over xk-1,…,x1, we can also predict/forecast that 
 

(38) 

, 

 

 

. 

(40) 

(39) 
 
etc., and finally  
 
 
 
 
Summarizing, the progression from statistical independence 
to Markov processes to  Martingales can be  understood as  a 
statistical 
systematic 
independence, 
factors, 
fn(xn,…,x1)=fn(xn)..f1(x1). A Markov process generalizes this by 
f1  alone, 
allowing 
fn(xn,…,x1)=p2(xn;xn-1)…p2(x2;x1)f1(x1). Every drift-free Markov 
process  is  a  martingale,  <x(tn)>c  =xn-1.  The  most  general 
martingale  keeps  only  the  last  condition  and  permits 
memory,  pn≠p2  for  n≥3.  In  this  way  we  have  a  successive 

restrictions.  For 
density 

to  be  determined  by  p2  and 

reduction 
the 

n-point 

in 

fn 

  ! xkp2(xk,tkxk"1,tk"1;...;x1,t1)#dxk=xk"1  ! xk=xkpk(xk,tkxk"1,tk"1;...;x1,t1)#pk"1(xk"1,tk"1xk"2,tk"2;...;x1,t1)dxkdxk"1=xk"1=xk"2  ! ...xk...=x2p2(x2,t2x1,t1)dx2"=x1in 

the 

that 

progression of complication in processes. All three classes of 
processes  have 
increment 
common 
autocorrelations  vanish.  But  for  statistical  independence 
<x(s)x(t)>=0,  whereas  for  martingales  <x(s)x(t)>=<x2(s)>  if 
s<t.  Fractional  Brownian  motion  and  other  systems  with 
long time increment autocorrelations fall completely outside 
this hierarchy.   
 
 
5. The Efficient Market Hypothesis 
 
We begin by sumarizing our  viewpoint  for the reader.  Real 
finance  markets  are  hard  to  beat,  arbitrage  posibilites  are 
hard to find and, once found, tend to disappear fast. In our 
opinion  the  EMH  is  simply  an  attempt  to  mathematize  the 
idea that the market is very hard to beat. If there is no useful 
information  in  market  prices,  then  those  prices  can  be 
‘noise  trading’.  A 
counted  as  noise,  the  product  of 
martingale  formulation  of  the  EMH  embodies  the  idea  that 
the  market  is  hard  to  beat,  is  overwhelmingly  noise,  but 
leaves  open  the  question  of  hard  to  find  correlations  that 
might be exploited for exceptional profit. 
 
A  strict  interpretation  of  the  EMH  is  that  there  are  no 
correlations,  no  patterns  of  any  kind,  that  can  be  employed 
systematically  to  beat  the  average  return  <R>  reflecting  the 
market  itself:  if  one  wants  a  higher  return,  then  one  must 
take on more risk. A Markov market is unbeatable, it has no 
systematically  repeated patterns,  no  memory to exploit. We 
will argue below that the stipulation should be added that in 
discussing the EMH we should consider only normal, liquid 
markets,  meaning  very  liquid  markets  with  small  enough 
transactions that approximately reversible trading is possible 
on a time scale of seconds [3]. Otherwise, ‘Brownian’ market 
models do not apply. Liquidity, ‘the money bath’ created by 
the noise traders whose behavior is reflected in the diffusion 

coefficient  [3],  is  somewhat  qualitatively  analogous  to  the 
idea of the heat bath in thermodynamics [20]: the second by 
second fluctuations in x(t) are created by the continual noise 
trading.  
 
Mandelbrot  [16]  proposed  a  less  strict  and  very  attractive 
definition of the EMH, one that directly reflects the fact that 
financial  markets  are  hard  to  beat  but  leaves  open  the 
question  whether  the  market  can  be  beaten  in  principle  at 
some  high  level  of  insight.  He  suggested  that  a  martingale 
condition  on  returns  realistically  reflects  the  notion  of  the 
EMH. A martingale may contain memory, but that memory 
can’t be easily exploited to beat the market precisely because 
the expectation of a martingale process x(t) at any later time 
is  simply  the  last  observed  return.  In  addition,  as  we’ve 
shown  above,  pair  correlations  in  increments  cannot  be 
exploited  to  beat  the  market  either.  The  idea  that  memory 
may  arise  (in  commodities,  e,g.)  from  other  variables  (like 
the weather) [16] correponds in statistical physics [10] to the 
appearance  of  memory  as  a  consequence  of  averaging  over 
larger 
other,  more  slowly  changing,  variables 
dynamical system.  
 
The martingale (a opposed to Markov) version of the EMH is 
also interesting because technical traders assume that certain 
price  sequences  give  signals  either  to  sell  or  buy.  In 
principle,  something  like  that  should  be  permitted  in  a 
martingale.  A  particular  price  sequence    (pn,  ….,p1),  were  it 
quasi-systematically  to  repeat,  can  be  encoded  as  returns 
(xn,…,x1)  so  that  a  transition  rate  density  pn(xn;xn-1,…,x1) 
could  be  interpreted  as  a  conditional  probability  to  buy  or 
sell.  Typically,  technical  traders  make  the  mistake  of  trying 
to interpret random price sequences quasi-deterministically, 
which  differs  from  our  interpretation  of  ‘technical  trading’ 
based  on  conditional  probabilities  (see  Lo  et  al  [21]  for  a 
discussion  of  technical  trading  claims,  but  based  on  a  non-

in  the 

the  data 

to  understand 

martingale,  non-empirically  based  model  of  prices).  With 
only a conditional probability for ‘signaling’ a specific price 
sequence,  an  agent  with  a  large  debt  to  equity  ratio  can 
easily suffer the Gamblers’ Ruin. In any case, we can offer no 
advice  about  technical  trading,  because  the  existence  of 
market  memory  has  not  been  firmly  established  (the 
question  is  left  open  by  the  analysis  of  ref.  [21]),  liquid 
finance markets look pretty Markovian so far as we’ve been 
[4],  but  one  can  go 
able 
systematically beyond the level of pair correlations to try to 
find  memory.  Apparently,  this  remains  to  be  done,  or  at 
least to be published. 
 
Fama  [22]  took  Mandelbrot’s  proposal  seriously  and  tested 
finance data at the simplest level for the fair game condition 
<x(t+T)>c=x(t).  We  continue  our  discussion  by 
first 
correcting  a  mathematical  mistake  made  by  Fama  (see  the 
first two of three unnumbered equations at the bottom of pg. 
391  in  [22]),  who  wrongly  concluded  in  his  discussion  of 
martingales  as  a  fair  game  condition  that  <x(t+T)x(t)>=0. 
Here’s  his  argument,  rewritten  partly  in  our  notation.  Let 
x(t) denote a ‘fair game’. With the initial condition chosen as 
the  unconditioned  expectation 
x(to)=0, 
<x(t)>=∫xdxf1(x,t)=0  (there  is  no  drift).  Then  the  so-called 
‘serial covariance’ is given by 
 
 
 
Fama states that this vanishes because <x(t+T)>cond=0. This is 
impossible:  by  a  fair  game  we  mean  a  Martingale,  the 
conditional 
is 
<x(t+T)>cond=∫ydyp2(y,t+T;x,t)=x=x(t)≠0, and so Fama should 
have  concluded  instead  that  <x(t+T)x(t)>=<x2(t)>  as  we 
showed  in  the  last  section.  Vanishing  of  (41)  would  be  true 
of statistically independent variables but is violated by a ‘fair 
game’.  Can  Fama’s  argument  be  salvaged?  Suppose  that 

then  we  have 

expectation 

(41) 

. 

  ! x(t+T)x(t)=xdx<x(t+T)>cond(x)f1(x,t)"try 

the 

to  use 

increment 
instead  of  x(t)  we  would 
x(t,T)=x(t+T)-x(t)  as  variable.  Then  <x(t,T)x(t)>=0  for  a 
Martingale,  as  we  showed  in  part  4.  However,  Fama’s 
argument still would not be generally correct because x(t,T) 
cannot be taken as a ‘fair game’ variable unless the variance 
is  linear  in  t,  and  in  financial  markets  the  variance  is  not 
linear  in  t  [3,4].  Fama’s  mislabeling  of  time  dependent 
averages  (typical  in  economics  and  finance  literature)  as 
‘market equilibrium’ has been corrected elsewhere [20]. 
 
In  our  discussion  of  the  EMH  we  shall  not  follow  the 
economists’  tradition  and  discuss  three  separate  forms 
(weak,  semi-strong,  and  strong  [22])  of  the  EMH,  where  a 
hard  to  test  or  effectively  nonfalsifiable  distinction  is  made 
between  three  separate  classes  of  traders.  We  specifically 
consider  only  normal  liquid  markets  with  trading  times  at 
multiples  of  10  min.  intevals  so  that  a  Martingale  condition 
holds  [4].  Normal  market  statistics  overwhelmingly  (with 
high probability, if not ‘with measure one’) reflect the noise 
traders  [3],  so  we  consider  only  normal  liquid  markets  and 
ask whether noise traders produce signals that one might be 
able  to  trade  on  systematically.  The  question  whether 
insiders,  or  exceptional  traders  like  Buffett  and  Soros,  can 
beat the market probably cannot be tested scientifically: even 
if  we  had  statistics  on  such  exceptional  traders,  those 
statistics  would  likely  be  too  sparse  to  draw  a  firm 
conclusion  (see  [3,4]  for  a  discussion  of  the  difficulty  of 
getting  good  enough  statistics  on  the  noise  traders,  who 
dominate  a  normal  market).  Furthrmore,  it  is  not  clear  that 
the beat liquid  markets, some  degree of  illiquidity seems to 
play  a  significant  role  there.  Effectively,  or  with  high 
trader  under 
probability, 
consideration    here,  the  noise  trader.  Noise  traders  provide 
the  liquidity  [24],  their  trading  determines  the  form  of  the 
diffusion  coefficient  D(x,t;{x})  [3],  where  {x}  reflects  any 
is 
memory  present.  The  question  that  we  emphasize 

is  only  one 

there 

type 

the 

level  n=2,  vanishing 

whether,  given  a  Martingale  created  by  the  noise  traders,  a 
normal liquid market can still be beaten systematically.  
 
One can test for martingales and for violations of the EMH at 
increasing levels of correlation. At the level n=1, the level of 
simple  averages,  the  ability  to  detrend  data  implies  a 
Martingale.  At 
increment 
autocorrelations  [4]  implies  a  martingale.  Both  conditions 
are consistent with Markov processes and with the EMH. A 
positive  test  for  a  martingale  with  memory  at  the  level  n≥3 
would  eliminate  Markov  processes,  and  perhaps  would 
violate the EMH as well. So far a we’re aware, this case has 
not yet been proposed or discussed in the literature. If such 
correlations  exist  and  would  be  traded  on,  then  a  finance 
theorist would argue that they  would be arbitra=ged away, 
changing  the  market  statistics  in  the  process.  If  true,  then 
this  would  make 
the  market  even  more  effectively 
Markovian. 
 
A Markov market cannot be systematically beaten, it has no 
memory of any kind to exploit. Volatility clustering [16] and 
so-called  ‘long  term  dependence’  [25]  appear  in  Markov 
models [25,26], are therefore not necessarily memory effects. 
In  the  folklore  of  finance  it’s  believed  that  some  traders  are 
able  to  make  money  from  volatility  clustering,  which  is  a 
Markovian  effect  with  a  nontrivial  variable  diffusion 
coeffient  D(x,t),  e.g.  D(x,t)=t2H-1(1+abs(x)/tH)  [26],  so  one 
would like to see the formulation of a trading strategy based 
on volatility clustering to check the basis for that claim.  
 
Testing  the  market  for  a  nonMarkovian  martingale  is 
nontrivial  and  apparently  has  not  been  done:  tests  at  the 
level  of  pair  correlations  leave  open  the  question  of  higher 
order correlations that may be exploited in trading. Whether 
the hypothesis of a martingale as EMH will stand the test of 
higher orders correlations exhibiting memory remains to be 

 

fat 

the 

(42) 

time 

tails  whenever 

seen. In the long run, one may be required to identify a very 
liquid ‘efficient market’ as Markovian.   
 
Finally,  martingales 
typically  generate  nonstationary 
increments. This means that it is generally impossible to use 
the increment x(t,T) (or the price difference p(t+T)-p(t)) as a 
variable  in the description  of the  underlying dynamics. The 
use  of  a  returns  or  price  increment  as  variable  in  data 
analysis  generates  spurious  Hurst  exponents    [4,27]  and 
spurious 
series  have 
nonstationary increments [3,4]. The reason that an increment 
cannot serve as a ‘good’ coordinate is that it depends on the 
staring time t: let z=x(t;T). Then 
 
 
 
is  not  independent  of  t,  although  attempts  to  construct  this 
quantity as histograms in data analysis implicitly presume t-
independence [4,27]. 
 Correspondingly,  there  exists  no 
Langevin eqn. for increments. The sole exception is when the 
variance  is  linear  in  t  so  that  the  increments  are  both 
stationary  and  uncorrelated; 
then 
independent  of  t  and  serves  as  a  ‘good’  coordinate.  But  in 
the  general  case  of  stationary 
increments  with  finite 
variance, unless the variance is linear in t there are long time 
correlations that destroy the fair game/martingale property. 
Nearly  all  existing  data  analyses  are  based  on  a  method  of 
building  histograms  called  ‘sliding  windows’  [4].  Sliding  a 
window from one value of t to another to read off x(T) from 
x(t,T)=x(t+T)-x(t)=x(T) 
the 
inherently 
increments  x(t,T)  are  stationary  (see  [27]  for  the  original 
discussion of the importance of nonstationary increments in 
data analysis).  
 
 
 

increment 

assumes 

that 

the 

is 

  ! f(z,t,t+T)=f2"(y,t+T;x,t)#(z$y+x)dxdy6. Martingales as EMH for nontrivial drift coefficients 
 
In  our  analysis  [4]  of  Euro-Dollar  1999-2004  FX  data,  the 
average  drift  is  a  small  constant  that  can  be  ignored.  We 
can’t  rule  out  that  that  result  may  be  era  dependent.  What 
would happen if an x-dependent drift were important? E.g., 
in  martingale  option  pricing  an  x-dependent  drift  R(x,t)=r-
D(x,t)/2 is theoretically necessary [20,28], where r is the risk 
free interest rate (or more generally the cost of carry [20]). In 
reality  option  pricing  via  the  exponential  distribution  has 
been sucessful with the neglect of that term [20,28].  
 
However, consider a market like the U.S. stock markets from 
1994-2000,  where  the  average  drift  <R>  should  describe  the 
bubble. If an x-dependent drift is a necessary consideration, 
then  the  condition  for  a  Martingale  as  the  EMH  must  be 
slightly modified. 
 
With  an  x-dependent  drift  R(x,t)  the  stochastic  integral 
equation  for  the  market  consists  of  a  drift  term  plus  a 
martingale, 
 

. 

(43) 

 
Whether or not R and/or D contain memory is at this stage 
unimportant. We can define an average drift 
 
 
 
reflecting  e.g.  an  intraday  average  [4]  conditioned  on  the 
daily  initial  conditions.  If  we  can  subtract  the  drift  from  x 
then  the  resulting  process  is  not  a  martingale.  The  best  we 
can obtain in this case is the restricted condition 
 

(44) 

, 

 

  ! x(t+T)=x(t)+R(x(s),s)ds+D(x(s),s)tt+T"tt+T"dB(s)  ! R=dxR(x,t)p2(x,txo,to") 

 

(45) 

 
 
where we can, e.g., take as initial condition the initial return 
at opening time to each day. However, the nice condition of 
uncorrelated increments is lost, 
 

 

 

 

(47) 

(46) 
 
so  we  no  longer  have  a  clear  and  easy  test  on  empirical 
returns data to rule out long time correlations.  
 
To  remedy  this  state  of  afairs,  we’re  forced  to  use  price  as 
variable.  Assume  that  R(x,t)=µ-D(x,t)/2,  which  reflects  the 
assumption that the basic market equation of motion is  
 
 
 
with  d(p,t)=D(x,t)  determined  empirically,  where  µ  is  the 
expected  ‘interest  rate’  on  the  financial  instrument  under 
consideration.  In  ref.  [21]  a  nonmartingale  Bachelier-type 
model  was  assumed,  p2d(p,t)=constant,  and  ‘patterns’  were 
assumed  without  proof  to  be  encoded  in  a  nonlinear  drift 
coefficient.  Next,  using  as  returns  variable  y=x-µt,  with  
S=pe-µt, we get a price martingale 
 
 
 
where (by Ito calculus) e(S,t)=d(p,t)=D(x,t). The condition to 
be tested empirically to establish this model is therefore  
<S(t,t-T)S(t,T)>=0,  where  the  increments  S(t,T)=S(t+T)-S(t) 
will  generally  be  nonstationary  with  <S(t+T)S(t)>=<S2(t)>  if 
T>0.  If  there  is  a  drift  coefficient  with  memory,  then  this 
model cannot be established. In the case of (47) the memory 

(48) 

   

  ! ydyp2"(y,txo,to)=xo  ! x(t,"T)x(t,T)=ds(R(x(s),s)"R)dw(R(x(w),w)"R)tt+T#t"Tt#$0  ! dp=µpdt+p2d(p,t)dB(t)  ! dS=S2e(S,t)dB(t)must be reflected in the diffusion coefficient. This possibility 
has not been studied in the finance literature. 
 
 
 
 
Acknowledgement 
 
Kevin  E.  Bassler  is  supported  by  the  NSF  through  grants 
#DMR-0406323 and #DMR-0427938. Gemunu H. Gunaratne 
is  supported  by  the  NSF  through  grant  #DMS-0607345  and 
by TLCC. Joseph L. McCauley is  grateful to a referee of [1] 
for  encouraging  us  to  extend  our  analysis  to  include  the 
EMH, to Harry Thomas for sending us four of his papers on 
the time evolution of  nonMarkovian systems, and to Enrico 
Scalas  for  pointing  us  to  Doob’s  assertion  that  a  Master 
Equation  is  not  a  sufficient  condition  to  make  a  process 
Markovian [28], which led us to ref. [6,7].  
 
 
References 
 
1. J. L. McCauley , G.H. Gunaratne, & K.E. Bassler, Hurst 
Exponents, Markov Processes, and Fractional Brownian Motion, 
Physica A (2007), in press. 
 
2. P. Hänggi, H. Thomas, H. Grabert, and P. Talkner, J. Stat. 
Phys. 18, 155, 1978. 
 
3.  J.  L.  McCauley,  K.E.  Bassler,  &  G.H.  Gunaratne,  On  the 
Analysis  of  Time  Series  with  Nonstationary  Increments  in 
Handbook of Complexity Research, ed. B. Rosser, 2007. 
 
4.  K.E.  Bassler,  J.  L.  McCauley,  &  G.H.  Gunaratne, 
Nonstationary  Increments,  Scaling  Distributions,  and  Variable 
Diffusion Processes in Financial Markets, 2006. 

 
5.  R.L.  Stratonovich.  Topics  in  the  Theory  of  Random  Noise, 
Gordon & Breach: N.Y., tr.  R. A. Silverman, 1963. 
 
6.  M.C.  Wang  &  G.E.  Uhlenbeck  in  Selected  Papers  on  Noise 
and Stochastic Processes, ed. N. Wax,  Dover: N.Y., 1954. 
 
7.  W.  Feller,  The  Annals  of  Math.  Statistics  30,  No.  4,  1252, 
1959. 
 
8. M. Courbage & D. Hamdan, The Annals of Probability 22, 
No. 3, 1662, 1994. 
 
9. K.E. Bassler, G.H. Gunaratne, & J. L. McCauley , Physica A 
369,343 (2006). 
 
10.  P.  Hänggi  and  H.  Thomas,  Zeitschr.  Für  Physik  B26,  85, 
1977. 
 
11.  R.  Durrett,  Brownian  Motion  and  Martingales  in  Analysis, 
Wadsworth, Belmont, 1984.  
 
12. M. Baxter and A. Rennie,. Financial Calculus, Cambridge, 
Cambridge, 1995. 
 
13. J.M. Steele, Stochastic Calculus and Financial Applications. 
Springer-Verlag, N.Y., 2000. 
 
14.  Joseph  L.  McCauley,  Stochastic  processes  for  physics  and 
finance, book manuscript to be submitted (2007).  
 
15.  B.  Mandelbrot  &  J.  W.  van  Ness,  SIAM  Rev.  10,  2, 
422,1968. 
 
16. B. Mandelbrot, J. Business 39, 242, 1966. 
 

17.  P.  Embrechts  and  M.  Maejima,  Self-similar  Processes, 
Princeton University Press, Princeton, 2002. 
 
18. E. Scalas, R. Gorenflo and F. Mainardi, Physica A284, 376, 
2000. 
 
19.  F.  Mainardi,  M.  Raberto,  R.  Gorenflo  and  E.  Scalas 
Physica A 287, 468, 2000. 
 
20.  J.L.  McCauley,  Dynamics  of  Markets:  Econophysics  and 
Finance, Cambridge, Cambridge, 2004. 
 
21. A. W. Lo, H. Mamaysky, and J. Wang, J. Finance LV, Nr. 
4, 1705, 2000. 
 
22. E. Fama, J. Finance 25, 383-417, 1970. 
 
23.  Johannes  A.  Skjeltorp,  Scaling  in  the  Norwegian  stock 
market, Physica A 283, 486-528, 2000. 
 
24. F. Black, J. of Finance 3, 529, 1986. 
 
25.  C.C.  Heyde  &  N.N.  Leonenko,  Adv.  Appl.  Prob.  37,  342, 
2005. 
 
26. K.E. Bassler, G.H. Gunaratne, & J. L. McCauley, work in 
progress (2007). 
 
27.  S.  Gallucio,  G.  Caldarelli,  M.  Marsilli,  and  Y.-C.  Zhang, 
Physica A245, 423, 1997. 
 
28.  J.  L.  McCauley,  G.H.  Gunaratne,  &  K.E.  Bassler, 
Martingale option pricing, submitted, 2006. 
 
29. 
http://www.dartmouth.edu/~chance/Doob/conversation.

Snell,  A  Conversation  with 

Joe  Doob, 

J.  L. 

html; Statistical Science 12, No. 4, 301, 1997. 
 

