Written: August 1999

Information Mechanics

John L. Haller Jr.

Graduate student
Electrical Engineering
Stanford University

Abstract:    The relationship between time, energy and information is discussed and a
quantitative equivalence is derived from the time evolution of the Schrödinger equation and the
weak law of large numbers.  A quick physical interpretation is shown in the tunneling event.  A
definition of physical information is proposed and used in examining the Heisenberg uncertainty
principle, the gaussian distribution and the harmonic oscillator.  The partitioning of phase space
is accomplished with the information cells of Gabor.  The interference phenomenon of the two
slit experiment is investigated.  Lastly and with less formality, the spin of the electron is
discussed.

Introduction:    The theory of quantum mechanics is intimately connected with the theory of
probability.  I shall therefore begin with a brief discussion of probability in quantum mechanics,
although in so doing I know that I am introducing a controversial subject.  In the Schrödinger
representation1 a system of particles may be described by a state vector, or wave function.  In the
spirit of quantum mechanics, the evolution of an undisturbed system is deterministic and obeys
the hamiltonian, a unitary operator.  The uncertainty or probabilistic nature of quantum
mechanics only shows itself when one wishes to measure the state of the system, or when
calculating transition rates.  Being more specific, the system acts probabilistically when you
force it into exclusive alternatives.  By forcing the system into exclusive alternatives, or
collapsing the wave packet, you require the particle to be wholly located at one of the
alternatives, where a measuring device can register an event.  In essence the act of measurement
quantizes the continuous wave function into a discrete value, where the probability of an event is
the integral of the wave function magnitude squared over the range of the measuring device's
extent.  The question that will be addressed is, "how much information can we extract from the
wave function and what is the form of that information?"

Statistical entropy, a measure of uncertainty, was introduced by Boltzmann and defined
as the log of the number of states.  A while later the concept of transmitting information over a
channel was explored2,3 and shown to be a linear function of the product of the time duration and
the frequency spread of the signal.  The theory of communication was then greatly advanced in
1948 with Shannon, who derived a quantitative metric for information.  Self information, or
entropy, is an abstract concept that measures the uncertainty contained within a random variable,
and is shown to be the negative expected log probability.  For example the flip of a fair coin has
one bit of self-information.  The outcome of a fair coin flip will be one of two equally likely
exclusive alternatives, and one bit is needed to perfectly describe the event.  If the coin is flipped
n times, n bits are needed to store the history of the sequence.  While information theory has been

mostly associated with electrical engineering and computer science, connections have been
shown between the statistical entropy and the information measure proposed by Shannon.4  For
example the result that information is the negative expected log probability, can be derived from
the canonical statistical ensemble.5  There have also been ties between the mathematical theory
of information and the second law of thermodynamics.6  Yet the notion of physical information
has not been well defined.  With the introduction of two concepts the abstract nature of
information will become more tangible.  

Imaginary time, the first concept, has previously been introduced in special relativity to

simplify the expression for the invariant distance between two events in four space.

s2 = (cid:140)x1

2  + (cid:140)x2

2  + (cid:140)x3
x4 = i$5 = i$c$t <
2 + (cid:140)x4

2 + (cid:140)x3

s2 = (cid:140)x1

2 + (cid:140)x2

2 - (cid:140)52

2 = (cid:22)5=1,4 (cid:140)x5

2

The use of imaginary time will allow the phase information to be extracted from the wave
function and will lead to the concept of imaginary, or possible, information.  Further explanation
of imaginary time will precede the proof of the information-energy relationship but for now it is
to be thought of as an orthogonal independent quantity of time.

The second concept that is needed is the idea that there are two principle types of

information.  Physical information and possible information.  This idea can be aided with the
following example.  There are two gentlemen and one shuffled deck of cards.  Gentleman A
picks up the top card, looks at it and replaces it on the top of the deck.  The question now is, what
is the probability that gentleman A saw the jack of diamonds.  Assuming that the deck is fair and
has all 52 cards, the possible information would tell both gentlemen that the top card is the jack
of diamonds with probability 1/52, since each card is equally likely and there are 52 of them. 
However, gentleman A saw either of two exclusive alternatives.  He either saw the jack of
diamonds, or did not.  Thus he would claim that the probability the top card is the jack of
diamonds is either 0 or 1.  He has been given knowledge of the physical information, the actual
ordering of that particular card.  

This idea of physical and possible information will be further explained as the results

derived here are interpreted.  

With these two fairly abstract concepts, the hidden nature of information will be shown to

have a simple and physical interpretation.  A qualitative connection between information and
physical systems can readily be seen in the covalent bond.  When two hydrogen atoms are
brought together they combine to form a bound H2 while losing the distinguishable nature of the
two electrons.  Now each electron can be found around either nucleus.  The electrons have lost
the information to which nucleus they were once attached, but have gained a binding energy.  

The time, energy, and information relation:    A system that is in an eigenstate, with an energy
eigenvalue (cid:15), can be described by a wave function that evolves in time, where the rate that the
wave function spins around in the complex plane is simply the eigenvalue (cid:15).  Thus each
eigenstate sweeps around in phase space at its corresponding rate.  It is attempted to interpret the
energy as the information rate of the system, and thus the information needed to describe a
system in an eigenstate for time - will be a linear function of the energy and the time.  For a
derivation of this relationship a system of n identical, symmetric, phase matched, and non-
interacting particles, is used.

The time dependent Schrödinger equation is solved for a system with eigenvalue (cid:15).

Now a system of n independent and symmetric particles is assumed.

55 (t) = exp[-i(cid:15)5(t-t5)]                                                         [1]

(cid:133) = 1
id/dt 55 (t) = H5 55 (t)
H5 55 (t) = (cid:15)5 55 (t)

5=1 H5

(cid:15)n = (cid:22)n
<
4n (t) = -n

5=1 55 (t)

Assuming further that each particle has the same eigenvalue, H5 = H, and that each particle has
the same phase, t5 = t0 = 0, the overall wave function, 4n (t), takes on a simple form.

4n (t) = -n

5=1 5(t) = exp[-in(cid:15)t]

4n (t) = exp[-n(cid:15)it]

In this equation, t is a quantity of time that has passed on a clock in the experimenter's lab.  The
clock is independent of the experiment and creates its own measure of time from an isolated
system, either from the decay of an atom, or from the swing of a pendulum.  In the experiment,
however, the system also has its own measurement of time.  Since the system has an energy, it
evolves in time and through periodicity can measure a quantity of time.  This independent,
quantity of time - has an imaginary nature when looked at from the isolated clock in the
laboratory.  Making the transformation i$t (cid:25) -, allows the phase information to be analyzed. 

The wave function is now a pure real number, and thus the magnitude squared of the wave
function is just the square of it.

i$t (cid:25) -
4n (-) = exp[-n(cid:15)-]

4*

n (-)4n (-) = exp[-2n(cid:15)-]

Taking the natural log of both sides, multiplying by -1/n, and substituting  -n
allows the weak law of large numbers to be evoked.

5=1 5(-) for 4n (-)

log[4*
-1/n log[4*

n (-)4n (-)] = -n2(cid:15)-
n (-)4n (-)] = 2(cid:15)-

-1/n log[-n

5=1 5*(-)5(-)] = -1/n (cid:22)n

5=1 log[5*(-)5(-)] = 2(cid:15)-

As n (cid:25) (cid:23), the sum approaches the expected value.

n (cid:25) (cid:23)

-1/n (cid:22) log[5*(-)5(-)] (cid:25) -E[log[5*(-)5(-)]]
with probability one by the weak law of large numbers

While the transformation, i$t (cid:25) -, has been used, interpreting 5*(-)5(-) as a probability, and
thus interpreting  -E[log[5*(-)5(-)]] as information, allows a simple equivalence between
information and energy and time to be seen.  

I = 2(cid:15)-                                                                 [2]

Before the interpretation of [2] is given, two more ways are used to arrive at the same

result.  Firstly, assuming that information is a linear function of time (t) and frequency (f) and LI
WKH(cid:3)WULYLDO(cid:3)DVVXPSWLRQ(cid:3)WKDW(cid:3)WKH(cid:3)DPRXQW(cid:3)RI(cid:3)LQIRUPDWLRQ(cid:3)WKDW(cid:3)LV(cid:3)WUDQVPLWWHG(cid:3)LV(cid:3)]HUR(cid:3)IRU(cid:3)VLJQDOV(cid:3)WKDW
KDYH(cid:3)]HUR(cid:3)GXUDWLRQ(cid:3)LQ(cid:3)WLPH(cid:3)DQG(cid:3)]HUR(cid:3)VSUHDG(cid:3)LQ(cid:3)IUHTXHQF\(cid:15)(cid:3)WKHQ(cid:3)D(cid:3)PHDVXUH(cid:3)RI(cid:3)WKH(cid:3)DPRXQW(cid:3)RI
LQIRUPDWLRQ(cid:3)LV(cid:3),(cid:3) (cid:3).(cid:3)f$t, where K is a constant that is to be determined.  To determine K, assume
that the signal that contains the information has variance in both the time domain and in the
frequency domain.  Furthermore, we will measure the frequency and the time in the unit-less
quantities f/((cid:140)f), and t/((cid:140)t) respectively, where (cid:140)f and (cid:140)t are usual standard deviations of the
signal.  Thus we arrive at an expression for K.

I =  f$t/((cid:140)f)$((cid:140)t)                                                           [3]

Upon maximizing the information, at a given f and t, the product ((cid:140)f)$((cid:140)t) is minimized.  Derived
in appendix A, ((cid:140)f)$((cid:140)t) has a minimum value 1/(4%).  Plugging this into equation [3] and setting 
E = h$f = 2%$f we arrive at the desired result.

I = 4%$f$t = 2E$t

Another derivation of equation [2] will closely follow the work of Brillouin.7  Here we
assume a noiseless physical RC circuit with time constant RC = (cid:11).  If the circuit is excited to
voltage Vn, the circuit will decay according to the exponential law

V = Vn$exp[-t/(cid:11)]                                                           [4]

The energy stored in the circuit is proportional to the square of the voltage and thus

Now let us assume that we use a code of n equidistant energy levels chosen uniformly 

E = En$exp[-2t/(cid:11)]

0, E0, 2$E0, 3$E0, ..., En = (n-1)$E0

Requiring error free transmission leads to the condition that we must wait a time interval
between successive pulses such that the energy has dropped below E0/2, such that we can
distinguish the next pulse which might be 0 or E0.  Solving for the worst case scenario leads to
the condition

E0/2 = (n-1)$E0$exp[-2t/(cid:11)]

t = ((cid:11)/2)$ln[2$(n-1)]                                                       [5]

To distinguish between two successive pulses a time period defined by equation [5] must be
used.  For a long time T the total number of signals will be T/t.  Given that each pulse strength is
equally likely, each signal carries ln[n] nats of information and the total information that is
transmitted will be the number of signals that can be sent in time T multiplied by the information
per pulse.

I = (T/t)$ln[n] = (2T/(cid:11))$ln[n]/ln[2$(n-1)]

The function f(n) = ln[n]/ln[2$(n-1)], n (cid:19) Z, is maximized for n = 2, and n = (cid:23) and has a value of
f(2) = f((cid:23)) =  1.1  Plugging f(n) = 1 into the equation above leads to 

Upon examining equation [4], one can see that 1/(cid:11) has the same mathematical form as an
imaginary angular frequency.  Viewing 1/(cid:11) as an imaginary energy, (cid:14), brings us again to the
same form of information as does equation [2]

I = 2T/(cid:11)

I = 2(cid:14)$T

It is the goal of this reporter to interpret equation [2] as saying that information is equal to

twice the action.  The indivisibility of the quantum unit of action ((cid:133)/2), discovered by Plank in
1905,  now takes on the form of quantum units of information with a value of 1 nat = log2[e] bits. 
How the information is encoded into the action remains to be discussed, yet a general rule of
assigning 1 nat of information per degree of freedom is presented. 

Quantization Rule:                                                                                                                    [6]

Given a system A with n degrees of freedom, there is another system B such that system
B can describe system A with n nats of information.  Furthermore, to describe the existence of m
forbidden areas in system A requires an additional m nats of information.

 The spin state of an electron, with spin ½, and one internal degree of freedom will be associated
with 1 nat of information.  A photon, with spin 1, and two degrees of freedom (direction and
polarization) will be assigned 2 nats of information.  The information in the spin state of the
electron will be discussed in the last section of this paper, however no attempt will be made here
in appointing 2 nats of information to a photon.  It has been shown that under certain situations
(single quadrature measurement of squeezed state) it is possible to extract 2 nats of information
per photon.8

(cid:20)

,W(cid:3)LV(cid:3)LQWHUHVWLQJ(cid:3)DQG(cid:3)ZRUWKZKLOH(cid:3)WR(cid:3)QRWH(cid:3)WKDW(cid:3)I(cid:11)Q(cid:12)(cid:3)LV(cid:3)PD[LPL]HG(cid:3)IRU(cid:3)WKH(cid:3)VDPH(cid:3)YDOXHV
RI(cid:3)Q(cid:3)WKDW(cid:3)DUH(cid:3)WKH(cid:3)DOORZHG(cid:3)PD[LPXP(cid:3)RFFXSDWLRQ(cid:3)QXPEHUV(cid:3)IRU(cid:3)IHUPLRQV(cid:3)(cid:11)Q(cid:3) (cid:3)(cid:21)(cid:12)(cid:3)DQG(cid:3)IRU(cid:3)ERVRQV(cid:3)(cid:11)Q(cid:3) 
(cid:23)(cid:12)

The tunneling event:    The tunneling of an electron across a barrier that is classically forbidden
has a finite probability of occurrence, and is a consequence of the requirement that the wave
function and its derivative be continuous.  In appendix B the WKB method is used to solve the
Schrödinger equation with the assumed solutions of the form 5(x) = exp[-iS(x)].  The
transmission probability across a barrier is defined as the outgoing intensity/ incoming intensity
which is proportional to (cid:13)5(b)(cid:13)2/(cid:13)5(a)(cid:13)2

When the wave function tunnels into the classically forbidden area, between a and b, the complex
exponential becomes a decaying exponential.  As shown in Appendix B, the transmission
tunneling probability, T, becomes 

This result also holds when the barrier is not square, and the transmission T becomes

T = exp[-2p$x]

where x = (b-a) and p s.t. p2/2m = (cid:13)Va - E(cid:13)

T = exp[-2,a

b p$dx]

Thus the transmission probability is exp[-2$action].  Looking at the tunneling event from the
viewpoint of universal probability,9 one can see the connection with equation [2].  The concept of
universal probability is that the probability of an event is exp[-L], where L is the description
length of the shortest program such that a universal computer outputs the event.  While no
universal computer has been defined, the idea that probability = exp[-I], is just the inverse of the
asymptotic equipartition property (a consequence of the W.L.L.N.).  Again we return to the result
that I = 2$action.  

Definition of physical information:    The interpretation of equation [2] as saying that
information is twice the action, brings with it a sense of physical tangibility for information.  For
example in the study of geomagnetically trapped radiation, three adiabatic invariants are used to
catalog the motion of ions around the earth.  The constancy of the action stored in the motion of
the ions, allows the prediction of the future paths of the ions.  Using the interpretation of action
described here, ones sees that the invariant is the information.  However, the interpretation of the
information rate as the energy (derived by time differentiation) leads to an ever growing amount
of information.  This is unrealistic for it is not possible to store an ever growing amount of
information.  Yet with the superposition of pure frequencies one can form a wave packet that has 
most of its area (in phase space) contained to a limited extent.  Thus a superposition of

eigenstates, each with its own information rate (twice the energy eigenvalue) leads to a wave
packet.  A definition of physical information, !I, is introduced as a measure of the overall
information contained in a wave packet.  The definition given below is not intended as the only
form of physical information, as some wave packets will have an undefined value for !I, notably
the exponential wave packet (see appendix C).

Definition:

!, (cid:18) (cid:23)%$ >(cid:31)I(cid:21)!(cid:3)(cid:16)(cid:3)(cid:31)I!(cid:21)@(cid:242)$>(cid:31)W(cid:21)!(cid:3)(cid:16)(cid:3)(cid:31)W!(cid:21)@(cid:242) QDWV(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)>(cid:26)@

ZKHUH(cid:3)>(cid:31)I(cid:21)!(cid:3)(cid:16)(cid:3)(cid:31)I!(cid:21)@(cid:242)  (cid:3)>,4(cid:13)(cid:11)I(cid:12)$I(cid:21)$$4(cid:11)I(cid:12)$GI(cid:3)(cid:16)(cid:3)>,4(cid:13)(cid:11)I(cid:12)$I$4(cid:11)I(cid:12)$GI@(cid:21)@(cid:242)
DQG(cid:3)>(cid:31)W(cid:21)!(cid:3)(cid:16)(cid:3)(cid:31)W!(cid:21)@(cid:242)  (cid:3)>,5(cid:13)(cid:11)W(cid:12)$W(cid:21)$$5(cid:11)W(cid:12)$GW(cid:3)(cid:16)(cid:3)>,5(cid:13)(cid:11)W(cid:12)$W$5(cid:11)W(cid:12)$GW@(cid:21)@(cid:242)

DQG(cid:3)ZKHUH(cid:3)4(f) = ,5(t)exp[-i2%ft]dt

!,(cid:3) (cid:3)(cid:23)%$(cid:11)(cid:140)I(cid:12)$(cid:11)(cid:140)W(cid:12)(cid:3) (cid:3)(cid:21)$(cid:11)(cid:140)7(cid:12)$(cid:11)(cid:140)W(cid:12)(cid:3) (cid:3)(cid:21)$(cid:11)(cid:140)((cid:12)$(cid:11)(cid:140)W(cid:12)

From this definition two immediate results follow.  Most notably from the Heisenberg

uncertainty principle, the result of Appendix A, where (cid:11)(cid:140)I(cid:12)$(cid:11)(cid:140)W(cid:12) (cid:7) 1/4% leads to 

!, (cid:7) 1 nat                                                               [8]

This inequality states that information that is stored in wave packets that have non-zero spread in
both the time domain and in the frequency domain must contain at least 1 nat of information.  

A second result that follows from the above definition is that the nth eigenstate of the
harmonic oscillator contains 2n +1 nats of information.  While the harmonic oscillator has a well
defined angular frequency, 7 = (k/m)½, the product of (cid:11)(cid:140)S(cid:12)$(cid:11)(cid:140)[(cid:12) does have a finite value and is
quantized to (n + ½).10  Carrying the definition of !, over to the momentum and space domain,
leads to the physical information of the nth state of the harmonic oscillator.

!,Q = (cid:21)$(cid:11)(cid:140)S(cid:12)$(cid:11)(cid:140)[(cid:12) = 2$n +1 nats                                               [9]

If a photon is absorbed into the harmonic oscillator, the physical information encoded

into the wave function grows by 2 nats.  This fits in nicely with the idea the a photon carries with
it 2 nats of information from its spin of 1.  Likewise an emission of a photon drops the physical
information of the harmonic oscillator by 2 nats, yet a photon is created and the 2 nats are carried
away by it.  To measure the angular frequency of the harmonic oscillator, one can measure the
frequency of photons that are emitted from it.  As more photons are measured, the precision of
the measurement increases.  It is theorized that the precision of a measurement of the frequency
of a harmonic oscillator in the nth state is 2$n nats, for after the nth photon is emitted no more
information is available.  Thus the harmonic oscillator stores the precise information as to its
angular frequency, yet it is not possible to copy this information indefinitely for there is not an
unlimited number of photons in the oscillator.

It is possible in a one dimensional oscillator for two oscillators of differing frequency to

collide and move action from one oscillator to the other.  If one of the oscillators has frequency f1
and the other one has frequency f2 =  f1/5, then if the first oscillator drops down one state the
other will be raised five states and it would appear that information is created.  However, this
increase in information comes from the possible information being transformed into physical

information.  Looking at the possible information as I =  f$t/((cid:140)f)$((cid:140)t) then it can be seen that
information is conserved, since f1$t/((cid:140)f)$((cid:140)t) =  5$f2$t/((cid:140)f)$((cid:140)t).  This situation can be aided with
the following example.  Imagine that a photon has a value that is greater than or equal to 2 units. 
Performing a measurement costs 2 units, and moreover you do not get any change back.   If you
have a photon that has a high energy and small temperature, then that photon has a high value,
say 100 units.  If you directly measure it you can get 2 nats out, however, if you go to a barter
table (collide a higher frequency oscillator with a lower frequency oscillator) you can exchange
your 100 unit photon for five photons of value 20 units.  Now each of the 20 unit value photons
can be measured to get 2 nats each.  However, this information comes from a lower energy state
and thus measuring photons from that state is not the same as measuring photons from the higher
energy state.

The ground state of the harmonic oscillator (n = 0) is the gaussian distribution.  The
gaussian distribution is the function that minimizes the product RI(cid:3)WKH(cid:3)YDULDQFHV(cid:3)RI(cid:3)WZR(cid:3)FRQMXJDWH
YDULDEOHV(cid:17)(cid:3)(cid:3)7KH(cid:3)JDXVVLDQ(cid:3)LV(cid:3)DOVR(cid:3)WKH(cid:3)GLVWULEXWLRQ(cid:3)WKDW(cid:3)PD[LPL]HV(cid:3)WKH(cid:3)VHOI(cid:16)LQIRUPDWLRQ(cid:3)RI(cid:3)D(cid:3)random
variable for a given variance.11  Therefore according to the above definition, equation [7], the
gaussian distribution should contain  (cid:23)%$(cid:11)(cid:140)I(cid:12)$(cid:11)(cid:140)W(cid:12) = 1 nat of information.  To find the total
entropy of a wave function, the differential entropy,  h(f(t)) = -,f(t)ln[f(t)]dt,  from both domains
must be accounted for.  To do so we will add the differential entropy of the probability
distribution in the time domain to the differential entropy of the probability distribution in the
frequency domain.  While the differential entropy is a relative quantity and can be negative, due
to its scaling property, the addition of the differential entropy from both domains results in a
more absolute and positive value.  The scaling property of the differential entropy presents
another dilemma as to the correct variables to use in the calculation of the differential entropy. 
For example should the differential entropy of the magnitude squared of the wave function with
angular frequency as the input variable be used, or should the standard frequency be used as the
input variable.  The answer is found in the energy theorem of the Fourier transform, which states

,5*(t)5(t)dt = ,4*(f)4(f)df

This fact of the Fourier transform allows the simultaneous normalization of the wave function in
both the time domain and in the standard frequency domain.  Therefore, to find the total entropy
of a wave function the differential entropy of the magnitude squared of the wave function in the
time domain will be added to the differential entropy of the magnitude squared of the wave
function in the standard frequency domain.  Derived in Appendix C, the differential entropy of a
gaussian distribution is given

h(5*(t)5(t)) = (½)ln[2%e((cid:140)t)2]
h(4*(f)4(f)) = (½)ln[2%e((cid:140)f)2]

Adding the two differential entropies and substituting 1/((cid:23)%(cid:12)(cid:3)IRU(cid:3)(cid:11)(cid:140)I(cid:12)$(cid:11)(cid:140)W(cid:12) leads to

h(5*(t)5(t)) + h(4*(f)4(f)) = (½)ln[(2%e)2((cid:140)t)2((cid:140)f)2] = ln[e/2]

To arrive at the desired result that the gaussian wave function contains 1 nat of information, an
extra bit of information is required.  This extra bit comes from the symmetry of the gaussian. 
Since the Fourier transform of a gaussian is again a gaussian, and since the gaussian is uniquely

describably by its mean and variance, the remaining bit of information is obtained in the
description of which of the conjugate variables corresponds to which variance.  Is the distribution
skinny in the time domain or in the frequency domain?  Consequently, the total entropy of the
gaussian distribution is found by adding the differential entropy in both domains to the bit
required to describe which domain corresponds to which variance.

!Igaussian = h(5*(t)5(t)) + h(4*(f)4(f)) + ln[2]                                   [10]

= ln[e/2] + ln[2] = 1 nat

By accounting for the self-information in both domains and accounting for the symmetry leads to
the result that a gaussian wave function stores 1 nat of information.  Applying the same
technique to the higher order wave functions of the harmonic oscillator (n (cid:7) 1) to arrive at the
result given by equation [9], is not as simple.  Due to the graceful symmetry of the gaussian it
was easy to account for the missing information.  Yet, the wave function of the harmonic
oscillator above the ground state are the Hermite polynomials, which contain much less
symmetry.  It will be a laborious task to find the encoding algorithm that catalogs the deficient
information.  Still, the Hermite polynomial of the nth order has n zeros.  Thus the wave function
of the harmonic oscillator in the nth state has n zeros in the spacial domain and n zeros in the
momentum domain, for a total of 2$n zeros.  Using the quantization rule [6], 1 nat of information
will be assigned to each zero and 1 nat of information will be attributed to the degree of freedom
of the ground state, which defines the angular frequency, for a total of 2$n + 1 nats of
information, which is in agreement with equation [9].

Partitioning of phase space:    In the classical treatment, if all the forces that act on a particle
are given and if precise initial conditions are prescribed to a particle, it is possible to predict with
certainty the trajectory of the particle for all time.  With the advent of quantum mechanics came
the understanding that a distinct point in phase space was not physically realizable, and thus the
future path becomes uncertain.  With this in-precision comes the advantage that only a finite
amount of information is needed to describe the point.  If one wished to describe a point to
infinite accuracy, then an infinite amount of information is required.  Yet as it has been shown
above, it requires only 1 nat of information to describe a gaussian wave packet.  The spreading of
a definite point into a gaussian distribution, allows a signal in phase space to be described by a
finite amount of information.  

In 1946 Gabor introduced the concept of an information cell that was used to tile the

time-frequency plane.12  He proposed the use of elementary signals as a basis for the description
of a signal that is a function of both frequency and time.  The elementary signals that he
proposed were gaussian wave packets that were shifted in time and modulated in frequency. 

While shifted and modulated gaussian pulses are not an orthogonal basis, he expanded a complex
signal as an infinite train of gaussian pulses in time and in frequency.  The expansion is as
follows2

Q(t) = (cid:22)(cid:23)

n=-(cid:23)(cid:22)(cid:23)

k=-(cid:23)cnk$exp[-(t-n$(2%)½$(cid:140)t)2/(4$((cid:140)t)2)]$exp[i$(2%)½$k$t/((cid:140)t)]

Therefore the infinite complex matrix, cnk, becomes the representation of the signal.  An
expansion of a real signal using “cosine-type” and “sine-type” elementary signals is given below

s(t) = (cid:22)(cid:23)

n=-(cid:23)exp[-(t-n$(2%)½$(cid:140)t)2/(4$((cid:140)t)2)]$(cid:22)(cid:23)

k=0[ank$cos[(2%)½$k$t/((cid:140)t)] + 

bnk$sin[(2%)½$(k + ½)$t/((cid:140)t)]]

Here the two semi-infinite real matrices, ank and bnk, together represent the signal.  Ultimately
these expressions give one complex number, cnk, for every two elementary areas of size ½, or two
real numbers, ank and bnk, for two cells of area ½ each.  This allocating of numbers to the time-
frequency plane is best illustrated in the following diagram

Each elementary box of size
(2%)½$(cid:140)t$(2%)½$(cid:140)f = ½ is allocated one real
number and is spaced every (2%)½$(cid:140)t
seconds in the time direction and is spaced
(2%)½$(cid:140)f Hz in the frequency direction. 
Thus to cover an area of the time-
frequency plane of size n, requires 2$n real
numbers, since each number occupies an
area of ½ each.  

Gabor concluded that each elementary signal, which occupies the smallest possible area in phase
space defined as 2%$(cid:11)(cid:140)I(cid:12)$(cid:11)(cid:140)W(cid:12)(cid:3) (cid:3)(cid:242)(cid:3), contains one datum of quantized information, that he
proposed to call a “logon”.  Thereby covering phase space up to frequency W and for a duration
of T requires 2WT real numbers and thus 2WT “logons” of information.  Measuring the time
duration in the number of cycles, n, of the highest frequency, W, equates T to n/W.  Thus it
requires 2$n “logons” of information to partition the phase space into the elementary signals. 
Bringing in the definition of physical information, !I, from equation [7], we can see that the
“logon” of information that Gabor suggested was actually 1 nat of information, since
4%$(cid:11)(cid:140)I(cid:12)$(cid:11)(cid:140)W(cid:12)(cid:3) (cid:3)1 nat.  Each elementary gaussian pulse carries with it 1 nat of information from
the formulation above. Accordingly to cover an area of phase space of size n requires 2$n nats of
information.

A much more rigorous development of the number of degrees of freedom of a signal that

is bound in frequency  to W and of finite duration T can be seen in the analysis of the prolate

(cid:21)

,Q(cid:3)*DERU¶V(cid:3)SDSHU(cid:15)(cid:3)KH(cid:3)XVHV(cid:3)WKH(cid:3)QRWDWLRQ(cid:3)(cid:140)W(cid:3)DQG(cid:3)(cid:140)I(cid:3)DV(cid:3)(cid:11)(cid:21)%(cid:12)(cid:242)(cid:3) WLPHV(cid:3)VWDQGDUG(cid:3)GHYLDWLRQ
RI(cid:3)WKH(cid:3)VLJQDO(cid:3)LQ(cid:3)WLPH(cid:3)DQG(cid:3)LQ(cid:3)IUHTXHQF\(cid:15)(cid:3)DQG(cid:3)WKXV(cid:3)(cid:140)W(cid:140)I(cid:3) (cid:3)(cid:242)(cid:17)(cid:3)(cid:3)7R(cid:3)VWD\(cid:3)FRQVLVWHQW(cid:3)ZLWK(cid:3)WKH(cid:3)QRWDWLRQ(cid:3)RI
WKLV(cid:3)UHSRUW(cid:15)(cid:3)(cid:140)W(cid:3)DQG(cid:3)(cid:140)I(cid:3)ZLOO(cid:3)EH(cid:3)WKH(cid:3)VTXDUH(cid:3)URRW(cid:3)RI(cid:3)>WKH(cid:3)VHFRQG(cid:3)PRPHQW(cid:3)(cid:16)(cid:3)WKH(cid:3)ILUVW(cid:3)PRPHQW(cid:3)VTXDUHG@(cid:17)

spheroidal wave functions.13  One of the main conclusions from the work of Slepian, Pollak, and
Landau is that the number of degrees of freedom of a signal, bound in frequency to W and of
time duration T, is roughly 2WT + 1.  Again measuring the time duration T in cycles of the
highest frequency W leads to the result that there are 2$n + 1 degrees of freedom.  Employing the
quantization rule [6] we arrive at the result that 2$n + 1 nats of information are required to
describe the signal.   This result is interpreted to say that 1 nat of information is present due to
the presence of a signal and the other 2$n nats are needed to cover the phase space occupied by it.

The two slit experiment:    Before the two slit experiment is examined, the gaussian wave
function will be used in analyzing the delta function.  The improper Dirac delta function can be
defined in a number of ways, the derivative of the step function for example.  Here we will look
at the delta function as a limit of the magnitude squared of a normalized gaussian wave function.  

(cid:13)!(t,(cid:5))(cid:13)2 (cid:25) (cid:13)(t) as (cid:5) (cid:25) 0
where !(t,(cid:5)) = (1/(cid:5)½)$exp[-%$t2/(2$(cid:5)2)]

Using this definition for the delta function allows the function ! to posses a Fourier transform
that can be normalized for any (cid:5) > 0 

 (f,(cid:5)) = ,!(t,(cid:5))$exp[-i$2%$f$t]dt = (2$(cid:5))½$exp[-2%$(cid:5)2$f2]

Thus for any (cid:5) > 0, the quantity (cid:140)W$(cid:140)I(cid:3)LV(cid:3)ILQLWH(cid:3)DQG(cid:3)KDV(cid:3)D(cid:3)YDOXH(cid:3)RI(cid:3)(cid:20)(cid:18)(cid:11)(cid:23)%(cid:12).  Using the expression
for the physical information contained in a gaussian wave function, equation [10], leads to the
result that for any (cid:5) > 0 the information contain in the pair of functions ! and   is one nat.  In
the limit that (cid:5) (cid:25) 0 the differential entropy of (cid:13)!(t,(cid:5))(cid:13)2 approaches negative infinity while the
differential entropy of (cid:13) (f,(cid:5))(cid:13)2 approaches positive infinity.  However, the sum of the two stays
finite and has a value of ln[e/2] nats.  Again adding the bit to describe which domain is
approaching the delta function and which domain is approaching the normalized uniform
distribution over the real line, gives a total of 1 nat.  Thus it can be viewed that a delta function in
one domain and the uniform distribution in the conjugate domain contains a total entropy of 1
nat.

It is interesting to see what happens when the delta function is separated into two delta

functions of size ½.  Breaking apart a delta function at the origin into two delta functions of
weight ½ and spreading them apart, one in the positive direction and one in the negative
direction, leads to a cosine wave in the conjugate domain, with a frequency defined by the
distance the two delta functions are moved away from the origin.  Defining 3(t,(cid:5))

3(t,(cid:5)) = (1/(2$(cid:5))½)$exp[-%$(t + t0)2/(2$(cid:5)2)] + (1/(2$(cid:5))½)$exp[-%$(t - t0)2/(2$(cid:5)2)]

2(f,(cid:5)) = ,3(t,(cid:5))$exp[-i$2%$f$t]dt
= (cid:5)½$exp[-2%$(cid:5)2$f2]$exp[-i$2%$f$t0] + (cid:5)½$exp[-2%$(cid:5)2$f2]$exp[i$2%$f$t0]
= 2$(cid:5)½$exp[-2%$(cid:5)2$f2]$cos[2%$f$t0]

(cid:13)3(t,(cid:5))(cid:13)2 = (1/(2$(cid:5)))$exp[-%$(t + t0)2/(cid:5)2] + (1/(2$(cid:5)))$exp[-%$(t - t0)2/(cid:5)2] + (cid:5)-1$exp[-%$(t2 + t0

2)/(cid:5)2]

For t0  R 1 and (cid:5) Q 1 the last term will be appreciably zero thus

(cid:13)3(t,(cid:5))(cid:13)2 x (1/(2$(cid:5)))$exp[-%$(t + t0)2/(cid:5)2] + (1/(2$(cid:5)))$exp[-%$(t - t0)2/(cid:5)2]

and (cid:13)2(t,(cid:5))(cid:13)2 = 4$(cid:5)$exp[-4%$(cid:5)2$f2]$cos2 [2%$f$t0]

as (cid:5) (cid:25) 0,  (cid:13)3(t,(cid:5))(cid:13)2 (cid:25) ½$(cid:13)(t + t0) + ½$(cid:13)(t - t0)

While (cid:13)3(t,(cid:5))(cid:13)2 approaches the even impulse pair, (cid:13)2(t,(cid:5))(cid:13)2 approaches the normalized cosine
squared distribution over the real line.  One can view the existence of a delta function in a
probability density function as a discrete probability.  Thus by separating the delta function at the
origin into two delta functions, an addition bit of discrete entropy is created in that domain. 
Subsequently the differential entropy of the conjugate domain is also affected for the uniform
distribution over the real line has turned into the cosine squared distribution.  

This mathematical treatment of the entropy associated with a delta function is closely

connected with the two slit experiment.  As shown in Appendix D, the probability distribution on
a measurement screen away from the partition is uniform if a measuring device locates the
particle at one slit.  If the particle is measured at one silt, its instantaneous location is described
by a delta function at that slit.  If a measurement of the particles location at the slits is not
attempted, then the instantaneous location of the particle, as it passes through the partition is an
even impulse pair.  The particle emerges from both slits with equal amplitude, and produces the
cosine squared distribution on a measurement screen away from the partition.  

While the two slit experiment looks like a one bit measurement, upper slit or lower slit, a one bit
measurement is not allowed by the definition of physical information, equation [7], and the
Heisenberg uncertainly principle.  As expressed in equation [8] at least 1 nat of information must
be extracted.  The extra ln[e/2] nats of information required to satisfy equation [8] comes from
the cosine squared distribution.  Given the same interval and assuming that the cosine squared
distribution is at its maximum or minimum at the ends of the interval, the uniform distribution
has ln[e/2] nats of entropy more than the cosine squared distribution.

X(cid:11)[(cid:12)(cid:3) (cid:3)(cid:20)(cid:18)(cid:11)(cid:21)U(cid:12)   for  x (cid:19) [-r, r]

c(x) = (1/r)Cos2(% (b/(cid:27))(x/r))    for  x (cid:19) [-r, r], b/(2$(cid:27)) (cid:19) Z

h(u) - h(c) =  -r,r (1/2$r)$ln[2$r]$dx + -r,r (1/r)Cos2(%$(b/(cid:27))$x/r)ln[(1/r)$Cos2(%$(b/(cid:27))$x/r)]dx

= -r,r (1/r)Cos2(%$(b/(cid:27))$x/r)ln[2$Cos2(%$(b/(cid:27))$x/r)]dx                             [11]

= ln[e/2]

This result holds for any r and any b/(2$(cid:27)) (cid:19) Z.  By inspection, it can be seen that the sine
squared distribution has ln[e/2] nats less than the uniform distribution.  Therefore by making a
one bit measurement in one domain, and collapsing two delta functions into one causes a change
in the other domain such that equation [8] is satisfied.  

H(½,½) + h(u) - h(c) = ln[2] + ln[e/2] = 1 nat (cid:7) (cid:21)$(cid:11)(cid:140)S(cid:12)$(cid:11)(cid:140)[(cid:12)(cid:3)(cid:7) (cid:20)(cid:3)QDW

Thus we can see that by properly accounting for the entropy in both domains, a one bit
measurement at one location necessarily affects the other domain such that a total of 1 nat of
information is extracted.  

7KH(cid:3)HOHFWURQ(cid:3)VSLQ(cid:29)
,QWHUSUHWLQJ(cid:3)HTXDWLRQ(cid:3)>(cid:21)@(cid:3)DV(cid:3)VD\LQJ(cid:3)WKDW(cid:3)LQIRUPDWLRQ(cid:3)LV(cid:3)WZLFH(cid:3)WKH(cid:3)DFWLRQ(cid:15)(cid:3)WKH
VSLQ(cid:3)RI(cid:3)WKH(cid:3)HOHFWURQ(cid:3)VKRXOG(cid:3)FRQWDLQ(cid:3)RQH(cid:3)QDW(cid:3)RI(cid:3)LQIRUPDWLRQ(cid:17)(cid:3)(cid:3)$(cid:3)VSLQ(cid:3)(cid:242)(cid:3)VWDWH(cid:3)LV(cid:3)D(cid:3)YHFWRU(cid:3)WKDW(cid:3)GHILQHV
D(cid:3)UD\(cid:3)LQ(cid:3)WKH(cid:3)XQLW(cid:3)VSKHUH(cid:17)(cid:3)(cid:3),I(cid:3)D(cid:3)PHDVXUHPHQW(cid:3)RFFXUV(cid:15)(cid:3)VD\(cid:3)LQ(cid:3)WKH(cid:3)](cid:16)GLUHFWLRQ(cid:15)(cid:3)WKH(cid:3)HOHFWURQ(cid:3)ZLOO(cid:3)GHSDUW
IURP(cid:3)WKH(cid:3)PHDVXUHPHQW(cid:3)HLWKHU(cid:3)VSLQ(cid:3)XS(cid:3)RU(cid:3)VSLQ(cid:3)GRZQ(cid:3)LQ(cid:3)WKH(cid:3)](cid:16)GLUHFWLRQ(cid:17)(cid:3)(cid:3)%HLQJ(cid:3)PRUH(cid:3)VSHFLILF(cid:15)(cid:3)WKH
YHFWRU(cid:15)(cid:3)WKDW(cid:3)GHILQHV(cid:3)WKH(cid:3)VWDWH(cid:15)(cid:3)ZLOO(cid:3)SRLQW(cid:3)LQ(cid:3)HLWKHU(cid:3)WKH(cid:3)SRVLWLYH(cid:3)RU(cid:3)QHJDWLYH(cid:3)](cid:16)GLUHFWLRQ(cid:17)(cid:3)(cid:3),I(cid:3)DQ
HOHFWURQ(cid:3)LV(cid:3)PHDVXUHG(cid:3)LQ(cid:3)WKH(cid:3)](cid:16)GLUHFWLRQ(cid:3)DQG(cid:3)D(cid:3)VXEVHTXHQW(cid:3)PHDVXUHPHQW(cid:3)RFFXUV(cid:3)LQ(cid:3)D(cid:3)GLUHFWLRQ(cid:3)WKDW
IRUPV(cid:3)DQ(cid:3)DQJOH(cid:3)WKHWD(cid:3)ZLWK(cid:3)WKH(cid:3)](cid:16)GLUHFWLRQ(cid:15)(cid:3)WKHQ(cid:3)WKH(cid:3)SUREDELOLW\(cid:3)RI(cid:3)WKH(cid:3)GLVFUHWH(cid:3)RXWFRPH(cid:3)LV
VLQXVRLGDO(cid:3)LQ(cid:3)WKHWD(cid:17)(cid:3)(cid:3),W(cid:3)LV(cid:3)DV(cid:3)LI(cid:3)WKH(cid:3)HOHFWURQ(cid:3)LV(cid:3)LQ(cid:3)D(cid:3)VXSHUSRVLWLRQ(cid:3)RI(cid:3)EHLQJ(cid:3)VSLQ(cid:3)XS(cid:3)DQG(cid:3)VSLQ(cid:3)GRZQ(cid:3)LQ
WKDW(cid:3)GLUHFWLRQ(cid:17)(cid:3)(cid:3)*RLQJ(cid:3)IXUWKHU(cid:15)(cid:3),(cid:3)ZLOO(cid:3)DUJXH(cid:3)WKDW(cid:3)LI(cid:3)WKH(cid:3)HOHFWURQ(cid:3)LV(cid:3)PHDVXUHG(cid:3)VSLQ(cid:3)XS(cid:3)LQ(cid:3)WKH(cid:3)](cid:16)
GLUHFWLRQ(cid:3)LW(cid:3)LV(cid:3)QRW(cid:3)RQO\(cid:3)VSLQ(cid:3)XS(cid:3)LQ(cid:3)WKDW(cid:3)GLUHFWLRQ(cid:15)(cid:3)EXW(cid:3)LV(cid:3)VSLQ(cid:3)XS(cid:3)LQ(cid:3)D(cid:3)VXSHUSRVLWLRQ(cid:3)RI(cid:3)WKH(cid:3)](cid:16)GLUHFWLRQ
DQG(cid:3)HYHU\(cid:3)RWKHU(cid:3)GLUHFWLRQ(cid:3)LQ(cid:3)WKH(cid:3)XQLW(cid:3)VSKHUH(cid:3)ZLWK(cid:3)D(cid:3)ZHLJKWLQJ(cid:3)WKDW(cid:3)LV(cid:3)VLQXVRLGDO(cid:3)LQ(cid:3)WKHWD(cid:15)(cid:3)WKHWD
EHLQJ(cid:3)WKH(cid:3)DQJOH(cid:3)EHWZHHQ(cid:3)DQ(cid:3)DUELWUDU\(cid:3)GLUHFWLRQ(cid:3)DQG(cid:3)WKH(cid:3)GLUHFWLRQ(cid:3)WKDW(cid:3)ZLOO(cid:3)DOZD\V(cid:15)(cid:3)ZLWK(cid:3)SUREDELOLW\
RQH(cid:15)(cid:3)SURGXFH(cid:3)DQ(cid:3)RXWFRPH(cid:3)RI(cid:3)VSLQ(cid:3)XS(cid:17)(cid:3)(cid:3)

:KHQ(cid:3)WZR(cid:3)HOHFWURQV(cid:3)DUH(cid:3)LQ(cid:3)WKH(cid:3)VDPH(cid:3)VWDWH(cid:15)(cid:3)WKH(cid:3)3DXOL(cid:3)H[FOXVLRQ(cid:3)SULQFLSOH(cid:3)VD\V(cid:3)WKDW(cid:3)RQH

HOHFWURQ(cid:3)LV(cid:3)VSLQ(cid:3)XS(cid:3)DQG(cid:3)WKH(cid:3)RWKHU(cid:3)HOHFWURQ(cid:3)LV(cid:3)VSLQ(cid:3)GRZQ(cid:17)(cid:3)(cid:3),I(cid:3)ZH(cid:3)VD\(cid:3)WKDW(cid:3)WKH(cid:3)SDLU(cid:3)RI(cid:3)HOHFWURQV(cid:3)IRUPV
D(cid:3)V\VWHP(cid:3)WKDW(cid:3)GRHV(cid:3)QRW(cid:3)KDYH(cid:3)DQ\(cid:3)SUHIHUUHG(cid:3)GLUHFWLRQ(cid:15)(cid:3)WKHQ(cid:3)WKH(cid:3)WZR(cid:3)VSLQ(cid:3)VWDWHV(cid:3)DUH(cid:3)DQWL(cid:16)SDUDOOHO(cid:3)DQG
WKH(cid:3)VWDWH(cid:3)RI(cid:3)WKH(cid:3)V\VWHP(cid:3)LV(cid:3)LQ(cid:3)D(cid:3)XQLIRUP(cid:3)VXSHUSRVLWLRQ(cid:17)(cid:3)(cid:3):KHQ(cid:3)WKH(cid:3)WZR(cid:3)HOHFWURQV(cid:3)EHFRPH(cid:3)VHSDUDWHG(cid:15)
RQH(cid:3)OHDYHV(cid:3)LQ(cid:3)D(cid:3)VSLQ(cid:3)XS(cid:3)VXSHUSRVLWLRQ(cid:3)VWDWH(cid:3)DQG(cid:3)WKH(cid:3)RWKHU(cid:3)LQ(cid:3)D(cid:3)VSLQ(cid:3)GRZQ(cid:3)VXSHUSRVLWLRQ(cid:3)VWDWH(cid:17)(cid:3)(cid:3)7KH
SUREDELOLW\(cid:3)GLVWULEXWLRQV(cid:3)KDYH(cid:3)FKDQJHG(cid:3)DQG(cid:3)WKXV(cid:3)ZH(cid:3)FDQ(cid:3)ORRN(cid:3)DW(cid:3)WKH(cid:3)FKDQJH(cid:3)LQ(cid:3)WKH(cid:3)LQIRUPDWLRQ(cid:3)LQ
WKH(cid:3)GLVWULEXWLRQV(cid:17)(cid:3)(cid:3)/LNH(cid:3)WKH(cid:3)WZR(cid:3)VOLW(cid:3)H[SHULPHQW(cid:15)(cid:3)WKH(cid:3)UHODWLYH(cid:3)HQWURS\(cid:3)EHWZHHQ(cid:3)WKH(cid:3)XQLIRUP
GLVWULEXWLRQ(cid:3)DQG(cid:3)WKH(cid:3)VLQH(cid:3)VTXDUHG(cid:3)GLVWULEXWLRQ(cid:3)ZLOO(cid:3)DFW(cid:3)DV(cid:3)RXU(cid:3)PHDVXUH(cid:17)(cid:3)(cid:3)6LQFH(cid:3)HDFK(cid:3)HOHFWURQ(cid:3)KDV
SUREDELOLW\(cid:3)(cid:242)(cid:3)RI(cid:3)EHLQJ(cid:3)LQ(cid:3)WKH(cid:3)VSLQ(cid:3)XS(cid:3)VXSHUSRVLWLRQ(cid:3)VWDWH(cid:3)DQG(cid:3)SUREDELOLW\(cid:3)(cid:242)(cid:3)RI(cid:3)EHLQJ(cid:3)LQ(cid:3)WKH(cid:3)VSLQ
GRZQ(cid:3)VXSHUSRVLWLRQ(cid:3)VWDWH(cid:15)(cid:3)HDFK(cid:3)HOHFWURQ(cid:3)VSLQ(cid:3)ZLOO(cid:3)FRQWDLQ(cid:3)RQH(cid:3)ELW(cid:3)RI(cid:3)HQWURS\(cid:3)IURP(cid:3)WKH(cid:3)VSLQ
XS(cid:18)GRZQ(cid:3)SRVVLELOLW\(cid:17)(cid:3)(cid:3)0RUHRYHU(cid:15)(cid:3)HDFK(cid:3)HOHFWURQ(cid:3)ZLOO(cid:3)DOVR(cid:3)FRQWDLQ(cid:3)WKH(cid:3)HQWURS\(cid:3)DVVRFLDWHG(cid:3)ZLWK(cid:3)JRLQJ
IURP(cid:3)WKH(cid:3)XQLIRUP(cid:3)VXSHUSRVLWLRQ(cid:3)VWDWH(cid:3)WR(cid:3)WKH(cid:3)VSLQ(cid:3)XS(cid:18)GRZQ(cid:3)VXSHUSRVLWLRQ(cid:3)VWDWH(cid:17)

7KH(cid:3)VSLQ(cid:3)XS(cid:3)VXSHUSRVLWLRQ(cid:3)VWDWH(cid:3)ZLOO(cid:3)EH(cid:3)ZHLJKWHG(cid:3)OLNH(cid:3)WKH(cid:3)SUREDELOLW\(cid:3)RI(cid:3)WKH(cid:3)VSLQ(cid:3)XS(cid:3)RXWFRPH(cid:3)RI(cid:3)D
VSLQ(cid:3)XS(cid:18)GRZQ(cid:3)PHDVXUHPHQW(cid:3)DW(cid:3)DQ(cid:3)DQJOH(cid:3)WKHWD(cid:15)(cid:3)DQG(cid:3)ZLOO(cid:3)EH(cid:3)QRUPDOL]HG(cid:3)IRU(cid:3)(cid:21) (cid:19) >(cid:16)%(cid:15)%@

SXS(cid:3)VWDWH(cid:11)(cid:21)(cid:12)(cid:3) (cid:3)(cid:11)(cid:20)(cid:18)%(cid:12)&RV(cid:21)(cid:11)(cid:21)(cid:18)(cid:21)(cid:12)

7KH(cid:3)VSLQ(cid:3)GRZQ(cid:3)VXSHUSRVLWLRQ(cid:3)VWDWH(cid:3)ZLOO(cid:3)EH(cid:3)ZHLJKWHG(cid:3)OLNH(cid:3)WKH(cid:3)SUREDELOLW\(cid:3)RI(cid:3)WKH(cid:3)VSLQ(cid:3)GRZQ
RXWFRPH(cid:3)RI(cid:3)D(cid:3)VSLQ(cid:3)XS(cid:18)GRZQ(cid:3)PHDVXUHPHQW(cid:3)DW(cid:3)DQ(cid:3)DQJOH(cid:3)WKHWD(cid:15)(cid:3)DQG(cid:3)ZLOO(cid:3)EH(cid:3)QRUPDOL]HG(cid:3)IRU(cid:3)(cid:21) (cid:19) >(cid:16)
%(cid:15)%@

7KH(cid:3)XQLIRUP(cid:3)VWDWH(cid:3)ZLOO(cid:3)EH(cid:3)XQLIRUP(cid:3)IRU(cid:3)(cid:21) (cid:19) >(cid:16)%(cid:15)%@

SGRZQ(cid:3)VWDWH(cid:11)(cid:21)(cid:12)(cid:3) (cid:3)(cid:11)(cid:20)(cid:18)%(cid:12)6LQ(cid:21)(cid:11)(cid:21)(cid:18)(cid:21)(cid:12)

SXQLIRUP(cid:11)(cid:21)(cid:12)(cid:3) (cid:3)(cid:20)(cid:18)(cid:11)(cid:21)%(cid:12)

7KH(cid:3)VSLQ(cid:3)RI(cid:3)WKH(cid:3)HOHFWURQ(cid:3)ZLOO(cid:3)FRQWDLQ(cid:3)RQH(cid:3)ELW(cid:3)RI(cid:3)HQWURS\(cid:3)IURP(cid:3)ZKLFK(cid:3)VXSHUSRVLWLRQ(cid:3)VWDWH(cid:3)LW(cid:3)LV(cid:3)LQ
SOXV(cid:3)WKH(cid:3)HQWURS\(cid:3)WKDW(cid:3)WKH(cid:3)FRVLQH(cid:15)(cid:3)DQG(cid:3)VLQH(cid:15)(cid:3)VTXDUHG(cid:3)GLVWULEXWLRQ(cid:3)LV(cid:3)DZD\(cid:3)IURP(cid:3)WKH(cid:3)XQLIRUP
GLVWULEXWLRQ(cid:15)(cid:3)ZKLFK(cid:3)KDV(cid:3)EHHQ(cid:3)VKRZQ(cid:3)WR(cid:3)EH(cid:3)OQ>H(cid:18)(cid:21)@(cid:15)(cid:3)HTXDWLRQ(cid:3)>(cid:20)(cid:20)@(cid:17)

,HOHFWURQ(cid:3)VSLQ   H(½,½) + h(SXQLIRUP) - h(SXS(cid:18)GRZQ(cid:3)VWDWH) = ln[2] + ln[e/2] = 1 nat

5HPDUNV(cid:29) $(cid:3)FROOHFWLRQ(cid:3)RI(cid:3)SDUWLFOHV(cid:3)WKDW(cid:3)HYROYH(cid:3)LQ(cid:3)WLPH(cid:3)ZDV(cid:3)EXLOW(cid:3)XS(cid:3)DQG(cid:3)WKHQ(cid:3)EURNHQ(cid:3)EDFN(cid:3)GRZQ
XVLQJ(cid:3)WKH(cid:3)$V\PSWRWLF(cid:3)(TXLSDUWLWLRQ(cid:3)3URSHUW\(cid:3)WR(cid:3)VKRZ(cid:3)WKH(cid:3)UHODWLRQVKLS(cid:3)EHWZHHQ(cid:3)LQIRUPDWLRQ(cid:3)DQG
HQHUJ\(cid:17)(cid:3)(cid:3)7ZR(cid:3)W\SHV(cid:3)RI(cid:3)LQIRUPDWLRQ(cid:3)ZHUH(cid:3)WKHRUL]HG(cid:17)(cid:3)(cid:3)3RVVLEOH(cid:3)LQIRUPDWLRQ(cid:3)WKDW(cid:3)H[SUHVVHV(cid:3)WKH
DPRXQW(cid:3)RI(cid:3)LQIRUPDWLRQ(cid:3)WKDW(cid:3)ZRXOG(cid:3)EH(cid:3)UHTXLUHG(cid:3)WR(cid:3)FRPSOHWHO\(cid:3)GHVFULEH(cid:3)D(cid:3)V\VWHP(cid:3)ZLWK(cid:3)D(cid:3)FHUWDLQ
HQHUJ\(cid:3)IRU(cid:3)D(cid:3)FHUWDLQ(cid:3)WLPH(cid:15)(cid:3)DQG(cid:3)SK\VLFDO(cid:3)LQIRUPDWLRQ(cid:17)(cid:3)(cid:3)7KH(cid:3)WXQQHOLQJ(cid:3)HYHQW(cid:3)ZDV(cid:3)XVHG(cid:3)WR(cid:3)VKRZ(cid:3)WKH
FRQQHFWLRQ(cid:3)ZLWK(cid:3)XQLYHUVDO(cid:3)SUREDELOLW\(cid:17)(cid:3)(cid:3)7KH(cid:3)SDUWLWLRQLQJ(cid:3)RI(cid:3)SKDVH(cid:3)VSDFH(cid:3)ZDV(cid:3)DFFRPSOLVKHG(cid:3)E\
DOORFDWLQJ(cid:3)RQH(cid:3)HOHPHQWDU\(cid:3)VLJQDO(cid:3)WR(cid:3)DQ(cid:3)DUHD(cid:3)WKH(cid:3)VL]H(cid:3)RI(cid:3)(cid:242)(cid:17)(cid:3)(cid:3)7KH(cid:3)WZR(cid:3)VOLW(cid:3)H[SHULPHQW(cid:3)JDYH(cid:3)D(cid:3)FOXH(cid:3)DV
WR(cid:3)WKH(cid:3)SURFHVVHV(cid:3)WKDW(cid:3)DUH(cid:3)LQYROYHG(cid:3)ZKHQ(cid:3)PHDVXULQJ(cid:3)WKH(cid:3)SK\VLFDO(cid:3)LQIRUPDWLRQ(cid:3)RI(cid:3)D(cid:3)V\VWHP(cid:17)(cid:3)(cid:3)7KH
VSLQ(cid:3)RI(cid:3)WKH(cid:3)HOHFWURQ(cid:3)ZDV(cid:3)H[SORUHG(cid:3)DQG(cid:3)D(cid:3)QHZ(cid:3)W\SH(cid:3)RI(cid:3)SK\VLFDO(cid:3)LQIRUPDWLRQ(cid:15)(cid:3)WKH(cid:3)VSLQ(cid:3)VWDWH(cid:15)(cid:3)ZDV
LQWURGXFHG(cid:17)(cid:3)(cid:3)7KHVH(cid:3)UHVXOWV(cid:3)DUH(cid:3)LQ(cid:3)QR(cid:3)ZD\(cid:3)LQWHQGHG(cid:3)WR(cid:3)H[KDXVW(cid:3)WKH(cid:3)SRVVLEOH(cid:3)VFRSH(cid:3)RI(cid:3),QIRUPDWLRQ
0HFKDQLFV(cid:3)RU(cid:3)UHSODFH(cid:3)4XDQWXP(cid:3)7KHRU\(cid:15)(cid:3)EXW(cid:3)UDWKHU(cid:3)DUH(cid:3)DLPHG(cid:3)DW(cid:3)EULQJLQJ(cid:3)QHZ(cid:3)OLJKW(cid:3)WR(cid:3)DQ(cid:3)ROG
GLVFXVVLRQ(cid:17)

$SSHQGL[(cid:3)$(cid:29) 7KH(cid:3)+HLVHQEHUJ(cid:3)XQFHUWDLQW\(cid:3)SULQFLSOH

The lower limit of the product of the variances of two conjugate variables will be derived

following the rigorous proof given by Bracewell.14

All integrals are to be taken between infinite limits.
F(s) = ,f(t)exp[-i2%st]dt
From the derivative theorem and the Rayleigh theorem
,f1f1* dt = 4%2 ,s2 FF* ds
The Schwarz inequality
4,ff * dt,gg* dt (cid:7) (cid:13),(f*g+fg*)dt(cid:13)2
Integration by parts
(cid:13),tf1dt(cid:13) = (cid:13),fdt(cid:13)

Now, taking f(t) and F(s) to be centered on its centroid and
,ff * dt = ,FF* ds = 1

((cid:140)t)2 ((cid:140)s)2 = ,t2 ff * dt,s2 FF* ds
= ,tf.tf* dt,f1f1* dt/4%2
(cid:7) (cid:13),(tf* .f1+tf.f1* )dt(cid:13)2 /16%2
= (cid:13),t d/dt (ff* )dt(cid:13)2 /16%2
= (cid:13),ff* dt(cid:13)2 /16%2
= 1/16%2
<
((cid:140)s)((cid:140)t) (cid:7) 1/4%
<
((cid:140)7)((cid:140)t) = ((cid:140)E)((cid:140)t) (cid:7) ½

Appendix B:    Probability of an electron tunneling through a classically forbidden barrier

7KH(cid:3)6FKU|GLQJHU(cid:3)HTXDWLRQ(cid:3)LV(cid:3)VROYHG(cid:3)DVVXPLQJ(cid:3)VROXWLRQV(cid:3)RI(cid:3)WKH(cid:3)IRUP(cid:3)5(x) = exp[-iS(x)]

(-1/2m)d2/dx2 5(x) + V(x)5(x) = E5(x)

(1/2m)(d/dxS(x))2 - i(1/2m)d2/dx2S(x) = E - V(x)

Expanding S(x) as S0(x) + S1(x)/i + S2(x)/(i2) +... leads to the conditions below

(1/2m)[d/dxS0(x)]2 - i(1/2m)(d2/dx2S0(x) + 2[d/dxS0(x)][d/dxS1(x)]) - ([d/dxS1(x)]2
+2[d/dxS0(x)][d/dxS2(x)] + d2/dx2S1(x)) + ... = E -V(x)
<
(1/2m)[d/dxS0(x)]2 = E -V(x),
d2/dx2S0(x) + 2[d/dxS0(x)][d/dxS1(x)] = 0,
[d/dxS1(x)]2 +2[d/dxS0(x)][d/dxS2(x)] + d2/dx2S1(x) = 0

The zero order approximation 

d/dxS0(x) = d/dx,x

xo p$dx1 = p = [2m(E-V(x))]½  

S0(x) = ±,x

<
xo p$dx1 = action

for x < a 

for x > b

for a < x < b, p is imaginary

Tunneling probability T

5(x) = C1exp[i$,x
5(a) = C1exp[i$,a

xo p$dx1]
xo p$dx1]

5(x) = 5(a)exp[i$,x

a p$dx1] = 5(a)exp[-1$,x

a(cid:13)p(cid:13)$dx1]

5(x) = 5(a)exp[-1$,b

a(cid:13)p(cid:13)$dx1]$exp[i$,x

b p$dx1 + i$%/4]

5(b) = 5(a)exp[-1$,b

a(cid:13)p(cid:13)$dx1]$exp[ i$%/4]

T (cid:18)(cid:13)5(b)(cid:13)2/(cid:13)5(a)(cid:13)2 = exp[-2$,b

a(cid:13)p(cid:13)$dx1]

Appendix C:    The calculation of the entropy in both domains of the gaussian distribution and
the exponential distribution.

The Gaussian wave function

5(t)  = (cid:8)(2a/(cid:8)(2))exp[-a2%t2]
4(s) = ,5(t)exp[-i2%st]dt = (1/a)(cid:8)(2a/(cid:8)(2))exp[-%s2/a2]

5*(t)5(t) = (2a/(cid:8)(2))exp[-2a2%t2]
4*(s)4(s) = ((cid:8)(2)/a)exp[-2%s2/a2]

((cid:140)t)2 = ,t2 5*(t)5(t)dt = 1/(4a2%)
((cid:140)s)2 = ,s2 4*(s)4(s)ds = a2/(4%)
((cid:140)s)2((cid:140)t)2 = 1/(4%)2

h(5*(t)5(t)) = -,5*(t)5(t) ln[5*(t)5(t)]dt
= ,(2a/(cid:8)(2))exp[-2a2%t2](2a2%t2)dt - ,(2a/(cid:8)(2))exp[-2a2%t2]ln[(2a/(cid:8)(2))]dt
= 2a2%/(4a2%) - (½)ln[2a2]
= (½)ln[e] + (½)ln[2%((cid:140)t)2]
= (½)ln[2%e((cid:140)t)2]

h(4*(s)4(s)) = -,4*(s)4(s) ln[4*(s)4(s)]ds
= (½)ln[2%e((cid:140)s)2]

h(5*(t)5(t)) + h(4*(s)4(s)) = (½)ln[(2%e)2((cid:140)s)2((cid:140)t)2]
= (½)ln[(e/2)2] = ln[e/2] nats

Adding the extra bit from the symmetry of the gaussian gives

Igaussian = h(5*(t)5(t)) + h(4*(s)4(s)) + ln[2] 
= ln[e/2] + ln[2] = 1 nat

The exponential wave function

5(t)  = a½$exp [-a$t/2] for t (cid:7) 0
4(s) = ,5(t)exp[-i2%st]dt = (2/a½)$[1 - i$4%$s/a]/[1 + (4%$s/a)2]

5*(t)5(t) = a$exp[-a$t] for t (cid:7) 0

4*(s)4(s) = (4/a)/[1 + (4%$s/a)2]       Cauchy distribution             

h(5*(t)5(t)) = -,5*(t)5(t) ln[5*(t)5(t)]dt

= ,0

(cid:23) a$exp[-a$t]$[a$t + ln[1/a]]$dt

h(4*(s)4(s)) = -,4*(s)4(s) ln[4*(s)4(s)]ds

(cid:23) (4/a)/[1 + (4%$s/a)2]$ln[a$(1 + (4%$s/a)2)/4]ds

= ,(cid:23)

= ln[e/a]

= ln[a]

h(5*(t)5(t)) + h(4*(s)4(s)) = ln[e/a] + ln[a] = 1 nat

Appendix D:    Probability distribution, as a function of x, on a circular measurement screen in
the two silt experiment.  The diagram in the regular text shows the parameter a as the extent of
the slits, parameter b as the distance between the slits, parameter (cid:27) as the wavelength of the wave
train, (cid:21) as the angle away from the normal, and x as r$sin((cid:21)).  If an event occurs such that we can
distinguish which slit the particle went throuh, the wave will act as if it only saw one slit.  The
resulting intensity, or probability, of a normally incident wave as measured on a measurement
screen at an angle (cid:21), will be uniform in the limit that the slit has zero extent.15

If an event does not occur, such that it is not possible to determine which slit the particle went
through, the wave acts as if it sees both slits.  The intensity for a normally incident wave on two
slits that are a length b apart will be sinusoidal in x in the limit that the extent of each slit goes to
zero.16

Probability (cid:8) Intensity (cid:8) (sin(u)/u)2
where u = % (a/(cid:27))sin((cid:21))

 as a (cid:25) 0
Probability (cid:8) 1

Probability (cid:8) Intensity (cid:8) (sin(u)/u)2Cos2(v)
where u = % (a/(cid:27))sin((cid:21)),
v = % (b/(cid:27)sin((cid:21)),
and x = r sin((cid:21))

as a (cid:25) 0
Probability (cid:8) Cos2(% (b/(cid:27))(x/r))

5HIHUHQFHV(cid:29)
(cid:20)(cid:17)

7KH(cid:3)3ULQFLSOHV(cid:3)RI(cid:3)4XDQWXP(cid:3)0HFKDQLFV(cid:15)(cid:3)(cid:23)WK (GLWLRQ
3(cid:17)(cid:3)$(cid:17)(cid:3)0(cid:17)(cid:3)’LUDF(cid:15)(cid:3)2[IRUG(cid:3)8QLYHUVLW\(cid:3)3UHVV(cid:15)(cid:3)(cid:20)(cid:28)(cid:24)(cid:27)(cid:3)(cid:3)(cid:134)(cid:3)(cid:21)(cid:21)(cid:16)(cid:21)(cid:23)

(cid:21)(cid:17)

‡&HUWDLQ(cid:3)IDFWRUV(cid:3)DIIHFWLQJ(cid:3)7HOHJUDSK(cid:3)VSHHG·
+(cid:17)(cid:3)1\TXLVW(cid:15)(cid:3)%HOO(cid:3)6\VWHPV(cid:3)7HFK(cid:17)(cid:3)-(cid:17)(cid:15)(cid:3)(cid:20)(cid:28)(cid:21)(cid:23)(cid:15)(cid:3)(cid:22)(cid:15)(cid:3)SS(cid:17)(cid:3)(cid:22)(cid:21)(cid:23)(cid:17)

(cid:22)(cid:17)

(cid:23)(cid:17)

(cid:24)(cid:17)

(cid:25)(cid:17)

(cid:26)(cid:17)

(cid:27)(cid:17)

(cid:28)(cid:17)

(cid:20)(cid:19)(cid:17)

(cid:20)(cid:20)(cid:17)

(cid:20)(cid:21)(cid:17)

(cid:20)(cid:22)(cid:17)

(cid:20)(cid:23)(cid:17)

(cid:20)(cid:24)(cid:17)

‡7UDQVPLVVLRQ(cid:3)RI(cid:3),QIRUPDWLRQ·
5(cid:17)(cid:3)9(cid:17)(cid:3)/(cid:17)(cid:3)+DUWOH\(cid:15)(cid:3)(cid:3)%HOO(cid:3)6\VWHPV(cid:3)7HFK(cid:17)(cid:3)-(cid:17)(cid:15) (cid:20)(cid:28)(cid:21)(cid:27)(cid:15)(cid:3)(cid:26)(cid:15)(cid:3)SS(cid:17)(cid:24)(cid:22)(cid:24)(cid:17)(cid:3)

6FLHQFH(cid:3)DQG(cid:3),QIRUPDWLRQ(cid:3)7KHRU\(cid:15)(cid:3)(cid:21)QG (GLWLRQ
/HRQ(cid:3)%ULOORXLQ(cid:15)(cid:3)$FDGHPLF(cid:3)3UHVV(cid:3),QF(cid:17)(cid:15)(cid:3)(cid:20)(cid:28)(cid:25)(cid:21)

)XQGDPHQWDOV(cid:3)RI(cid:3)6WDWLVWLFDO(cid:3)DQG(cid:3)7KHUPDO(cid:3)3K\VLFV
)(cid:17)(cid:3)5HLI(cid:15)(cid:3)0F*UDZ(cid:16)+LOO(cid:15)(cid:3),QF(cid:17)(cid:3)(cid:20)(cid:28)(cid:25)(cid:24)(cid:17)(cid:3)(cid:3)SS(cid:17)(cid:3)(cid:21)(cid:23)(cid:27)(cid:16)(cid:21)(cid:24)(cid:21)

‡:KLFK(cid:3)3URFHVVHV(cid:3)6DWLVI\(cid:3)WKH(cid:3)6HFRQG(cid:3)/DZ"·
7KRPDV(cid:3)0(cid:17)(cid:3)&RYHU(cid:15)(cid:3)6WDQIRUG(cid:3)8QLYHUVLW\
Chapter in "Physical Origins of Time Asymmetry"
J. J. Halliwell, J. Perez-Mercader & W. H. Zurek, eds.,
Cambridge University Press, 1994  Chapter 5

6FLHQFH(cid:3)DQG(cid:3),QIRUPDWLRQ(cid:3)7KHRU\(cid:15)(cid:3)(cid:21)QG (GLWLRQ
/HRQ(cid:3)%ULOORXLQ(cid:15)(cid:3)$FDGHPLF(cid:3)3UHVV(cid:3),QF(cid:17)(cid:15)(cid:3)(cid:20)(cid:28)(cid:25)(cid:21)(cid:15)(cid:3)SS(cid:17)(cid:3)(cid:26)(cid:24)(cid:15)(cid:26)(cid:25)

(OHPHQWV(cid:3)RI(cid:3),QIRUPDWLRQ(cid:3)7KHRU\
7KRPDV(cid:3)0(cid:17)(cid:3)&RYHU(cid:3)(cid:9)(cid:3)-R\(cid:3)$(cid:17)(cid:3)7KRPDV(cid:15)(cid:3)
-RKQ(cid:3):LOH\(cid:3)(cid:9)(cid:3)6RQV(cid:15)(cid:3),QF(cid:17)(cid:3)(cid:20)(cid:28)(cid:28)(cid:20)(cid:17)(cid:3)(cid:3)SS(cid:17)(cid:3)(cid:3)(cid:20)(cid:25)(cid:19)

4XDQWXP(cid:3)0HFKDQLFV(cid:15)(cid:3)(cid:21)QG (GLWLRQ
/(cid:17)(cid:3)6FKLII(cid:15)(cid:3)0F*UDZ(cid:16)+LOO(cid:15)(cid:3),QF(cid:17)(cid:3)(cid:20)(cid:28)(cid:24)(cid:24)(cid:17)(cid:3)(cid:3)SS(cid:17)(cid:3)(cid:25)(cid:19)(cid:16)(cid:25)(cid:26)

‡3UHSDUDWLRQ(cid:15)(cid:3)PHDVXUHPHQW(cid:3)DQG(cid:3)LQIRUPDWLRQ(cid:3)FDSDFLW\(cid:3)RI(cid:3)RSWLFDO(cid:3)TXDQWXP(cid:3)VWDWHV·
<(cid:17)(cid:3)<DPDPRWR(cid:3)DQV(cid:3)+(cid:17)(cid:3)$(cid:17)(cid:3)+DXV(cid:15)(cid:3)5HYLHZ(cid:3)RI(cid:3)0RGHUQ(cid:3)3K\VLFV(cid:15)(cid:3)2FWREHU(cid:3)(cid:20)(cid:28)(cid:27)(cid:25)(cid:15)(cid:3)9RO(cid:17)(cid:3)(cid:24)(cid:27)(cid:15)(cid:3)1R(cid:17)(cid:3)(cid:23)

7KH(cid:3)0DWKHPDWLFDO(cid:3)7KHRU\(cid:3)RI(cid:3)&RPPXQLFDWLRQ
&(cid:17)(cid:3)((cid:17)(cid:3)6KDQQRQ(cid:3)DQG(cid:3):(cid:17)(cid:3):HDYHU(cid:15)(cid:3)(cid:3)7KH(cid:3)8QLYHUVLW\(cid:3)RI(cid:3),OOLQRLV(cid:3)3UHVV(cid:15)(cid:3)8UEDQD(cid:3),O(cid:17)(cid:15)(cid:3)(cid:20)(cid:28)(cid:24)(cid:28)(cid:17)

‡7KHRU\(cid:3)RI(cid:3)&RPPXQLFDWLRQ·
’(cid:17)(cid:3)*DERU(cid:15)(cid:3)(cid:3)-(cid:17)(cid:3),QVW(cid:17)(cid:3)(OHF(cid:17)(cid:3)(QJUV(cid:17)(cid:15)(cid:3)(cid:20)(cid:28)(cid:23)(cid:25)(cid:15)(cid:3)(cid:28)(cid:22)(cid:15)(cid:3),,,(cid:3)S(cid:17)(cid:23)(cid:21)(cid:28)

‡3URODWH(cid:3)6SKHURLGDO(cid:3):DYH(cid:3))XQFWLRQV(cid:15)(cid:3))RXULHU(cid:3)$QDO\VLV(cid:3)DQG(cid:3)8QFHUWDLQW\(cid:3)(cid:16)(cid:3),,,(cid:29)(cid:3)7KH
’LPHQVLRQ(cid:3)RI(cid:3)WKH(cid:3)6SDFH(cid:3)RI(cid:3)(VVHQWLDOO\(cid:3)7LPH(cid:16)(cid:3)DQG(cid:3)%DQG(cid:16)/LPLWHG(cid:3)6LJQDOV·
+(cid:17)(cid:3)-(cid:17)(cid:3)/DQGDX(cid:3)DQG(cid:3)+(cid:17)(cid:3)2(cid:17)(cid:3)(cid:3)3ROODN(cid:15)(cid:3)%HOO(cid:3)6\VWHPV(cid:3)7HFK(cid:17)(cid:3)-(cid:17)(cid:15)(cid:3)(cid:20)(cid:28)(cid:25)(cid:21)(cid:15)(cid:3)(cid:23)(cid:20)(cid:15)(cid:3)SS(cid:17)(cid:3)(cid:20)(cid:21)(cid:28)(cid:24)(cid:16)(cid:20)(cid:22)(cid:22)(cid:25)

The Fourier Transform and Its Application
Ronald Bracewell, McGraw-Hill, Inc. 1986.  pp.160,161

3K\VLFV(cid:3)RI(cid:3):DYHV
:LOOLDP(cid:3)&(cid:17)(cid:3)(OPRUH(cid:3)(cid:9)(cid:3)0DUN(cid:3)$(cid:17)(cid:3)+HDOG(cid:15)(cid:3)(cid:3)
0F*UDZ(cid:16)+LOO(cid:15)(cid:3),QF(cid:17)(cid:3)(cid:20)(cid:28)(cid:25)(cid:28)(cid:17)(cid:3)(cid:3)SS(cid:17)(cid:3)(cid:22)(cid:24)(cid:20)(cid:16)(cid:22)(cid:24)(cid:23)

(cid:20)(cid:25)(cid:17)

LELG(cid:15)(cid:3)(cid:3)SS(cid:17)(cid:3)(cid:22)(cid:25)(cid:24)(cid:16)(cid:22)(cid:25)(cid:26)

