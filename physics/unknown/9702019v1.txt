7
9
9
1
 
b
e
F
 
9
1
 
 
]
h
p
-
h
t
a
m

[
 
 
1
v
9
1
0
2
0
7
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

INTEGRATION OVER A GENERIC
ALGEBRA

R. Casalbuoni
Dipartimento di Fisica, Univ. di Firenze
I.N.F.N., Sezione di Firenze

Firenze Preprint - DFF - 270/02/1997

ABSTRACT

In this paper we consider the problem of quantizing theories de-
ﬁned over conﬁguration spaces described by non-commuting pa-
rameters. If one tries to do that by generalizing the path-integral
formalism, the ﬁrst problem one has to deal with is the deﬁni-
tion of integral over these generalized conﬁguration spaces. This
is the problem we state and solve in the present work, by con-
structing an explicit algorithm for the integration over a general
algebra. Many examples are discussed in order to illustrate our
construction.

1 Introduction

The very idea of supersymmetry leads to the possibility of extending ordi-
nary classical mechanics to more general cases in which ordinary conﬁgura-
tion variables live together with Grassmann variables. More recently the idea
of extending classical mechanics to more general situations has been further
emphasized with the introduction of quantum groups, non-commutative ge-
ometry, etc. In order to quantize these general theories, one can try two ways:
i) the canonical formalism, ii) the path-integral quantization. In refs. [1, 2]
classical theories involving Grassmann variables were quantized by using the
canonical formalism. But in this case, also the second possibility can be
easily realized by using the Berezin’s rule for integrating over a Grassmann
algebra. It would be desirable to have a way to perform the quantization of
theories deﬁned in a general algebraic setting. In this paper we will make a
ﬁrst step toward this construction, that is we will give general rules allowing
the possibility of integrating over a given algebra. Given these rules, the
In order to deﬁne
next step would be the deﬁnition of the path-integral.
the integration rules we will need some guiding principle. So let us start by
reviewing how the integration over Grassmann variables come about. The
standard argument for the Berezin’s rule is translational invariance. In fact,
this guarantees the validity of the quantum action principle. However, this
requirement seems to be too technical and we would rather prefer to rely on
some more physical argument, as the one which is automatically satisﬁed by
the path integral representation of an amplitude, that is the combination law
for probability amplitudes. This is a simple consequence of the factorization
properties of the functional measure and of the additivity of the action. In
turn, these properties follow in a direct way from the very construction of
the path integral starting from the ordinary quantum mechanics. We re-
call that the construction consists in the computation of the matrix element
qf , tf

, (ti < tf ) by inserting the completeness relation

qi, ti

h

|

i

dq

q, t

|

q, t
|

ih

= 1

Z

(1.1)

, N), and taking the limit N

inside the matrix element at the intermediate times ta (ti < ta < tf , a =
1,
(for sake of simplicity we consider
→ ∞
here the quantum mechanical case of a single degree of freedom). The rele-
vant information leading to the composition law is nothing but the complete-

· · ·

3

ness relation (1.1). Therefore we will assume the completeness as the basic
principle to use in order to deﬁne the integrations rules over a generic algebra.
In this paper we will limit our task to the construction of the integrations
rules, and we will not do any attempt to construct the functional integral
in the general case. The extension of the relation (1.1) to a conﬁguration
space diﬀerent from the usual one is far from being trivial. However, we can
use an approach that has been largely used in the study of non-commutative
geometry [4] and of quantum groups [5]. The approach starts from the obser-
vation that in the normal case one can reconstruct a space from the algebra
of its functions . Giving this fact, one lifts all the necessary properties in the
function space and avoids to work on the space itself. In this way one is able
to deal with cases in which no concrete realization of the space itself exists.
We will see in Section 2 how to extend the relation (1.1) to the algebra of
functions. In Section 3 we will generalize the considerations of Section 2 to
the case of an arbitrary algebra. In Section 4 we will discuss numerous ex-
amples of our procedure. The approach to the integration on the Grassmann
algebra, starting from the requirement of completeness was discussed long
ago by Martin [6].

2 The algebra of functions

Let us consider a quantum dynamical system and an operator having a com-
plete set of eigenfunctions. For instance one can consider a one-dimensional
free particle. The hamiltonian eigenfunctions are

ψk(x) =

1
√2π

exp (

ikx)

−

Or we can consider the orbital angular momentum, in which case the eigen-
functions are the spherical harmonics Y m
ℓ (Ω). In general the eigenfunctions
satisfy orthogonality relations

ψ∗

n(x)ψm(x) dx = δnm

Z

(we will not distinguish here between discrete and continuum spectrum).
However ψn(x) is nothing but the representative in the
basis of the eigen-
kets

of the hamiltonian

x
|

h

n
i

|

(2.1)

(2.2)

(2.3)

ψn(x) =

x
|

n
i

h

4

Therefore the eq. (2.2) reads

x

n
|

ih

x
|

m
i

Z h

dx = δnm

x
i

and

which is equivalent to say that the
states form a complete set and that
m
n
are orthogonal. But this means that we can implement the
|
i
|
i
space by means of the orthogonality relation obeyed
completeness in the
by the eigenfunctions deﬁned over this space. Another important observation
is that the orthonormal functions deﬁne an algebra. In fact we can expand
the product of two eigenfunctions in terms of the eigenfunctions themselves

x
i

|

|

with

For instance, in the case of the free particle

ψm(x)ψn(x) =

cnmpψp(x)

n
X

cnmp =

ψn(x)ψm(x)ψ∗

p(x) dx

Z

ckk′k′′ =

1
√2π

δ(k + k′

k′′)

−

In the case of the angular momentum one has the product formula [7]

ℓ1 (Ω)Y m2
Y m1

ℓ2 (Ω) =

ℓ1+ℓ2

+L

XL=|ℓ1−ℓ2|
ℓ1ℓ200

XM =−L "
L0

(2ℓ1 + 1)(2ℓ2 + 1)
4π(2L + 1)

#

|

h

ih

JM

LM

× h

j1j1m1m2|

ℓ1ℓ2m1m2|
are nothing but the Clebsch-Gordan coeﬃcients. A
where
set of eigenfunctions can then be considered as a basis of the algebra (2.5),
with structure constants given by (2.6). Any function can be expanded in
, and therefore it will be convenient, for
terms of the complete set
build up in terms of the
the future, to introduce a generalized Fock space
eigenfunctions

ψn(x)

(2.8)

F

}

{

i

i

Y M
L (Ω)

(2.4)

(2.5)

(2.6)

(2.7)

(2.9)

=

ψ

|

i

ψ0(x)
ψ1(x)

· · ·
ψn(x)

· · ·



















5

(2.10)

(2.11)

(2.12)

(2.13)

(2.14)

(2.15)

(2.16)

(2.17)

A function f (x) such that

can be represented as

where

f (x) =

anψn(x)

n
X

f (x) =

ψ

a
|

h

i

a
|

h

= (a0, a1,

, an,

)
· · ·

· · ·

To write the orthogonality relation in terms of this new formalism it is con-
venient to realize the complex conjugation as a linear operation on
. In
fact, ψ∗

n(x) itself can be expanded in terms of ψn(x)

F

or

Deﬁning a bra in

ψ∗

n(x) =

ψm(x)Cmn

n
X

ψ∗

= C T

ψ

i
as the transposed of the ket

i

|

|

ψ

F

h

|

ψ

= (ψ0(x), ψ1(x),

|

i
(x), ψn(x),

)
· · ·

· · ·

the orthogonality relation becomes

ψ∗

Z |

ih

|

ψ

dx =

C

ψ

ψ

dx = 1

|

ih

|

Z

Notice that by taking the complex conjugate of eq. (2.14), we get

The relation (2.16) makes reference only to the elements of the algebra of
. The previous expression is
functions that we have organized in the space
the key element in order to deﬁne the integrations rules on the algebra. In
fact, we can now use the algebra product to reduce the previous expression
to a linear form

F

δnm =

Cnℓψℓ(x)ψm(x) dx =

Cnℓcℓmp

ψp(x) dx

(2.18)

Xℓ Z

Xℓ,p

Z

CC ∗ = 1

6

If the set of equations

Anmp

ψp(x) dx = δnm, Anmp =

Cnℓcℓmp

(2.19)

Z

p
X
ψp(x) dx, then we are able to deﬁne the integration over
has a solution for
all the algebra, by linearity. We will show in the following that indeed a
solution exists for many interesting cases. However we will not try here to
deﬁne the conditions under which the equations are satisﬁed. Let us just
show what we get for the free particle. The matrix C is easily obtained by
noticing that

Xℓ

R

1
√2π

 

exp(

ikx)

−

∗

!

exp(ikx)

=

=

1
√2π

Z

dk′δ(k + k′)

exp(

ik′x)

(2.20)

1
√2π

−

Ckk′ = δ(k + k′)

(2.21)

Akk′k′′ =

dq δ(k + q)

δ(q + k′

k′′) =

δ(k

k′ + k′′)

(2.22)

1
√2π

1
√2π

−

−

and therefore

It follows

Z

from which

δ(k

k′) =

dk′′

Akk′k′′ψk′′(x)dx =

−

Z

Z

1
2π

Z

exp(

i(k′

−

−

k)x)dx (2.23)

This example is almost trivial, but is shows how, given the structure constants
of the algebra, the property of the exponential of being the Fourier transform
of the delta-function follows automatically from the formalism. In fact, what
we have really done it has been to deﬁne the integration rules by using
only the algebraic properties of the exponential. As a result, our integration
rules require that the integral of an exponential is a delta-function. One can
perform similar steps in the case of the spherical harmonics, where the C
matrix is given by

C(ℓ,m),(ℓ′,m′) = (

1)mδℓ,ℓ′δm,−m′

(2.24)

and then using the constant function Y 0
relation.

0 = 1/√4π, in the completeness

−

7

The procedure we have outlined here is the one that we will generalize
in the next Section to arbitrary algebras. Before doing that we will consider
the possibility of a further generalization. In the usual path-integral formal-
ism sometimes one makes use of the coherent states instead of the position
operator eigenstates. In this case the basis in which one considers the wave
functions is a basis of eigenfunctions of a non-hermitian operator

with

ψ(z) =

ψ

z

|

i

h

z

a
|

i

=

z

z

|

i

(2.25)

(2.26)

The wave functions of this type close an algebra, as
do. But this time
the two types of eigenfunctions are not connected by any linear operation.
In fact, the completeness relation is deﬁned on the direct product of the two
algebras

ψ

i

h

|

z∗

dz∗dz
2πi

exp(

z∗z)

z

z∗

= 1

(2.27)

Z

−
Therefore, in similar situations we will not deﬁne the integration over the
original algebra, but rather on the algebra obtained by the tensor product of
the original algebra times a copy of the algebra itself. The copy corresponds
to the complex conjugated functions of the previous example.

ih

|

|

3 Eigenvalues and eigenvectors for a generic

algebra

Let us start with a generic algebra
In the following we will consider also the case n
multiplication rules

A

with n+1 elements xi with i = 0, 1,

n.
. We assume the

· · ·

→ ∞

xixj = fijkxk

(3.1)

with the usual convention of sum over the repeated indices. The structure
constants fijk deﬁne uniquely the algebraic structure. Consider for instance
the case of an abelian algebra. In this case

xixj = xjxi

fijk = fjik

(3.2)

−→

8

(3.3)

(3.4)

(3.5)

(3.6)

(3.7)

The associativity condition reads

leading to the condition

xi(xjxk) = (xixj)xk

filmfjkl = fijlflkm

f (a, x) =

aixi

n

i=0
X

We will make use of this equation in the following. An algebra being a vector
space, the most general function on the algebra (that is a mapping
)
is a linear one:

A → A

Of course, this relation deﬁnes a mapping between the n + 1 dimensional
row-vectors and the functions on the algebra, that is a mapping between

n+1 and

C

.

A

a

(a0, a1,

, an)

f (xi)

| ≡
By proceeding as in Section 2 we introduce the space
in terms of the generators of the algebra

←→

· · ·

h

F

of vectors build up

=

x
i

|

x

|

i ∈ F

x0
x1

·
·xn













,













a

h

| ←→ h

a
|

x
i

x′

|

i

= O

x
i

|

F
a′

9

The mapping (3.6) becomes

The action of a linear operator on

is induced by its action on

a′

h

|

=

O

a
|

h

←→ h

=

x
i

|

O

a
|

h

x
i

|

=

x′

a
|

h

i

where

In order to be able to generalize properly the discussion of Section 2 it will
be of fundamental importance to look for linear operators having the vectors

n+1

C

(3.8)

(3.9)

(3.10)

as eigenvectors and the algebra elements xi as eigenvalues. As we shall
x
|
i
see this notion is strictly related to the mathematical concept of right and
left multiplication algebras associated to a given algebra. The linear
operators we are looking for are deﬁned by the relation

that is

or

Xi

x
i

|

=

xi

x
i

|

(Xi)jkxk = xjxi = fjikxk

(Xi)jk = fjik

To relate this notion to the right multiplication algebra, let us consider the
right multiplication of an arbitrary element of the algebra by a generator

xi = f (a, x)xi =

ajxjxi =

ajfjikxk

a
|

x
i

h

j
X
ai(Xi)jkxk = f (aXi, x) =

j
X

aXi

x
i

|

h

=

=

j
X
a
|

h

(Xi)

x
i

|

from which the (3.11) follows. Therefore the matrices Xi correspond to the
linear transformations induced on the algebra by the right multiplication by
the element xi. In a complete analogous way we can consider column vectors
a
i

, and deﬁne a function on the algebra as

|

g(x, b) =

= ( x0, x1,

˜x
|

b
i

h

b0
b1

·
·








··

, xn ) 





=

xibi

i
X

Now let us consider the left multiplication

xig(x, b) = xi

˜x
|

b
i

h

=

fijkxkbj

Xj

Deﬁning

(3.11)

(3.12)

(3.13)

(3.14)

(3.15)

(3.16)

(3.17)

(Πi)kj = fijk

10

(3.18)

(3.19)

we get

therefore

xig(x, b) =

xk(Πi)kjbj = g(x, Πib) =

Πi

˜x
|

h

b
i

|

Xj

Πi = xi

˜x
|

h

˜x
|

h

The two matrices Xi and Πi corresponding to right and left multiplication
are generally diﬀerent:

(Xi)jk = fjik,

(Πi)jk = fikj

(3.20)

In terms of the matrices Xi and Πi one can characterize diﬀerent algebras.
For instance, consider the abelian case. It follows from eq. (3.2)

Xi = ΠT
i

(3.21)

If the algebra is associative, then from (3.4) the following three relations can
be shown to be equivalent:

XiXj = fijkXk, ΠiΠj = fijkΠk,

[Xi, ΠT

j ] = 0

(3.22)

The ﬁrst two say that Xi and Πi are linear representations of the algebra. The
third that the right and left multiplication commute for associative algebras.
Recalling the discussion in Section 2 we would like ﬁrst consider the case
of a basis originating from hermitian operators. Notice that the generators
xi play here the role of generalized dynamical variables. It is then natural
to look for the case in which the operators Xi admit both eigenkets and
eigenbras. This will be the case if

that is Πi and Xi are connected by a non-singular C matrix. This matrix is
exactly the analogue of the matrix C deﬁned in eq. (2.14). From (3.19), we
get

Πi = CXiC −1

CXiC −1 = xi

˜x
|

h

˜x
|

h

=

x
|

h

C

˜x
|

h

Xi = xi

x
|

h

x
|

h

11

(3.23)

(3.24)

(3.25)

(3.26)

By putting

we have

In this case, the equations (3.11) and (3.26) show that Xi is the analogue of
an hermitian operator. We will deﬁne now the integration over the algebra
by requiring that

where 1 the identity matrix on the (n + 1)
of the linear mappings on the algebra. In more explicit terms we get

(n + 1)dimensional linear space

×

x

x
|

ih

= 1

Z(x) |

xi(xkCkj) = δij

xixj = (C −1)ij

fijkxk = (C −1)ij

Z(x)

Z(x)

Z(x)

x′
i = Sijxj

ix′
x′

j = fijkx′
k

SilSjmflmp = fijkSkp

12

or

as well as

with

(x) xi, we can say to have deﬁned
If we can invert this relation in terms of
the integration over the algebra, because we can extend the operation by
R
linearity.

We will discuss now the variation of the measure of integration with re-
spect to an automorphism of the algebra. In particular, we will restrict our
analysis to the case of a simple algebra (that is an algebra having as ideals
only the algebra itself and the null element). Let us consider an invertible
linear transformation on the basis of the algebra leaving invariant the multi-
plication rules (that is an automorphism)

This implies the following conditions for the transformation S

This relation can be written in a more convenient form in terms of the ma-
trices Xi and Πi

SXiS−1 = (S−1)ijXj, ST −1ΠiST = (S−1)ijΠj

(3.34)

(3.27)

(3.28)

(3.29)

(3.30)

(3.31)

(3.32)

(3.33)

In the case we are considering here Xi and Πi are related by the C matrix
(see eq. (3.23), and therefore we get

(C −1ST −1C)Xi(C −1ST C) = SXiS−1

(3.35)

In the case of a simple Lie algebra, one can show that the enveloping algebra
of the right and left multiplications forms an irreducible set of linear operators
[8], and therefore by the Shur’s lemma we obtain

C −1ST C = kS−1

where k is a constant. It follows

x

h

| → h

˜x
|

ST C = k

CS−1 = k

˜x
|

h

S−1

x
|

h

Now we require

which is satisﬁed by taking

x′

x′

ih

|

=

x

x
|

ih

Z(x) |

Z(x′) |

=

1
k Z(x)

Z(x′)

In fact

x′

x′

ih

|

=

Z(x′) |

1
k Z(x)

S

k

x
i

|

x
|

h

S−1 = 1

Of course it may happen that the C matrix does not exist. This would
correspond to the case of non-hermitian operators discussed in Section 2. So
∗, the
we look for a copy
corresponding generators will satisfy

∗ of the algebra. By calling x∗ the elements of

A

A

It follows

h
Then, we deﬁne the integration rules on the tensor product of
such a way that the completeness relation holds

|

|

and

∗ in

A

A

i x∗
x∗

j = fijkx∗
k

˜x∗

Πi = x∗
i h

˜x∗

˜x∗

x

ih

|

= 1

Z(x,x∗) |

13

(3.36)

(3.37)

(3.38)

(3.39)

(3.40)

(3.41)

(3.42)

(3.43)

or

xix∗

j = δij

Z(x,x∗)

(3.44)

This second type of integration is invariant under orthogonal transformation
or unitary transformations, according to the way in which the ∗ operation
acts on the transformation matrix S. If ∗ acts on complex numbers as the
ordinary conjugation, then we have invariance under unitary transformations,
otherwise if ∗ leaves complex numbers invariant, then the invariance is under
orthogonal transformations. Notice that the invariance property does not
depend on S being an automorphism of the original algebra or not.

The two cases considered here are not mutually exclusive. In fact, there

are situations that can be analyzed from both points of view.

We want also to emphasize that this approach does not pretend to be
complete and that we are not going to give any theorem about the classiﬁ-
cation of the algebras with respect to the integration. What we are giving is
rather a set of rules that one can try to apply in order to deﬁne an integration
over an algebra. As argued before, there are algebras that do not admit the
integration as we have deﬁned in (3.29) or in (3.44). Consider, for instance,
a simple Lie algebra. In this case we have the relation

which implies

or C = 1. Then the eq. (3.29) requires

fijk = fjki

Xi = Πi

δij =

xixj =

fijkxk

Z(x)

Z(x)

which cannot be satisﬁed due to the antisymmetry of the structure constants.
Therefore, we can say that, according to our integration rules, there are
algebras with a complete set of states and algebras which are not complete.

4 Examples

In this Section we will discuss several examples of both types of integration.

(3.45)

(3.46)

(3.47)

14

4.1 The bosonic case

We will start trying to reproduce the integration rules in the bosonic case.
It is convenient to work in the coherent state basis. The coherent states are
deﬁned by the relation

where a is the annihilation operator, [a, a†] = 1. The representative of a state
at ﬁxed occupation number in the coherent state basis is

So we will consider as elements of the algebra the quantities

xi =

zi
√i!

,

i = 0, 1,

,

· · ·

∞

The states in

are therefore

F

z

a
|

i

=

z

z

|

i

z

n
|

h

i

=

zn
√n!

1
z
z2/√2!










·
·










The algebra is deﬁned by the multiplication rules

xixj =

= xi+j

zi+j
√i! j!

(i + j)!
i! j!

s

from which

It follows

and

fijk = δi+j,k

k!
i! j!

s

k!
i! j!

s

j!
i! k!

s

(Xi)jk = δi+j,k

(Πi)jk = δi+k,j

15

(4.1)

(4.2)

(4.3)

(4.4)

(4.5)

(4.6)

(4.7)

(4.8)

In particular we get

(X1)jk = √k δj+1,k,

(Π1)jk = √k + 1 δj−1,k

(4.9)

Therefore X1 and Π1 are nothing but the representative, in the occupation
number basis, of the annihilation and creation operators respectively.
It
follows that the C matrix cannot exist, because [X1, Π1] = 1, and a unitary
transformation cannot change this commutation relation into [Π1, X1] =
1.
For an explicit proof consider, for instance, X1

−

0 √1
0
0

0
0 √2
0

0
0
0 √3

X1 =










· · ·
· · ·
· · ·
· · ·
· · ·










·
·
If the matrix C would exist it would be possible to ﬁnd states

·
·

·
·

·
·

such that

z

h

|

z

X1 = (0, f0(z), √2f1(z),

) = (zf0(z), zf1(z), zf2(z),

(4.13)

)
· · ·

· · ·

f0(z) = f1(z) = f2(z) =

= 0

· · ·

Now, having shown that no C matrix exists, we will consider the complex
conjugated algebra with generators constructed in terms of z∗, where z∗ is
the complex conjugate of z. Then the equation

with

This would mean

|
h
which implies

is satisﬁed by

z

X1 = z

z

h

|

h

|

z

h

|

= (f0(z), f1(z),

)
· · ·

˜z∗

Πi = z∗
i h

|

˜z∗

|

h

˜z∗

h

|

= (1,

z∗
√1!

,

z∗2
√2!

,

)
· · ·

16

(4.10)

(4.11)

(4.12)

(4.14)

(4.15)

(4.16)

and the integration rules give

ziz∗j
√i!j!

= δi,j

Z(z,z∗)

Z(z,z∗)

=

Z

dz∗dz
2πi

exp(

z

2)

−|

|

We see that our integration rules are equivalent to the gaussian integration

Another interesting example is again the algebra of multiplication of the

complex numbers but now deﬁned also for negative integer powers

znzm = zn+m,

− ∞ ≤

n, m

+

≤

∞

with z restricted to the unit circle

Deﬁning the vectors in

as

F

z∗ = z−1

=

z

|

i

·z−i

·1
z

·zi

·



































Xi = zi

z

h

|

z

h

|

the Xi and Πi matrices are given by

(Xi)ij = δi+j,k,

(Πi)ij = δi+k,j

(4.22)

and now we can construct a C matrix connecting these two set of matrices.
This is easier seen by looking for a bra which is eigenvector of Xi

In components, by putting

= (

z

h

|

· · ·

, f−i(z),

, f0(z),

, fi(z),

· · ·

)
· · ·

· · ·

17

(4.17)

(4.18)

(4.19)

(4.20)

(4.21)

(4.23)

(4.24)

we get

This equation has the solution

fj(z)(Xi)jk = fj(z)δi+j,k = fk−i(z) = zifk(z)

(4.25)

fi(z) = z−i

therefore

|
The matrix C is given by

h

z

= (

, zi,

· · ·

, 1,

· · ·

· · ·

, z−i,

)
· · ·

or. more explicitly by

(C)ij = (C −1)ij = δi,−j

C =

·
·
·
·
·










·
0
0
1

·

·
·
0 1
1 0
0 0

·

·

·
·
·
·
·










(CΠiC −1)lp = δl,−mδi+n,mδn,−p = δi−p,−l = δi+l,p = (Xi)lp

(4.30)

Notice that the C matrix is nothing but the representation in
complex conjugation (z

of the
z∗ = z−1). The completeness relation reads now

F

→

In fact

from which

Our algebraic deﬁnition of integral can be interpreted as an integral along a
circle C around the origin. In fact we have

(4.26)

(4.27)

(4.28)

(4.29)

(4.31)

(4.32)

(4.33)

ziz−j = δij

Z(z)

zk = δk0

Z(z)

=

1
2πi ZC

dz
z

Z(z)

18

4.2 The fermionic case

We will discuss now the case of the Grassmann algebra
1, θ, such that θ2 = 0. The multiplication rules are

G1, with generators

θiθj = θi+j,

i, j, i + j = 0, 1

(4.34)

and zero otherwise (see Table 1).

1
1
θ

θ
θ
0

1
θ

Table 1: Multiplication table for the Grassmann algebra

G1.

From the multiplication rules we get the structure constants

fijk = δi+j,k,

i, j, k = 0, 1

(4.35)

from which the explicit expressions for the matrices Xi and Πi follow

(X0)ij = fi0j = δi,j =

(X1)ij = fi1j = δi+1,j =

(Π0)ij = f0ji = δi,j =

(cid:18)

(cid:18)

1 0
0 1 (cid:19)
1
0
0 (cid:19)
0
(cid:18)
1 0
0 1 (cid:19)
0
0
0 (cid:19)
1

(cid:18)

(Π1)ij = f1ji = δi,j+1 =

(4.36)

Notice that X1 and Π1 are nothing but the ordinary annihilation and creation
= (1, 0). The C matrix
Fermi operators with respect to the vacuum state
exists and it is given by

0

i

|

(cid:18)
The ket and the bra eigenvectors of Xi are

(C)ij = δi+j,1 =

0 1
1 0 (cid:19)

=

θ

|

i

1
θ (cid:19)

,

(cid:18)

= (θ, 1)

θ

h

|

19

(4.37)

(4.38)

and the completeness reads

or

which means

θ

θ

=

ih

|

ZG1 |

ZG1 (cid:18)

θ
0

1
θ (cid:19)

=

1 0
0 1 (cid:19)

(cid:18)

θiθ1−j = δi,j

ZG1

1 = 0,

θ = 1

(4.39)

(4.40)

(4.41)

ZG1

The case of a Grassmann algebra

ZG1
n, which consists of 2n elements ob-
tained by n anticommuting generators θ1, θ2,
, θn, the identity, 1, and by
all their products, can be treated in a very similar way. In fact, this algebra
can be obtained by taking a convenient tensor product of n Grassmann al-
gebras
G1, which means that the eigenvectors of the algebra of the left and
right multiplications are obtained by tensor product of the eigenvectors of
eq. (4.38). The integration rules extended by the tensor product give

· · ·

G

θ1θ2 · · ·

θn = 1

ZGn

(4.42)

G2 because it can be obtained by tensor product of

and zero for all the other cases, which is equivalent to require for each copy
G1 the equations (4.41). It is worth to mention the case of the Grassmann
of
G1 times a copy
algebra
∗
1 . Then we can apply our second method of getting the integration rules
G
and show that they lead to the same result with a convenient interpretation
G2 is generated by θ1, θ2. An involution of the
of the measure. The algebra
algebra is given by the mapping

∗ :

θ2

θ1 ↔
with the further rule that taking the ∗ of a product one has to exchange the
order of the factors. It will be convenient to put θ1 = θ, θ2 = θ∗. This allows
G1,∗). Then the ket and bra eigenvectors of
∗
(
us to consider
1 ≡
∗
1 respectively are given by
G1 and
left and right multiplication in
1
θ (cid:19)

= (1, θ∗)

G2 as

G1 ⊗ G

(4.43)

(4.44)

˜θ∗

=

G

(cid:18)

θ

h

i

|

|

,

20

with

h
The completeness relation reads

|

˜θ∗

Πi = θ∗i

˜θ∗

h

|

θ

˜θ∗

ih

|

=

Z(G1,∗) |

Z(G1,∗) (cid:18)

1
θ

θ∗
θθ∗

=

(cid:19)

(cid:18)

1 0
0 1 (cid:19)

This implies

1 =

θ =

Z(G1,∗)

Z(G1,∗)

Z(G1,∗)

Z(G1,∗)

θθ∗ = 1

θ∗ = 0

(4.45)

(4.46)

(4.47)

These relations are equivalent to the integration over
identiﬁcation

=

exp(

θ∗θ)

G2 if we do the following
(4.48)

2)
Notice that the factor exp(
appearing in the gaussian measure of (4.18). In fact it has the same origin,
coming out of the norm

Z(G1,∗)
θ∗θ) plays the same role of the factor exp(

ZG2

−|

−

z

|

−

˜θ∗

h

θ

|

i

= 1 + θ∗θ = exp(θ∗θ)

(4.49)

4.3 The case of parastatistics

p
We will discuss now the case of a paragrassmann algebra of order p,
1 , with
generators 1, and θ, such that θp+1 = 0. The multiplication rules are deﬁned
by

G

θiθj = θi+j,

i, j, i + j = 0,

, p

(4.50)

and zero otherwise (see Table 2).

From the multiplication rules we get the structure constants

fijk = δi+j,k,

i, j, k = 0, 1,

, p

(4.51)

from which we obtain the following expressions for the matrices Xi and Πi:

(Xi)jk = δi+j,k,

(Πi)jk = δi+k,j,

i, j, k = 0, 1

, p

(4.52)

· · ·

· · ·

· · ·

21

1
1
θ

1
θ

·
θp−1
θp

·
θp−1
θp

θ
θ
θ2

·
θp
0

θp−1
θp−1
θp

·
0
0

θp
θp
0

·
0
0

·
·
·
·
0
0

Table 2: Multiplication table for the paragrassmann algebra

p
1 .

G

In analogy with the Grassmann algebra we can construct the C matrix

(C)ij = δi+j,p

(4.53)

In fact

(CXiC −1)lq = δl+m,pδi+m,nδn+q,p = δi+p−l,p−q = δi+q,l = (Πi)lq

(4.54)

The ket and the bra eigenvectors of Xi are given by

θ

= 




and the completeness reads

i

|

1
θ



,

·
θp






θ

h

|

= (θp,

, θ, 1)

· · ·

which means

θiθp−j = δij

ZGp

1

θp−1 = 0

1 =

θ =

ZGp

1

ZGp

1

1

ZGp
θp = 1

ZGp

1

in agreement with the results of ref. [6] (see also [9]).

(4.55)

(4.56)

(4.57)

(4.58)

22

4.4 The algebra of quaternions

The quaternionic algebra is deﬁned by the multiplication rules

eAeB =

δAB + ǫABCeC, A, B, C = 1, 2, 3

(4.59)

where ǫABC is the Ricci symbol in 3 dimensions. The quaternions can be
iσA. The automorphism group
realized in terms of the Pauli matrices eA =
of the quaternionic algebra is SO(3), but it is more useful to work in the so
called split basis

−

u0 =

(1 + ie3),

u∗
0 =

(1

ie3)

1
2
1
2

−
(e1 −

u+ =

(e1 + ie2),

u− =

ie2)

(4.60)

−

1
2
1
2

In this basis the multiplication rules are given in Table 3.

u0
u0
0
0
u−

u0
u∗
0
u+
u−

u∗
0
0
u∗
0
u+
0

u+
u+
0
0
u∗
0

−

u−
0
u−
u0
0

−

Table 3: Multiplication table for the quaternionic algebra.

The automorphism group of the split basis is U(1), with u0 and u∗
and u+ and u− with charges +1 and

1 respectively. The vectors in

0 invariant
are

F

|

u



= 




The matrices XA and ΠA satisfy the quaternionic algebra because this is an
associative algebra. So X+ and X− satisfy the algebra of a Fermi oscillator
It is easy to get explicit expressions for the left and right
(apart a sign).

(4.61)






i

−

u0
u∗
0
u+
u−

23

multiplication matrices and check that the C matrix exists and that it is
given by

1 0
0 1
0 0
0 0

0
0
0
1
−

0
0
1
−
0








C = 





= (u0, u∗
0,

u

h

|

u−,

u+)

−

−

Therefore

The exterior product is given by

u

u

|

ih

|

(u0, u∗
0,

u−,

u+)

−

−








u0
u∗
0
u+
u−
u0
0
0
u−

= 





= 





0
u∗
0 −
u+
0

0
u−
u0
0

u+
−
0
0
u∗
0








According to our integration rules we get

u0 =

Z(u)

Z(u)

u∗
0 = 1,

Z(u)

Z(u)

u+ =

u− = 0

(4.65)

In terms of the original basis for the quaternions we get

1 = 2,

ei = 0

Z(u)

Z(u)

and we see that, not unexpectedly, the integration coincides with taking
the trace in the 2
2 representation of the quaternions. That is, given an
arbitrary functions f (u) on the quaternions we get

×

f (u) = T r[f (u)]

Z(u)

By considering the scalar product

u′

u

|

i

h

= u′

0u0 + u∗
0

′u0 −

u∗
−

′u+ −

+u∗
u′
−

24

(4.62)

(4.63)

(4.64)

(4.66)

(4.67)

(4.68)

we see that

and

u′

u

|

i

h

= 2

u′

u

|

i

Z(u)h

= u′

0 + u∗
0

′ = 1

(4.69)

(4.70)

Therefore

behaves like a delta-function.

u′

u

|

i

h

4.5 The algebra of octonions

We will discuss now how to integrate over the octonionic algebra (see [10]).
This algebra (said also a Cayley algebra) is deﬁned in terms of the multipli-
cation table of its seven imaginary units eA

eAeB =

δAB + aABCeC, A, B, C = 1,

, 7

(4.71)

· · ·

where aABC is completely antisymmetric and equal to +1 for (ABC) =
(1, 2, 3), (2,4,6), (4,3,5), (3,6,7), (6,5,1), (5,7,2) and (7,1,4). The automor-
phism group of the algebra is G2. We deﬁne also in this case the split basis
as

u0 =

(1 + ie7),

ui =

(ei + iei+3),

u∗
0 =

u∗
i =

1
2
1
2

(1

ie7)

−

(ei

iei+3)

−

(4.72)

where i = 1, 2, 3. In this basis the multiplication rules are given in Table 4.

u0
u∗
0
ui
u∗
i

u∗
0
0
u∗
0
ui
0

uj
uj
0
ǫijku∗
k −
δiju∗
0

u∗
j
0
u∗
j
δiju0
ǫijkuk

−

Table 4: Multiplication table for the octonionic algebra.

−

1
2

1
2

u0
u0
0
0
u∗
i

This algebra is non-associative and in the split basis it has an automorphism
group SU(3). The non-associativity can be checked by taking, for instance,

ui(uju∗

k) = ui(

δjku0) = 0

(4.73)

−

25

and comparing with

The vectors in

are

F

(uiuj)u∗

k = ǫijmu∗

mu∗

k =

ǫijkǫkmnun

−

(4.74)

u0
u∗
0
ui
u∗
i

|

i

u



= 




and one can easily evaluate the matrices X and Π corresponding to right and
left multiplication. We will not give here the explicit expressions, but one
can easily see some properties. For instance, one can evaluate the anticom-
mutator [Xi, X ∗

(4.75)






[Xi, X ∗

j ]+, by using the following relation
j + X ∗
u∗
j |

ui = (
|
The algebra of the anticommutators of Xi, X ∗
three Fermi oscillators (apart from the sign)

j ]+|

= Xi

u

u

u

u

i

i

i

|

ui)u∗

j + (
|

u

u∗
j)ui

i
i turns out to be the algebra of

i

(4.76)

The matrices X0 and X ∗

[Xi, X ∗

j ]+ =

δij,

[Xi, Xj]+ = 0,

−
0 deﬁne orthogonal projectors
0 = X ∗

0 )2 = X ∗

0 , X0X ∗

(X ∗

0 X0 = 0

X 2

0 = X0,

[X ∗

i , X ∗

j ]+ = 0

(4.77)

Further properties are

and

X0 + X ∗

0 = 1

X ∗

i =

X T
i

−

Similar properties hold for the left multiplication matrices. One can also show
that there is a matrix C connecting left and right multiplication matrices.
This is given by

0
0
13
−
0
3 identity matrix. It follows that the bras, eigenvectors

C = 





1 0
0 1
0 0
0 0

0
0
0
13

(4.81)






−



where 13 is the 3
of the matrices of type X, are

×

(4.78)

(4.79)

(4.80)

(4.82)

u

h

|

= (u0, u∗
0,

u∗
i ,

−

ui)

−

26

For getting the integration rules we need the external product

u0
u∗
0
ui
u∗
i
u0
0
0
u∗
i

(cid:16)

0
u∗
0
ui
0

u

u

|

ih

|

= 












u0, u∗
0,

u∗
j ,

−

uj

−

(cid:17)

0
u∗
j
−
δiju0
ǫijkuk

−

uj
−
0
ǫijku∗
k
δiju∗
0

−








= 




According to our rules we get

u0 =

Z(u)

Z(u)

u∗
0 = 1,

ui =

Z(u)

Z(u)

u∗
i = 0

Other interesting properties are

u

u

h

|

i

= u0 + u∗

0 + 3u∗

0 + 3u0 = 4

u′

u

|

i

h

= u′

0u0 + u∗
0

′u0 −

u∗
i

′ui

−

iu∗
u′
i

and using

we get

u′

u

|

i

Z(u)h

= u′

0 + u∗
0

′ = 1

Showing that

behaves like a delta-function.

u′

u

|

i

h

(4.83)

(4.84)

(4.85)

(4.86)

(4.87)

27

5 Conclusions and outlook

In this paper we have shown how it is possible to deﬁne an integral over an
arbitrary algebra. The main idea is to restate the completeness relation in the
conﬁguration space (the space spanned by the eigenkets
of the position
operator), in terms of the wave functions (the functions on the conﬁguration
space). In this way the completeness relation can be understood in algebraic
terms and this has allowed us to deﬁne the integration rules over an arbitrary
algebra in terms of the completeness relation itself. The physical motivation
to require the completeness relation is that it ensures the composition law
for probabilities, as discussed in the Introduction.

x
i

|

The motivations of the present work come from searching a way of quan-
tizing a theory deﬁned on a conﬁguration space made up of non-commuting
variables, the simplest example being the case of supersymmetry. The work
presented here is only a ﬁrst approach to this subject. First of all we have
limited our investigation to the construction of the integration rules, but we
have not tried to study under which conditions they are satisﬁed in a given
algebra. Or, said in a diﬀerent way, we have not looked for a classiﬁcation
of algebras with respect to the integration rules we have deﬁned. Second,
in order to build up the functional integral, a further step is necessary. One
needs a diﬀerent copy of the given algebra to each diﬀerent time along the
path-integration. This should be done by taking convenient tensor products
of copies of the algebra. Given these limitations, we think, however, that the
step realized in this work is a necessary one in order to solve the problem of
quantizing the general theories discussed here.

28

References

[1] F.A.Berezin and M.S.Marinov, JETP Lett. 21 (1975) 321, ibidem Ann.

of Phys. 104 (1977) 336.

[2] R.Casalbuoni, Il Nuovo Cimento, 33A (1976) 115 and ibidem 389.

[3] F.A.Berezin, The method of second quantization, Academic Press (1966).

[4] A.Connes, Noncommutative geometry, Academic Press (1994).

[5] V.G.Drinfeld, Quantum Groups,

in Proceedings of the International
Congress of Mathematicians, Berkeley 1986, pp. 798-820, AMS, Provi-
dence, RI.

[6] J.L.Martin Proc. Roy. Soc. 251A (1959) 543.

[7] A.Messiah, Quantum Mechanics, North Holland, Amsterdam (1962).

[8] R.D.Schafer, An introduction to nonassociative algebras, Academic Press

(1966).

[9] A.P.Isaev, Dubna preprint, q-alg/9609030.

[10] R.Casalbuoni, G.Domokos and S. K¨ovesi-Domokos, Il Nuovo Cimento,

31A (1976) 423.

29

