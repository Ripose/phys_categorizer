1

ON THE COMPUTATIONAL CAPABILITIES OF PHYSICAL SYSTEMS

PART II: RELATIONSHIP WITH CONVENTIONAL COMPUTER

SCIENCE

 by David H. Wolpert

NASA Ames Research Center, N269-1, Moffett Field, CA 94035, dhw@ptolemy.arc.nasa.gov

PACS numbers: 02.10.By, 02.60.Cb, 03.65.Bz

Abstract: In the ﬁrst of this pair of papers, it was proven that there cannot be a physical computer

to which one can properly pose any and all computational tasks concerning the physical universe.

It was then further proven that no physical computer C can correctly carry out all computational

tasks that can be posed to C. As a particular example, this result means that no physical computer

that can, for any physical system external to that computer, take the speciﬁcation of that external

system’s state as input and then correctly predict its future state before that future state actually

occurs; one cannot build a physical computer that can be assured of correctly “processing infor-

mation faster than the universe does”. These results do not rely on systems that are inﬁnite, and/or

non-classical, and/or obey chaotic dynamics. They also hold even if one uses an inﬁnitely fast,

inﬁnitely dense computer, with computational powers greater than that of a Turing Machine. This

generality is a direct consequence of the fact that a novel deﬁnition of computation — “physical

computation” — is needed to address the issues considered in these papers, which concern real

2

physical computers. While this novel deﬁnition does not ﬁt into the traditional Chomsky hierar-

chy, the mathematical structure and impossibility results associated with it have parallels in the

mathematics of the Chomsky hierarchy. This second paper of the pair presents a preliminary

exploration of some of this mathematical structure. Analogues of Chomskian results concerning

universal Turing Machines and the Halting theorem are derived, as are results concerning the

(im)possibility of certain kinds of error-correcting codes. In addition, an analogue of algorithmic

information complexity, “prediction complexity”, is elaborated. A task-independent bound is

derived on how much the prediction complexity of a computational task can differ for two differ-

ent reference universal physical computers used to solve that task, a bound similar to the “encod-

ing” bound governing how much the algorithm information complexity of a Turing machine

calculation can differ for two reference universal Turing machines. Finally, it is proven that either

the Hamiltonian of our universe proscribes a certain type of computation, or prediction complex-

ity is unique (unlike algorithmic information complexity), in that there is one and only version of

it that can be applicable throughout our universe.

INTRODUCTION

3

Recently there has been heightened interest in the relationship between physics and computa-

tion ([1-33]). This interest extends far beyond the topic of quantum computation. On the one

hand, physics has been used to investigate the limits on computation imposed by operating com-

puters in the real physical universe. Conversely, there has been speculation concerning the limits

imposed on the physical universe (or at least imposed on our models of the physical universe) by

the need for the universe to process information, as computers do.

To investigate this second issue one would like to know what fundamental distinctions, if any,

there are between the physical universe and a physical computer. To address this issue the ﬁrst of

this pair of papers begins by establishing that the universe cannot contain a computer to which one

can pose any arbitrary computational task. Accordingly, paper I goes on to consider computer-

indexed subsets of computational tasks, where all the members of any such subset can be posed to

the associated computer. It then proves that one cannot build a computer that can “process infor-

mation faster than the universe”. More precisely, it is shown that one cannot build a computer that

can, for any physical system, correctly predict any aspect of that system’s future state before that

future state actually occurs. This is true even if the prediction problem is restricted to be from the

set of computational tasks that can be posed to the computer.

This asymmetry in computational speeds constitutes a fundamental distinction between the

universe and the set of all physical computers. Its existence casts an interesting light on the ideas

of Fredkin, Landauer and others concerning whether the universe “is” a computer, whether there

are “information-processing restrictions” on the laws of physics, etc. [10, 18]. In a certain sense,

the universe is more powerful than any information-processing system constructed within it could

be. This result can alternatively be viewed as a restriction on the universe as a whole — the uni-

verse cannot support the existence within it of a computer that can process information as fast as it

can.

The analysis of paper I also establishes (for example) the necessarily fallible nature of retrod-

4

iction, of control, and of observation. (This latter result can be viewed as a kind of uncertainty

principle that does not rely on quantum mechanics.) The way that results of such generality are

derived is by examining the underlying issues from the broad perspective of the computational

character of physical systems in general, rather than that of some single precisely speciﬁed physi-

cal system. The associated mathematics does not directly involve dynamical systems like Turing

machines. Rather it casts computation in terms of partitions of the space of possible worldlines of

the universe. For example, to specify what input a particular physical computer has at a particular

time is to specify a particular subset of all possible worldlines of the universe; different inputs to

the computation correspond to different such subsets. Similar partitions specify outputs of a phys-

ical computer. Results concerning the (im)possibility of certain kinds of physical computation are

derived by considering the relationship between these kinds of partitions. In its being deﬁned in

terms of such partitions, “physical computation” involves a structure that need not even be instan-

tiated in some particular physically localized apparatus; the formal deﬁnition of a physical com-

puter is general enough to also include more subtle non-localized dynamical processes unfolding

across the entire universe.

This second paper begins with a cursory review of these partition-based deﬁnitions and

results of paper I. Despite its being distinct from the mathematics of the Chomsky hierarchy, as

elaborated below, the mathematics and impossibility results governing these partitions bears many

parallels with that of the Chomsky hierarchy. Section 2 of this second paper explicates some of

that mathematical structure, involving topics ranging from error correction to the (lack of) transi-

tivity of computational predictability across multiple distinct computers. In particular, results are

presented concerning physical computation analogues of the mathematics of Turing machines,

e.g., “universal” physical computers, and Halting theorems for physical computers. In addition, an

analogue of algorithmic information complexity, “prediction complexity”, is elaborated. A task-

independent bound is derived on how much the prediction complexity of a computational task can

differ for two different reference universal physical computers used to solve that task. This bound

is similar to the “encoding” bound governing how much the algorithmic information complexity

5

of a Turing machine calculation can differ for two reference universal Turing machines. It is then

proven that one of two cases must hold. One is that the Hamiltonian of our universe proscribes a

certain type of computation. The other possibility is that, unlike conventional algorithmic infor-

mation complexity, its physical computation analogue is unique, in that there is one and only ver-

sion of it that can be applicable throughout our universe.

Throughout these papers, B ” {0, 1}, ´

is deﬁned to be the set of all real numbers, ‘^’ is the

logical and operator, and ‘NOT’ is the logical not operator applied to B. To avoid proliferation of

symbols, often set-delineating curly brackets will be used surrounding a single symbol, in which

case that symbol is to taken to be a variable with the indicated set being the set of all values of that

variable. So for example “{y}” refers to the set of all values of the variable y. In addition o(A) is
the cardinality of any set A, and 2A is the power set of A. u ˛ U are the possible states of the uni-
verse, and ^U is the space of allowed trajectories through U. So ^u ˛
^U is a single-valued map from
t ˛
^ut the state of the universe at time t. Note that since the universe is
microscopically deterministic, ut for any t uniquely speciﬁes ^u. Sometimes there will be implicit
constraints on ^U. For example, we will assume in discussing any particular computer that the
space ^U is restricted to worldlines ^u that contain that computer. An earlier analysis addressing

to u ˛ U, with ut ”

some of the issues considered in this pair of papers can be found in [30].

I. REVIEW OF DEFINITIONS AND FOUNDATIONAL RESULTS RELATED TO

PHYSICAL COMPUTATION

In paper I the process by which real physical computers make predictions concerning physical

systems is abstracted to produce a mathematical deﬁnition of physical computation. This section

reviews that deﬁnition and the associated fundamental mathematical results. The reader is

referred to paper I for more extensive discussion of the deﬁnitions.

´
6

i) Deﬁnition of a Physical Computer

We start by distinguishing the speciﬁcation of what we want the computer to calculate from

the results of that calculation:

Deﬁnition 1: Any question q ˛ Q is a pair, consisting of a set A of answers and a single-valued
function from ^u ˛

A. A(q) indicates the A-component of the pair q.

^U to a ˛

Here we restrict attention to Q that are non-empty and such that there exist at least two elements
in A(q) for at least one q ˛ Q. We make no other a priori assumptions concerning the spaces
{A(q ˛ Q)} and Q. In particular, we make no assumptions concerning their ﬁniteness.

Example 1 (conventional prediction of the future): Say that our universe contains a system S

external to our computer that is closed in the time interval [0, T], and let u be the values of the ele-
ments of a set of canonical variables describing the universe. a

is the t = T values of the compo-

nents of u that concern S, measured on some ﬁnite grid G of ﬁnite precision. q is this deﬁnition of
a with G and the like fully speciﬁed. (So q is a partition of the space of possible uT, and therefore
is an element of that partition.) Q is a set of such q’s, differing in G, whose associated
of

^
U, and a

answers our computer can (we hope) predict correctly.

The input to the computer is implicitly reﬂected in its t = 0 physical state, as our interpretation

of that state. In this example (though not necessarily in general), that input speciﬁes what question

we want answered, i.e., which q and associated T we are interested in. It also delineates one of
several regions R ˝
^U, each of which, intuitively, gives the t = 0 state of S. Throughout each such
R, the system S is closed from the rest of the universe during t ˛

[0, T]. The precise R delineated

further speciﬁes a set of possible values of u0 (and therefore of the Hamiltonian describing S), for

example by being an element of a (perhaps irregular) ﬁnite precision grid over U0, G'. If, for some
R, q( ^u ) has the same value for all ^u ˛ R, then this input R uniquely speciﬁes what a
associated ^u. If this is not the case, then the R input to the computer does not sufﬁce to answer

is for any

7

question q. So for any q and region R both of which can be speciﬁed in the computer’s input, R
must be a subset of a region q-1(a ) for some a

.

Implicit in this deﬁnition is some means for correctly getting the information R into the com-

puter’s input. In practice, this is often done by having had the computer coupled to S sometime

before time 0. As an alternative, rather than specify R in the input, we could have the input contain

a “pointer” telling the computer where to look to get the information R. (The analysis of these

papers holds no matter how the computer gains access to R.) In addition, in practice the input, giv-

ing R, q, and T, is an element of a partition over an “input section” of our computer. In such a
case, the input is itself an element of a ﬁnite precision grid over ^U, G". So an element of G" spec-

iﬁes an element of G (namely q) and element of G' (namely R.)

Given its input, the computer (tries to) form its prediction for a by ﬁrst running the laws of

physics on a u0 having the speciﬁed value as measured on G', according to the speciﬁed Hamilto-

nian, up to the speciﬁed time T. The computer then applies q(.) to the result. Finally, it writes this
prediction for a onto its output and halts. (More precisely, using some fourth ﬁnite precision grid

G"' over its output section, it “writes out” (what we interpret as) its prediction for what region in

U the universe will be in at T, that prediction being formally equivalent to a prediction of a region
in ^U.) The goal is to have it do this, with the correct value of a
, by time t < T. Note that to have

the computer’s output be meaningful, it must specify the question q being answered as well as the
answer a

, i.e., the output must be a physical state of the computer that we interpret as a question-

answer pair.

Consider again the case where there is in fact a correct prediction, i.e., where R is indeed a

subset of the region q-1(a ) for some a

. For this case, formally speaking, “all the computer has to

do” in making its prediction is recognize which such region in the partition q that is input to the

computer contains the region R that is also input to the computer. Then it must output the label of

that region in q. In practice though, q and R are usually “encoded” differently, and the computer
must “translate” between those encodings to recognize which region q-1(a ) contains R; this trans-

lation constitutes the “computation”.

8

Given this deﬁnition of a question, we can now deﬁne the input and output portions of a phys-

ical computer by generalizing our example of conventional computation.

Deﬁnition 2: i) A (computation) partition is a set of disjoint subsets of ^u whose union equals ^U,
or equivalently a single-valued mapping from ^U into a non-empty space of partition-element

labels. Unless stated otherwise, any partition is assumed to contain at least two elements.

ii) In an output partition, the space of partition element labels is a space of possible “outputs”,

{OUT}.
iii) In a physical computer, we require {OUT} to be the space of all pairs {OUTq ˛ Q, OUTa
A(OUTq)}, for some Q and A(.) as deﬁned in Def. (1). This space — and therefore the associated

output partition — is implicitly a function of Q. To make this explicit, often, rather than an output

^U ﬁ OUT ˛

partition, we will consider the full associated double (Q, OUT(.)), where OUT(.) is the output par-
˛ A(OUTq)}. Also, we will ﬁnd it useful to use an
tition ^u ˛
output partition to deﬁne an associated (“prediction”) partition, OUTp(.) : ^u ﬁ
(A(OUTq( ^u ),
OUTa ( ^u )).

{OUTq ˛ Q, OUTa

iv)

In an input partition, the space of partition element labels is a space of possible “inputs”,

{IN}.

v) A (physical) computer consists of an input partition and an output partition double. Unless

explicitly stated otherwise, both of those partitions are required to be (separately) surjective.

Since we are restricting attention to non-empty Q, {OUT} is non-empty. We say that OUTq is the

“question posed to the computer”, and OUTa

is “the computer’s answer”. The surjectivity of IN(.)

and OUT(.) is a restriction on {IN} and {OUT}, respectively.

While motivated in large measure by the task of predicting the future, the deﬁnition of physi-

cal computation is far broader, concerning any computation that can be cast in terms of inputs,

questions about physical states of nature, and associated answers. This set of questions includes in

˛
9

particular any calculation that can be instantiated in a physical system in our universe, whether

that question is a “prediction” or not. All such physically realizable calculations are subject to the

results presented below.

Even in the context of prediction though, the deﬁnition of a physical computer presented here

is much broader than computers that work by the process outlined in Ex. 1 (and therefore the

associated theorems are correspondingly further-ranging in their implications). For example, the

computer in Ex. 1 has the laws of physics explicitly built into its “program”. But our deﬁnition

allows other kinds of “programs” as well. Our deﬁnition also allows other kinds of information

input to the computer besides q and a region R (which together with T constitute the inputs in Ex.

1). As discussed in paper I, we will only need to require that there be some t = 0 state of the com-
puter that, by accident or by design, induces the correct prediction at t = t . This means we do not

even require that the computer’s initial state IN “accurately describes” the t = 0 external universe

in any meaningful sense. Our generalization of Ex. 1 preserves analogues of the grids G (in Q(.)),

G" (in IN(.)) and G"' (in OUT(.)), but not of the grid G'.

In fact, our formal deﬁnition of a physical computer broadens what we mean by the “input to

the computer”, IN, even further. While the motivation for our deﬁnition, exempliﬁed in Ex. 1, has

the partition IN(.) “ﬁx the initial state of the computer’s inputs section”, that need not be the case.
IN(.) can reﬂect any attributes of ^u. An “input” — an element of a partition of ^U — need not

even involve the t = 0 state of the physical computer. In other words, as we use the terms here, the

computer’s “input” need not be speciﬁed in some t = 0 state of a physical device. Indeed, our def-

inition does not even explicitly delineate the particular physical system within the universe that

we identify with the computer. (A physical computer is simply an input partition together with an

output partition.) This means we can even choose to have the entire universe “be the computer”.

For our purposes, we do not need tighter restrictions in our deﬁnition of a physical computer.

Nonetheless, a pedagogically useful example is any localized physical device in the real world

meeting our limited restrictions. No matter how that device works, it is subject to the impossibility

results described below.

10

ii) Intelligible computation

Consider a “conventional” physical computer, consisting of an underlying physical system
whose t = 0 state sets IN( ^u ) and whose state at time t sets OUT( ^u ), as in our example above.

We wish to analyze whether the physical system underlying that computer can calculate the future

sufﬁciently quickly. In doing so, we do not want to allow any of the “computational load” of the

calculation to be “hidden” in a restriction on the possible questions. Our computer possess a sufﬁ-

cient degree of ﬂexibility. We impose this via the following construction (see paper I for a detailed

justiﬁcation):

Deﬁnition 3: Consider a physical computer C ”
tion from ^U into B, f, is an intelligibility function (for p ) if

(Q, IN(.), OUT(.)) and a ^U-partition p

. A func-

^u, ^u' ˛

^U, p ( ^u ) = p ( ^u' ) (cid:222)

f( ^u ) = f( ^u' ).

A set F of such intelligibility functions is an intelligibility set for p

.

We view any intelligibility function as a question by deﬁning A(f) to be the image of ^U under

f. If F is an intelligibility set for p and F ˝ Q, we say that p

is intelligible to C with respect to F. If

the intelligibility set is not speciﬁed, it is implicitly understood to be the set of all intelligibility
functions for p

.

We say that two physical computers C1 and C2 are mutually intelligible (with respect to the
pair {Fi}) iff both OUT2 is intelligible to C1 with respect to F2 and OUT1 is intelligible to C2 with
respect to F1.

intelligibility functions f, $ q ˛ OUTq such that q = f, i.e.,
^U, q( ^u ) = f( ^u ). Note that since p

^u ˛

is intelligible to C iff "

Plugging in, p
such that A(q) = the image of ^U under f, and such that "
contains at least two elements, if p

{OUTq} such that A(OUTq) =
B, an OUTq such that A(OUTq) = {0}, and one such that A(OUTq) = {1}. Usually we are inter-
ested in the case where p
 is an output partition of a physical computer, as in mutual intelligibility.

is intelligible to C, $ OUTq ˛

"
11

is a mapping from the elements of p

into

Intuitively, an intelligibility function for a partition p
is intelligible to C if Q contains all binary-valued functions of p

B. p
question concerning the universe as measured on p
partition isn’t “rigged ahead of time” in favor of some particular question concerning p
by the surjectivity of OUT(.), the requirement of intelligibility means that $

^u' ˛

, i.e., if C can have posed any

. This ﬂexibility in C ensures that C’s output

. Formally,
^u

^
U such that "

^U, [OUTq( ^u' )]( ^u ) = f( ^u ).

iii) Predictable computation

We can now formalize the concept of a physical computer’s “making a correct prediction”:

, and intelligibility set for p

, F. We say

Deﬁnition 4: Consider a physical computer C, partition p
that p
i) p
ii) "

 is weakly predictable to C with respect to F iff:
 is intelligible to C with respect to F, i.e., F ˝ OUTq ;
 f ˛ F,
IN ˛
IN( ^u )  =  IN

{IN} that weakly induces f, i.e., an IN such that:

OUTp( ^u )  =  (A(OUTq( ^u )), OUTa ( ^u ))  =  (A(f), f( ^u )).

Intuitively, condition (ii) means that for all questions q in F, there is an input state such that if C is
initialized to that input state, C’s answer to that question q (as evaluated at t ) must be correct.

Note that we even allow the computer to be mistaken about what question it is answering — i.e.,
for OUTq( ^u ) to not equal f — so long as C’s answer is correct. We will say a computer C' with
output OUT'(.) is weakly predictable to another if the partition OUT'p(.) is. If we just say “predict-

able” it will be assumed that we mean weak predictability.

As a formal matter, note that in the deﬁnition of predictable, even though f(.) is surjective onto
A(f) (cf. Def. 3), it may be that for some IN, the set of values f( ^u ) takes on when ^u is restricted
so that IN( ^u ) = IN do not cover all of A(f). The reader should also bear in mind that by surjectiv-

˛
$
(cid:222)
ity, "

IN ˛

{IN}, $

^u ˛

^U such that IN( ^u ) = IN.

12

iv) Distinguishable computers

There is one ﬁnal deﬁnition that we need before we can establish our unpredictability results:

Deﬁnition 5: Consider a set of n physical computers {Ci ”
say {Ci} is (input) distinguishable iff "
that "
 i, INi( ^u ) = INi simultaneously.

n-tuples (IN1 ˛

(Qi, INi(.), OUTi(.)) : i = 1, ..., n}. We
^U such

{IN1}, ..., INn ˛

{INn}), $

^u ˛

We say that {Ci} is pairwise (input) distinguishable if any pair of computers from {Ci} is distin-
guishable, and will sometimes say that any two such computers C1 and C2 “are distinguishable
from each other”. We will also say that {Ci} is a maximal (pairwise) distinguishable set if there
are no physical computers C ˇ

 {Ci} is a (pairwise) distinguishable set.

 {Ci} such that C ¨

iv) The impossibility of posing arbitrary questions to a computer

The ﬁrst result in paper I states that for any pair of physical computers there are always

binary-valued questions about the state of the universe that cannot even be posed to at least one of

those physical computers:

Theorem 1: Consider any pair of physical computers {Ci : i = 1, 2}. Either $ ﬁnite intelligibility
set F2 for C2 such that C2 is not intelligible to C1 with respect to F2, and/or $ ﬁnite intelligibility
set F1 for C1 such that C1 is not intelligible to C2 with respect to F1.

Thm. 1 reﬂects the fact that while we do not want to have C’s output partition “rigged ahead of

time” in favor of some single question, we also cannot require too much ﬂexibility of our com-

puter. It is necessary to balance these two considerations. Accordingly, before analyzing predic-

tion of the future, to circumvent Thm. 1 we must deﬁne a restricted kind of intelligibility set to

which Thm. 1 does not apply:

13

Deﬁnition 6: An intelligibility function f for an output partition OUT(.) is question-independent
iff "

^U:

^u, ^u' ˛
OUTp( ^u )  =  OUTp( ^u' )

     f( ^u ) = f( ^u' ).

An intelligibility set as a whole is question-independent if all its elements are.

We write C1 > C2 (or equivalently C2 < C1) and say simply that C2 is (weakly) predictable to
C1 (or equivalently that C1 can predict C2) if C2 is weakly predictable to C1 for all question-inde-
pendent ﬁnite intelligibility sets for C2.

Similarly, from now on we will say that C2 is intelligible to C1 without speciﬁcation of an
intelligibility set if C2 is intelligible to C1 with respect to all question-independent ﬁnite intelligi-
bility sets for C2.

Intuitively, f is question-independent if its value does not vary with q among any set of q all of

which share the same A(q). As an example, say our physical computer is a conventional digital

workstation. Have a certain section of the workstation’s RAM be designated the “output section”

of that workstation. That output section is further divided into a “question subsection” designating
(i.e., “containing”) a q, and an “answer subsection” designating an a

. Say that for all q that can be

designated by the question subsection A(q) is a single bit, i.e., we are only interested in binary-

valued questions. Then for a question-independent f, the value of f can only depend on whether

the answer subsection contains a 0 or a 1. It cannot vary with the contents of the question subsec-

tion.

A detailed example of a pair of mutually (question-independent) intelligible computers is pre-

sented in paper I. In addition to this explicit demonstration that Thm. 1 does not hold for question-

independent intelligibility sets, examples 2, 2', and 2" of paper I establish that:

(cid:222)
14

a) There are pairs of input-distinguishable physical computers, C1, C2, in which C2 is predictable
to C1, C1 > C2;
b) Given C1 and C2 as in (a), we could have yet another computer C3 that also predicts C2 (i.e.,
such that C3 > C2) while being distinguishable from C1;
c) Given C1 and C2 as in (a), we could have a computer C4, distinguishable from both C1 and C2,
where C4 > C1, so that C4 > C1 > C2. We can do this either with C4 > C2 or not.

ii) The impossibility of assuredly correct prediction

To establish our main impossibility result in paper I we started with the following lemma:

Lemma 1: Consider a physical computer C1. If $ any output partition OUT2 that is intelligible to
C1, then $ q1 ˛ Q1 such that A(q1) = B, a q1 ˛ Q1 such that A(q1) = {0}, and a q1 ˛ Q1 such that
A(q1) = {1}.

This can be used to establish paper I’s central theorem:

Theorem 2: Consider any pair of distinguishable physical computers {Ci : i = 1, 2}. It is not pos-
sible that both C1 > C2 and C1 < C2.

Restating it, Thm. 2 says that either $ ﬁnite question-independent intelligibility set for C1, F1,
such that C1 is not predictable to C2 with respect to F1, and/or $ ﬁnite question-independent intel-
ligibility set for C2, F2, such that C2 is not predictable to C1 with respect to F2.

Thm. 2 holds no matter how large and powerful our computers are; it even holds if the “phys-

ical system underlying” one or both of our computers is the whole universe. It also holds if instead
C2 is the rest of the physical universe external to C1. A set of implications of Thm. 2 for various

kinds of physical prediction scenarios are discussed in paper I. As also discussed there, impossi-

15

bility results that are in some senses even stronger than those associated with Thm. 2 hold when

we do not restrict ourselves to distinguishable computers, as we do in Thm. 2.

3. THE MATHEMATICAL STRUCTURE RELATING PHYSICAL COMPUTERS

There is a rich mathematical structure governing the possible predictability relationships

among sets of physical computers, especially if one relaxes the presumption (obtaining in much of

paper I) that the universe can contain multiple copies of C. This section presents some of that

structure.

i)  The graphical structure over a set of computers induced by weak predictability

While it directly concerns pairs of physical computers, Thm. 2 also has implications for the

predictability relationships within sets of more than two computers. An example is the following:

Corollary 1: It is not possible to have a fully distinguishable set of n physical computers {Ci}
such that C1 > C2 > ... > Cn > C1.

Proof: Hypothesize that the corollary is wrong. Deﬁne the composite device C* ” (I

* (.) ”

n-1 INi(.), Q1, OUT1(.)). Since {Ci} is fully distinguishable, IN*(.) is surjective. Therefore C*
i=1

is a physical computer.

INn-2 ˛

{INn-2} such that "

^u ˛

^U for which A(OUTn-1

Since by hypothesis Cn is intelligible to Cn-1, $ OUTn-1

q such that A(OUTn-1
^U for which A(OUTn-1

q) = B. Also,
since Cn-2 > Cn-1, $
q( ^u )) = B,
INn-2( ^u ) = INn-2 (cid:222) OUTn-2a ( ^u ) = OUTn-1a ( ^u ). Iterating and exploiting full distinguishabil-
ity, $
q( ^u )) = B, (IN1( ^u ), .., INn-2( ^u ))
= (IN1, ..., INn-2) (cid:222) OUT*( ^u ) = OUT1( ^u ) = OUTn-1( ^u ). The same holds when we restrict ^u
q( ^u )) = {0}.
so that the space A(OUTn-1
Since by hypothesis Cn is intelligible to Cn-1, and since IN*(.) is surjective, this result means

q( ^u )) = {1}, and when we restrict ^u so that A(OUTn-1

(IN1, ..., INn-2) such that "

^u ˛

N
P
16

that Cn is predictable to C*. Conversely, since Cn > C1 by hypothesis, the output partition of C* is
predictable to Cn, and therefore C* is. Finally, since {Ci} is fully distinguishable, C* and Cn are

distinguishable. Therefore Thm. 2 applies, and by using our hypothesis we arrive at a contradic-

tion. QED.

What are the general conditions under which two computers can be predictable to one

another? By Thm. 2, we know they aren’t if they’re input-distinguishable. What about if they’re

one and the same? No physical computer is input-distinguishable from itself, so Thm. 2 doesn’t

apply to this issue. However it still turns out that Thm. 2’s implication holds for this issue:

Theorem 3: No physical computer is predictable to itself.

Proof. Assume our corollary is wrong, and some computer C is predictable to itself. Since by def-
inition predictability implies intelligibility, we can apply Lemma 1 to establish that there is a q ˛

OUTq, q', such that A(q') = B. Therefore one question-independent intelligibility function for C is
^U ﬁ B that equals 1 if A(OUTq( ^u )) = B and OUTa ( ^u ) = 0, and equals
the function f from ^u ˛
0 otherwise. Therefore by hypothesis $
{IN} such that IN( ^u ) = IN (cid:222) A(OUTq( ^u )) = B
and OUTa ( ^u ) = f( ^u ). But if A(OUTq( ^u )) = B, then f( ^u ) = NOT[OUTa ( ^u )], by deﬁnition of
f(.). Since IN is surjective, this means that there is at least one ^u ˛
^U such that A(OUTq( ^u )) = B
and OUTa ( ^u ) = NOT[OUTa ( ^u )]. This is impossible. QED.

IN ˛

Intuitively, this result holds due to the fact that a computer cannot make as its prediction the logi-

cal inverse of its prediction. An important corollary of this result is that no output partition is pre-

dictable to a physical computer that has that output partition. Combining Thm. 3 and Coroll. 1 and

identifying the predictability relationship with an edge in a graph, we see that fully distinguish-

able sets of physical computers constitute (unions of) directed acyclic graphs.

17

ii) Weak predictability and variants of error correction

When considering sets of more than two computers, it is important to realize that while it is

symmetric, the input-distinguishability relation need not be transitive. Accordingly, separate pair-

wise distinguishable sets of computers may partially “overlap” one another. Similarly, stipulating

the values of the inputs of any two computers in a pairwise-distinguishable set may force some of

the other computers in that set to have a particular input value.

Coroll. 1 does not apply to such a set. As it turns out though, Thm. 2 still has strong implica-

tions even for a set of more than two computers that is not fully distinguishable, so long as the set

is pairwise distinguishable. Deﬁne a god computer as any physical computer in a pairwise distin-

guishable set such that all other physical computers in that set are predictable to the god computer.

Then by Thm. 2, each such set can contain at most one god computer. There is at most one com-

puter in any pairwise distinguishable set that can correctly predict the future of all other members

of that set, and more generally at most one that can accurately predict the past of, observe, and/or

control any system in that set (see paper I). In particular, for any human being physical computer,

for any pairwise distinguishable set of computers including that human, there can be at most one

god computer. (Lest one read too much into the phrase “god computer”, note that like any other

computer, a god computer is merely a set of partitions, and need not correspond to any localized

physical apparatus.)

Even a god computer may not be able to correctly predict all other computers in its distin-
guishable set simultaneously. The input value it needs to adopt to correctly predict some C2 may
preclude it from correctly predicting some C3 and vice-versa. One way to analyze this issue is to
consider a composite partition OUT2· 3 deﬁned by the output partitions of C2 and C3. We can then

investigate whether and when our god computer can weakly predict the composite output parti-

tion. The following deﬁnition formalizes this:

Deﬁnition 7: Consider a pairwise distinguishable set {Ci} with god computer C1. Deﬁne the par-

18

^U ) ”

(OUT q

titions OUTi· j ( ^u ˛
(OUT1a ( ^u ), OUT2a ( ^u )), and each question [OUT q
([OUT1
to C1.

q( ^u )]( ^u' ), [OUT2

i· j ( ^u ), OUT ai· j ( ^u )), where each answer map OUT ai· j ( ^u ) ”
^U ﬁ

the mapping given by ^u' ˛

i· j ( ^u )] ”

q( ^u )]( ^u' )). Then C1 is omniscient if OUT2· 3·

... is weakly predictable

Intuitively, OUTi· j is just the double partition (OUTi(.), OUTj(.)) = ((OUTi
q(.), OUTia (.)),
q(.), OUTja (.)), re-expressed to be in terms of a single question-valued partition and a sin-
(OUTj
gle answer-valued partition. To motivate this re-expression, for any two questions qi ˛ Qi and qj ˛
Qj, let qi · qj be the ordered product of the partitions qi and qj; it is the partition assigning to every
point ^u' ˛
q( ^u ) is
the question qj, OUT i· j
is deﬁned similarly, only with one
fewer levels of “indirection”, since answer components of output partitions are not themselves

q ( ^u ) is the question qi · qj. OUTi· j

^U the label (qi( ^u' ), qj( ^u' )). Then if OUTi

q( ^u ) is the question qi and OUTj

partitions (unlike question components).

Note that even though any OUTi(.) and OUTj(.) are both surjective mappings, OUTi· j need
j ˛ A(Qj)}. It is

not be surjective onto the set of quadruples {qi ˛ Qi, qj ˛ Qj, a

i ˛ A(Qi), a

straight-forward to verify that an omniscient computer is a god computer.

In general, one might presume that two non-god computers in a pairwise-distinguishable set

could have the property that, while individually they cannot predict everything, considered jointly

they would constitute a god computer, if only they could work cooperatively. An example of such

cooperativity would be having one of the computers predict when the other one’s prediction is

wrong. It turns out though that under some circumstances the mere presence of some other com-

puter in that pairwise distinguishable set may make such error-correction impossible, if that other

computer is omniscient.

As an example of this, say we have three pair-wise distinguishable computers C1, C2, C3,
where C3 always answers with a bit (i.e., /$ q3 ˛ Q3 such that A(q3) |˝ B). We will want C2’s out-
put to “correct” C3’s predictions, and have those predictions potentially concern C1. So have C1
be intelligible to C3. As a technical condition, assume not only that C3’s output can be any of its

a
19

possible question-answer pairs, but also that for any of its questions, for any of the associated pos-
sible answers, there are situations where that answer is correct (so that C2 should leave C3’s
answer alone in those situations). Then it turns out that due to Thm. 2, if C1 is omniscient, it is not
possible that C2 always correctly outputs a bit saying whether C3’s answer is the correct response
to C3’s question. More formally,

Corollary 2: Consider three pair-wise distinguishable computers C1, C2, C3, where /$ q3 ˛ Q3
such that A(q3) |˝ B. Assume that C1 is an omniscient computer, and that C1 is intelligible to C3.
Finally, assume that " pairs (q3 ˛ Q3, a 3 ˛ A(q3)), $
q( ^u ) = q3 and
q3( ^u ) = a 3 (i.e., [OUT3
^U, OUT2a ( ^u ) = 1
if [OUT3

q( ^u )]( ^u ) = a 3). Then it is not possible that "

q( ^u )]( ^u ) = OUT3a ( ^u ), 0 otherwise.

^U such that both OUT3

^u ˛

^u ˛

3

2

^u ˛

q(.) = OUT3

^U, q ( ^u ) = [OUT3

q(.), Q2-3 = Q3 and OUT2-3

Proof: Hypothesize that the corollary is wrong. Construct a composite device C2-3, starting by
having IN2-3(.) ” OUT3
q(.). Next deﬁne the question q by
a ( ^u ) = 0, q ( ^u ) ” OUT3a ( ^u ) otherwise. (N.b. no
the rule q ( ^u ) ” NOT[OUT
a ( ^u )] if OUT
assumption is made that q
Q2-3.) To complete the deﬁnition of the composite computer C2-3,
have OUT2-3a ( ^u ) = q ( ^u ).
Now by our hypothesis, "

q( ^u )]( ^u ). By the last of the conditions
speciﬁed in the corollary, this means that "
^u such that
q( ^u ) = q2-3 and OUT2-3a ( ^u ) = a 2-3. So C2-3 allows all possible values of {OUT2-3}, as
OUT2-3
a physical computer must. Due to surjectivity of OUT3
q, it also allows all possible values of the
space {IN2-3}. To complete the proof that C2-3 is a (surjective) physical computer, we must estab-
lish that OUT2-3a ( ^u ) ˛ A(OUT2-3
^U. To do this note that if for example
q( ^u )) = {1}, then since it is always the case that the OUT2-3a ( ^u ) =
A(OUT2-3
q( ^u )]( ^u ), OUT2-3a ( ^u ) = 1. Similarly OUT2-3a ( ^u ) ˛
[OUT2-3
q( ^u )) = {0}. Finally, if A(OUT2-3
q( ^u )) = B, then the simple
A(OUT2-3
fact that OUT2-3a ( ^u ) ˛ B always means that OUT2-3a ( ^u ) ˛

q( ^u )) = A(OUT3
q( ^u )]( ^u ) = [OUT3
q( ^u )) when A(OUT2-3

a 2-3 ˛ A(q2-3)),

(q2-3 ˛ Q2-3,

q( ^u )) "

^u ˛

 A(OUT2-3

q( ^u )).

˛
$
20

Since C1 is intelligible to C3 and Q2-3 = Q3, C1 is intelligible to C2-3. Moreover, given any
question q2-3 ˛ Q2-3, $
^U for which IN2-3( ^u ) =
IN2-3, OUT2-3( ^u ) = q2-3. But as was just shown, OUT2-3a ( ^u ) = q2-3( ^u ) for that ^u. Therefore
C1 is predictable to C2-3.

{IN2-3} such that "

associated IN2-3 ˛

^u ˛

q( ^u )), A(OUT3

Next, since C1 is omniscient, OUT2· 3 is intelligible to C1. Therefore any binary function of
q( ^u )), OUT2a ( ^u ), OUT3a ( ^u )) is
the regions deﬁned by quadruples (A(OUT2
an element of Q1. Any single such region is wholly contained in one region deﬁned by the pair
q( ^u )), OUT2-3a ( ^u )) though. Therefore any binary function of the regions deﬁned by
(A(OUT2-3
such pairs is an element of Q1. Therefore C2-3 is intelligible to Q1. Similarly, the value of any
such binary function must be given by OUT1a ( ^u ) whenever IN1( ^u ) equals some associated IN1.
So C2-3 is predictable to C1.

Finally, since C1 and C3 are input-distinguishable, so are C1 and C2-3, and therefore Thm. 2

applies. This establishes that our hypothesis results in a contradiction. QED.

This result even holds if OUT2· 3 is only intelligible to C1, without necessarily being predictable

to it.

Coroll. 2 can be viewed as a restriction on the efﬁcacy of any error correction scheme in the

presence of a (distinguishable) omniscient computer. There are other restrictions that hold even in

the absence of such a third computer. An example is the following implication of Thm. 2:

Corollary 3: Consider two distinguishable mutually intelligible physical computers C1 and C2,
q ˛ Q2. It is impossible
where both A(OUT1
that C1 and C2 are “anti-predictable” to each other, in the sense that for each of them, the predic-

q) ˝ B and A(OUT2

q ˛ Q1 and OUT2

q) ˝ B " OUT1

tion they make concerning the state of the other can always be made to be wrong by appropriate

choice of input.

Proof: By assumption C1 and C2 are mutually intelligible. So what we must establish is whether

21

for both of them, for all intelligibility functions concerning the other one, there exists an appropri-
ate value of INi such that that intelligibility function is incorrectly predicted.

IN2 ˛

{IN2} such that IN2( ^u ) = IN2 implies that [A(OUT2

Hypothesize that the corollary is wrong. Then " question-independent intelligibility functions
for C1, f1, $
q( ^u )) = NOT[A(f1)]] ^
[OUT2a ( ^u ) = NOT[f1( ^u )]]. However by deﬁnition of question-independent intelligibility func-
tions, given any such f1, there must be another question-independent intelligibility function for
C1, f3, deﬁned by f3(.) ” NOT(f1(.)). Therefore $
{IN2} such that IN2( ^u ) = IN2 implies
that [A(OUT2

IN2 ˛
q( ^u )) = A(f3)]  ^  [OUT2a ( ^u ) = f3( ^u )].

This NOT(.) transformation bijectively maps the set of all question-independent intelligibility
functions for C2 onto itself. Since that set is ﬁnite, this means that the image of the set under the

NOT(.) transformation is the set itself. Therefore our hypothesis means that all question-indepen-
dent functions for C1 can be predicted correctly by C2 for appropriate choice of IN2 ˛
{IN2}. By
similar reasoning, we see that C1 can always predict C2 correctly. Since C1 and C2 are distinguish-

able, we can now apply Thm. 2 and arrive at a contradiction. QED.

iii)  Strong predictability

At the other end of the spectrum from distinguishable computers is the case where one com-

puter’s input can ﬁx another’s, either by being observed by that other computer or by setting that

other computer’s input more directly. The following variant of predictability captures this rela-

tionship:

Deﬁnition 8: Consider a pair of physical computers C1 and C2. We say that C2 is strongly predict-
able to C1 (or equivalently that C1 can strongly predict C2), and write C1 >> C2 (or equivalently
C2 << C1) iff:

i) C2 is intelligible to C1;
ii) "

 question-independent intelligibility functions for C2, q1, "
IN1 ˛

{IN1} that strongly induces the pair (q1, IN2), i.e., such that:

 IN2 ˛

 {IN2},

$
22

IN1( ^u ) =  IN1

    [OUT1

p( ^u ) = (A(q1), q1( ^u ))]   ^  [IN2( ^u ) = IN2].

Intuitively, if C1 can strongly predict C2, then for any IN2 and associated implication OUT2
p —
for any computation C2 might undertake — there is an input to C1 that is uniquely associated
with IN2 and that causes C1 to output (any desired question-independent intelligibility function
of) OUT2
p. Intuitively, there is some invertible “translating” map that takes C2’s input and
“encodes” it in C1’s input, in such a way that C1 can “emulate” C2 running on C2’s input, and
thereby produce C2’s associated output. In this way C1 can emulate C2, much like universal Tur-

ing machines can emulate other Turing machines. (Recall the deﬁnition of universal Turing

machine, and see the deﬁnition of a universal physical computer below.)

Strong predictability of a computer implies weak predictability of that computer. (Unlike with

weak predictability, there is no such thing as strong predictability of a partition.) So for example

both Thm. 3 and Coroll. 1 still hold if they are changed by replacing weak predictability with

strong predictability. However weak predictability does not imply strong predictability. Moreover,

the mathematics for sets of physical computers some of which are strongly predictable to each

other (and therefore not distinguishable) differs in some respects from that when all the computers

are distinguishable (the usual context for investigations of weak predictability). An example is the

following result, which shows that strong predictability always is transitive, unlike weak predict-

ability (cf. Ex. 2" in paper I):

Theorem 4: Consider three physical computers {C1, C2, C3}, and a partition p
and p

 are intelligible to C1.
i)  C1 >> C2 > p
ii) C1 >> C2 >> C3 (cid:222) C1 >> C3.

C1 > p ;

, where both C3

(cid:222)
(cid:222)
23

Proof: To prove (i), let f be any question-independent intelligibility function for p
. By Lemma 1,
the everywhere 0-valued question-independent intelligibility function of p
is contained in Q1, and
since C1 > C2, there must be an IN1 such that IN1( ^u ) = IN1 (cid:222) OUT1a ( ^u ) = 0. The same is true

for the everywhere 1-valued function. Therefore to prove the claim we need only establish that for
every question-independent intelligibility function for p
, f, for which A(f) = B, f ˛ Q1, and there
exists an IN1 such that IN1( ^u ) = IN1 (cid:222) OUT1a ( ^u ) = f( ^u ). Restrict attention to such f from

now on.

Deﬁne a question-independent intelligibility function for C2, I2, such that A(I2) = B, and such

p( ^u ) = (B, 1) and ^u such that OUT2

that for all ^u for which A(OUTq( ^u )) = B, I2( ^u ) = OUT2a ( ^u ). (Note that since C2 > p
both exist ^u for which OUT2
f ˛
esis, for any of the f we are considering, $
IN2
= (B, f( ^u )). However the fact that C1 >> C2 (cid:222)
IN2( ^u ) = IN2
such a ^u, A(OUT2a ( ^u )) = B, and therefore I2( ^u ) = OUT2a ( ^u ). So OUT2
equals (B, OUT2a ( ^u )). So for that IN1, OUT1

{IN1} such that IN1( ^u ) = IN1 (cid:222)
p( ^u ) = (A(I2), I2( ^u )) = (B, I2( ^u )). Since IN2( ^u ) = IN2

f and such that OUT1

f for
p( ^u ) for such a ^u

, there
p( ^u ) = (B, 0.) Now by hypoth-
p( ^u )

f (cid:222) OUT2

{IN2} such that IN2( ^u ) = IN2

IN1 ˛

p( ^u ) = (A(f), f( ^u )).

This establishes (i). The proof for (ii) goes similarly, with the redeﬁnition that IN1

f ﬁxes the

value of IN3 as well as ensuring that OUT2

p( ^u ) = (A(f), f( ^u )). QED.

Strong predictability obeys the following result which is analogous to both Thm.’s 2 and 3:

Theorem 5: Consider any pair of physical computers {Ci: i = 1, 2}. It is not possible that both C1
>> C2 and C1 << C2.

Proof: Choose any IN2. For any question-independent intelligibility function of OUT2
must exist an IN1
IN1
However since OUT2

p, f, there
f ˛ {IN1} that strongly induces IN2 and f, since C1 >> C2. Label any such IN1 as
f} ˝ { ^u : IN2( ^u ) = IN2}.
p is not empty, there are at least two question-independent intelligibility

f (IN2 being implicitly ﬁxed). So for any such f, { ^u : IN1( ^u ) = IN1

$
24

} ˙

f1

{ ^u : IN1( ^u ) = IN1

f2} = ˘

q) (namely A(f1) and A(f2), respectively). This means that { ^u : IN1( ^u ) = IN1

p, f1 and f2, where A(f1) „ A(f2) (cf. Lemma 1). Moreover, the intersection
functions of OUT2
{ ^u : IN1( ^u ) = IN1
, since these two sets induce different
f1} (cid:204)
A(OUT1
{ ^u : IN2( ^u ) = IN2}. On the other hand, for the same reasons, there must also exist an IN2 that
{ ^u : IN1( ^u ) =
strongly induces IN1
f1}. So { ^u : IN2( ^u ) = IN2'} (cid:204) { ^u : IN2( ^u ) = IN2}. This is not compatible with the fact that
IN1
IN2(.) is a partition. QED.

IN2' such that { ^u : IN2( ^u ) = IN2'} (cid:204)

f1. Therefore $

Many of the conditions in the preceding results can be weakened and the associated conclu-

sions still hold. Indeed, this is even true for Thm. 2, where we can weaken the deﬁnition of “intel-
ligibility” and still establish the impossibility of having both C1 > C2 and C2 > C1. (For example,
that impossibility will still obtain even if neither C1 nor C2 contains B-valued questions, if they

instead contain all possible functions mapping each others’ values of OUTp onto {0, 1, 2}.) These

weakened version are usually more obscure though, which is why they are not presented here.

iv) Physical computation analogues of Halting theorems in Turing machine theory

There are several ways that one can relate the mathematical structure of physical computation

to that of conventional computer science. Here we sketch the salient concepts for one such rela-

tion coupling physical computation and the mathematical structure governing Turing machines

(TMs).

A TM is a device that takes in an input string on an input tape, then based on it produces

a sequence of output strings, either “halting” at some time with a ﬁnal output string, or never halt-

ing. If desired, the fact that the halt state has / hasn’t been entered by any time can be reﬂected in

a special associated pattern in the output string, in which case the sequence of output strings can

always be taken to be inﬁnite. As explicated above, in the real world inputs and (sequences of)
outputs are elements of partitions of ^U. So in one translation of TMs to physical computers,

strings on tapes are replaced with elements of the partitions IN(.) and OUT(.). Rather than

25

through a set of internal states, read/write operations, state-transition rules, etc., the transforma-

tion of inputs to outputs in a physical computer is achieved simply through the deﬁnition of the

pair of an associated input partition and output partition. For a TM that declares in its output

string whether it has halted, the physical computation analogue of whether a computation will
ever halt is simply whether ^u is in some special subset of {OUT}. Although not formally

required, in the real world IN(.) and OUT(.) usually differ. In this they are analogous to TM’s with

multiple tapes rather than conventional single-tape TMs.

An alternative to identifying the full output partition of a physical computer with a TM’s out-

put tape, motivated by the deﬁnition of predictability, is to identify the coarser partition ^u ﬁ
OUTp( ^u ) with a TM’s output tape. (This is loosely analogous to a TM’s being able to overwrite
the “question” originally posed on its tape when producing its “answer” on that tape.) We will

adopt this identiﬁcation from now on, and use it to identify the physical computation analogue of
a TM as an input partition together with the surjective mapping ^u ﬁ OUTp( ^u ) of an associated
output partition.

This identiﬁcation motivates several analogues of the Halting theorem. Since whether a partic-
ular physical computer C2 “halts” or not can be translated into whether its output is in a particular
region, the question of whether C2 halts is a particular intelligibility function of C2. Correctly
answering the question of whether C2 halts means predicting that intelligibility function of C2. In

the context of physical computation it is natural to broaden the issue to concern all intelligibility
functions of C2. Accordingly, in this analogue of the claim resolved for TM’s (in the negative) by
the Halting theorem, one asks if it is possible to construct a physical computer C1 that can predict
any computer C2. To answer this, consider the case where C2 is a copy of C1 (cf. Def. 2(v) of

paper I for a formal deﬁnition of a physical computer’s “copy”). Then by applying Thm.’s 2, 3 and

5, one sees that the answer is no, in agreement with the Halting theorem. (See also Coroll. 3.)

There exist a number of alternative physical computer analogues of the Halting problem.

Though not pursued at length here, it is worth brieﬂy presenting one such alternative. This alterna-

tive is motivated by arguing that, in the real world, one is not interested so much in whether the

26

computation will ever “halt”, but rather whether the associated output is “correct”. If we take

“correct” to be relative to a particular question, this motivates the following alternative analogue

of the Halting theorem:

Theorem 6: Given a set of physical computers {Ci}, /$

 C1 ˛

{Ci} such that "

 C2 ˛

 {Ci},

i) C2 is intelligible to C1;
 Q2, $
ii) "
  OUT2a ( ^u ).

 IN1 ˛

 q2 ˛

 {IN1} such that IN1( ^u ) = IN1 (cid:222)

 OUT1a ( ^u ) = 1 iff q2( ^u ) =

Proof: Choose C2 such that OUT2(.) = OUT1(.). (If need be, to do this simply choose C2 = C1.)
Then in particular, OUT1a (.) = OUT2a (.). Now since C2 is intelligible to C1 by hypothesis, by
Lemma 1 $ q1 ˛ Q1 such that A(q1) = {0}, and therefore $ q2 ˛ Q2 such that A(q2) = {0}. For
that q2, OUT1a ( ^u ) = 1 iff 0 = OUT1a ( ^u ), which is impossible. QED.

A TM T1 can emulate a TM T2 if for any input for T2, T1 produces the same output as T2

when given an appropriately modiﬁed version of that input. (Typically, the “modiﬁcation”
involves pre-pending an encoding of T2 to that input.) The analogous concept for a physical com-

puter is strong predictability; o ne physical computer can “emulate” another if it can strongly pre-
dict that other one. Intuitively, the two components of T1’s emulating T2, involving T2’s input and

its computational behavior, respectively, correspond to the two components of the requirement
concerning IN1 values that occur in the deﬁnition of strong predictability. The requirement con-
p( ^u ) = (A(q), q( ^u )) for any q (that is
cerning IN1 values that is imposed by ensuring that OUT1
an intelligibility function) for C2 is analogous to encoding (the computational behavior of) the
TM T2 in a string provided to the emulating TM, T1. Requiring as well that the value IN1 ensures
that IN2( ^u ) = IN2 is analogous to also including an “appropriately modiﬁed” version of T2’s
input in the string provided to T1. (Note that any mapping taking IN2 ˛
{IN2} to an IN1 that in
turn induces that starting IN2 is invertible, by construction.) This motivates the following deﬁni-

tion of the analogue of a universal TM:

27

Deﬁnition 9: A universal physical computer for a set of physical computers is a member of that

set that can strongly predict all other members of that set.

Note that rather than reproduce the output of a computer it is strongly predicting, a universal

physical computer produces the value of an intelligibility function applied to that output. This

allows the computers in our set to have different output spaces from the universal physical com-

puter. However it contrasts with the situation with conventional TM’s, being a generalization of

such TM’s.

v)  Prediction complexity

In computer science theory, given a universal TM T, the algorithmic complexity of an output

string s is deﬁned as the length of the smallest input string s' that when input to T produces s as

output. To construct our physical computation analogue of this, we need to deﬁne the “length” of

an input region of a physical computer. To do this we start with the following pair of deﬁnitions:

Deﬁnition 10: For any physical computer C with input space {IN}:

i) Given any partition p

, a (weak) prediction input set (of C, for p ) is any set s ˝

{IN} such

that both every intelligibility function for p

is weakly induced by an element of s, and for any

proper subset of s at least one such function is not weakly induced. We write the space of all weak
prediction input sets of C for p

 as C-1(p ).

ii) Given any other physical computer C' with input space {IN'} for which the set of all ques-

tion-independent intelligibility functions is {f'}, a strong prediction input set of C, for the triple
C', in' ˝

{IN} such that both every pair (f' ˛

f ', IN' ˛

{IN'}, and f ' ˝

{f'}, is any set s ˝

in') is

strongly induced by a member of s, and for any proper subset of s at least one such pair is not

strongly induced. We write the space of all strong prediction input sets (of C, for C', in', and f ') as

C-1(C', in', f ').

28

Intuitively, the prediction set of C for p

/ C' is a minimal subset of {IN} that is needed by C for p

/

C' to be predictable to C. In the case of strong prediction, we provide the associated deﬁnition the

extra ﬂexibility of being able to restrict what intelligibility functions are being considered.

Now, to deﬁne the physical computation analogue of algorithmic information complexity,

identify the “length of an input string” with the negative logarithm of the volume of a subset of the

partition IN(.):

Deﬁnition 11: Given a physical computer C and a measure dm
i) Deﬁne V(in ˝ {IN}) as the measure of the set of all ^u ˛
length of in (with respect to IN(.)) as l(in) ”
ii) Given a partition p
ity of p

 (with respect to C), c(p

 -ln[V(in)];

 | C), as minr ˛

 C-1(p ) [l(r )].

that is predictable to a physical computer C, deﬁne the prediction complex-

 over ^U:

^U such that IN( ^u ) ˛

in, and deﬁne the

We are primarily interested in prediction complexities of binary partitions, in particular of the

binary partitions induced by the separate single elements of multi-element partitions. (The binary
partition induced by some p ˛
'( ^u ) „ p}.) To see what Def. 11(ii)
means for such a partition, say you are given some set s
^U (i.e., you are given a binary partition
of ^U). Suppose further that you wish to know whether the universe is in s

'( ^u ) = p, ^u s.t. p

, and you have some

' is { ^u s.t. p

computer C to use to answer (all four intelligibility functions of) this question. Then loosely
speaking, the prediction complexity of s with respect to C is the minimal amount of Shannon

information that must be imposed in C’s inputs in order to be assured that C’s output correctly
answers that question. In particular, if s corresponds to a potential future state of some system S
external to C, then c(s
S.1s

| C) is a measure of how difﬁcult it is for C to predict that future state of

In many situations it will be most natural to choose dm

to be uniform over accessible phase

p
(cid:204)
29

space volume, so that the complexity of in is the negative physical entropy of constraining ^u to lie
in in. But that need not be the case. For example, we can instead deﬁne dm

so that the volume of

each element of the associated {IN} is some arbitrary positive real number. In this case, the

lengths of the elements of {IN} provides us with an arbitrary ordering over those elements.

The following example illustrates the connection between lengths of regions in and lengths of

strings in TM’s:

Example 3:

In a conventional computer (see Ex. 1 above), we can deﬁne a “partial string” s

(sometimes called a “ﬁle”) taking up the beginning of an input section as the set of all “complete

strings” taking up the entire input section whose beginning is s. We can then identify the input to

the computer as such a partial string in its input section. (Typically, there would be a special ﬁxed-

size “length of partial string” region even earlier, at the very beginning of the input section, telling

the computer how much of the complete string to read to get that partial string.) If we append cer-

tain bits to s to get a new longer input partial string, s', the set of complete strings consistent with
s' is a proper subset of the set of complete strings consistent with s. Assuming our measure dm
independent of the contents of the “length of partial string” region, this means that l(s') ‡

l(s).

is

This is in accord with the usual deﬁnition of the length of a string used in Turing machine the-
ory. Indeed, if s' contains n more bits than does s, then there are 2n times as many complete strings

consistent with s as there are consistent with s'. Accordingly, if we take logarithms to have base 2,

l(s') = l(s) + n.

Say we want our computer to be able to predict whether ^u lies in some set s

. (To maintain the
analogy with Turing machines, s could delineate an “output partial string”. This could be done for

example by delineating a particular OUTp value, perhaps even one in some other computer.) In
the usual way, this corresponds to having the binary partition { ^u ˛

} be weakly predict-

, ^u ˇ

able to our computer. So the prediction complexity of that prediction is the length of the shortest

region of our input space that will weakly induce that prediction. (Note that since we require that
all four intelligibility functions of s be induced, more than one input “partial string” is required

s
s
for that induction, in general.)

30

The fact that OUTp values specify the set A(OUTq) makes working with Def.’s 10 and 11 a bit

messy. In particular, to relate prediction complexity to properties of the associated universal phys-

ical computer we must use a set of “identity” intelligibility functions deﬁned as follows:

Deﬁnition 12 (i): Given a space X ˝ B and a physical computer C with input and output spaces

{IN} and {OUT} respectively,

{IC

X} is the set of all question-independent intelligibility functions of C where A(IC

X) = X,

and where "

^u such that A(OUTq( ^u )) = X, IC

X( ^u ) = OUTa ( ^u ).

We also will need the following deﬁnition:

Deﬁnition 12 (ii): Given a space X ˝ B and a physical computer C with input and output spaces

{IN} and {OUT} respectively,

when X is a set C-1(X) is also a set, deﬁned as those IN ˛ { IN} such that IN( ^u ) = IN (cid:222)

A(OUTq( ^u )) = X.

[C2]-1(X), I2

X ˛

So for example, if X = B, a pair (IN2 ˛
X}) is an input to C2 and an intelligi-
bility function of C2’s output, respectively. That input IN2 induces an associated output question,
q2 ˛ OUT2
q, that takes on (both) B values as one varies over the ^u input to it. Similarly, the intel-
ligibility function IN2

X takes on (both) B values as one varies over the inputs to it.

{I2

Using these deﬁnitions, we now bound how much more complex a partition can appear to C1
than to C2 if C1 can strongly predict C2. Though somewhat forbidding in appearance, intuitively,
the bound simply reﬂects the complexity cost of “encoding” C2 in C1’s input.

Theorem 8: Given any partition p

 and physical computers C1 and C2 where C1 >> C2 > p

,

31

i) c(p

 | C1)   - c(p

 | C2)

ln[o(2

)]  -  ln[3]  +

max {X˝ B, IN2˛[ C2]-1(X), I2
min {X˝ B, IN2˛[ C2]-1(X)} l[ IN2 ] ,

˛ {I2
X

-1

X}} l[ (C1)

(C2, IN2, I2

X) ]    -

or alternatively,

ii) c(p

 | C1)   - c(p

 | C2)

ln[o(2

)]    +

min {X˝ B, IN2˛[ C2]-1(X),  I2
X
min {X˝ B, IN2˛[ C2]-1(X)} l[ IN2 ]  .

˛ {I2

X}} l[ (C1)

-1

(C2, IN2, I2

X) ]   -

f (cid:222) OUT2

f(IN2

f

, consider any IN2

f ˛ {IN2} that weakly induces f,
p( ^u ) = (A(f), f( ^u )). (The analysis will not be affected if p
that are ques-
f), to strongly induce IN2
p. (Indeed, in general

Proof: Given any intelligibility function f for p
i.e., such that IN2( ^u ) = IN2
is an output partition and we restrict attention to those intelligibility functions for p
tion-independent.) Since C1 >> C2, we can then choose an IN1, IN1
together with any question-independent intelligibility function of OUT2
there can be more than one such value of IN1 that induces IN2
so that the vector OUT1
that IN1, IN2( ^u ) = IN2
OUT2a ( ^u ), which in turn equals f( ^u ) for that IN2. So "
OUT1
ity function for p
IN2
IN2

that IN2
f, the set of ^u ˛
f( ^u ) = IN2
f. This means that l(IN1

^U such that IN1( ^u ) = IN1
f)) ‡

f weakly induces in C2. However since IN1( ^u ) = IN1

A(f)( ^u )) for any possible function I2

q( ^u )) = A(f), which means that I2

A(f). Now for
A(f)( ^u ) =
f),
f) weakly induces in C1 the same intelligibil-

^u such that IN1( ^u ) = IN1

A(f)), I2

p( ^u ) = (A(I2
f, and therefore A(OUT2

f). (Our task, loosely speaking, is to bound this differ-

f.) So in particular, we can choose it

p( ^u ) = (A(f), f( ^u )). In other words, IN1

f(IN2

the set such that IN2( ^u ) =

f(IN2

l(IN2

f(IN2

f(IN2

f) (cid:222)

f(IN2

f) is ˝

ence in lengths, and then to extend the analysis to simultaneously consider all such question-inde-

pendent intelligibility functions f.)

Take {fi} to be the set of all intelligibility functions for p. By the preceding construction, p

is

weakly predictable to C1 with a (not necessarily proper) subset of {IN1

fi(IN2

fi)} being a member

£
p
£
p
32

of (C1)-1(p ). Now any member of (C1)-1(p ) must contain at least three disjoint elements, corre-
q( ^u )) = B, {0}, or {1}. (See the discussion
sponding to intelligibility functions q with A(OUT1
the volume (as measured by dm ) of any subset of

just before Lemma 1.) Accordingly,
{IN1
ing the smallest volume. In other words, the length of any subset of {IN1
must be at most -ln(3) plus the length of the longest element of {IN1
fi(IN2
£ maxfi [l(IN1

(C1)-1(p ) must be at least 3 times the volume of the element of {IN1
fi(IN2
fi)} ˛
fi(IN2
fi)}. Therefore c(p

fi)} hav-
(C1)-1(p )
| C1)

fi(IN2

fi)} ˛

fi))] - ln(3).
fi} to be the set in (C2)-1(p ) with minimal length. {IN2

fi(IN2
Now take {IN2

fi} has at most o(2

) dis-

joint elements, one for each intelligibility function for p
this means that c(p

| C2) ‡

)] + minfi [l(IN2
fi(IN2

fi))] - minfi [l(IN2

fi)]. Therefore we can write c(p

. Using the relation mini[gi] = -maxi [-gi],
| C2)
fi, IN2( ^u ) =

fi)]. The fact that for all IN2

| C1) - c(p

ln[o(2

-ln[o(2
)] - ln(3) + maxfi [l(IN1
 A(OUT2

IN2

q( ^u )) = A(fi) ˝ B completes the proof of (i).

fi
To prove (ii), note that we can always construct one of the sets in (C1)

-1

(p ) by starting with the

set consisting of the element of {IN1
adding other IN1 values to that set, until we get a full (weak) prediction set. Therefore c(p
minfi l(IN1

fi)} having the shortest length, and then successively
| C1) £

fi)). Using this bound rather than the one involving -ln(3) establishes (ii). QED.

fi(IN2

fi(IN2

Note that the set of X ˛ B such that [C2]-1(X) exists must be non-empty, since C2 > p
larly, C2 > p means that there is a ^u such that A(OUTq( ^u )) = X ˝ B. The associated I2
exists by construction: simply deﬁne I2
for all other ^u, I2

X always
^u such that A(OUTq( ^u )) = X, and
X( ^u ) = x for some x ˛ X. Therefore the extrema in our bounds are always well-

X( ^u ) = OUT2a ( ^u ) "

. Simi-

deﬁned.

As one varies p

, in both bounds in Thm. 8 the dependence of the bound on C1 and C2 does not
for all p sharing the same cardinality. So in

change. In addition, those bounds are independent of p
particular they are independent of p

for all binary partitions like those discussed in Ex. 3. This

illustrates how Thm. 7 is the physical computation analogue of the result in Turing machine the-

ory that the difference in algorithmic complexity of a ﬁxed string with respect to two separate Tur-

p
p
£
p
(cid:222)
33

ing machines is bounded by the complexity of “emulating” the one Turing machine on the other,

independent of the ﬁxed string in question.

Consider the possibility that for the laws of physics in our universe, there exist partitions IN(.)
and OUT(.) that constitute a universal physical computer C* for all other physical computers in

our universe. Then by Thm. 5, no other computer is similarly universal. Therefore there exists a

unique prediction complexity measure that is applicable to all physical computers in our universe,
namely complexity with respect to C*. (This contrasts with the case of algorithmic information

complexity, where there is an arbitrariness in the choice of the universal TM used.) If instead there

is no universal physical computer in our universe, then every physical computer C must fail at

least once at (strongly) predicting some other physical computer. (Note that unlike the case with

weak predictability considered in Thm. 2, here we aren’t requiring that the universe be capable of

having two distinguishable versions of C.) This establishes the following:

Theorem 9: Either infallible strong prediction is impossible in our universe, or there is a unique

complexity measure in our universe.

Similar conclusions hold if one restricts attention to a set of (physically localized) conventional

physical computers (cf. Ex. 1 above), where the light cones in the set are arranged to allow the

requisite information to reach the putative universal physical computer.

FUTURE WORK AND DISCUSSION

Any results concerning physical computation should, at a minimum, apply to the computer

lying on a scientist’s desk. However that computer is governed by the mathematics of determinis-

tic ﬁnite automata, not that of Turing machines. In particular, the impossibility results concerning

Turing machines rely on inﬁnite structures that do not exist in any computer on a scientist’s desk.

34

Accordingly, there is a discrepancy between the domain of those results and that of any truly gen-

eral theory of physical computers.

On the other hand, when one carefully analyzes actual computers that perform calculations

concerning the physical world, one uncovers a mathematical structure governing those computers

that is replete with its own impossibility results. While much of that structure parallels Turing

machine theory, much of it has no direct analogue in that theory. For example, this new structure

has no need for tapes, moveable heads, internal states, read/write capabilities, and the like, none

of which have any obvious connection to the laws governing our universe (i.e., any connection to

quantum mechanics and general relativity).

In fact, when the underlying functions of real-world computers are stripped down to their

essentials, one does not even need to identify a “computer” with a device occupying a particular

localized region of space-time, never mind one with heads and the like. In place of all those con-

cepts one has a structure involving several partitions over the space of all worldlines of the uni-

verse. The partitions in that structure delineate a particular computer’s inputs, the questions it

addresses, and its outputs. The impossibility results of physical computation concern the relation

of those partitions. Computers in the conventional, space-time localized sense (the box on your

desk) are simply special examples, with lots of extra restrictions that turn out to be unnecessary in

the underlying mathematics. Accordingly, the general deﬁnition of a “physical computer” has no

such restrictions. A side-beneﬁt of this breadth is that the associated mathematics can be viewed

as concerning many information-processing activities (e.g., observation, control) normally viewed

as distinct from computation.

In the ﬁrst paper in this pair, this deﬁnition of a physical computer was motivated and pre-

sented, along with some associated theorems. Those theorems imply, amongst other things, that

fool-proof prediction of the future is impossible — there are always some questions concerning

the future that cannot even be posed to a computer, and of those that can be posed, there are

always some for which the computer’s answer will be wrong. By exploiting the breadth of the def-

inition of physical “computation”, similar results hold for the information-processing of observa-

tion and of control. All of this is true even in a classical, non-chaotic, ﬁnite universe, and

regardless of the where in the Chomsky hierarchy the computer lies.

35

This second paper launches from the theorems of the ﬁrst paper into a broader, albeit prelimi-

nary investigation of the mathematics of physical computation. It is shown that the computability

structure relating distinct physical computers is that of a directed, acyclic graph. In addition, there

is at most one computer (called a “god computer”) that can predict /observe /control all other

computers. Other results derived include limits on error-correction using multiple computers, and

some analogues of the Halting theorem.

Next a deﬁnition of the complexity of a particular computational task for a particular physical

computer, prediction complexity, is motivated. The motivation of this new deﬁnition of complex-

ity proceeds by analogy to the concept of the algorithmic information complexity of a symbol

sequence for a universal Turing machine. However whereas algorithmic information complexity

concerns a Turing machine’s generating such a symbol sequence, prediction complexity involves

a physical computer’s addressing a computational task concerning the physical universe.

The difference in prediction complexity of a particular task p

for two different physical com-
puters C1 and C2 is considered. It is proven that that complexity difference is bounded by a func-
tion that only depends on C1 and C2, and is independent of p
complexity for two physical computers is analogous to the algorithmic information complexity

. This bound relating the difference in

cost of emulating one universal Turing machine with another one. Finally, it is proven that either a

certain kind of computation is not possible in our universe, or there is a preferred computer in our

universe. If it exists, that computer could be used to uniquely specify the prediction complexity of
any task p
deﬁnition of physical complexity (in contrast to the arbitrariness inherent in algorithmic informa-

. Accordingly, either a certain kind of computation is impossible, or there is a preferred

tion complexity’s choice of universal Turing machine).

The following ideas are just a few of the questions that the analysis of this paper raises:

i) What other restrictions are there on the predictability relations within distinguishable sets of

physical computers beyond that they form unions of DAG’s? In other words, which unions of

DAG’s can be manifested as the predictability relations within a distinguishable set? How does

this answer change depending on whether we are considering sets of fully input-distinguishable

computers or sets of pairwise-distinguishable computers? For what computers are there ﬁnite /

36

countably inﬁnite / uncountably inﬁnite numbers of levels below it in the DAG to which it

belongs? Might such levels be gainfully compared to the conventional computer science theory

issue of position in the Chomsky hierarchy?

ii) One might try to characterize the unpredictability-of-the-future result of paper I as the physical

computation analogue of the following issue in Turing machine theory. Can one construct a Tur-

ing machine M that can take as input A, an encoding of a Turing machine and its tape, and for any

such A compute what state A’s Turing machine will be in after will be in after n steps, and per-

form this computation in fewer than n steps? This characterization suggests investigating the for-

mal parallels (if any) between the results of these papers and the “speed-up” theorems of

computer science.

iii) More speculatively, the close formal connection between the results of this second paper and

those of computer science theory suggest that it may be possible to ﬁnd physical analogues of

most of the other results of computer science theory, and thereby construct a full-blown “physical

computer science theory”. In particular, it may be possible to build a hierarchy of physical com-

puting power, in analogy to the Chomsky hierarchy. In this way we could translate computer sci-

ence theory into physics, and thereby render it physically meaningful.

We might be able to do at least some of this even without relying on the DAG relationship

among the physical computers in a particular set. As an example, we could consider a system that

can correctly predict the future state of the universe from any current state of the universe, before

that future state occurs. The behavior of such a system is perfectly well-deﬁned, since the laws of

physics are fully deterministic (for quantum mechanics this statement implicitly presumes that

one views those laws as regarding the evolution of the wave function rather than of observables

determined by non-unitary transformations of that wave function). Nonetheless, by the central

unpredictability result of paper I, we know that such a system lies too high in the hierarchy to

exist in more than one copy in our physical universe.

37

With such a system identiﬁed with an oracle of computer science theory we have the deﬁni-

tion of a “physical” oracle. Can we construct further analogues with computer science theory by

leveraging that deﬁnition of a physical oracle? In other words, can we take the relationships

between (computer science) oracles, Turing machines, and the other members of the (computer

science) Chomsky hierarchy, and use those relationships together with our (physical) oracle and

physical computers to gainfully deﬁne other members of a (physical) Chomsky hierarchy?

iv) Can we then go further and deﬁne physical analogues of concepts like P vs. NP, and the like?
Might the halting probability constant W

of algorithmic information theory have an analogue in

physical computation theory?

As another example of possible links between conventional computer science theory and that

of physical computers, is there a physical computer analogue of Berry’s paradox? Weakly predict-

ing a partition is the physical computation analogue of “generating a symbol sequence” in algo-

rithmic information complexity. The core of Berry’s paradox is that there are numbers k such that

no Turing machine can generate a sequence having algorithmic information complexity k (with

respect to some pre-speciﬁed universal Turing machine U). So for example one closely related
such that $
issue in physical computation is to characterize the physical computers C1 and x ˛
a computer C2 where C1 >> C2 and where " partitions p, C2 weakly predicts whether c(p
| C1) >
p( ^u ) = (B, whether c(p
x (i.e., such that $
| C1) >

{IN2} such that IN2( ^u ) = IN2 (cid:222) OUT2

IN2 ˛

x)).

v) Concerns of computer science theory, and in particular of the theory of Turing machines, have

recently been incorporated into a good deal of work on the foundations of physics [33}. Future

work involves replacing physical computers for Turing machines in this work, along with replac-

ing notions like prediction complexity for notions like algorithmic complexity.

vi) Other future work involves investigating other possible deﬁnitions of complexity for physical

´
38

computation. Even sticking to analogues of algorithmic information complexity, these might

extend signiﬁcantly beyond the modiﬁcations to the deﬁnition of prediction complexity discussed

in the text. For example, one might try to deﬁne the analogue of a bit sequence’s “length” in terms

of the number of elements in Q. One might also take the (inverse) complexity of a computational

device to be the number of input-distinguishable computers that can predict that device (working

in some pre-speciﬁed input-distinguishable set, presumably).

vii) Yet other future work includes calculating physical complexity of various systems for some of

the simple physical models of real-world computers (e.g., “billiard ball” computers, DNA com-

puting, etc.) that have been investigated, and investigating the prediction complexity of systems

like crystals and gases.

FOOTNOTES

[1] Especially for non-binary p, many other deﬁnitions of prediction complexity besides Def.
11(ii) can be motivated. For example, one could reasonably deﬁne the complexity of p
sum of the complexities of each binary partition induced by an element of p
it as S p˛
in the text even for binary partitions, is minr

, i.e., one could deﬁne
c({ ^u ˛ p, ^u ˇ p} | C). Another variant, one that would differ from the one considered

l(IN)]. For reasons of space, no such

to be the

˛ C-1(p ) [S

IN˛

alternatives will be considered in this paper.

REFERENCES

p
r
39

[1] Adami, C. and Cerf, N.J. (2000). Physica D. 137, pp. 62-69.

[2] Bennett, C.H. (1973). IBM Journal of Research and Development, 17, 525-532.

[3 Bennett, C. H. (1982). International Journal of Theoretical Physics, 21, 905.

[4] Bennett, C. H. (1987). Scientiﬁc American. 257 (11), 88.

[5] Bennett, C. H. (1988). IBM Journal of Research and Development, 32 (no. 1), 16-24.

[6] Berger, J. (1990), International Journal of Theoretical Physics, 29, no. 9, 985-995.

[7] da Costa, N., and Doria, F. (1991). International Journal of Theoretical Physics, 30, 1041.

[8] Farmer, J., and Sidorowich, J. (1988). Exploiting chaos to predict the future and reduce noise,

Los Alamos Laboratory report LA-UR-88-901.

[9] Feynman, R. (1986). Foundations of Physics, 16, 507.

[10] Fredkin, E., and Toffoli, T. (1982). International Journal of Theoretical Physics, 21, 219.

[11] Gell-Mann, M., and Lloyd, S. (1996). Complexity, 2, pp. 44-52.

[12] Geroch, R., Hartle, J. (1986). Foundations of Physics, 16, 533.

[13] Kanter, I. (1990). Physical Review Letters. 64. 332.

[14] Landauer, R. (1961). IBM Journal of Research and Development, 5, 183.

[15] Landauer, R. (1967). IEEE Spectrum. September, 105.

[16] Landauer, R., (1971). Ferroelectrics, 2, 47.

[17] Landauer, R. (1986). Foundations of Physics, 16, 551.

[18] Landauer, R. (1988). Nature, 335, 779-784.

[19] Landauer, R. (1991). PHYSICS TODAY, May, 23.

[20] Lloyd, S. (1990). Any nonlinearity sufﬁces for computation. Cal Tech. report CALT-68-

1689.

[21] Lloyd, S., and Slotine, J.-J. (1996). Int. J. Adapt. Cont. Sig. Proce, 10, p. 499.

[22] Moore, C. (1990). Unpredictability and undecidability in dynamical systems. Physical

Review Letters}, 64, pp. 2354--2357.

[23] Pour-El, M., and Richards, I. (1982). International Journal of Theoretical Physics, 21, 553.

[24] Ruohonen, K. (1997). Complexity, 2, no. 6, p. 41.

40

[25] Touchette, H., and Lloyd, S. (2000). Physical Review Letters. 84, no. 6, pp. 1256-1259.

[26] Wheeler, J.A., and Zurek, W.H. (1983). Quantum theory and measurement. Princeton Uni-

versity Press, Princeton, NJ. 785-786.

[27] Wolpert, D. (1992). PHYSICS TODAY, 98, March.

[28] Wolpert, D. (1992). International Journal of Theoretical Physics, 31, 743-785.

[29] Wolpert, D. (1990). The relationship between many-to-one mappings and thermodynamic

irreversibility. Los Alamos Laboratory report LA-UR-90-4108.

[30] Wolpert, D. (1996). An Incompleteness Theorem for Predicting the Future. Santa Fe Institute

working paper SFI-TR-96-03-008. See also Wolpert, D. (1991). On the computability of the

future. Los Alamos Laboratory Report LA-UR-91-3344.

[31] Wolpert, D. (1990). Complex Systems, 4,151-200, 201-249.

[32] Wolpert, D. (1993). “The Second Law, Computation, and the Temporal (A)symmetry of

Memory”, in Advances in the Physics of Computation, Ed. D. Matzke, IEEE press, 1993.

[33] Zurek, W. (1988). Algorithmic randomness and physical entropy. Los Alamos Laboratory

report LA-UR-88-1547.

ACKNOWLEDGMENTS: This work was done under the auspices of the Department of Energy,

the Santa Fe Institute, and the National Aeronautics and Space Administration. I would like to

thank Bill Macready, Cris Moore, Paul Stolorz, Tom Kepler and Carleton Caves for interesting

discussion.

