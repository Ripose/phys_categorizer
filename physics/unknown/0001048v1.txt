High-resolution path-integral development of ﬁnancial options

Lester Ingber

Lester Ingber Research

POB 06440 Sears Tower, Chicago, IL 60606

and

DRW Inv estments LLC

311 S Wacker Dr, Ste 900, Chicago, IL 60606

ingber@ingber.com, ingber@alumni.caltech.edu

ABSTRACT

The  Black-Scholes  theory  of  option  pricing  has  been  considered  for  many years  as  an

important  but  very  approximate  zeroth-order  description  of  actual  market  behavior. We

generalize the functional form of the diffusion of these systems and also consider multi-factor

models including stochastic volatility. Daily Eurodollar futures prices and implied volatilities

are ﬁt to determine exponents of functional behavior of diffusions using methods of global

optimization, Adaptive Simulated Annealing (ASA), to generate tight ﬁts across moving time

windows  of  Eurodollar  contracts. These  short-time  ﬁtted  distributions  are  then  developed

into  long-time  distributions  using  a  robust  non-Monte  Carlo  path-integral  algorithm,

PATHINT, to generate prices and derivatives commonly used by option traders.

Ke ywords: options; eurodollar; volatility; path integral; optimization; statistical mechanics

0
0
0
2

 

n
a
J
 

3
2

 
 
 

8
4
0
1
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

High-resolution path-integral ...

- 2 -  

Lester Ingber

1.  INTRODUCTION

1.1.  Background

There always is much interest in developing more sophisticated pricing models for ﬁnancial instruments.

In particular, there currently is much interest in improving option pricing models, particularly with respect

to stochastic variables [1-4].

The standard Black-Scholes (BS) theory assumes a lognormal distribution of market prices, i.e., a

diffusion linearly proportional to the market price. However, many texts include outlines of more general

diffusions proportional to an arbitrary power of the market price [5].

The above aspects of stochastic volatility and of more general functional dependencies of diffusions

are  most  often  “swept  under  the  rug”  of  a  simple  lognormal  form. Experienced  traders  often  use  their

own intuition to put volatility “smiles” into the BS theoretical constant coefﬁcient in the BS lognormal

distribution to compensate for these aspects.

It is generally acknowledged that since the market crash of 1987, markets have been increasingly

difﬁcult to describe using the BS model, and so better modelling and computational techniques should be

used  traders [6],  although  in  practice  simple  BS  models  are  the  rule  rather  than  the  exception  simply

because  they are  easy  to  use [7].  To a large  extent,  previous  modelling  that  has  included  stochastic

volatility  and  multiple  factors  has  been  driven more  by  the  desire  to  either  delve into  mathematics

tangential  to  these  issues,  or  to  deal  only  with  models  that  can  accommodate  closed-form  algebraic

expressions.  We do not  see  much  of  the  philosophy in the  literature  that  has  long  driven the  natural

sciences:  to  respect  ﬁrst  raw data,  secondly  models  of  raw data,  and  ﬁnally  the  use  of  numerical

techniques  that  do  not  excessively  distort  models  for  the  sake of ease  of  analysis  and  speed  of

computation.  Indeed, very often the reverse set of priorities is seen in mathematical ﬁnance.

1.2.  Our Approach

We  hav e addressed  the  above  issues  in  detail  within  the  framework  of  a  previously  developed

statistical mechanics of ﬁnancial markets (SMFM) [8-13].

Our approach requires three sensible parts. Part one is the formulation of the model, which to some

extent also involves speciﬁcation of the speciﬁc market(s) data to be addressed. Part two is the ﬁtting of

High-resolution path-integral ...

- 3 -  

Lester Ingber

the model to speciﬁc market data. Part three is the use of the resulting model to calculate option prices

and their Greeks (partial derivatives of the prices with respect to their independent variables), which are

used as risk parameters by traders. Each part requires some speciﬁc numerical tuning to the market under

consideration.

The ﬁrst part was to develop the algebraic model to replace/generalize BS, including the possibility

of  also  addressing  how to handle  data  regions  not  previously  observed  in  trading. This  is  not  absurd;

current BS models perform integrals that must include a much inﬂuence from fat tails that include data

regions never seen or likely to be seen in real-world markets.  There are some issues as to whether we

should take seriously the notion that the market is strongly driven by some element of a “self-fulﬁlling

prophesy” by the BS model [14], but in any case our models have parameters to handle a wide range of

possible cases that might arise.

We  hav e developed two parallel tracks starting with part one, a one-factor and a two-factor model.

The two-factor model includes stochastic volatility. At ﬁrst we sensed the need to develop this two-factor

model, and we now see that this is at the least an important benchmark against which to judge the worth

of the one-factor model.

The second part was to ﬁt the actual raw data so we can come up with real distributions.  Some tests

illustrated that standard quasi-linear ﬁtting routines, could not get the proper ﬁts, and so we used a more

powerful  global  optimization,  Adaptive  Simulated  Annealing  (ASA) [15].  Tuning  and  selection  of  the

time periods to perform the ﬁts to the data were not trivial aspects of this research. Practical decisions

had to be made on the time span of data to be ﬁt and how to aggregate the ﬁts to get sensible “fair values”

for reasonable standard deviations of the exponents in the diffusions.

The third part was to develop Greeks and risk parameters from these distributions without making

premature  approximations  just  to  ease  the  analysis. Perhaps  someday, simple  approximations  and

intuitions similar to what traders now use for BS models will be available for these models, but we do not

think  the  best  approach  is  to  start  out  with  such  approximations  until  we  ﬁrst  see  proper  calculations,

especially  in  this  uncharted  territory. When  it  seemed  that  Cox-Ross-Rubenstein  (CRR)  standard  tree

codes  (discretized  approximations  to  partial  differential  equations) [16]  were  not  stable  for  general

exponents, i.e., for other than the lognormal case, we turned to a PATHINT code developed a decade ago

for some hard nonlinear multifactor problems [17], e.g., combat analyses [18], neuroscience [19,20], and

High-resolution path-integral ...

- 4 -  

Lester Ingber

potentially chaotic systems [21,22].  In 1990 and 1991 papers on ﬁnancial applications, it was mentioned

how these  techniques  could  be  used  for  stochastic  interest  rates  and  bonds [9,10].  The modiﬁcations

required here for one-factor European and then American cases went surprisingly smoothly; we still had

to tune the meshes, etc. The two-factor model presented a technical problem to the algorithm, which we

have  reasonably  handled  using  a  combination  of  selection  of  the  model  in  part  one  and  a  reasonable

approach to developing the meshes.

1.3.  Outline of Paper

Section 1 is this introduction. Section 2 describes the nature of Eurodollar (ED) futures data and

the evidence for stochastic volatility. Section 3 outlines the algebra of modelling options, including the

standard  BS  theory  and  our  generalizations. Section  4  outlines  the  three  equivalent  mathematical

representations  used  by  SMFM;  this  is  required  to  understand  the  development  of  the  short-time

distribution  that  deﬁnes  the  cost  function  we  derive  for  global  optimization,  as  well  as  the  numerical

methods we have dev eloped to calculate the long-time evolution of these short-time distributions.  Section

5 outlines ASA and explains its use to ﬁt short-time probability distributions deﬁned by our models to the

Eurodollar  data;  we  offer  the  ﬁtted  exponent  in  the  diffusion  as  a  new important  technical  indicator  of

market  behavior. Section  6  outlines  PATHINT  and  explains  its  use  to  develop  long-time  probability

distributions  from  the  ﬁtted  short-time  probability  distributions,  for  both  the  one-factor  and  two-factor

tracks.  Section 7 describes  how we use  these  long-time  probability  distributions  to  calculate  European

and  American  option  prices  and  Greeks;  here  we  give  numerical  tests  of  our  approach  to  BS  CRR

algorithms.  Section 8 is our conclusion.

2.  DAT A

2.1.  Eurodollars

Eurodollars are ﬁxed-rate time deposits held primarily by overseas banks, but denominated in US

dollars.  They are  not  subject  to  US  banking  regulations  and  therefore  tend  to  have  a  tighter  bid-ask

spread than deposits held in the United States [23].

High-resolution path-integral ...

- 5 -  

Lester Ingber

2.2.  Futures

The three-month Eurodollar futures contract is one of the most actively traded futures markets in

the world.  The contract is quoted as an index where the yield is equal to the Eurodollar price subtracted

from 100. This yield is equal to the ﬁxed rate of interest paid by Eurodollar time deposits upon maturity

and is expressed as an annualized interest rate based on a 360-day year. The Eurodollar futures are cash

settled based on the 90-day London Interbank Offer Rate (LIBOR). A “notional” principal amount of $1

million, is used to determine the change in the total interest payable on a hypothetical underlying time

deposit, but is never actually paid or received [23].

Currently a total of 40 quarterly Eurodollar futures contracts (or ten years worth) are listed, with

expirations annually in March, June, September and December.

2.3.  Options on Futures

The options traded on the Eurodollar futures include not only 18 months of options expiring at the

same time as the underlying future, but also various short dated options which themselves expire up to

one year prior to the expiration of the underlying futures contract.

2.4.  Front/Back Month Contracts

For purposes  of  risk  minimization,  as  discussed  in  a  previous  paper [4],  traders  put  on  spreads

across a variety of option contracts. One common example is to trade the spread on contracts expiring

one  year  apart,  where  the  future  closer  to  expiration  is  referred  to  as  the  front  month  contract,  and  the

future  expiring  one  year  later  is  called  the  back  month. The  availability  of  short  dated  or  “mid-curve”

options which are based on an underlying back month futures contract, but expire at the same time as the

front month, allow one to trade the volatility ratios of the front and back month futures contracts without

having to take the time differences in option expirations into consideration. We  studied the volatilities of

these types of front and back month contracts. Here, we give analyses with respect only to quarterly data

longer than six months from expiration.

High-resolution path-integral ...

- 6 -  

Lester Ingber

2.5.  Stochastic Volatility

Below we dev elop two-factor models to address stochastic volatility. In a previous paper, we hav e

performed empirical studies of Eurodollar futures to support the necessity of dealing with these issues [4].

3.  MODELS

3.1.  Random walk model

The  use  of  Brownian  motion  as  a  model  for  ﬁnancial  systems  is  generally  attributed  to

Bachelier [24], though he incorrectly intuited that the noise scaled linearly instead of as the square root

relative  to the  random  log-price  variable.  Einstein is  generally  credited  with  using  the  correct

mathematical  description  in  a  larger  physical  context  of  statistical  systems. However,  sev eral  studies

imply that changing prices of many markets do not follow a random walk, that they may have long-term

dependences  in  price  correlations,  and  that  they may  not  be  efﬁcient  in  quickly  arbitraging  new

information [25-27]. A random walk for returns, rate of change of prices over prices, is described by a
Langevin  equation  with  simple  additive  noise h , typically  representing  the  continual  random  inﬂux  of

information into the market.

˙G =  -

g 1 + g 2h ,

˙G = dG

/dt ,

< h (t) >h = 0 , < h (t), h (t¢ ) >h = d (t -

t¢ ) ,  

(1)

where g 1 and g 2 are constants, and G
observable,  may  not  be  the  only  appropriate  dependent  variable  or  order  parameter  for  the  system  of

is the logarithm of (scaled) price. Price, although the most dramatic

markets [28]. This  possibility  has  also  been  called  the  “semistrong  form  of  the  efﬁcient  market

hypothesis” [25].

The generalization of this approach to include multivariate nonlinear nonequilibrium markets led to

a model of statistical mechanics of ﬁnancial markets (SMFM) [8].

High-resolution path-integral ...

- 7 -  

Lester Ingber

3.2.  Black-Scholes (BS) Theory

The  standard  partial-differential  equation  used  to  formulate  most  variants  of  Black-Scholes  (BS)

models describing the market value of an option, V , is

¶ V
¶ t

+ 1
2

s 2S2

¶ 2V
¶ S2

+ rS

¶ V
¶ S

- rV = 0 ,  

(2)

where S is  the  asset  price,  and s

is  the  standard  deviation,  or  volatility  of S, and r is  the  short-term

interest rate. The solution depends on boundary conditions, subject to a number of interpretations, some

requiring minor transformations of the basic BS equation or its solution. For example, the basic equation

can  apply  to  a  number  of  one-dimensional  models  of  interpretations  of  prices  given to V , e.g.,  puts  or

calls, and to S, e.g., stocks or futures, dividends, etc.

For instance, if V is set to C, a call on an European option with exercise price X with maturity at T ,

the solution is

C(S, t) = SN(d1) - Xe

- r(T-

t) N(d2) ,

d1 =

ln(S/X) + (r + 1
s 2)(T -
2
t)1/2

s (T -

d2 =

ln(S/X) + (r -
s (T -

1

s 2)(T -
2
t)1/2

t)

t)

,

.

(3)

In  practice,  the  volatility s

is  the  least  known  parameter  in  this  equation,  and  its  estimation  is

generally  the  most  important  part  of  pricing  options. Usually  the  volatility  is  given in a yearly  basis,

baselined to some standard, e.g., 252 trading days per year, or 360 or 365 calendar days. Therefore, all

values  of  volatility  given in the  graphs  in  this  paper, based  on  daily  data,  would  be  annualized  by
‘252 = 15. 87. We hav e used this factor to present our
multiplying the standard deviations of the yields by (cid:214)

implied volatilities as daily movements.

3.3.  Some Key Issues in Derivation of BS

The basic BS model considers a portfolio in terms of delta (D ),

P = V -

S ,

(4)

‘
‘
D
High-resolution path-integral ...

- 8 -  

Lester Ingber

in a market with Gaussian-Markovian (“white”) noise X and drift m ,

dS
S

= s dX + m dt ,

where V (S, t) inherits a random process from S,

dV = s S

¶ V
¶ S

dX +

m S

¶ V
¶ S

+ 1
2

s 2S2

¶ 2V
¶ S2

+

¶ V
¶ t

dt .

This yields

dP = s (cid:230)

¶ V
¶ S

ł dX +

m S

¶ V
¶ S

+ 1
2

s 2S2

¶ 2V
¶ S2

+

¶ V
¶ t

m D S

dt .

The expected risk-neutral return of P

is

dP = rP dt = r(V -

S)dt .

(5)

(6)

(7)

(8)

Options V on futures F can be derived, e.g., using simple transformations to take cost of carry into

consideration, such as

F = Ser(T-

t) ,

and setting

dP = rV dt .

The corresponding BS equation for futures F is

¶ V
¶ t

+ 1
2

s 2F 2

¶ 2V
¶ S2

- rV = 0 .  

At least two advantages are present if D

is chosen such that

D =

¶ V
¶ S

.

(9)

(10)

(11)

(12)

Then, the portfolio can be instantaneously “risk-neutral,” in terms of zeroing the coefﬁcient of X, as well
as independent of the direction of market, in terms of zeroing the coefﬁcient of m . For the above example

of V = C,

D = N(d1) .  

(13)

(cid:230)
(cid:231)
Ł
(cid:246)
(cid:247)
ł
Ł
-
D
(cid:246)
(cid:230)
(cid:231)
Ł
-
(cid:246)
(cid:247)
ł
D
High-resolution path-integral ...

- 9 -  

Lester Ingber

Other trading strategies based on this simple model use similar constructs as risk parameters, e.g.,

gamma (G ), theta (Q

), vega (¡ ), rho (r ) [5],

¶ 2P
¶ S2 ,

,

¶ t

G =

Q =

¡ =

¶ s

,

.

r =

¶ r

The BS equation, Eq. (2), may be written as

Q + rSD + 1
2

(s S)2G = rf .

3.4. S x Models

Our two-factor model includes stochastic volatility s of the underlying S,

dS = m dt + s F(S, S0, S¥

, x, y) dzS ,

ds = n dt + e dzs

,

< dzi > = 0 , i = {S, s } ,

< dzi(t) dz j(t¢ ) > = dt d (t -

t¢ ) , i = j ,

< dzi(t) dz j(t¢ ) > = r dt d (t -

t¢ ) , i „

j ,

F(S, S0, S¥

, x, y) =

S,
S x S1- x
0
S yS1- x

,

0 S x- y

S < S0
S0 £ S £ S¥
S > S¥

,

,

(14)

(15)

(16)

are selected to lie outside the data region used to ﬁt the other parameters, e.g., S0 = 1
where S0 and S¥
and S¥ = 20  for  ﬁts  to  Eurodollar  futures  which  historically  have  a  very  tight  range  relative  to other

¶
P
¶
P
¶
P
(cid:236)
(cid:239)
(cid:237)
(cid:239)
(cid:238)
¥
High-resolution path-integral ...

- 10 -  

Lester Ingber

markets.  We hav e used the Black-Scholes form F = S inside S < S0 to obtain the usual beneﬁts, e.g., no
negative  prices  as  the  distribution  is  naturally  excluded  from S < 0  and  preservation  of  put-call  parity.

Put-call  parity  for  European  options  is  derived quite  independent  of  any mathematical  model  of

options [5]. In its simplest form, it is given by

c + Xe

- r(T-

t) = p + S ,

(17)

where c ( p) is the fair price of a call (put), X is the strike price, r is the risk-free interest rate, t is the
present time, T is the time of expiration, and S is the underlying market.  We hav e taken y = 0, a normal

distribution, to reﬂect total ignorance of markets outside the range of S > S¥
. The one-factor model just
assumes a constant s . It is often noted that BS models incorrectly include untenable contributions from

large S regions because of their fat tails [29].  (If we wished to handle negative interest rates, ED prices >
100, we would move shift the S = 0 axis to some S < 0 value.)

We  found that the abrupt, albeit continuous, changes across S0 especially for x £ 0 did not cause

any similar effects in the distributions evolved using these diffusions, as reported below.

The  formula  for  pricing  an  option P, derived in a Black-Scholes  generalized  framework  after

factoring out interest-rate discounting, is equivalent to using the form

dS = m S dt + s F(S, S0, S¥

, x, y) dzS ,

ds = n dt + e dzs

.

(18)

We  experimented with some alternative functional forms, primarily to apply some smooth cutoffs
across  the  above  three  regions  of S. For  example,  we  used F¢ , a function F designed  to  revert  to  the

lognormal Black-Scholes model in several limits,

F¢ (S, S0, S¥

, x) = S C0 + (1 - C0) ((S x S1- x

0 C¥ + S0(1 - C¥

))) ,

C0 = exp

|1 - x|
1 + |1 - x|

S
S0

|2- x|+1ø

,

C¥ = exp

2ø

,

S
S¥

lim F¢ (S, S0, S¥

, x„ 1

Sﬁ

, x) = S0 = constant ,

Ø
Œ
º
-
(cid:230)
Ł
(cid:246)
ł
œ
ß
Ø
Œ
º
-
(cid:230)
Ł
(cid:246)
ł
œ
ß
¥
High-resolution path-integral ...

- 11 -  

lim F¢ (S, S0, S¥
Sﬁ 0+

, x) =

lim F¢ (S, S0, S¥
xﬁ 1

, x) = S .

Lester Ingber

(19)

However, our ﬁts were most sensitive to the data when we permitted the central region to be pure S x using

F above.

3.4.1.  Various F(S, x) Diffusions

Fig.  1  gives examples  of F(S, S0, S¥

, x, y) dzS for x in {-1,  0,  1,  2}. The  other  parameters  are

S = 5, S0 = 0. 5, S¥ = 20, y = 0.

Fig. 1.

4.  STATISTICAL MECHANICS OF FINANCIAL MARKETS (SMFM)

4.1.  Statistical Mechanics of Large Systems

Aggregation problems in nonlinear nonequilibrium systems typically are “solved” (accommodated)

by  having  new entities/languages  developed  at  these  disparate  scales  in  order  to  efﬁciently  pass

information  back  and  forth. This  is  quite  different  from  the  nature  of  quasi-equilibrium  quasi-linear

systems, where thermodynamic or cybernetic approaches are possible. These approaches typically fail for

nonequilibrium nonlinear systems.

Many systems  are  aptly  modeled  in  terms  of  multivariate  differential  rate-equations,  known  as

Langevin equations,

˙M G = f G + ˆgG
j

h j , (G = 1, . . . , L

) , ( j = 1, . . . , N) ,

˙M G = dM G/dt ,

< h j(t) >h = 0 , < h j(t), h j¢ (t¢ ) >h = d jj¢ d (t -

t¢ ) ,  

where f G and  ˆgG
microscopic index indicating the source of ﬂuctuations, and N ‡

j are  generally  nonlinear  functions  of  mesoscopic  order  parameters M G,

over repeated indices is used. Vertical bars on an index, e.g., |j|, imply no sum is to be taken on repeated

(20)

j

is  a

. The Einstein convention of summing

L
High-resolution path-integral ...

- 12 -  

Lester Ingber

indices.

Via a somewhat  lengthy,  albeit  instructive  calculation,  outlined  in  several  other  papers [8,10,30],

involving an intermediate derivation of a corresponding Fokker-Planck or Schr¨odinger-type equation for

the conditional probability distribution P[M(t)|M(t0)], the Langevin rate Eq. (20) is developed into the
more  useful  probability  distribution  for M G at  long-time  macroscopic  time  event t = (u + 1)q + t0, in
terms of a Stratonovich path-integral over mesoscopic Gaussian conditional probabilities [31-35].  Here,

macroscopic variables are deﬁned as the long-time limit of the evolving mesoscopic system.

The corresponding Schr¨odinger-type equation is [33,34]

¶ P/¶ t = 1
2

(gGG¢

P),GG¢

(gG P),G + V ,

gGG¢ = kTd jk ˆgG

j ˆgG¢

k

,

gG = f G + 1
2

d jk ˆgG¢

j ˆgG
k,G¢

,

[. . .],G = ¶ [. . .]/¶ M G .

(21)

This  is  properly  referred  to  as  a  Fokker-Planck  equation  when V ” 0.  Note that  although  the  partial

differential  Eq.  (21)  contains  information  regarding M G as  in  the  stochastic  differential  Eq.  (20),  all

references to j have been properly averaged over.  I.e.,  ˆgG

j in Eq. (20) is an entity with parameters in both

microscopic  and  mesoscopic  spaces,  but M is  a  purely  mesoscopic  variable,  and  this  is  more  clearly

reﬂected in Eq. (21).

The path integral representation is given in terms of the “Feynman” Lagrangian L.

P[Mt|Mt0]dM(t) = (cid:242)

. . . (cid:242) DM exp(- S)d [M(t0) = M0]d [M(t) = Mt] ,

S = k

- 1
T min

t

(cid:242) dt¢ L ,

t0

u+1

r =1

DM =

lim
uﬁ

g1/2

(2pq

)- 1/2dM G
r

,

G

L( ˙M G, M G, t) = 1
2

( ˙M G - hG)gGG¢ ( ˙M G¢

- hG¢ ) + 1
2

hG

;G + R/6 - V ,

-
¥
P
P
High-resolution path-integral ...

- 13 -  

Lester Ingber

hG = gG -

1

2

- 1/2(g1/2gGG¢ ),G¢

g

,

gGG¢ = (gGG¢ )- 1 ,

g = det(gGG¢ ) ,

hG

;G = hG

,G + G F

GF hG = g

- 1/2(g1/2hG),G ,

JK ” gLF[JK, L] = gLF(gJL,K + gKL,J - gJK,L) ,
G F

R = gJL RJL = gJL gJK RFJKL ,

RFJKL = 1
2

(gFK,JL - gJK,FL - gFL,JK + gJL,FK ) + gMN (G M

FKG N
JL -

G M

FLG N

JK ) .  

(22)

Mesoscopic  variables  have  been  deﬁned  as M G in  the  Langevin  and  Fokker-Planck  representations,  in

terms of their development from the microscopic system labeled by j. The Riemannian curvature term R

arises from nonlinear gGG¢ , which is a bona ﬁde metric of this space [33].  Even if a stationary solution,
˙M G terms gives rise to these

˙M G = 0, is ultimately sought, a necessarily prior stochastic treatment of

i.e.,

Riemannian  “corrections.” Even for  a  constant  metric,  the  term hG

;G contributes  to L for  a  nonlinear
JT¢ G M G, where the Lagrange multipliers JT¢ G are constraints

mean hG. V may include terms such as

T¢

on M G, which are advantageously modeled as extrinsic sources in this representation; they too may be

time-dependent.

For our  purposes,  the  above  Feynman  Lagrangian  deﬁnes  a  kernel  of  the  short-time  conditional

probability distribution, in the curved space deﬁned by the metric, in the limit of continuous time, whose

iteration  yields  the  solution  of  the  previous  partial  differential  equation  Eq.  (21). This  differs  from  the

Lagrangian  which  satisﬁes  the  requirement  that  the  action  is  stationary  to  the  ﬁrst  order  in dt — the

WKBJ approximation, but which does not include the ﬁrst-order correction to the WKBJ approximation

as  does  the  Feynman  Lagrangian. This  latter  Lagrangian  differs  from  the  Feynman  Lagrangian,

essentially by replacing R/6 above by R/12 [36]. In this sense, the WKBJ Lagrangian is more useful for

some  theoretical  discussions [37].  However,  the  use  of  the  Feynman  Lagrangian  coincides  with  the

numerical method we present here using the PATHINT code.

S
High-resolution path-integral ...

- 14 -  

Lester Ingber

Using the variational principle, JTG may also be used to constrain M G to regions where they are

empirically bound. More complicated constraints may be afﬁxed to L using methods of optimal control

theory [38]. With respect to a steady state P, when it exists, the information gain in state P is deﬁned by

¡ [P] = (cid:242)

. . . (cid:242) DM¢ P ln (P/P) ,

DM¢ = DM/dMu+1 .

(23)

In the economics literature, there appears to be sentiment to deﬁne Eq. (20) by the Ito, rather than

the  Stratonovich  prescription. It  is  true  that  Ito  integrals  have  Martingale  properties  not  possessed  by

Stratonovich integrals [39] which leads to risk-neural theorems for markets [40,41], but the nature of the

proper  mathematics  should  eventually  be  determined  by  proper  aggregation  of  relatively  microscopic

models of markets.  It should be noted that virtually all investigations of other physical systems, which are

also continuous time models of discrete processes, conclude that the Stratonovich interpretation coincides
with reality, when multiplicative noise with zero correlation time, modeled in terms of white noise h j, is

properly  considered  as  the  limit  of  real  noise  with  ﬁnite  correlation  time [42].  The path  integral

succinctly demonstrates the difference between the two: The Ito prescription corresponds to the prepoint
discretization  of L, wherein q ˙M(t) ﬁ M r +1 - M r and M(t) ﬁ M r . The  Stratonovich  prescription
and
corresponds 

q ˙M(t) ﬁ M r +1 - M r

discretization 

to 

the  midpoint 

of

L, wherein

M(t) ﬁ

1

2

(M r +1 + M r ).  In terms  of  the  functions  appearing  in  the  Fokker-Planck  Eq.  (21),  the  Ito

prescription of the prepoint discretized Lagrangian, L I , is relatively simple, albeit deceptively so because

of its nonstandard calculus.

L I ( ˙M G, M G, t) = 1
2

( ˙M G - gG)gGG¢ ( ˙M G¢

- gG¢ ) - V .

(24)

In the absence of a nonphenomenological microscopic theory, the difference between a Ito prescription

and a Stratonovich prescription is simply a transformed drift [36].

There are several other advantages to Eq. (22) over Eq. (20). Extrema and most probable states of

M G, << M G >>, are  simply  derived by a variational  principle,  similar  to  conditions  sought  in  previous

studies [43]. In the Stratonovich prescription, necessary, albeit not sufﬁcient, conditions are given by

d G L = L,G - L, ˙G:t

= 0 ,

High-resolution path-integral ...

- 15 -  

Lester Ingber

L, ˙G:t

= L, ˙GG¢ ˙M G¢ + L, ˙G ˙G¢ ¨M G¢

.

(25)

For stationary  states,

˙M G = 0,  and ¶ L/¶ M G = 0 deﬁnes  << M G >>, where  the  bars  identify  stationary

variables; in this case, the macroscopic variables are equal to their mesoscopic counterparts. [Note that L
is not the stationary solution of the system, e.g., to Eq. (21) with ¶ P/¶ t = 0.  However, in some cases [44],

L is a deﬁnite aid to ﬁnding such stationary states.] Many times only properties of stationary states are

examined, but here a temporal dependence is included. E.g., the ˙M G terms in L permit steady states and

their ﬂuctuations to be investigated in a nonequilibrium context.  Note that Eq. (25) must be derived from

the path integral, Eq. (22), which is at least one reason to justify its development.

4.2.  Correlations

Correlations  between  variables  are  modeled  explicitly  in  the  Lagrangian  as  a  parameter  usually
designated r (not to be confused with the Rho Greek calculated for options). This section uses a simple
two-factor  model  to  develop  the  correspondence  between  the  correlation r in  the  Lagrangian  and  that

among the commonly written Weiner distributions dz.

Consider coupled stochastic differential equations

dr = f r(r, l)dt + ˆgr(r, l)s 1dz1 ,

dl = f l(r, l)dt + ˆgl(r, l)s 2dz2 ,

< dzi >= 0 , i = {1, 2} ,

< dzi(t)dz j(t¢ ) >= dtd (t -

t¢ ) , i = j ,

< dzi(t)dz j(t¢ ) >= r dtd (t -

t¢ ) , i „

j ,

d (t -

t¢ ) =

0 , ,
1 ,

t „
t¢
t = t¢

,
,

where < . >  denotes expectations.

These can be rewritten as Langevin equations (in the Itoˆ prepoint discretization)

dr/dt = f r + ˆgrs 1(g +

n1 + sgnrg

n2) ,

(26)

(cid:236)
(cid:237)
(cid:238)
-
High-resolution path-integral ...

- 16 -  

Lester Ingber

dl/dt = gl + ˆgls 2(sgnrg

n1 + g +

n2) ,

g – = 1
2

[1 –

(1 -

r 2)1/2]1/2 ,

ni = (dt)1/2 pi ,

where p1 and p2 are independent [0,1] Gaussian distributions.

The equivalent short-time probability distribution, P, for the above set of equations is

P = g1/2(2p dt)- 1/2 exp(- Ldt) ,

L = 1
2

F †gF ,

F = (cid:230)

dr/dt -
dl/dt -

f r)
f l)

,

g = det(g) ,

k = 1 -

r 2 .

g, the metric in {r, l}-space, is the inverse of the covariance matrix,

- 1 =

g

( ˆgrs 1)2
r ˆgr ˆgls 1s 2

r ˆgr ˆgls 1s 2
( ˆgls 2)2

.

(27)

(28)

(29)

The  above  also  corrects  previous  papers  which  inadvertently  dropped  the  sgn  factors  in  the

above [9,10,17].

5.  ADAPTIVE SIMULATED ANNEALING (ASA) FITS

5.1.  ASA Outline

The algorithm developed which is now called Adaptive Simulated Annealing (ASA) [45] ﬁts short-

time probability distributions to observed data, using a maximum likelihood technique on the Lagrangian.

This algorithm has been developed to ﬁt observed data to a theoretical cost function over a D-dimensional

parameter space [45], adapting for varying sensitivities of parameters during the ﬁt. The ASA code can

-
(cid:214)
‘
Ł
(cid:246)
ł
(cid:230)
(cid:231)
Ł
(cid:246)
(cid:247)
ł
High-resolution path-integral ...

- 17 -  

Lester Ingber

be obtained at no charge, via WWW from http://www.ingber.com/ or via FTP from ftp.ingber.com [15].

5.1.1.  General description

Simulated annealing (SA) was developed in 1983 to deal with highly nonlinear problems [46], as an

extension  of  a  Monte-Carlo  importance-sampling  technique  developed  in  1953  for  chemical  physics

problems.  It helps to visualize the problems presented by such complex systems as a geographical terrain.

For example,  consider  a  mountain  range,  with  two “parameters,” e.g.,  along  the  North−South  and

East−West  directions. We  wish  to  ﬁnd  the  lowest  valley in this  terrain. SA  approaches  this  problem

similar to using a bouncing ball that can bounce over mountains from valley to valley.  We start at a high

“temperature,” where the temperature is an SA parameter that mimics the effect of a fast moving particle

in a hot object like a hot molten metal, thereby permitting the ball to make very high bounces and being

able  to  bounce  over any  mountain  to  access  any valley,  giv en enough  bounces. As  the  temperature  is

made  relatively  colder, the  ball  cannot  bounce  so  high,  and  it  also  can  settle  to  become  trapped  in

relatively smaller ranges of valleys.

We  imagine that our mountain range is aptly described by a “cost function.” We deﬁne probability

distributions of the two directional parameters, called generating distributions since they generate possible

valleys  or  states  we  are  to  explore.  We deﬁne  another  distribution,  called  the  acceptance  distribution,

which depends on the difference of cost functions of the present generated valley we are to explore and

the last saved lowest valley.  The acceptance distribution decides probabilistically whether to stay in a new

lower  valley or to bounce  out  of  it. All  the  generating  and  acceptance  distributions  depend  on

temperatures.

In 1984 [47], it was established that SA possessed a proof that, by carefully controlling the rates of

cooling  of  temperatures,  it  could  statistically  ﬁnd  the  best  minimum,  e.g.,  the  lowest  valley of our

example above. This was good news for people trying to solve hard problems which could not be solved

by other algorithms. The bad news was that the guarantee was only good if they were willing to run SA

forever.  In 1987,  a  method  of  fast  annealing  (FA)  was  developed [48], which  permitted  lowering  the

temperature exponentially faster, thereby statistically guaranteeing that the minimum could be found in

some  ﬁnite  time. However,  that  time  still  could  be  quite  long. Shortly  thereafter, Very  Fast  Simulated

Reannealing  (VFSR)  was  developed  in  1987 [45],  now called  Adaptive  Simulated  Annealing  (ASA),

High-resolution path-integral ...

- 18 -  

Lester Ingber

which is exponentially faster than FA.

ASA  has  been  applied  to  many problems  by  many people  in  many disciplines [49-51]. The

feedback of many users regularly scrutinizing the source code ensures its soundness as it becomes more

ﬂexible and powerful.

5.1.2.  Mathematical outline

ASA considers a parameter a i

k in dimension i generated at annealing-time k with the range

a i
k

˛ [Ai, Bi] ,  

calculated with the random variable yi,

k+1 = a i
a i

k

+ yi(Bi - Ai) ,

yi ˛ [- 1, 1] .

The generating function gT (y) is deﬁned,

gT (y) = D
i=1

1

2(|yi| + Ti) ln(1 + 1/Ti)

” D
i=1

gi
T (yi) ,  

(30)

(31)

(32)

where the subscript i on Ti speciﬁes the parameter index, and the k-dependence in Ti(k) for the annealing

schedule has been dropped for brevity. Its cumulative probability distribution is

GT (y) =

. . .

y1

- 1

yD

- 1

(cid:242) dy¢ 1 . . . dy¢ D gT (y¢ ) ” D

P Gi
i=1

T (yi) ,

T (yi) = 1
Gi
2

+ sgn (yi)

2

ln(1 + |yi|/Ti)
ln(1 + 1/Ti)

.

yi is generated from a ui from the uniform distribution

ui ˛ U[0, 1] ,

yi = sgn (ui -

1

2

)Ti[(1 + 1/Ti)|2ui- 1| - 1] .

It is straightforward to calculate that for an annealing schedule for Ti

Ti(k) = T0i exp(- ci k1/D) ,  

(33)

(34)

(35)

P
P
(cid:242)
High-resolution path-integral ...

- 19 -  

Lester Ingber

a global minima statistically can be obtained. I.e.,

gk »

k0

D

1

i=1

2|yi|ci

= ¥

]

1
k

[

k0

.

Control can be taken over ci, such that

T fi = T0i exp(- mi) when k f = exp ni ,

ci = mi exp(- ni/D) ,  

(36)

(37)

where mi and ni can be considered “free” parameters to help tune ASA for speciﬁc problems.

ASA has over 100 OPTIONS available for tuning. A few important ones were used in this project.

5.1.3.  Reannealing

Whenever doing a multi-dimensional search in the course of a complex nonlinear physical problem,
inevitably  one  must  deal  with  different  changing  sensitivities  of  the a i in  the  search. At  any giv en

annealing-time,  the  range  over which  the  relatively  insensitive  parameters  are  being  searched  can  be

“stretched  out”  relative  to the  ranges  of  the  more  sensitive  parameters.  This can  be  accomplished  by

periodically  rescaling  the  annealing-time k, essentially  reannealing,  every  hundred  or  so  acceptance-

ev ents (or at some user-deﬁned modulus of the number of accepted or generated states), in terms of the

sensitivities si calculated at the most current minimum value of the cost function, C,

si = ¶ C/¶ a i .

(38)

In terms of the largest si = smax, a default rescaling is performed for each ki of each parameter dimension,
whereby a new index k¢ i is calculated from each ki,

ki ﬁ

k¢ i ,

T¢ ik¢ = Tik(smax/si) ,

k¢ i = ((ln(Ti0/Tik¢ )/ci))D .

(39)

Ti0 is set to unity to begin the search, which is ample to span each parameter dimension.

¥
S
¥
S
P
High-resolution path-integral ...

- 20 -  

Lester Ingber

5.1.4.  Quenching

Another adaptive feature of ASA is its ability to perform quenching in a methodical fashion.  This

is applied by noting that the temperature schedule above can be redeﬁned as

Ti(ki) = T0i exp(- ci kQi/D

i

) ,

ci = mi exp(- niQi/D) ,  

in terms of the “quenching factor” Qi. The sampling proof fails if Qi > 1 as

DP

1/kQi/D =

1/kQi < ¥

.

k

k

(40)

(41)

This simple calculation shows how the “curse of dimensionality” arises, and also gives a possible

way of living with this disease. In ASA, the inﬂuence of large dimensions becomes clearly focussed on

the  exponential  of  the  power  of k being  1/D, as the  annealing  required  to  properly  sample  the  space

becomes prohibitively slow.  So, if resources cannot be committed to properly sample the space, then for

some systems perhaps the next best procedure may be to turn on quenching, whereby Qi can become on

the order of the size of number of dimensions.

The scale of the power of 1/D temperature schedule used for the acceptance function can be altered

in  a  similar  fashion.  However,  this  does  not  affect  the  annealing  proof  of  ASA,  and  so  this  may  used

without damaging the sampling property.

5.2. x-Indicator of Market Contexts

Our studies of contexts of markets well recognized by option traders to have signiﬁcantly different

volatility  behavior  show that  the  exponents x are  reasonably  faithful  indicators  deﬁning  these  different

contexts.

We  feel  the  two-factor  model  is  more  accurate  because  the  data  indeed  demonstrate  stochastic

volatility [4]. We  also note that the two-factor x’s  are quite robust and uniform when being ﬁt by ASA

across the last few years.  This is not true of the one-factor ASA ﬁtted x’s unless we do not use the Black-
Scholes s as a parameter, but rather calculate as historical volatility during all runs. Some results of two-
factor studies and one-factor studies using a Black-Scholes s have been reported elsewhere [13].

S
S
High-resolution path-integral ...

- 21 -  

Lester Ingber

Since s is not widely traded and arbitraged, to ﬁt the two-factor model, we calculate this quantity

as an historical volatility for both its prepoint and postpoint values.  Some previous studies used a scaled
implied volatility (which is calculated from a BS model). We use a standard deviation s ¢ ,

s ¢ = StdDev((dS / F(S, S0, S¥

, x, y))) .  

(42)

In the one-factor model, it does not make good numerical sense to have two free parameters in one
term, i.e., s and x, as these cannot be ﬁt very well within the variance the data. Instead, one method is to
take guidance from the two-factor results, to set a scale for an effective s , and then ﬁt the parameter x.
Another method it apply the above StdDev as a proxy for s . Some motivation for this approach is given

by  considering  collapsing  a  two-factor  stochastic  volatility  model  in  one-factor  model:  The  one-factor

model now has an integral over the stochastic process in its diffusion term. The is integral is what we are

approximating by using the standard deviation of a moving window of the data.

6.  PATH-INTEGRAL (PATHINT) DEVELOPMENT

6.1.  PATHINT Outline

The ﬁts described above clearly demonstrate the need to incorporate stochastic volatility in option

pricing  models.

If  one-factor  ﬁts  are  desired,  e.g.,  for  efﬁciency of calculation,  then  at  the  least  the

exponent of price x should be permitted to freely adapt to the data. In either case, it is required to develop

a full  set  of  Greeks  for  trading. To  meet  these  needs,  we  have  used  a  path-integral  code,  PATHINT,

described below, with great success. At this time, the two-factor code takes too long to run for daily use,

but it proves to be a good weekly baseline for the one-factor code.

The PATHINT algorithm develops the long-time probability distribution from the Lagrangian ﬁt by

the  ﬁrst  optimization  code. A robust  and  accurate  histogram-based  (non-Monte  Carlo)  path-integral

algorithm  to  calculate  the  long-time  probability  distribution  has  been  developed  to  handle  nonlinear

Lagrangians [18-20,22,52-54],

The histogram procedure recognizes that the distribution can be numerically approximated to a high
degree of accuracy as sum of rectangles at points Mi of height Pi and width D Mi. For convenience, just
consider a one-dimensional system. The above path-integral representation can be rewritten, for each of

its intermediate integrals, as

High-resolution path-integral ...

- 22 -  

Lester Ingber

P(M; t + D

t) = (cid:242) dM¢ [g1/2

s

(2p D

t)- 1/2 exp(- LsD

t)]P(M¢ ; t) = (cid:242) dM¢ G(M, M¢ ; D

t)P(M¢ ; t) ,

P(M; t) = N
i=1

p (M - Mi)Pi(t) ,

p (M - Mi) =

1

D Mi- 1) £ M £

0 ,  (Mi -
1 ,  otherwise ,

2

(Mi + 1
2

D Mi) ,

,

which yields

Pi(t + D

t) = Tij(D

t)P j(t) ,

Tij(D

t) =

2

D Mi- 1 + D Mi

(cid:242) Mi+D Mi/2
D Mi- 1/2
Mi-

dM (cid:242) M j+D M j/2
D M j- 1/2

M j-

dM¢ G(M, M¢ ; D

t) .  

(43)

(44)

Tij is a banded matrix representing the Gaussian nature of the short-time probability centered about the

(varying) drift.

Care must be used in developing the mesh in D M G, which is strongly dependent on the diagonal

elements of the diffusion matrix, e.g.,

D M G »

(D

tg|G||G|)1/2 .

(45)

Presently, this constrains the dependence of the covariance of each variable to be a nonlinear function of

that  variable,  albeit  arbitrarily  nonlinear, in order  to  present  a  straightforward  rectangular  underlying

mesh.  Below we address how we hav e handled this problem in our two-factor stochastic-volatility model.

Fitting  data  with  the  short-time  probability  distribution,  effectively  using  an  integral  over this

epoch,  permits  the  use  of  coarser  meshes  than  the  corresponding  stochastic  differential  equation. The

coarser  resolution  is  appropriate,  typically  required,  for  numerical  solution  of  the  time-dependent  path-
integral: By considering the contributions to the ﬁrst and second moments of D M G for small time slices q ,

conditions on the time and variable meshes can be derived [52].  The time slice essentially is determined
- 1, where L is the “static” Lagrangian with dM G/dt = 0, throughout the ranges of M G giving the
by q £ L
most important contributions to the probability distribution P. The variable mesh, a function of M G, is
optimally chosen such that D M G is measured by the covariance gGG¢ , or D M G» (gGGq )1/2.

S
(cid:236)
(cid:239)
(cid:237)
(cid:239)
(cid:238)
High-resolution path-integral ...

- 23 -  

Lester Ingber

If the histogram method is further developed into a trapezoidal integration, then more accuracy can

be  expected  at  more  complex boundaries [53]. Such  problems  does  not  arise  here,  and  6−7  signiﬁcant

ﬁgure accuracy is easily achieved provided great care is taken to develop the mesh as described above.

For example,  after  setting  the  initial-condition  discretized  delta  function MSUPG at  the  prepoint  of  an

interval, the mesh going forward in M G is simply calculated stepwise using

D M G = (gGGq )1/2 .

(46)

However, going backwards in M G, an iterative procedure was used at each step, starting with an estimate

from the prepoint and going forward again, until there was no mismatch. That much care is required for

the mesh was observed in the original Wehner-Wolfer paper [52].

It  is  important  to  stress  that  very  good  numerical  accuracy is required  to  get  very  good  Greeks

required for real-world trading. Many authors develop very efﬁcient numerical schemes to get reasonable

prices to 2 or 3 signiﬁcant ﬁgures, but these methods often are not very good to enough signiﬁcant ﬁgures

to get good precision for the Greeks. Typical Monte Carlo methods are notorious for giving such poor

results  after  very  long  computer  runs. In  particular, we do not  believe  that  good  Greeks  required  for

trading can be obtained by using meshes obtained by other simpler algorithms [55].

The PATHINT algorithm in its present form can “theoretically” handle any n-factor model subject

to its diffusion-mesh constraints. In practice, the calculation of 3-factor and 4-factor models likely will

wait until giga-hertz speeds and giga-byte RAM are commonplace.

6.2.  Development of Long-Time Probabilities

The noise determined empirically as the diffusion of the data is the same, independent of x within

our  approach. Therefore,  we  scale  different  exponents  such  that  the  the  diffusions,  the  square  of  the

“basis-point volatilities” (BPV), are scaled to be equivalent.  Then, there is not a very drastic change in

option prices for different exponents x for the strike X set to the S underlying, the at-the-money (ATM)

strike.  This is  not  the  case  for  out  of  the  money (OTM)  or  in  the  money (ITM)  strikes,  e.g.,  when

exercising the strike would generate loss or proﬁt, resp. This implies that current pricing models are not

radically mispricing the markets, but there still are signiﬁcant changes in Greeks using more sophisticated

models.

High-resolution path-integral ...

- 24 -  

Lester Ingber

6.3.  Dependence of Probabilities on S and x

Fig. 2 gives examples of the short-time distribution evolved out to T = 0. 5 year for x in {-1, 0, 1,
2}, with 500 intermediate epochs/foldings, and BS s = 0. 0075. Each calculation scales s by multiplying

by S/F(S, S0, S¥

, x, y).

Fig. 2.

Fig. 3 gives an example of a two-factor distribution evolved out to T = 0. 5 year for x = 0. 7.

Fig. 3.

6.4.  Two-Factor Volatility and PATHINT Modiﬁcations

In  our  two-factor  model,  the  mesh  of S would  depend  on s and  cause  some  problems  in  any

PATHINT grid to be developed in S-s .

For some  time  we  have  considered  how to handle  this  generic  problem  for n-factor  multivariate

systems with truly multivariate diffusions within the framework of PATHINT. In one case, we have taken

advantage of the Riemannian invariance of the probability distribution as discussed above, to transform to

a system where the diffusions have only “diagonal” multiplicative dependence [19]. However, this leads

to cumbersome numerical problems with the transformed boundary conditions [20].  Another method, not

yet fully tested, is to develop a tiling of diagonal meshes for each factor i that often are suitable for off-

diagonal regions in an n-factor system, e.g.,

D M i
k

= 2mi

kD M i
0 ,

‘ ‘
D M i
0 »

‘g|i||i|

k0

t ,

(47)

where the mesh of variable i at a given point labeled by k is an exponentiation of 2, labeled by mi

k; the

integral power mi
the one-factor PATHINT mesh conditions, in terms of some minimal mesh D M i

k is determined such that it gives a good approximation to the diagonal mesh given by

0, throughout regions of

the Lagrangian giving most important contributions to the distribution as predetermined by a scan of the

(cid:214)
‘
D
High-resolution path-integral ...

- 25 -  

Lester Ingber

system.  This tiling of the kernel is to be used together with interpolation of intermediate distributions.

The results of our study here are that, after the at-the-money BPV are scaled to be equivalent, there

is not a very drastic change in the one-factor ATM Greeks developed below.  Therefore, while we have
not  at  all  changed  the  functional  dependence  of  the  Lagrangian  on S and s , we hav e determined  our
meshes using a diffusion for the S equation as s 0 F(S, S0, S¥
, x, y), where s 0 is determined by the same
BPV-equivalent condition as imposed on the one-factor models. This seems to work very well, especially
since we have  taken our s equation to be normal with a limited range of inﬂuence in the calculations.
Future work yet has to establish a more deﬁnitive distribution for s .

7.  CALCULATION OF DERIVATIVES

7.1.  Primary Use of Probabilities For European Options

We  can use PATHINT to develop the distribution of the option value back in time from expiration.

This is the standard approach used by CRR, explicit and implicit Crank-Nicolson models, etc [56].

For European  options,  we  also  take advantage  of  the  accuracy of PATHINT  enhanced  by

normalizing the distribution as well as the kernel at each iteration (though in these studies this was not

required  after  normalizing  the  kernel).  Therefore, we  have  calculated  our  European  option  prices  and

Greeks  using  the  most  elementary  and  intuitive  deﬁnition  of  the  option’s price V [57],  which  is  the

expected value

V = < max[z(S - X), 0] > ,

z = 1 ,
z = - 1 ,

call
put

,

(48)

where X is  the  strike price,  and  the  expected  value  < . >  is taken  with  respect  to  the risk-neutral

distribution  of  the  underlying  market S.

It should  be  noted  that,  while  the  standard  approach  of

developing the option price delivers at the present time a range of underlying values for a given strike, our

approach delivers a more practical complete range of strikes (as many as 50−60 for Eurodollar options)

for a given underlying at the present time, resulting in a greatly enhanced numerical efﬁciency.  The risk-

neutral distribution is effectively calculated taking the drift as the cost-of-carry b times S, using the above

arguments leading to the BS formula. We  hav e designed our codes to use parameters risk-free-rate r and

cost-of-carry b such that

(cid:236)
(cid:237)
(cid:238)
High-resolution path-integral ...

- 26 -  

Lester Ingber

b = r, cost of carry on nondividend stock ,

b = r - q, cost of carry on stock paying dividend yield q ,

b = 0, cost of carry on future contract ,

b = r - r f , cost of carry on currency with rate r f ,

which is similar to how generalized European BS codes use b and r [58].

Using this approach, the European price V E is calculated as

V E = <<  max[[z(e(b- r)T ST - e

- rT X), 0]] >> .  

(49)

(50)

The  American  price V A must  be  calculated  using  a  different  kernel  going  back  in  time  from

expiration, using as “initial conditions” the option values used in the above  average.  This kernel is the

transposed matrix used for the European case, and includes additional drift and “potential” terms due to

the need to develop this back in time. This can be understood as requiring the adjoint partial differential

equation or a postpoint Lagrangian in real time.

That is, a forward equation for the conditional probability distribution P[M(t + dt), t + dt|M(t), t] is

¶ P/¶ t = 1
2

(gGG¢

P),GG¢

(gG P),G + V ,

(51)

where the partial derivatives with respect to M G act on the postpoint M G(t + dt).  A backward equation
for the conditional probability distribution P[M(t + dt), t + dt|M(t), t] is

¶ P/¶ t = 1
2

gGG¢

P,GG¢

- gG P,G + V ,

(52)

where the partial derivatives with respect to M G act on the prepoint M G(t).  The forward equation has a

particularly simple form in the mathematically equivalent prepoint path integral representation.

Above, we hav e described  how the  forward  distribution  at  present  time T0 is  evolved  using

PATHINT  to  the  time  of  expiration, P(T ),  e.g.,  using  a  path-integral  kernel K folded  over n epochs,

where it is folded with the function O,

V = < O(T ) P(T ) > = < O((K n P(t0))) > ,

O(T ) = max[[z(e(b- r)T ST - e

- rT X), 0]] ,  

(53)

-
High-resolution path-integral ...

- 27 -  

Lester Ingber

to determine the European value at the present time of the calls and puts at different strike values X. An

equivalent  calculation  can  be  performed  by  using  the  backward  equation,  expressed  in  terms  of  the

“equivalent” kernel K † acting on O,

V = < O(T ) P(T ) > = < ((K nO(T )))P(t0) > .  

(54)

It is convenient to use the simple prepoint representation for the Lagrangian, so the backward kernel is

ﬁrst re-expressed as a forward kernel by bringing the diffusions and drifts inside the partial derivatives,

giving a transformed adjoint kernel K †.

The  above  mathematics  is  easily  tested  by  calculating  European  options  going  forwards  and

backwards.  For American options, while performing the backwards calculation, at each point of mesh,

the options price evolving backwards from T is tested and calculated as

Onew = max[(S - X), (e

- rdtOold)] .

(55)

The Greeks {D

, G

, Q}

are directly taken off the ﬁnal developed option at the present time, since the M G

mesh  is  available  for  all  derivatives.  We get  excellent  results  for  all  Greeks. Note  that  for  CRR  trees,
only one point of mesh is at the present time, so D

requires moving back one epoch and G

requires moving

back two epochs, unless the present time is pushed back additional epochs, etc.

7.2.  PATHINT Baselined to CRR and BS

The  CRR  method  is  a  simple  binomial  tree  which  in  a  speciﬁc  limit  approaches  the  BS  partial

differential equation. It has the virtues of being fast and readily accommodates European and American

calculations.  However, it suffers a number of well-known numerical problems, e.g., a systematic bias in

the  tree  approximation  and  an  oscillatory  error  as  a  function  of  the  number  of  intermediate
epochs/iterations in its time mesh. Some Greeks like {D

can be directly taken off the tree used for

, G

, Q}

pricing with reasonable approximations (at epochs just before the actual current time). The ﬁrst problem

for American options can be alleviated somewhat by using the variant method [5],

CRRvariant = CRRAmerican - CRREuropean + BS .

(56)

The  second  problem  can  be  alleviated  somewhat  by  averaging  runs  of n iterations  with  runs  of n + 1

iterations [59]. This  four-fold  increase  of  runs  is  rarely  used,  though  perhaps  it  should  be  more  often.

Furthermore,  if  increased  accuracy in price  is  needed  in  order  to  take numerical  derivatives,  typically

High-resolution path-integral ...

- 28 -  

Lester Ingber

200−300  iterations  should  be  used  for  expirations  some  months  away,  not  30−70  as  too  often  used  in

practice.

When  taking  numerical  derivatives there  can  arise  a  need  to  tune  increments  taken  for  the

differentials.  For some Greeks like D

and G

the size of the best differentials to use may vary with strikes

that have different sensitivities to parts of the underlying distribution.  One method of building in some

adaptive  ﬂexibility  across  many such  strikes  is  to  increase  the  order  of  terms  used  in  taking  numerical

derivatives.  (This was not required for results presented here.) For example, it is straightforward to verify

that, while the central difference

df
dx

= f (x + dx) -
2dx

f (x - dx)

is typically good to o(((dx)3)),

=

df
dx

f (x + 2dx) + 8 f (x + dx) - 8 f (x - dx) + f (x - 2dx)

12dx

is typically good to o(((dx)5)). Similarly, while

d2 f
dx2

= f (x + dx) - 2 f (x) + f (x - dx)

dx dx

is typically good to (((dx)4)),

d2 f
dx2

=

- d(x + 2dx) + 16 f (x + dx) - 30 f (x) + 16 f (x - dx) -

f (x - 2dx)

dx dx

is typically good to (((dx)6)).

(57)

(58)

(59)

(60)

Table 1 gives an example of baselining our one-factor PATHINT code to the CRR and BS codes

using the above safeguards for an option whose American price is the same as its European counterpart, a

typical  circumstance [58].  In the  literature,  the  CRR  code  is  most  often  taken  as  the  benchmark  for

American calculations. We took the number of intermediate epochs/points to be 300 for each calculation.
Parameters used for this particular ATM call are T = 0. 5 years, r = 0. 05, b = 0, s = 0. 10.

Table 1.

-
High-resolution path-integral ...

- 29 -  

Lester Ingber

Tests  with  American  CRR  and  American  PATHINT  lead  to  results  with  the  same  degrees  of

accuracy.

7.3.  Two-Factor PATHINT Baselined to One-Factor PATHINT

Previous  papers  and  tests  have  demonstrated  that  the  two-factor  PATHINT  code  performs  as

expected.  The code was developed with only a few lines to be changed for running any n-factor problem,

i.e., of course after coding the Lagrangian speciﬁc to a given system.  Tests were performed by combining

two one-factor problems, and there is no loss of accuracy.  Howev er, here we are making some additional
mesh  approximations  as  discussed  above  to accommodate s

in  the S diffusion.  This seems  quite

reasonable, but there is no sure test of the accuracy.  We indeed see that the ATM results are very close

across x’s, similar to our ATM comparisons between BS and our one-factor PATHINT results for various
x’s, where again scaling is performed to have all models used the same BPV (using the s 0 procedure for
the mesh as described above for the two-factor model).

The  logical  extension  of  Greeks  for  the  two-factor  model  is  to  develop  derivatives of price  with
respect to r and e in s volatility equation. However, we did not ﬁnd a bona ﬁde two-factor proxy for the
one-factor ¡
, the derivative of price with respect to the one-factor s constant.  We get very good ATM ¡

comparisons between BS and our one-factor models with various x’s. We tried simply multiplying the

noise in the two-factor stochastic volatility in the price equation by a parameter with deviations from 1 to

get numerical derivatives of PATHINT solutions, and this gav e somewhat good agreement with the ATM
BPV-scaled  BS ¡ within  a  couple  of  signiﬁcant  ﬁgures. Perhaps  this  is  not  too  surprising,  especially
given the correlation substantial r between the price and volatility equations which we do not neglect.

8.  CONCLUSIONS

The  results  of  our  study  are  that,  after  the  at-the-money basis-point  volatilities  are  scaled  to  be

equivalent, there is only a very small change in option prices for different exponents x, both for the one-

factor and two-factor models. There still are signiﬁcant differences in Greeks using more sophisticated

models,  especially  for  out-of-the-money options.  This implies  that  current  pricing  models  are  not

radically mispricing the markets.

High-resolution path-integral ...

- 30 -  

Lester Ingber

Our  studies  point  to  contexts  of  markets  well  recognized  by  option  traders  to  have  signiﬁcantly

different  volatility  behavior. Suppression  of  stochastic  volatility  in  the  one-factor  model  just  leaks  out

into stochasticity of parameters in the model, e.g., especially in x, unless additional numerical methods

are employed, e.g., using an adaptive standard deviation.  Our studies show that the two-factor exponents

x are reasonably faithful indicators deﬁning these different contexts.  The x-exponents in the two-factor

ﬁts are quite stable. As such, especially the two-factor x can be considered as a “context indicator” over a

longer  time  scale  than  other  indicators  typically  used  by  traders. The  two-factor  ﬁts  also  exhibit
differences due to the s parameters, including the r correlations, in accord with the sense traders have

about the nature of changing volatilities across this time period.

Modern methods of developing multivariate nonlinear multiplicative Gaussian-Markovian systems

are quite important, as there are many such systems and the mathematics must be diligently exercised if

such  models  are  to  faithfully  represent  the  data  they describe.  Similarly, sophisticated  numerical

techniques,  e.g.,  global  optimization  and  path  integration  are  important  tools  to  carry  out  the  modeling

and  ﬁtting  to  data  without  compromising  the  model,  e.g.,  by  unwarranted  quasi-linear  approximations.

Three quite different systems have beneﬁted from this approach:

The  large-scale  modeling  of  neocortical  interactions  has  beneﬁted  from  the  use  of  intuitive

constructs  that  yet  are  faithful  to  the  complex algebra  describing  this  multiple-scaled  complex system.

For example,  canonical-momenta  indicators  have  been  successfully  applied  to  multivariate  ﬁnancial

markets.

It is clear that ASA optimization and PATHINT path-integral tools are very useful to develop the

algebra of statistical mechanics for a large class of nonlinear stochastic systems encountered in ﬁnance.

However, it also is clear that each system typically presents its own non-typical unique character and this

must  be  included  in  any such  analysis. A virtue  of  this  statistical  mechanics  approach  and  these

associated tools is they appear to be ﬂexible and robust to handle quite different systems.

ACKNOWLEDGMENTS

I thank  Donald  Wilson  for  his  support  and  Jennifer  Wilson  for  collaboration  running  ASA  and

PATHINT calculations. Implied volatility and yield data was extracted from the MIM database of Logical

Information Machines (LIM).

High-resolution path-integral ...

- 31 -  

Lester Ingber

REFERENCES

1. 

L. Ederington and W. Guan, Is implied volatility an informationally efﬁcient and effective predictor

of future volatility?, U Oklahoma, Norman, OK, (1998).

2. 

G. Bakshi,  C.  Cao,  and  Z.  Chen,  Pricing  and  hedging  long-term  options,  Pennsylvania  State  U,

University Park, PA, (1998).

3. 

L. Ingber, Some Applications of Statistical Mechanics of Financial Markets, LIR-98-1-SASMFM,

Lester Ingber Research, Chicago, IL, (1998).

4. 

L. Ingber and J.K. Wilson, Volatility of volatility of ﬁnancial markets, Mathl. Computer Modelling

29, 39-57 (1999).

5. 

J.C. Hull, Options,  Futures,  and  Other  Derivatives,  Third Edition, Prentice  Hall,  Upper  Saddle

River, NJ, (1997).

6. 

J.C. Jackwerth, Recovering risk aversion from option prices and realized returns, London Business

School, London, UK, (1998).

7. 

F.A. Longstaff and E.S. Schwartz, Valuing American options by simulation: A simple least-squares

approach, Capital Management Sciences, Los Angels, CA, (1998).

8. 

L. Ingber, Statistical  mechanics  of  nonlinear  nonequilibrium  ﬁnancial  markets, Math.  Modelling

5 (6), 343-361 (1984).

9. 

L.

Ingber, Statistical  mechanical  aids  to  calculating  term  structure  models, Phys.  Rev.  A

42 (12), 7057-7064 (1990).

10.  L. Ingber, M.F. Wehner, G.M.  Jabbour, and  T.M.  Barnhill,  Application  of  statistical  mechanics

methodology 

to 

term-structure 

bond-pricing  models, Mathl.  Comput.  Modelling

15 (11), 77-98 (1991).

11.  L. Ingber, Statistical  mechanics  of  nonlinear  nonequilibrium  ﬁnancial  markets:  Applications  to

optimized trading, Mathl. Computer Modelling 23 (7), 101-121 (1996).

12.  L. Ingber, Canonical momenta indicators of ﬁnancial markets and neocortical EEG, in Progress in

Neural  Information  Processing, (Edited  by  S.-I.  Amari,  L.  Xu,  I.  King,  and  K.-S.  Leung),  pp.

777-784, Springer, New York, (1996).

High-resolution path-integral ...

- 32 -  

Lester Ingber

13.  L. Ingber and J.K. Wilson, Statistical mechanics of ﬁnancial markets: Exponential modiﬁcations to

Black-Scholes, Mathl. Computer Modelling , (to be published) (1999).

14.  C. Azariadis, Self-fulﬁlling prophecies, J. Econ. Theory 25, 380-396 (1981).

15.  L. Ingber, Adaptive  Simulated  Annealing  (ASA),  Global  optimization  C-code,  Lester  Ingber

Research, Chicago, IL, (1993).

16. 

J. C.  Cox,  S.  A.  Ross,  and  M.  Rubenstein,  Option  pricing:  A  simpliﬁed  approach, J.  Fin.  Econ.

7, 229-263 (1979).

17.  L. Ingber, Data mining and knowledge discovery via statistical mechanics in nonlinear stochastic

systems, Mathl. Computer Modelling 27 (3), 9-31 (1998).

18.  L. Ingber, H. Fujio,  and  M.F. Wehner, Mathematical  comparison  of  combat  computer  models  to

exercise data, Mathl. Comput. Modelling 15 (1), 65-90 (1991).

19.  L. Ingber, Statistical  mechanics  of  neocortical  interactions:  Path-integral  evolution  of  short-term

memory, Phys. Rev. E 49 (5B), 4652-4664 (1994).

20.  L. Ingber and P.L. Nunez, Statistical mechanics of neocortical interactions: High resolution path-

integral calculation of short-term memory, Phys. Rev. E 51 (5), 5074-5083 (1995).

21.  L. Ingber, R. Srinivasan,  and  P.L.  Nunez,  Path-integral  evolution  of  chaos  embedded  in  noise:

Dufﬁng neocortical analog, Mathl. Computer Modelling 23 (3), 43-53 (1996).

22.  L. Ingber, Path-integral  evolution  of  multivariate  systems  with  moderate  noise, Phys.  Rev.  E

51 (2), 1616-1619 (1995).

23.  Federal Reserve Bank, Instruments of the Money Markets, Seventh Edition, Federal Reserve Bank

of Richmond, Richmond, VA, (1993).

24.  L. Bachelier, The´orie de la Spe´culation, Annales de l’Ecole Normale Supe´rieure 3 (1900).

25.  M. C. Jensen, Some anomalous evidence regarding market efﬁciency,  an editorial introduction, J.

Finan. Econ. 6, 95-101 (1978).

26.  B. B. Mandelbrot, When can price be arbitraged efﬁciently? A limit to the validity of the random

walk and martingale models, Rev. Econ. Statist. 53, 225-236 (1971).

27.  S. J. Taylor, Tests of the random walk hypothesis against a price-trend hypothesis, J. Finan. Quant.

Anal. 17, 37-61 (1982).

High-resolution path-integral ...

- 33 -  

Lester Ingber

28.  P. Brown, A. W. Kleidon, and T. A. Marsh, New evidence on the nature of size-related anomalies in

stock prices, J. Fin. Econ. 12, 33-56 (1983).

29.  F.J. Fabozzi, Tr easury Securities and Derivatives, Fabozzi Associates, New Hope, PA, (1998).

30.  L. Ingber, Statistical  mechanics  of  neocortical  interactions:  A  scaling  paradigm  applied  to

electroencephalography, Phys. Rev. A 44 (6), 4017-4060 (1991).

31.  K.S. Cheng,  Quantization  of  a  general  dynamical  system  by  Feynman’s path  integration

formulation, J. Math. Phys. 13, 1723-1726 (1972).

32.  H. Dekker, Functional  integration  and  the  Onsager-Machlup  Lagrangian  for  continuous  Markov

processes in Riemannian geometries, Phys. Rev. A 19, 2102-2111 (1979).

33.  R. Graham, Path-integral methods in nonequilibrium thermodynamics and statistics, in Stochastic

Processes  in  Nonequilibrium  Systems, (Edited  by  L.  Garrido,  P. Seglar, and  P.J.  Shepherd),  pp.

82-138, Springer, New York, NY, (1978).

34.  F. Langouche,  D.  Roekaerts,  and  E.  Tirapegui,  Discretization  problems  of  functional  integrals  in

phase space, Phys. Rev. D 20, 419-432 (1979).

35.  F. Langouche, D. Roekaerts, and E. Tirapegui, Short derivation of Feynman Lagrangian for general

diffusion process, J. Phys. A 113, 449-452 (1980).

36.  F. Langouche,  D.  Roekaerts,  and  E.  Tirapegui, Functional  Integration  and  Semiclassical

Expansions, Reidel, Dordrecht, The Netherlands, (1982).

37.  M. Rosa-Clot and S. Taddei, A path integral approach to derivative security pricing: I. Formalism

and analytic results, INFN, Firenze, Italy, (1999).

38.  P. Hagedorn, Non-Linear Oscillations, Oxford Univ., New York, NY, (1981).

39.  B. Oksendal, Stochastic Differential Equations, Springer, New York, NY, (1998).

40. 

J.M. Harrison and D. Kreps, Martingales and arbitrage in multiperiod securities markets, J. Econ.

Theory 20, 381-408 (1979).

41.  S.R. Pliska, Introduction to Mathematical Finance, Blackwell, Oxford, UK, (1997).

42.  C.W. Gardiner, Handbook of Stochastic Methods for Physics, Chemistry and the Natural Sciences,

Springer-Verlag, Berlin, Germany, (1983).

High-resolution path-integral ...

- 34 -  

Lester Ingber

43.  R. C. Merton, An intertemporal capital asset pricing model, Econometrica 41, 867-887 (1973).

44.  L. Ingber, Statistical mechanics of neocortical interactions: Stability and duration of the 7+−2 rule

of short-term-memory capacity, Phys. Rev. A 31, 1183-1186 (1985).

45.  L. Ingber, Very fast simulated re-annealing, Mathl. Comput. Modelling 12 (8), 967-973 (1989).

46.  S. Kirkpatrick,  C.D.  Gelatt,  Jr.,  and  M.P. Vecchi,  Optimization  by  simulated  annealing, Science

220 (4598), 671-680 (1983).

47.  S. Geman and D. Geman, Stochastic relaxation, Gibbs distribution and the Bayesian restoration in

images, IEEE Trans. Patt. Anal. Mac. Int. 6 (6), 721-741 (1984).

48.  H. Szu and R. Hartley, Fast simulated annealing, Phys. Lett. A 122 (3-4), 157-162 (1987).

49.  M. Wofsey,  Technology: Shortcut tests validity of complicated formulas, The Wall Street Journal

222 (60), B1 (1993).

50.  L.

Ingber, Simulated  annealing:  Practice  versus 

theory, Mathl.  Comput.  Modelling

18 (11), 29-57 (1993).

51.  L. Ingber, Adaptive  simulated  annealing  (ASA):  Lessons  learned, Control  and  Cybernetics

25 (1), 33-54 (1996).

52.  M.F. Wehner  and  W.G.  Wolfer, Numerical  evaluation  of  path-integral  solutions  to  Fokker-Planck

equations. I., Phys. Rev. A 27, 2663-2670 (1983).

53.  M.F. Wehner  and  W.G.  Wolfer, Numerical  evaluation  of  path-integral  solutions  to  Fokker-Planck

equations. II. Restricted stochastic processes, Phys. Rev. A 28, 3003-3011 (1983).

54.  M.F. Wehner  and  W.G.  Wolfer, Numerical  evaluation  of  path  integral  solutions  to  Fokker-Planck

equations. III. Time and functionally dependent coefﬁcients, Phys. Rev. A 35, 1795-1801 (1987).

55.  M. Rosa-Clot and S. Taddei, A path integral approach to derivative security pricing: II. Numerical

methods, INFN, Firenze, Italy, (1999).

56.  P. Wilmott, S. Howison, and J. Dewynne, The Mathematics of Financial Derivatives, Cambridge U

Press, Cambridge, (1995).

57.  L. Ingber, A simple options training model, Mathl. Computer Modelling 30, 167-182 (1999).

High-resolution path-integral ...

- 35 -  

Lester Ingber

58.  E.G. Haug, The  Complete  Guide  to  Option  Pricing  Formulas, McGraw-Hill,  New York,  NY,

(1997).

59.  M. Broadie  and  J.  Detemple,  Recent  advances  in  numerical  methods  for  pricing  derivative

securities, in Numerical Methods in Finance, (Edited by L.C.G Rogers and D. Talay), pp. 43-66,

Cambridge University Press, Cambridge, UK, (1997).

High-resolution path-integral ...

- 36 -  

Lester Ingber

FIGURE CAPTIONS

FIG. 1. (a) F(S, S0, S¥

, x, y) for x = 1, the Black-Scholes case. The other parameters are S = 5,

S0 = 0. 5, S¥ = 20, y = 0.  (b) F(S, S0, S¥
for x = - 1.  (d) F(S, S0, S¥

, x, y) for x = 2.

, x, y) for x = 0, the normal distribution.  (c) F(S, S0, S¥

, x, y)

FIG.  2. The  short-time  probability  distribution  at  time T = 0. 5 years  for x = 1,  the  (truncated)
Black-Scholes  distribution.  The short-time  probability  distribution  at  time T = 0. 5 years  for x = 0,  the
normal distribution.  The short-time probability distribution at time T = 0. 5 years for x = - 1.  The short-
time probability distribution at time T = 0. 5 years for x = 2.

FIG. 3. A two-factor distribution evolved out to T = 0. 5 year for x = 0. 7.

High-resolution path-integral ...

- 37 -  

Lester Ingber

TABLE CAPTIONS

Table 1. Calculation of prices and Greeks are given for closed form BS (only valid for European

options), binomial tree CRREuropean, CRRAmerican, CRRvariant, and PATHINT. As veriﬁed by calculation,

the American option would not be exercised early, so the PATHINT results are identical to the European

option.  The CRRAmerican differs  somewhat  from  the  CRREuropean due  to  the  discrete  nature  of  the

calculation.  All CRR calculations include averaging over 300 and 301 iterations to minimize oscillatory

errors.

High-resolution path-integral ...

- Figure 1 -

Lester Ingber

20

18

16

14

12

10

8

6

4

2

0

(a) x = 1

x = 1

0

2

4

6

8

10 12 14 16 18 20
S

(c) x = -1

x = -1

)

S
(
F

)

S
(
F

0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

(b) x = 0

x = 0

0

2

4

6

8 10 12 14 16 18 20

S

(d) x = 2

x = 2

)

S
(
F

0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

800

700

600

500

)

S
(
F

400

300

200

100

0

0

2

4

6

8 10 12 14 16 18 20

0

2

4

6

8 10 12 14 16 18 20

S

S

High-resolution path-integral ...

- Figure 2 -

Lester Ingber

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0
3.5

4

4.5

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

y
t
i
l
i

b
a
b
o
r
P
 
e
m
T
-
g
n
o
L

i

y
t
i
l
i

 

b
a
b
o
r
P
e
m
T
-
g
n
o
L

i

(a) x = 1

x = 1

6

6.5

7

5.5

5
Price

(c) x = -1

x = -1

y
t
i
l
i

b
a
b
o
r
P
 
e
m
T
-
g
n
o
L

i

y
t
i
l
i

 

b
a
b
o
r
P
e
m
T
-
g
n
o
L

i

(b) x = 0

x = 0

3

3.5

4

4.5

5

5.5

6

6.5

7

Price

(d) x = 2

x = 2

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

3

3.5

4

4.5

5
Price

5.5

6

6.5

0
3.5

4

4.5

5.5

5
Price

6

6.5

7

High-resolution path-integral ...

- Figure 3 -

Lester Ingber

Two-Factor Probability

Long-Time Probability

100

0

3.75

4

4.25

4.5

4.75

5

Price

0.195

0.19

0.185

0.18

0.175

Volatility

0.17

0.165

6

0.16

6.25

5.25

5.5

5.75

High-resolution path-integral ...

- Table 1 -

Lester Ingber

Greek 

Price 

Delta 

Gamma 

Theta 

Rho 

Ve ga

BS

0.138

0.501

1.100

-0.131

-0.0688

1.375 

CRREuropean

CRRAmerican

CRRvariant

PATHINT

0.138 

0.530 

1.142 

0.138 

0.534 

1.159 

0.138 

0.506 

1.116 

-0.130 

-0.132 

-0.133 

-0.0688 

-0.0530 

-0.0530 

1.375 

1.382 

1.382 

0.138

0.501

1.100

-0.131

-0.0688

1.375

