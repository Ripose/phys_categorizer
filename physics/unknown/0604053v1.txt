1 

Ferguson5 

Canada 

CA  95616, USA 

MA 02215, USA. 

Ergodicity in Natural Earthquake Fault Networks  

K. F. Tiampo1, J. B. Rundle2, W. Klein3, J. Holliday2, J.S. Sá Martins4, & C. D. 

[1] Department of Earth Sciences, University of Western Ontario, London, Ontario, 

[2] Center for Computational Science and Engineering, University of California, Davis, 

[3] Dept. of Physics and Center for Computational Science, Boston University, Boston, 

[4] Instituto de Fisica, Universidade Federal Fluminense, Av. Litoranea s/n, Boa 

Viagem, Niteroi 24210-340, RJ, Brazil 

[5] Council on Foreign Relations, 1779 Massachusetts Avenue, Washington, DC 20036, 

USA  

Numerical  simulations  suggest  that  certain  driven  nonlinear  systems  can  be 
characterized  by  mean-field  statistical  properties  often  associated  with  ergodic 
dynamics  [1-3].      These  driven  mean-field  threshold  systems  feature  long-range 
interactions and can be treated as equilibrium-like systems with dynamics that are 
statistically stationary over long time intervals.  Recently the equilibrium property 
of ergodicity was identified in one example of a natural, driven threshold system, 
an  earthquake  fault  network,  by  means  of  the  Thirumalai-Mountain  (TM) 
fluctuation metric developed in the study of diffusive systems [4].  In this work we 
analyze  the  seismicity  of  three  earthquake  faults  networks  from  a  variety  of 
tectonic  settings  around  the  world  in  an  attempt  to  investigate  the  range  of 
applicability  of  effective  ergodicity,  using  the  TM  metric  and  other  associated 
statistics  for  each  data  set.    Results  suggest  that  all  of  these  natural  earthquake 
systems  display  effective  ergodicity,  and  that  ergodicity  depends  on  the 
relationship  between  the  spatial  and  temporal  scales,  discretization,  and 
magnitude.    These  systems  display  punctuated  ergodicity,  residing  in  metastable 
wells for varying periods of time, as in the mean field models that have been used 
to study these networks.  This analysis supports the application of the principles of 
equilibrium  statistical  mechanics  to  partially  explain  the  physics  of  earthquake 
fault systems from different tectonic settings.  
  

2 

I. Introduction 

Driven  threshold  systems  represent  some  of  the  most  important  nonlinear,  self-

organizing systems in nature, and include neural nets, magnetic de-pinning transitions in 
superconductors,  domain  rearrangements  in  flowing  foams,  charge  density  waves  in 
semiconductors, earthquake fault networks, and the World Wide Web, as well as many 
political, social, and ecological systems [5-12]. All of these systems have dynamics that 

are  strongly  correlated  in  space  and  time,  and  all  typically  display  a  multiplicity  of 
spatial and temporal scales. In particular, if the range of interactions between elements 
of  the  system  is  long  and  the  coupling  weak  [13,  14],  so  that  the  dynamics  can  be 
interpreted  as  mean-field,  fluctuations  tend  to  be  suppressed  and  the  system  may 

approach an equilibrium state [1-3]. Recent work in the study of nonequilibrium physics 
using computer simulations of simplified models of natural dissipative systems suggests 
that certain equilibrium-like properties may be recovered at the appropriate spatial and 
temporal  scales.  A  number  of  investigators  have  shown  that  models  of  statistically 

stationary,  driven  dissipative  mean-field  systems  appear  to  demonstrate  effectively 
ergodic dynamics and these model systems reside in a sequence of physical states that 
are similar to equilibrium, or metastable equilibrium, states [1-4]. Recently, we showed 
that  one  particular  naturally  occurring  system,  an  earthquake  fault  network, 

demonstrates the same effectively ergodic, or equilibrium-like, properties [3].  
To  summarize  our  results:  We  have  applied  a  fluctuation  metric  developed  by 
 
Thirumalai and Mountain to test for the presence of ergodic dynamics in seismic data 
obtained from  three very different tectonic regimes. Previous work [1-4] suggests that 

the  elastic  interaction,  which  is  known  to  be  long-range,  is  responsible  for  inducing  a 
mean-field  condition  in  earthquake  fault  systems.  We  find  similar  results  in  all  three 
cases, despite the different seismicity levels, driving forces, and catalog completeness, 
providing support for the conclusion that the stationary dynamics of natural earthquake 

fault systems also represent effectively ergodic, equilibrium-like dynamics. 
 
II. Earthquake Dynamics 

A  key  element  of  driven  threshold  systems  is  that  their  dynamics  are  strongly 

correlated  in  space  and  time  over  a  multiplicity  of  spatial  and  temporal  scales.    In 
particular,  if  the  range  of  interactions  between  elements  of  the  system  is  long  and  the 
coupling weak, so that the dynamics can be understood as mean-field, fluctuations tend 
to be suppressed, but not eliminated, and the system may approach an equilibrium state 

(i.e.,  described  by  a  Boltzmann  factor)  [13,  14].    In  addition,  Boltzmann  fluctuations, 
which are an important property of equilibrium systems, have been directly observed in 

3 

driven mean-field slider block simulations [5, 15-19].  Ferguson et al. showed, using a 
fluctuation  metric  originally  developed  to  test  for  the  presence  of  ergodic  behavior  in 
thermal  systems  [20,  21],  that  driven  mean-field  cellular  automata  versions  of  slider 

block  models  could  also  be  considered  to  demonstrate  ergodic  behavior  over  finite 
intervals of time [2].  The same result was obtained for the Burridge-Knopoff model of 
earthquake  systems  [22].    Finally,  direct  observations  of  Gaussian  fluctuations  and 
detailed  balance  in  transition  probabilities  provide  evidence  of  ergodic  behavior  in  a 

driven system of mean-field coupled map lattices [3]. 

One  critical  question  is  whether  these  conclusions  from  models  of  driven, 
dissipative systems can be extended to natural driven systems.  We previously showed 
that  the  California  earthquake  fault  system  displayed  ergodic  behavior  over  a  large 

enough spatial and temporal region [4]. 

Driven nonlinear threshold systems are composed of interacting spatial networks 
of cells, each with one or more inputs, an internal state variable σ(t) that evolves in time 
in  response  to  inputs,  and  one or  more  outputs.    Each  cell  is  connected  to  an  external 

driving  source,  and  to  the  other  cells  by  means  of  an  interaction  network.    Threshold 
dynamics arises when a cell is subjected to this persistent external forcing that increases 
F
the value of σ(t) through time until a predefined failure threshold σ
 is reached.  At that 
time  the  cell  fails,  reducing  σ(t)  to  a  residual  value  σR.    Thresholds,  residual  values, 
internal states, and the resulting dynamics are all modified by the presence of noise and 
disorder.    Interactions  between  cells  leads  to  dynamical  self-organization  in  these 
systems,  and  may  be  excitatory  (positive)  in  the  sense  that  failure  of  connected 
neighbors brings a cell closer to firing, or inhibiting (negative) in the opposite case [23].  

Mean-field  threshold  systems  arise  when  the  coupling,  or  interaction,  between  cells  is 
long  range  but  weak,  leading  to  suppression  of  all  but  the  longest  wavelength 
fluctuations.  These dynamics often result in strong space-time correlations in oscillator 
firings, along with the appearance of multiple scales in space and time. 

In the mean-field regime, as the interaction length becomes large, resulting in a 
damping of the fluctuations, a mean-field spinodal appears that is the classical limit of 
stability  of  a  spatially  extended  system  [24-26].    Examined  in  this  limit,  driven 
threshold  systems  often  display  equilibrium-like  behavior,  including  locally  ergodic 

properties.   

Following the initial discovery that driven mean-field slider block systems with 
microscopic  noise  display  equilibrium  properties  [1,  5],  other  studies  have  confirmed 
local ergodicity, the existence of Boltzmann fluctuations in both these and other mean- 

or near mean-field systems, and the appearance of an energy landscape, similar to other 
equilibrium  systems  [2-4,  15-19].    Thus  the  origin  of  the  physics  of  scaling,  critical 

4 

phenomena  and  nucleation  appears  to  be  connected,  at  least  in  part,  to  the  ergodic 
properties of these mean-field systems. 

In the 1990s, two major developments in seismic research greatly added to the 

understanding  of  earthquake  fault  network  as  a  complex  dynamical  system.  Stress 
transfer  interaction  studies  demonstrated  that  fault  interactions  are  in  large  part 
controlled  by  the  stress  state  of  the  underlying  geophysical  medium  [27-31].  On  the 
other hand, a combination of theoretical analysis and numerical simulations established 

the  link  between  earthquake  fault  networks  and  the  physics  of  critical  point  systems, 
characterized by nonlinear dynamics, nonclassical nucleation, large correlation lengths, 
and the Gutenberg-Richter scaling law [1-4, 17, 32-48].   

As  in  other  threshold  systems,  interactions  in  the  natural  earthquake  system 

occur along a spatial network of cells, or fault segments, and are mediated by means of 
a  potential  that,  in  this  case,  allows  stresses  to  be  redistributed  to  other  segments 
following slip on any particular segment.  For faults embedded in a linear elastic host, 
this  potential  is  a  stress  Green's  function  whose  exact  form  is  calculated  from  the 

equations  of  linear  elasticity,  once  the  geometry  of  the  fault  system  is  specified.    A 
persistent driving force, arising from plate tectonic motions, increases stress on the fault 
segments [1, 2, 17]. 

Once  the  stresses  reach  a  threshold  characterizing  the  limit  of  stability  of  the 

fault, a sudden slip event occurs.  The slipping  segment then  may trigger slip  at other 
locations  on  the  fault  surface  whose  stress  levels  are  near  the  failure  threshold  at  that 
time.    In  this  manner,  larger  earthquakes  result  from  the  interactions  and  nonlinear 
nature of the stress thresholds [1, 2, 45, 47]. 

Because the external fault  medium is elastic, the interactions between different 
patches  and  different  faults  are  also  elastic  over  short  time  scales.  This  fundamental 
elastic interaction results in the formulation of a  mean-field regime for the earthquake 
system  [1,  45,  47].  This  mean-field  behavior  occurs  in  elastic  systems  due  to  the 
inverse-cube nature of the stress Green's function (proportional to 1/|x-x′|3) that controls 
the  elastic  stress  interactions  between  the  fault  patches  in  the  medium  [1,  2].  These 
long-range  interactions  lead  to  an  averaging  of  stress  over  the  system,  damping  the 
effects of short wavelength details [48]. Longer spatial and temporal wavelength effects 

become increasingly important, and the correlation lengths become increasingly larger 
as they approach a spinodal critical point, in association with power law scaling similar 
to the Gutenberg-Richter relation [1, 41, 48, 49]. 

The  specific  example  used  to  represent  these  driven  mean-field  threshold 

systems  characterized  by  Langevin  dynamics  with  additive  noise  is  the  slider  block 
model  for  earthquake  faults.    Consider  a  two-dimensional  (d=2)  network  of  blocks 

5 

sliding on a frictional surface, with the blocks arranged in a regular lattice pattern.  Each 
block is connected to q other blocks by means of linear coupling springs, each having a 
spring  constant  KC,  and  to  a  loader  plate  by  means  of  a  loader  spring,  again  linear, 
having constant KL.  The loader plate translates at a fixed velocity V.  In the simplest 
case of nearest-neighbor interactions, q = 2d, but when q >> 2d, and qKC → constant, 
mean-field systems result [1-2, 17].  For slider block models, the state variable σi(t) is 
the force or stress on the ith block.  The persistent motion of the loader plate raises the 
level of stress on all blocks over time. When σi(t) = σF, the block begins to slide, and 
comes to rest when σi = σR.  The original Burridge-Knopoff slider block model, which 
had  massive  blocks,  has  recently  been  shown  to  display  the  ergodicity  property  when 
the  springs  between  the  blocks  are  long-range  [22].    Other  investigations  emphasized 

the  use  of  Stochastic  Continuous  Cellular  Automaton  (SCCA)  models,  in  which  the 
blocks  are  massless,  the  motion  is  over-damped,  and  in  which  the  sliding  block  is 
subjected  to  an  additional  small-amplitude  random  force  that  plays  the  role  of  a 
thermalizing  noise  [1-2,  17].    In  these  SCCA  models,  frequently  used  to  model 

earthquake fault systems, ergodic properties also have been observed [1-2, 4]. 

In 

these  numerical  simulations,  mean-field  earthquake  networks  are 
nonequilibrium systems that can exhibit properties of equilibrium systems as they settle 
into  a  metastable  equilibrium  state.  The  time  averaged  elastic  energy  of  the  system 

fluctuates  around  a  constant  value  for  some  long  period  of  time.  These  periods  are 
punctuated  by  major  events  which  reorder  the  system  before  it  settles  into  another 
metastable well around a new mean energy state [1-2, 4, 48].  During these reorderings 
the system is not ergodic; hence, we refer to these systems as punctuated ergodic. 

Note  that  the  spatial  and  temporal  firing  patterns  of  such  driven  threshold 
systems  are  emergent  processes  that  develop  from  the  obscure  underlying  structures, 
parameters,  and  dynamics  of  a  multidimensional  nonlinear  system  [50].    As  a  result, 
these  patterns  are  complex  and  often  difficult  to  understand  and  interpret  from  a 

deterministic  perspective.    For  example,  while  it  is  not  possible  to  measure  all  the 
cellular  potentials  of  the  neurons  of  the  human  brain  and  the  physical  and  chemical 
parameters  which  control  the  temporal  evolution  of  its  potentials  and  currents,  it  is 
possible to observe the complex firing patterns of neural cells [51, 52].  Similarly, there 

is no means at present to measure the stress and strain at every point in an earthquake 
fault system, or the constitutive parameters that characterize this heterogeneous medium 
and its dynamics, but those patterns that express themselves in the resulting seismicity 
can be observed from the surface of the earth [53-58]. 

This  seismicity,  the  firing  patterns  that  are  the  surface  expression  or  proxy  for 
the  dynamical  state  of  the  underlying  fault  system,  can  be  located  in  both  space  and 

6 

time  with  considerable  accuracy  [59-61].  If  this  natural  system  is,  as  simulations 
suggest, a mean-field threshold system in punctuated metastable equilibrium [1, 2, 48], 
then the time averaged elastic energy of the system fluctuates around a constant value 

for some period of time.  These periods are punctuated by major events that reorder the 
system  before  it  settles  into  another  metastable  energy  well.    Here  we  will  employ  a 
quantity called the Thirumalai-Mountain (TM) fluctuation  metric in order to study the 
possible  existence  of  punctuated  ergodic  properties  of  several  natural  earthquake  fault 

systems [2, 4, 20, 21]. 

III. The Thirumalai-Mountain Metric 
 

The TM  metric  measures effective  ergodicity, or the difference between  the 
time  average  of  a  quantity,  generally  related  to  the  energy,  Ej,  at  each  site,  and  its 
ensemble  average  over  the  entire  system.    The  fundamental  idea  is  that  of  statistical 
symmetry,  in  which  the  N  oscillators,  particles,  cells,  or  spins  in  the  system  are 

statistically identical, in terms of their averaged properties – the statistics of one particle 
look the same as the statistics for the entire system [20, 21, 62].  While most systems are 
ergodic for infinite averaging times, if the actual measurement time scales are finite, but 
long,  a  large  sub-class  will  have  all  regions  of  phase  space  sampled  with  equal 

likelihood  and  the  system  is  effectively  ergodic  [20].    Exceptions  to  this  are  systems 
such as glasses, which are ergodic for infinite averaging times but for finite averaging 
times  are  not.    Practically,  for  effectively  ergodic  systems,  the  spatial  and  temporal 
averages  are  constant  over  a  large  enough  representative  sample  in  time  and  space.  

Ergodicity  is  a  behavior  that  is  generally  limited  to  equilibrium  states,  in  which 
transition probabilities are univarying or follow a definite cycle, and implies stationarity 
as  well.    Therefore,  if  such  a  system  is  ergodic,  it  is  also  in  some  form  of  stable  or 
metastable equilibrium and can be analyzed as such. 

The fluctuation metric 

)(teΩ

, proposed by Thirumalai and Mountain is  

 

 

 

Ω

e

t
)(

=

t
)(

−

(
t
ε

)]

2

,

ε
[
i

1
N

N
∑
1
i
=

tε
)(
i

tE
i

)'(

dt

'

t
1
∫=
t
0

where 

 
is the time average of a particular individual property, 

)(tEi

, and  

ε

)(
t

N
1
∑=
N
i

ε

)(
i t

   
)1(

 

)2(

)3(

7 

is the ensemble average of that temporal average over the entire system.  If the system is 

effectively  ergodic  at  long  times, 

te
Ω )(

=

,  where  D  is  a  diffusion  constant  that 

D
t

measures  the  rate  of  ergodic  convergence  [20,  21].    Physically,  the  deviation  of  the 
time-averaged  quantity  from  its  ensemble  average  in  equation  (1)  is  decreasing  as  a 
function of time, and all particles in the system are statistically similar.   

Note, also, from above, that the TM metric is actually a measure of the spatial 

variance of the temporal mean over a time interval t at each location, calculated at each 
successive time step.  As a result, if the dynamics are sampling all of the phase space 
equally, and there is a general equivalence of the temporal and ensemble averages, then 
the  central  limit  theorem  holds  such  that  the  variance,  which  becomes  a  constant 

controlled by the large sample size N, is divided by the increasing time, t [20]. 

In  slider  block  models  used  to  replicate  the  behavior  of  earthquake  fault 
networks,  as  the  interaction  range  increases,  the  system  approaches  mean-field  limit 
behavior.  If, as a result, these slider block  models are in  metastable equilibrium, they 

can be analyzed using the methods and principles of equilibrium statistical mechanics.  
Ferguson  et  al.  [2]  applied  the  TM  metric  to  the  energy  of  each  block  in  slider  block 
numerical simulations to show that the system was ergodic at external velocities, V, that 
approach V = 0.  The data showed the expected linear relationship between the inverse 

TM metric and time, such that  

1
te
Ω )(

=

,   

t
D

 

 

 

 

 

 

 

(4) 

denoting effective ergodicity as defined above [2]. 

For  a  similar  slider  block  model  [8],  the TM  metric  was  calculated  not  for  the 
energy but for numbers of events.  In this calculation of the TM metric, Ei(t) ≡ Ri(t), the 
number  of  events  greater  than  a  certain  magnitude.    Note  that  number  of  events  is  a 
proxy  for  energy  release,  as  detailed  below.  In  this  case,  there  was  an  initial  transient 

phase,  in  addition  to  the  linear  sections  expected  from  equation  4,  where  the  system 
exhibits ergodic behavior punctuated by the occurrence of larger events [4]. 

Not only have slider block models been shown to be in metastable equilibrium, 
and can be analyzed as such [1-3, 13], we demonstrated previously that the same applies 

to at least one natural earthquake fault network [4] and that the interactions in a natural 
driven  system  are  also  mean-field  in  the  ergodic  case.    Here  we  proceed  to  study 
different types of regional earthquake networks by applying the TM fluctuation metric 
to the associated fault system seismicity. 

 
IV.  Application 

8 

 
We  apply  the  TM  metric  to  the  surface  expression  of  the  energy  release  in  a  regional 
fault system.  For application to the earthquake fault system, the number of earthquakes 

of a particular magnitude or greater can be expressed as a function of the seismic energy 
release.  If N(t) is the seismicity rate, or number of events for a given time period, for 
earthquakes  of  magnitude  greater  than  m,  and  a  is  the  rate  for  all  events  over  a  given 
region, then 

 
where b ≈ 1.0, and a is a constant over the region of interest [53, 63, 64].  Also, 
if E(t) is the energy for a given magnitude m, in joules, c ≈ 1.44 and d ≈ 5.24 [63, 64], 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

tN
)(

=

a
10

−

bm

,

    

 
or 

log

tN

−=)(

a

bm

,  

tE
)(

=

10

cm

d

10

,

  

 

m

=

log

tE
)(
c

−

d

.

    

 

 

 

 

such that  

 
Substituting, 
  

 

and 

 
and 
  

log

tN
)(

a
−=

′−′=
b

a

log

tE
(

),

  

(9) 

b

(log

−

d

)

tE
)(
c

tN
)(

=

10

tE
)(

a

′

′−
b

,

  

 

 

 

 

(10) 

 
where a′ and b′ are again constants that depend on the region and time period of 

interest.    The  number  of  events  in  a  given  time  period,  N(t),  greater  than  a  given 
magnitude, m, is therefore a function of the seismic energy release. 

(5) 

 

(6) 

(7) 

(8) 

 

 

 

 

9 

Therefore,  for  this  application  of  the  TM  metric,  we  used  Ei(t)  ≡  Ni(t),  the 
number  of  events  greater  than  some  minimum  magnitude  m,  calculated  for  each  year.  
Specifically,  we  specify  for  each  region  or  subregion  under  analysis  in  each  tectonic 

zone (California, Spain, or Canada) a grid, or set of boxes, that we will use to separate 
our seismic events by location, designated by i.  The boxsize is varied as we attempt to 
investigate its effect on the resulting ergodic properties of the region (see below), but is 
most often set to a default value of 0.1° in the latitude and longitude directions. 

For each box we count the number of seismic events to occur during a specific 
time period which is, for all subsequent analyses discussed here, at one year.  This is our 
seismicity rate, Ni(t), or number of events for each year at each location i.  Again, for 
our purposes in  calculating  the TM metric  and  its inverse, Ni(t) is  a proxy for energy, 
and substituted for Ei(t) in equation (2), above. 

 

V. Seismicity Data 
 
For  this  analysis,  we  employed  catalogs  from  three  different  regions  of  the  world  – 
California,  Spain,  and  eastern  Canada.    These  three  particular  catalogs  were  chosen 
because they represent very different tectonic regions, but the seismicity in each of these 
regions is shallow, limiting the need to account for a depth effect, and they are each well 

characterized.    Here  we  include  additional  TM  analyses  of  the  seismicity  catalogs  for 
the Iberian peninsula and eastern Canada as well as a more comprehensive TM analysis 
of  the  California  data  than  that  included  in  our  initial  work  [4],  for  a  variety  of 
magnitude  cutoffs,  time  periods  and  spatial  scales,  and  an  investigation  into  the 

constitutive features that underlie these periods of effective ergodicity. 
 

A. California 

The California fault system consists of a large transform boundary between the 
Pacific  and  North  American  plates  that  spans  almost  1100  kms.    The  San  Andreas,  a 

right-lateral  strike-slip  fault  capable  of  producing  events  as  large  as  M~8,  is  the 
dominant structure; however, the 15-to-20 km deep elastic region is broken by a variety 
of  faults  of  different  sizes  and  mechanisms,  producing  a  variety  of  patterns  and 
behaviors  throughout  the  region  [60].    Figure  1  shows  a  schematic  of  the  California 

fault network, superimposed upon which are the largest events to have occurred in the 
region since 1932.  

The seismicity data employed in our analysis is taken from existing observations 
in California between the years 1932 and 2004, and is an amalgamation of data from the 

10 

Southern  California  Earthquake  Center  (SCEC)  (www.scec.org)  and  the  Northern 
California  Seismic  Network  (NCSN)  (quake.geo.berkeley.edu).    Note  that,  while  the 
catalog  contains  more  than  939,000  events  of  magnitudes  greater  than  1,  we  use  only 
events having magnitude M ≥ 3, to ensure completeness of the catalog.  Also, while the 
network  coverage  has  changed  significantly  since  its  inception  in  the  early  1930s,  the 
catalog  is  not  declustered  in  any  way.  Using  various  subsets  of  this  data  covering  the 
period from January 1, 1932 through December 31, 2004, we compute the TM  metric 

for California seismicity, over the region 32º to 40º latitude, -115º to –125º longitude. 

 
B. Eastern Canada 

Eastern  Canada  is  an  intraplate,  shield  region  in  which  most  of  the  earthquake 
activity  is  associated  with  large  lithospheric-scale  tectonic  and  geological  structures 

arising  from  past  orogenic  and  rifting  episodes,  and  that  appear  to  control  the  spatial 
distribution of seismicity [65].  Figure 2 shows the largest events to occur in the region 
since  1900.    Activity  varies  from  low  background  seismicity  to  medium  (magnitude 
ranging  from  4  to  6)  and  large  (magnitude  M~7)  earthquakes,  and  the  bulk  of  the 

seismicity occurs within the top 25 km of the crust.  Here we compute the TM metric 
for the region 42º to 52º latitude, -60º to -85º longitude. 
 

C. Spain 

The Iberian Peninsula is complicated and diffuse, controlled to the south by the 
convergence between the Eurasian and African plates, but it is also affected by a general 

uplift causing radial extension [66].  As a result, the regional seismicity of the Iberian 
Peninsula  is  complicated,  characterized  by  a  diffuse  geographical  distribution  that 
ranges from low to moderate magnitudes, with a maximum depth of 146 km, although 
the bulk of the seismicity is shallower.  Figure 3 shows the largest events to occur in the 

region  since  1970.    Earthquakes  rarely  exceed  magnitude  5.0  either  on  the  Iberian 
Peninsula  itself  or  in  northern  Morocco,  the  westernmost  Mediterranean  Sea  and  the 
Atlantic Ocean south of Portugal [66]. 

The  data  used  has  been  recorded  by  the  Geographic  National  Institute,  which 

runs  the  National  Seismic  Network  with  42  stations,  35  of  them  of  short  period, 
connected  in  real  time  with  the  Reception  Center  of  Seismic  Data  in  Madrid.  The 
catalog,  with  more  than  10000  earthquakes  in  the  region  between  35º  north  and  45º 
latitude  and  between  -5º  to  15º  longitude,  contains  all  the  seismic  data  in  the  Iberian 

Peninsula and northwestern Africa collected in the period 1970 - 2001. 
 

11 

VI. Results 
 
 
A. California 

 
In Figure 4 we plot the inverse TM metric for the number of events in southern 
California,  from  1932  through  2001.    The  linear  relationship  between  the  inverse  TM 
metric and time can be observed again, as seen in the numerical simulations and in our 

previous work with California seismicity [1, 2, 4].  Note that Figure 4 is a correction to 
Figure 3 of [4], where the boxsize was incorrect for events of magnitude three.  Here, 
the  system  is  determined  to  be  ergodic  when  the  inverse  TM  metric  is  linear,  with  a 
positive slope.  Note that, for a boxsize of 0.1, the California earthquake fault system is 

ergodic for only a small period of time between approximately 1955 and 1968, M ≥ 2 
(Figure 4a).  It is ergodic for M ≥ 3 from 1932 to approximately 1970, but not for the 
subsequent time period (Figure 4b).   The fault system is ergodic over long stretches for 
the time period shown in Figure 4c, M ≥ 4.  

Several interesting conclusions can be drawn from Figure 4.  While in our earlier 
work  [4]  we  studied  only  events  of  M  ≥  3,  here  we  show  analyses  for  three  different 
cutoff  magnitudes.    The  results  for  M  ≥  2  are  not  intuitive  (Figure  4a).    Ergodicity 
implies  a  condition  in  which  all  regions  of  phase  space  are  sampled  with  equal 

likelihood.  While it might be hypothesized that by adding more small events the system 
would become more ergodic, sampling the phase space more evenly, this is not the case, 
confirming that ergodicity is not related directly to the number of events, or an outcome 
of  random  sampling  of  many  events.  Note  that  there  are  approximately  six  times  as 

many events of M ≥ 2 as M ≥ 3.  One hypothesis for this unexpected result is that, by 
adding  many  small  events  that  occur  over  the  entire  network,  the  system  is  sampling 
one  portion  of  the  phase  space,  the  background  seismicity,  more  preferentially.    In 
addition,  the  catalog  is  not  complete  for  M  ≥  2  over  the  entire  time  period,  and  the 

increasing  ability  to  sample  more  events  over  time  with  better  instrumentation  and 
coverage affects the phase space coverage.  We will investigate these details below. 

Figure 4b shows the inverse TM metric for M ≥ 3.  Here we see that the system 
is ergodic for long periods prior to the early 1970s, and is then ergodic for short periods 

throughout  the  1970s,  but  is  no  longer  ergodic  after  1979.    We  hypothesize  that  the 
early  ergodic  behavior  is  related  to  the  stability  of  the  networks  and  catalog  prior  to 
1970,  when  digitization  of  the  seismic  networks  began  and  many  more  events  were 
recorded in new spatial regions. 

For  events  of  M  ≥  4,  the  California  fault  system  is  effectively  ergodic  for 
relatively long periods of time, on the order of decades, from 1932 through 2004.  These 

12 

equilibrium  periods  are  punctuated  by  the  occurrence  of  large  earthquakes,  shown  in 
Table  1  and  highlighted  with  arrows  on  Figure  4c.    These  include  the  Kern  County 
event of 1952, the Imperial Valley earthquake in 1979, the Landers sequence of 1992, 

and the Hector Mine earthquake in 1999.  Between these events the fault system resides 
for long periods in an ergodic, local energy minimum on a complex energy landscape.  
Eventually, the  nonlinear dynamics  lead  to  a  large  earthquake,  and  the  system  departs 
from  its  current  local  energy  minimum,  to  migrate  to  a  new  local  minimum,  where  it 

again resides in an effectively ergodic state.   

In  Figure  5  we  plot  the  number  of  events  per  year  for  different  magnitude 
cutoffs.    For  M  ≥  2  (Figure  5a),  the  rate  remains  relatively  constant  through  the  late 
1960s, and increases sharply at the same time that the system becomes non-ergodic, as 

shown  in  Figure  4.    Note  that  this  again  coincides  with  digitization  of  the  seismic 
network  in  the  early  1970s.    While  this  increased  the  ability  to  detect  smaller  events, 
including the spatially and temporally clustered aftershocks of larger events, and helps 
to explain the decrease in the inverse metric after 1968, it does not account for the lack 

of ergodicity prior to that time. It does imply that, while a requirement, a constant rate 
of events is not a sufficient condition for ergodicity, and supports our hypothesis that a 
system of events that includes those of M ≥ 2 does not sample the phase space equally. 

Figure  5b  shows  the  number  of  events  for  M  ≥  3.    Here  the  rate  of  events  is 

approximately constant prior to the early 1970s.  Fluctuations in the yearly rate increase 
at  the  same  time  as  the  onset  of  the  decrease  in  the  inverse  metric  (Figure  4b), 
coinciding  with  network  increases  subsequent  to  the  1971  San  Fernando  earthquake.  
While the mean becomes approximately constant over short periods of time, the yearly 

rate maintains a relatively high variance, and ergodicity is not achieved for a significant 
length  of  time.    Ergodicity  disappears  entirely  in  the  late  1970s,  reflecting  significant 
variation in the rate of events of M ≥ 3, as well as digitization of the seismic data [60]. 

For M ≥ 4, Figure 5c reflects a relatively constant mean value of the seismicity 

rate  over  the  entire  time  period.    Here  the  number  of  events  of  M  ≥  4  was  not 
significantly affected by the digitization of the network in the early 1970s.  Increases are 
seen  for  short  periods  during  and  after  the  1952  Kern  County  and  1992  Landers 
earthquakes,  but  are  not  distinct  at  the  time  of  the  1979  Imperial  Valley  event.    This 

again leads to the conclusion that while a constant mean rate of seismicity is important 
for  the  ergodic  condition,  changes  in  the  variance  that  result  in  non-ergodic  behavior 
can be spatial as well as temporal. 

In  Figure  6  we  calculate  the  spatial  variation  of  California  seismicity  for  the 

same three magnitude ranges over the period 1932 to 2004.  Here circle size increases 
with increasing magnitude.  The first feature that one notices is the similarity between 

13 

the three images.  While there are considerably more events for M ≥ 2 (Figure 6a), the 
bulk of the seismicity occurs in the same regions as for M ≥ 3 (Figure 6b), reinforcing 
the  hypothesis  that  the  change  in  ergodic  behavior  is  a  result  of  the  system  spending 

more  time  in  a  particular  portion  of  the  phase  space  due  to  the  addition  of  small 
magnitude  background  seismicity.    Figure  6c  details  the  spatial  distribution  of 
seismicity,  M  ≥  4,  for  1932  to  2004.    While  the  clustering  is  more  localized  in  this 
figure, the locations of maximum activity remain the same as those shown in Figures 6a 

and 6b. 

Figure  7  shows  the  seismicity  distribution,  M  ≥  3,  for  the  time  period  1970  to 
2004.  The spatial variation for this figure is more like that of Figure 6c than Figure 6b.  
The similarity to the spatial variation for the M ≥ 4 ergodic events shown of Figure 6c 

prompted the analysis of the seismicity for M ≥ 3 since 1970. 

Figure  8  shows  the  inverse  TM  metric  for  a  boxsize  of  0.1  degrees,  1970  to 
2004,  M  ≥  3.    The  seismicity  for  this  time  period  and  discretization  is  effectively 
ergodic for the time periods between large events.  In this case, after an initial transient 

period,  the  system  becomes  ergodic  after  the  1983  Coalinga  earthquake,  the  1992 
Landers  sequence,  and  the  1999  Hector  Mine  event.    Again,  the  pattern  of  seismicity 
seen for M ≥ 3 during this time period is remarkably similar to that seen for M ≥ 4 over 
the  entire  history,  yet  the  total  number  of  events  is  much  larger.    For  the  time  period 

1932 to 2004, the catalog contains 29,307 events of M ≥ 3.   On the other hand, for M ≥ 
4, the total number of events in the catalog, or population size, is 4211, far less than the 
8181 boxes in the region at a boxsize of 0.1 degrees.  Finally, for the time period 1970 
to 2004, the total number of events in the catalog, M ≥ 3, is 19133. 

Figure 9 shows the results of two additional TM calculations for M ≥ 3. Figure 
9a shows the same  time period  as Figure 4b, 1932 through  2004, but for a boxsize  of 
0.02  degrees  (approximately  2.2  km  square).   Figure 9b is the  inverse  TM  calculation 
again for the period 1932 to 2004, but now for a boxsize that approximates the rupture 

dimension  of  an  earthquake  of  magnitude  three,  0.0011  degrees  or  0.12  km  [67].    In 
addition,  for  Figure  9b,  the  TM  calculation  is  performed  such  that  those  boxes  which 
contain no events are not included in the calculation, where N is replaced by the number 
of boxes that are not empty in equations 1 and 3, above.   

For a boxsize of 0.02, M ≥ 3, the system is effectively ergodic for the entire time 
period,  except  for  a  short  non-linear  section  between  approximately  1955  and  1965 
(Figure  9a).    This  supports  the  proposition  that  a  relationship  exists  between  the 
boxsize,  or  the  sampling  rate  of  the  total  number  of  events,  and  the  ergodic  behavior.  

One  possible  interpretation  is  that  when  the  system  is  not  ergodic  the  central  limit 
theorem (CLT) no longer holds, and the spatial variance of the temporal mean no longer 

14 

goes as 1/t, as required for linearity in the TM metric (Equation 2).  As the number of 
boxes, N, increases with smaller boxsize, the law of large numbers reasserts itself, and 
the system again reaches effective ergodicity.  Physically, the smaller size of the boxes 

allows the seismicity to sample a larger number of individual realizations of the phase 
space with equal likelihood. 

However, Figure 9b displays ergodic behavior for the time period after 1980, for 
events greater than magnitude 3.  The inset shows the results for 1980 to 2004, with the 

linear  trend  removed,  highlighting  the  departures  from  ergodicity  as  a  result  of 
earthquakes  such  as  the  1992  Landers  sequence.    Again,  as  stated  above,  here  the 
boxsize  is  equivalent  to  the  approximate  rupture  dimension  for  an  earthquake  of 
magnitude  three  [67],  the  lower  magnitude  cutoff  for  this  analysis,  and  no  boxes  that 

without events are included in the calculation.  This result is supported by the work of 
Xia and colleagues [personal communication, 68], who found that the inclusion of large 
numbers  of  locations  with  zero  events  in  calculating  the  TM  metric  for  large-scale 
numerical  earthquake  simulations  distorted  the  results.    They  began  with  a  simulation 

based  upon  the  Olami-Feder-Christensen  model  [69],  and  fixed  a  certain  number  of 
boxes such that there were no events allowed in those locations.  The resulting inverse 
metric calculation was not linear, implying that the system was not ergodic.  Removing 
those  boxes  with  no  events  from  the  calculations  caused  the  inverse  TM  metric  to 

become linear again, correctly validating its ergodic behavior.  This illustrates the fact 
that  it  is  the  fault  systems  that  have  the  ergodicity  property,  and  not  geographical 
regions. 

In Figures 10 and 11 we investigate the behavior of those quantities that are used 

to calculate the TM  metric as originally described, where every box is included in the 
calculation, even if it contains no events during the time period of interest, to match the 
conditions in our earlier figures. Figure 10 details the mean and variance in number of 
earthquakes,  at  a  boxsize  of  0.1  degrees,  for  cumulative  magnitude,  M  ≤  m.    These 

values approach a constant over both time and space for cumulative magnitudes greater 
than 3.0.  This reinforces the conclusion that the system is stationary over large enough 
spatial  areas  and  time  periods,  as  is  implied  by  the  ergodicity  constraint.  However,  it 
also  illustrates  that  stationarity  is  not  a  sufficient  condition  for  ergodicity,  as  for  a 

number of these spatial and temporal regions, at certain magnitude cutoffs and boxsizes, 
the system does not display ergodicity for significant periods of time (Figure 4). 

In Figure 11 is shown the spatial variance for California seismicity over time, for 
events of magnitude greater than or equal to that shown for different magnitude cutoffs 

and boxsizes.  Figure 11a illustrates that, for M ≥ 3.0 and a boxsize of 0.1 degree, the 

15 

slope of the spatial variance changes significantly in the late 1970s, with the digitization 
of seismic records, and corresponding to the breakdown of ergodicity seen in Figure 4b.   
The rate of change of the variance is nearly 10 times higher in the last 15 years 

than in the first 40, but is nearly constant for the period after 1980, corresponding to the 
ergodic behavior seen in Figures 8 and 9.  In Figure 11b, for a boxsize of 0.02 degree 
and M ≥ 3.0, and the rate of change of the variance over time is significantly less than 1, 
although the slope shows some variation after the 1952 Kern County earthquake.  This 

change  in  slope  corresponds  to  the  divergence  in  ergodicity  seen  during  the  10  year 
period from the mid-1950s to the mid-1960s in Figure 8a.  Finally, for M ≥ 4.0 and a 
boxsize  of  0.1  degree,  the  slope  is  effectively  constant,  with  a  change  per  year  that  is 
still  significantly  less  than  one.    The  short-term  divergence  from  ergodicity  seen 

subsequent  to  large  events  in  the  earthquake  catalog  corresponds  to  sudden  increases 
seismicity due to aftershocks and a resulting increase in the variance after the 1952 Kern 
County,  the  1979  Imperial  Valley,  the  1992  Landers,  and  the  1999  Hector  Mine 
earthquakes, as in Figure 4c. 

 

B. Spain 
 
The  inverse  TM  metric  for  the  Iberian  Peninsula  is  plotted  in  Figure  12,  for  a 

boxsize of 0.1 degrees, M ≥ 3.0 (Figure 12a) and M ≥ 4.0 (Figure 12b), 1970 to 2001.  
Here we see, again, that while the system is not ergodic for M ≥ 3.0 at this boxsize, it 
does achieve ergodicity for M ≥ 4.0, even for this relatively short time period.   

In Figure 13 we show the spatial distribution of events from the Iberian catalog, 

where increasing circle size again denotes increasing magnitude, from M ≥ 3.0 (Figure 
13a)  to  M  ≥  4.0  (Figure  13b).    As  in  the  case  of  California,  the  clustering  in  the 
seismicity  is  similar  for  both  magnitude  cutoffs,  suggesting  the  variability  in  the 
temporal statistics is the controlling factor in the ergodic behavior of seismic catalogs. 

Figure  14  plots the  total  number  of  events  per  year  for  the  Iberian  catalog,  for 
both M ≥ 3.0 (Figure 14a) and M ≥ 4.0 (Figure 14b).  Again the number of events per 
year does not remain constant for M ≥ 3.0, in the case for the entire time period, 1970 to 
2001.  On the other hand, the seismicity rate for M ≥ 4.0 remains effectively constant 

for the entire period, except for a minor variation in the early 1980s, at the same time as 
the system diverges from ergodicity in Figure 12b. 

 
C. Eastern Canada 

 

16 

In  Figure  15  we  plot  the  inverse  TM  metric  for  the  eastern  Canadian  catalog.  
This  catalog  covers  the  longest  time  period  of  all  three  catalogs,  1900  to  2001.    The 
inverse TM metric is shown for a magnitude cutoff of M ≥ 3.0 (Figure 15a) and M ≥ 4.0 

(Figure 15b).   

Figure  15a,  M  ≥  3.0,  displays  ergodic  behavior  for  the  first  80  years,  after  an 
initial transient period, followed by a deviation from ergodic behavior beginning around 
1980.  Increased data collection and network coverage in eastern Canada in recent years 

and the associated change in earthquake statistics is the most likely explanation for this 
deviation  from  ergodicity  [70].    One  other  possible  explanation  for  the  flattening  that 
occurs  after  1980  is  the  inclusion  of  boxes  with  zero  events  in  this  calculation,  at  a 
boxsize  significantly  greater  than  the  rupture  dimension  of  the  minimum  fault  size,  as 

illustrated  for  California  (Figures  4  and  9),  although  additional  testing  is  necessary  to 
verify  this.  Figure  15b,  M  ≥  4.0,  again  displays  ergodic  behavior  for  the  entire  time 
period,  suggesting  that  the  temporal  variation  in  phase  space  configuration  for  that 
magnitude range is stable.  

Figure 16 details the spatial distribution of earthquakes in eastern Canada for the 
same  time  period  and  magnitude  cutoffs,  where  increasing  circle  size  again  denotes 
increasing  magnitude.    The  spatial  clustering  for  M  ≥  3.0  (Figure  16a)  and  M  ≥  4.0 
(Figure 16b) is very similar, as in the case of the Spanish and California catalog, despite 

the lower number of events. 

Figure 17 is a plot of the number of events per year for eastern Canada, M ≥ 3.0 
(Figure 17a) and M ≥ 4.0 (Figure 17b).  While the number of events per year for M ≥ 
3.0 increases over the catalog life, the period for 1920 through 1980 displays a constant 

mean,  corresponding  to  the  ergodic  behavior  in  Figure  15a,  while  the  rate  is 
continuously increasing subsequently.  Figure 17b shows that the seismicity rate for M 
≥ 4.0 has a relatively constant statistics for the entire period.  In addition, it suggests that 
ergodic  behavior  is  not  dependent  on  large  numbers  of  events,  as  the  rate  of  M ≥  4.0 

earthquakes per year over the entire regions is always less than eight. 

 

VII. Conclusions 
 

In conclusion, we employ here the Thirumalai-Mountain fluctuation metric and 
data from  existing seismic  monitoring networks to identify the presence of  ergodicity, 
an equilibrium property in the dynamics of the natural earthquake fault system in three 
varied  tectonic  regions;  California,  Spain,  and  eastern  Canada.  While  the  results  are 

clearly  impacted  by  the  quality  of  the  catalogs,  in  particular  their  magnitude  of 
completeness and the spatial variation of subnetworks, natural earthquake fault systems 

17 

are effectively ergodic and mean-field, as in the numerical simulations that are used to 
study these systems, displaying critical point behavior with correlations over a range of 
spatial and temporal scales.  All three of these fault systems display punctuated ergodic 

behavior for some combination of  magnitude and boxsize, despite that fact that one is 
located  in  a  region  of  high  seismicity  and  strong  directional  tectonic  forcing 
(California), the second is a region of moderate seismicity and varied stress directions 
(Spain),  and  the  third  lies  in  an  area  of  low  seismicity  and  low  intraplate  stresses 

(eastern  Canada).    It  should  be  noted  that  recent  work  in  the  study  of  aftershock 
sequences  also  has  shown  that  the  lower  magnitude  cutoff  and  spatial  discretization 
significantly affects the statistical behavior of seismicity [71]. 

This work  supports  the  general  conclusion  that  natural  fault  systems  display  at 

least  some  of  the  dynamics  of  driven  mean-field  systems,  as  seen  in  numerical 
simulations of interacting slider blocks and coupled map lattices.  These systems reside 
in metastable wells for significant periods of time for particular magnitude regions and 
spatial  discretization  (boxsize),  on  the  order  of  several  decades  for  all  three  fault 

systems.  As the dynamical systems evolve, they migrate to a new free energy minimum 
with the occurrence of a large earthquake.  

In  a  detailed  study  of  the  magnitudes  and  boxsizes  applicable  to  ergodic 
behavior in each of these systems, we have determined that a lower magnitude cutoff of 

4.0  appears  to  display  ergodicity  for  all  spatial  and  temporal  regions.    Lower  cutoff 
ranges  require  smaller  discretization  in  order  to  ensure  central  limit  theorem  behavior 
and  a  1/t  increase  in  the  inverse  TM  metric.  We  have  also  shown,  by  removing  those 
locations  from  the  calculation  that  do  not  contain  any  events  over  the  time  period 

(Figure 9) that it is the fault systems themselves that have the ergodicity property, and 
not  geographical  regions.    Finally,  earlier  and  shorter  temporal  regions  appear  to  be 
affected by the quality and completeness of the catalogs. 

We have performed a variety of statistical tests on the catalogs in an attempt to 

better understand the underlying ergodic behavior and its genesis.  While it appears that 
a  relatively  constant  rate  of  events  is  an  important  prerequisite,  and  that  the  level  of 
spatial  variability  in  the  temporal  statistics  is  the  controlling  factor  in  the  ergodic 
behavior  of  seismic  catalogs,  no  one  statistic  is  sufficient  to  ensure  quantification  of 

ergodicity.  We also show that stationarity, while a necessary condition, is not sufficient 
to  ensure  ergodicity  in  seismic  networks.    The  TM  metric,  a  measure  of  the  spatial 
variance of the temporal mean, alone provides the ability to quantify ergodic behavior. 

Finally,  this  work  suggests  that  many  of  the  observed  properties  of  the  natural 

system, such as scaling, large correlation lengths, and the classification of earthquakes 
as nonclassical nucleation events, can be understood as manifestations of an effectively 

18 

ergodic, nonlinear threshold system.  The success of the TM metric for this application, 
a measure initially based upon the model of a Brownian particle in a diffusive system, 
argues  for  the  interpretation  of  the  natural  earthquake  system  as  a  diffusive  one,  and 

may provide a means to better quantify the diffusive nature of the fault system and its 
dynamics  in  the  future.    Finally,  this  supports  the  previous  work  that  used  numerical 
simulations  to  model  driven  threshold  systems,  and  validates  their  use  in  the  study  of 
their natural counterparts in general, and earthquake fault systems in particular. 

 
Acknowledgements:  Research by KFT was funded by an NSERC Discovery Grant.  This research also 
was  supported  by  the  Southern  California  Earthquake  Center.    SCEC  is  funded  by  NSF  Cooperative 
Agreement  EAR-8920136  and  USGS  Cooperative  Agreements  14-08-0001-A0899  and  1434-HQ-
97AG01718.    The  SCEC  contribution  number  for  this  paper  is  813.    Research  by  JBR  was  funded  by 
USDOE/OBES  grant  DE-FG03-95ER14499  (theory),  and  by  NASA  grant  NAG5-5168  (simulations).  
Research by WK was supported by USDOE/OBES grant DE-FG02-95ER14498 and W-7405-ENG-6 at 
LANL.    WK  would  also  like  to  acknowledge  the  hospitality  and  support  of  CNLS  at  LANL.  CDF 
completed his part of this research while a graduate student at the Dept. of Physics, Boston University and 
received funding through WK’s grants.  
 
Special  thanks  goes  to  Dr.  John  Adams  of  the  GSC,  Canada  and  Dr.  Antonio  Posadas  and  Dr.  Abigail 
Jiménez  of  the  Department  of  Applied  Physics,  University  of  Almerίa,  Spain  for  supplying  the  eastern 
Canadian and Spanish catalogs, respectively. 

Correspondence and requests for materials should be addressed to K.T. (e-mail: ktiampo@uwo.ca). 

 
REFERENCES 

 
[1]  W.  Klein,  C.  Ferguson,  and  J.B.  Rundle,  in  Reduction  and  Predictability  of 
Natural Disasters, ed. by J.B. Rundle, D.L. Turcotte, and W. Klein, SFI series in 
the science of complexity, XXV (Addison-Wesley, Reading, MA, 1996) p. 223. 

[2]  C.D. Ferguson, W. Klein, and J.B. Rundle, Phys. Rev. E 60, 1359 (1999). 
[3]  D. Egolf, D. Science 287, 101 (2000). 
[4]  K.F. Tiampo, J.B. Rundle, W. Klein, J.S. Sá Martins, and C. D. Ferguson, Phys. 

Rev. Lett. 91, 238501 (2003). 

[5] 

J.B.  Rundle,  W.  Klein,  S.  Gross,  and  D.L.  Turcotte,  Phys.  Rev.  Lett.  75,  1658 
(1995). 

[6]  D. Fisher, K. Dahmen, S. Ramanathan, and Y. Ben-Zion, Y., Phys. Rev. Lett. 78, 

4885 (1997). 

[7] 

J.  Hertz,  A.  Krogh,  and  R.G.  Palmer,  Introduction  to  the  Theory  of  Neural 
Computation,  Lecture  Notes  I,  Santa  Fe  Inst.  (Addison  Wesley,  Reading,  MA, 
1991). 

[8]  A.V.M. Herz and J.J. Hopfield, Phys. Rev. Lett. 75, 1222 (1995). 
[9]  D.S. Fisher, Phys. Rev. B 31, 7233 (1985). 

19 

[10]  J.S. Urbach, R.C. Madison, and J.T. Markert, Phys. Rev. Lett. 75, 276 (1995). 
[11]  P. Bak, C. Tang, and K. Weisenfield, Phys. Rev. Lett.  59, 381 (1987). 
[12]  A.D. Gopal, and D.J. Durian, Phys. Rev. Lett. 75, 2610 (1995). 
[13]  M. Kac, G.E. Uhlenbeck, and P.C. Hemmer, J. Math. Phys. 4, 216 (1961). 
[14]  P. Gaspard, M.E. Briggs, M.K. Francis, et al., Nature 394, 865 (1998). 
[15]  J.B.  Rundle,  W.  Klein,  K.F.  Tiampo,  and  J.S.  Sá  Martins,  Proc.  Nat.  Acad.  Sci. 

U.S.A., Suppl. 1 99, 2463 (2002). 

[16]  J.J. Hopfield, Proc. Nat. Acad. Sci. U.S.A. 79, 2554 (1982). 
[17]  W.  Klein,  M.  Anghel,  C.D.  Ferguson,  J.B.  Rundle,  and  J.S.  Sá  Martins  in 
Geocomplexity and the Physics of Earthquakes, ed. by J.B. Rundle, D.L. Turcotte, 
and W. Klein, Geophysical Monograph Vol. 120 (AGU, Washington D.C., 2000) 

[18]  G. Morein, D.L. Turcotte, and A. Gabrielov, Geophys. J. Int. 131, 552 (1997). 
[19]  I.G. Main, G. O’Brien, and J.R. Henderson, J. Geophys. Res. 105, 6105 (2000). 
[20]  D.  Thirumalai,  R.D.  Mountain,  and  T.R.  Kirkpatrick,  Phys.  Rev.  A  39,  3563 

p. 43. 

(1989). 

[21]  D. Thirumalai, and R.D. Mountain, Phys. Rev. E 47, 479 (1993). 
[22]  J. Xia, H. Gould, W. Klein, J.B. Rundle, Phys. Rev. Lett., 95, 248501 (2005). 
[23]  J.B.  Rundle,  W.  Klein,  K.  Tiampo,  and  S.  Gross,  Linear  pattern  dynamics  in 

nonlinear threshold systems, Phys. Rev. E, 61, 2418, (2000). 
[24]  N. Gulbahce, H. Gould, W. Klein, Phys. Rev. E, 69, 036119 (2004). 
[25]  J.L.  Leibowitz,  in  Statistical  Mechanics:  Fluctuation  Phenomena,  ed.  by  O. 

Penrose (North-Holl, Amsterdam, 1979) p. 295. 

[26]  J.D. Gunton and M. Droz,. Introduction to the Theory of Metastable and Unstable 

States, Lecture Notes in Physics 183 (Springer-Verlag, Berlin, 1983). 

[27]  R.A. Harris and R.W. Simpson, R.W., Nature 360, 251 (1992). 
[28]  R.S. Stein, G.C.P. King, and J. Lin, Science 258, 1328 (1992).  
[29]  G.C.P. King, R.S. Stein, and J. Lin, Bull. Seis. Soc. Am. 84, 935 (1994).  
[30]  J. Gomberg, J. Geophys. Res. 101, 751 (1996). 
[31]  R.S. Stein, Nature 402, 605 (1999). 
[32]  R.F. Smalley, D.L. Turcotte, and S.A. Solla, J. Geophys. Res. 90, 1894 (1985). 
[33]  P. Bak and C. Tang, J. Geophys. Res. 94, 15635 (1989).  
[34]  J.B. Rundle, J. Geophys. Res. 94, 12337 (1989). 
[35]  A. Sornette and D. Sornette,  Europhys. Lett. 9, 1197 (1989). 
[36]  J.F. Pacheco, C.H. Scholz, and L.R. Sykes, Nature 355, 71 (1992).  
[37]  Y. Ben-Zion and J.R. Rice, J. Geophys. Res. 98, 14109 (1993).  
[38]  B. Romanowicz and J.B. Rundle, Bull. Seis. Soc. Am. 83, 1294 (1993).  

20 

[39]  J.B. Rundle, J. Geophys. Res. 98, 21943 (1993). 
[40]  H. Saleur, C.G. Sammis, and D. Sornette, J. Geophys. Res. 101, 17661 (1996). 
[41]  C.G. Sammis, D. Sornette, H. Saleur, in Reduction and Predictability of Natural 
Disasters,  ed.  by  J.B.  Rundle,  D.L.  Turcotte,  and  W.  Klein,  SFI  series  in  the 
science of complexity, XXV (Addison-Wesley, Reading, MA, 1996) p. 143.  
[42]  D.  Sornette,  L.  Knopoff,  Y.Y.  Kagan,  and  C.  Vanneste,  J.  Geophys.  Res.  101, 

[43]  M. Eneva and Y. Ben-Zion, J. Geophys. Res. 102, 17785 (1997). 
[44]  J.B. Rundle, S. Gross, W. Klein, C. Ferguson, and D.L. Turcotte, Tectonophysics 

[45]  Y.  Huang,  H.  Saleur,  C.  Sammis,  and  D.  Sornette,  D.  Europhys.  Lett.  41,  43 

13883 (1996). 

277, 147 (1997). 

(1998).  

[46]  S.C. Jaume and L.R. Sykes, Pure Appl. Geoph. 155, 279 (1999). 
[47]  J.B. Rundle, W. Klein, and S. Gross, Pure Appl. Geoph. 155, 575 (1999). 
[48]  W. Klein, J.B. Rundle, and C.D. Ferguson, Phys. Rev. Lett. 78, 3793 (1997). 
[49]  J.M.  Yeomans,  Statistical  Mechanics  of  Phase  Transitions  (Clarendon  Press, 

Oxford, U.K., 1992). 

[50]  H.F. Nijhout, in  Pattern Formation  in the Physical and Biological Sciences, SFI 

Lecture Notes V (Addison Wesley, Reading, MA, 1997) p. 269. 

[51]  C.M.  Gray,  Pattern  Formation  in  the  Physical  and  Biological  Sciences,  SFI 

Lecture Notes V (Addison Wesley, Reading, MA, 1997) p. 93. 

[52]  C.J.  Shatz,  Pattern  Formation  in  the  Physical  and  Biological  Sciences,  SFI 

Lecture Notes V (Addison Wesley, Reading, MA, 1997) p. 299. 
[53]  C.F. Richter, Elementary Seismology (Freeman, San Francisco, 1958). 
[54]  H.  Kanamori,  in  Earthquake  Prediction:  An  International  Review,  ed.  by  D.W. 

Simpson, II, and P.G. Richards (AGU, Washington, D.C., 1981), p. 1. 

[55]  D.L. Turcotte, Ann. Rev. Earth Planet. Sci. 19, 263 (1991). 
[56]  R.J.  Geller,  D.D.  Jackson,  Y.Y.  Kagan,  and  F.  Mulargia,  F.  Science  275,  1616 

(1997). 

[57]  M. Wyss et al., Science 278, 487 (1997). 
[58]  L.R. Sykes, B.E. Shaw, and C.H. Scholz, Pure Appl. Geophys. 155, 207 (1999). 
[59]  W.H. Bakun and T.V. McEvilly, J. Geophys. Res. 89, 3051 (1984). 
[60]  K. Sieh, M. Stuiver, and D. Brillinger, J. Geophys. Res. 94, 603 (1989). 
[61]  D. Hill, J.P. Eaton, L.M. Jones, USGS Prof. Paper 1515, (U.S. GPO, Washington, 

D.C., 1990) p. 115. 

[62]  R.G. Palmer, Adv. Phys. 31, 669 (1982). 
[63]  H. Kanamori, J. Geophys. Res. 82, 2981 (1977). 

21 

[64]  D.L.  Turcotte,  Fractals  and  Chaos  in  Geology  and  Geophysics,  2nd  ed. 

(Cambridge University Press, Cambridge, U.K., 1997). 

[65]  J.E.  Adams, and P.W. Basham, Geoscience Canada, 16, n. 1, 3 (1989). 
[66]  M.  Herraiz,  G.  De  Vicente,  R.  Lindo-Naupari,  J.  Giner,  J.  L.  Simon,  J.  M. 
Gonzalez-Casado, O. Vadillo, M. A. Rodriguez-Pascua, J. I. Cicuendez, A. Casas, 
L. Cabanas, P. Rincon, A. L. Cortes, M. Ramirez, , and M. Lucini, Tectonics, 19, 
762–786, 2000. 

[67]  D.L. Wells and K.J. Coppersmith, BSSA. 84, 974-991, 1994. 
[68]  J. Xia, H. Gould, W. Klein, J.B Rundle, in preparation, 2006. 
[69]  Z. Olami, H.J.S. Feder, K. Christensen, Phys. Rev. Lett. 68, 1244–1247. 
[70]  P.W.  Basham,  D.H.  Weichert,  F.M.  Anglin,  M.J.  Berry,  BSSA,  75,  563-595, 

[71]  R. Shcherbakov, D.L. Turcotte, J.B. Rundle, PAGEOPH, 162, 1051-1076, 2005.  

1985. 

 

22 

Figure 1:  Large events in southern California, 1932-2004. 

23 

Figure 2:  Large events in eastern Canada, 1900-2001. 

24 

Figure 3:  Large events in Spain, 1970-2001. 

25 

to 

Figure  4:    Plots  of  the  inverse  TM  metric, 
normalized 
for 
California, for a boxsize of 0.1 degree and 
a) all M ≥ 2.0, b) all M ≥ 3.0, and c) all M 
≥ 4.0. 

initial  value, 

the 

26 

27 

Figure 5:  Count of the number of events 
per year in California for a) all M ≥ 2.0, 
b) all M ≥ 3.0, and c) all M ≥ 4.0. 

28 

Figure 6:  Plots of California seismicity, 1932-2004, for a) all M ≥ 2.0, b) all 
M ≥ 3.0, and c) all M ≥ 4.0. 

29 

Figure 7:  California seismicity, M ≥ 3.0, 
1970-2004. 

30 

Figure  8:    Inverse  TM  metric  for  California 
seismicity,  M  ≥  3.0,  for  the  period  1970-2004, 
boxsize equal to 0.1 degree. 

31 

a 

b 

Figure  9:    Inverse  TM  metric  for  boxsizes  of  a) 
0.02º (2.2 km), for all boxes and b) 0.0011º (0.12 
km),  only  for  those  boxes  that  contain  at  least 
one  event.    Inset  shows  the  inverse  metric  for 
1980 to 2004, with the linear trend removed. 

32 

Figure  10:    Statistical  quantities  for  California  seismicity  for  cumulative 
magnitude  (all  events  less  than  or  equal  to  that  shown).  a)  Spatial  mean,  b) 
temporal mean, c) spatial variance, and d) temporal variance. 

33 

Figure  11: 
  Spatial  variance  for  California 
seismicity  over  time,  for  events  of  magnitude 
greater  than  or  equal  to  that  shown.  a)  M  ≥  3.0, 
boxsize = 0.1 degree, b) boxsize = 0.02 degree, M 
≥ 3.0, and c) boxsize = 0.1 degree, M ≥ 4.0. 

34 

Figure 12:  Inverse TM metric for Iberian 
peninsula, boxsize = 0.1 degree, a) M ≥ 3.0, 
and b) M ≥4.0. 

35 

Figure 13:  Seismicity for Iberian peninsula, 
1970-2001, a) M ≥ 3.0, and b) M ≥ 4.0. 

36 

Figure 14:  Numbers of events per year for 
Iberian Peninsula, a) M ≥ 3.0 and b) M ≥ 4.0. 

37 

Figure  15:    Inverse  TM  metric  for  eastern 
Canada,  1900-2001  and  boxsize  =  0.1  degree, 
a) M ≥ 3.0 and b) M ≥ 4.0. 

38 

Figure  16:    Seismicity  for  eastern  Canada, 
1900-2001, a) M ≥ 3.0 and b) M ≥ 4.0. 

39 

Figure 17:  Number of events per year, 1900-
2001 for eastern Canada, a) M ≥ 3.0 and b) M 
≥ 4.0. 

 

40 

