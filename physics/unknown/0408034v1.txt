New Pedagogy for Using Internet-Based Teaching Tools in Physics Course

David Toback1,§, Andreas Mershin1,2,#, Irina Novikova1,3,(cid:1)

1 Department of Physics, Texas A&M University, College Station, TX 77840-4242
2 Center for Biological Engineering, Massachusetts Institute of Technology,
77 Massachusetts Ave., Cambridge, MA 02139, USA
3 Harvard-Smithsonian Center for Astrophysics, Cambridge, MA 02138

Acquiring  the  mathematical,  conceptual,  and  problem-solving  skills  required  in  university-level

physics courses is hard work, and the average student often lacks the knowledge and study skills they need

to succeed in the introductory courses. Here we propose a new pedagogical model and a straight-forwardly

reproducible  set  of  internet-based  testing  tools.  Our  work  to  address  some  of  the  most  important  student

deficiencies is based on three fundamental principles: balancing skill level and challenge, providing clear

goals and feedback at every stage, and allowing repetition without penalty. Our tools include an Automated

Mathematics  Evaluation  System  (AMES),  a  Computerized  Homework  Assignment  Grading  System

(CHAGS), and a set of after-homework quizzes and mini-practice exams (QUizzes Intended to Consolidate

Knowledge, or QUICK). We describe how these tools are incorporated into the course, and present some

preliminary results on their effectiveness.

PACS numbers: 01.40Gb, 01.50H, 01.40D

Introduction

The  average  college  student  often  does  not  have  the

appropriate  preparation  level  and  study  skills  to  succeed  in

introductory-level  physics  courses.  In  addition  to  class

attendance  and/or  group  study,  students  must  also  learn  to

work  by  themselves  to  develop  the  mathematical,

conceptual,  and  problem-solving  skills  they  need.  While

computerized homework and quiz grading programs (see, for

example  [1,2])  offer  exciting  possibilities  (including  the

reduction  of  costly  and  time-consuming  human  grading)

[3,4],  many  simply  have  the  equivalent  of  having  students

turn in their homework online, and studies have shown this

yields  no  performance  advantage  over  homework  turned  in

on  paper  if  grading  for  the  latter  is  quick,  thorough  and

consistent  [3].  We  propose  a  new  pedagogical  model  that

takes advantage of modern information technology and helps

our students where they need it most.

1

(cid:1)In  this  paper  we  describe  some  of  the  roadblocks  our

students encounter during their course and the steps we have

taken  to  remove  them.  Our  pedagogy  is  based  on  three

fundamental  principles:  balancing  skill  level  and  challenge,

providing  clear  goals  and  feedback  at  every  stage,  and

allowing  repetition  without  penalty.  Using  these  principles

we  have  implemented  a  set  of  internet-based  testing  tools

which  include  math  quizzes,  homework  collection  and

grading,  homework  quizzes,  and  mini-practice  exams.

Students  that  use  these  systems  see  where  they  need  to

concentrate their efforts, become more comfortable with the

mathematics  they  need,  and  are  taught  powerful  ways  to

study  by  themselves.  We  conclude  with  some  preliminary

results  from  using  these  systems  in  the  context  of  a  typical

style lecture-based course over a number of semesters.

The Problem and the Pedagogy

game  are  acquired  and  integrated  simultaneously.  Learning

to  get  good  at  video  games  clearly  resonates  with  today's

To succeed in their first-year, calculus-based physics courses

youth.  Those  who  play  are  often  incredibly  focused  and

(Classical Mechanics and Electricity & Magnetism) students

engaged:  they  are  active  learners.  The  contrast  with  the

must  develop  analytical  problem-solving  skills.  Not  only

typical student sitting in a physics lecture could not be more

must they learn to understand and use the physics concepts

striking. We have used this video game model to develop a

in  a  problem,  they  must  turn  the  physical  quantities  into

pedagogy  which  has  students  work  on  learning  physics  the

variables  or  symbols,  “translate”  the  problem/concepts  into

same  way  they  work  at  video  games;  our  hope  is  to  get  at

equations,  and  “turn  the  crank”  on  the  mathematics  to  find

least some fraction of the dedicated effort and intensity.

the answer (a “closed-form” solution). Our experience is that

majority of our students (mainly undergraduate engineers at

We  have  created  a  set  of  three  internet-based  testing

Texas  A&M  University),  has  little  experience  with,  and  in

tools/quizzes that utilize our pedagogical model. They are i)

some  cases  a  distinct  fear  of,  symbol-based  problems

an  Automated  Mathematics  Evaluation  System  (AMES)

requiring  closed-form  solutions.  Some  do  not  even  feel

which helps students hone/develop a mathematical “toolkit”

comfortable  with  such  simple  tasks  as  fraction  addition  or

needed  to  solve  physics  problems;  ii)  a  Computerized

solving two equations with two unknowns.

Homework  Assignment  Grading  System  (CHAGS)  which

encourages  solving  all  the  assigned  problems  in  both

To confront these problems, we encourage a learning model

symbolic  and  numeric  form  and  gives  feedback  along  the

which  is  culturally  familiar  to  most  students  in  our  classes

way;  and  iii)  a  set  of  after-homework  QUizzes  Intended  to

and often produces many hours of intense, concentrated and

Consolidate  Knowledge  (QUICK)  which  provide  short  new

passionate  non-schoolwork  effort:  playing  video  games.

problems for students to solve.  In each we begin with a clear

Today's student understands a video game instinctively, and

definition of what it means to “get to the next level,” we give

the fun comes not just from fancy graphics, but also from the

them  unlimited  attempts  to  get  a  perfect  score  without

quality  of  the  interaction  and  the  game's  structure.  Good

penalty (changing the problem slightly on each attempt), and

games, following sound psychological principles [5], require

we give them feedback along the way. We make “winning”

focus, a balance of skill level and challenge, clear goals and

worth their time by rewarding them: guaranteed high scores

feedback,  as  well  as  the  opportunity  to  repeat  the  task  at

towards  their  final  grade.  In  order  to  pass  the  course  we

hand until it is no longer difficult. In a typical game there is

require they get a perfect 100% score on all assignments, in

a score so one can see how well one is doing, the goal is to

sequence.  However,  to  balance  this  weighty  requirement,

get as high a score as possible. Often there are several levels,

and  as  a  further  incentive,  we  offer  another  video  game

and  each  level  is  designed  so  that  one  can  progress  with

concept, bonus points, for getting 100% on-time. While we

significant but not too much effort. At home, it is trivial to

have implemented these tools using WebCT [1], they can be

start  a  new  game  and  one  plays  as  many  games  as  one

straightforwardly 

implemented  with  other  software

pleases  in  order  to  get  past  each  level.  Even  then,  just

packages.

because  one  can  pass  a  level  once  does  not  mean  it  is  easy

the next time; getting to the highest levels requires repetition

until  all  the  skills  that  are  useful  at  various  stages  of  the

2

Automated Mathematics Evaluation System (AMES)

penalty, until they reach the same proficiency level.

During  the  first  week  of  the  semester  we  assign  a  set  of

Every  time  a  quiz  is  attempted,  students  are  presented  with

online  mathematics  quizzes  that  are  strictly  limited  to  the

the  same  questions  they  answered  incorrectly  the  previous

relevant  pre/co-requisite  math  topics  for  the  course  and  are

time (but with the five multiple-choice answers shuffled) and

designed  to  be  finished  quickly.  Our  intent  is  to  remind

students of the relevant calculation tools they should already

fresh  ones  from  the  same  section  to  replace  the  ones  they
answered correctly2.  It  is  also  important  that  all  the  seven

have  by  giving  them  enough  practice  until  they  have

AMES categories are represented in each ten-question quiz;

(re)gained facility, and to establish a high competency level
for  the  course1.  Each  quiz  consists  of  ten  multiple-choice

in  this  way  students  become  accustomed  to  working

simultaneously with more than one concept, such as algebra

problems,  developed  by  the  authors  from  standard

and  vectors,  and  do  not  learn  one  only  to  forget  the  other.

homework  problems,  which  cover  what  we  have  identified

After  finishing  with  AMES  students  are  more  comfortable

as  the  most  common  deficiencies  of  our  students.  Every

and  proficient  in  the  entire  set  of  physics-relevant  math

attempt  randomly  draws  from  our  large  pool  of  questions

topics.

and includes at least one from each of seven different areas:

equations  in  two  variables;  iii)  quadratic  equations  and

(CHAGS)

identities; iv) geometry and trigonometry including vectors;

i) simple algebraic expressions in one variable; ii) systems of

Computerized  Homework  Assignment  Grading  System

v)  fractions,  numbers,  exponents,  powers  of  ten;  vi)  word

Our course now requires students to turn in their homework

problems  and  proportionalities,  and  vii)  simple

online  using  CHAGS.  In  addition  to  the  “free-tries-until-

differentiation and integration (calculus is a co-requisite for

perfection methodology,” what is different about CHAGS is

the  course,  but  many  students  have  seen  the  material

that  it  is  designed  for  turning  in  homework  after  students

previously; there are instructions for those who have not yet

have  completed  the  assignment  with  paper  and  pencil  and

taken  calculus).  Examples  of  questions  and  AMES  screen

produced  their  answers  in  closed  form.  Students  receive  a

shots can be found in [6].

list of problems from the course textbook where the typical

problem  is  stated  with  numerical  values  for  given  physical
variables (e.g. the mass is 10 kg, the angle is 20o, etc.), and

Students  have  ten  minutes  to  complete  each  quiz,  and  they

must obtain a 100% on ten “separate” quizzes (although each

they are asked to find a numerical solution (e.g. what is the

quiz  is  actually  drawn  randomly  from  the  same  pool  of

value of the acceleration). We have found that inexperienced

questions).  Each  question  is  designed  such  that  a  well-

students  tend  to  start  by  writing  their  equations  with  the

prepared  student  can  easily  complete  an  entire  quiz  in  less

numerical  values  directly  entered  in,  and  they  try  to

than five minutes. By design, the system “levels the playing

manipulate the equations until they get the correct numerical

field” as those already comfortable with the mathematics can

answer provided in a solution manual. We urge our students

quickly pass, and those needing help re-take quizzes without

to  use  symbolic  variables,  such  as  mass  =  m ,  angle=  (cid:1),

                                                            
1 We have also begun to develop an additional set of quizzes to train
students to transform a word problem into a set of equations even before

                                                            
2 We note that this important feature of AMES was originally developed on
our custom-built prototype system, but is not currently available on WebCT

learning any physics concepts.

and has been requested from the developers.

3

acceleration = a, and then solve for a in terms of m, (cid:1), etc.

elucidate  mistakes  and  enhance  understanding  [8].  In  our

case  students  can  immediately  see  all  the  correct  numerical

To turn in their homework after obtaining a complete set of

answers  and  use  multiple  attempts,  if  needed,  to  guarantee

closed-form answers, students log in to CHAGS where they

that they find the errors in their symbolic answers.

expect to see a set of problems identical to the ones they just

solved, but with the different numeric values of one or two

Quizzes Intended to Consolidate Knowledge (QUICK)

of the parameters. They have only a short time to substitute

 

the new number(s) into their formulae, recalculate and input

 Successful  completion  of  the  homework  assignment  after

the new numeric result, which is then checked by the system

many hours and/or attempts does not necessarily mean that a

at  run-time  allowing  for  small  rounding  errors.  The  time

student  is  prepared  to  solve  an  unfamiliar  problem.  Often

constraint  forces  students  to  be  ready  with  their  formulae

this is the ideal time to provide real feedback to the students

before  they  log  in  to  the  system  and  thus  emphasizes  the

as  to  whether  they  truly  understand  the  material  and/or  to

utility  of  obtaining  closed-form  solutions.  We  note  that

reinforce their learning with additional practice. To do this,

although input of answers in symbolic form is possible, and

we have implemented a short, multiple-choice quiz for each

in some cases preferable, this option is not available in many

textbook  chapter  using  the  standard  test  banks  which  are

commercial systems [7]. An advantage we have found is that

readily  available  (and  free  to  instructors)  [9].  Each  consists

numerical answers encourage students to be careful in their

calculations  and  to  perform  mental  "reality  checks"  for  the

of two intermediate-level problems randomly drawn from a
large  pool4,  selected  from  the  textbook’s  test  bank,

magnitudes  of  various  physical  quantities  which  develops

necessitating  roughly  three  to  five  minutes  per  problem  to

intuition for the realistic values for everyday things such as

solve  (we  give  students  ten  minutes  total).  Again,  students

the speed of a bicycle or the mass of a billiard ball.

are required to get a perfect score on a quiz for each chapter

and  they  are  allowed  unlimited  attempts,  albeit  with

As  in  AMES,  the  number  of  attempts  is  unlimited  and  we

completely new, randomly drawn problems on each attempt.

require  students  to  correctly  answer  all  the  problems,  all  at

We  also  offer  a  voluntary  practice  tool  to  help  students  in

once,  so  there  is  no  temptation  to  ignore  harder  ones  or  to

their  preparation  for  each  traditional  in-class  exam.  After

learn  a  set  of  topics  and  then  forget  them.  In  contrast,  the

successfully  submitting  all  the  homework  assignments  and

problems are always the same, but all of the parameters are
changed  for  every  problem  on  every  attempt.  3  This

completing the associated quizzes for the chapters covered in

the upcoming exam, students gain access to a mini-practice

effectively  discourages  the  time-wasting  trial-and-error

exam created using the same type of quiz problems from the

strategies  [3].  Furthermore,  studies  have  shown  that

same  chapters.  For  example,  our  first  exam,  which  covers

immediately  providing  the  correct  numerical  response  and

chapters  1,  2,  and  3,  the  mini-practice  exam  includes  four

allowing  a  second  chance  gives  students  the  opportunity  to

randomly selected problems (one from Ch. 1, one from Ch 2

                                                            
3 In  order  to  minimize  both  student  complaints  and  lucky  guesses,  and
maximize  the  benefit  of  the  requirement  to  solve  many  problems  at  once,

we  typically  break  up  an  assignment  of  15  small  problems  into  three

separate submissions, each with a 20-minute time limit.

and  two  from  Ch.  3)  and  the  students  have  20  minutes  to

                                                            
4 We note that WebCT (and other programs) do not currently allow us to
use the feedback from all our teaching tools to generate personalized
quizzes. We look forward to the day when the software can "learn" so we
can better target the individual weaknesses of each student.

4

complete  all  problems.  This  tool  not  only  provides  a

submission and other available computer-facilitated teaching

meaningful feedback on student readiness for the traditional

tools. Our systems have now been tested for many semesters,

exam,  it  teaches  students  to  learn  the  material  as  a  whole,

and Figs. 1 and 2 present statistical analysis of performance

and not just “cram” one piece at a time. It also pushes them

when  these  methods  were  incorporated  into  the  classroom

to  study  for  physics  exams  by  solving  many  problems

for  the  most  recent  semester.  Both  show  clear  correlation

instead  of  the  common  “read  the  book  or  look  over  your

between  performance  and  in-class  examination  scores.  On

homework  and  figure  you’re  ready  if  it  makes  sense”

the weight of this evidence alone, however, we cannot make

approach.  Even  though  mini-practice  exams  are  not  part  of

any strong statements on the effectiveness of these tools, as

the  required  course  work,  we  have  found  that  “earning  the

smart  and/or  diligent  students  who  completed  our  quizzes

right” to take the mini-practice exam is an effective “carrot,”

might  have  done  well  even  without  them.  Additional,

and  we  further  encourage  students  by  explicitly  offering  a

appropriately  controlled  quantitative  studies  are  clearly

few  bonus  points  for  scoring  a  100%  before  each  in-class

needed to accurately evaluate the usefulness of the proposed

exam.

methodologies.  Our  data  does  show  that  we  succeed  in

getting the majority of the students to finish all quizzes and

homework assignments on time and that most complete the

voluntary  mini-practice  exams  as  a  preparation  for  in-class

tests.  Perhaps  most  importantly,  showing  these  figures  in

class  provides  an  unambiguous  message  to  the  poorly

performing  students:  “if  you  want  to  improve  your  grade,

here is what you need to be doing.”

We  are  aware  that  the  stringent  requirement  that  every

student  pass  all  homework  assignments  at  100%  imposes  a

restriction  on  the  difficulty  level  of  the  problems.  We  also

note  that  while  we  find  that  students  withdraw  from  our

course  earlier  than  in  other  courses,  the  final  number  of

students who leave is roughly the same. Of those who stay,

only  ~3%  of  students  do  not  finish  the  requirements  when

periodically  reminded  of  them.  From  those  there  are  none

who  would  pass  the  course  if  the  homework  requirement

were lifted. Finally, these requirements do not alter the grade

distribution curve even with ~97% of the students achieving

100% scores, since this only produces a small overall shift of

the mean (provided the homework/quiz portion of the grade

is  not  larger  than  about  ten  percent).  At  the  same  time  we

have found “securing” 100% for at least a part of the course

grade  to  have  a  profound  positive  impact  on  the  morale  of

Figure  1 A  comparison  of  the  grade  distribution  for  the  first  exam  for
students who completed AMES (ten 100% scores) beforehand and for those
who did not.

Discussion

We  feel  that  our  “video-game”  model,  which  encourages

repetition and facility of all relevant skills at once, has many

advantages  over  traditional  pen-and-paper  homework

5

many students.

Figure 2 A  comparison  of  the  grade  distribution  for  the  second  exam  for
students who completed a voluntary mini-practice exam before the in-class
examination and for those who did not.

What  the  students  thought:  There  are  a  range  of  student

responses  and  clearly  not  all  are  converts.  Some  students

complained  bitterly  about  being  forced  to  spend  too  much

time  on  their  homework  as  our  system,  like  others,  does

suffer  from  the  occasional  time-wasters  of  mistyped
numbers,  internet  outages,  broken  URLs,  etc5.   Many

appreciated  the  feedback  and  the  opportunity  to  secure  a

high  homework  grade.  A  surprising  number  of  students

“confessed” to having developed more self-confidence in the

class  and  said  that  they  now  understood  how  to  study  for

other classes as well.

What  the  teachers  thought:  While  some  are  uncomfortable

with  the  perfection  requirement  and  the  constraints  this

                                                            
5 We battle the other common problem - unclearly-worded questions, typos,
incorrect solutions - by giving extra credit to the first couple students who

report any broken question.

system  puts  on  their  students,  they  are  happy  with  the

outcome. Prior to the existence of these systems, instructors

generally  heard  complaints  about  the  mathematical  content

of  the  course  ("I  understand  the  physics  but  can’t  do  the

math") or the difficulty of the exams ("I've never had to do a

problem with variables before"). The introduction of AMES

and CHAGS nearly eliminated such gripes. In addition many

reported  that  the  pervasive  "symbol  fear"  was  all  but

eliminated  and  that  students  no  longer  waste  valuable  class

time  complaining  that  they  cannot  follow  the  simple

algebraic manipulations on the blackboard. Time and effort

can  now  be  concentrated  on  teaching  physics  concepts.  If

nothing  more,  this  aspect  alone  makes  the  course  more

enjoyable to teach.

Conclusions

We have described a new pedagogy for using internet-based

testing  tools  to  develop  math  skills,  turn  in  homework  and

take practice quizzes in introductory university-level physics

courses.  We  have  found  that  by  using  a  balance  between

skill level and challenge, providing clear goals and feedback

at  every  stage,  and  giving  the  student  the  opportunity  to

repeat,  without  penalty,  until  the  task  at  hand  is  no  longer

difficult,  we  have  addressed  some  of  the  most  important

deficiencies of our students. We believe this system teaches

students to study in a powerful way which is new to most of

them.  Our  preliminary  results  are  promising  and  we

encourage  teachers  elsewhere  to  try  similar  methods  and

possibly perform more systematic evaluations. We hope that

with  the  pervasiveness  of  internet  access  and  general

computer  familiarity  of  the  average  college  student  others

will find our methods to be a useful and economical way of

improving  understanding  and  performance  in  their  physics

courses.

Acknowledgments

6

We would like to thank Wayne Saslow, Teruki Kamon, Peter

Moore, “Take (Your) Work Out of (Their)

McIntyre,  Bob  Webb,  George  Welch,  Cathy  Ezrailson  and

Homework,” AAPT Announcer, 34 (2), 175 (2004).

Joan  Wolf  for  useful  discussions,  and  Joel  Walker,  Matt

[5]  See for example, M. Csikszentmihaly, “FLOW,”

Cervantes, Rhonda Blackburn, Jim Snell, Court Samson and

Harper & Row Publishers Inc, 1990 and references

Sally  Yang  for  help  with  programming  and  other  technical

therein.

expertise.  Financial  support  was  provided  by  the  Texas

[6]    See http://faculty.physics.tamu.edu/toback/218/quiz/

A&M  University  Department  of  Physics,  Instructional

AMES_Brochure.pdf.

Technology  Services,  and  the  Montague  Scholarship

[7] B. Crowell, “Checking Students’ Symbolic Math on

Program  at  the  Center  for  Teaching  Excellence.  AM  was

a Computer,” Phys. Teach. 41, 478 (Nov. 2003).

partially  supported  by  the  S.A.  Onassis  Public  Benefit

[8]

See for example R.W. Hall, L.G. Butler, S.Y.

McGuire, S.P. McGlynn, G.L. Lyon, R.L. Reese, and

P.A. Limbach, “Automated, Web-based, Second-

Chance Homework,” J. Chem. Educ. 78, 1704 (Dec.

2001) and references therein.

[9]  We have taken the test item file by E. Oberhofer, D.

Curott and R. Pelcovits from “Physics for Scientists

and Engineers” by D.C. Giancoli, Prentice Hall, 3rd

Edition (2000).

Foundation.

# mershin@physics.tamu.edu

(cid:1) inovikova@cfa.harvard.edu

§ toback@physics.tamu.edu 

References

[1] WebCT.com http://www.webct.com.

[2]  Tycho homework system:

http://www.physics.uiuc.edu/research/per/Tycho.html;

CAPA http://www.lon-capa.org; Homework Service

http://hw.utexas.edu/overview.html.

[3]

S. Bonham, R. Beichner, and D. Deardorff, “On-

line homework: does it make a difference?” Phys.

Teach. 39, 293 (2001); S. W. Bonham, D.L. Deardorff,

and R. J. Beichner, “Comparison of Student

Performance Using Web and Paper-Based Homework

in College-Level Physics,” J. Res. Sci. Teach. 40, 50

(2003).

[4]

J.H. Penn, V.M. Nedeff, and G. Gozdzik, “Organic

Chemistry and the Internet: A Web-Based Approach to

Homework and Testing Using the WE_LEARN

System,” J. Chem Educ. 77, 227 (Feb. 2000); R.S.

Cole, and J. B. Todd, “Effects of Web-Based

Multimedia Homework with Immediate Rich Feedback

on Student Learning in General Chemistry,” J. Chem.

Educ. 80, 1338 (Nov. 2003); P. McDonald and C. F.

7

