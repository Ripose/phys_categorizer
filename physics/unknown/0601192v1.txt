Re-inventing Willis 
 
M.V. Simkin and V.P. Roychowdhury 
Department of Electrical Engineering, University of California, Los Angeles, CA 90095-1594 
 
Scientists  often  re-invent  things  which  were  long  known.  Here  we  review  these  activities  as  related  to  the 
mechanism  of  producing  power  law  distributions,  originally  proposed  in  1922  by  Yule  to  explain 
experimental data on the sizes of biological genera, collected by Willis. We estimate that scientists are busy 
re-discovering America about 2/3 of time. 

The book of Ecclesiastes says: “Is there any thing 
whereof  it  may  be  said,  See,  this  is  new?  It  hath 
been  already  of  old  time,  which  was  before  us.” 
The job of the scientists is to discover new things, 
thus  they  are  the  most  affected.    In  this  paper  we 
report  a  case  study  involving  the  mechanism  of 
generating  power-law  distributions  known  as 
Yule’s  process,  Simon’s  model,  Cumulative 
Advantage,  or  Preferential  Attachment.  We  also 
discuss  the  relation  of  Yule’s  process  to  Galton-
Watson process and to Self-Organized Criticality.  

Yule’s process 
In  1922  Willis  and  Yule  [1]  analyzed  the  data  on 
frequency  distribution  of  the  sizes  of  biological 
genera,  collected  by  Willis  [2].  They  discovered 
that  this  distribution  follows  a  power  law.  To 
explain  this  observation  Yule  [3]  proposed  the 
following  model 1 .  Consider 
types  of 
mutations: specific (that is producing a new specie 
of the same genus), which occur in each specie at 
rate s, and generic (that is producing a new genus) 
which occur in each genus at rate g.  
In  this  model  the  expectation  value  of  the  total 
)tg ·
. 
number  of  genera  grows  with  time  as
Therefore  the  probability  distribution  of  the  ages 
of genera is: 

(
exp

two 

                                                 
1  A  quarter  of  this  paper  consists  of  relevant 
passages  copied  from  original  papers.  This  is  not 
plagiarism:  the  latter  is  copying  from  a  single 
source. In contrast, copying from many sources is 
original in-depth research. 
 

 

1 

(cid:1)

 

 

 

 

 

. 

·

.  

)t

(1) 

)gt

(
= exp
s

(
= exp
g
-

( )
tp
The expectation number of species in a genus of age t 
is: 
( )
tn
Now  suppose  that  chance  can  be  ignored,  that  the 
number  of  species  in  a  genus  can  be  taken  as  a 
continuous variable, and that the above can be taken 
as absolute functional relations. The size of genus is 
then  absolutely  determined  by  its  age,  and  we  can 
find the number of genera of each size by eliminating 
t from Eq. (1) using Eq. (2): 

(2) 

 

=

ln

( )
nt

1
s
This leads to: 

( )n

; 

dt

=

dn
ns
·

. 

( )
np

=

g-

n

; 

g
s

+= 1g

. 

 

(3) 

g
s

The  exact  solution  was  also  found  by  Yule  [3].  The 
probability of a genus of an age t to be monotypic, i.e. 
just  one  specie, 
to  consist  of 
is,  obviously, 
(
)st
( )
= exp
tp
. For a genus to contain two species 
-
1
at  time  t,  a  single  mutation  must  occur  at  some 
intermediate  time  t1,  the  original  specie  must  not 
mutate  until  t1,  and  two  resulting  species  must  not 
mutate for the time t- t1. The probability for  a genus 
to contain two species is obtained by integrating over 
all possible values of t1,: 

t

0
st

( )
tp
2

= (cid:1)

( )
stpdt
1

1

1

exp

(
-

2

(
ts

-

t
1

)
)

=

 

(
-

(
)
1

(
-

)st
)

-

exp

exp
In general, it can be verified by induction that: 
 

( )
tp
n

=

(
exp
-

st

(
)
1

-

(
exp
-

st

n

-

) 1
)

 

 

(4) 

 
We  see  that  the  size  distribution  of  genera  of  the 
same  age  is  exponential.  This  result  was  re-
discovered in 1992 by Günter et al [4] and in 2000 
by  Krapivsky  and  Redner  [5],  who  used  more 
complicated mathematical methods. 
 
Combining  the  distribution  of  the  number 
of species in genera of age t (given by Eq.(4)) with  
the  distribution  of  the  ages  of  genera  (Eq.(1))  we 
obtain  the  overall    probability  distribution  of 
genera with regard to the number of species: 
 

p

n

=

dtp

( ) ( )
tpt

n

=

¥

(cid:1)

0

dt

exp

(
-

st

(
)
1

-

exp

(
-

st

)
)

n

1
-

g

exp

(
-

gt

)

=

g
s

dxx

(
1

-

x

)

n

1
-

=

  (5) 

¥

(cid:1)

0

g
s

1

(cid:1)

0

g
s

(cid:7)
(cid:5)
B
(cid:6)

g
s

+

,1

n

(cid:4)
=(cid:2)
(cid:3)

g
s

G

G

(cid:7)
(cid:5)
(cid:6)
(cid:7)
(cid:5)
(cid:6)

g
s
g
s

+

1

(cid:4)
G(cid:2)
(cid:3)

( )
n

1
++

n

(cid:4)
(cid:2)
(cid:3)

 
Here B and  G are  Euler’s  Beta  and  Gamma 
functions. 
The large-n asymptotic of Eq.(5) is 
 

p

n

(cid:181)

. 

 

 

 

(6) 

+

1

(cid:4)
(cid:2)
(cid:3)

1
+

G

(cid:7)
(cid:5)
(cid:6)

g
s
g
s

n

g
s

Modified Yule’s model 
We  introduce  this  modification  in  order  to  make 
the  similarity  between  Yule’s  and  Simon’s  model 
(which  we  discuss  later)  more  obvious.  Let  us 
assume  that  the  rate  of  generic  mutations  is 
proportional  to  the  number  of  species  in  a  genus. 
In this case the number of genera grows with time 
(
(
exp
s
 and  the  age  distribution  of 
as 
genera is: 
 

)t

·

+

g

)

( )
tp

=

(
s

+

g

)

(
exp
-

(

s

+

)tg
)

. 

 
Substituting this into Eq.(5) we get: 

p

n

=

dtp

( )
pt

t

n

=

¥

(cid:1)

0

¥

(cid:1)

0

=

=

1

(cid:1)

0

g

g

s

s

+
s

+
s

gs
+
s

dxx

(
1

-

x

)

n

1
-

(cid:7)
(cid:5)
B
(cid:6)

g
s

+

,2

n

(cid:4)
=(cid:2)
(cid:3)

dt

exp

(
-

st

(
)
1

-

exp

(
-

st

)
)

n

1
-

(

s

+

g

)

exp

(
-

(

s

+

)
tg

)

(7) 

s

g

+
s

G

G

(cid:7)
(cid:5)
(cid:6)
(cid:7)
(cid:5)
(cid:6)

g
s
g
s

+

2

(cid:4)
G(cid:2)
(cid:3)

( )
n

2
++

n

(cid:4)
(cid:2)
(cid:3)

(cid:181)

s

g

+
s

(cid:7)
(cid:5)
G
(cid:6)

+

2

(cid:4)
(cid:2)
(cid:3)

+

2

g
s
g
s

n

The  major  difference  between 
the  probability 
distribution, generated by the modified Yule’s model 
(Eq.(7)) and the one generated by the standard Yule’s 
model (Eq.(6)) is that Eq.(7) has the exponent of the 

power  law  equal  to 

+= 2g

,  while  Eq.(6)  has  it 

g
s

equal  to

+= 1g

.  By  changing  parameters  g  and  s, 

g
s

Eq.(6) can be tuned to have an exponent of any value 
greater than 1, while Eq.(7) has the exponent always 
greater  than  2.  Willis’  data  could  be  fitted  with  a 
power  law  with  an  exponent  of  around  1.5.  Only 
standard  Yule’s  model  can  account  for  it,  while 
modified can’t. 
 
Champernowne’s model of income 
distribution 
To explain the power law in distribution of incomes, 
discovered  by  Pareto,  Champernowne  [6]  invented 
the following model.   He divided income recipients   
into  ranges  of  equal  proportionate  width.    That  is,  if 
Imin is the minimum income considered, then the first 
range  contains  persons  with  incomes  between  Imin 
and  aImin,  the  second  range  persons  with  incomes 
between  aImin  and  a2Imin,  and  so  on.  Next  he 
introduces  transition  probabilities  rnm  that  a  person 
who is in class m at time t will be in class n at time t 

 

2 

+ 1.  He assumes that rnm is a function of only n-m 
(except  for  the  small  m,  when  it  is  modified  to 
prohibit falling below minimum income).  
To illustrate the Champernowne’s model we will 
consider the simplest nontrivial transition function, 
the one which only allows transitions between 
adjacent classes: 
 
rnm
(cid:11)
(cid:8)
(cid:10)
(cid:8)
r
(cid:9)
1
-
 

mn
-
mn
-
mn
-
 

r
1
r
0
1
-=
 

when
when
 

(
mnr
-

=
-=

r
0
 

when

0
1

(8) 

r
1

-

=

=

=

1

)

 

 

 

rn

0

=

(cid:11)
(cid:10)
(cid:9)

r
1
1
-=

r
1

when
when

n
n

=
=

1
0

 

r
0

+

r
1
-

 
In equilibrium the occupation probabilities, pn, of 
income ranges, n, should satisfy the following 
equations: 
 

 

n

1
+

0

n

n

p

p

=

=

n
+

+
r
1
-

pr
1
)

pr
0
(
r
0
 
 
which in the case 
 

p
 

0

- +
1
+

 

pr
1
-
pr
1
1
-
 
-< r

1

r
1

, 
 

 
 
 have following solution: 

 
 

p

n

(
1
-=

rr
1

)
- ·
1

(
rr
1
1
-

)n

. 

 

 

(9) 

occupation 

probabilities 

 
The 
decrease 
exponentially with income ranges range number, n. 
As  pn  is  the  probability  to  have  income  between 
an-1Imin  and  an  Imin  -  income  exponentially  grows 
with the range number.  The situation is similar to 
what was in Yule’s model, with time replaced by n. 
This leads to the income distribution of the form: 
 

( )
Ip

~

g-I

,  

1
+=g

 

(10) 

ln

)

(
r
1-
ln

r
1
( )a

. 

 
A continuum version of Champernowne’s model 
was re-discovered in 1996 by Levy and Solomon 
[7]. 

Simon’s model 
The  distribution  of  words  by  the  frequency  of  their 
use  follows  a  power  law.  This  fact  was  discovered 
sometime  before  1916  by  Estoup  [8],  re-discovered 
in  1928  by  Condon  [9],  and  once  more  in  1935  by 
Zipf [10]. Nowadays it is widely known as Zipf’s law. 
To explain this observation Simon [11] proposed the 
following  model.  Consider  a  book  that  is  being 
written,  and  that  has  reached  a  length  of  N  words. 
With probability a the (N+1)-st word is a new word – 
a  word  that  has  not  occurred  in  the  first  N  words. 
With probability 1-a the (N+1)-st word is one of the 
old words. The probability that it will be a particular 
old word is proportional to the number of its previous 
occurrences.  
 
If certain word appeared K times among N words, the 
probability  that  (N+1)-st  word  will  be  this  word  is 

·

(
)
-a1

.  The  evolution  of  the  word  frequency 

K
N
KN  denotes  the  number  of  words 
distribution  (here
that appeared K times) is described by the following 
equations: 
 
dN
1
dN
dN
K
dN

N
1
N
)1
·-

(
)
1 a
-=

(
1
--

NK
·

( >K

-1
K
N

(11) 

,      

)
a

a

)1

K

N

-

·

=

·

(

 

K

 
Assuming  that  the  distribution  of  words  has  reached 
its stationary state we can replace the derivatives with 
the ratios: 
 

(12)

 

=

a

(
1
--

)
a

·

N
1
N

 

N
1
N

 

N
K
N

(
)
1 a
-=

·

(

K

)1
·-

N

-

NK
·

K

-1
K
N

( >K

)1

.      

 
 
 

 
 
 

 
 
 
The probability that the word occurs K times is equal 
to 

 
 
 

 
 

 
 

 
 

 

3 

(13) 

the probability for the next word to be a new word. It 
is equal to: 

 is the number of distinct words 

 

 

 

)

,  

P
K =

N
a=
 
 

(
NN
K
(
)ND
)
(
ND
where 
in the book. 
 
 
We thus have: 
 
 
 
After substituting Eq. (14) in Eq. (12) we get: 

NP
a=
K

(
NN
K

 
 

 
 

 
 

)

 

 

 

 

 

(14) 

  (K > 1).                  

(15) 

1
a-

, 

1P

=

P
K
P
K

1
-

2

=

K
1
-
)a-
(
11
+

K

 
Iterating the above equation we get  
 

1
-
a

2

=

PK

=

·

(
)
)
(
K
(
112)
G
+G
-
a
(
)
)
(
K
111
++
G
-
a
(
)
)
(
111)
1
+G
-
a
)
)
(
111
1
-
++
-
a
a
(
)
)
(
111
1
+G
a
-
(
)a
111
+
-
K
a
-

·

·

K
(
G
(
K
G

(cid:181)

1

   

(16) 

 
In 1976 Price [12] used Simon’s model to explain 
a  power  law  distribution  of  citations  to  scientific 
papers,  which  he  discovered  in  1965  [13]2.      He 
proposed to call it “cumulative advantage process”.  
Simon’s  model  was  re-discovered  in  1992  by 
Günter et al [4] and 1999 by  Barabasi and Albert 
[16].  In  the  latter  case  it  acquired  a  new  name: 
“preferential attachment”. 

Solution of the modified Yule’s model 
by Simon’s method 
In  Simon’s  model  genus  corresponds  to  a  distinct 
word,  and  number  of  species 
in  a  genus 
corresponds  to  the  number  of  occurrences  of  a 
word  in  the  text.  The  probability  of  a  new 
mutation  to  be  a  generic  mutation  corresponds  to 

                                                 
2 This was rediscovered in 1997 by Silagadze[14] and  in 
1998 by Redner [15].  

 

4 

=a

g
+

s

g

 

 

Substituting this in Eq. (16) we recover Eq. (7) 

Solution of Yule’s model by Simon’s 
method 
Original Yule’s model is more difficult to solve by 
Simon’s method. The problem is that the probability 
of a new mutation to be generic changes in time.  
This probability is given by the equation: 
 

=a

gN

, 

g
gN

g

sN

s

+

 

 

 

(17) 

(
= exp

 
sN  the 
gN is  the  total  number  of  genera,  and 
where 
total  number  of  species.  Let  us  compute  these 
numbers at time t. Suppose, that at time 0 there  was 
one  genus,  consisting  of  single  specie.  The 
expectation number of genera at time t is, obviously,  
 
N g
 
The expectation number of species in the primal 
genus at time t is:  
 
1
N s
 
The number of species in new genera is: 
 

(
= exp
s

)tg
·

(18)  

)t

·

. 

  

 

 

 

N

*
s

= (cid:1)

gdt
1

exp

(

gt

1

)

exp

(

(
ts

-

t
1

)
)

=

 

(
exp

(

gt

)

-

exp

)st
(
)

t

0

g
-

g

s

 
The expectation number of all species at time t is:  
 

N

s

=

N

1
s

+

N

*
s

=

exp

(

gt

)

+

exp

(

)st

 

g
-

g

s

s
-

s

g

 
The large t asymptotic of the above is: 

 

N s

=

(cid:11)
(cid:8)(cid:8)
(cid:10)
(cid:8)
(cid:8)
(cid:9)

g
-
s
-

s

g

g

s

exp

(

gt

)

when

g

>

s

exp

(

st

)

when

s

>

g

   

(19) 

 
Let us consider the case g > s. Substituting Eqs.(18) 
and (19) into Eq.(17) we get: 
 

a

=

gt

ge

s

g
-

g

s

gt

e

gt

+

ge

1
-=

s
g

 

 

(20) 

 
Substituting Eq.(20) into Eq.(14) we recover 
Eq.(5). 
 
Let  us  now  consider  the  case  s  >  g.  After 
substituting Eqs.(18) and (19) into Eq.(17) we get: 
 

a

( )
t

=

gt

ge

s

s
-

s

g

st

e

gt

+

ge

(cid:181)

g

g

s

-
2
s

(
--

)tgs

e

 

(21) 

After expressing t through sN , using Eq.(19), and 
substituting the result into Eq.(21) we get: 

(
a

N

s

)

=

CN

-
g
s

; 

-= 1g

. 

 

 

(22) 

g
s

Here C is a function of g and s. 
 
Let us consider a modified Simon’s model where  
 
a
 
The number of distinct words as a function of total 
number of words will be  
 

-
g
= CN .  

(23) 

 

 

 

 

N

g
-

)

= (cid:1)

(
ND

dMCM

C
1
-
After substituting Eq.(24) into Eq.(13) and the 
result together with Eq.(23) into Eq.(12) we get:  

(24) 

g

N

1
g
-

=

 

 

0

1P

=

1
2

-
-

g
g

 

P
K
P
K

1
-

=

K
1
-
1
g-+

 

K

 

 
By iteration of Eq. (25) we get: 
 

PK

(
1
-=

)
g

K
(
G
(
K
G

(
2)
-G
2
-+

 

 

 

)
g
)g
g
s

 

 

(25) 

(26) 

after substituting 

-= 1g

into Eq.(26) we recover 

Eq.(5). 
This  model  with  N-dependent  a  was  first  suggested 
and  solved  by  Simon  [11].  It  was  rediscovered  by 
Dorogovtsev  and  Mendes  [17]  in  the  context  of 
science of networks.  
 
This exercise shows that Yule’s and Simon’s models 
are two ways of looking at the same thing. In contrast, 
Champernowne’s model is similar, but not identical. 

Markov-Eggenberger-Polya Urn models 
The  urn  contains  one  white  and  one  black  ball.  We 
take  out  a  ball  at  random,  than  put  it  back  and  add 
another  ball  of  the  same  color.  The  procedure  is 
repeated again and again. This model was considered 
in  1907  by  Markov  [18],  and  re-discovered  in  1923 
by Eggenberger and Polya (see Ref. [19] pp.176-177).  
The  model  is  nowadays  known  as  Polya’s  urn 
scheme.  Obviously,  the  procedure  has  cumulative 
advantage  feature  of  Yule-Simon  process.  This 
connection  was,  probably,  first  pointed  out  by  Price 
[12]  in  1975,  and  re-discovered  in  2003  by  Chung, 
Handjani,  and  Jungreis  [20].  Markov’s  problem  is 
easier to solve than Yule’s. After one step in the urn 
there  can  be  either  one  black  and  two  white  balls  or 
one white and two black balls with equal probability. 
It  is  easy  to  show  that  after  two  steps  the  possible 
combinations  are  3-1,  2-2,  and  1-3,  and  all  of  them 
have  the  same  probability.  In  general,  after  N  steps 
there can be any number of white balls from 1 to N+1 
all  with  equal  probabilities N1
.  This  can  be  proved 
by  induction.  If  this  holds  true  for  N  steps,  than  the 
probability to have n white balls after N+1 steps is 

 

5 

(
np

-

,1

N

)

+

(
Nnp
,

)

=

 

N

n

1
-+
N
1
+

(
Nnp
,
n
1
-
N
1
+
N
+

)
1
=+

1
N

=

1
+

1

1

N

N
This  uniform  distribution  of  balls  reminds  the 
zero-temperature  distribution  of  particles  obeying 
Bose-Einstein  statistics,  when  the  ground  level  is 
doubly  degenerate.  The  relation  of  cumulative 
advantage  process  to  Bose-Einstein  statistics  was 
pointed  out  in  [21],  [22],  [23].  If  we  modify  the 
urn  scheme  so  that  with  probability  a we  add  a 
ball  of  a  new  color  –  we  recover  the  Yule-Simon 
process. 

Spectrum of cosmic radiation 
In  1949  Fermi  [24]  explained  experimentally 
observed power-law spectrum of cosmic radiation 
as  follows.  The  particles, 
like  protons,  are 
accelerated  through  collisions  with  wandering 
interstellar  magnetic 
fields.  An  elementary 
the 
estimate  can  be  obtained  by  picturing 
collisions against reflecting obstacles of very large 
mass, moving with random velocities averaging to 
V. Assuming this picture, one finds easily that the 
average  gain  in  energy  per  collision  is  given  as 

2

(cid:7)
(cid:5)
(cid:6)

V
c

(cid:4)
(cid:2)
(cid:3)

order  of  magnitude  by

dE

=

E

,  where  E 

represents  the  energy  of  the  particle  inclusive  of 
rest energy,  and c is the speed of light.  If we call 
t the  time  between  scattering  collisions,  the 
energy  acquired  by  a  particle  of  age  t  will 

be

( )
tE

=

Mc

(cid:7)
(cid:5)
2 exp
(cid:5)
(cid:6)

(cid:7)
(cid:5)
(cid:6)

V
c

(cid:4)
(cid:2)
(cid:3)

2

t
t

(cid:4)
(cid:2)
(cid:2)
(cid:3)

.  During  the  process 

of  acceleration  a  proton  may  loose  most  of  its 
energy  by  a  nuclear  collision.  This  absorption 
process can be considered to proceed according to 
an exponential law. We expect the age distribution 

to  be

( )
tE

,  where  T  is  the  time 

collisions.  Combining 
between 
relationships  between  age  and  energy  with  the 
the 
probability  distribution  of  age,  we  find 

=

-

(cid:7)
(cid:4)
t
(cid:5)
(cid:2)
exp
(cid:6)
(cid:3)
T
absorption 

probability 

of 

the 

energy: 

distribution 
(cid:7)
c
(cid:5)
V
(cid:6)

(cid:4)
(cid:2)
(cid:3)

2

 

t
1
--
TE

(
Ep

)

(cid:181)

Renormalization group 
Near critical temperature, Tc, of a second order phase 
transitions  physical  parameters  of  the  system  are 
power-law  functions  of  the  reduced  temperature, 

.  In  1971  Wilson  [25]  developed  the 

t

=

TT
-
c
T
c

renormalization  group  (RG)  method  to  explain  this 
phenomenon.  He  studied  how  parameters  of  the 
system  change  after  n  successive  re-scalings  of  the 
length  by  a  factor  l.  He  found  that  the  reduced 
temperature 
n: 
n
=)(

.  At  the  same  time  correlation  length 

exponentially  with 

grows 

t

n

y

t

(
l

) t

x

n

l -=)(

n
x

.  As  a 
decreases  exponentially  with  n: 
result  the  correlation  length  scales  with  the  reduced 
t
.  Similar  to  what 
temperature  as: 
happened  in  Yule’s  model,  the  power  law  came  out 
of two exponential dependencies. 

1-(cid:181)x

( )
t

ty

Bradford’s law 
Bradford Law states that the distribution of scientific 
journals  by  the  number  of  articles,  they  contain, 
law.  In  1970  Naranan  [26] 
follows  a  power 
considered  the  model  where  both  the  number  of 
journals  and  the  size  of  each  journal  increase 
exponentially  with  time.  He  obtained  an  equation 
identical to Eq. (3) with g and s being growth rates of 
the  number  of  journals  and  number  of  articles  in  a 
journal  respectively.  This  very  mechanism  was 
rediscovered in 1999 by Huberman and Adamic [28] 
in  the  context  of  distribution  of  websites  by  the 
amount  of  webpages 
  Both 
aforementioned reinventions ([26], [27]) appeared in 
the same journal (Nature), were the original paper by 
Willis and Yule [1] was published 
 
 In  his  first  paper  on  this  topic  [26]  Naranan 
mentioned  the  1949  paper  by  Fermi  [24]  as  the 
source  of  the  idea.  Later  he  found  [27]  that  that  the 
original  idea  was  older  and  that  it  was  several  times 

contain. 

they 

 

6 

re-invented.   He gave a list of related papers, from 
which we benefited in writing this article.  

Monkey-typed text 
In  1957  Miller  [29]  had  explained  Zipf’s  law  in 
word frequencies as follows. A monkey, sitting at 
a  typewriter,  is  randomly  hitting  its  keys.  The 
resulting  discourse  is  a  random  sequence  of 
independent symbols: the letters and the space that 
mark the boundaries between words. There are  M 
letters. The probabilities of all letters and of space 
are equal 1/(M+1). If a word contains m letters, the 
probability  for  it  to  be  printed  by  a  monkey  is 
Mm/(M+1)m+1. The number of m-letter words is Mm. 
Now m plays again the role of t in Yule’s problem. 
Thus  we  get  a  power  law  distribution  with 

exponent

1
+=g

ln

(
(
MM
(
M
ln

+
)

)
)
1

2
-=

ln

(
ln

)
1
M
+
)M
(

. 

law 

 
This explanation was rediscovered in 1992 
by Li [30]. By the way, Li credited Miller for the 
idea,  citing  his  Introduction  to  the  book  by  Zipf 
[10], where Miller wrote that typing monkeys will 
produce  Zipf’s 
law,  but  did  not  give  a 
mathematical  proof.    Apparently,  Li  decided  that 
Miller never produced that proof. 
A  more  interesting  thing  is  that  Miller’s 
 
explanation of Zipf’s law was a re-invention of the 
explanation proposed by Mandelbrot back in 1953 
from 
[31].  Mandelbrot  derived  Zipf’s 
optimization  criteria.  He  considered  a  word-by-
word coding of a text using q elementary symbols, 
one of which is used as a separator between words. 
He  asked  a  question  what  distribution  of  word 
frequencies  will 
to  maxim  Shannon 
information  per  symbol  of  encoded  text.  After 
some algebra he found that this distribution should 
be  Zipfian.  Now  note  that  maximum  Shannon 
entropy is achieved when the sequence of symbols 
is  completely  random.  We  see  that  Miller  just 
solved  the  Mandelbrot’s  problem  by  another 
method  (a  simpler  one).  Mandelbrot  understood 
that  these  two  explanations  of  Zipf’s  Law  are 
identical  (see  [32]),  but  some  authors,  who  wrote 
on the issue lately, don’t. 

lead 

Psychophysical law 
Perceived intensity varies with physical intensity as a 
power  law  [33].  For  example,  for  brightness  the 
exponent  is  about  1/3.    This  behavior  is  puzzling 
since  frequency  of  nerve  impulses  from  sensory 
receptors  is  related  logarithmically  to  intensity  of 
stimulations.  In  1963  MacKay  [34]  proposed  the 
matched response model, which can resolve apparent 
paradox. In his model perception is adaptive response 
to  stimulation.  Perceived  intensity  of  a  stimulus 
reflects  not  the  frequency  of  impulses  from  receptor 
organ,  but  the  magnitude  of  internal  activity  evoked 
to  match  or  counterbalance  that  frequency.  MacKay 
proposed  that  frequency  of  matching  impulses  is 
logarithmically  related  to  the  magnitude  of  internal 
activity.    In  such  case  both  perceived  intensity  and 
physical 
the 
frequency of nerve impulses and we get a power law 
relation  between  them,  similarly  how  we  get  it  in 
Yule’s model. 

intensity  depend  exponentially  on 

The Science of Networks 
In 1999 in order to explain the power-law distribution 
of  connectivity  in  the  World  Wide  Web  [35]  and 
other networks Barabasi and Albert [16] proposed the 
following  model.  Starting  with  a  small  number  of 
nodes, at every time step we add a new node and link 
it  to  one  of  the  nodes  already  present  in  the  system. 
When  choosing  the  nodes  to  which  the  new  node 
connects, we assume that the probability pi that a new 
node will be connected to node i is proportional to its 
degree ki . With the substitution node = distinct word 
and degree = number of occurrences Barabasi-Albert 
model  reduces  to  Simon’s  model  with  a=1/2. This 
was pointed out in [36]. 

that  many  families 

Galton-Watson processes 
In  the  19th  century  some  British  gentlemen  had 
noticed 
that  had  occupied 
conspicuous positions in the past became  extinct. At 
first  they  concluded  that  increase  in  intellectual 
capacity  is  accompanied  by  a  decrease  in  fertility.  
However, in 1875 Watson and Galton [37] developed 
the theory of branching processes, which showed that 
a  large  proportion  of  families  (or  surnames)  should 
become  extinct  by  the  ordinary  law  of  chances.  The 

 

7 

( )1p

( )0p

Branching 

mathematical model considered was   that in each 
 per  cent  of  the  adult  males  have 
generation 
no sons, 
  have one son and so on. The model 
can  be  solved  using  method  of  generating 
functions  and  apart  from 
the  probability  of 
extinction one can derive the exact formula for the 
probability  distribution  of  total  offspring  (i.e.  the 
sum  of  the  numbers  of  sons,  grandsons,  grand-
grandsons  and  so  on).  In  the  case  when  the 
average number of sons per adult male equals one, 
this turns out to be a power law with exponent 3/2.   
One  can  also  compute  an  approximate  expression 
for 
the  probability  distribution  of  surname 
frequencies in a given generation. This turns out to 
be a power law with exponent 1.  
processes  were  re-discovered  in  genetics  (replace 
surname  with  gene),  chemical  chain  reactions, 
nuclear chain reactions, cosmic rays (see the book 
by Harris [38]) and most recently in sandpiles [39]. 
 
Galton-Watson process is similar to Yule’s 
process.    If  we  apply  Yule’s  model  to  find 
distribution  of  species  by  number  of  individuals 
than  “specie”  will  be  replaced  with  “individual” 
and “genus” with “specie”. Specific mutation will 
correspond to a birth without mutation and generic 
mutation  to  specific  mutation.  These  are  only 
verbal  changes,  which  do  not  affect  math.  Now 
remember  that,  unlike  species,  individuals  are 
mortal.  We  will  have  to  adjust  Yule’s  model  for 
that,  and  it  will  transform  it  into  Galton-Watson 
model. 
 
The scientists will appreciate the following 
illustration of the connection between Yule-Simon 
and  Galton-Watson  processes.  A  model  where, 
when scientist is writing a manuscript, he picks up 
few  random  papers,  cites  them,  and  also  copies  a 
fraction  of  their  references  leads  to  Yule-Simon 
process.  A  modification  of  that  model:  when 
scientist  is  writing  a  manuscript,  he  picks  up  few 
random recent papers, cites them, and also copies 
a  fraction  of  their  references  leads  to  Galton-
Watson  process.  The  only  difference  between  the 
two models is the word recent.  See Ref. [40] for 
details. 

The Science of Self-Organized Criticality 
In  its  mean-field  version  Self  Organized  Criticality 
(SOC)  can  be  described  as  a  Galton-Watson 
branching  process  [41],  [42].  Here  the  sand  grains, 
which  are  moved  after  the  original  toppling,  are 
equivalent  to  sons.  This  moved  grains  can  cause 
further  toppling,  resulting  in  the  motion  of  more 
grains, which are equivalent to grandsons, and so on. 
The total number of displaced grains is the size of the 
avalanche  and  is  equivalent  to  total  offspring  in  the 
case  of  a  branching  process.  Size  distribution  of 
offspring  is  equivalent  to  distribution  of  avalanches 
in SOC. To be fair SOC is not completely reduced to 
a  critical  branching  process:  it  has  a  built  in 
dissipative  mechanism  (sand  grains  fall  from  the 
edges),  which  tunes  the  branching  process  into  a 
critical state.  

Genetic model of Moran 
A  model  of  the  evolution  of  a  gene  pool  can  be 
formulated  by  replacing  “surname”  with  “gene”  in 
Galton-Watson  model.  Unfortunately,  this  model  is 
not  exactly  soluble.  However,  a  modification  of  the 
model, suggested in 1962 by Moran [43] and further 
studied  by  Karlin  and  McGregor  [44],  is  exactly 
soluble. In this model genes die one by one at random 
and are replaced with new genes.  
 
The  exact  model  we  consider  is  as  follows. 
There is a gene pool of fixed but large size. At each 
step  one  selected  at  random  gene  dies.  We  select 
from  the  pool  a  random  gene  and  add  to  the  pool  a 
gene  of  the  same  type.  With  the  probability  a the 
 
added gene can mutate.  
 
Moran’s model can be reformulated in verbal 
terms.  Consider  a  string  of  words  of  large  but  fixed 
length  N.  At  each  step  we  delete  one  randomly 
selected  word  and  add  one  word  according  to  the 
rules  of  Simon’s  model.  (With  probability a  it  is  a 
new  word.  With  probability  1-a  it  is  one  of  the  old 
words. The probability that it is a particular old word 
is  proportional 
its  previous 
occurrences.) 
 
 
Equilibrium  word  frequencies  should  satisfy  the 
KN  denotes  the  number  of 
following  equations  (here
words that appeared K times): 

the  number  of 

to 

 

8 

N
1
N

+

2

N
N

N
1
N

2

(
1
--

)
a

·

+

a

=

0

                (27a) 

-

 

-

NK
·
N

(

K

K

+

)1
·+
N

N

K

1
+

-

(
1

-

)
a

·

(
1

-

)
a

·

+

K

NK
·
N
)1
·-
N

K

(

N

K

1
-

=

0

 

( >K

)1

 

(27b) 

N1
N
N
2
N

 

 

 

1N note  that  the  rate  of  creation  of  new 
To  find 
words  is a. At  the  same  time  the  rate  of  loss  of 
N1 :  clearly,  a  word  gets  extinct 
N

distinct  words  is 

when  a  word  which  occurs  only  once  is  selected 

for  deletion.  It  follows  that

a=

.  Substituting 

=

)
(
1
aa -
2

,  and, 

.  In  general,  it  can  be 

this  in  Eq.(27a),  we  get 

2

=

similarly,

(
)
1
aa -
3

N
3
N
verified by induction that 
N
K
N

(
)
1
-
aa
K

.  

=

1
-

 

K

 

 

 

(28) 

(29) 

(30) 

The  probability  that  the  word  occurs  K  times  is 
equal to,  

where  D  is  the  number  of  distinct  words  in  the 
string. The latter can be computed as  

P
K =

N
K
D

, 

D

=

KN

 

¥

(cid:12)

1K
=

 

 

 

 

 

 

 

. 

=

P
K

(
1 -
(
1ln

After  substituting  Eq.(28)  in  Eq.(30),  and  the 
result into Eq.(29) we get: 
K
)
a
)K
a
frequency  distribution 
The  word 
hyperbolic law with an exponential cut-off.  
 
A  small  modification  of  Moran’s  model  makes  it 
very similar to Simon’s model. The rules of word 
addition remain the same. The rule of deletion will 
follows.  The  deletion  happens  with 
be  as 

follows  a 

(31) 

probability a. We select a random distinct word (the 
probability  is  equal  for  all  distinct  words  in  the 
sequence  and  does  not  depend  on  the  number  of 
occurrence  of 
the  word).  Than  we  delete  all 
occurrences  of  this  word  from  the  sequence.  With 
these  new  rules  the  equilibrium  equations  (27)  will 
change only slightly. Third and fourth terms will not 
change,  as  the  rules  of  addition  didn’t  change.  
Second  term  will  disappear,  because  if  a  word  is 
deleted  than  all  its  occurrences  are  deleted,  it  does 
1-KN  category,  like  it  was 
not  just  move  from 
term  will 
in 

previous  model.  The 

KN to 

first 

N Ka-
D

become

,  where  D  is  the  number  of  distinct 

words  in  the  sequence.  To  compute  D  note  that  the 
average number of occurrences of a word is N/D.  In 
equilibrium the rate of addition must be equal to the 
rate of deletion. Therefore aN/D=1, or
. The 
N K , and Eq.(27) transform into: 
N

first term becomes

D a=
N

-

 

-

N
1
N

N
K
N

(
1
--

)
a

·

+

a

=

0

, 

N
1
N

(
1
-+

)
a

·

(

K

)1
·-
N

N

K

1
-

-

(
1

-

)
a

·

NK
·
N

K

=

0

 

   

( >K

)1

 

 (32) 

The  above  equations  are  identical  to  Eq.  (12)  and 
therefore have the same solution, Eq.(15).  Although 
the  above  model  has  the  same  solution  as  standard 
Simon’s  model,  it  is  not  identical  to  it.  In  the  latter 
words  are  added  but  not  deleted  and  the  number  of 
words in the sequence is growing. In the above model 
words are both added and deleted and the number of 
words  in  the  sequence  is  constant.  This  model  was 
formulated and solved by Simon in [11]. 

Cumulative advantage and Bose-Einstein 
statistics 
In Simon’s model the probability that a new word is a 
word  that  has  already  appeared  exactly  N  times  is 
proportional to N. This resembles the transition rules 
for  particles  obeying  Bose-Einstein  statistics.  For 
such  particles  the  probability  to  move  to  certain 

 

9 

quantum  level  is  proportional  to  the  number  of 
particles  already  sitting  on  that  level.  This  was 
first  pointed  out  in  1974  by  Hill  [21]  and  further 
discussed  by  Ijiri  and  Simon  (see  the  Chapter 
"Some distributions associated with Bose-Einstein 
statistics" in Ref. [22]). This link was rediscovered 
in 2001 by Bianconi and Barabasi [23]. 

Re-inventing Willis 
We  summarized  the  re-inventions,  described  in 
this  paper,  in  Table  1.  We  treat  Simon’s  and 
Yule’s  models  as  different  things,  because  they 
 

use  different  mathematical  approaches  (alternative 
ways  to  America).  We  count  it  as  a  re-discovery 
when  the  same  America  is  discovered  in  the  same 
way.  Even  with  this  restriction  almost  everything 
appears to be re-discovered twice.  
 
We conclude that re-discovering America is the most 
common  scientific  occupation,  both  in  this  country 
and abroad:  the scientists are busy with it two thirds 
of time. 
 

Table 1. Re-inventing Willis. 

Phenomenon 
Yule’s process 

Discovered 
Yule (1925) 

Simon’s process 
Champernowne’s 
process 
Power 
word frequencies 
Power 
scientific citing 

law 

law 

of 

Fermi (1949) 

Huberman and Adamic (1999) 

Re-discovered 

Simon (1955) 
Champernowne  
(1953) 
Estoup (before 1916)  Condon (1928) 

Günter et al (1992) 
Levy and Solomon (1996) 

Barabasi and Albert (1999) 
 

Zipf (1935) 

of 

Price (1965) 

Silagadze (1997) 

Redner (1998) 

 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 

  

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

10 

 
1.  J.C. Willis and G.U. Yule, “Some statistics of 
evolution and geographical distribution in 
plants and animals, and their significance”, 
Nature, 109, 177 (1922).  

2.  J.C. Willis, Age and area: a study in 

geographical distribution and origin of species 
(University press, Cambridge, 1922). 
3.  G.U. Yule, “A mathematical theory of 

evolution, based on the conclusions of Dr. J.C. 
Willis, F.R.S.”, Philosophical Transactions of 
the Royal Society of London B, 213, 21 
(1925). 

4.  R. Günter, B. Schapiro, and P. Wagner, 
“Physical complexity and Zipf’s law”, 
International Journal of Theoretical Physics 31, 
524 (1992); R. Günter, L. Levitin, B. Schapiro, 
and P. Wagner, “Zipf’s law and the effect of 
ranking on probability distributions”, 
International Journal of Theoretical Physics 35, 
395 (1996). 

5.  P. L.  Krapivsky and S. Redner, “Organization 
of growing random networks”, Phys. Rev. E, 
63, 066123 (2001). 

6.  D.G. Champernowne, “A model of income 
distribution”, Economic Journal 63, 318 
(1953). 

7.  M. Levy and S. Solomon, “Dynamical 

Explanation for the Emergence of Power Law 
in a Stock Market Model”, Int. J.  Mod. Phys.  
C, 7, 65 (1996); M. Levy and S. Solomon, 
“Power laws are logarithmic Boltzmann laws”, 
Int. J.  Mod. Phys.  C, 7, 595 (1996), 
http://www.arxiv.org/abs/adap-org/9607001 
8.  Estoup, J.B., Gammes sténographique, 1916 

(as cited in Ref. [32]). See also: 
http://torvald.aksis.uib.no/corpora/2002-
2/0070.html 

9.  E.U. Condon, “Statistics of vocabulary”, 

Science, 67, 300 (1928). 

10. G.K. Zipf, The psycho-biology of language 
(MIT Press, Cambridge, 1965). This is a re-
issue of the book originally published in 1935. 
11. H.A. Simon, “On a class of skew distribution 
functions”, Biometrika, 42, 425 (1955). 

12. D. de S. Price, "A general theory of bibliometric 

and other cumulative advantage process", Journal 
of American Society for Information Science, 27, 
292 (1976). 

13. D. de S. Price, "Networks of Scientific Papers", 

Science, 149, 510 (1965). 

14. Silagadze, Z.K., “Citations and Zipf-Mandelbrot 

law”, Complex Syst. 11, 487 (1997). 

15. Redner, S., “How popular is your paper? An 

empirical study of citation distribution”, cond-
mat/9804163; Eur. Phys. J. B 4, 131 (1998). 
16. Barabasi, A.-L. and R. Albert, “Emergence of 

scaling in random networks”, Science, 286, 509 
(1999). 

17. S.N. Dorogovtsev and J.F.F. Mendes, “Evolution 
of networks”, Advances in Physics, 51, 1079 
(2002). (see the chapter “accelerated growth of 
networks” ) 

18. A.A. Markov “Extension of the law of large 

numbers to dependent variables” in A.A. Markov, 
Selected Works, (Izdatel’stvo Akademii Nauk 
SSSR, Moscow, 1951)  (in Russian). (The 
original paper was published in 1907 in an 
obscure journal.) The ball problem is discussed 
on pp.351-354. 

19. N.L. Johnson and S. Kotz, Urn Models and their 
Application, (John Wiley, New York, 1977). 

20. F. Chung, S. Handjani, and D. Jungreis,  

“Generalizations of Polya's urn Problem”, Annals 
of Combinatorics 7 (2003) 141-153. 

21. B.M. Hill “Zipf’s law and prior distributions for 
the composition of a population”, Journal of 
American Statistical Association, 65, 1220 
(1970); B.M. Hill “The rank-frequency form of 
Zipf’s law”, Journal of American Statistical 
Association, 69, 1017 (1974). 

22. Y. Ijiri and H.A. Simon "Skew distributions and 
the size of business firms" (North-Holland, 
Amsterdam, 1977) 

23. G. Bianconi and A.-L. Barabási, “Bose-Einstein 
condensation in complex networks”, Phys. Rev. 
Lett. 86, 5632 (2001). 

24. E. Fermi, “On the origin of the cosmic radiation”, 

Phys. Rev. 75, 1169 (1949). 

25. K. G. Wilson, Phys. Rev. B 4, 3174 (1971) (for 
simpler explanation see Chapt. 9.4 of N.D. 

 

11 

http://www.mugu.com/galton/essays/1870-
1879/galton-1874-jaigi-family-extinction.pdf 
38. T.E. Harris, “The theory of branching processes” 

(Springer, Berlin, 1963) 

39. P. Bak, How Nature Works: the Science of Self-
Organized Criticality (Copernicus, New York, 
1999) 

40. M.V. Simkin and  V.P. Roychowdhury, “A 

mathematical theory of citing”, 
http://arxiv.org/abs/physics/0504094 
41. P. Alstrøm “Mean-field exponents for self-

organized critical phenomena”, Phys. Rev. A 38, 
4905–4906 (1988) 

42. K. B. Lauritsen, S. Zapperi, and H. E. Stanley, 

“Self-organized branching processes: Avalanche 
models with dissipation”, Phys. Rev. E 54, 2483–
2488 (1996). 

43. P.A.P. Moran, The statistical processes of 

evolutionary theory, (Clarendon, Oxford, 1962) 

44. S. Karlin and J. McGregor, “The number of 
mutant forms maintained in a population”, in 
Proceedings of the Fifth Berkeley Symposium on 
Mathematical Statistics and Probability, vol.4, pp 
415-438 (University of California Press, Berkeley, 
1967) 

 
 

Goldenfeld, Lectures on Phase Transitions 
and the Renormalization Group (Addison-
Wesley, 1992)). 

26. S. Naranan, “Bradfords’s law of bibliography 

of science: an interpretation”, Nature, 227, 631 
(1970). 

27. S. Naranan, “Power law relations in science 

bibliography – a self-consistent interpretation”, 
Journal of Documentation, 27, 83 (1971). 
28. B.A. Huberman and L. Adamic, “Growth 

dynamics of the World-Wide Web”, Nature, 
401, 131 (1999). 

29. G. A Miller. “Some effects of intermittent 
silence”, American Journal of Psychology, 
70:311-314, 1957. 

30. W. Li, “Random texts exhibit Zipf’s-law-like 

word frequency distribution”, IEEE 
Transactions on Information Theory, 38 (1992) 
1842. 

31. B. Mandelbrot, “An informational theory of 
the statistical structure of languages”, in 
Communication Theory, edited by W. Jackson 
(Academic Press, New York, 1953). 
32. B. Mandelbrot, “Information theory and 
Psycholinguistic: a theory of word 
frequencies” in Readings in mathematical 
social science, ed. P.F. Lazarsfeld and N.W. 
Henry (Science Research Associates, Chicago, 
1966) 

33. S.S. Stevens, “Neural events and the 

psychophysical law”, Science, vol. 170, pp 
1043-1055 (1970). 

34. D.M. MacKay, “Psychophysics of perceived 

intensity: a theoretical basis for Fechner’s and 
Stevens’ laws”, Science, vol. 139, pp1213-
1216 (1963). 

35. R. Albert, H. Jeong, and A.-L. Barabasi, 

“Diameter of the world-wide web”, Nature, 
401, 130 (1999). 

36. S. Bornholdt and H. Ebel, “World Wide Web 
scaling exponent from Simon's 1955 model”, 
Phys. Rev. E 64, 035104 (2001). 
37. H. W. Watson and F. Galton, “On the 

probability of the extinction of families”, 
Journal of the Anthropological Institute 4, 138 
(1875). Available online at:               

 

12 

