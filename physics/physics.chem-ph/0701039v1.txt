7
0
0
2
 
n
a
J
 
3
 
 
]
h
p
-
m
e
h
c
.
s
c
i
s
y
h
p
[
 
 
1
v
9
3
0
1
0
7
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Optimization of quantum Monte Carlo wave functions by energy minimization

Julien Toulouse∗
Cornell Theory Center, Cornell University, Ithaca, New York 14853, USA.

C. J. Umrigar†
Cornell Theory Center and Laboratory of Atomic and Solid State Physics,
Cornell University, Ithaca, New York 14853, USA.
(Dated: February 20, 2014)

We study three wave function optimization methods based on energy minimization in a variational
Monte Carlo framework: the Newton, linear and perturbative methods. In the Newton method, the
parameter variations are calculated from the energy gradient and Hessian, using a reduced variance
statistical estimator for the latter.
In the linear method, the parameter variations are found by
diagonalizing a non-symmetric estimator of the Hamiltonian matrix in the space spanned by the
wave function and its derivatives with respect to the parameters, making use of a strong zero-variance
principle. In the less computationally expensive perturbative method, the parameter variations are
calculated by approximately solving the generalized eigenvalue equation of the linear method by a
nonorthogonal perturbation theory. These general methods are illustrated here by the optimization
of wave functions consisting of a Jastrow factor multiplied by an expansion in conﬁguration state
functions (CSFs) for the C2 molecule, including both valence and core electrons in the calculation.
The Newton and linear methods are very eﬃcient for the optimization of the Jastrow, CSF and
orbital parameters. The perturbative method is a good alternative for the optimization of just the
CSF and orbital parameters. Although the optimization is performed at the variational Monte Carlo
level, we observe for the C2 molecule studied here, and for other systems we have studied, that as
more parameters in the trial wave functions are optimized, the diﬀusion Monte Carlo total energy
improves monotonically, implying that the nodal hypersurface also improves monotonically.

I.

INTRODUCTION

Quantum Monte Carlo (QMC) methods (see e.g.
Refs. 1–3) constitute an alternative to standard ab ini-
tio methods of quantum chemistry for accurate calcula-
tions of the electronic structure of atoms, molecules and
solids. The two most commonly used variants, varia-
tional Monte Carlo (VMC) and diﬀusion Monte Carlo
(DMC), rely on an explicitly-correlated trial wave func-
tion, generally consisting for atoms and molecules of a
Jastrow factor multiplied by a short expansion in conﬁg-
uration state functions (CSFs), each consisting of a linear
combination of Slater determinants, a form capable of en-
compassing most of the electron correlation eﬀects. To
fully beneﬁt from the considerable ﬂexibility in the form
of the wave function, it is crucial to be able to eﬃciently
optimize the parameters in these wave functions.

Variance minimization in correlated sampling [4–6] has
become the most frequently used method in QMC for
optimizing wave functions because it is far more eﬃ-
cient than straightforward energy minimization on a ﬁ-
nite Monte Carlo sample. However, while the method
works relatively well for the optimization of the Jastrow
factor, it is much less eﬀective for the optimization of
the determinantal part of the wave function (though still
possible [4, 7, 8]). Further, there is some evidence that
energy-optimized wave functions give on average better

∗Electronic address: toulouse@tc.cornell.edu
†Electronic address: cyrus@tc.cornell.edu

expectation values for other observables than variance-
optimized ones (see, e.g., Refs. 9, 10). As a result, a lot
of eﬀort has recently been devoted to developing eﬃcient
methods for the optimization of QMC wave functions by
energy minimization. On the other hand, it should be
mentioned that variance-minimized wave functions often
have a smaller time-step error in DMC.

We now summarize some of the major approaches that
have been proposed for energy minimization in VMC.
The most eﬃcient method to minimize the energy with
respect to linear parameters, such as the CSF coeﬃcients,
is to solve the associated generalized eigenvalue equa-
tion using a non-symmetric estimator of the Hamilto-
nian matrix [11]. The energy ﬂuctuation potential (EFP)
method [12–16] is very eﬃcient for optimizing some non-
linear parameters and has been applied very successfully
to the optimization of the orbitals [13, 16] and CSF co-
eﬃcients [15, 16]. It has also been applied to the opti-
mization of Jastrow factors in periodic solids [14]. The
perturbative EFP method, a simpliﬁcation of the EFP
method, retains the same convergence rate for the opti-
mization of the orbitals and CSF coeﬃcients while de-
creasing the computational cost [17]. The stochastic re-
conﬁguration (SR) method, originally developed for lat-
tice systems [18], has been applied to the full optimiza-
tion of atomic and molecular wave functions consisting
of an antisymmetrized geminal power part multiplied by
a Jastrow factor [19, 20]. It is related to the perturbative
EFP method and is simpler but less eﬃcient [16, 17]. The
Newton method is a conceptually simple and general op-
timization method but a straightforward implementation
of it in QMC is rather ineﬃcient [21, 22]. However, an

improved version of it, making use of a reduced variance
estimator of the Hessian matrix [23], is very eﬃcient for
the optimization of Jastrow factors. Another modiﬁed
version of the Newton method with an approximate Hes-
sian, named stochastic reconﬁguration with Hessian ac-
celeration (SRH), has been applied to lattice models [24].

In this work, we investigate the three best energy min-
imization methods for the optimization of the Jastrow,
CSF and orbital parameters of QMC wave functions: the
Newton, linear and perturbative methods. The New-
ton method has already been applied very successfully
to the optimization of Jastrow factors by Umrigar and
Filippi [23], and in this paper it is also applied to the opti-
mization of the determinantal part of the wave function.
The linear method is an extension of the zero-variance
generalized eigenvalue equation approach of Nightingale
and Melik-Alaverdian [11] to arbitrary nonlinear param-
eters: at each step of the iterative procedure, the wave
function is linearized with respect to the parameters and
the optimal values of the parameters are found by diago-
nalizing the Hamiltonian in the space spanned by the cur-
rent wave function and its derivatives with respect to the
parameters. This method is brieﬂy presented in Ref. 25.
The perturbative method coincides with the perturbative
EFP method of Scemama and Filippi [17] for the opti-
mization of the CSF and orbital parameters. Here, we
put this approach on more general grounds by recasting
it as a simpliﬁcation of the linear method where the gen-
eralized eigenvalue equation is solved approximately by
a nonorthogonal perturbation theory. The Newton and
linear methods are very eﬃcient for the optimization of
the Jastrow, CSF and orbital parameters. The perturba-
tive method is a good alternative for the optimization of
just the CSF and orbital parameters.

The paper is organized as follows.

In Sec. II, the
parametrization of the trial wave function is presented.
The energy minimization procedures are discussed in
Sec. III, and their realizations in VMC are discussed in
Sec IV. Sec. V contains computational details of the cal-
culations performed on the C2 molecule to test the opti-
mization methods, and in Sec. VI we present the results.
Sec. VII contains our conclusions.

Hartree atomic units (Ha) are used throughout this

work.

II. WAVE FUNCTION PARAMETRIZATION
AND DERIVATIVES

We begin by describing the form of the wave function
used, the actual parametrization chosen for the optimiza-
tion and the corresponding derivatives of the wave func-
tion with respect to the parameters.

2

A. Form of the wave function

We use an N -electron wave function of the usual
Jastrow-Slater form that is denoted at each iteration of
the optimization procedure by

|Ψ0i = ˆJ(α0)|Φ0i,

(1)

where ˆJ(α0) is a Jastrow operator depending on the cur-
rent parameters α0
i and |Φ0i is a multi-determinantal
wave function. For notational convenience, we assume
that the wave function |Ψ0i is always normalized to unity,
i.e. hΨ0|Ψ0i = 1. In practice, |Ψ0i can have arbitrary
normalization.

The wave function |Φ0i is a linear combination of NCSF
orthonormal conﬁguration state functions (CSFs), |CI i,
with current coeﬃcients c0
I ,

|Φ0i =

c0
I |CI i.

(2)

NCSF

I=1
X

P

k dI,k|D↑

ki, |CI i =

Each CSF is a short linear combination of products of
spin-up and spin-down Slater determinants, |D↑
ki and
ki|D↓
|D↓
ki, where the coeﬃcients
dI,k are fully determined by the spatial and spin sym-
metries of the state considered (see, e.g., Ref. 26).
The use of CSFs is important to decrease the num-
ber of coeﬃcients to be optimized and to ensure the
correct symmetry of the wave function after optimiza-
tion in the presence of statistical noise.
The N↑-
electron and N↓-electron spin-assigned Slater determi-
nants are generated from a set of current orthonormal
k1↑ˆa†
k2↑ · · · ˆa†
ki =
orbitals,
ˆa†
kN ↓|vaci, where ˆa†
kN↑+1↓ˆa†
k σ (with σ =↑, ↓)
is the fermionic creation operator for the spatial orbital
|φ0
ki in the spin-σ determinant, and |vaci is the vacuum
state of second quantization. The (occupied and virtual)
spatial orbitals are written as linear combinations of Nbas
basis functions |χµi (e.g., Slater or Gaussian functions)
k,µ, |φ0
with current coeﬃcients λ0
The N -electron Jastrow operator, ˆJ(α0), is deﬁned
by its matrix elements in the N -electron position basis
|Ri = |r1, r2, ..., rN i

|D↑
ki = ˆa†
kN↑+2↓ · · · ˆa†

kN↑ ↑|vaci and |D↓

Nbas
µ=1 λ0

k,µ|χµi.

ki =

P

hR| ˆJ(α0)|R′i = J(α0; R)δ(R − R′),

(3)

where J(α0; R) is the spin-assigned Jastrow factor, a real
positive function of R which is symmetric under the ex-
change of two same-spin electrons. Its action on an ar-
bitrary N -electron state |Φi is given by hR| ˆJ(α0)|Φi =
J(α0; R)Φ(R) where Φ(R) = hR|Φi. The Jastrow oper-
ator is Hermitian, ˆJ(α0)† = ˆJ(α0). We use ﬂexible Jas-
trow factors consisting of the exponential of the sum of
electron-nucleus, electron-electron and electron-electron-
nucleus terms, written as systematic polynomial or Pad´e
expansions [27] (see, also, Refs. 7, 28).

B. Wave function parametrization

We want to optimize the Jastrow parameters αi, the
CSF coeﬃcients cI and the orbital coeﬃcients λk,µ. Some
parameters in the Jastrow factor are ﬁxed by impos-
ing the electron-nucleus and electron-electron cusp con-
ditions [29] on the wave function; the other Jastrow
parameters are varied freely. Due to the arbitrariness
of the overall normalization of the wave function, only
NCSF − 1 CSF coeﬃcients need be varied, e.g., the coeﬃ-
cient of the ﬁrst conﬁguration can be kept ﬁxed. The
situation is more involved for the orbital coeﬃcients
which are not independent due to the invariance prop-
erties of determinants under elementary row operations.
To easily retain only unconstrained, non-redundant or-
it is convenient
bital parameters in the optimization,
to vary the orbital coeﬃcients by performing rotations
among the (occupied and virtual) orbitals with a uni-
tary operator parametrized as an exponential of an anti-
Hermitian operator. This parametrization is used in
multi-conﬁguration self-consistent-ﬁeld (MCSCF) calcu-
lations (for a recent and general review of MCSCF the-
ory, see Ref. 30). More speciﬁcally, we use the following
parametrization of the wave function depending on N opt
Jas
Jastrow parameters α, N opt
CSF = NCSF − 1 free CSF coef-
ﬁcients c (c1 is ﬁxed), and N opt
orb orbital rotation param-
eters κ

|Ψ(α, c, κ)i = ˆJ(α)eˆκ(κ)

cI |CI i,

(4)

NCSF

I=1
X

where eˆκ(κ) is the unitary operator that performs rota-
tions in orbital space (see, e.g., Refs. 31, 32). More elab-
orate parametrizations of the CSF coeﬃcients, such as a
unitary parametrization [33], are often used in MCSCF
theory (see, e.g., Ref. 32), but we have not found any
decisive advantage to using them for our purpose.

The rotations in orbital space are generated by the
anti-Hermitian real singlet orbital excitation opera-
tor [34]

ˆκ(κ) =

κkl ˆE−
kl,

k<l
X

(5)

k↑ˆal↑ + ˆa†

where the sum is over all non-redundant orbital pairs,
kl = ˆEkl − ˆElk, and ˆEkl = ˆa†
ˆE−
k↓ˆal↓ is the singlet
excitation operator from orbital l to orbital k. In Eq. (4),
the action of the operator eˆκ(κ) is to rotate each occupied
orbital in the Slater determinants as
|φki = eˆκ(κ)|φ0

)kl|φ0

(6)

(e

κ

ki =

l i,

l
X

where the sum is over all (occupied and virtual) or-
bitals, and (eκ)kl are the elements of the orthogonal
matrix eκ constructed from the real anti-symmetric ma-
trix κ with elements κkl. More generally, any unitary
matrix can be written as an exponential of an anti-
Hermitian matrix, the oﬀ-diagonal upper triangular part

3

of the anti-Hermitian matrix realizing a non-redundant
parametrization of the unitary matrix. To maintain the
orthonormality of the entire set of orbitals, the opera-
tor eˆκ(κ) is applied to the virtual orbitals as well. For
a single Slater determinant wave function, the orbitals
can be partitioned into three sets referred to as closed
(i.e., doubly occupied), open (i.e., singly occupied) and
virtual (i.e., unoccupied). The non-redundant excita-
tions to consider are then: closed → open, closed →
virtual and open → virtual. For a multi-conﬁguration
wave function, the orbitals can be partitioned into three
sets referred to as inactive (i.e., occupied in all determi-
nants), active (i.e., occupied in some determinants and
unoccupied in the others) and secondary (i.e., unoccu-
pied in all determinants). For a multi-conﬁguration com-
plete active space (CAS) wave function [35], the non-
redundant excitations are then: inactive → active, inac-
tive → secondary and active → secondary. For a single-
determinant and multi-determinant CAS wave function,
the action of the reverse excitation from orbital k to l
( ˆElk) in ˆE−
kl = ˆEkl − ˆElk is always zero. For a general
multi-conﬁguration wave function (not CAS), some ac-
tive → active excitations must also be included. Con-
sequently, the action of the reverse excitation ˆElk in
kl = ˆEkl − ˆElk does not generally vanish. Only ex-
ˆE−
citations between orbitals of the same spatial symmetry
have to be considered. In the super conﬁguration inter-
action approach [36] where the orbitals are optimized by
adding the single excitations of the (multi-conﬁguration)
reference wave function to the variational space, pio-
neered in QMC by Filippi and coworkers [16, 17], an
alternative linear parametrization of the orbital space is
|φ0
chosen, |φki =
ki, instead of the unitary
parametrization of Eq. (6). In that case, the optimized
orbitals are not orthonormal.

ˆ1 + ˆκ(κ)

(cid:1)

(cid:0)

In the following, we will collectively refer to the Jas-
trow, CSF and orbital parameters as p = (α, c, κ). The
wave function of Eq. (1) is thus simply |Ψ0i = |Ψ(p0)i
where p0 = (α0, c0, κ0 = 0) are the current parameters.
We will designate by N opt = N opt
Jas + N opt
orb the
total number of parameters to be optimized.

CSF + N opt

C. First-order wave function derivatives

We now give the expressions for the ﬁrst-order deriva-
tives of the wave function |Ψ(p)i of Eq. (4) with respect
to the parameters pi at p = p0

which collectively designate the derivatives with respect
to the Jastrow parameters

|Ψii =

∂|Ψ(p)i

(cid:18)

∂pi (cid:19)p=p0

,

|Ψαi i =

∂ ˆJ(α0)
∂αi

|Φ0i,

(7)

(8)

(9)

(10)

(11)

(12)

with respect to the CSF parameters

III. ENERGY MINIMIZATION PROCEDURES

|ΨcI i = ˆJ(α0)|CI i,

and with respect to the orbital parameters

In this section, we present the three methods inves-
tigated in this work to minimize the variational energy
with respect to the wave function parameters p

|Ψκkli = ˆJ(α0) ˆE−

kl|Φ0i.

E = min

E(p),

p

(17)

The ﬁrst-order orbital derivatives are thus generated by
the single excitations of orbitals out of the state |Φ0i.

D. Second-order wave function derivatives

The second-order derivatives with respect to the pa-
rameters pi at p = p0, which are needed only for the
Newton method, are

|Ψiji =

∂2|Ψ(p)i
∂pi∂pj (cid:19)p=p0

,

(cid:18)

which collectively designate the Jastrow-Jastrow deriva-
tives

the Jastrow-CSF derivatives

|Ψαiαj i =

∂2 ˆJ(α0)
∂αi∂αj

|Φ0i,

|ΨαicI i =

∂ ˆJ(α0)
∂αi

|CI i,

the Jastrow-orbital derivatives

|Ψαiκkl i =

∂ ˆJ(α0)
∂αi

ˆE−

kl|Φ0i,

(14)

the CSF-orbital derivatives

|ΨcI κkl i = ˆJ(α0) ˆE−

kl|CI i,

(15)

and the orbital-orbital derivatives

where E(p) = hΨ(p)| ˆH|Ψ(p)i/hΨ(p)|Ψ(p)i and ˆH =
ˆT + ˆWee + ˆVne is the electronic Hamiltonian,
includ-
ing the kinetic, electron-electron interaction and nuclei-
electron interaction terms. The Hamiltonian can also in-
clude a nonlocal pseudopotential, enabling one to avoid
the explicit treatment of core electrons. The energy cor-
responding to the current parameters p0 will be denoted
by E0 = E(p0).

A. Newton optimization method

The Newton method was ﬁrst applied to the opti-
mization of QMC wave functions by Rappe and cowork-
ers [21, 22]. It has been considerably improved by Umri-
gar and Filippi [23], and by Sorella [24], by making use of
a lower variance statistical estimator of the Hessian ma-
trix and by employing stabilization techniques. In Ref. 23
the correct Hessian was used, whereas in Ref. 24 an ap-
proximate Hessian, which reduces to the exact Hessian
for parameters that are linear in the exponent, was used.
We now recall the basic working equations.

The energy E(p) is expanded to second-order in the

(13)

parameters p around p0

E[2](p) = E0 +

gi∆pi +

hij∆pi∆pj,

N opt

i=1
X

1
2

N opt

N opt

i=1
X

j=1
X

where the sums are over all the parameters to be opti-
mized, ∆pi = pi − p0
i are the components of the vector
of parameter variations ∆p,

gi =

∂E(p)
∂pi (cid:19)p=p0

,

(cid:18)

hij =

∂2E(p)
∂pi∂pj (cid:19)p=p0

,

(cid:18)

|Ψκklκmn i = ˆJ(α0) ˆE−
kl

ˆE−

mn|Φ0i.

(16)

are the components of the energy gradient vector g, and

Notice that the wave function form of Eq. (4) is linear in
the CSF parameters and therefore the CSF-CSF deriva-
tives are zero, |ΨcI cJ i = 0. The orbital-orbital deriva-
tives correspond to double excitations of orbitals out of
the state |Φ0i. Since we usually start the optimization
with reasonably good initial orbitals coming from a stan-
dard MCSCF calculation we set these second derivatives
to zero, |Ψκklκmn i = 0, in order to reduce the compu-
tational cost per iteration during Newton minimization.
Nevertheless, it takes only a few steps to optimize the
orbitals as discussed in Sec. VI.

are the elements of the energy Hessian matrix h.
Im-
position of the stationarity condition on the expanded
energy expression, ∂E[2](p)/∂pi = 0, gives the following
standard solution for the parameter variations

∆p = −h−1 · g,

(21)

where h−1 is the inverse of the Hessian matrix. In prac-
tice, the energy gradient and Hessian are calculated in

4

(18)

(19)

(20)

VMC with the statistical estimators given in Sec. IV A,
yielding the parameter variations ∆p of Eq. (21) that
are used to update the current wave function, |Ψ0i →
|Ψ(p0 + ∆p)i. It simply remains to iterate until conver-
gence.

Stabilization. As explained in Ref. 23, the stabilization
of the Newton method is achieved by adding a positive
constant, adiag ≥ 0, to the diagonal of the Hessian matrix
h, i.e. hij → hij + adiagδij. As adiag is increased, the pa-
rameter variations ∆p become smaller and rotate from
the Newtonian direction to the steepest descent direction.
A good value of adiag is automatically determined at each
iteration by performing three very short Monte Carlo cal-
culations using correlated sampling with wave function
parameters obtained with three trial values of adiag, and
predicting by parabolic interpolation the value of adiag
that minimizes the energy [25], with some bounds im-
posed. The use of correlated sampling makes it possible
to calculate energy diﬀerences with much smaller statis-
tical error than the energies themselves. This procedure
helps convergence if one is far from the minimum or if the
statistical noise is large in the Monte Carlo evaluation of
the gradient and Hessian.

We have found that adding in a multiple of the unit
matrix to the Hessian as described above works well, but
there exist other possible choices of positive deﬁnite ma-
trices that could be added in. For instance, Sorella [24]
adds in a multiple of the overlap matrix of the ﬁrst-order
derivatives of the wave function. Another possible choice
is a multiple of the Levenberg-Marquardt approximation
to the Hessian of the variance of the local energy.

B. Linear optimization method

The most straightforward way to energy-optimize lin-
ear parameters in wave functions, such as the CSF pa-
rameters, is to diagonalize the Hamiltonian in the vari-
ational space that they deﬁne, leading to a generalized
eigenvalue equation. This has been done in QMC for ex-
ample in Refs. 11, 37. The linear method that we present
now is an extension of the approach of Ref. 11 to arbitrary
nonlinear parameters. This method is also presented in
Ref. 25, using slightly diﬀerent but equivalent conven-
tions.

For notational convenience, we ﬁrst introduce the nor-

malized wave function

|Ψ(p)i =

|Ψ(p)i
hΨ(p)|Ψ(p)i

.

(22)

The idea is then to expand this normalized wave func-
tion |Ψ(p)i to ﬁrst-order in the parameters p around the
current parameters p0,

p

|Ψlin(p)i = |Ψ0i +

∆pi |Ψii,

(23)

N opt

i=1
X

5

(25)

(26)

where the wave function at p = p0 is simply |Ψ(p0)i =
|Ψ0i = |Ψ0i (chosen to be normalized to 1) and, for i ≥ 1,
|Ψii are the derivatives of |Ψ(p)i that are orthogonal to
|Ψ0i

|Ψii =

∂|Ψ(p)i

(cid:18)

∂pi (cid:19)p=p0

= |Ψii − S0i |Ψ0i,

(24)

where S0i = hΨ0|Ψii. The minimization of the energy
calculated with this linear wave function

Elin = min

Elin(p),

p

where

Elin(p) =

hΨlin(p)| ˆH|Ψlin(p)i
hΨlin(p)|Ψlin(p)i

,

leads to the stationary condition of the associated La-
grange function

∇p

hΨlin(p)| ˆH|Ψlin(p)i − ElinhΨlin(p)|Ψlin(p)i
h
i

= 0,

(27)

where Elin acts as a Lagrange multiplier for the normal-
ization condition. The Lagrange function is quadratic in
p and Eq. (27) leads to the following generalized eigen-
value equation

H · ∆p = Elin S · ∆p,

(28)

where H is the matrix of the Hamiltonian ˆH in
the (N opt + 1)-dimensional basis consisting of
the
current normalized wave function and its derivatives
{|Ψ0i, |Ψ1i, |Ψ2i, · · · , |ΨN opt i}, with elements H ij =
hΨi| ˆH|Ψji, S is the overlap matrix of this (N opt + 1)-
dimensional basis, with elements Sij = hΨi|Ψji (note
that S00 = 1 and Si0 = S0i = 0 for i ≥ 1), and ∆p is
the (N opt+1)-dimensional vector of parameter variations
with ∆p0 = 1. The linear method consists of solving the
generalized eigenvalue equation of Eq. (28), for the lowest
(physically reasonable) eigenvalue and associated eigen-
vector denoted by ∆p. The overlap and (non-symmetric)
Hamiltonian matrices are computed in VMC using the
statistical estimators given in Sec. IV B. Although we
focus here on the optimization of the ground-state wave
function, solving Eq. (28) also gives upper bound esti-
mates of excited state energies of states with the same
spatial and spin symmetries.

However, there is an arbitrariness in the previously-
described procedure: we have found the parameter varia-
tions ∆p from the expansion of the wave function |Ψ(p)i
of Eq. (22), but another choice of the normalization of
the wave function will lead to diﬀerent parameter varia-
tions. To see that, consider a diﬀerently-normalized wave
function

|Ψ(p)i = N (p)|Ψ(p)i,

(29)

where the normalization function N (p) is chosen to sat-
isfy N (p0) = 1 so as to leave unchanged the normaliza-
tion at p = p0, i.e.
|Ψ(p0)i = |Ψ0i. The derivatives of
this new wave function are

|Ψii =

∂|Ψ(p)i

 

∂pi !p=p0

= |Ψii + Ni |Ψ0i,

(30)

where Ni = (∂N (p)/∂pi)p=p0, i.e. their projections onto
the current wave function |Ψ0i depend on the normaliza-
tion. Consequently, the ﬁrst-order expansion of this new
wave function

|Ψlin(p)i = |Ψ0i +

∆pi |Ψii,

(31)

N opt

i=1
X

leads, after optimization of the energy, to diﬀerent opti-
mal parameter variations ∆p. As the two wave functions
|Ψlin(p)i and |Ψlin(p)i lie in the same variational space,
they must be proportional after minimization of the en-
ergy, which implies that the new optimal parameter vari-
ations ∆p are actually related to the original optimal
parameter variations ∆p by a uniform rescaling

∆p =

1 −

∆p
N opt
i=1 Ni∆pi

.

(32)

P

Any choice of normalization does not necessarily give
good parameter variations. For the CSF parameters, it
is obvious that the best choice is the normalization of the
wave function of Eq. (4) in order to keep the linear de-
pendence on these parameters, ensuring convergence of
the linear method in a single step. This is achieved by
choosing |Ψii = |Ψii which gives

Ni = Si0,

for linear parameters.

(33)

For the nonlinear Jastrow and orbital parameters, several
criteria are possible. We have found that a good one is to
choose the normalization by imposing that, for the vari-
ation of the nonlinear parameters, each derivative |Ψii is
orthogonal to a linear combination of |Ψ0i and |Ψlini, i.e.
hΨi|ξΨ0 + (1 − ξ)Ψlin/||Ψlin||i = 0, where ξ is a constant
between 0 and 1, resulting in

Ni = −

(1 − ξ)

nonlin
j

∆pjSij

(1 − ξ) + ξ

P
1 +

nonlin
j,k ∆pj∆pkSjk

for nonlinear parameters,

q

P

,

(34)

where the sums are only over the nonlinear Jastrow and
orbital parameters. The simple choice ξ = 1 ﬁrst used by
Sorella [18] in the context of the SR method leads in many
cases to good parameter variations, but in some cases can
result in parameter variations that are too large. The
choice ξ = 0 making the norm of the linear wave function
change ||Ψlin − Ψ0|| minimum is safer but in some cases

6

can yield parameter variations that are too small.
In
those cases, the choice ξ = 1/2, imposing ||Ψlin|| = ||Ψ0||,
avoids both too large and too small parameter variations.
In particular, if ∆p = ∞, meaning that Ψlin is orthogo-
nal to Ψ0, it follows from Eqs. (32) and (34) that ∆p is
zero for ξ = 0 but ∆p is non-zero and ﬁnite for ξ = 1/2.
In practice, all these three choices for ξ usually lead to a
very rapid convergence of the nonlinear parameters. In
contrast, choosing the original derivatives, i.e. Ni = Si0,
leads to slowly-converging or diverging Jastrow parame-
ters.

Stabilization.
Similarly to the procedure used for the
Newton method, we stabilize the linear method by adding
a positive constant, adiag ≥ 0, to the diagonal of H except
for the ﬁrst element, i.e. H ij → H ij + adiagδij(1 − δi0).
Again, as adiag becomes larger, the parameter variations
∆p become smaller and rotate toward the steepest de-
scent direction. The value of adiag is then automatically
adjusted in the course of the optimization in the same
way as in the Newton method. Note that if instead we
were to add adiag to S
· H then it would be the “level-
shift” parameter commonly used in diagonalization pro-
cedures. We prefer to add to H, in part because it is not
· H in order to solve Eq. (28).
necessary to compute S

−1

−1

′

′

−1

· H,
−1

= S
N opt
k=0 (S

i.e.
)ikhΨk| ˆH|Ψji.

Connection to the EFP method.
The generalized
eigenvalue equation of Eq. (28) can be re-written
· ∆p = Elin∆p,
as an eigenvalue equation, H
where H
with matrix elements
′
H
form is
This
ij =
useful
to establish the connection with the EFP
optimization method for the CSF and orbital parame-
ters [13, 15, 16]. This latter approach consists of solving
at each iteration the eﬀective eigenvalue equation,
· ∆p = EEFP∆p, where the EFP eﬀective Hamil-
H
= hΦi| ˆH|Φiiδij +
tonian has matrix elements H

EFP
ij
)ikhΨk| ˆH|Ψ0i [(1 − δi0)δ0j + δi0(1 − δ0j)],

EFP

P

N opt
k=1 (S

the

current wave

|Φii designates

function
where
P
i.e.
and its derivatives without the Jastrow factor,
|Ψii = ˆJ(α0)|Φii, and hΨk| ˆH|Ψ0i are just the compo-
nents of half the gradient of the energy. Hence, in the
EFP method, only the oﬀ-diagonal elements in the ﬁrst
column and ﬁrst row calculated from the components of
the energy gradient are retained in H

EFP

−1

.

Connection to the Newton and SRH methods.
In the lin-
ear method, the energy expression that is minimized at
each iteration, Elin(p), contains all orders in the parame-
ter variations because of the presence of the denominator
in Eq. (26), though only the zeroth- and ﬁrst-order terms
match those of the expansion of the exact energy E(p).
In contrast, in the Newton method, the energy expres-
sion of Eq. (18), E[2](p), is truncated at second-order
in ∆p but is exact up to this order. Now, if instead of
solving the generalized eigenvalue equation (28), one ex-
pands the energy expression of Eq. (26) to second order

in ∆p, one recovers the Newton method with an approx-
imate (symmetric) Hessian hlin
ij = H ij + H ji − 2E0Sij
corresponding exactly to the SRH method with β = 0 of
Ref. 24. The SRH method is much less stable and con-
verges more slowly than either our linear method or our
Newton method for the systems studied here.

C. Perturbative optimization method

The perturbative method discussed next is identical
to the perturbative EFP approach of Scemama and Fil-
ippi [17] for the optimization of the CSF and orbital pa-
rameters, provided that the same choice is made for the
energy denominators (see below). We give here an al-
ternate proof without introducing the concept of energy
ﬂuctuations that in principle extends the method to other
kinds of parameters as well.

Instead of calculating the optimal linearized wave func-
tion |Ψlini by diagonalizing the Hamiltonian ˆH in the
subspace spanned by {|Ψ0i, |Ψ1i, |Ψ2i, · · · , |ΨN opt i}, we
formulate a nonorthogonal perturbation theory for |Ψlini.
The textbook formulation of perturbation theory starts
from the Hamiltonian ˆH whose eigenstates we wish to
compute, and a zeroth order Hamiltonian ˆH (0) whose
Instead, here we start with ˆH
eigenstates are known.
and the states {|Ψ0i, |Ψ1i, |Ψ2i, · · · , |ΨN opt i}, and de-
ﬁne a zeroth order operator ˆH (0) for which these states
are right eigenstates. To do this, we introduce {h ˜Ψi|},
the dual (biorthonormal) basis of the basis {|Ψii}, i.e.
h ˜Ψi|Ψji = δij, given by (see, e.g., Ref. 38)

h ˜Ψi| =

−1

(S

)ij hΨj|,

(35)

−1

where (S
)ij are the elements of the inverse of the over-
lap matrix S, and we introduce the non-Hermitian pro-
jector operator onto this subspace

ˆP =

|Ψiih ˜Ψi|.

(36)

N opt

j=0
X

N opt

i=0
X

The optimal linearized wave function, minimizing the en-
ergy [Eq. (25)], satisﬁes the projected Schr¨odinger equa-
tion

ˆP ˆH|Ψlini = Elin ˆP |Ψlini,

(37)

with the normalization condition h ˜Ψ0|Ψlini = 1, ensuring
that the coeﬃcient of |Ψlini on |Ψ0i = |Ψ0i is 1 as in
Eq. (23).

To construct the perturbation theory, we now intro-
duce a ﬁctitious projected Schr¨odinger equation depend-
ing on a coupling constant λ

λ
ˆP ˆH λ|Ψ
lini = Eλ
lin

ˆP |Ψ

λ
lini,

(38)

7

λ
with the normalization condition h ˜Ψ0|Ψ
lini = 1 for all λ,
so that, for λ = 1, Eq. (38) reduces to Eq. (37): ˆH λ=1 =
λ=1
ˆH, |Ψ
lin i = |Ψlini, Eλ=1
lin = Elin, and we partition the
Hamiltonian ˆH λ as follows

ˆH λ = ˆH (0) + λ ˆH (1).

(39)

In this expression, ˆH (0) is a zeroth-order non-Hermitian
operator

ˆH (0) =

Ei|Ψiih ˜Ψi|,

(40)

N opt

i=0
X

where Ei are arbitrary energies. Clearly, ˆH (0) admits
|Ψii as right-eigenstate and h ˜Ψi| as left-eigenstate, with
common eigenvalue Ei. The non-Hermitian perturba-
tion operator is obviously deﬁned as ˆH (1) = ˆH − ˆH (0).
λ
λ
lini and Eλ
We expand |Ψ
|Ψ
lini =
∞
k=0 λk|Ψ
lin . The zeroth-
lin =
(0)
lin i =
order (right) eigenstate and energy are simply: |Ψ
P
|Ψ0i and E(0)
lin = E0. The ﬁrst-order correction to the
wave function is determined by the equation

lin in powers of λ:
k=0 λkE(k)

(k)
lin i and Eλ

P

∞

ˆP

ˆH (0) − E0

|Ψ

(1)

lin i = − ˆP

(cid:16)

(cid:17)

ˆH (1) − E(1)
lin
(cid:16)

(cid:17)

|Ψ0i.

(41)

To solve this equation, we deﬁne the non-Hermitian pro-
N opt
i=1 |Ψiih ˜Ψi| which, in compari-
jector operator ˆR =
son to the projector ˆP , also removes the component par-
allel to |Ψ0i. Note that ˆR ˆP = ˆR, ˆR commutes with
λ
(1)
ˆH (0) − E0 and ˆR|Ψ
lini = 1 and
(1)
h ˜Ψ0|Ψ0i = 1, implying h ˜Ψ0|Ψ
lin i = 0), so that applying
ˆR on Eq. (41) leads to

lin i (since h ˜Ψ0|Ψ

(1)
lin i = |Ψ

P

|Ψ

(1)
lin i = −

ˆR
ˆH (0) − E0
N opt

|Ψ0i

ˆH (1) − E(1)
lin
(cid:16)
h ˜Ψi| ˆH − E0 − E(1)

(cid:17)
lin |Ψ0i

Ei − E0

= −

|Ψii

= −

i=1
X
N opt

N opt

i=1
X

j=1
X

(S

−1

)ij

hΨj| ˆH|Ψ0i
Ei − E0

|Ψii,

(42)

where E0 and E(1)
lin in the numerator and the term j = 0
have been dropped since, for i 6= 0, h ˜Ψi|Ψ0i = 0 and
(S
)i0 = 0, respectively. Therefore, the parameter vari-
ations in this ﬁrst-order perturbation theory are

−1

N opt

∆p(1)

i = −

1
∆Ei

−1

(S

)ij H j0,

(43)

j=1
X
where H j0 = hΨj| ˆH|Ψ0i = hΨj| ˆH − E0|Ψ0i = gj/2 is
just half the gradient of the energy and ∆Ei = Ei − E0.

The perturbative method consists of calculating the pa-
rameter variations ∆p(1) according to Eq. (43), updat-
ing the current wave function, |Ψ0i → |Ψ(p0 + ∆p(1))i,
and iterating until convergence.
It is apparent from
Eq. (43) that the perturbative method can be viewed
as the Newton method with an approximate Hessian,
hpert
ij = (S
)ij /∆Ei, as also noted in Ref. 17.
The energy denominators ∆Ei in Eq. (43) remain to be
chosen. Since perturbation theory works best when ˆH (0)
is “close” to ˆH we choose ˆH (0) to have the same diagonal
elements as ˆH, resulting in

−1

∆Ei =

− E0 =

− H 00.

(44)

hΨi| ˆH|Ψii
hΨi|Ψii

H ii
Sii

In practice, only rough estimates of the ∆Ei’s are neces-
sary for the optimization so that one can compute them
for just the initial iteration and keep them ﬁxed for the
following iterations. Therefore, for these iterations, only
the inverse overlap matrix, S
, and the gradient of the
energy, gj = 2 H j0, need to be calculated in the pertur-
bative method, leading to an important computational
speedup per iteration in comparison to the linear method.

−1

Stabilization.
Similarly to the linear method, the per-
turbative method can be stabilized by adding an ad-
justable positive constant, adiag ≥ 0, to the energy de-
nominators, i.e. ∆Ei → ∆Ei + adiag, which has the eﬀect
of decreasing the parameter variations ∆p(1).

Connection to the perturbative EFP and SR methods.
For the CSF and orbital parameters, if the energy de-
nominators are chosen to be ∆Ei = hΦi| ˆH|Φii/hΦi|Φii −
hΦ0| ˆH|Φ0i/hΦ0|Φ0i (i.e., without the Jastrow factor),
Eq. (43) exactly reduces to the perturbative EFP
method [17]. Also, Eq. (43) reduces to the SR optimiza-
tion method [18–20] if the energy denominators are all
chosen equal, ∆Ei = ∆E for all i.

IV. VARIATIONAL MONTE CARLO
REALIZATION

When the previously-described energy minimization
procedures are implemented in VMC it is important to
pay attention to the statistical ﬂuctuations. Expressions
that are equivalent in the limit of an inﬁnite Monte Carlo
sample, can in fact have very diﬀerent statistical errors
for a ﬁnite sample. We provide prescriptions for low vari-
ance estimators in this section.

At each step of the optimization,

the quantum-
mechanical averages are computed by sampling the prob-
ability density of the current wave function Ψ0(R)2. We
will denote the statistical average of a local quantity,
M
k=1 f (Rk) where the M
f (R), by hf (R)i = (1/M )
electron conﬁgurations Rk are sampled from Ψ0(R)2.

P

and

8

A. Energy gradient and Hessian

In terms of the derivatives Ψi(R) of the wave function
of Eq. (4), and using the Hermiticity of the Hamiltonian
ˆH, an estimator of the energy gradient is [39]

gi = 2

EL(R)

−

hEL(R)i

, (45)

Ψi(R)
Ψ0(R)

"(cid:28)

Ψi(R)
Ψ0(R)

(cid:29)

(cid:28)

(cid:29)

#

where EL(R) = [H(R)Ψ0(R)] /Ψ0(R) is the local en-
ergy. In the limit that Ψ0(R) is an exact eigenfunction,
the local energy becomes constant, EL(R) = Eexact for
all R, and thus the gradient of Eq. (45) vanishes with
zero variance. This leads to the following zero-variance
in
principle for the Newton and perturbative methods:
the limit that Ψ0(R) is an exact eigenfunction, the pa-
rameter variations of Eqs. (21) and (43) vanish with zero
variance.

Taking the derivative of Eq. (45) leads to the straight-
forward estimator of the energy Hessian of Lin, Zhang
and Rappe (LZR) [21]

hLZR
ij = Aij + Bij + Cij ,

(46)

where

Aij = 2

EL(R)

−

hEL(R)i

Ψij(R)
Ψ0(R)

Ψi(R)
Ψ0(R)

Ψj(R)
Ψ0(R)

Ψi(R)
Ψ0(R)

Ψj(R)
Ψ0(R)

"(cid:28)

−

+

(cid:28)

(cid:28)

Ψij(R)
Ψ0(R)

(cid:29)

(cid:29)

(cid:28)

EL(R)

(cid:29)

hEL(R)i

,
#

(cid:29)

(47)

involving the second derivatives Ψij(R) of the wave func-
tion,

Bij = 4

Ψi(R)
Ψ0(R)

Ψj(R)
Ψ0(R)

EL(R)

(cid:29)

"(cid:28)

−

(cid:28)

−2

Ψi(R)
Ψ0(R)

Ψj(R)
Ψ0(R)

(cid:29)

gj − 2

hEL(R)i

#
Ψj(R)
Ψ0(R)

gi

(cid:29)

= 4

Ψi(R)
Ψ0(R)

Ψi(R)
Ψ0(R)

(cid:29)

−

(cid:28)

* (cid:18)

Ψj(R)
Ψ0(R)

−

×

(cid:18)

(cid:28)
Ψi(R)
Ψ0(R)

(cid:28)
Ψj(R)
Ψ0(R)

(cid:28)

(cid:29)(cid:19)

(cid:29)(cid:19)

(EL(R) − hEL(R)i)

,
+
(48)

Cij = 2

EL,j(R)

,

(49)

Ψi(R)
Ψ0(R)

(cid:28)

(cid:29)

=

EL,j(R)

[H(R)Ψj(R)] /Ψ0(R) −
where
[Ψj(R)/Ψ0(R)] EL(R) is the derivative of the local
energy with respect to parameter j. In this estimator of
the Hessian, the term that ﬂuctuates the most is Cij .

Umrigar and Filippi [23] observed that the ﬂuctuations
of a covariance habi − haihbi are much smaller than those
of habi if the ﬂuctuations of a are much smaller that the
ha2i − hai2 ≪ |hai|, and, a is not
average of a, i.e.,
strongly correlated with 1/b. In Eq. (49), Ψi(R)/Ψ0(R)
is always of the same sign for parameters in the exponent
and in practice its ﬂuctuations are much smaller than
its average. Further, it follows from the Hermiticity of
the Hamiltonian that hEL,j(R)i vanishes in the limit of
an inﬁnite sample [21]. Using these two observations,
Umrigar and Filippi [23] provided an estimator of the
Hessian

p

hUF
ij = Aij + Bij + Dij,

(50)

that ﬂuctuates much less than the straightforward LZR
estimator, where the symmetrized estimator

Dij =

Ψi(R)
Ψ0(R)

Ψj(R)
Ψ0(R)

(cid:28)

(cid:28)
+

EL,j(R)

−

(cid:29)
EL,i(R)

(cid:28)
−

Ψi(R)
Ψ0(R)

(cid:29)
Ψj(R)
Ψ0(R)

(cid:29)

(cid:28)

(cid:29)

hEL,j(R)i

hEL,i(R)i ,

(51)

has the same average as the term Cij in the limit of an
inﬁnite sample, but being a covariance has much smaller
ﬂuctuations. We note that Aij is already a covariance
and Bij is a tri-covariance.

Although the Aij and Bij terms vanish with zero vari-
ance in the limit that Ψ0(R) is an exact eigenfunction
(the Dij term does not),
in practice for the Jastrow
parameters, far from the minimum, the Bij ﬂuctuates
more than the Dij term for the Jastrow parameters in
the Hessian of Eq. (50). With the form of the Jastrow
factors that we use, we have observed that the ratio
(Bij + Dij)/Dij is roughly independent of i and j for
most i and j though it changes during the Monte Carlo
iterations. It is typically between 1.2 and 2.5 at the initial
iteration and between 0.9 and 1.1 at the ﬁnal iteration.
We exploit this to decrease the ﬂuctuations by deﬁning
a new, approximate Hessian partially averaged over the
Jastrow parameters

hTU
ij = Aij +

hh|Bij + Dij|ii
hh|Dij|ii

Dij ,

(52)

Jas (N opt

where TU are the initials of the present authors, and the
average over the Jastrow parameter pairs are deﬁned by
N opt
hhXijii = (2/N opt
j=i Xij. The av-
Jas
erage is calculated as hh|Bij + Dij|ii / hh|Dij |ii and not
as hh(|Bij + Dij |)/|Dij|ii to avoid possible numerical di-
vergences of this ratio for small Dij . In Eq. (52), i and
j refer only to Jastrow parameters. For all the terms
related to the other parameters (including all the mixed

Jas + 1))

N opt
Jas
i=1

P

P

9

terms), the Hessian of Eq. (50) is used without further
modiﬁcation.

Exact or approximate wave functions such as Ψ0(R)
go linearly to zero with the distance d between R and
their nodal hypersurface, i.e., Ψ0(R) ∼ d for d → 0.
The local energy EL(R) generally diverges as 1/d for
In contrast
d → 0 for approximate wave functions.
to the case of the Jastrow parameters, the derivatives
Ψi(R) for the CSF and orbital parameters have a dif-
ferent nodal hypersurface than Ψ0(R) and the ratio
Ψi(R)/Ψ0(R) thus also diverges as 1/d, even if the
wave function Ψ0(R) is exact. Consequently, the deriva-
tive of the local energy EL,i(R) generally diverges as
1/d2 for approximate wave functions.
In the expres-
sion of the Hessian, the leading divergence at the nodes
of the approximate wave function Ψ0(R) thus comes
from the terms (Ψi(R)/Ψ0(R)) (Ψj(R)/Ψ0(R)) EL(R),
(Ψi(R)/Ψ0(R)) EL,j(R) and (Ψj(R)/Ψ0(R)) EL,i(R)
that behave as 1/d3.
It is however easy to check that
these third-order divergences cancel exactly in Eq. (50).

B. Overlap and Hamiltonian matrices

The elements of the symmetric overlap matrix S are

S00 = 1,

(53a)

and, for i, j > 0,

and

Si0 = S0j = 0,

(53b)

Sij =

Ψi(R)
Ψ0(R)

Ψj(R)
Ψ0(R)

Ψi(R)
Ψ0(R)

−

(cid:29)

(cid:28)

(cid:28)

Ψj(R)
Ψ0(R)

(cid:29) (cid:28)

(cid:29)

. (53c)

The elements of the Hamiltonian matrix H are

H 00 = hEL(R)i ,

(54a)

and, for i, j > 0,

H i0 =

EL(R)

−

hEL(R)i ,

(54b)

Ψi(R)
Ψ0(R)

(cid:28)

Ψi(R)
Ψ0(R)

(cid:29)

(cid:28)

(cid:29)

H 0j =

Ψj(R)
Ψ0(R)
(cid:20)(cid:28)
+ hEL,j(R)i ,

EL(R)

−

(cid:29)

(cid:28)

Ψj(R)
Ψ0(R)

hEL(R)i
(cid:21)
(54c)

(cid:29)

which are two estimators of half of the energy gradient,

and

H ij =

"(cid:28)

Ψi(R)
Ψ0(R)

Ψj(R)
Ψ0(R)

EL(R)

(cid:29)

EL(R)

EL(R)

(cid:29)

(cid:29)

(cid:29) (cid:28)

(cid:29) (cid:28)

Ψj(R)
Ψ0(R)
Ψi(R)
Ψ0(R)

Ψj(R)
Ψ0(R)

(cid:29) (cid:28)

(cid:29)

hEL(R)i

#

−

−

+

+

Ψi(R)
Ψ0(R)
Ψj(R)
Ψ0(R)

Ψi(R)
Ψ0(R)

(cid:28)

(cid:28)

(cid:28)

Ψi(R)
Ψ0(R)

"(cid:28)

EL,j(R)

−

hEL,j(R)i

Ψi(R)
Ψ0(R)

(cid:29)

(cid:28)

(cid:29)

.
#
(54d)

−1

We do not use the Hermiticity of the Hamiltonian ˆH to
symmetrize the matrix H. In fact, as shown by Nightin-
gale and Melik-Alaverdian [11], using the non-symmetric
matrix H of Eqs. (54) leads to a stronger zero-variance
principle than the one previously-described for the New-
ton and perturbative methods:
in the limit that the
states {|Ψ0i, |Ψ1i, |Ψ2i, · · · , |ΨN opt i} span an invariant
subspace of the Hamiltonian ˆH, i.e. in the limit that the
linear wave function Ψlin(R) of Eq. (23) after optimiza-
tion is an exact eigenfunction, the matrix S
· H and
consequently the eigenvector solution ∆p have zero vari-
ance. In practice, even if we do not work in an invariant
subspace of ˆH, using the non-symmetric matrix H leads
to smaller statistical errors on a ﬁnite sample than us-
ing its symmetrized analog. Although in principle diago-
nalization of a non-symmetric matrix leads to complex
eigenvalues, in practice the physically-reasonable (i.e.,
with large overlap with the current wave function) low-
est eigenvectors have usually real eigenvalues. Of course,
in the limit of an inﬁnite sample M → ∞ a symmetric
matrix H is recovered.
subsec-
in
As
terms
tion
the Hessian,
(Ψi(R)/Ψ0(R)) (Ψj(R)/Ψ0(R)) EL(R)
and
(Ψi(R)/Ψ0(R)) EL,j(R)
the
Hamiltonian matrix of Eq. (54d) display a third-order
divergence 1/d3 as the distance d between R and the
nodal hypersurface of Ψ0(R) goes to zero, again these
divergences cancel exactly.

expression of

although

previous

in the

noted

the

the

for

C. Comparison of computational cost per iteration

At each optimization iteration, beside the calculation
the current wave function Ψ0(R) and the local energy
EL(R), the Newton method requires the computation
of the ﬁrst-order and second-order wave function deriva-
tives, Ψi(R) and Ψij(R), and the ﬁrst-order derivatives
of the local energy EL,i(R). The linear method requires
the calculation of Ψi(R) and EL,i(R) but not of the

10

second-order derivatives of the wave function with re-
spect to the parameters. In principle, this decreases the
computational cost per iteration, especially if the many
orbital-orbital second-order derivatives were to be com-
puted in the Newton method.
In practice, since our
implementation of the Newton method neglects these
orbital-orbital derivatives, the computational cost per it-
eration of the Newton and linear methods is very similar.
The perturbative method requires the computation of
the same quantities as the linear method. However, since
the method is not very sensitive to having accurate en-
ergy denominators ∆Ei in Eq. (43), and since the energy
denominators do not undergo large changes from iter-
ation to iteration we compute these for the ﬁrst itera-
tion only. Hence it is not necessary to compute EL,i(R)
for subsequent iterations. This leads to a computational
speedup per iteration in comparison to the linear method.
The precise speedup factor depends on the wave func-
tion used; typically, for the systems studied here, we
have found factors ranging from about 1.5 for a single-
determinant wave function to 5.5 for the largest multi-
determinant wave function considered, for the iterations
for which the ∆Ei’s are not computed.

V. COMPUTATIONAL DETAILS

We illustrate the optimization methods by calculating
the ground-state electronic energy of the all-electron C2
molecule at the experimental equilibrium interatomic dis-
tance of 2.3481 Bohr [40]. The ground-state wave func-
tion is of symmetry 1Σ+
g in the point group D∞h. The es-
timated exact, inﬁnite nuclear mass, non-relativistic elec-
tronic energy is −75.9265(8) Hartree [41], where the num-
ber in parenthesis is an estimate of the uncertainty in the
last digit. This system has a strong multi-conﬁguration
character due to the energetic near-degeneracy of the va-
lence orbitals, making it a challenging system despite its
small size.

We

initio
start by generating a standard ab
wave function using the quantum chemistry program
GAMESS [42], typically a restricted Hartree-Fock (RHF)
wave function or a MCSCF wave function, using the
symmetry point group D4h which is the largest sub-
group of D∞h available in GAMESS.i We use the uncon-
tracted Slater basis set form of Clementi and Roetti [43],
with exponents reoptimized at the RHF level by Koga
et al. [44]. For carbon, the basis set contains two 1s,
three 2s, one 3s and four 2p Slater functions, that
are each approximated by a ﬁt to six Gaussian func-
tions [45, 46] in GAMESS. Speciﬁcally, we consider the
following ab initio wave functions: a RHF wave func-
tion, with orbital occupations 1σ2
u,y;
a CAS(8,5) wave function, containing 6 CSFs in D4h sym-
metry made of 7 Slater determinants generated by dis-
tributing the 8 valence electrons over the 5 active valence
orbitals 2σg2σu1πu,x1πu,y3σg; a CAS(8,7) wave func-
tion, containing 80 CSFs made of 165 determinants with

u,x1π2

u1π2

u2σ2

g1σ2

g2σ2

function,

the 7 active orbitals 2σg2σu1πu,x1πu,y3σg1πg,x1πg,y;
a CAS(8,8) wave
containing 264 CSFs
made of 660 determinants with the 8 active orbitals
2σg2σu1πu,x1πu,y3σg1πg,x1πg,y3σu, i.e. all the valence
orbitals originating from the n = 2 shell of the C atoms.
In addition, we construct a larger one-electron basis set
by adding to the basis of Koga et al. one d function with
an exponent of 2.13 optimized in RHF and we consider
a wave function obtained from a restricted active space
(RAS) calculation in this basis that would correspond to
a CAS(8,26) calculation, using all the 26 orbitals origi-
nating from the n = 2 and n = 3 shells of the C atoms,
but where only single (S), double (D), triple (T) and
quadruple (Q) excitations are allowed in the active space.
This wave function, that we denote by RAS-SDTQ(8,26),
contains 110481 CSFs made of 411225 determinants.

)
e
e
r
t
r
a
H

(
 
y
g
r
e
n
E

-75.2

-75.3

-75.4

-75.5

-75.6

-75.7

-75.8

The standard ab initio wave function is then multi-
plied by a Jastrow factor, imposing the electron-electron
cusp conditions, but with essentially all other free pa-
rameters chosen to be 0 to form our starting trial wave
function. QMC calculations are performed with the pro-
gram CHAMP [47], using this time the true Slater basis
set rather than its Gaussian expansion. In comparison to
GAMESS, additional symmetries outside the point group
D4h are detected numerically which allows one to reduce
the numbers of CSFs to 5, 50 and 165 for the CAS(8,5),
CAS(8,7) and CAS(8,8) wave functions, respectively. For
the large RAS-SDTQ(8,26) wave function, only a fraction
of all the CSFs are retained in QMC by applying a vari-
able cutoﬀ on the CSF coeﬃcients and an extrapolation
procedure is used to estimate the QMC result if all the
CSFs had been included (see Sec. VI E). For the orbital
optimization, only the single excitations between orbitals
of the same irreducible representation of D∞h are gen-
erated. We however impose no restriction inside each of
the two-dimensional irreducible representations πu and
πg. Although one can in principle identify the πx and
πy components and forbid excitations between these two
components to further reduce the number of free param-
eters, these redundancies appear to cause no problem in
practice during the optimization. Also, we impose the
electron-nucleus cusp condition on each orbital. The pa-
rameters of the trial wave function are optimized by the
previously-described energy minimization procedures in
VMC, using a very eﬃcient accelerated Metropolis algo-
rithm [48, 49], allowing us to simultaneously make large
Monte Carlo moves in conﬁguration space and have a
high acceptance probability. Once a trial wave func-
tion has been optimized, we perform a DMC calculation
within the ﬁxed-node and the short-time approximations
(see, e.g., Refs. 50–53). We use an imaginary time-step
of τ = 0.01 H−1 in an eﬃcient DMC algorithm featuring
very small time-step errors [54], so that the accuracy is
essentially limited by the quality of the nodal hypersur-
face of the trial wave function.

11

Linear method
Perturbative method
Newton method (UF)
Newton method (TU)

Optimization of the Jastrow

)
e
e
r
t
r
a
H

(
 
y
g
r
e
n
E

-75.762

-75.763

-75.764

-75.765

 3

 4

 5

 6

 7

 8

Iterations

 0

 1

 2

 3

 4

 5

 6

 7

 8

Iterations

FIG. 1: Convergence of the VMC total energy EVMC of the
all-electron C2 molecule during the optimization of the 24
Jastrow parameters in a wave function composed of the RHF
Slater determinant multiplied by a Jastrow factor. The linear,
perturbative and Newton energy minimization methods are
compared. For the Newton method, the results obtained with
the UF Hessian of Eq. (50) and the TU Hessian of Eq. (52) are
shown. The statistical error on the energy at each iteration is
0.5 mHa. The insert is an enlargement of the last 6 iterations.

VI. RESULTS AND DISCUSSION

A. Optimization of the Jastrow factor

We ﬁrst study the convergence behavior of the energy
minimization methods for the separate optimization of
the Jastrow, CSF and orbital parameters. To facilitate
comparisons, we apply the VMC optimization procedures
with a common ﬁxed statistical error of the energy at
each step, namely 0.5 mHa. This is not the usual way
in which we routinely perform optimizations which is de-
scribed later in Sec. VI D.

Figure 1 shows the convergence of the total VMC en-
ergy during the optimization of the 24 Jastrow param-
eters in a wave function composed of the RHF Slater
determinant multiplied by a Jastrow factor. The linear,
perturbative and Newton methods are compared. For
the Newton method, we present the results obtained with
the UF Hessian of Eq. (50), already used in Ref. 23, and
with the TU Hessian of Eq. (52). To compare the ﬂuc-
tuations of these two Hessians, we have computed the
N opt
j=i (σ(hij ))2
quantity η = 1/N opt(N opt + 1)
where (σ(hij ))2 is the variance of the element hij of
the Hessian averaged over 100 Monte Carlo conﬁgura-
tions. For the initial iteration of the optimization, far
from the energy minimum, the UF Hessian ﬂuctuates
more than the TU Hessian by a factor ηUF/ηTU = 3.6.
For comparison, the LZR Hessian of Eq. (46) ﬂuctuates
more than the TU Hessian by a factor ηLZR/ηTU = 150,
more than two orders of magnitude larger even for this
modest system. Near the energy minimum, the factors

N opt
i=1

P

P

)
e
e
r
t
r
a
H

(
 
y
g
r
e
n
E

-75.845

-75.846

-75.847

-75.848

-75.849

-75.85

-75.851

-75.852

-75.853

-75.854

-75.855

Linear method
Perturbative method
Newton method (UF)

12

Linear method
Perturbative method
Newton method (UF)

Optimization of the CSFs

Optimization of the orbitals

)
e
e
r
t
r
a
H

(
 
y
g
r
e
n
E

-75.764

-75.766

-75.768

-75.77

-75.772

-75.774

-75.776

-75.778

-75.78

-75.782

-75.784

-75.786

 0

 1

 2

 3

 4

 5

 6

 7

 8

 0

 1

 2

 3

 4

 5

 6

 7

 8

Iterations

Iterations

FIG. 2: Convergence of the VMC total energy EVMC of the
all-electron C2 molecule during the optimization of the 49
CSF parameters in a wave function composed of a CAS(8,7)
part multiplied by a previously-optimized Jastrow factor. The
linear, perturbative and Newton [with the UF Hessian of
Eq. (50)] energy minimization methods are compared. The
statistical error on the energy at each iteration is 0.5 mHa.

FIG. 3: Convergence of the VMC total energy EVMC of the
all-electron C2 molecule during the optimization of the 44
orbital parameters in a wave function composed of a single
Slater determinant multiplied by a previously-optimized Jas-
trow factor. The linear, perturbative and Newton [with the
UF Hessian of Eq. (50)] energy minimization methods are
compared. The statistical error on the energy at each itera-
tion is 0.5 mHa.

are ηUF/ηTU = 3.3 and ηLZR/ηTU = 600. These fac-
tors tend to increase with the system size. The Newton
method with the UF Hessian converges reasonably fast
in about 6 iterations, which is a little faster than the
convergence shown in Figs. 1,2 and 4 of Ref. 23 due to
the previously-described correlated sampling adjustment
of the stabilizing constant adiag in the course of the op-
timization and despite the fact that we are performing
an all-electron rather than a pseudopotential calculation
here[55]. The Newton method with the TU Hessian dis-
plays an even faster convergence, the energy being essen-
tially converged within the statistical error at iteration 3
or 4. The linear method has a similar convergence rate to
the Newton method with the TU Hessian. The Newton
method with the TU Hessian and the linear method are
both stable even without stabilization if suﬃciently large
Monte Carlo samples are used. When stabilization is
employed, the stabilization constant adiag remains small
during the optimization, in this example from 10−3 for
the initial iteration to 10−7 for the last iterations which
is 2 or 3 orders of magnitude smaller than the values of
adiag in the Newton method with the UF Hessian. The
perturbative method, in contrast, converges very slowly.
In fact, it turns out that the energy denominators for
the Jastrow parameters, ∆Eαi , calculated according to
Eq. (44), are all of order unity and adiag needs to be
increased to as much as 102 to retain stability. In this
case, the perturbative method essentially reduces to the
ineﬃcient SR optimization technique.

B. Optimization of the CSF coeﬃcients

Figure 2 shows the convergence of the total VMC en-
ergy during the optimization of the 49 CSF parameters in
a wave function composed of a CAS(8,7) determinantal
part multiplied by a previously-optimized Jastrow factor,
using the linear, perturbative and Newton [with the UF
Hessian of Eq. (50)] methods. The linear method con-
verges in 1 iteration, as it must, and does not require
any stabilization. When stabilization is used, adiag re-
mains as low as 10−6 to 10−8 during the whole optimiza-
tion. The Newton and perturbative methods converge
in 2 or 3 iterations, and are not as intrinsically stable,
adiag being a few orders of magnitude larger for the New-
ton method and several orders of magnitude larger for
the perturbative method. The energy denominators for
the CSF parameters in the perturbative method, ∆EcI ,
calculated according to Eq. (44), span only one order of
magnitude.

C. Optimization of the orbitals

Figure 3 shows the convergence of the total VMC en-
ergy during the optimization of all the 44 orbital param-
eters in a wave function composed of a single Slater de-
terminant multiplied by a previously-optimized Jastrow
factor, using the linear, perturbative and Newton [with
the UF Hessian of Eq. (50)] methods. The three methods
display very similar convergence rates, the energy being
converged within the statistical error in 1 iteration using
any of the three methods. In this example, the linear and
perturbative methods converged even without stabiliza-

RHF orbitals
RKS B3LYP orbitals

)
e
e
r
t
r
a
H

(
 
y
g
r
e
n
E

-75.76

-75.765

-75.77

-75.775

-75.78

-75.785

-75.79

 0

 2

 4

 6

 8  10  12  14  16  18  20  22  24  26  28  30

Number of virtual orbitals

FIG. 4: Total VMC energy EVMC of the all-electron C2
molecule with respect to the number of virtual orbitals in-
cluded in the optimization of the orbital parameters in a
wave function composed of a single Slater determinant mul-
tiplied by a previously-optimized Jastrow factor, using RHF
and RKS B3LYP starting orbitals. The orbitals are ordered
according to their energies. The statistical error on the energy
is 0.5 mHa.

tion whereas the Newton method required stabilization.
The energy denominators for the orbital parameters in
the perturbative method, ∆Ekl, calculated according to
Eq. (44), typically span two orders of magnitude from 1
to 100.

In the previous orbital optimization, we have consid-
ered a full optimization of all the orbital parameters, i.e.
all the allowed excitations from the 6 closed occupied
orbitals to the 30 virtual orbitals were included in the
calculation. One may also consider a partial orbital opti-
mization by restricting the excitations to the lowest sev-
eral virtual orbitals, as also proposed within the EFP or
perturbative EFP approaches [56]. This allows one to
reduce the computational eﬀort and also to decrease the
statistical noise in the calculation since it is the excita-
tions to the highest-lying virtual orbitals that modify the
most the nodal structure of the wave function, leading
to large ﬂuctuations of the ratio Ψi(R)/Ψ0(R). Fig. 4
shows the total VMC energy with respect to the number
of virtual orbitals included in the optimization for a wave
function composed of a single Slater determinant multi-
plied by a previously-optimized Jastrow factor. Two sets
of starting orbitals are compared: orbitals obtained from
a RHF calculation and orbitals obtained from a restricted
Kohn-Sham (RKS) calculation with the hybrid exchange-
correlation functional B3LYP [57, 58], using the ordering
given by the orbital energies. In both cases, as expected,
the energy decreases monotonically within the statistical
error as the number of virtual orbitals included in the
optimization increases. However the slope of the energy
does not change monotonically and it is necessary to in-
clude almost all the orbitals to get close to the optimal
energy. From Fig. 4 we see that for the C2 molecule the

13

B3LYP orbitals provide a better starting point than the
RHF orbitals.
In our experience, this is often but not
always the case. It is possible that the selection of the
virtual orbitals adopted here, based on the orbital energy
ordering, may not be the best choice and other selections
based on symmetry or chemical intuition could lead to a
more rapid convergence.

Note that Fig. 4 was obtained by just optimizing the
orbital parameters for a ﬁxed, previously-optimized Jas-
trow factor. If instead the Jastrow and orbital param-
eters are optimized simultaneously a signiﬁcantly lower
including all 30 virtual orbitals
energy is obtained, e.g.
gives an energy of -75.8069(5) Ha (see Table I) as opposed
to -75.7845(5) Ha in Fig. 4.

To summarize, the Newton and the linear methods
converge very rapidly when optimizing any kind of pa-
rameter, though the linear method is more stable for the
optimization of the determinantal part of the wave func-
tion. The perturbative method is a good, less expensive
alternative for the optimization of the orbital parameters
and, to a lesser extent, for the optimization of the CSF
parameters, but is very slowly convergent for the Jastrow
parameters.

It is clear from Eq. (43) that the perturbative method
can be viewed as a Newton method with an approximate
Hessian. The poor behavior of the perturbative method
for the Jastrow parameters means that this Hessian is
a bad approximation to the exact Hessian, whose eigen-
values span more than 10 orders of magnitude for these
parameters. In fact, any method based on an approxi-
mate Hessian that is not able to reproduce all these or-
ders of magnitude, such as the steepest-descent method,
is bound to converge very slowly. On the other hand, the
eigenvalues of the Hessian for the CSF and orbital pa-
rameters span only a couple of orders of magnitude and
the approximate Hessian of the perturbative method is
suﬃcient to allow rapid convergence.

D. Optimization of all the parameters:
simultaneous or alternated optimization?

After having studied the behavior of the energy min-
imization methods for the optimization of each kind of
parameter, we now move on to the more practical prob-
lem of how to optimize all the parameters.

The most obvious possibility is to optimize simulta-
neously the Jastrow, CSF and orbital parameters using
the linear method, the method having the best overall
eﬃciency for all these parameters. In practice, we pro-
ceed as follows. We start an optimization run with a
short Monte Carlo simulation with a large statistical er-
ror (e.g., 0.02 Ha for the C2 molecule), and we decrease
progressively the statistical error at each iteration until
the energy is converged to 10−3 Ha for three consecu-
tive iterations. We choose the optimal parameters to be
those from the iteration with the smallest value of EVMC
plus three times the statistical error of EVMC, which is

Simultaneous optimization of the Jastrow, CSFs and orbitals

Simultaneous optimization of the Jastrow, CSFs and orbitals

14

)
e
e
r
t
r
a
H

(
 
y
g
r
e
n
E

-75.4

-75.5

-75.6

-75.7

-75.8

-75.9

)
e
e
r
t
r
a
H

(
 
y
g
r
e
n
E

-75.855

-75.86

-75.865

-75.87

-75.875

-75.88

)
e
e
r
t
r
a
H

(
 
n
o
i
t
a
i
v
e
d
d
r
a
d
n
a
t
S

 

 0.97

 0.96

 0.95

 0.94

 0.93

 0.92

 0.91

 0.9

 0.89

 0.88

)
e
e
r
t
r
a
H

(
 
y
g
r
e
n
e
 
l
a
c
o
l
 
f
o
 
n
o
i
t
a
i
v
e
d
d
r
a
d
n
a
t
S

 

 2

 1.8

 1.6

 1.4

 1.2

 1

 0.8

 2

 3

 5

 6

 2

 3

 5

 6

 4
Iterations

 4
Iterations

 0

 1

 2

 3

 4

 5

 6

 0

 1

 2

 3

 4

 5

 6

Iterations

Iterations

FIG. 5: Convergence of the VMC total energy EVMC (left plot) and of the VMC standard deviation of the local energy
σVMC (right plot) of the all-electron C2 molecule during the simultaneous optimization of the 24 Jastrow parameters, 49 CSF
parameters and 64 orbital parameters in a wave function composed of the CAS(8,7) determinantal part multiplied by a Jastrow
factor, using the linear energy minimization method. The statistical error on the energy is initially of 0.02 Ha and is decreased
by a factor 2 at each iteration until 0.5 mHa. The inserts are enlargements of the last 5 iterations.

often but not always the last iteration. A typical exam-
ple of the convergence of the total VMC energy and of
the standard deviation σVMC is shown in Fig. 5 for the si-
multaneous optimization of the Jastrow, CSF and orbital
parameters in a wave function composed of a CAS(8,7)
In
determinantal part multiplied by a Jastrow factor.
this case, the energy converges in 4 or 5 iterations. The
standard deviation typically converges a little slower than
the energy since we are optimizing just the energy here.
A faster convergence, to a somewhat smaller value of the
standard deviation, can be achieved by optimizing a lin-
ear combination of the energy and variance as in Ref. [23].

Another possibility is to alternate between the opti-
mization of the diﬀerent kinds of parameters until global
convergence. This has the advantage of allowing one to
use diﬀerent optimization methods for the various pa-
rameters, e.g. optimization of the Jastrow factor and the
CSF coeﬃcients with the Newton or linear method and
optimization of the orbitals with the less expensive but
still very eﬃcient perturbative method. Fig. 6 shows the
convergence of the total VMC energy and of the standard
deviation during the alternated optimization of the Jas-
trow parameters and of the orbital parameters in a wave
function composed of a single Slater determinant multi-
plied by a Jastrow factor for the all-electron C2 molecule.
The convergence of the energy is surprisingly very slow,
the convergence of the standard deviation is even worse.
This is an indication of the presence of a strong coupling
between some Jastrow and orbital parameters. This situ-
ation is in sharp contrast with the case where a pseudopo-
tential is used to remove the core electrons. Fig. 7 shows
the convergence of the total VMC energy during the al-
ternated optimization of the Jastrow parameters and of
the orbital parameters in a wave function composed of a
single Slater determinant multiplied by a Jastrow factor

for the C2 molecule with a Hartree-Fock pseudopoten-
tial [59] and an adequate Gaussian one-electron basis set.
The convergence is very fast, the energy being essentially
converged within the statistical error in 1 macroitera-
tion. This favorable behavior has already been observed
in other systems with pseudopotentials [56], but we have
also found pseudopotential systems for which the conver-
gence is not as fast.

For the all-electron case, it thus seems that simultane-
ous optimization of the parameters is much preferable.
The coupling between the diﬀerent parameters seems to
be too strong to allow an eﬃcient alternated optimiza-
tion. For large systems most of the wave function pa-
rameters are orbital and CSF parameters for which the
perturbative method works well. It seems then promising
to simultaneously optimize all the parameters with the
Newton or the linear methods, using for the part of the
Hessian or the Hamiltonian matrices involving the CSF
and orbital coeﬃcients rough approximations inspired by
the perturbative method [60].

E. Systematic improvement by wave function
optimization

Table I reports the total VMC and DMC energies,
EVMC and EDMC, and the VMC standard deviation of
hEL(R)2i − hEL(R)i2 for the
the local energy σVMC =
diﬀerent trial wave functions considered. For the single-
determinant, CAS(8,5), CAS(8,7) and CAS(8,8) wave
functions, we present the results for three levels of op-
timization. At the ﬁrst level, only the Jastrow factor
is optimized. At the second level, the Jastrow factor
and the CSF coeﬃcients are optimized together. At the
third level, the Jastrow factor, the CSF coeﬃcients and

p

Alternated optimization of the Jastrow and orbitals
for all-electron C2

Alternated optimization of the Jastrow and orbitals
for all-electron C2

15

)
e
e
r
t
r
a
H

(
 
y
g
r
e
n
E

-75.76

-75.765

-75.77

-75.775

-75.78

-75.785

-75.79

-75.795

-75.8

-75.805

-75.81

 1.45

 1.4

 1.35

 1.3

 1.25

 1.2

 1.15

 1.1

)
e
e
r
t
r
a
H

(
 
n
o
i
t
a
i
v
e
d
d
r
a
d
n
a
t
S

 

 2

 4

 6

 8  10  12  14  16  18  20  22  24  26  28  30

 2

 4

 6

 8  10  12  14  16  18  20  22  24  26  28  30

Macroiterations

Macroiterations

FIG. 6: Demonstration of the slow convergence of the VMC total energy EVMC (left plot) and of the VMC standard deviation
of the local energy σVMC (right plot) of the all-electron C2 molecule during the alternated optimization of the 24 Jastrow
parameters and 44 orbital parameters in a wave function composed of a single Slater determinant multiplied by a Jastrow factor.
The half-integer macroiteration numbers correspond to the optimization of the Jastrow factor and the integer macroiteration
numbers correspond to the optimization of the orbitals. The statistical error on the energy is always 0.5 mHa. The simultaneous
optimization of the Jastrow and orbital parameters gives an energy of −75.8069(5) Ha and a standard deviation of 1.1 Ha,
indicated on the plots by horizontal lines.

Parameters optimized in VMC

EVMC

EDMC

Wave function form
Jastrow × determinant

Jastrow × CAS(8,5)

Jastrow × CAS(8,7)

-75.7648(5) -75.8570(5)
Jastrow (24)
-75.8069(5) -75.8682(5)
Jastrow (24) + orbitals (44)
-75.8045(3) -75.8750(5)
Jastrow (24)
-75.8094(5) -75.8807(5)
Jastrow (24) + CSFs (6)
-75.8374(5) -75.8882(5)
Jastrow (24) + CSFs (6)+ orbitals (52)
-75.8469(5) -75.8973(5)
Jastrow (24)
-75.8546(5) -75.9032(5)
Jastrow (24) + CSFs (49)
-75.8769(5) -75.9092(5)
Jastrow (24) + CSFs (49) + orbitals (64)
-75.8462(5) -75.8999(6)
Jastrow (24)
Jastrow (24) + CSFs (164)
-75.8562(5) -75.9050(6)
Jastrow (24) + CSFs (164) + orbitals (70) -75.8801(6) -75.9099(5)
Jastrow × RAS-SDTQ(8,26) Jastrow + CSFs + orbitals (extrapolation) -75.9016(5) -75.9191(5)
-75.9265(8)
Exact

Jastrow × CAS(8,8)

σVMC
1.4
1.1
1.3
1.3
1.0
1.2
1.2
0.9
1.1
1.1
0.9
–

TABLE I: Total VMC and DMC energies, EVMC and EDMC, and VMC standard deviation of the local energy σVMC of the C2
molecule for diﬀerent trial wave functions and diﬀerent levels of optimization. The kind and number of optimized parameters
are indicated. When not optimized in VMC, the CSF and orbital coeﬃcients have been ﬁxed at their RHF values for the single-
determinant case and at their CAS MCSCF values for the multi-conﬁguration cases. For the large Jastrow × RAS-SDTQ(8,26)
wave function, the VMC and DMC values are obtained by an extrapolation procedure (see Sec. VI E and Fig. 8). For the
energies, the numbers in parenthesis are estimates of the statistical error on the last digit. All units are Hartree.

the orbitals are all optimized together. Going from one
level to the next one improves the accuracy of the wave
function but also increases the computational cost of the
optimization. We note that it is important to reoptimize
the determinantal (CSF and orbital) parameters, along
with the Jastrow parameters, rather than keeping them
ﬁxed at the values obtained from the MCSCF wave func-
tions. For each wave function, the eﬀect of reoptimizing
the determinantal part is to lower the VMC energy by
about 0.03 to 0.04 Ha, and the standard deviation of the
energy by about 0.2 to 0.3 Ha. More remarkably, even
though the optimization is performed at the VMC level,

the DMC energy also goes down by about 0.01 Ha, imply-
ing that the nodal hypersurface of the trial wave function
also improves. In addition, one observes a systematic im-
provement of the VMC and DMC energies when the size
of the CAS increases, provided that at least the CSF co-
eﬃcients are reoptimized with the Jastrow factor.

Including all the 110481 CSFs of the RAS-SDTQ(8,26)
wave function is too costly in quantum Monte Carlo but
one can use a series of truncated wave functions obtained
by retaining only small numbers of CSFs with coeﬃcients
larger in absolute value than a variable cutoﬀ, and then
estimate by extrapolation the energy in the limit that

Alternated optimization of the Jastrow and orbitals
for C2 with a pseudopotential

-11.004

 0.5

 1

 1.5

 2

Macroiterations

FIG. 7: Convergence of the VMC total energy EVMC of the C2
molecule with a pseudopotential removing the core electrons
during the alternated optimization of the 24 Jastrow param-
eters and 42 orbital parameters in a wave function composed
of a single Slater determinant multiplied by a Jastrow factor.
The half-integer macroiteration numbers correspond to the
optimization of the Jastrow factor and the integer macroiter-
ation numbers correspond to the optimization of the orbitals.
The statistical error on the energy is always 0.5 mHa. The
simultaneous optimization of the Jastrow and orbital param-
eters gives an energy of −11.0030(5) Ha, indicated on the plot
by horizontal lines.

VMC
DMC

-10.99

-10.992

-10.994

-10.996

-10.998

-11

-11.002

)
e
e
r
t
r
a
H

(
 
y
g
r
e
n
E

-75.8

-75.82

-75.84

-75.86

-75.88

-75.9

-75.92

)
e
e
r
t
r
a
H

(
 
y
g
r
e
n
E

 0.7

 0.75

 0.8

 0.85

 0.9

 0.95

 1

Sum of squares of MCSCF CSF coefficients

FIG. 8: VMC and DMC energies obtained with the truncated,
fully reoptimized Jastrow-Slater RAS-SDTQ(8,26) wave func-
tions with respect to the sum of the squares of the MCSCF
NCSF
)2. The latter quan-
CSF coeﬃcients retained, P
i=1
tity is equal to 1 in the limit where all the CSFs of the RAS-
SDTQ(8,26) calculation are kept in the wave function which
is extrapolated by quadratic ﬁts.

(cMCSCF

i

16

NCSF
i=1 (cMCSCF
i

all the CSFs are kept. Fig. 8 shows the VMC and DMC
energies obtained with these truncated, fully reoptimized
multi-determinantal wave functions with respect to the
sum of the squares of the MCSCF CSF coeﬃcients re-
)2. Since the RAS-SDTQ(8,26)
tained,
wave function is normalized, the latter quantity is equal
to 1 in the limit where all the CSFs are kept in the wave
function. Experience shows that the energies are well
extrapolated by quadratic ﬁts. The extrapolated DMC
energy is −75.9191(5) which amounts for 98.6% of the
correlation energy (using the HF energy of -75.40620 Ha
calculated in Ref. 40).

P

On the other hand, to calculate accurate well depths
(dissociation energy + zero-point energy) it is often suf-
ﬁcient to rely on some partial cancellation of error be-
tween the atom and the molecule by employing atomic
and molecular wave functions that are consistent with
each other. For example, using the DMC energy of
the C2 molecule given by the Jastrow-Slater full-valence
CAS(8,8) wave function and the DMC energy of the C
atom given by the consistent Jastrow-Slater full-valence
CAS(4,4) wave function with the same one-electron basis
leads to a well depth of 6.46(1) eV, in perfect agreement
within the uncertainty with the exact, non-relativistic
well depth estimated at 6.44(2) eV [41, 61]. In contrast,
the well depth calculated from MCSCF with the molecu-
lar CAS(8,8) and atomic CAS(4,4) wave functions (with-
out Jastrow factor) is 5.62 eV, in poor agreement with
the exact value.

VII. CONCLUSIONS

the Newton,

We have studied three wave function optimization
methods based on energy minimization in a VMC con-
text:
linear and perturbative methods.
These general methods have been applied here to the
optimization of wave functions consisting of a multi-
conﬁguration expansion multiplied by a Jastrow factor
for the all-electron C2 molecule. The Newton and lin-
ear methods are both very eﬃcient for the optimization
of the Jastrow, CSF and orbital parameters, the linear
method being generally more stable. The less computa-
tionally expensive perturbative method is eﬃcient only
for the CSF and orbital parameters. We have used the
linear method to simultaneously optimize the Jastrow,
CSF and orbital parameters, a much more eﬃcient pro-
cedure than alternating between optimizing the diﬀerent
kinds of parameters. The linear method is capable of
yielding not only ground state energies but excited state
energies as well [11].

Although the optimization is performed at the VMC
level, we have observed for the C2 molecule studied
here, as well as for other systems not discussed in the
present paper, that as more parameters are optimized the
DMC energies decrease monotonically, implying than the
nodal hypersurface also improves monotonically. In fact,
a sequence of trial wave functions consisting of multi-

conﬁguration expansions of increasing sizes multiplied by
a Jastrow factor, with all the Jastrow, CSF and orbital
parameters optimized together allows one to systemati-
cally reduce the ﬁxed-node error of DMC calculations for
the systems studied.

Future directions for this work include optimization of
the exponents of the one-electron basis functions (either
Slater or Gaussian functions), direct optimization of the
DMC energy and optimization of the geometry.

Anthony Scemama and Paola Gori-Giorgi for stimulat-
ing discussions and useful comments on the manuscript,
and Eric Shirley for having provided us with the code
for generating Hartree-Fock pseudopotentials. This work
was supported in part by the National Science Foun-
dation (DMR-0205328, EAR-0530301), Sandia National
Laboratory and DOE-CMSN. The calculations were per-
formed at the Cornell Nanoscale Facility and the Theory
Center.

17

Acknowledgments

We thank Claudia Filippi, Peter Nightingale, Sandro
Sorella, Richard Hennig, Roland Assaraf, Andreas Savin,

[1] B. L. Hammond, J. W. A. Lester, and P. J. Reynolds,
Monte Carlo Methods in Ab Initio Quantum Chemistry
(World Scientiﬁc, Singapore, 1994).

[2] M. P. Nightingale and C. J. Umrigar, eds., Quantum
Monte Carlo Methods in Physics and Chemistry, NATO
ASI Ser. C 525 (Kluwer, Dordrecht, 1999).

[3] W. M. C. Foulkes, L. Mitas, R. J. Needs, and G. Ra-

jagopal, Rev. Mod. Phys. 73, 33 (2001).

[22] M. W. Lee, M. Mella, and A. M. Rappe, J. Chem. Phys.

[23] C. J. Umrigar and C. Filippi, Phys. Rev. Lett. 94, 150201

2650 (2000).

112, 244103 (2005).

(2005).

[24] S. Sorella, Phys. Rev. B 71, 241103 (2005).
[25] C. J. Umrigar, J. Toulouse, C. Filippi, S. Sorella, and

R. Hennig, cond-mat/0611094.

[4] C. J. Umrigar, K. G. Wilson, and J. W. Wilkins, Phys.

[26] C.-J. Huang, C. Filippi, and C. J. Umrigar, J. Chem.

Rev. Lett. 60, 1719 (1998).

[5] C. J. Umrigar, K. G. Wilson, and J. W. Wilkins, in Com-
puter Simulation Studies in Condensed Matter Physics:
Recent Developments, edited by D. P. Landau, K. K.
Mon, and H. B. Sch¨uttler (Springer, Berlin, 1988).
[6] C. J. Umrigar, Int. J. Quantum Chem. 23, 217 (1989).
[7] C. Filippi and C. J. Umrigar, J. Chem. Phys. 105, 213

(1996).

[8] C.-J. Huang, C. J. Umrigar, and M. P. Nightingale, J.

Chem. Phys. 107, 3007 (1997).

Phys. 108, 8838 (1998).
[27] C. J. Umrigar, unpublished.
[28] A. D. G¨u¸cl¨u, G. S. Jeon, C. J. Umrigar, and J. K. Jain,

Phys. Rev. B 72, 205327 (2005).

[29] T. Kato, Comm. Pure Appl. Math. 10, 151 (1957).
[30] M. W. Schmidt and M. S. Gordon, Annu. Rev. Phys.

Chem. 49, 233 (1998).

[31] H. J. A. Jensen, in Relativistic and Electron Correlation
Eﬀects in Molecules and Solids, edited by G. L. Malli
(Plenum, New York, 1994), p. 179.

[9] M. Snajdr and S. M. Rothstein, J. Chem. Phys. 112,

[32] T. Helgaker, P. Jørgensen, and J. Olsen, Molecular

[10] F. J. G´alvez, E. Buend´ıa, and A. Sarsa, J. Chem. Phys.

4935 (2000).

115, 1166 (2001).

Electronic-Structure Theory (Wiley, Chichester, 2002).

[33] E. Dalgaard, Chem. Phys. Lett. 65, 559 (1979).
[34] E. Dalgaard and P. Jørgensen, J. Chem. Phys. 69, 3833

[11] M. P. Nightingale and V. Melik-Alaverdian, Phys. Rev.

(1978).

Lett. 87, 043401 (2001).

[35] B. O. Roos, P. R. Taylor, and P. E. M. Siegbahn, Chem.

[12] S. Fahy, in Quantum Monte Carlo Methods in Physics
and Chemistry, edited by M. P. Nightingale and C. J.
Umrigar (Kluwer, Dordrecht, 1999), NATO ASI Ser. C
525, p. 101.

[13] C. Filippi and S. Fahy, J. Chem. Phys. 112, 3523 (2000).
[14] D. Prendergast, D. Bevan, and S. Fahy, Phys. Rev. B 66,

155104 (2002).

Phys. 48, 157 (1980).

[36] F. Grein and T. C. Chang, Chem. Phys. Lett. 12, 44

[37] D. M. Ceperley and B. Bernu, J. Chem. Phys. 89, 6316

[38] E. Artacho and L. M. del Bosch, Phys. Rev. A 43, 5770

(1971).

(1988).

(1991).

[15] F. Schautz and S. Fahy, J. Chem. Phys. 116, 3533 (2002).
[16] F. Schautz and C. Filippi, J. Chem. Phys. 120, 10931

B 16, 3081 (1977).

[39] D. Ceperley, G. V. Chester, and M. H. Kalos, Phys. Rev.

[17] A. Scemama and C. Filippi, Phys. Rev. B 73, 241101

13, 340 (1974).

[18] S. Sorella, Phys. Rev. B 64, 024512 (2001).
[19] M. Casula and S. Sorella, J. Chem. Phys. 119, 6500

154110 (2005).

(2004).

(2006).

(2003).

[40] P. E. Cade and A. C. Wahl, At. Data Nucl. Data Tables

[41] L. Bytautas and K. Ruedenberg, J. Chem. Phys. 122,

[42] M. W. Schmidt, K. K. Baldridge, J. A. Boatz, S. T. El-
bert, M. S. Gordon, J. H. Jensen, S. Koseki, N. Mat-
sunaga, K. A. Nguyen, S. J. Su, et al., J. Comp. Chem.
14, 1347 (1993).

[20] M. Casula, C. Attaccalite, and S. Sorella, J. Chem. Phys.

121, 7110 (2004).

[21] X. Lin, H. Zhang, and A. M. Rappe, J. Chem. Phys. 112,

[43] E. Clementi and C. Roetti, At. Data Nucl. Data Tables

18

[44] T. Koga, H. Tatewaki, and A. J. Thakkar, Phys. Rev. A

Chem. Phys. 99, 2865 (1993).

14, 177 (1974).

47, 4510 (1993).

[45] W. J. Hehre, R. F. Stewart, and J. A. Pople, J. Chem.

Phys. 51, 2657 (1969).

[46] R. F. Stewart, J. Chem. Phys. 52, 431 (1970).
[47] CHAMP, a quantum Monte Carlo program written by C.
J. Umrigar, C. Filippi and coworkers, URL http://www.
tc.cornell.edu/~cyrus/champ.html.

[48] C. J. Umrigar, Phys. Rev. Lett. 71, 408 (1993).
[49] C. J. Umrigar,

in Quantum Monte Carlo Methods in
Physics and Chemistry, edited by M. P. Nightingale and
C. J. Umrigar (Kluwer, Dordrecht, 1999), NATO ASI
Ser. C 525, p. 129.

[50] J. B. Anderson, J. Chem. Phys. 63, 1499 (1975).
[51] J. B. Anderson, J. Chem. Phys. 65, 4121 (1976).
[52] P. J. Reynolds, D. M. Ceperley, B. J. Alder, and W. A.

Lester, J. Chem. Phys. 77, 5593 (1982).

[53] J. W. Moskowitz, K. E. Schmidt, M. A. Lee, and M. H.

Kalos, J. Chem. Phys. 77, 349 (1982).

[54] C. J. Umrigar, M. P. Nightingale, and K. J. Runge, J.

[55] The convergence in 2 iterations, mentioned near the end
of Ref. 23 was obtained using the correlated sampling
adjustment of adiag and the TU Hessian.

[56] C. Filippi, private communication.
[57] A. D. Becke, J. Chem. Phys. 98, 5648 (1993).
[58] P. J. Stephens, F. J. Devlin, C. F. Chabalowski, and M. J.

Frisch, J. Phys. Chem. 98, 11623 (1994).

[59] We used the code of E. Shirley to generate norm-
conserving Hartree-Fock pseudopotential according to
the construction of D. Vanderbilt, Phys. Rev. B 32, 8412
(1985).

[60] C. Filippi, J. Toulouse, and C. J. Umrigar, in preparation.
[61] Note that this estimate of the exact well depth diﬀers
from the one used in Ref. 25 where we used instead the
scalar-relativistic, valence-corrected estimate of Ref. 41
since calculations were performed with a relativistic pseu-
dopotential.

