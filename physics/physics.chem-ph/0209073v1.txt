2
0
0
2
 
p
e
S
 
9
1
 
 
]
h
p
-
m
e
h
c
.
s
c
i
s
y
h
p
[
 
 
1
v
3
7
0
9
0
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Optimal series representations for numerical path integral simulations

Cristian Predescu and J. D. Doll
Department of Chemistry, Brown University, Providence, Rhode Island 02912
(Dated: February 21, 2014)

By means of the Ito-Nisio theorem, we introduce and discuss a general approach to series repre-
sentations of path integrals. We then argue that the optimal basis for both “primitive” and partial
averaged approaches is the Wiener sine-Fourier basis. The present analysis also suggests a new
approach to improving the convergence of primitive path integral methods. Current work indi-
cates that this new technique, the “reweighted” method, converges as the cube of the number of
path variables for “smooth” potentials. The technique is based on a special way of approximating
the Brownian bridge which enters the Feynman-Ka¸c formula and it does not require the Gaussian
transform of the potential for its implementation.

PACS numbers: 02.70.Ss, 05.30.-d
Keywords: density matrix; path integrals; random series; Monte Carlo

I.

INTRODUCTION

0

{

B0

Bu, u

Numerical simulations based on the path integral ap-
proach have proved highly successful in the calculation
of thermodynamic properties for complex, many-body
quantum systems (see Refs. 1,2 and the cited bibliog-
raphy). Mainly the result of Feynman3 and Ka¸c,4 the
centerpiece of the theory is the fact that the density
matrix of a monodimensional system can be written as
the expectation value of a suitable functional of a stan-
. More precisely,
u, 0
1
dard Brownian bridge
≤
is a standard Brownian motion start-
if
ing at zero, then the Brownian bridge is the stochastic
process
i.e., a Brownian mo-
u
tion conditioned on B1 = 0.5 In this paper, we shall
reserve the symbol E to denote the expected value (av-
erage value) of a certain random variable against the un-
derlying probability measure of the Brownian bridge B0
u.
For a monodimensional canonical ensemble character-
ized by the inverse temperature β = 1/(kBT ) and made
up of identical particles of mass m0 moving in the po-
tential V (x), the Feynman-Ka¸c density matrix formula
reads:3,4,6

≥
Bu|

B1 = 0, 0

≤

≤

≤

u

{

}

}

{

}

1

β~2
m0

B0
u

du

,

ρ(x, x′; β)
ρf p(x, x′; β)

= E exp

β

x0(u) +

1
V

−

−

0
Z






(1)

where ρf p(x, x′; β) stands for the density matrix of a
similar free particle canonical ensemble, while x0(u) is
a shorthand for x + (x′
x)u.

s



h

i

Current research is focused on the development of ac-
curate, ﬁnite-dimensional approximations of the stochas-
tic integrals that appear in Eq. 1 and in related thermo-
dynamic expressions. The importance of Eq. 1 as given
here consists of the fact that the Brownian motion, hence
the Brownian bridge, are well understood mathematical
objects, which can be simulated by a variety of means.
The discussion in the present paper is based on the ran-
dom series technique as a general representation scheme
for the Brownian bridge B0
u. The approach is particularly
interesting, as it is directly related to the “path integral”

concept, and can be justiﬁed by means of the Ito-Nisio
theorem,7 whose statement is presented in Appendix A.
We consider a number of questions related to the ran-
dom series implementation of the Feynman-Ka¸c formula.
The so called primitive8 and partial averaging9 tech-
niques, developed initially for the Fourier path integral
(FPI) method,8 are generalized here for arbitrary se-
ries representations. Then, we address the question of
whether or not there exists a preferred basis within which
to implement the two techniques. We present strong ev-
idence suggesting that the fastest convergent series for
each method is the Wiener series on which the Fourier
path integral approach is based. Finally, we introduce a
new, non-averaging technique called the reweighted FPI
method in order to improve the convergence of primitive
FPI.

O

Motivated by the optimality of the Wiener series,
we undertake the task of establishing numerically the
asymptotic rate of convergence for the three FPI meth-
ods: the primitive FPI, the partial averaging FPI (PA-
FPI), and the reweighted FPI (RW-FPI). The asymptotic
rate of convergence of the primitive FPI was extensively
studied2,10 and is known to be
(1/n) for suﬃciently
smooth potentials. However, there are at present no an-
alytical or numerical studies concerning the exact asymp-
totic behavior of the PA-FPI method. For the particu-
lar case of the harmonic oscillator, it is known that the
(1/n3). (The reader
asymptotic rate of convergence is
should not mistake the full PA-FPI for the so called gra-
dient corrected PA-FPI, which was shown to converge as
(1/n2) in Ref. 10 for potentials having continu-
fast as
ous second-order derivatives). To cope with the numer-
ical diﬃculties encountered, we develop a Monte Carlo
technique which allows us to study the asymptotic be-
havior of the PA-FPI and RW-FPI methods, at least for
single-well potentials. With its help, we ﬁnd strong nu-
merical evidence suggesting that the asymptotic rate of
convergence for both PA-FPI and RW-FPI approaches is
(1/n3) for suﬃciently smooth potentials. To our knowl-
O
edge, RW-FPI thus becomes the most rapidly convergent
method among those that leave the original potential un-

O

O

changed.

The error analysis performed in Appendix E allows us
to introduce what we call “accelerated” estimators, which
are capable of improving the rate of convergence of any of
(1/nα+1)
the aforementioned methods from
(1/nα+2) for the
for the ﬁrst-order correction, and to
second-order correction, respectively. Although there is a
price paid in the form of an increase in the variance of the
respective estimators, the ﬁrst-order correction appears
suitable for general applications.

(1/nα) to

O

O

O

II. SERIES REPRESENTATIONS OF THE
BROWNIAN BRIDGE

where

The most general series representation of the Brown-
ian bridge is given by the Ito-Nisio theorem, the explicit
statement of which is presented in Appendix A. We begin
by assuming that we are given
}k≥1, a system of
functions on the interval [0, 1], which, together with the
constant function, λ0(τ ) = 1, make up an orthonormal
basis in L2[0, 1]. If Ω is the space of inﬁnite sequences
¯a

(a1, a2, . . .) and

λk(τ )

{

≡

∞

P [¯a] =

µ(ak)

Yk=1
is the (unique) probability measure on Ω such that the
ak are independent identically dis-
coordinate maps ¯a
tributed variables with distribution probability

→

then,

µ(ak ∈

A) =

1
√2π

ZA

2

e−z

/2 dz

u(¯a) d=
B0

akΛk(u), 0

u

1

≤

≤

∞

Xk=1

i.e., the right-hand side random series is equal in distri-
bution to a standard Brownian bridge. Therefore, the
notation B0
u(¯a) in (4) is appropriate and allows us to in-
terpret the Brownian bridge as a collection of random
functions of argument ¯a, indexed by u.

Using the Ito-Nisio representation of the Brownian

bridge, the Feynman-Ka¸c formula (1) takes the form

ρ(x, x′; β)
ρf p(x, x′; β)

=

dP [¯a] exp

x0(u) +

ZΩ

s

β~2
m0

∞

Xk=1

β

−

(cid:26)

0
Z

1
V

h

du

akΛk(u)
i
consider

.
(cid:27)

√2 cos(kπτ )

To reinforce the formula (5),
the func-
tions
}k≥1, which, together with the con-
stant function, make up a complete orthonormal system
of L2[0, 1]. Since

{

(2)

(3)

(4)

(5)

u

0
Z

√2 cos(kπτ )dτ =

2
π2

sin(kπu)
k

,

r

the Ito-Nisio theorem implies that

∞

B0
u

d
=

2
π2

r

ak

sin(kπu)
k

, 0

u

1,

≤

≤

Xk=1
so that the Feynman-Ka¸c formula (5) becomes

ρ(x, x′; β)
ρf p(x, x′; β)

=

dP [¯a] exp

β

x0(u) +

−

(cid:26)

akσk sin(kπu)
i

ZΩ
∞

Xk=1

1
V

,
(cid:27)

0
Z

du

h

2

(6)

(7)

σ2
k =

2β~2
m0π2

1
k2 .

Equation (7), derived here as a special case of the
Ito-Nisio theorem,
is the so-called Fourier path inte-
gral method.8 Historically, the sine-Fourier representa-
tion was one of the ﬁrst explicit constructions of the
Brownian motion.11 Following the mathematical litera-
ture, we shall call it the Wiener construction after the
name of its author, even though the original FPI method
was deduced using arguments other than those presented
here.

The “primitive” series representation method consists
of approximating the Brownian bridge by the n-th order
partial sum of the series (4). Thus,

P (x, x′; β)
ρn
ρf p(x, x′; β)

=

dP [¯a] exp

x0(u) +

ZΩ

s

β~2
m0

n

β

−

(cid:26)

0
Z

1
V

h

du

akΛk(u)
i

(8)

(cid:27)

Xk=1
An immediate question arises: What is the best choice
independent of potential,
1,
of functions λi(u),
such that (8) has the fastest convergence? Although the
phrase “independent of potential” carries ambiguities, in
the remainder of this section we shall provide a more
precise statement of the problem.

≥

i

We start with the observation that the Wiener basis is
the only basis for which both λi(u), and their primitives
Λi(u), i
1 are orthogonal. Indeed, let us notice that
by construction, Λi(0) = 0 for i

1 and that

≥

≥

Λi(1) =

λi(τ )λ0(τ )dτ = 0

i

∀

≥

1

1

0
Z

by orthogonality and the fact that λ0(τ ) = 1. The unique
basis, Λi(u), for which

1

0
Z
1

0
Z

Λi(τ )Λj(τ )dτ = 0,

i

= j

λi(τ )λj (τ )dτ = δij ,

i, j

1

Λi(0) = Λi(1) = 0,

∀

∀

∀

≥
1

i

≥

6
is made (up to a multiplication factor) of the eigenfunc-
tions of the Dirichlet problem:

1
2

−

∆Λi(u) = eiΛi(u), Λi(0) = Λi(1) = 0,

as follows from the associated Dirichlet variational prin-
ciple and the non-degeneracy of the spectrum of the “par-
ticle in a box problem”. But that basis is precisely the
Wiener basis.

The orthogonality of the primitives, λi(u), suggests
that the Wiener basis is (in a sense that will be made
clear below) optimal for the representation of the Brow-
nian bridge. Let us deﬁne

Sn

u (¯a) =

akΛk(u) and Bn

u (¯a) =

akΛk(u),

n

Xk=1

∞

Xk=n+1

as the n-th order partial sum in (4) and the correspond-
ing “tail” series, respectively. In terms of these sums, the
Brownian bridge is expressed as B0
u(¯a) = Sn
u (¯a).
Obviously, Bn
u and Sn
u are independent. Moreover, a
standard theorem regarding the sum of
independent
Gaussian distributed random variables shows that Bn
u
and Sn
u are again Gaussian distributed random variables
of mean zero and variances

u (¯a) + Bn

E(Bn

u )2 =

Λk(u)2

and E(Sn

u )2 =

Λk(u)2,

∞

Xk=n+1

respectively. By independence, we have the equality

n

Xk=1

u),

−

3

where we used the fact that the variance of the Brownian
bridge does not depend upon the series representation
and so, it can be computed by using any convenient basis
(e.g. the sine-Fourier basis).

A natural way of measuring the quality of the approx-
u(¯a) is the value of the time average

u (¯a)

B0

imation Sn
of the variances of the tails

≈

E(B0

u )2du =
Sn

E(Bn

u )2du =

1

0
Z

n

1

0
Z

u −
1

0

Z

h

u(1

u)

−

−

Λk(u)2

du.

(10)

Xk=1

i

Intuitively, the best approximating series is the one that
minimizes the functional (10) for each n (we shall show
that the answer is indeed a series). More clearly, we want
, the system of functions on the
to ﬁnd
interval [0, 1] which, together with the constant function
λ0(τ ) = 1, make up an orthonormal system in L2[0, 1]
and which realizes the maximum of the functional

λk(τ ); k

1, n

∈

{

}

n

1

G(λ1, . . . , λn) =

Λ2

k(u)du.

(11)

Xk=1 Z
√2 cos(kπτ )

0

}k≥1 together with the
Since the system
constant function make up a complete orthonormal sys-
tem of L2[0, 1], we may write

{

λk(u) =

√2 cos(lπu)

λk(τ )√2 cos(lπτ )dτ.

1

0
Z

E(B0

u)2 = E(Bn

u )2 + E(Sn

u )2 = u(1

(9)

Replacing this in (11), we obtain

G(λ1, . . . , λn) =

Λ2

k(u)du =

n

1

n

∞

∞

1

1

2

λk(τ )λk(θ) cos(lπτ ) cos(jπθ)dτ dθ

×

0

Xk=1 Z
sin(lπu)
l

1

2
π2

0
Z

Xk=1

Xl=1
n

j=1
X
1

0 Z
0
Z
1

Xk=1 Z

0 Z
0

sin(jπu)
j

du =

λk(τ )λk(θ)

2
π2

cos(lπτ ) cos(lπθ)
l2

dτ dθ,

(12)

{

√2 sin(kπτ )

where we used the fact that the system
}k≥1
is also orthonormal. From the theory of integral equa-
tions with symmetric kernels, we learn that the maxi-
mum of (12) is realized on the set of the n eigenfunctions
having the largest eigenvalues. Since the kernel is al-
ready in the series representation form, the maximum
k=1 1/(πk)2 and is attained on the
of our problem is
(orthonormal) functions

n

P

λk(u) = √2 cos(kπu) k

1, n.

∈

It follows that the Wiener representation is the unique
series for which the time-average of the variance of the

tail series reaches the minimum value of

1

0
Z

E(B0

u −

u )2du =
Sn

1
6 −

n

Xk=1

1
π2k2 .

(13)

However, there is a direct connection between the
asymptotic rate of convergence of the primitive method
and the quantity E(B0
u )2, a connection that is given
Sn
by formula (20) and is analyzed in Section IIIA. It allows
us to conclude that the Wiener representation is the best
series for general use in the primitive method.

u −

∞

Xl=1

∞

Xl=1

4

III.

IMPROVEMENTS IN THE PRIMITIVE

FOURIER PATH INTEGRAL TECHNIQUE

utilized, we shall call the aforementioned approaches the
PA-FPI and the RW-FPI methods, respectively.

In the primitive series approach [c.f. Eq.

(8)], the
“tail” portion of the Brownian bridge is simply discarded.
Rather than neglecting these terms entirely, it is possible
to include (approximately) their eﬀects through a num-
ber of approaches. One of these is known as the partial
averaging method.9 Another is a method we term the
reweighted method introduced in Section IIIB. We note
that in both methods the n-th order partial sum Sn
u is un-
changed, its distribution being identical to the primitive
method one. All methods which preserve the distribu-
tion of the partial sum Sn
u are referred to by the name of
the respective series. As such, if the sine-Fourier basis is

A. Partial Averaging Method

Developed initially for the Fourier path integral
method, the partial averaging technique can be deﬁned
for all series representations. The key is the indepen-
dence of the coordinates ak, which physically amounts
to choosing those representations for which the kinetic
energy operator is diagonal. Denoting by En the aver-
age over the coeﬃcients beyond the rank n, the partial
averaging formula reads:

P A(x, x′; β)
ρn
ρf p(x, x′; β)

=

dµ(a1) . . .

dµ(an) exp

β En

x0(u) +

R

Z

R

Z

−

(cid:26)

1
V

0
Z

h

β~2
m0

s

∞

Xk=1

du

akΛk(u)
i

(cid:27)

(14)

∞
As we mentioned before, the series
k=n+1 akΛk(u) is
again a Gaussian distributed variable of mean zero and
variance E(Bn
u )2. Using this together with the equal-

P

ity (9), it is not diﬃcult to show that formula (14) be-
comes

P A(x, x′; β)
ρn
ρf p(x, x′; β)

=

dµ(a1) . . .

dµ(an) exp

β

R

Z

R

Z

−

(cid:26)

0
Z

h

1
V u,n

x0(u) +

β~2
m0

s

n

Xk=1

akΛk(u)
i

du

,
(cid:27)

(15)

There is one property of the partial averaging method
of particular note: an application of Jensen’s inequality12
shows that

where

V u,n(x) =

1
2πΓ2

n(u)

exp

z2
2Γ2
n(u)

(cid:21)

−

(cid:20)

R

Z

V (x + z)dz,

with Γ2

n(u) deﬁned by

p

Γ2

n(u) =

β~2
m0 "

u(1

u)

−

−

n

Xk=1

Λk(u)2

.

#

(16)

(17)

ρn+1
P A (x, x′; β)
ρf p(x, x′; β)

=

dµ(a1) . . .

dµ(an)

dµ(an+1) exp

R

Z

R

Z

R

Z

R

Z

R

Z

dµ(a1) . . .

dµ(an) exp

β

dµ(an+1)

−

(cid:26)

R

Z

0
Z

dµ(a1) . . .

dµ(an) exp

R

Z

R

Z

β

−

(cid:26)

0
Z

β

−

(cid:26)

0
Z

1
V u,n+1

x0(u) +

h

1
V u,n+1

x0(u) +

β~2
m0

β~2
m0

s

s

n+1

Xk=1
n+1

Xk=1

1
V u,n

x0(u) +

h

h
β~2
m0

s

n

Xk=1

du

akΛk(u)
i

(cid:27)

du

akΛk(u)
i

≥

(cid:27)

(cid:27)

du

akΛk(u)
i
P A(x, x′; β)
ρn
ρf p(x, x′; β)

=

.

= (18)

5

Therefore, the sequence

P A(x, x′; β)
ρ1

P A(x, x′; β)
ρ0

. . .
(19)
is an increasing sequence that converges from below to
the true density matrix, ρ(x, x′; β).

P A(x, x′; β)
ρn

. . .

≤

≤

≤

≤

Let us now consider the problem of choosing the best
series representation for use within the partial averaging
framework. We notice that the sequence Γ2
n(u), given by
P A(x, x′; β)
formula (17), decreases monotonically while ρn
increases monotonically, as shown by formula (19).
In
fact, there is a connection between (17) and (19) in the
sense that the faster the Gaussian spread converges to
zero, the faster V u,n(x) converges to the original po-
P A(x, x′; β) increases to
tential V (x), and the faster ρn

ρ(x, x′; β). We note that this observation is general, in-
dependent of the potential V (x). Of course, one may try
P A(x, x′; β) directly, but then the best basis
to optimize ρn
will depend upon the potential, an undesirable computa-
tional feature. We thus conclude that the optimal basis
for the partial averaging method is the one for which the
time-average of Γ2
n(u) has the fastest decrease to zero,
i.e. the Wiener or Fourier basis. In this sense, the best
partial averaging method is the PA-FPI approach.

We now present one ﬁnal argument in favor of the
Wiener basis, an argument that will lead us to a new
computational approach, the reweighted FPI technique.
Remembering the primitive random series method (8)
and deﬁning

and

X∞(x, x′, ¯a; β) = exp

x0(u) +

β

−




0
Z

1
V

h

β~2
m0

s

∞

Xk=1

du

,

akΛk(u)
i

Xn(x, x′, ¯a; β) = exp

β

−

1
V

0
Z

h

x0(u) +

n

β~2
m0

s

akΛk(u)
i

Xk=1

du

,


















respectively, we have to the ﬁrst-order in β:

EnX∞(x, x′, ¯a; β)

Xn(x, x′, ¯a; β)

βXn(x, x′, ¯a; β)

≈

x0(u) +

−
β~2
m0

s

n

Xk=1

1

V
0 
Z


h



akΛk(u)
i

−

h

V u,n

x0(u) +

×

s

β~2
m0

n

Xk=1

akΛk(u)


i

du.



(20)

The rate of convergence for the primitive random series
method thus depends on the diﬀerence between V (x) and
V u,n(x), which in turn depends on the value of Γ2
n(u).
Therefore, to a ﬁrst approximation, the diﬀerences be-
tween the exact and the n-th order FPI density matrices
depend not on the detailed structure of the respective
tails, but rather on the spread of the tail series, Bn
u (¯a),
a quantity whose time average reaches a minimum for
the Wiener series. One can readily verify that the term
of order β vanishes for the partial averaging analog of
formula (20), an indication that the technique exactly
accounts for the extra spread of the paths induced by
the tail series.

B. Reweighting Method

Unlike the partial averaging method, the reweighting
technique attempts to account for the eﬀects of the tail
series in a way that does not involve modifying the as-
sociated potential energy. We shall work out the result

for the Wiener basis, noting that: (1) the approach can
be applied to any arbitrary representation, and (2) the
eﬃciency of the method will depend upon the speciﬁc
series selected. The basic idea is to replace Bn
u (¯a) by an-
other collection, Rn
, bn), which is supported by an
n-dimensional underlying probability space. We require
that:

u(b1,

· · ·

1. The variance at the point u of Rn

noted by Γ′2

n(u), be as close as possible to Γ2

u(b1,

· · ·

, bn), de-
n(u).

2. The variables Sn

, bn) be
independent and their sum have a joint distribution
as close to a Brownian bridge as possible.

, an) and Rn

u (a1,

u(b1,

· · ·

· · ·

· · ·

β~2
m0

, bn) =

n
k=1 bkΩk(u), with b1,

One possible candidate for our approach is to choose
u(b1,

Rn
, bn
identically distributed standard normal
independent
random variables. Condition 2 above is realized in
the Ito-Nisio theorem by insuring that the collection
}k≥1 is orthogonal, where ωk(u) is the
cos(kπu), ωk(u)

· · ·

P

q

{

derivative of Ωk(u). We shall enforce this condition by
choosing Ωk(u) = αn,k sin[(k+n)πu] where αn,k are some
constants yet to be determined. With the condition 1
above in mind, and by noticing that in the exact FPI
representation (7) the terms of the form sin[(k + nj)πu]
with j
, our intuition tells us
→ ∞
that a good candidate for αn,k is

1 “decouple” as n

≥

∞

α2

n,k =

2
π2

1
(k + jn)2 .

j=1
X
With this choice, the n-th order RW-FPI density matrix
is given by the formula

RW (x, x′; β)
ρn
ρf p(x, x′; β)

1
V

x0(u) +

=

dP [¯a] exp

β

−

(cid:26)

0
Z

akσn,k sin(kπu)
i

h

du

,
(cid:27)

where

σ2
n,k =

2β~2
m0π2 × 


∞

j=0 1/(k + jn)2,


The evaluation of the path weights σ2
Appendix D.

P

if 1

k

n

≤

≤

if n < k

2n.

≤

(22)
n,k is discussed in

Clearly, our choice of Rn

, bn) is not unique. For
u(b1,
a better understanding of the quality of the approxima-
tion, let us compare numerically:

· · ·

ZΩ

+

2n

Xk=1

1/k2,

n(u), the tail variance for the full FPI representa-

Γ2
tion and for the PA-FPI method,

n(u) =

Γ′2
for the RW-FPI method, and

2n
k=n+1 σ2

n,k sin(kπu)2, the tail variance

n(u) =

2n
k=n+1 σ2

Γ′′2
k sin(kπu)2, the tail variance
for the FPI method if it were computed without
reweighting (i.e. by simply considering the next n
Fourier terms).

P

P

Fig 1 plots the above variances for n = 9. We notice that
n(u) and Γ′2
Γ2
n(u) are indeed close, much closer than the
result obtained by simply expanding the primitive FPI
approach with a similar number of additional terms.

IV. ASYMPTOTIC CONVERGENCE OF THE
FPI TECHNIQUES

We say that a given method converges asymptotically
(1/nα) if the partition function, the density matrix

as

•

•

•

O

6

at each pair of points (x, x′), and their ﬁrst-order temper-
(1/nα). Generally
ature derivatives converge as fast as
speaking, the aforementioned quantities may have dif-
ferent asymptotic rates of convergence. However, if the
potential is smooth enough, our intuition says that this

O

Tail variances

2 ( )
/ 2( )
/ / 2( )

0.02

0.01

(21)

0.00

0.0

0.5

1.0

FIG. 1: A plot of the tail variances for the PA-FPI, RW-FPI,
and 2n-order primitive FPI for n = 9. Notice that the simple
inclusion of the next 9 terms within the primitive FPI is not
the optimal strategy.

is not true. For the case of the harmonic oscillator, we
shall only verify the convergence of the partition func-
tion. On the other hand, for numerical simulations it is
more convenient to compute the average energy of the
system with the help of the so called T-estimator, which
can solely be expressed as a functional of the diagonal
density matrix:

E
h

T
β =
i

−

∂
∂β

ln

ρ(x; β)dx

.

(23)

R
(cid:20)Z

(cid:21)

The above formula can be expressed as the statistical
average

R dx

E
h

T
β =
i

R

Ω dP [¯a]Xn(x, ¯a; β)ET
R dx
R
R

Ω dP [¯a]Xn(x, ¯a; β)

R

n (x, ¯a; β)

,

(24)

which can be evaluated by Monte Carlo integration. Us-
ing the notation

n

xn(¯a, u; β) =

akσk sin(kπu)

Xk=1
to denote the stochastic portions of the current path
truncated to the ﬁrst n terms, one easily deduces that
the T-estimator function for the primitive FPI method is

7

(25)

(26)

(27)

ET

n (x, ¯a; β) =

1
2β

+

0
Z

1
V [x + xn(¯a, u; β)] du +

1
V ′[x + xn(¯a, u; β)] xn(¯a, u; β) du,

1
2

0

Z

while for the PA-FPI method, one obtains

ET

n (x, ¯a; β) =

′
u,n[x + xn(¯a, u; β)] xn(¯a, u; β) du +

1
V u,n[x + xn(¯a, u; β)] du +

+

0

Z
′′
u,n[x + xn(¯a, u; β)] Γ2

1
V

n(u) du.

1
V

1
2

0
Z

1
2β

1
2

0

Z

By a simple integration by parts against the coordinate x, one may eliminate the second derivative of the potential
and obtain the following equivalent PA-FPI energy estimator:

ET

n (x, ¯a; β) =

1
V u,n[x + xn(¯a, u; β)] du +

+

′
u,n[x + xn(¯a, u; β)] xn(¯a, u; β) du +

1
2β

β
2

0

Z
1
V

′

0
(cid:26)Z

u,n[x + xn(¯a, u; β)] Γ2

n(u) du

1
V

′
u,n[x + xn(¯a, u; β)] du

.

(cid:27)

1
V

1
2

0
Z

0
(cid:27) (cid:26)Z

The T-estimator for the RW-FPI method has the same expression as the one for primitive FPI, except for the

redeﬁnition of the current path

xn(¯a, u; β) =

akσn,k sin(kπu).

2n

Xk=1

It is important to note that because of the way we have included the temperature dependence of the path distribution
in the above analysis, we have obtained directly the so called “virial” forms of the energy estimators. These virial
expressions have desirable variance properties10,13 and are generally preferred for precise Monte Carlo applications.
The special form (27) of the PA-FPI energy estimator is numerically advantageous since it does not require the
evaluation of the second derivatives of the averaged potential. Although we do not study it in this paper because it is
not a functional of the diagonal density matrix, the H-estimator for the PA-FPI method can similarly be put in the
simple form:

EH

n (x, ¯a; β) =

+ V (x) +

1
2β

~2β2
4m0 Z

1

1
(u

0
0 Z

−

τ )2V

′
u,n[x + xn(¯a, u; β)] V

′
τ,n[x + xn(¯a, τ ; β)] du dτ.

(28)

The equivalent H-estimator functions for the primitive FPI and RW-FPI approaches look formally the same, except
that the potential is no longer averaged. The H-estimator is thus properly deﬁned even for potentials that do not
have second-order derivatives. The reader should notice that the double integral appearing in (28) is really a sum of
products of monodimensional integrals. We chose this representation for symmetry purposes. The estimator is thus
the sum of the “classical” energy and a “quantum” correction term.

A. Partition functions for the harmonic oscillator

In Ref. 10, enough analytical evidence was presented
to suggest that the asymptotic behavior of the primitive
and partial averaging FPI methods is controlled at most
by the values of the second derivatives of the potential.
Here, we conjecture that this remains true of the RW-FPI
method, so that an analysis of the harmonic oscillator,
the simplest potential having a non-vanishing second-
order derivative, should provide a reliable guess of the
asymptotic rates for all “smooth” potentials (deﬁned here
as the potentials having continuous second-order deriva-
tives). Therefore, we shall study the asymptotic conver-

gence of the partition function for a one-dimensional par-
ticle of mass m0 = 1 moving in the quadratic potential
V (x) = x2/2. We also set ~ = 1 and β = 1.

The exact analytical expressions for the harmonic os-
cillator partition functions are derived in the Appendix B
for the three methods: primitive FPI, PA-FPI, and RW-
FPI, respectively. The partition functions of even and
odd orders have a slightly diﬀerent convergence behavior
1)n is 0 or 2 (see Appendix B).
according to whether 1
To avoid the appearance of certain oscillations in our
plots, we shall only compute the odd subsequence for the
RW-FPI method. Remember, however, that the 2n + 1-
th order RW-FPI approach uses in fact twice as many
points. To ensure fairness as far as the computational

(
−

−

eﬀort is concerned, we shall compare the 2n + 1-th order
RW-FPI results with those of the 4n + 2-th order primi-
tive FPI and PA-FPI approaches since, for a given order,
the former method uses twice as many path variables as
do the latter techniques. It is convenient to redeﬁne the
order of the RW-FPI method as being equal to the num-
ber of random variables used to parameterize the paths,
in this case: 4n + 2. In general,

RW (x, x′; β)
ρ2n
ρf p(x, x′; β)

1
V

x0(u) +

=

dP [¯a] exp

β

−

(cid:26)

0
Z

ZΩ

+

2n

Xk=1

akσn,k sin(kπu)
i

h

du

,
(cid:27)

(29)

where σn,k is given by formula (22) and is evaluated in
Appendix D.

Let us assume that we may expand the diﬀerence
Z(β) as the generalized power series
P r(β)

Z n

−

Z n

P r(β)

−

Z(β) =

c
nα

1 +

 

∞

Xk=1

ck
nk

,

!

= 0. For n large enough, it suﬃces to consider the

with c
approximation

Z n

P r(β)

Z(β)

−

c
nα

≈

1 +

(cid:16)

c1
n

.

(cid:17)

(30)

By passing to the subsequence 4n + 2 and taking the
ratios of consecutive diﬀerences, we obtain:

Z 4n−2
P r
Z 4n+2
P r

(β)
(β)

Z(β)
Z(β) ≈

4n + 2
2
4n

(cid:18)

−

(cid:19)

−
−

α 1 + c1/(4n + 2)
2)
1 + c1/(4n

.

−

Next, we take the logarithm and use the approximation
1/(1 + x)

x for the last term:

1

≈

−

log

1 +

(cid:18)

4

Z 4n−2
(β)
P r
Z 4n+2
P r

−
(β)

(β)

Z 4n+2
P r
Z(β)

−
1
(cid:18)

−

≈

(cid:19)

c1
4n2

.

1

(cid:19)

−

α log

1 +

+ log

(cid:18)

4n

2

(cid:19)

−

We expand the logarithms on the right-hand side of the
(1/n3)
above equation so that the error be of the order
and then multiply the resulting equation by n2
1/4 to
obtain

O
−

(n2

−

1/4) log

1 +

(cid:18)

Z 4n−2
(β)
P r
Z 4n+2
P r

−
(β)

nα + α/2

α

−

(β)

Z 4n+2
P r
Z(β)
−
4n + 2
4n

2 −

≈

(cid:19)
c1/4.

−
It is convenient to introduce the notation

DZ 4n+2
P r

(β) = Z 4n−2

(β)

P r

Z 4n+2
P r

(β)

−

and set

P r = (n2
αn

−

1/4) log

1 +

(cid:18)

DZ 4n+2
P r
(β)

Z 4n+2
P r

(β)

Z(β)

−

.

(cid:19)

8

Asymptotic rate for the quadratic potential

30

20

10

0

1

3

5

7

9

11

FIG. 2: A plot of the indices of convergence for the PA-FPI,
RW-FPI, and primitive FPI for the quadratic potential.

Since (4n + 2)/(4n

2)

1 for n large, we conclude

−

≈

αn

P r ≈

αn

α/2

−

c1
4

,

−

(31)

which shows that αn
P r should be asymptotically a straight
line whose slope gives the convergence order. Here, Z(β)
is the exact value of the partition function and the in-
dex P r is used to denote the primitive FPI method. Of
course, similar expressions can be written for the other
two methods identiﬁed by the indices RW and P A. For
general expressions which apply to any of the techniques,
we shall use the index M t.

Once the asymptotic order is established, we may de-
termine the value of the constant c by analyzing the slope
of the equation

cn
Mt ≈

cn + c/2 + cc1,

(32)

where

Mt = (4n + 2)α(n + 1/2)
cn

Z 4n+2
Mt

(β)

Z(β)

.

−

(cid:3)

(cid:2)

The asymptotic behavior implied by (32) can easily be
established by replacing n by 4n + 2 in equation (30).

Fig. 2 shows that the linear region predicted by our
analysis is quite rapidly reached for the harmonic os-
cillator. One easily notice that the PA-FPI and RW-
FPI methods have similar asymptotic behavior, while the
primitive FPI approach has a slower rate of convergence.
The asymptotic slopes are computed as the slope of
the line that best ﬁts the last [N/3] values, where N is
the number of data points calculated. We assume that
we computed enough points so that the last [N/3] are in
the asymptotic region. Euler least-square ﬁt gives then
the value

[N/3]

k kαk

αMt =

Mt −
k k2

k αk
(
P
−

Mt ·
k k)2

P

k k

,

[N/3]
P

(33)

P

P

6
9

Asymptotic rates for different estimators

30

20

10

0

3

where the summation is done over the last [N/3] data
points. Of course, the exact value for α is the limit as
of the right-hand side of the above formula.
N
For N = 12, (33) gives: αP r = 1.002, αP A = 3.007 and
αRW = 3.008, suggesting that the asymptotic behavior is
(1/n3) for the last two meth-

(1/n) for the ﬁrst, and

→ ∞

O
ods, respectively.

O

The constants c are calculated in a similar fashion and
the numerical values for N = 12 are: cP r = 0.049,
10−3, and cRW = 0.887, respectively.
cP A =
Therefore, the partial averaging method is superior to
the reweighted method in the sense that it has a smaller
convergence constant (smaller in modulus).

7.933

−

·

Theoretically, if we can compute the diﬀerence between
successive values of the partition function with suﬃcient
precision, we can improve the convergence of any of the
FPI methods by using better estimators. For ﬁrst-order,
the result can be obtained as follows: formula (30) shows
that

Z 4n+2
Mt

(β)

c
(4n + 2)α

−

(34)

(1/(4n+2)α+1)
converges to the exact answer as fast as
and therefore, the last equation is a better estimator as
far as the asymptotic behavior is concerned. Given that
the convergence exponent α is known, the constant c can
be approximately (but arbitrarily exactly as n
)
→ ∞
evaluated from the equation:

O

DZ 4n+2
Mt

(β)

(4n + 2)α

(4n

(4n + 2)α(4n

−

2)α
−
2)α ≈

c
(4n + 2)α

α
n

c

≈

Solving for c and replacing in (34), one ends up with the
ﬁrst-order corrected estimator

F Z 4n+2
Mt

(β) = Z 4n+2

Mt

(β)

DZ 4n+2
Mt

(β)

(35)

−

n
α

−

The second-order estimator can be derived by apply-
ing the ﬁrst-order correction to the ﬁrst-order estimator.
One easily computes:

SZ 4n+2
Mt

(β) = Z 4n+2

(β)

Mt

−

(2α + 1)n
α(α + 1)
n
α(α + 1)

DZ 4n+2
Mt

(β)

−

DZ 4n−2
Mt

(β) +

where

n2
α(α + 1)

h

DZ 4n−2
Mt

(β)

DZ 4n+2
Mt

(β)

(36)

−

i
estimator

is

The asymptotic

convergence of

this

O

(1/nα+2).
In principle, one can continue this process beyond
second-order. However, as we shall see in the Ap-
pendix E, such higher order estimators are of little practi-
cal value. To demonstrate the behavior of the corrected
estimators, we compute the convergence exponents for
the primitive FPI using the corresponding analog of equa-
tion (31). Fig. 3 clearly shows the diﬀerence in the rate
of convergence for the original and corrected estimators.

5

7

9

11

FIG. 3: A plot of the exponents of convergence for the three
Z-estimators. The method employed is primitive FPI as ap-
plied to the quadratic potential.

The numerical values are αZ = 1.002, αF Z = 1.997, and
αSZ = 2.958, demonstrating our predictions. From now
on, we shall refer to the original, unaccelerated estimator
as the zero-order estimator.

B. A numerical example: The quartic potential

As we said in the beginning of this section, for numer-
ical purposes it is convenient to study the convergence of
the T-method energy estimator in the virial form, which
can be computed by Monte Carlo integration. As we
explain below, the numerical study of the asymptotic be-
havior is not a computationally easy task, especially for
those methods that have rapid asymptotic convergence.
More explicitly, let us take a look at the following analog
of (31):

αn

Mt ≈

αMtn

αMt/2

−

c1,Mt
4

,

−

(37)

Mt = (n2
αn

−

1/4) log

1 +

(cid:18)

E4n−2

Mt −
E4n+2

E4n+2
Mt
E

Mt −

.

(cid:19)

P A −

E4n+2
P A

For the partial averaging method, we suggested that the
diﬀerence E4n+2
E decays to zero as fast as 1/n3. In
turn, the diﬀerences E4n−2
between consecu-
P A −
tive terms decay to zero as fast as 1/n4. It is thus clear
that faster rates of convergence of the method require
greater precision in the evaluation of the terms E4n+2
P A .
If we assume an independent sampling of the probability
density shown in formula (24), the error in the Monte
Carlo evaluation of E4n+2
P A /√N , where N is
the number of Monte Carlo sampling points and ∆E4n+2
is the standard deviation. This error should satisfy the

is ∆E4n+2

P A

P A

inequality:

∆E4n+2
P A |
|

/√N

E4n−2

P A −

E4n+2
P A |

≪ |
It follows that the number of Monte Carlo points nec-
essary to insure a given relative error for αP A scales at
n8 as a function of the number
least as badly as N
of Fourier coeﬃcients. The same is true for RW-FPI,
n4. We
while for the primitive FPI we only need N
emphasize that this scaling is related to our immediate
task of establishing the asymptotic rates of convergence
and is not an issue that would arise in typical numerical
applications.

∝

∝

The second observation we make is that the ratio

E4n−2
|

Mt −

E4n+2
Mt

/
|

∆E4n+2
Mt
|

|

increases as the temperature is dropped. Consequently,
we would like to conduct our model computations at low
temperature, where the quantum eﬀects are big enough
so that the diﬀerences between consecutive terms are sig-
niﬁcant. At high temperature, the classical limit is a
good approximation and these diﬀerences may be smaller
than the statistical errors we are able to achieve. We are
therefore forced to conduct our computations in the “un-
favorable” range of temperatures, and in general, we need
to study groundstate problems.

We hope this is enough rationale to justify the need for
a special Monte Carlo integration scheme capable of accu-
rately sampling the low temperature distributions with
good eﬃciency and low correlation, at least for certain
classes of simpler systems. One such scheme is discussed
in Appendix E, and it generally applies to the class of
single-well potentials.

For comparison purposes, we shall also compute the
T-estimator energies for the trapezoidal Trotter method.
Expressions similar to those presented here for the FPI
methods were deduced by Coalson14 and employed by
Mierke and Truhlar2 as the TT-FPI method. We shall
keep this name in the present paper, though, as deﬁned
here, the TT-FPI approach is not an FPI method because
the n-th order partial sum Sn
u is not the one for the prim-
itive FPI. The importance of this method consists of the
(1/n2)
fact that its asymptotic rate of convergence is
for smooth enough potentials, being the fastest primitive
method to date that leaves the potential unchanged.15
We do not present this scheme in the present paper and
for further information we refer the reader to the cited
literature.

O

The prototype system studied in this work is the quar-
tic potential V (x) = x4/2. We set ~ = 1 and m0 = 1 and
β = 10. The groundstate of the quartic potential was
evaluated by variational methods to be E0 = 0.530181,
while the average energy at the temperature correspond-
ing to β = 10 is E = 0.530183. We computed the average
12, corre-
energy for the sequence 4n + 2 with 1
sponding to the actual numbers of Fourier coeﬃcients
6, 10, . . . , 50. In these calculations, the number of points
employed in the Gauss-Legendre quadrature scheme was

≤

≤

n

10

Asymptotic rate for the quartic potential

-

-

-

-

30

20

10

0

2

4

6

8

10

12

FIG. 4: The straight lines drawn represent the linear least
square ﬁt for the last four data. Their slopes give the conver-
gence exponents for each method.

·

·

·
108 for TT-FPI, 5

108 Monte Carlo points for primitive
200. We used 1.25
108 points for RW-FPI, and
FPI, 2.5
·
109 points for PA-FPI calculations, respectively. The
2
values of R4n+2
P A were previously computed in a quarter of
these numbers during a “warm-up” period, but we con-
tinued to improve them during the main Monte Carlo
procedure. Table I of Appendix F summarizes the re-
sults of the computer evaluations. The diﬀerences be-
tween successive energy terms were computed with the
help of the estimator (E9). The errors were computed
with the help of the formulae (E3) for the average ener-
gies, and (E11) for the estimated diﬀerences.

αn−1

Fig 4 shows the behavior of the functions αn

Mt for the
four methods. Among the non-averaged methods, we re-
mark that the primitive FPI approach reaches its asymp-
totic behavior faster than the TT-FPI method, which in
turn reaches its asymptotic region faster than the RW-
FPI technique. This behavior is shown in Fig 5, which
plots the current slope αn
Mt . Although the RW-
Mt −
FPI method did not reach its ﬁnal asymptotic behav-
ior, the trend is clear. The computed convergence expo-
nents using the last four data points are: αP A = 3.082,
αRW = 2.917, αT T = 2.071, and αP r = 1.019. There-
fore, we conclude that the asymptotic convergence of the
(1/n2)
methods is
for TT-FPI, and
(1/n) for primitive FPI. Lastly, it
is worth comparing the convergence constants for the
PA-FPI and RW-FPI methods since they have the same
asymptotic convergence exponent. The numerical values
are cP A = 59.4 and cRW =
736.7, showing that the
PA-FPI method is over 10 times faster than the RW-
FPI method. This is in agreement with the observations
made for the partition function of the harmonic oscillator
in the previous section. The PA speed-up of the conver-
gence is important, especially with respect to minimizing
the number of path variables required in practical appli-
cations.

(1/n3) for PA-FPI and RW-FPI,

O

O

O

−

11

O

O

it is the best way of improving the asymptotic behavior of
the primitive FPI method (at the cost of computing the
Gaussian transform of the potential). The TT-FPI and
RW-FPI methods increase the order of convergence of
(1/n3), respectively,
(1/n2), and
the primitive FPI to
without increasing the variance of the corresponding esti-
mators. It should be noted that, unlike the complete par-
tial averaging approach, the reweighting method does not
require the Gaussian transform of the potential. While a
ﬁnal decision awaits detailed future studies, we anticipate
that this latter feature of the reweighting approach will
be beneﬁcial for applications where the Gaussian trans-
form is either formally ill-posed and/or computationally
diﬃcult to obtain. Finally, as discussed in Appendix E,
the ﬁrst and the second-order estimators also improve
the asymptotic convergence. Although both have larger
variances, the ﬁrst order estimator appears computation-
ally feasible since its variance decreases with the number
of Fourier coeﬃcients.

Acknowledgments

The authors acknowledge support from the National
Science Foundation through awards CDA-9724347, CHE-
0095053, and CHE-0131114. They also would like to
thank Professor D. L. Freeman and Dr. Dubravko Sabo
for continuing discussions concerning the present devel-
opments.

16 N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A.
M. Teller, and E. Teller J. Chem. Phys. 21, 1087 (1953).
17 M. Kalos and P. Whitlock, Monte Carlo Methods (Wiley-

Interscience, New York, 1986).

18 W. Feller, An Introduction to Probability Theory and its
Applications (John Wiley and Sons, New York, 1950),
Vol. 1, p. 324.

19 D. Sabo, D. L. Freeman, and J. D. Doll, J. Chem. Phys.

-
-

-
-

1
-

-

4

3

2

1

0

2

4

6

8

10

12

FIG. 5: The current slopes for each method should ideally
converge to 3 for PA-FPI and RW-FPI, 2 for TT-FPI, and 1
for primitive FPI.

V. CONCLUSIONS

In this paper, we have shown that the best series rep-
resentation (with respect to asymptotic convergence) for
use in Monte Carlo path integral methods is the Wiener
sine-Fourier series. Both the RW-FPI and TT-FPI meth-
ods are not series representations and we suggest that the
latter also falls in the category of reweighting techniques.
The partial averaging technique has the asymptotic con-
(1/n3), with a small convergence constant and
vergence

O

(2001).

3 R. P. Feynman, Rev. Modern Phys. 20, 367 (1948).
4 M. Kac, in Proceedings of the 2nd Berkeley Symposium
on Mathematical Statistics and Probability (University of
California, Berkeley, 1951) pp. 189-215.

5 R. Durrett, Probability: Theory and Examples, 2nd ed.

(Duxbury, New York, 1996), pp. 430-431.

(Academic, London, 1979).

7 S. Kwapien and W.A. Woyczynski, Random Series and
Stochastic Integrals: Single and Multiple (Birkh¨auser,
Boston, 1992), Chap. 2.5.

8 J. D. Doll and D. L. Freeman, J. Chem. Phys. 80, 2239

9 J. D. Doll, R. D. Coalson, and D. L. Freeman, Phys. Rev.

(1984).

Lett. 55, 1 (1985)

10 M. Eleftheriou, J. D. Doll, E. Curotto, and D. L. Freeman,

J. Chem. Phys. 110, 6657 (1998).

11 N. Wiener, J. of Math. and Phys. 2, 131 (1923).
12 See Probability: Theory and Examples (Ref. 5), p. 14.
13 D. L. Freeman and J. D. Doll, J. Chem. Phys. 80, 5709

(1984).

14 R. D. Coalson, J. Chem. Phys. 85, 926 (1986).
15 H. De Raedt and B. De Raedt, Phys. Rev. A 28, 3575

1 D. M. Ceperley, Rev. Mod. Phys. 67, 279 (1995).
2 S. L. Mierke and D. G. Truhlar, J. Chem. Phys. 114, 621

(1983).

6 B. Simon, Functional Integration and Quantum Physics

113, 2522 (2000).

APPENDIX A: ITO-NISIO THEOREM

is uniformly convergent almost surely and equal in distri-
bution with a standard Brownian bridge.

Theorem 1 (Ito-Nisio7) Let
thonormal basis in L2[0, 1] such that λ0(τ ) = 1, let

}k≥0 be any or-

λk(τ )

{

12

and let ¯a
ak}k≥1 be a sequence of independent iden-
tically distributed (i.i.d.) standard normal random vari-
ables. Then, the series

≡ {

Λk(u) =

λk(τ )dτ,

u

0
Z

akΛk(u)

∞

Xk=1

APPENDIX B: HARMONIC OSCILLATOR

The 2n-th order primitive FPI approximation of the partition function for an harmonic oscillator centered at the

origin has the expression

Z 2n

P r(β) =

dx

da1 . . .

da2nρn

P r(x, ¯a; β),

R

Z

R

Z

R

Z

where

where

ρn
P r(x, ¯a; β) =

(2π)−n exp

m0
2π~2β

r

2n

a2
k/2

exp

!

−




 −

Xk=1

β

m0ω2
2

1

2n

0 "

Z

Xk=1

x +

akσk sin(kπu)

du

.

By explicitly computing the integral over t and then completing the square, one obtains



2

#






ρ2n
P r(x, ¯a; β) =

(2π)−n exp

m0
2π~2β

r

2n

1
2

(−

ξkak +

βm0ω2x
ξk

1

−

(
−
kπ

2

1)k

βm0ω2
2

x2

exp

(−

βm0ω2σ2
k
ξ2
k

(cid:18)

1)k

1

−

(
−
kπ

Xk=1 (cid:20)

1
"

−

2n

Xk=1

(cid:21)

) ×
2

,

#)

(cid:19)

k = 1 + βm0ω2σ2
ξ2

k/2.

For use as a trial density in Monte Carlo simulations, it is convenient to replace the last factor by its limit n

ρ2n
tr (x, ¯a; β) =

m0
2π~2β

exp

m0ω
~ x2 tanh

−

(cid:20)

r

~ω
2

β

(cid:18)

(cid:19)(cid:21)

1

(2π)n exp

1
2

(−

2n

Xk=1 (cid:20)

ξkak +

βm0ω2x
ξk

1

−

(
−
kπ

2

1)k

)

(cid:21)

It is not diﬃcult to show that the trial densities for the primitive FPI and PA-FPI methods are identical (after
normalization) but we shall employ formula (B2) for the RW-FPI technique too. Practice shows that the penalty for
considering the last two approximations is minimal, while (B2) has some advantages with regard to the organization
of the computations.

To evaluate the partition functions for the primitive FPI approach, we integrate (B1) and obtain

Z 2n

P r(β) =

1
β~ω "

2n

Yk=1

1
ξk # (

1

−

2n

Xk=1

βm0ω2σ2
k
ξ2
k

(cid:18)

1)k

1

−

(
−
kπ

)

(cid:19)

−1/2

2

.

We leave for the reader the simple task of showing that the 2n-th order PA-FPI density matrix has the form

(B1)

:
→ ∞

.

(B2)

(B3)

(B4)

P A(β) = Z 2n
Z 2n

P r(β) exp

β2~2ω2
2π2

π2
6 −

 

"−

2n

Xk=1

1
k2

.

!#

The RW-FPI method’s partition function is similar to the one for the primitive FPI method and is given by

Z 2n

RW (β) =

1
β~ω "

2n

Yk=1

1
ξn,k # (

1

−

2n

Xk=1

βm0ω2σ2
ξ2
n,k

n,k

1)k

1

−

(
−
kπ

(cid:18)

)

(cid:19)

−1/2

2

,

where

ξ2
n,k = 1 + βm0ω2σ2

n,k/2.

13

(B5)

APPENDIX C: METROPOLIS SAMPLING

The Metropolis et al.16,17 sampling of a general prob-
Ω consists of generating a
ability density ρ(x) with x
∈
homogeneous Markov chain having the transition proba-
bility density

τ (x′

x) = A(x′
|

x)

[1

A(y

−

ZΩ

x)T (x′
|
x)]T (y
|

x) +
|
x)dy,
|

δ(x′

−

(C1)

where T (x′
x) is a trial transition probability density
|
which would generate an irreducible chain by itself,
δ(x′
x) is the Dirac function, and the acceptance prob-
−
ability A(x′

x) is given by the formula
|

A(x′

x) = min
|

x′)
ρ(x′)T (x
|
ρ(x)T (x′
x)
|

.

(cid:27)

1,

(cid:26)

This choice of A(x′
x) is one of the many possible which
|
satisfy the condition

A(x′

x)T (x′
|

x′)ρ(x′).
x′)A(x
x)ρ(x) = T (x
|
|
|

The last relation implies that the Markov chain of transi-
x′) satisﬁes the detailed bal-
tion probability density τ (x
|
ance condition

τ (x′

x′)ρ(x′),
x)ρ(x) = τ (x
|
|

R

which by integration against x′ and use of the normal-
Ω ρ(x)dx = 1 shows that ρ(x) is a
ization condition
stationary distribution of the transition kernel τ (x′
x).
|
Moreover, it can be shown that the associated Markov
chain is ergodic and that this implies that ρ(x) is the
unique stationary distribution.18 Let us consider the sta-
tionary sequence X0, X1, . . . with X0 having the distribu-
tion density ρ(x) and Xn having the conditional density
P (Xn = x′
x′). One can generate
Xn−1 = x) = τ (x
|
|
a sample x0, x1, . . . starting with any point x0, by the
Metropolis algorithm:

1. given xn, generate xn+1 from the probability den-

xn);
sity T (x
|

2. compute A(xn+1

xn);
|

3. generate a random number q uniformly on [0, 1];

4. if q

A(xn+1

≤
ject it.

xn), accept the move; otherwise, re-
|

For the expected value E(f ) =
Ω ρ(x)f (x)dx, Birkhoﬀ’s
ergodic theorem (Theorem 2.1, Chapter 6 of Ref. 5) guar-
antees that

R

1
n

n−1

Xk=0

f (Xi)

E(f )

→

(C2)

almost surely. In words, the probability that we may gen-
erate a sequence x0, x1, . . . by the Metropolis algorithm
such that

n−1

1
n

f (xi) 9 E(f )

Xk=0
is zero. In fact, if the variance of f (x) is ﬁnite

0(f ) = E(f
σ2

Ef )2 <

,
∞

−
a central limit theorem holds. Since the random vari-
ables f (X0) and f (Xn) have the same distribution, their
correlation coeﬃcient takes the form
E [f (X0)f (Xn)]
σ2
0(f )

rn(f ) =

E(f )2

−

Explicitly, let us introduce the notation

dx1 . . .

dxn−1τ (x′

x1) . . . τ (xn−1
|

x),
|

τ n(x′

x) =
|

with τ 0(x′

ZΩ
x) = δ(x′
|
E [f (X0)f (Xn)] =

−

dx

ZΩ
x) and τ 1(x′

x) = τ (x′
|
dx′ρ(x) τ n(x′

x). Then,
|

x)f (x)f (x′).
|

ZΩ

ZΩ
In practice, we can evaluate these expectations, and
therefore the correlation coeﬃcients, again with the help
of Birkhoﬀ’s theorem:

E [f (X0)f (Xn)] = lim
k→∞

f (xj)f (xj+n).

(C3)

1
k

k−1

j=0
X

In these conditions, it can be shown (Theorem 7.6,

Chapter 7 of Ref. 5) that

n−1
k=0 f (Xi)

−
σ(f ) n1/2

E(f )

ξ,

⇒

P

(C4)

14

where ξ has the standard normal distribution and

σ2(f ) = σ2

0(f )

1 + 2

"

∞

n=1
X

rn(f )

.

#

(C5)

If the sampling were independent, the correlation coef-
ﬁcients would vanish and we would recover the classical
central limit theorem. In practice however, the correla-
tion coeﬃcients are positive, many times having a slow
decay to zero and the independent sampling may be con-
sidered a fortunate case. Without entering the details,
we mention that there are two factors that contribute to
large correlation coeﬃcients: a) a strongly correlated pro-

posal T (x′
eﬃciency (or the acceptance ratio) is deﬁned as

x) and b) a low overall eﬃciency. The overall
|

Ac =

dx′

dxρ(x)A(x′

x)T (x′
|

x)
|

(C6)

ZΩ

ZΩ

and represents the fraction of moves accepted. Therefore,
if the overall eﬃciency has large enough values (Ac
≥
0.2), it is a good idea to use an independent proposal
from a trial probability ρtr(x).
ρ(x) and
f (x) is smooth enough, we may approximately relate the
correlation coeﬃcients to the overall eﬃciency as follows:
from the relation (C1), we easily compute

If ρtr(x)

≈

r1(f ) = 1

− R

Ω dx′
Ω dx[f (x)2
Ω dx′
R
R
R

−

Ω dx[f (x)2

−

f (x)f (x′)]ρ(x′)ρtr(x)A(x′

f (x)f (x′)]ρ(x′)ρ(x)

x)
|

,

where

A(x′

1,

x) = min
|

(cid:26)
approximation

ρ(x′)ρtr(x)
ρ(x)ρtr(x′)

.

(cid:27)

ρ(x′)ρtr(x)A(x′

Using
the
Ac ρ(x)ρ(x′),
the
r1(f )
Ac.
1
thought, one may argue that rn(f )
(1
formula (C5) takes the approximate value

≈
to
right-hand
In general, by a similar line of
Ac)n. The

x)
|
simpliﬁes

side

≈

−

≈

−

∞

2
Ac −

1

.

σ2(f )

σ2
0(f )

1 + 2

≈

"

Ac)k

= σ2

0(f )

(1

−

#

(cid:18)

Xk=1

(cid:19)
(C8)
Therefore, the bigger the acceptance probability, the
faster the convergence of the Monte Carlo procedure. In
the limit Ac = 1, we recover the independent sampling,
but a quick look at formula (C7) shows that in this case
ρtr(x) = ρ(x).

APPENDIX D: COMPUTATION OF THE PATH

WEIGHTS σ2

n,k FOR THE RW-FPI METHOD.

If n < k

2n, we have

σ2
n,k =

≤
2β~2
π2m0

∞

j=0
X

where

1
(k + jn)2 =

2β~2
π2m0

1
n2 h
(cid:18)

k

n

−
n

,

(cid:19)
(D1)

h(x) =

∞

1
(j + x)2 .

Hurwitz ζ-function, usually implemented by many math-
ematical libraries. Alternatively, h(x) can be evaluated
via the trivial identity

(C7)

h(x) = ζ(2)

2xζ(3)+3x2ζ(4)

x4

−

4j + 3x
(j + x)2j4 , (D2)

∞

j=1
X

−

where ζ(s) is the Riemann ζ-function

ζ(s) =

1
ns .

∞

n=1
X

≈

We have ζ(2) = π2/6, ζ(3)
1.2020569031596, and
ζ(4) = π4/90, with the last series in (D2) converging
quite fast. More precisely, the error in the evaluation
of h(x) committed by truncating the series to the ﬁrst n
1/n4
terms is easily seen to be smaller than
uniformly on the whole interval [0, 1], so that summation
over the ﬁrst 100 terms gives the value of h(x) with an
error of at most 10−8. This error is suﬃciently small for
our applications.

j>n 4/j5

P

≤

APPENDIX E: A SPECIALIZED MONTE CARLO
SCHEME

As suggested in Appendix C, the use of an indepen-
dent trial distribution in the Metropolis algorithm is a
good strategy provided that we are able to ﬁnd a good
approximation ρ4n+2
(x, ¯a; β) to the density we need to
sample in this case,

tr

j=1
X
Clearly, the values of the function h(x) are only needed
over the interval [0, 1] and they can be evaluated via the

ρ4n+2
Mt

(x, ¯a; β) =

(x, ¯a, β)

X 4n+2
Mt
(2π)2n+1

exp

1
2

 −

4n+2

Xk=1

a2
k

.

!
(E1)

The quartic potential

4 / 2

2

0
2

2

6

4

2

0
-2

-1

0

1

2

FIG. 6: A plot of the quartic potential (solid line) and its
best variational quadratic approximation. Here, m0 = 1 and
ω = 1.442.

This approximation may be taken to be the similar ex-
pression for a harmonic oscillator potential m0ω2(x
−
A)2/2, because we know how to generate an independent
sample of this. In order for the approximation to work
well for many of the single well potentials of interest, we
optimize the parameters ω and A to obtain a best ﬁt in
the sense of increasing the overall acceptance ratio. How-
ever, since we are analyzing groundstate problems, suf-
ﬁciently good approximations can be obtained from the
Ritz variational principle. Thus, we look for the parame-
ters ω and A which realize the minimum of the functional

E(ω, A) =

ψω,A ˆHψω,Adx,

R

Z

where

ψω,A(x) =

1/4

exp

m0ω
π~

(cid:16)

(cid:17)

−

h

m0ω
2~ (x

−

A)2

i

is the groundstate eigenfunction of the trial harmonic
potential and

ˆH =

~2

−

2m0

∆ + V (x)

is the Hamiltonian of the original single well potential.
By a translation of the reference system, we may assume
that the optimizing parameter A is zero. For the case of
the quartic potential V (x) = x4/2, the best optimizing
parameters are ω = 1.442 and A = 0. Fig. 6 plots the
quartic potential and its best quadratic approximation.
Rather than using the 4n + 2-th order probability den-
sity of the best harmonic reference as the trial density,
it is more convenient to use the slightly modiﬁed for-
mula (B2) of Appendix B. The advantage is that (B2)
is the exponential of a series. As such, if we generate
the vector (x, a0, ..., a4n+2) from the probability density
ρ4n+2
(x, ¯a; β) given by (B2), we can use the vectors of the
tr

15

≤

form (x, a0, ..., a4k+2) with k
n for the paths of smaller
length because it is clear that these vectors are drawn
from the distribution ρ4k+2
(x, ¯a; β). The time saved with
the generation of random numbers fully compensates the
slight decrease in the acceptance ratio. We use (B2) for
all FPI methods in the following examples.

tr

For PA-FPI and primitive FPI, there is another advan-
tage in using the trial density (B2). A large portion of
the computational time is spent with the construction of
the paths

4n+2

¯a4n+2(u; β) =

akσk sin(kπu),

Xk=1
especially for large n. However, if the trial probability
density (B2) is used, we can employ the recurrence for-
mula

¯a4n+2(u; β) = ¯a4n−2(u; β) +

akσk sin(kπu).

4n+2

Xk=4n−1

k

≤

≤

Therefore, the time necessary to construct all the paths of
length 4k + 2 with 1
n at a given point t scales like
(n2). This is especially important for
(n) instead of
O
the PA-FPI method, which has the fastest convergence
and for which a large number of Monte Carlo steps is
necessary to establish the asymptotic convergence rate.
Unfortunately, since the paths for RW-FPI are not series,
we cannot employ the same strategy for this method.

O

As shown in the Appendix C, the advantage of our
Monte Carlo strategy consists of the fact that it has low
correlation provided that the acceptance ratio is large.
To a ﬁrst approximation, the statistical error in the esti-
mation of the energy is [we employ the usual 2σ deﬁni-
tion for the error, corresponding to a conﬁdence interval
of 95.4%]

1/2

(cid:0)

=

2σ0

Errs

E4n+2
Mt

2
Ac −

E4n+2
Mt
√N
(cid:0)
E4n+2
where N is the number of Monte Carlo points, σ2
0
Mt
is the variance of the T-estimator function, and Ac is the
(cid:1)
acceptance ratio [see (C8)]. A more precise formula is
given by (C5):

(E2)

(cid:19)

(cid:18)

1

(cid:1)

(cid:1)

(cid:0)

,

∞

1/2

1 + 2

rk

E4n+2
Mt

Errs

E4n+2
Mt

=

2σ0

E4n+2
Mt
√N
(cid:0)

(cid:0)

(cid:1)

(cid:0)

(cid:1)

"

Xk=1

#
(cid:1)
(E3)
and we have shown in Appendix C how the correlation
coeﬃcients can be evaluated during the Monte Carlo pro-
cedure. However, we can use (E2) to ﬁnd the number of
steps after which the correlation becomes negligible. In
the case of the quartic potential, the acceptance ratio
was bigger than 0.6 for all simulations performed. Since
8
k=1 0.4k = 2.332, we may
2/0.6
safely truncate the series in (E3) to the ﬁrst eight corre-
P
lation coeﬃcients and we shall do so for all computations
concerning the quartic potential.

1 = 2.333

1 + 2

−

≈

Another important aspect in our computations is the
numerical evaluation of the one-dimensional time aver-
ages that are involved. This issue was extensively studied
by Sabo et. al.,19 who concluded that a Gauss-Legendre
quadrature in a number of points equal to three times the
number of Fourier coeﬃcients should suﬃce for most ap-
plications. We also employ the Gauss-Legendre quadra-
ture scheme, but in a number of points equal to four
times the maximum number of Fourier coeﬃcients com-
puted. Extensive computer observations show that the
relative error in the evaluation of the T-estimator func-

tion is smaller than 10−8 for the quartic potential. Of
course, for real-life applications we do not need such a
precision but here it is important to rule out any factor
likely to alter the asymptotic law of convergence.

Earlier in this section, we saw that the scaling of the
number of Monte Carlo points with the number of Fourier
coeﬃcients was dictated by the decay of the diﬀerences
E4n−2
. We
shall improve on this fact by directly evaluating these
diﬀerences with the help of a biased estimator. Deﬁne

, which we shall denote by DE4n+2

E4n+2
Mt

Mt −

Mt

and

Next, deﬁne

r4n+2
Mt

(x, ¯a; β) = X 4n−2

(x, ¯a; β)/X 4n+2

(x, ¯a; β)

Mt

Mt

R4n+2

Mt =

R dx

R

Ω dP [¯a]X4n+2(x, ¯a; β)r4n+2
Ω dP [¯a]X4n+2(x, ¯a; β)
R dx

Mt

(x, ¯a; β)

.

R
R

R

DET,Mt

4n+2 (x, ¯a; β) = ET,Mt

4n−2 (x, ¯a; β) r4n+2

Mt

(x, ¯a; β)/R4n+2

ET,Mt

4n+2 (x, ¯a; β).

Mt −

It is a simple exercise to show that

E4n−2

Mt −

E4n+2

Mt =

R dx

R

R

Ω dP [¯a]X4n+2(x, ¯a; β)DET,Mt
Ω dP [¯a]X4n+2(x, ¯a; β)

R dx

4n+2 (x, ¯a; β)

.

R
A biased estimator for the function (E6) can be constructed as follows: assume you are given a sequence (xk, ¯ak)

R

with 1

k

N , which samples the probability distribution (E1). At step k, compute

≤

≤

Rk,4n+2
Mt

=

r4n+2
Mt

(xj , ¯aj; β) and Errs(k, R4n+2

).

Mt

1
k

k

j=1
X

and construct the function

DET,Mt

k,4n+2(x, ¯a; β) = ET,Mt

4n−2 (x, ¯a; β) r4n+2

Mt

(x, ¯a; β)/Rk,4n+2

Mt

ET,Mt

4n+2 (x, ¯a; β).

−

Then, the biased estimator is deﬁned by the well-known recurrence formula

starting with DE0,4n+2

Mt

DEk,4n+2
Mt

=

(k

−
= 0. Clearly, DEk,4n+2

h

Mt

1)DEk−1,4n+2
Mt

+ DET,Mt

k,4n+2(xk, ¯ak; β)

k

converges to DE4n+2

Mt

as k gets large.

i .

The bias in (E8) is due to the fact that we do not use the exact value of R4n+2

Mt but its unbiased statistical estimator.

However, for large enough k, it is not diﬃcult to justify the estimate:

k,4n+2(x, ¯a; β)

DET,Mt
(cid:12)
(cid:12)
(cid:12)

DET,Mt

−

4n+2 (x, ¯a; β)
(cid:12)
(cid:12)
(cid:12)

/

(cid:12)
(cid:12)

It follows then that the error due to bias is at most

ET,Mt

4n−2 (x, ¯a; β)

r4n+2
Mt

(x, ¯a; β)

Errs(k, R4n+2
R4n+2
Mt

Mt

)

.

R4n+2
(cid:12)
Mt
(cid:12)

Errb(N, DE4n+2

Mt

) =

1
N

Xk=1 (cid:12)
(cid:12)

N

ET,Mt

4n−2 (xk, ¯ak; β)

(xk, ¯ak; β)

r4n+2
Mt
Rk,4n+2
(cid:12)
Mt
(cid:12)

Errs(k, R4n+2
Mt
Rk,4n+2
Mt

)

.

The total error is then obtained by also adding the statistical error computed with the help of the formula (E3):

Err(N, DE4n+2

) = Errs(N, DE4n+2

) + Errb(N, DE4n+2

).

Mt

Mt

Mt

16

(E4)

(E5)

(E6)

(E7)

(E8)

(E9)

(E10)

(E11)

In the present paper, we pre-computed a start value of R4n+2

using a quarter of the number of Monte Carlo points
during the warm-up step and then continued to improve the value in the main procedure. In these conditions, one
may argue that the error for the diﬀerence (E7) satisﬁes the inequality

Mt

Err(N, DE4n+2

)

Mt

Errs(N, DE4n+2

Mt

) + √5 E

E4n−2
Mt

≤

Errs(5N/4, R4n+2
R4n+2
Mt

Mt

)

,

(cid:0)(cid:12)
(cid:12)

(cid:12)
(cid:1)
(cid:12)

where

17

(E12)

E

E4n−2
Mt

=

(cid:0)(cid:12)
(cid:12)

(cid:1)

(cid:12)
(cid:12)

R dx

R

R

Ω dP [¯a]X4n−2(x, ¯a; β)

ET,Mt
Ω dP [¯a]X4n−2(x, ¯a; β)

R dx

4n−2 (x, ¯a; β)

(cid:12)
(cid:12)

.

(cid:12)
(cid:12)

R

R

Formula (E12) helps us explain why the use of the
biased estimator (E8) is advantageous. Had we directly
evaluated the diﬀerence
DE4n+2

Mt = E4n−2

E4n+2
Mt

(E13)

,

Mt −

the error would have been

(cid:0)

Mt

Err

both

+ Errs

= Errs

(x, ¯a; β)

(cid:1)
however

.
→ ∞

N, E4n−2
Mt

N, DE4n+2

(cid:0)
(cid:1)
r4n+2
that
Mt
4n+2 (x, ¯a; β) converge to 1 and 0,

N, E4n+2
.
Mt
(E14)
(cid:0)
(cid:1)
and
Notice
DET,Mt
respectively
as n
In turn, their variances (which control
the statistical errors) converge to zero. Clearly, this is
not the case for the variance of the T-method energy
estimator. More precisely, Table II presents strong
numerical evidence suggesting that the decay of their
(1/n2) and we expect
standard deviations is as fast as
this to be true for all smooth enough potentials. This
implies that for a ﬁxed but large number of Monte Carlo
points N , the error in (E11) has the asymptotic behavior

O

Err(N, DET,Mt
4n+2 )

const
n2√N

≈

(E15)

The importance of (E15) is twofold. First, it shows
that if the estimator (E9) is used, the scaling of the num-
ber of Monte Carlo samples with respect to the number
of Fourier coeﬃcients is now determined by the decay of
E4n+2
n6 for
E to zero. More precisely, we have N
n2
PA-FPI and RW-FPI, N
for primitive FPI.

∝
n4 for TT-FPI, and N

Mt −

∝

∝

Second, the errors of the estimators of order one and

two [see (35) and (36)] have the asymptotic behavior:

Err(N, F ET,Mt

4n+2 ) = Errs(N, ET,Mt

4n+2 ) +

Err(N, ET,Mt
4n+2 )

≈

1
α

const
n√N ≈

(E16)

and,

const
α(α + 1)√N (cid:20)

4n+2 ) = Errs(N, ET,Mt

4n+2 ) +

Err(N, SET,Mt
1

2α + 1
n

+

n

1

Errs(N, ET,Mt

−
4n+2 ) +

≈

2n2

+ 2 +

(n
4

1)2
−
const

≈

(cid:21)

·

α(α + 1)√N

This readily implies that the use of the estimators of
order one and two does not change the scaling of the
number of Monte Carlo points needed to achieve a given
error threshold for the estimated energy with the number
of Fourier coeﬃcients. The net result is an improvement
in the asymptotic behavior for the estimators of order
one and two. However, in the case of the second-order
estimator, we notice an increase in the variance of the es-
timator which may be quite large for practical purposes.
For the ﬁrst-order estimator there is no asymptotic in-
crease in the variance, which makes it more suitable for
practical applications. In fact, the ﬁrst-order estimator
may also be used for potentials that do not have con-
tinuous second-order derivatives but for which the decay
with the number of Fourier coeﬃcients implied by (E15)
can be replaced by the slower one

Err(N, DET,Mt
4n+2 )

const
n√N

.

≈

Finally, in the cases where it cannot be utilized as an en-
ergy estimator because of an unduly large variance, the
correction term brought in by the ﬁrst-order estimator is
still useful as a measure of how far the zero-order esti-
mator is from the true result.

The reader may work out the expression for the esti-
mator of order three and see that in this case the scaling
is changed. This explains our earlier assertion that the
estimators of order three or more are of little practical
value.

APPENDIX F: TABLES OF NUMERICAL
VALUES

(E17)

The following tables contain the numerical results de-
scribed in Section IVB. See that discussion for the details.

18

TABLE I: Average energies, estimated diﬀerences, and their statistical error for the quartic potential at β = 10. The variational
energy is 0.530183.

n

1

2

3

4

5

6

7

8

9

10

11

12

Average energies

E4n+2
P r
E4n+2
T T
E4n+2
RW
E4n+2
P A

E4n+2
P r
E4n+2
T T
E4n+2
RW
E4n+2
P A

0.302878 0.365234 0.401528 0.425003 0.441342 0.453379 0.462581 0.469834 0.475704 0.480548 0.484613 0.488071
0.343731 0.416263 0.454541 0.476808 0.490728 0.499978 0.506376 0.510972 0.514391 0.516994 0.518994 0.520602
0.351676 0.432846 0.473011 0.493918 0.505667 0.512786 0.517363 0.520451 0.522627 0.524201 0.525370 0.526247
0.596947 0.552843 0.541042 0.536268 0.533916 0.532629 0.531862 0.531383 0.531069 0.530854 0.530701 0.530593

DE4n+2
-.124981 -.062354 -.036316 -.023475 -.016353 -.012025 -.009205 -.007265 -.005872 -.004848 -.004062 -.003452
P r
DE4n+2
-.147346 -.072843 -.038307 -.022241 -.013929 -.009222 -.006401 -.0046052 -.003424 -.002593 -.002013 -.001589
T T
DE4n+2
RW -.162238 -.080976 -.040075 -.020896 -.011746 -.007111 -.004573 -.003100 -.002176 -.001575 -.001168 -.000886
DE4n+2
0.549021 0.044095 0.011781 0.004772 0.002347 0.001285 0.000763 0.000481 0.000316 0.000216 0.000151 0.000109
P A

Estimated diﬀerences

Statistical errors for energies(2σ)

0.000088 0.000084 0.000081 0.000080 0.000078 0.000078 0.000077 0.000077 0.000076 0.000076 0.000076 0.000076
0.000056 0.000057 0.000056 0.000055 0.000054 0.000054 0.000054 0.000053 0.000053 0.000053 0.000053 0.000053
0.000043 0.000042 0.000041 0.000040 0.000039 0.000038 0.000038 0.000038 0.000038 0.000037 0.000037 0.000037
0.000024 0.000023 0.000021 0.000020 0.000020 0.000020 0.000020 0.000019 0.000019 0.000019 0.000018 0.000018

Statistical errors for diﬀerences (2σ)

DE4n+2
0.032356 0.000304 0.000095 0.000055 0.000036 0.000026 0.000020 0.000016 0.000012 0.000010 0.000009 0.000007
P r
DE4n+2
0.054577 0.001325 0.000199 0.000092 0.000061 0.000046 0.000036 0.000030 0.000025 0.000021 0.000018 0.000015
T T
DE4n+2
RW 0.037799 0.001600 0.000333 0.000074 0.000045 0.000032 0.000025 0.000019 0.000016 0.000013 0.000011 0.000009
DE4n+2
0.004595 0.000080 0.000027 0.000014 0.000009 0.000007 0.000005 0.000004 0.000003 0.000003 0.000002 0.000002
P A

TABLE II: Standard deviations for r4n+2

(x, ¯a; β) and DET,M t

M t

4n+1 (x, ¯a; β) and their asymptotic convergence exponents α.

n

2

3

4

5

6

7

8

9

10

11

12

α

r4n+2
P r
DET,P r

1.771976 0.437892 0.226571 0.143267 0.099735 0.073744 0.056769 0.045052 0.036617 0.030341 0.025542 2.027
4n+2 0.907676 0.222962 0.116896 0.075168 0.052794 0.039381 0.030502 0.024296 0.019827 0.016464 0.013907 1.985

r4n+2
9.411364 1.149898 0.499554 0.326273 0.241282 0.187604 0.151356 0.125104 0.105345 0.090015 0.077867 1.822
T T
DET,T T
4n+2 5.259389 0.856299 0.342638 0.204763 0.148354 0.112764 0.089384 0.072996 0.060898 0.051628 0.044358 1.825

r4n+2
17.63636 1.953891 0.543819 0.324225 0.228415 0.171841 0.134647 0.108553 0.089442 0.074985 0.063776 1.961
RW
DET,RW
4n+2 8.421340 2.378073 0.393884 0.210005 0.142382 0.105825 0.082139 0.065720 0.053826 0.044884 0.037983 1.999

r4n+2
1.164360 0.309710 0.182490 0.122904 0.088704 0.067010 0.052355 0.041982 0.034380 0.028648 0.024221 2.100
P A
DET,P A
4n+2 1.596240 0.291506 0.142120 0.087909 0.060274 0.044039 0.033599 0.026465 0.021387 0.017629 0.014785 2.013

Primitive FPI

TT-FPI

RW-FPI

PA-FPI

