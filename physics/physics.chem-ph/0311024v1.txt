A generalized exchange-correlation functional: the Neural-Networks approach

Xiao Zheng, LiHong Hu, XiuJun Wang, and GuanHua Chen
Department of Chemistry, The University of Hong Kong, Hong Kong, China
(Dated: February 2, 2008)

A Neural-Networks-based approach is proposed to construct a new type of exchange-correlation
functional for density functional theory. It is applied to improve B3LYP functional by taking into
account of high-order contributions to the exchange-correlation functional. The improved B3LYP
functional is based on a neural network whose structure and synaptic weights are determined from
116 known experimental atomization energies, ionization potentials, proton aﬃnities or total atomic
energies which were used by Becke in his pioneer work on the hybrid functionals [J. Chem. Phys. 98,
5648 (1993)]. It leads to better agreement between the ﬁrst-principles calculation results and these
116 experimental data. The new B3LYP functional is further tested by applying it to calculate the
ionization potentials of 24 molecules of the G2 test set. The 6-311+G(3df,2p) basis set is employed in
the calculation, and the resulting root-mean-square error is reduced to 2.2 kcal·mol−1 in comparison
to 3.6 kcal·mol−1 of conventional B3LYP/6-311+G(3df,2p) calculation.

PACS numbers:

I.

INTRODUCTION

Density functional

theory (DFT) converts many-
electron problems into eﬀective one-electron problems.
This conversion is rigorous if the exact exchange-
It is thus important
correlation functional is known.
to ﬁnd the accurate DFT exchange-correlation function-
als. Much progress has been made, primarily due to
the development of generalized gradient approximation
(GGA) [1, 2, 3] and hybrid functionals [4]. Existing
exchange-correlation functionals include local or nearly
local contributions such as local spin density approxima-
tion (LSDA) [5] and GGA [1, 2, 3], and nonlocal terms,
for instance, exact exchange functional. Although these
local and nonlocal terms account for the bulk contribu-
tions to exact exchange-correlation functional, high-order
contributions are yet to be identiﬁed and taken into ac-
count. Conceding that it is exceedingly diﬃcult to de-
rive analytically the exact universal exchange-correlation
functional, we resort to an entirely diﬀerent approach.

An important methodology in the development of
exchange-correlation functionals has been established by
utilizing highly accurate experimental data to determine
exchange-correlation functionals [4, 6, 7]. Becke pio-
neered this semiempirical approach and determined the
three parameters in B3LYP functional [8] by a least-
square ﬁt to 116 molecular and atomic energy data [4].
Building upon this semiempirical methodology, we pro-

pose here a new approach which takes into account of
high-order contributions beyond the existing local and
nonlocal exchange-correlation functionals.

Since its beginning in the late ﬁfties, Neural Networks
has been applied to various engineering problems, such
as robotics, pattern recognition, and speech [9]. A neural
network is a highly nonlinear system, and is suitable to
determine or mimic the complex relationships among rel-
evant physical variables. Recently we developed a com-
bined ﬁrst principles calculation and Neural-Networks
correction approach to improve signiﬁcantly the accu-
racy of calculated thermodynamic properties [10]. In this
work, we develop a Neural-Networks-based approach to
construct the DFT exchange-correlation functional and
apply it to improve the results of the popular B3LYP cal-
culations. In Section II we describe the Neural-Networks-
based methodology and report our work leading to im-
proved B3LYP calculations. The results of the improved
B3LYP calculations and their comparisons to the exper-
imental data are given in Section III. Further discussion
is given in Section IV.

II. METHODOLOGY

B3LYP functional is a hybrid functional composed of
several local and nonlocal exchange and correlation con-
tributions, and can be expressed as

3
0
0
2
 
v
o
N
 
5
 
 
]
h
p
-
m
e
h
c
.
s
c
i
s
y
h
p
[
 
 
1
v
4
2
0
1
1
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

EXC = a0ESlater

X

+ (1 − a0)EHF

X + aX ∆EBecke

X

+ aCELY P

C

+ (1 − aC )EV MN

,

C

(1)

X

where ESlater
tional
tional, EBecke

X

[5, 11, 12], EHF
X

is the local spin density exchange func-
is the exact exchange func-
is Becke’s gradient-corrected exchange

functional [1], ELY P
is the correlation functional of Lee,
Yang and Parr [2], and EV MN
represents the correlation
functional proposed by Vosko, Wilk and Nusair [13]. The

C

C

values of its three parameters, a0, aX and aC , dictate
the contributions of various terms. They have been de-
termined via the least-square ﬁt to the 116 atomization
energies (AEs), ionization potentials (IPs), proton aﬃni-
ties (PAs) and total atomic energies (TAEs) by Becke [4],
and are 0.80, 0.72 and 0.81, respectively. Note that
aX <a0<aC. B3LYP functional explicitly consists of the
ﬁrst and second rungs of the Jacob’s ladder of density
functional approximation [14] and the partial exact ex-
change functional [4]. Being determined via the least-
square ﬁt to the 116 experimental data, B3LYP func-
tional includes implicitly the high-order contributions to
the exact functional such as those in the meta-GGA func-
tional [14]. These high-order contributions are averaged
over the 116 energy data [4], and their functional forms
or the values of a0, aX and aC are assumed invariant
for all types of atomic or molecular systems. Since high-
order contributions to the exact exchange-correlation en-
ergy are in fact system-dependent, their inclusion in
Eq. (1) leads to the system-dependence of a0, aX and
aC which is in turn dictated by the characteristic prop-
erties of the system. The challenge is to identify these
characteristic properties, and more importantly, to de-
termine their quantitative relationships to the values of
a0, aX and aC. These characteristic properties, termed
as the physical descriptors of the system, satisfy two cri-
teria: (1) they must be of purely electronic nature, since
the exact exchange-correlation functional is a universal
functional of electron density only; and (2) they should
reﬂect the electron distribution. After identifying these
physical descriptors that are related to the high-order
contributions to the exchange-correlation functional, we
employ Neural Networks to determine their quantitative
relationships to a0, aX and aC . Instead of being taken
as a system-dependent semiempirical functional, the re-
sulting neural network can be viewed as a generalized
universal exchange-correlation functional. It can be sys-
tematically improved upon the availability of new exper-
imental data.

Beyond the GGA, Perdew and co-workers [15] pro-
posed the meta-GGA in which the exchange-correlation
functional depends explicitly on the kinetic energy den-
sity of the occupied Kohn-Sham orbitals,

τ (r) =

|∇ψα(r)|2

(2)

1
2

occ

X
α

R

where ψα(r) is the wave function of an occupied Kohn-
Sham orbital α. The total kinetic energy of the elec-
τ (r)d3r, should relate closely to
tronic system, T =
the high-order contributions to B3LYP functional, and is
thus chosen as a key physical descriptor. The exchange-
correlation functional is uniquely determined by the elec-
tron density distribution ρ(r). ρ(r) can be expanded in
terms of the multipole moments. Being the zeroth-order
term of the expansion, the total number of electrons Nt
is recognized as a natural physical descriptor, and the
dipole and quadrupole moments of the system are se-
lected as another two descriptors. We use the magnitude

2

y + d2

x + d2

of the dipole moment D ≡ qd2
z for the dipole
descriptor, where di (i = x, y, z) is a component of the
dipole vector. For the quadrupole descriptor, we choose
Q ≡ qQ2
zz, where Qii (i = x, y, z) is a di-
agonal element of the quadrupole tensor. The exchange
functional accounts for the exchange interaction among
the electrons of the same spin. Spin multiplicity gS is
thus adopted as a physical descriptor as well.

xx + Q2

yy + Q2

Our neural network adopts a three-layer architecture
which consists of an input layer, a hidden layer and an
output layer [9]. The values of the physical descriptors,
gS, Nt, D, T and Q, are inputted into the neural network
at the input layer. The values of the modiﬁed a0, aX and
aC for each atom or molecule, denoted by ˜a0, ˜aX and
˜aC , are obtained at the output layer. Diﬀerent layers
are connected via the synaptic weights [9]. The neural
network structure such as the number of hidden neurons
at the hidden layer is to be determined.

We take the 116 experimental energies that were em-
ployed by Becke [4] as our training set, and they are
utilized to determine the structure of our neural network
and its synaptic weights. Instead of the basis-set-free cal-
culations carried out by Becke [4], we adopt a Gaussian-
type-function (GTF) basis set, 6-311+G(3df,2p), in our
calculations. Geometry of every molecule is optimized di-
rectly using conventional B3LYP/6-311+G(3df,2p). The
values of T , D and Q are obtained at the same level of
calculations. Besides gS, Nt, D, T and Q, a bias is in-
troduced as another input and its value is set to 1 in all
cases. The values of ˜a0, ˜aX and ˜aC vary from system
to system, and are used to modify the B3LYP functional
for each atom or molecule. The modiﬁed B3LYP func-
tional is subsequently used to evaluate its AE, IP, PA, or
TAE. The resulting energies are then compared to their
experimental counterparts, and the comparison is used
to tune the synaptic weights of our neural network. The
process is iterated until the diﬀerences between the cal-
culated and measured energies are small enough for all
the molecules or atoms in the training set, and the neural
network is then considered as converged, i.e., its synaptic
weights are determined.

The structure and synaptic weights of our neural net-
work are optimized via a cross-validation technique [16].
The 116 energy values are randomly partitioned into six
subsets of equal size. Five of them are used to train the
weights of the neural network, and are termed as the
estimation subset. The sixth is used to compare the pre-
diction of current neural network, and is termed as the
validation subset. This procedure is repeated six times in
rotation to assess the performance of current neural net-
work. The number of neurons in the hidden layer is varied
from 1 to 5 to decide the optimal structure of the neural
network. We ﬁnd that the hidden layer containing two
neurons yields the best overall results, i.e., the minimal
root-mean-square (RMS) errors and the minimal RMS
diﬀerence between the estimation and validation subsets
(less than 0.2 kcal·mol−1). Minimizing the RMS diﬀer-

3

   B3LYP 
  with new
 parameters

   AE, IP,
 PA or TAE

Input layer (i)

Hidden layer (j)

Output layer (k)

Spin Multiplicity

x1

{Wji}

{W’kj}

Number of Electrons

x2

Dipole Moment

x3

Kinetic Energy

x4

Quadrupole Moment

x5

Bias

y0

Bias

x0

y1

y2

a0

aX

aC

FIG. 1: Architectural graph of our neural network and ﬂow chart of our calculations

ence between the estimation and validation subsets helps
ensure the predictive capability of our neural network.
Therefore, the 6-3-3 structure is adopted for our neural
network, see Fig. II. The input values at the input layer,
x1, x2, x3, x4, x5 and x0 are gS, Nt, D, T , Q and bias,
respectively. Except for the bias, input values are scaled
before being inputted into the neural network as follows,

xi =

(C1 − C2)·pi + C2·pmax
i
− pmin
pmax
i
i

− C1·pmin

i

(3)

i

and pmin

where C1 and C2 are two constants between 0 and 1 that
set the upper and lower boundaries, pi and xi are the val-
ues of the physical descriptor before and after the scaling,
and pmax
are the maximum and minimum val-
i
ues of the descriptor (i=1-5). In our neural network we
adopt C1 = 0.9 and C2 = 0.1, therefore all the inputs
xi are within the interval [0.1, 0.9]. The biases are in-
troduced at both the input and hidden layers and their
value are set to unity. The synaptic weights {Wji} con-
nect the input layer {xi} and the hidden neurons {yj},
and {W ′
kj} connect the hidden neurons and the output.
The corrected ˜a0, ˜aX and ˜aC are given at the output

layer, and they are related to the input {xi} as

˜a0 = Sigb{[

W ′

1j ·Siga(

Wjixi)] + W ′

10} (4)

˜aX = Sigb{[

W ′

2j ·Siga(

Wjixi)] + W ′

20} (5)

˜aC = Sigb{[

W ′

3j ·Siga(

Wjixi)] + W ′

30} (6)

2

2

2

X
j=1

X
j=1

X
j=1

5

5

5

X
i=0

X
i=0

X
i=0

1

where Siga(v) =
1+exp(−αv) and Sigb(v) = βtanh(γv),
and α and γ are the parameters that control the switch
steepness of Sigmoidal functions Siga(v) and Sigb(v).
An error back-propagation learning procedure [17] is used
to optimize the values of Wji and W ′
kj (i=0-5, and j=0-2.
Zero indices are referred to the biases).

III. RESULTS

TABLE I: Descriptors and Parameters of Training Set

No. Name

gS

Nt

1
2
3

H2
LiH
BeH

1
1
2

2
4
5

D
(DB)
0.00
5.72
0.29

T

(a.u.)

1.83
8.98
16.73

Q
(DB·˚A)
3.35
10.59
14.41

˜a0

˜aX

˜aC

0.779
0.788
0.767

0.726
0.737
0.722

0.906
0.911
0.927

Descriptors and Parameters of Training Set continued...

No. Name

gS

Nt

D
(DB)

T

(a.u.)

Q
(DB·˚A)

˜a0

˜aX

˜aC

4

4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62

CH
2
CH2(3B1)3
CH2(1A1)1
2
CH3
1
CH4
3
NH
2
NH2
1
NH3
2
OH
1
OH2
1
FH
1
Li2
1
LiF
1
C2H2
1
C2H4
1
C2H6
2
CN
1
HCN
1
CO
2
HCO
H2CO
1
H3COH 1
N2
1
H2NNH2 1
2
NO
O2
3
HOOH 1
1
F2
CO2
1
SiH2(1A1)1
SiH2(3B1)3
2
SiH3
1
SiH4
2
PH2
1
PH3
1
SH2
1
ClH
1
Na2
3
Si2
1
P2
3
S2
1
Cl2
1
NaCl
1
SiO
1
SC
3
SO
2
ClO
1
FCl
1
Si2H6
CH3Cl
1
H3CSH 1
1
HOCl
1
SO2
2
H
1
He
2
Li
1
Be
2
B
3
C

7
8
8
9
10
8
9
10
9
10
10
6
12
14
16
18
13
14
14
15
16
18
14
18
15
16
18
18
22
16
16
17
18
17
18
18
18
22
28
30
32
34
28
22
22
24
25
26
34
26
26
26
32
1
2
3
4
5
6

1.48
0.61
1.81
0.00
0.00
1.54
1.82
1.53
1.68
1.91
1.85
0.00
6.22
0.00
0.00
0.00
1.38
3.04
0.10
1.67
2.41
1.69
0.00
1.93
0.14
0.00
0.00
0.00
0.00
0.09
0.07
0.00
0.00
0.52
0.57
1.00
1.12
0.00
0.00
0.00
0.00
0.00
8.74
3.21
1.99
1.55
1.33
0.91
0.00
1.95
1.55
1.55
1.71
0.00
0.00
0.00
0.00
0.00
0.00

41.17
45.29
44.98
49.28
53.68
58.63
63.23
68.24
79.89
85.35
105.36
16.62
116.17
101.73
111.54
121.45
111.45
117.02
135.49
140.01
145.41
155.46
132.87
152.86
155.35
178.05
187.79
229.74
246.26
300.05
300.26
306.45
312.63
353.40
360.14
411.71
466.75
344.67
625.88
744.63
866.42
994.10
662.67
403.18
468.48
518.11
579.64
607.86
671.93
549.86
494.08
585.49
655.49
0.50
2.87
7.43
14.59
24.57
37.76

12.51
12.98
13.80
13.80
14.70
10.93
12.10
13.14
10.08
11.07
9.13
22.29
10.65
20.75
23.65
26.44
18.85
19.43
19.13
19.86
20.69
22.83
18.79
22.79
18.57
17.78
19.53
16.40
28.63
27.42
27.00
28.06
28.84
26.07
27.16
25.00
22.63
33.68
46.53
45.05
44.07
42.53
30.03
30.97
33.25
31.14
30.57
29.71
55.02
33.84
36.34
30.94
41.21
2.41
1.87
13.87
13.05
12.61
11.06

0.771
0.752
0.789
0.771
0.789
0.753
0.773
0.791
0.774
0.791
0.792
0.786
0.797
0.794
0.796
0.798
0.779
0.797
0.795
0.782
0.799
0.800
0.795
0.800
0.781
0.766
0.799
0.800
0.804
0.802
0.773
0.790
0.803
0.791
0.805
0.806
0.807
0.807
0.796
0.817
0.804
0.821
0.817
0.809
0.810
0.789
0.803
0.813
0.818
0.813
0.812
0.813
0.817
0.760
0.779
0.764
0.783
0.766
0.749

0.726
0.714
0.737
0.727
0.737
0.715
0.729
0.739
0.729
0.740
0.740
0.735
0.746
0.743
0.746
0.748
0.736
0.747
0.744
0.739
0.748
0.750
0.744
0.750
0.737
0.727
0.748
0.749
0.754
0.753
0.735
0.747
0.754
0.749
0.756
0.757
0.758
0.758
0.760
0.771
0.768
0.775
0.772
0.761
0.763
0.752
0.762
0.766
0.772
0.766
0.765
0.766
0.771
0.714
0.725
0.720
0.731
0.722
0.710

0.927
0.939
0.909
0.927
0.908
0.939
0.927
0.909
0.927
0.909
0.908
0.911
0.911
0.910
0.910
0.911
0.928
0.911
0.910
0.928
0.911
0.911
0.909
0.911
0.927
0.939
0.909
0.909
0.912
0.913
0.940
0.930
0.913
0.930
0.913
0.914
0.914
0.914
0.942
0.919
0.942
0.920
0.919
0.915
0.916
0.941
0.931
0.915
0.920
0.916
0.916
0.916
0.918
0.925
0.906
0.927
0.909
0.927
0.939

Descriptors and Parameters of Training Set continued...

No. Name

gS

Nt

D
(DB)

T

(a.u.)

Q
(DB·˚A)

˜a0

˜aX

˜aC

5

N
63
O
64
F
65
Ne
66
67
Na
68 Mg
Al
69
Si
70
P
71
S
72
Cl
73
Ar
74
PH
75
SH
76
H+
77
He+
78
Li+
79
Be+
80
B+
81
C+
82
N+
83
O+
84
F+
85
Ne+
86
Na+
87
88 Mg+
Al+
89
Si+
90
P+
91
S+
92
Cl+
93
Ar+
94
CH4
95
+
NH3
96
OH+
97
+
OH2
98
FH+
99
+
100
SiH4
101 PH+
+
102 PH2
+
103 PH3
SH+
104
SH2
105
106
SH2
107 ClH+
108 C2H2
109 C2H4
110 CO+
111 N2
112 N2
113 O2
114 P2
115
S2
+
116 Cl2
117 FCl+
SC+
118
+
119 H3

4
3
2
1
2
1
2
3
4
3
2
1
3
2
1
2
1
2
1
2
3
4
3
2
1
2
1
2
3
4
3
2
2
2
3
2
2
2
2
1
2
3
+(2B1)2
+(2A1)2
2
2
2
2
+(2Σg)2
+(2Πu)2
+
2
2
2
2
2
2
1

+

+

+

+

+

7
8
9
10
11
12
13
14
15
16
17
18
16
17
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
9
9
8
9
9
17
15
16
17
16
17
17
17
13
15
13
13
13
17
29
31
33
25
21
2

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.40
0.77
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.01
0.00
2.02
2.12
2.36
1.21
0.62
0.80
0.35
1.08
1.37
0.54
1.53
0.00
0.00
2.73
0.00
0.00
0.00
0.00
0.00
0.00
1.70
0.52
0.00

54.49
75.09
99.53
128.66
161.83
199.57
241.93
289.39
340.77
397.58
459.07
526.13
346.54
403.69
0.00
1.99
7.22
14.26
24.25
37.34
53.96
74.46
98.93
127.90
161.63
199.29
241.71
288.61
340.42
397.23
458.63
525.55
52.90
67.71
79.19
84.52
104.35
310.53
346.56
353.00
359.87
404.05
411.17
411.00
466.10
100.59
110.31
135.32
132.02
130.77
180.07
741.28
869.18
997.85
610.61
469.27
3.06

9.68
9.06
8.28
7.55
19.78
21.87
26.04
25.10
23.66
22.91
21.73
20.36
24.90
23.98
0.00
0.60
0.70
4.99
6.11
6.39
6.17
5.82
5.67
5.42
5.09
10.60
13.08
15.64
16.27
16.07
16.14
15.13
8.23
7.32
6.24
6.77
6.01
18.93
17.05
17.79
18.05
16.69
17.29
12.72
16.58
14.82
15.16
12.48
13.12
13.95
13.06
33.44
33.65
33.40
22.93
23.20
1.50

0.731
0.752
0.772
0.791
0.779
0.796
0.784
0.770
0.755
0.776
0.794
0.807
0.774
0.793
0.777
0.759
0.779
0.763
0.782
0.766
0.748
0.731
0.752
0.773
0.791
0.778
0.796
0.784
0.770
0.756
0.777
0.795
0.770
0.771
0.754
0.774
0.775
0.789
0.788
0.803
0.790
0.776
0.793
0.789
0.794
0.777
0.779
0.781
0.778
0.777
0.783
0.808
0.811
0.814
0.803
0.797
0.779

0.698
0.713
0.727
0.738
0.735
0.746
0.741
0.733
0.722
0.738
0.751
0.759
0.737
0.750
0.723
0.714
0.725
0.717
0.729
0.720
0.710
0.698
0.713
0.728
0.739
0.734
0.745
0.740
0.733
0.723
0.739
0.752
0.725
0.725
0.715
0.729
0.730
0.746
0.745
0.753
0.747
0.738
0.750
0.744
0.751
0.732
0.734
0.736
0.733
0.731
0.738
0.767
0.771
0.773
0.761
0.754
0.725

0.946
0.938
0.926
0.907
0.928
0.911
0.929
0.940
0.947
0.940
0.929
0.913
0.940
0.930
0.905
0.925
0.905
0.926
0.907
0.926
0.938
0.946
0.938
0.926
0.907
0.927
0.909
0.928
0.940
0.947
0.940
0.929
0.926
0.926
0.939
0.926
0.926
0.929
0.928
0.911
0.928
0.940
0.929
0.925
0.929
0.927
0.926
0.927
0.926
0.924
0.926
0.932
0.932
0.933
0.930
0.929
0.905

6

Descriptors and Parameters of Training Set continued...

No. Name

gS

Nt

D
(DB)

T

(a.u.)

Q
(DB·˚A)

˜a0

˜aX

˜aC

+

120 C2H3
+
121 NH4
122 H3O+
+
123
SiH5
+
124 PH4
125 H3S+
126 H2Cl+

1
1
1
1
1
1
1

14
10
10
18
18
18
18

0.98
0.00
0.00
1.30
0.00
1.48
1.90

107.01
72.98
90.43
317.11
366.99
418.61
473.92

15.19
7.54
7.32
19.69
18.64
17.84
16.99

0.794
0.789
0.789
0.803
0.804
0.806
0.807

0.743
0.736
0.737
0.754
0.754
0.756
0.758

0.909
0.906
0.906
0.911
0.911
0.912
0.912

gS, Nt, D, T and Q of each molecule or atom in
the training set are listed in Table I. The conventional
B3LYP/6-311+G(3df,2p) calculations are carried out to
evaluate AEs, IPs, PAs or TAEs of the molecules and
atoms in the training set, and the results are given in
Tables II, III, IV and V, respectively. Compared to the
experimental data, the RMS deviations are 3.0, 4.9, 1.6
and 10.3 kcal·mol−1 for AEs, IPs, PAs and TAEs, respec-
tively. The physical descriptors of each molecule or atom
in the training set are inputted to the neural network,
and the ˜a0, ˜aX and ˜aC from the output layer are used
to construct the B3LYP functional which is used subse-
quently to calculate AE, IP, PA or TAE. These values
are then compared to the 116 energy values in the train-
ing set, and the synaptic weights {Wji} and {W ′
kj } are
tuned accordingly. The ﬁnal values of synaptic weights
are shown in Tables
In Table VIII we
III and III.
list the derivatives of ˜a0, ˜aX and ˜aC with respect to xi
(i=0-5). The magnitude of a derivative reﬂects the in-
ﬂuence on ˜a0, ˜aX and ˜aC of the corresponding physical
descriptor. The larger the magnitude is, the more signif-
icant the physical descriptor is to determine the values
of ˜a0, ˜aX and ˜aC . Derivatives in Table VIII are ob-
tained at xi = 0.5 (i=1-5) and x0 = 1. We ﬁnd that the
spin multiplicity gS and total kinetic energy T have the
derivatives of the largest two magnitudes. Similar results
are observed at xi = 0.1 (i=1-5) and x0 = 1, or xi = 0.9
(i=1-5) and x0 = 1. Hence gs and T are identiﬁed as two
most signiﬁcant descriptors to determine the high-order
components of ˜a0, ˜aX and ˜aC . The ﬁnal or optimal val-
ues of ˜a0, ˜aX and ˜aC for each molecule or atom are listed
in Table I. Note that their values are overall shifted from
the original B3LYP values, while the order ˜aX <˜a0<˜aC
is kept for each molecule or atom. This overall shift is
caused by the ﬁnite basis set. More importantly, their
values are slightly diﬀerent from each other. Therefore,
is system-dependent.
the resulting B3LYP functional
We list the Neural-Networks-corrected AEs, IPs, PAs
and TAEs in Tables
II, III, IV and V, respectively.
∆1 and ∆2 in these tables are the diﬀerences between
the calculated values and the experimental counterpart
for the conventional B3LYP/6-311+G(3df,2p) and the
Neural-Networks-based B3LYP/6-311+G(3df,2p) calcu-
lations, respectively. Compared to their experimental
counterparts, the RMS deviations of Neural-Networks-

based B3LYP/6-311+G(3df,2p) calculations are 2.4, 3.7,
1.6 and 2.7 kcal·mol−1 for AE, IP, PA and TAE, re-
spectively, and are less than those of the conventional
B3LYP/6-311+G(3df,2p) calculations (cf. Table
IX).
We note that the Neural-Networks-based B3LYP/6-
311+G(3df,2p) calculations yield much improved TAE
results (see Table V). In Becke’s original work [4], the
RMS deviations are 2.9, 3.9, 1.9, and 4.1 kcal·mol−1 for
AE, IP, PA and TAE, respectively. The new B3LYP/6-
311+G(3df,2p) calculations yield improved results in
comparison to Becke’s work [4] (cf. Table IX).

To examine the performance of our neural network, a
test is carried out by calculating the IPs of 24 molecules
which are selected from the G2 test set [18]. To save the
computational time, only the 24 smallest molecules are
selected besides those appeared in the training set and
are termed as the testing set. Physical descriptors of each
molecule in the testing set are inputted into our neural
network and the Neural-Networks-corrected ˜a0, ˜aX and
˜aC are used to construct the new B3LYP functional (see
Table X). To calculate their IPs, the cation counterparts
of the 24 molecules need to be included as well. Their ˜a0,
˜aX and ˜aC are also listed in Table X. The resulting IPs
are given in Table XI, in comparison to those obtained
from the conventional B3LYP/6-311+G(3df,2p) calcula-
tions. Obviously, the resulting IPs for most molecules are
improved upon the Neural-Networks correction. For the
Neural-Networks-based B3LYP/6-311+G(3df,2p) calcu-
lation, its RMS deviation for the 24 molecules is reduced
to 2.2 kcal·mol−1 from the original 3.6 kcal·mol−1. This
test demonstrates the validity of our Neural-Networks-
based functional.

IV. DISCUSSION AND CONCLUSION

There are currently two schools of density functional
construction: the reductionist school and the semiem-
piricist school. The reductionists attempt to deduce the
universal exchange-correlation functional from the ﬁrst-
principles. The Jacob’s ladder [14] of density functional
approximations depicts the approach that the reduction-
ists take towards the universal exchange-correlation func-
tional of chemical accuracy. Becke realized that the
existence and uniqueness of exact exchange-correlation

TABLE II: Atomization Energy (kcal·mol

−1)

TABLE III: Ionization Potential (eV)

No. Name
1 H2
2 LiH
3 BeH
4 CH
5 CH2(3B1)
6 CH2(1A1)
7 CH3
8 CH4
9 NH
10 NH2
11 NH3
12 OH
13 OH2
14 FH
15 Li2
16 LiF
17 C2H2
18 C2H4
19 C2H6
20 CN
21 HCN
22 CO
23 HCO
24 H2CO
25 H3COH
26 N2
27 H2NNH2
28 NO
29 O2
30 HOOH
31 F2
32 CO2
33 SiH2(1A1)
34 SiH2(3B1)
35 SiH3
36 SiH4
37 PH2
38 PH3
39 SH2
40 ClH
41 Na2
42 Si2
43 P2
44 S2
45 Cl2
46 NaCl
47 SiO
48 SC
49 SO
50 ClO
51 FCl
52 Si2H6
53 CH3Cl
54 H3CSH
55 HOCl
56 SO2

a
Expt. DFT-1
103.9
103.5
56.4
56.0
55.0
46.9
81.4
79.9
181.4
179.6
170.4
170.6
291.3
289.2
392.9
392.5
83.4
79.0
176.0
170.0
279.5
276.7
102.9
101.3
217.6
219.3
133.5
135.2
20.5
24.0
135.8
137.6
386.4
388.9
531.3
531.9
664.8
666.3
176.7
176.6
303.6
301.8
253.1
256.2
273.2
270.3
357.8
357.2
480.0
480.8
226.1
225.1
410.9
405.4
153.0
150.1
121.7
118.0
249.9
252.3
34.8
36.9
382.4
381.9
146.2
144.4
125.4
123.4
210.6
214.0
303.9
302.8
150.5
144.7
230.2
227.4
172.6
173.2
101.1
102.2
17.1
16.6
70.1
74.0
115.5
116.1
102.0
100.7
54.4
57.2
93.1
97.5
185.6
190.5
164.7
169.5
124.8
123.5
65.1
63.3
59.5
60.3
499.3
500.1
369.6
371.0
443.0
445.1
154.8
156.3
246.4
254.0

b

∆1 DFT-NN
103.8
0.4
56.4
0.4
53.8
8.1
80.8
1.5
179.8
1.8
170.7
-0.2
289.7
2.1
392.9
0.4
81.5
4.4
173.8
6.0
278.4
2.8
101.8
1.6
218.4
-1.7
134.5
-1.7
-3.5
21.2
137.0
-1.8
387.1
-2.5
532.5
-0.6
665.0
-1.5
174.5
0.1
304.1
1.8
254.7
-3.1
272.0
2.9
358.6
0.6
481.3
-0.8
226.0
1.0
410.0
5.5
150.7
2.9
117.7
3.7
252.4
-2.4
-2.1
38.6
385.5
0.5
146.4
1.8
122.8
2.0
207.4
-3.4
303.4
1.1
147.9
5.8
228.8
2.8
172.8
-0.6
101.7
-1.1
21.0
0.5
-3.9
69.6
115.1
-0.6
103.6
1.3
56.9
-2.8
-4.4
99.0
188.0
-4.9
168.1
-4.8
124.4
1.3
67.1
1.8
-0.8
65.6
496.9
-0.8
371.8
-1.4
444.7
-2.1
159.1
-1.5
253.3
-7.6

aconventional B3LYP/6-311+G(3df,2p)
bNeural-Networks-based B3LYP/6-311+G(3df,2p)

∆2
0.3
0.4
6.9
0.9
0.2
0.1
0.5
0.4
2.5
3.8
1.7
0.5
-0.9
-0.7
-2.8
-0.6
-1.8
0.6
-1.3
-2.1
2.3
-1.5
1.7
1.4
0.5
0.9
4.6
0.6
-0.3
0.1
1.7
3.6
2.0
-0.6
-6.6
0.6
3.2
1.4
-0.4
-0.5
4.4
-4.4
-1.0
2.9
-0.3
1.5
-2.5
-1.4
0.9
3.8
5.3
-3.2
0.8
-0.4
2.8
-0.7

7

∆2
-0.02
0.23
0.14
-0.26
0.34
0.18
0.02
0.34
0.20
0.13
0.13
0.07
-0.10
-0.07
-0.18
-0.04
-0.02
0.06
-0.15
0.02
0.11
-0.01
0.03
-0.07
-0.07
-0.05
-0.06
-0.04
-0.09
-0.15
-0.06
-0.10
-0.14
0.23
0.35
0.01
0.37
-0.18
0.01
-0.12
0.06
0.18

No. Name
1 H
2 He
3 Li
4 Be
5 B
6 C
7 N
8 O
9 F
10 Ne
11 Na
12 Mg
13 Al
14 Si
15 P
16 S
17 Cl
18 Ar
19 CH4
20 NH3
21 OH
22 OH2
23 FH
24 SiH4
25 PH
26 PH2
27 PH3
28 SH
29 SH2(2B1)
30 SH2(2A1)
31 ClH
32 C2H2
33 C2H4
34 CO
35 N2(2Σg)
36 N2(2Πu)
37 O2
38 P2
39 S2
40 Cl2
41 FCl
42 SC

a
Expt. DFT-1
13.66
13.60
24.93
24.59
5.62
5.39
9.12
9.32
8.74
8.30
11.55
11.26
14.67
14.54
14.16
13.61
17.76
17.42
21.77
21.56
5.42
5.14
7.73
7.65
6.02
5.98
8.11
8.15
10.38
10.49
10.55
10.36
13.07
12.97
15.80
15.76
12.46
12.62
10.20
10.18
13.23
13.01
12.62
12.62
16.10
16.04
10.91
11.00
10.17
10.15
9.92
9.82
9.83
9.87
10.46
10.37
10.41
10.47
12.65
12.78
12.74
12.75
11.25
11.40
10.29
10.51
14.18
14.01
15.84
15.58
16.66
16.70
12.58
12.07
10.34
10.53
9.55
9.36
11.38
11.50
12.62
12.66
11.43
11.33

b

∆1 DFT-NN
13.58
0.06
24.82
0.34
5.53
0.23
9.06
-0.20
8.64
0.44
11.44
0.29
14.56
0.13
13.95
0.55
17.62
0.34
21.69
0.21
5.27
0.28
7.72
0.08
5.88
0.04
8.08
-0.04
10.31
-0.11
10.32
0.19
12.95
0.10
15.82
0.04
12.47
-0.16
10.20
0.02
13.12
0.22
12.61
0.00
16.07
0.06
10.93
-0.09
10.08
0.02
9.77
0.10
9.81
-0.04
10.33
0.09
10.38
-0.06
12.63
-0.13
12.69
-0.01
11.30
-0.15
10.37
-0.22
14.24
0.17
15.93
0.26
16.71
-0.04
12.44
0.51
10.35
-0.19
9.37
0.19
11.38
-0.12
12.72
-0.04
11.51
0.10

aconventional B3LYP/6-311+G(3df,2p)
bNeural-Networks-based B3LYP/6-311+G(3df,2p)

functional do not guarantee that the functional is ex-
pressible in simple or even not so-simple analytical form,
and introduced the semiempirical approach to construct
accurate exchange-correlation functionals. We go be-
yond the semiempirical approach by constructing the
Neural-Networks-based exchange-correlation functional.
Our generalized functional is a neural network whose
structure and synaptic weights are determined by ac-
curate experimental data.
It is dynamic, and evolves
readily when more accurate experimental data become
available. Although the parameters in the resulting func-

TABLE IV: Proton Aﬃnity (kcal·mol

−1)

TABLE VII: Optimized Synaptic Weights W’kj

a
No. Name Expt. DFT-1
98.6
154.0
201.4
162.1
153.2
186.0
168.2
132.8

1 H2
2 C2H2
3 NH3
4 H2O
5
SiH4
6 PH3
7 H2S
8 HCl

100.8
152.3
202.5
165.1
154.0
187.1
168.8
133.6

b

∆1 DFT-NN
98.4
-2.2
154.3
1.7
201.6
-1.1
162.3
-3.0
154.3
-0.8
185.7
-1.1
167.9
-0.6
133.9
-0.8

∆2
-2.4
2.0
-0.9
-2.8
0.3
-1.4
-0.9
0.3

aconventional B3LYP/6-311+G(3df,2p)
bNeural-Networks-based B3LYP/6-311+G(3df,2p)

TABLE V: Total Atomic Energy (hartrees)

No. Name
1 H
2 He
3 Li
4 Be
5 B
6 C
7 N
8 O
9 F
10 Ne

b

a
Expt. DFT-1
-0.500
-2.904
-7.478
-14.667
-24.654
-37.845
-54.590
-75.067
-99.731

-0.502 -0.002
-2.913 -0.009
-7.491 -0.013
-14.671 -0.004
-24.663 -0.009
-37.857 -0.012
-54.601 -0.011
-75.091 -0.024
-99.762 -0.031
-128.937 -128.960 -0.023

∆1 DFT-NN
∆2
0.001
-0.499
-2.906 -0.002
-7.482 -0.004
0.006
-14.661
0.005
-24.649
0.004
-37.841
-54.583
0.007
-75.069 -0.002
-99.737 -0.006
0.002

-128.935

aconventional B3LYP/6-311+G(3df,2p)
bNeural-Networks-based B3LYP/6-311+G(3df,2p)

tional, such as ˜a0, ˜aX and ˜aC , are system-dependent as
compared to the universal functionals adopted by both
reductionists and semiempiricists, the neural network is
not system-dependent and is regarded as a generalized
universal functional. Our approach relies on Neural Net-
works to discover automatically the hidden regularities
or rules from large amount of experimental data.
It
is thus distinct from the semiempirical approach. We
term it as the discovery approach. Compared to the
conventional B3LYP/6-311+G(3df,2p) calculations, the
Neural-Networks-based B3LYP/6-311+G(3df,2p) calcu-
lations yield much improved AEs, IPs, PAs and TAEs
(cf. Table IX). However, the improvement over Becke’s

TABLE VI: Optimized Synaptic Weights Wji

Wj1
Wj2
Wj3
Wj4
Wj5
Wj0

j=1
-0.89
0.52
0.18
0.78
0.22
0.15

8

k=3
0.46
0.36
0.53

∂˜aC
∂xi
0.099
-0.010
0.007
0.014
0.023
0.044

TABLE VIII: The Derivatives of ˜a0, ˜aX and ˜aC w.r.t. Each
Physical Descriptora

W’k1
W’k2
W’k0

i=1
i=2
i=3
i=4
i=5
i=0

k=1
0.21
0.18
-0.03

k=2
-0.02
0.06
0.54

∂˜a0
∂xi
-0.067
0.035
0.011
0.050
0.012
0.009

∂˜aX
∂xi
-0.036
0.034
0.015
0.058
0.022
0.011

aDerivatives are obtained at xi=0.5 (i=1-5) and x0=1.

calculation [4] is not as signiﬁcant. This leaves room for
further improvement or investigation.

To summarize, we have developed a promising new
approach, the Neural-Networks-based approach, to con-
struct the accurate DFT exchange-correlation functional.
The improved B3LYP functional developed in this work
is certainly not yet the ﬁnal exchange-correlation func-
tional of chemical accuracy that we seek for. Our work
opens the door of an entirely diﬀerent methodology to de-
velop the accurate exchange-correlation functionals. The
Neural-Networks-based functional can be systematically
improved as more or better experimental data become
available. The introduction of Neural Networks to the
construction of exchange-correlation functionals is po-
tentially a powerful tool in computational chemistry and
physics, and may open the possibility for ﬁrst-principles
methods being employed routinely as predictive tools in
materials research and development.

We thank Prof. YiJing Yan for extensive discussion
on the subject. Support from the Hong Kong Research
Grant Council (RGC) and the Committee for Research
and Conference Grants (CRCG) of the University of
Hong Kong is gratefully acknowledged.

TABLE IX: RMS (all data are in the unit of kcal·mol

−1)

Properties
Number of samples
a
A
b
DFT-1
DFT-NNc

AE
56
2.9
3.0
2.4

IP
42
3.9
4.9
3.7

PA TAE Overall
116
10
3.4
4.1
4.7
10.3
2.9
2.7

8
1.9
1.6
1.6

aBecke’s work
bconventional B3LYP/6-311+G(3df,2p)
cNeural-Networks-based B3LYP/6-311+G(3df,2p)

j=2
1.11
-0.09
0.09
0.20
0.28
0.06

No.

Name

gS

Nt

TABLE X: Descriptors and Parameters of Testing Set

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48

CF2
CH2
CH2S
CH3Cl
CH3F
CH3
CH3OH
CH3O
CHO
CO2
COS
HOF
NH2
NH
SC
B2H4
C2H5
CH3SH
CS2
N2H2
N2H3
Si2H2
Si2H4
SiH3
+
CF2
+
CH2
CH2S+
CH3Cl+
CH3F+
+
CH3
CH3OH+
CH3O+
CHO+
+
CO2
COS+
HOF+
+
NH2
NH+
SC+
B2H4
C2H5
CH3SH+
+
CS2
N2H2
N2H3
Si2H2
Si2H4
+
SiH3

+

+

+

+

+

+

1
3
1
1
1
2
1
2
2
1
1
1
2
3
1
1
2
1
1
1
2
1
1
2
2
2
2
2
2
1
2
3
1
2
2
2
3
2
2
2
1
2
2
2
1
2
2
2

24
8
24
26
18
9
18
17
15
22
30
18
9
8
22
14
17
26
38
16
17
30
32
17
23
7
23
25
17
8
17
16
14
21
29
17
8
7
21
13
16
25
37
15
16
29
31
16

D
(DB)
0.51
0.63
1.75
1.96
1.87
0.00
1.67
2.11
1.69
0.00
0.85
1.95
1.83
1.54
1.92
0.79
0.34
1.54
0.00
0.00
2.56
0.57
0.00
0.07
1.08
0.52
1.70
1.89
3.72
0.00
1.43
2.44
3.76
0.00
1.66
2.80
0.56
1.73
0.54
0.28
0.70
1.16
0.00
0.00
2.55
0.22
0.00
0.06

T
(a.u.)
301.68
45.13
481.58
549.86
176.46
49.28
155.45
149.00
140.01
246.26
589.92
208.68
63.22
58.63
468.67
76.44
115.61
494.06
942.06
142.57
147.28
643.83
658.51
306.32
303.37
44.66
481.65
550.53
177.34
48.83
155.82
149.57
140.98
245.22
588.35
210.63
62.72
58.03
469.27
75.62
117.00
494.52
941.86
143.30
148.94
642.41
656.32
306.15

Q
(DB·˚A)
27.87
12.98
33.56
33.85
21.21
13.87
22.90
22.23
19.87
28.71
41.32
17.89
12.11
10.94
33.28
26.08
25.37
36.34
53.04
21.13
21.96
50.42
51.48
27.95
20.16
7.41
24.05
24.57
13.46
7.61
14.56
14.24
12.86
20.89
31.06
12.46
7.39
6.69
23.22
16.76
16.11
25.68
40.10
13.30
14.25
34.76
36.04
17.96

˜a0

0.805
0.754
0.810
0.812
0.798
0.771
0.798
0.784
0.781
0.803
0.815
0.799
0.772
0.754
0.809
0.793
0.782
0.811
0.822
0.795
0.784
0.816
0.817
0.789
0.792
0.768
0.798
0.801
0.784
0.784
0.782
0.766
0.794
0.788
0.804
0.784
0.753
0.769
0.795
0.776
0.794
0.799
0.815
0.779
0.795
0.806
0.807
0.786

˜aX

0.754
0.714
0.761
0.763
0.746
0.725
0.746
0.739
0.736
0.752
0.767
0.746
0.726
0.715
0.760
0.742
0.738
0.763
0.776
0.743
0.739
0.770
0.771
0.745
0.747
0.721
0.754
0.757
0.738
0.730
0.736
0.726
0.741
0.743
0.761
0.738
0.713
0.722
0.751
0.730
0.741
0.755
0.773
0.733
0.743
0.763
0.764
0.741

9

˜aC

0.909
0.936
0.913
0.914
0.908
0.924
0.908
0.926
0.925
0.909
0.915
0.907
0.924
0.936
0.914
0.909
0.926
0.914
0.920
0.907
0.926
0.918
0.918
0.928
0.925
0.923
0.927
0.927
0.924
0.903
0.924
0.936
0.906
0.925
0.928
0.924
0.935
0.923
0.927
0.924
0.905
0.927
0.930
0.923
0.905
0.929
0.929
0.925

[1] A. D. Becke, Phys. Rev. A., 38, 3098 (1988).
[2] C. Lee, W. Yang and R. G. Parr, Phys. Rev. B., 37, 785

[3] J. P. Perdew and Y. Wang, Phys. Rev. B., 45, 13244

(1988)

(1992)

[4] A. D. Becke, J. Chem. Phys., 98, 5648 (1993)
[5] W. Kohn and L. J. Sham, Phys. Rev., 140, A1133 (1965)
[6] A. D. Becke, J. Chem. Phys., 107, 8554 (1997)
[7] F. A. Hamprecht, A. J. Cohen, D. J. Tozer and N. C.

Handy, J. Chem. Phys., 109, 6264 (1998)

10

[8] M. J. Frisch et al. Gaussian 98, Revision A.11.3 Gaussian,

Inc., Pittsburgh PA, 2002.

[9] B. D. Ripley, Pattern recognition and neural networks,

(New York : Cambridge University Press, 1996)

[10] L. H. Hu, X. J. Wang, L. H. Wong and G. H. Chen, J.

Chem. Phys., in press.

[11] P. Hohenberg and W. Kohn, Phys. Rev., 136, B864

(1964)
[12] J. C.

Slater,

of Molecu-
lar and Solids. Vol. 4.: The Self-Consistent Field for
Molecular and Solids, (McGram-Hill, New York, 1974)

Quantum Theory

[13] S. H. Vosko, L. Wilk and M. Nusair, Canadian J. Phys.,

58, 1200 (1980)

[14] J. P. Perdew and K. Schmidt, Density Functional The-
ory and Its Application to Materials, ed. V. Van Poren,
C. Van Alsenoy and P. Geerlings, (Melville, New York,
2001), page 1.

[15] J. P. Perdew, S. Kurth, A. Zupan and P. Blaha, Phys.

Rev. Lett., 82, 2544 (1999); 82, 5179 (1999) (E)

[16] X. Yao, X. Zhang, R. Zhang, M. Liu, Z. Hu, B. Fan,

Computers & Chemistry, 25, 475 (2001)

[17] D. E. Rumelhart, G. E. Hinton, R. J. Williams, Nature,

323, 533 (1986)

[18] L. A. Curtiss, K. Raghavachari, P. C. Redfern, V. Ras-
solov and J. A. Pople, J. Chem. Phys., 109, 7764 (1998)

TABLE XI: Ionization Potential of Testing Set (all data are
in unit of eV)

a
Expt. DFT-1
No. Name
11.35
11.42
1 CF2
10.40
10.39
2 CH2
9.28
9.38
3 CH2S
11.08
11.22
4 CH3Cl
12.30
12.47
5 CH3F
9.95
6 CH3
9.84
10.59
7 CH3OH 10.85
10.58
10.72
8 CH3O
8.49
8.14
9 CHO
13.74
13.77
10 CO2
11.19
11.18
11 COS
12.66
12.71
12 HOF
11.33
11.14
13 NH2
13.68
13.49
14 NH
11.43
11.33
15 SC
9.50
9.70
16 B2H4
8.22
8.12
17 C2H5
9.33
9.44
18 CH3SH
10.03
10.07
19 CS2
9.55
9.59
20 N2H2
7.90
7.61
21 N2H3
8.03
8.20
22 Si2H2
7.90
8.09
23 Si2H4
8.18
8.14
24 SiH3

aRMS = 3.6 kcal·mol−1
bRMS = 2.2 kcal·mol−1

b

∆1 DFT-NN
11.48
10.28
9.34
11.10
12.38
9.76
10.68
10.55
8.27
13.86
11.25
12.73
11.22
13.58
11.44
9.54
7.97
9.43
10.03
9.62
7.57
8.15
8.04
8.06

-0.07
0.01
-0.10
-0.14
-0.17
0.09
-0.26
-0.14
0.35
-0.03
0.01
-0.05
0.19
0.19
0.10
-0.20
0.10
-0.11
-0.04
-0.04
0.29
-0.17
-0.21
0.04

∆2
0.06
-0.11
-0.04
-0.12
-0.09
-0.08
-0.17
-0.17
0.13
0.09
0.07
0.02
0.08
0.09
0.11
-0.16
-0.15
-0.01
-0.04
0.03
-0.04
-0.05
-0.05
-0.08

