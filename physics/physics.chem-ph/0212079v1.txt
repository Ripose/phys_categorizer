2
0
0
2
 
c
e
D
 
9
1
 
 
]
h
p
-
m
e
h
c
.
s
c
i
s
y
h
p
[
 
 
1
v
9
7
0
2
1
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Multiresolution analysis in statistical mechanics. I. Using wavelets to calculate
thermodynamic properties

Ahmed E. Ismail, Gregory C. Rutledge, and George Stephanopoulos
Department of Chemical Engineering, Massachusetts Institute of Technology,
Cambridge, MA 02139
(July 30, 2013)

The wavelet transform, a family of orthonormal bases, is introduced as a technique for performing
multiresolution analysis in statistical mechanics. The wavelet transform is a hierarchical technique
designed to separate data sets into sets representing local averages and local diﬀerences. Although
one-to-one transformations of data sets are possible, the advantage of the wavelet transform is as an
approximation scheme for the eﬃcient calculation of thermodynamic and ensemble properties. Even
under the most drastic of approximations, the resulting errors in the values obtained for average
absolute magnetization, free energy, and heat capacity are on the order of 10%, with a corresponding
computational eﬃciency gain of two orders of magnitude for a system such as a 4 × 4 Ising lattice. In
addition, the errors in the results tend toward zero in the neighborhood of ﬁxed points, as determined
by renormalization group theory.

I. INTRODUCTION

Spin models are popular tools for theoretical calculations and for numerical simulations, as their universality classes
allow a huge range of diﬀerent systems—as varied as binary metal alloys, surface adsorption, and neural networks—to
be modeled simultaneously. For example, even the “trivial” one-dimensional Ising model can be used to model the
helix-coil transition in biopolymers; the deep connection between magnetic models and polymer chains allow us to
predict scaling behavior and other properties across an even wider range of materials.1 Lattice models are still widely
used in modeling the thermodynamics of complex systems, because their regular structure simpliﬁes the type and
nature of interactions among components of the system. Moreover, the diﬃculty in obtaining analytical solutions
of lattice systems, and the relative ease of computational simulations thereof, make them ideal test cases for new
simulation algorithms.

Although simulations of lattice models are relatively straightforward to implement, they share the same drawbacks
as oﬀ-lattice models. The chief drawback is that as the number of particles grows large, the time required to sample
the system accurately increases rapidly. A popular approach for addressing this problem is to coarse-grain the system:
that is, we “rescale” the problem by increasing the basic size of a simulation element. For example, we might coarse-
grain an atomic representation of a polymer chain into a “united atom” model, where a chain molecule is treated as
if it consisted only of the backbone. More creative approaches redeﬁne the problem to be addressed: for example,
Mattice and coworkers have produced a method which maps a polymer chain atomistically onto a high-coordination
lattice; this lattice is then used as the basis for a Monte Carlo simulation; the resulting conﬁguration is then used to
map back to continuous space to provide “evolution in time.”2–5

This paper illustrates the use of the wavelet transform as a mathematical basis for performing thermodynamic
computations of lattice models. The wavelet transform is an important tool in multiresolution analysis, which analyzes
a system simultaneously at several length or frequency scales selected to reﬂect the actual physical processes underlying
the observed behavior as closely as possible. The wavelet transform possesses a number of convenient properties,
including orthogonality, compactness, and reconstruction; we will make these concepts more precise in Section II B
below. The orthogonal nature of most wavelet constructions makes them a logical choice for use in ab initio density-
matrix quantum chemistry computations, in which the selection of an accurate basis set is crucial to the convergence
and eﬃciency of the calculations.6–8 Wavelet decompositions have been applied principally in electrical engineering,
particularly in the ﬁeld of signal processing. In this context, white noise and Markov processes have been studied using
multiscale methods.9, 10 To date, however, wavelet analysis does not seem to have been extensively applied to models
in statistical mechanics. Huang uses wavelet analysis to observe the statistical distribution of multiplicity ﬂuctuations
in a lattice gas,11 while Gamero et al. employ wavelets to introduce their notion of multiresolution entropy, although
their primary goal is dynamic signal analysis rather than statistical mechanics simulations,12 while O’Carroll attempts
to establish a theoretical foundation connecting wavelets to the block renormalization group.13, 14 A more in-depth
review of the connection between wavelets and renormalization theory is provided in a recent monograph by Battle.15

1

II. WAVELET TRANSFORM FUNDAMENTALS

A. The conceptual picture

The wavelet transform is a hierarchical method for decomposing a data set into averages and diﬀerences. Like the
Fourier transform, it can be used to provide a decomposition in both real space and reciprocal space (k-space), or time
space and frequency space. Unlike the Fourier transform, however, it is capable of providing simultaneously localized
transformations in both real and reciprocal space. A function localized in position space, such as a ﬁnite impulse
function, cannot be represented by a few terms of its Fourier series: many terms are required before good convergence
is achieved. By contrast, in wavelet space, this same function can be almost completely described by just a handful
of wavelet coeﬃcients. Although the ﬁrst wavelet was discovered almost a century ago by Haar,16 they have become
an important computational technique only in the last decade, following the work of Mallat,17, 18 Daubechies,19 and
others.20–22

The wavelet transform, like any other transform, takes a mathematical object and transforms it into another: we

can represent its action by writing

˜u =

[u] ;

W

W

depends both on the type of wavelet we have selected, and the object u which we wish to
the speciﬁc form of
, however, are derived from the same source: a set of coeﬃcients
transform. All versions of the wavelet transform
which deﬁne the transform. If u is a discrete data set, such as a signal sampled at regular intervals, then
is usually
represented as a matrix; while if u represents a continuous data set, such as the same signal measured at all times,
then
is often called a “ﬁlter bank” and the integral form
a “wavelet transform,” we will not distinguish between them in what follows, as the theory developed here for discrete
lattices and ﬁlter banks should carry over to continuous systems and wavelet transforms essentially unchanged.

acts as an integral operator. While the matrix form of

W

W

W

W

Similar to the Fourier transform, the wavelet transform decomposes the object x into two separate components, as
two diﬀerent functions, a scaling function φ and a wavelet function ψ, both operate on x. However, the two functions
separate its components not into cosines and sines, but into averages and diﬀerences, with a “wavelength” equal to
the “window” over which the scaling and wavelet functions are nonzero. In another important distinction, the wavelet
transform is recursive, so that it can be applied in succession to any set of averages which is produced using that
wavelet transform, to produce another level of averages and another level of details.

We shall now make the above concepts more mathematically precise. Let us deﬁne u to be a discrete set of samples
u = (u (1) , u (2) , . . . , u (n)). Then applying the scaling and wavelet functions φ and ψ to u create a set of averages
s (i) and a set of diﬀerences δ (i):

(1)

(2)

(3)

s (i) =

φ (k) u (i + k) ,

δ (i) =

ψ (k) u (i + k) ,

r

1

−

Xk=0
1
r
−

Xk=0

where r is a ﬁnite integer which deﬁnes the length scale, often referred to as the “size of the support,” over which
φ and ψ are nonzero. The index i runs from 1 to n; generally the data set is padded with zeros to ensure that all
sums in (2) and (3) are well-deﬁned, although periodicity is sometimes used instead.23 The coeﬃcients φ (k) and
ψ (k) in (2) and (3) are related,19, 23 and are central in controlling the features of the wavelet transform. Note the
wavelet transform is inherently redundant: for every sample u (i) in the original set u, we now have two values, a
local average s (i) and a local diﬀerence δ (i). Since the new data are simply linear combinations of the original
values, it is superﬂuous to retain both sets; at the same time, it is obvious that we cannot simply discard one set
of data and recover all the original information using only the other data set.
Instead, we choose to keep only
the odd-numbered s (i)’s and δ (i)’s, eliminating the even-numbered samples; this process is called downsampling.23
Downsampling removes half of the s (i) and half of the δ (i), regardless of the length r of the wavelet. Now we are
1). These n data points can be stored as the
left with n data: s (1) , s (3) , . . . , s (n
1) and δ (1) , δ (3) , . . . , δ (n
1) to ˜u(1) (1) , ˜u(1) (2) , . . . , ˜u(1) (n/2), and the
level-one wavelet transform ˜u of u, by assigning s (1) , s (3) , . . . , s (n
corresponding δ (i)’s as ˜u(1) (n/2 + 1) , . . . , ˜u(1) (n). [The superscript (1) denotes that the wavelet transform has been
applied once to this data set.] We can either stop at this level of description, or continue by further decomposing the
averages: then the new object u(1) to be transformed is u(1) (1) = ˜u (1) , . . . , u(1) (n/2) = ˜u (n/2), and so on. Note
that although ˜u(1) contains the averages s (i)’s and the diﬀerences δ (i)’s obtained in the previous step, successive

−
−

−

2

transforms only apply to averages obtained in the previous step. This process can be repeated until we have reduced
our set of averages to a single point; no further averaging is possible. We assume henceforth that the data set u(k)
has been suﬃciently downsampled to retain only the minimum data set required.

B. Properties and examples of wavelet and scaling functions

Until this point, we have not introduced any speciﬁc wavelet or scaling functions. Before we do so, we note that the
choice of a wavelet transform to apply to a given system usually hinges on the desired properties which one wishes
to include in the transformed data. Three principal properties are almost universally required for ﬁlter banks and
wavelet families:19, 23

1. Perfect reconstruction: No data is distorted by performing analysis followed by synthesis, so that the only

permissible change is a delay in recovery of the original sample.

2. Orthogonality: Wavelets computed at diﬀerent length scales or at diﬀerent spatial locations are mutually or-

thogonal; thus ﬂuctuations in the system are localized at the scales where they are most relevant.

3. Compact support: Properly designed wavelets are identically zero except for a ﬁnite interval, which means that

exact results can be obtained using only a ﬁnite number of terms.

Other properties, such as orthonormality, symmetry in the functional form of the wavelet or a certain number of

vanishing moments, can be taken into account when constructing the wavelet transform.24

The two most commonly encountered selections are the Haar and Daubechies wavelets, named after their respective
discoverers. The Haar pair is the oldest and simplest set of wavelets:16 the coeﬃcients of the scaling function are
φ = (φ (0) , φ (1)) = 1
1, 1). No
√2
other wavelet can be described with two points, and therefore no other wavelet has a support as compact as the Haar
wavelet. The scaling function φ simply averages the values stored at neighboring points, while ψ ﬁnds the diﬀerence
between those values; the extra factor of √2 is incorporated to ensure orthonormality between overlapping φ (k) and
ψ (k). A simple example of the action of the Haar wavelet is shown in Fig. 1.

(1, 1), while the coeﬃcients of the wavelet function are ψ = (ψ (0) , ψ (1)) = 1
√2

−

(

The Daubechies wavelets are a family of orthonormal functions whose construction was explicitly designed to
have orthogonality as well as vanishing higher-order moments.25 Daubechies was able to show that the Haar wavelet
is in fact the “ﬁrst” member of the Daubechies family; that is, the Haar wavelet is the Daubechies wavelet with
the shortest support. The second such member has four terms in its deﬁnition: the scaling function is deﬁned by
φ = (φ (0) , φ (1) , φ (2) , φ (3)) = 1
. The wavelet function reverses the order of the
4√2
coeﬃcients and inverts the sign of every other component, which allows the orthonormality properties to be satisﬁed:
φ (1) , φ (0)). We can see that the Haar wavelet obeys the same
ψ = (ψ (0) , ψ (1) , ψ (2) , ψ (3)) = (
φ (1) , φ (0)). This pattern can be extended, using diﬀerent coeﬃcients
pattern as the Daubechies wavelet: ψH = (
but the same general sign rules, for wavelets with 6, 8, 10, . . . coeﬃcients. The resulting wavelet and scaling functions
become increasingly smooth, and therefore are better suited for data sets in which there is only a gradual change in
the data set with position—in thermodynamic systems, this would be more useful for, say, a spin-N Ising model than
a spin- 1

(cid:0)
φ (3) , φ (2) ,
−

1 + √3, 3 + √3, 3

2 Ising model (presuming that N

√3, 1

1
2 ).

√3

−

−

−

−

(cid:1)

≫

C. Matrix formulation of the wavelet transform

For discrete systems, a conceptually simple method of implementing the wavelet transform is to set up the transform
as a matrix equation. The input u is converted into a column vector u, so that the coeﬃcients s (i) and δ (i) are
obtained via the dot product of u with vectors h (i) and l (i), where the vectors are padded so that the ﬁrst nonzero
element is located at position i:

h (i) = (0, . . . , 0, φ (0) , φ (1) , . . . , φ (r
l (i) = (0, . . . , 0, ψ (0) , ψ (1) , . . . , ψ (r

1) , 0, . . . , 0) ,
1) , 0, . . . , 0) .

−
−

The vectors s and δ, which contain the wavelet-transformed coeﬃcients of the decomposition, can be obtained by
forming the matrices H and L and right-multiplying by the vector u:

s = Hu and δ = Lu,

3

where the rows of the matrices H and L are the vectors (h (1) , . . . , h (n)) and (l (1) , . . . , l (n)), respectively.
As mentioned in the previous section, we do not need to keep all of the s (i)’s and δ (i)’s in order to ob-
tain perfect reconstruction of our signal; thus, we can obtain all the necessary coeﬃcients in a single ma-
trix multiplication by combining the relevant rows of H and L into a single matrix W(1), whose rows are
(h (1) , h (3) , . . . , h (n

1)). Thus, the wavelet transformation (1) can be written as

1) , l (1) , l (3) , . . . , l (n

−

−

s (n

1)

h (n

1)

=

s (1)
...
−
δ (1)
...
−





































h (1)
...

−
l (1)
...
−

u (1)
u (2)

...

u (n)

.

































δ (n

1)

l (n

1)

(4)

(5)

(6)

We will denote the product on the left-hand side of (4) as ˜u.

u(1) (1) , . . . , u(1) (n/2)

As stated above, the wavelet process can be applied recursively: the set of averages (s (1) , s (3) , . . . , s (n

1)) can be
, and operated on by an N
treated as a new data sample u(1) =
2 reduction of W(1), which
2 ×
we denote W(2), to produce a new set of n/4 averages
s(2) (1) , s(2) (3) , . . . , s(2) (n/2
and corresponding new
1)
−
set of n/4 diﬀerences
1)
. To reconstruct the original data set, we combine these n/2
(cid:0)
obtained from applying W(1). This process
values along with the n/2 diﬀerences
(cid:1)
can be repeated as many times as desired, dividing the m non-downsampled averages s(k) into m/2 averages s(k+1)
and m/2 diﬀerences δ(k+1). However, since at each iteration the matrix W(k) only operates on selected elements of
the vector ˜u(k) = W(k
1), computations for multiple levels can be performed at the same time. Thus, if we
wish to apply the wavelet transform K times, we can write this operation as an extended matrix product:26

(cid:0)
δ(2) (1) , δ(2) (3) , . . . , δ(2) (n/2

−
δ(1) (1) , δ(1) (3) , . . . , δ(1) (n

1)u(k

1)

−

−

(cid:1)

(cid:1)

(cid:1)

(cid:0)

(cid:0)

N

−

−

where the Q(k) are a family of matrices of the form

˜u(K) = Wu =

Q(k)u,

K

Yk=1

Q(k) =

W(k) 0
I

0

.

(cid:21)

(cid:20)

×

In (6), Q(k) is always an N

N matrix, while the matrix W(k) has size

N/2k

−

1

N/2k

−

1

.

To recover the original data sample u following a wavelet transform W, we can simply multiply ˜u by the inverse of the
(cid:1)
1 is equal to its transpose WT . Consequently,
wavelet matrix W. The matrix W is unitary: that is, its inverse W−
if W is known, all that is necessary to reverse the transformation is to left-multiply ˜u(k) by the transpose WT .
Moreover, the computation (4) of the wavelet transform can usually be carried out “in place” by manipulating local
coordinates; in this manner, the computation is carried out even more rapidly than a standard multiplication, and
without the increased storage costs associated with matrix multiplications.27, 28

(cid:0)

(cid:1)

(cid:0)

×

D. Multidimensional wavelet transforms

Since virtually all problems in lattice thermodynamics are in multiple dimensions, it is necessary to take the
wavelet transform of a multivariate function or data set. Several methods have been developed to carry out such
transformations; among them are Cohen and Daubechies’s separable wavelets, which form the multidimensional scaling
and wavelet functions φ (x, y), ψxx (x, y), ψxy (x, y), and ψyy (x, y) from products of the one-dimensional scaling
and wavelet functions φ (x) and ψ (x).20 A more general algorithm, the lifting algorithm, has been developed by
Sweldens.29, 30 It divides the wavelet transform into two steps: the ﬁrst computes the wavelet coeﬃcients δ (i) ; the
second step uses the wavelet coeﬃcients to speed up the calculation of the scaling coeﬃcients. “Initialization” of the
lifting algorithm requires the use of an appropriately selected basis function.

A particularly convenient basis function for the multidimensional lifting transform is the generalized orthogonal
Haar wavelets outlined by Sweldens.29 An extension of the one-dimensional wavelet transform, they can be cre-
ated in any number of dimensions, and have the same basic orthonormality properties as the one-dimensional Haar
functions, although the orthonormality constant becomes 2−
[The
two-dimensional version is shown in Figure 2.] Moreover, the use of the Haar wavelets as a starting point for further

d/2, where d is the dimensionality of the system.

4

iterations of the lifting algorithm allow the development of additional, “better” lifted wavelets with more desirable
properties, such as smoothness.

It can further be seen that the “oversampling” problem which exists in one dimension will be magniﬁed in multiple
dimensions: since the number of wavelet functions which are produced from each data point increases by a factor of
two with each additional dimension added, we must reduce the number of points maintained for each wavelet function
by that same factor. Thus, in two dimensions, we keep only every fourth point; in three dimensions, every eighth
point, and so on. The wavelet transform for multidimensional systems can thus still be written in the form of (5) and
(6), after we have written the multidimensional data set in terms of a column vector. This can be accomplished by
wrapping around the edges of the matrix in creating u: for example, after inserting element (1, N ) of a two-dimensional
data set into u, we next store element (2, 1), and so forth. The other signiﬁcant diﬀerence in the structure of these
equations is that the size of the submatrix W(k) in (6) is now N/2(k

1)d instead of N/2k

N/2(k

N/2k

1.

1)d

1

−

−

−

×

−

×

III. WAVELET ANALYSIS OF LATTICE THERMODYNAMICS

A. Applying the wavelet transform to Hamiltonians

The standard model for studying the thermodynamic behavior of lattice systems is the spin- 1

2 Ising model, which
contains both nearest-neighbor pairwise interactions as well as interactions between lattice sites and an external ﬁeld.
The Hamiltonian for this system is normally written in the form

β

−

H

= h

σi + J

σiσj,

i
X

ij
Xh
i

where h is the strength of the external ﬁeld in the direction of the spins σi, and J is the strength of the interaction
between nearest-neighbor pairs of spins on the lattice; these pairs are indicated by the subscript
in the second
1; for convenience we let kB = 1, so that temperature,
summation in (7). The inverse temperature β = (kBT )−
external ﬁeld, and nearest-neighbor interactions are all dimensionless quantities. The model can be further extended
by the inclusion of a position-dependent external ﬁeld, or by the inclusion of pairwise interactions beyond nearest
neighbors; in this case, (7) can be written in the more general form

ij
h

i

β

−

H

=

hiσi +

Jij σiσj,

i
X

i
X

j
X

where in (8) hi is the strength of the external ﬁeld at lattice site i, and Jij is the strength of the interaction between
sites i and j. Analytical solutions of (7) are well-known for one-dimensional systems and two-dimensional systems
when h = 0;31, 32 it has recently been suggested that analytic solutions do not exist for more complicated systems.33
While (7) and (8) are compact representations of the Hamiltonian of the system, the expansion of the lattice
variables si and sj as a sum of wavelet coeﬃcients makes these equations impractical for applying the wavelet
transformation. Since the system is described discretely, we want to use discrete wavelets, and therefore a matrix
formulation of the Hamiltonian would be convenient. Using graph theory,34 this is readily accomplished: let the
vectors u = (σ1, σ2, . . . , σN ) and h = (h1, . . . , hN ) denote the values of each of the N lattice variables in the system
and the set of external-ﬁeld interaction strengths, respectively, constructed in the row-wise manner described in the
previous section. Furthermore, deﬁne the matrix J such that element Jij is the strength of the interaction between
site i and site j. If these sites do not interact, then Jij = 0. Then, the Hamiltonian (8) can be written in the form of
a matrix equation:

= hT u + uT Ju,

β

−

H

where the superscript T denotes the transpose of the vector (or matrix) which precedes it.

The matrix W which deﬁnes the wavelet transform satisﬁes by construction WT W = I, where I is the identity
matrix. Therefore, to apply the wavelet transform, we simply insert WT W between each pair of terms in (9), thereby
obtaining

(7)

(8)

(9)

(10)

β

−

H

=

hT WT

(Wu) +

uT WT

WJWT

(Wu) .

(cid:0)

(cid:1)

(cid:1) (cid:16)

(cid:17)

(cid:0)

5

(11)

(12)

Using the general matrix property that BT AT = (AB)T , (10) can be rewritten in terms of the wavelet-transformed
vectors ˜h(K)= Wh, ˜u(K)= Wu, and the wavelet-transformed matrix ˜J(K)= WJWT :

β ˜
H

−

=

T

˜h(K)

˜u(K) +

˜u(K)

T

˜J(K)˜u(K).

(cid:16)

(cid:17)

(cid:16)

(cid:17)

It is important to note that in writing equation (11), we have not made any explicit assumptions about the form of the
matrix W, other than to require it to be a matrix describing a wavelet transform. As a result, we can perform several
levels of multiresolution simultaneously through appropriate preparation of the matrix W in the manner outlined
1 = WT to recover an original conﬁguration u is a one-to-one
above. Using the inverse wavelet transform W−
mapping only if we are provided with n distinct data points, as contained in ˜u(K).

Examining (11), we see that the result of applying the wavelet transform to a set of spins u is to create a new
representation ˜u(K), which contains the same information about the spins as does the original state vector u. However,
the vector ˜u(K) contains n/2dK averages, where d is the dimensionality of the lattice; these averages can be viewed as
“block spins” in a sense similar to that of Kadanoﬀ.35 The remaining elements of ˜u(K) contain the local diﬀerences in
the spins; that is, they can be used to describe the speciﬁc set of spins which give rise to a particular block spin ˜s(K)
.

i

B. Computing thermodynamic functions

The canonical partition function

Z =

exp (

β

(u)) ,

−

H

u
S
X
∈

where S is the conﬁguration space of the system, can be used to derive all the thermodynamic properties of a lattice
system. Applying the wavelet transform W to the state vector u results in a new state vector ˜u(K) belonging to the
conﬁguration space ˜S(K). Provided that W satisﬁes the perfect reconstruction property, if the summation over u
˜S
˜S(K), the results will be identical. This result follows naturally,
in (12) is replaced with the summation over ˜u(K)
˜S(K) for each state vector
since perfect reconstruction necessarily implies that there is a unique state vector ˜u(K)
β ˜
u
H

∈
Ensemble averages involving wavelet-transformed variables are in general no more complicated than computations
involving the original variables. In general, the transformation of a function (or functional) of the original variables
f (u) or f [u] will generally have the same characteristics after applying the wavelet transform to obtain ˜f (K)
˜u(K)
or ˜f (K)
. Moreover, the standard properties of ensemble averaging, such as linearity, also apply, which makes
(cid:1)
calculations of moments of the distribution particularly simple.

S, and by construction of the wavelet-transformed Hamiltonian (11),

∈
(K).

˜u(K)

H

−

−

=

∈

∈

β

(cid:0)

The above formulation can be applied to any system whose Hamiltonian can be written in the form of equation
(8), or as the sum of contributions, each of which is of that form. While the wavelet transform can be applied to
any lattice system whose Hamiltonian is a function of the components of the state vector u—or, indeed, to any
Hamiltonian which is a functional of u (r) for continuous systems—in most of these cases, it is necessary to rely on
the more cumbersome series expansions, or integral transforms in the case of continuous systems.

In addition, for Ising spin variables, the use of the wavelet transform poses an additional challenge. While it is
entirely straightforward to describe the possible values an individual lattice site can take—for a spin-q Ising model, the
allowed values of an individual spin σ are
1, q—the rules which determine whether an arbitrarily
selected “transformed” state vector ˜u(K) represents a real state vector u are cumbersome to manipulate and to
implement, and have proven a formidable challenge in prior research as well.36

q + 1, . . . , q

−

−

−

q,

(cid:2)

(cid:3)

×

×

4 and 32

In this section, we use two variants of the two-dimensional Ising model as a basis for our calculations: we look at
4
32 Ising lattices; the former is used for calculations when it is desired to perform calculations over
all states explicitly, while the latter is illustrative of larger systems, for which exact calculations are intractable. The
emphasis in this paper will be on the use of wavelets to yield approximate answers in signiﬁcantly faster time than
is possible with a Monte Carlo simulation incorporating all degrees of freedom explicitly. The methodology by which
the wavelet transform can be extended to Monte Carlo simulations of lattice systems is the focus of the companion
paper.37

IV. ANALYSIS

6

Before proceeding to the results of the calculations, we make note of the time required to execute the simulations.
Each of Figures 3 through 6 plots the observed variables in the temperature range T = 0.50 to T = 5.00, with a step
size of ∆T = 0.01. The computations for the original problem, with 216 = 65536 states to consider explicitly, required
more than 6.8 seconds per point to execute the required calculations on a 733 MHz Pentium III; the same calculations
using one and two applications of the wavelet transform required just 0.061 and 0.026 seconds per point to consider
54 = 625 and 17 states, respectively.

A. Weighting functions for wavelet-transformed statistics

Until now, we have worked with wavelet transforms which preserve the number of degrees of freedom between
the original and transformed problems. This approach yields results for the wavelet-transformed system in exact
agreement with those for the original system. However, as mentioned above, in such cases the transformed equations
are usually harder to model than the original ones. Hence it is desirable to use the wavelet transform not only as a
means of describing a lattice system, but also to derive an approximation scheme whereby estimates of thermodynamic
properties can be made eﬃciently, while still oﬀering error estimates that bound the true results.

E

δ(k)
)
i A (
·
D

= 0 for any choice of property A (

The approach we adopt in this paper is to ignore all local diﬀerences: that is, we assume that δ(k)

i = 0 for all values
of i and k. As a secondary assumption, we assume that correlation functions which include wavelet coeﬃcients are
). These extreme assumptions
also equal to zero: that is, we assume
·
represent a “worst-case scenario” for the use of the wavelet transform method; any more accurate representation of
the behavior of the wavelet coeﬃcients will lead to similarly more accurate results in the calculations we present
below. Note that under certain circumstances, these approximations are accurate: for Hamiltonians of the form (8)
which do not exhibit interactions with an external ﬁeld, there exist conﬁgurations with equal energies but opposite
; consequently, when we take the average over all conﬁgurations, the ensemble average of δ(k)
signs for δ(k)
i will vanish.
(s) , and have obtained a
. If we then make our approximation that all the wavelet coeﬃcients are negligible, then we

new function ˜
H
can reduce ˜
(K)
H
that were preserved by the wavelet transform. We know that the partition function of the system before we performed
(cid:17)
the wavelet transform is given by (12); after using the wavelet transform, we hypothesize that the partition function
of the new system is given by

Let us assume that we have applied the wavelet transform to our original Hamiltonian,

, where ˜s(K) represents the set of all averages

to a new function ˜
(cid:1)
H

, . . . , s(K)
m

˜u(K)
(cid:0)

s(K)
1

˜u(K)

˜s(K)

(K)

(K)

H

(cid:16)

(cid:0)

(cid:1)

(cid:0)

(cid:1)

i

˜s(K)

where the w
u
Clearly, the new partition function (13) will be identical to the original partition function (12) if we deﬁne

is the weight of conﬁguration ˜s(K) in the conﬁguration space ˜S(K); since multiple conﬁgurations
= 1 as we did in the untransformed Ising model.

S can correspond to the same ˜s(K), we cannot set w

˜s(K)

∈

(cid:0)

(cid:1)

˜Z =

w

˜s(K)

exp

(K)

˜s(K)

,

β ˜
H

−

X˜s(K)
∈

˜S(K)

(cid:16)

(cid:17)

(cid:16)

(cid:16)

(cid:17)(cid:17)

(cid:0)

(cid:1)

w (˜s) =

exp

β

−

(cid:16)

H

(cid:16)

(u)

˜
H

−

(K)

˜s(K)

,

(cid:16)

(cid:17)(cid:17)(cid:17)

u:u

˜s(K)

X
→

(13)

(14)

→

˜s(K) denotes that the sum is to be performed over all conﬁgurations u which have the
where the notation u : u
same set of wavelet-transformed averages ˜s(K). However, evaluating (14) to obtain the weighting functions is no more
tractable than the computation of the original partition function. Thus, any computational eﬃciency to be gained is
by ﬁnding an economical approximation for (14). One such approach is to take w
to be equal to the number
of states s whose wavelet transform yields ˜s(K), so that (13) is the standard form of the canonical partition function
for a system with degenerate energy levels. Let us call the number of such states s with equivalent averages ˜s(K) the
. The restriction of ˜u(K) to the averages ˜s(K) prevents
degeneracy of state ˜s(K), and denote this degeneracy as g
a unique reconstruction of u, unless g

˜s(K)

˜s(K)

˜s(K)

= 1.

(cid:0)

(cid:1)

(cid:0)

(cid:1)

(cid:0)

(cid:1)

7

B. Order parameter

m =

1
N *

σi

;

+

i
X

A natural variable to compute is the order parameter, generically denoted η, which for lattice spin systems is the

average magnetization,

for other members of the Ising universality class, the order parameter can represent the overall density ρ or the
diﬀerence between the densities of two phases.38 While the computation of the order parameter is straightforward
in simulations, its calculation can be made diﬃcult in the case of zero external ﬁeld because of symmetries in the
conﬁguration space: for every conﬁguration with magnetization mi, there exists another conﬁguration with the same
energy and magnetization
mi. As a result, when all the states are combined using (15), we do not observe spontaneous
magnetization, but instead ﬁnd m = 0 at all temperatures. Thus, we consider the absolute value of the magnetization,
4 Ising model with the wavelet transform,
m
|
setting all δ (i)’s to zero, and without the wavelet transform are shown in Figure 3. We note that the error is essentially
negligible for temperatures below T = 1, and decreases again for large values of T , where diﬀerences in energy levels
become negligible and the average magnetization of a state is the only contributing factor to

in place of the magnetization m. The results of this calculation for the 4

×

−

|

m
|

.
|

C. Free-energy considerations

The Helmholtz free energy is just the logarithm of the partition function: A =

kBT ln Z; if we estimate the
partition function using an expression such as (13), we naturally expect the approximated value A to diﬀer from
4 Ising model under the wavelet transform, we ﬁnd as
its true value. When we examine the behavior of the 4
×
expected that the two free energy surfaces are similar, although they are clearly not identical. In particular, the exact
numerical values obtained from the two equations are not the same. However, since the assignment A = 0 is arbitrary
in any system, we can choose to deﬁne A = 0 as either the maximum or the minimum free energy obtained in each
system. Under these conditions, the energy scales for the exact calculation and the wavelet transform calculation
are essentially identical, particularly at the so-called “ﬁxed points” of the system—that is, for points which are not
aﬀected by renormalization transformations.39 For the two-dimensional Ising model, these points are at T = 0, and
at inﬁnite (positive or negative) values of the external ﬁeld interaction h.

−

This agreement at the ﬁxed points should not be surprising: the ﬁxed points correspond to unique conﬁgurations of
the system, such that for the conﬁgurations ˜s(K) which result from the wavelet transform of the ﬁxed points u∗, the
degeneracy of the states is unity. Consequently, the approximation w
is correct for the dominant
conﬁguration in the system, and therefore the behavior of the approximate partition function Z ′ is almost identical
to that of the true partition function Z in the vicinity of the ﬁxed points.

˜s(K)

˜s(K)

= g

(cid:0)

(cid:1)

(cid:1)

(cid:0)

As can be seen in Figure 4, the free energy converges to the same values in the low-temperature limit, where only a
few states which are essentially unaﬀected by the wavelet transform contribute to the partition function of the system.
At high temperatures, the agreement is less exact, because of the approximations made in evaluating the Boltzmann
factors of the block spin conﬁgurations.

D. Entropy of a wavelet-transformed lattice system

It is relatively straightforward to show that coarse-graining a system with a countable phase space—that is, a phase
space whose states can be completely enumerated—requires a correction factor to ensure satisfactory agreement with
results from the ﬁne-scale system. As an example, consider the entropy of a wavelet-transformed spin- 1
2 Ising model.
The original lattice has 2Nt total conﬁgurations, and therefore in the high-temperature limit, the entropy approaches

If we ignore the weighting factor of the wavelet-transformed system by setting w

˜s(K)

= 1 for all states ˜s(K), the

resulting system will have

1 +

, and the maximum possible entropy for this system is

(cid:0)

(cid:1)

Smax = kBNt ln 2.

N (K)

1
K
i=1 N (i)

−

(cid:16)

Q

(cid:17)
max = kBN (K) ln
S(K)

K

1

−

 

i=1
Y

N (k) + 1

.

!

8

(15)

(16)

(17)

˜s(K)

for the weighting function w

Comparing (17) to the original limit of Smax = kBNt ln 2, we must have Smax > S(K)
max, since the conﬁguration space is
smaller, which indicates that our coarse-graining has eﬀectively reduced the available entropy of the system. We can
conclude from this that unless the volume of phase space is conserved by the coarse-graining procedure, some entropy
will be lost at high temperatures, regardless of the accuracy of the coarse-graining. Our choice of the degeneracy
g
for the systems
under study here.

preserves the volume of phase space in the limit of T

(cid:0)
Looking at the speciﬁc case of the 4

(cid:1)
4 Ising model, we compute the entropy as a function of temperature for
zero external ﬁeld for the exact problem, and for the wavelet-transformed problem using one and two iterations of
the two-dimensional Haar wavelet. The results are shown in Figure 5. As before, we ﬁnd that errors vanish in the
low-temperature limit, where only the lowest-energy states make a contribution to the partition function; since there
0 limit of the entropy is
are two such states, namely those with all spins up and all spins down, we ﬁnd that the T

→ ∞

˜s(K)

×

(cid:0)

(cid:1)

→

S (T

0)

→

≈ −

2

1
2

i=1
X

ln

= ln 2

1
2

˜S w (˜s) = 216,and therefore,
In the high-temperature limit, the entropies agree because, by construction, we have
∈
˜S w (˜s), and the entropy tends toward
since the Boltzmann factor goes to unity for all states as T
the value Smax given by (16). Disagreement in the intermediate temperature regime is largely the result of grouping
together states with diﬀerent energies into a single transformed state with a single energy. In particular, the grouping
of higher-energy states together at a lower energy increases the probability of being in those states, and therefore
increases the total entropy of the system. This explains the seemingly anomalous result of coarse-graining increasing
the entropy at intermediate temperatures observed in Figure 5.

→ ∞

, Z

P

P

→

∈

˜s

˜s

For more general systems, we can consider the formal deﬁnition of the entropy for a continuous distribution,

S =

kB

−

u

S

∈

Z

du p (u) ln p (u) ,

where p (u) is the probability of observing the conﬁguration u. For the original Ising model, each conﬁguration u is
(u)) , and thus the entropy is
unique, and therefore the probability p (u) is just the Boltzmann weight Z −
given by

1 exp (

H

−

β

S = kB ln Z +

duβ

(u) exp (

β

(u)) .

H

−

H

kB
Z

u

S

∈

Z

After performing the wavelet transform, and discarding ﬁner-scale details, we must account for the weighting factor
w (˜s) in our expression for the entropy. Consequently, the entropy for such a system is given by

S(K) =

kB

d˜s w (˜s) p (˜s) ln p (˜s)

−

˜S

˜s
Z

∈
= kB ln ˜Z +

kB
˜Z

˜S

˜s
Z

∈

d˜s w (˜s) β ˜
H

(cid:16)

(cid:17)

(K)

˜s(K)

β ˜
H

(K)(˜s(K)),

e−

where the coarse-grained partition function ˜Z is given by (13).

E. Fluctuation properties

(18)

(19)

(20)

For a given thermodynamic system, the constant-volume heat capacity C is deﬁned as the ﬂuctuation in the internal

energy of the system:

E2

2

E

C =

− h
kBT 2
(cid:11)
It is well-known that in the vicinity of a continuous phase transition, the heat capacity C diverges. At the same time,
2
it is also known that no system of ﬁnite size can have C
i
→ ∞
in the energy of the system will also remain ﬁnite. However, we can still observe evidence of power-law divergence
near the critical temperature.40 For small ﬁnite systems, we do not observe evidence of a divergence in the heat
capacity; instead, the heat capacity is a smooth function of temperature T . The wavelet transform largely preserves

, since the energy, and hence the variance

(21)

− h

E2

E

(cid:11)

(cid:10)

(cid:10)

i

.

9

the behavior of the original model; we observe the same general functional form in both the original model as well as
the transformed systems, as seen in Figure 6. However, for large ﬁnite systems, we can still detect the characteristic
32 Ising model as
power-law divergence in the vicinity of the critical point; such a divergence is shown for a 32
Figure 7.

×

Applying the wavelet transform to a given thermodynamic system, we expect that we will still ﬁnd evidence of a
critical point; however, because of the mean-ﬁeld like behavior of the wavelet transform method, the critical point
should be found at a higher temperature in the wavelet-transformed system than in the original system. Computing
the heat capacity for large lattices cannot be done by exhaustive enumeration; therefore, we save discussion of our
numerical results for a subsequent paper,37 and present a brief heuristic argument. As the size of a block spin
increases, corresponding to a greater number of iterations of the wavelet transform, we expect that the suppression
of ﬂuctuations in the system will lead to an increase in the temperature of the phase transition, while the actual
numerical value of the heat capacity itself decreases. The decrease in the number of degrees of freedom in the system
is accompanied by an increasing trend towards homogeneity of the system—the remaining conﬁgurations begin to look
2 decreases with increasing
more and more similar to one another. As a result, the variance measured by
i
amounts of coarse-graining. This trend is much less pronounced for small systems, as shown in Figure 6. When
the number of degrees of freedom is small, the ability to perform an exact enumeration ensures that the only errors
observed are those introduced by the wavelet approximation itself. Thus, since the free energy and entropy of small
systems are accurately reproduced by the transform, only minor deviations in the phase transition temperature for
small systems are expected.

− h

E2

E

(cid:10)

(cid:11)

V. SIMILARITIES TO RENORMALIZATION GROUP THEORIES

It should already be apparent that close aﬃnities exist between the method described here and position-space
renormalization methods. The construction of wavelet-based averages naturally corresponds to Kadanoﬀ’s concept
of a “block spin” transformation:35 both the present method and Kadanoﬀ’s approach rely on combining a region
of contiguous spins into a single new “block spin.” However, with the approach outlined above, we do not seek to
impose the requirement that the block spins must be restricted to have the same spin values as the original spins.
For example, in a wavelet-transformed spin- 1
1.
In addition, we do not impose “majority rules” or other “tiebreakers” in the case where there are equal numbers of
“up” and “down” spins contained in a single block.

2 Ising model, the block spins can take on values other than +1 and

−

A less apparent connection can also be established with Migdal’s “bond-moving” approximation,41, 42 or similarly
with Wilson’s recursion method.43 In particular, Migdal’s method can be compared to applying a separable wavelet
transformation, in that the recursion is performed in only one spatial direction at a time. However, using the methods
of either Migdal or Wilson, after performing the bond-moving or decimation transformation, the new interaction
strengths J ′ij are determined by manipulating the resulting Hamiltonian and recasting it in the form of the original,
leading at times to very complicated, nonlinear formulas for the J ′ij as a function of Jij. By contrast, using wavelets,
the values for the transformed coupling coeﬃcients ˜Jij are obtained directly by transforming the interaction matrix J,
since ˜J = WJWT . The trade-oﬀ that must be made for the algorithmic transparency of obtaining the new coupling
constants via a matrix multiplication is that we cannot solve for the ﬁxed points of the recursion relation, which
makes the production of a renormalization “ﬂow diagram” using the wavelet method a diﬃcult problem.

The behavior of the wavelet transform and of the renormalization group diﬀers in another, important manner.
By the nature of its construction, the group of renormalization transformations is only a semi-group, inasmuch as
reversing the mapping to move from a coarsened description to a more detailed description is impossible.44, 45 Using
the wavelet transform, a reverse mapping is theoretically possible: reversibility fails because of the approximations
invoked to reduce the number of wavelet coeﬃcients which are kept, rather than as an inherent limitation of the
wavelet transform itself.

Using the wavelet transform as a basis for calculations of lattice systems yields an impressive reduction in the
computational time required to obtain estimates of thermodynamic properties, at the price of modest errors in
accuracy, given the relatively small size of the systems considered here, and the approximations introduced to simplify
our calculations. The wavelet transform provides a systematic approach to coarse-grain systems to any level of
resolution. The method produces correct results in the vicinity of ﬁxed attractors, with decreasing accuracy as one
approaches the critical point in parameter space.

VI. CONCLUSIONS

10

In addition, the use of the wavelet transform on such systems is simple to implement: after selecting a particular set of
wavelets, all of the operations can be reduced to matrix multiplications, as shown in Section III A. The computational
requirements needed to implement the transformation are small: if the transformation cannot be accomplished in the
explicit form of a matrix multiplication, it is possible to organize the calculation to be performed in-place.29 Moreover,
the amount of coarse-graining that can be achieved using the wavelet transform can be adjusted dynamically. These
properties of the wavelet transform lead naturally to an extension of the method to systems for which simulations are
required; the resulting algorithm is the focus of the companion paper.37

VII. ACKNOWLEDGMENTS

Funding for this research was provided in part by a Computational Sciences Graduate Fellowship (AEI) sponsored

by the Krell Institute and the Department of Energy.

1 K. F. Freed, Renormalization Group Theory of Macromolecules, Wiley, New York, 1987.
2 R. F. Rapold and W. L. Mattice, Macromolecules 29, 2457 (1996).
3 J. Cho and W. L. Mattice, Macromolecules 30, 637 (1997).
4 P. Doruker and W. L. Mattice, Macromolecules 30, 5520 (1997).
5 P. Doruker and W. L. Mattice, Macromol. Theory Simul. 8, 463 (1999).
6 T. A. Arias, Rev. Mod. Phys. 71, 267 (1999).
7 G. Beylkin, N. Coult, and M. J. Mohlenkamp, J. Comput. Phys. 152, 32 (1999).
8 B. R. Johnson, J. P. Modisette, P. J. Nordlander, and J. L. Kinsey, J. Chem. Phys. 110, 8309 (1999).
9 M. R. Luettgen, W. C. Karl, A. S. Willsky, and R. R. Tenney, IEEE Trans. Sign. Process. 41, 3377 (1993).
10 M. R. Luettgen, Image Processing with Multiscale Stochastic Models, PhD thesis, Massachusetts Institute of Technology,

1993.

11 D.-W. Huang, Phys. Rev. D 56, 3961 (1997).
12 L. G. Gamero, A. Plastino, and M. E. Torres, Physica A 246, 487 (1997).
13 M. O’Carroll, J. Stat. Phys. 73, 945 (1993).
14 M. O’Carroll, J. Stat. Phys. 71, 415 (1993).
15 G. Battle, Wavelets and Renormalization, World Scientiﬁc, Singapore, 1999.
16 A. Haar, Math. Ann. 69, 331 (1910).
17 S. G. Mallat, IEEE Trans. Pattern Analysis and Machine Intelligence 11, 674 (1989).
18 S. G. Mallat, Trans. Amer. Math. Soc. 315, 69 (1989).
19 I. Daubechies, Ten Lectures on Wavelets, volume 61 of CBMS-NSF Regional Conference Series in Applied Mathematics,

SIAM, Philadelphia, 1992.

20 A. Cohen and I. Daubechies, Rev. Mat. Ibero-amer. 9, 51 (1993).
21 W. Sweldens and R. Piessens, SIAM J. Numer. Anal. 31, 1240 (1994).
22 W. Sweldens and R. Piessens, Numer. Math. 68, 377 (1994).
23 G. Strang and T. Nguyen, Wavelets and Filter Banks, Wellesley-Cambridge, Cambridge, MA, 1996.
24 W. Sweldens and P. Schr¨oder, Building your own wavelets at home, in Wavelets in Computer Graphics, pp. 15–87, ACM

SIGGRAPH Course notes, New Orleans, 1996.

25 I. Daubechies, Commun. Pure Appl. Math. 41, 909 (1988).
26 D. Gines, G. Beylkin, and J. Dunn, Appl. Comput. Harmon. A. 5, 156 (1998).
27 G. H. Golub and C. F. Van Loan, Matrix Computations, Johns Hopkins University Press, Baltimore, 1996.
28 L. N. Trefethen and D. Bau III, Numerical Linear Algebra, SIAM, Philadelphia, 1997.
29 W. Sweldens, SIAM J. Math. Anal. 29, 511 (1997).
30 I. Daubechies and W. Sweldens, J. Fourier Anal. Appl. 4, 247 (1998).
31 R. K. Pathria, Statistical Mechanics, Butterworth-Heinemann, Woburn, MA, 1996.
32 L. Onsager, Phys. Rev. 65, 117 (1944).
33 S. Istrail, Statistical Mechanics, Three-Dimensionality, and NP-Completeness: I. Universality of Intractability for the
Partition Functionof the Ising Model Across Non-Planar Surfaces, in Proceedings of the 32nd Annual ACM Symposium on
Theory of Computing, pp. 87–96, Portland, OR, 2000, ACM Press.

34 T. H. Cormen, C. E. Leiserson, and R. L. Rivest, Introduction to Algorithms, McGraw Hill-MIT Press, Cambridge,

MA, 1990.

11

35 N. Goldenfeld, Lectures on Phase Transitions and the Renormalization Group., Addison-Wesley, Reading, MA, 1992.
36 C. Best, A. Sch¨afer, and W. Greiner, Nucl. Phys. B: Proc. Suppl. 34, 780 (1994).
37 A. E. Ismail, G. Stephanopoulos, and G. C. Rutledge, Submitted to J. Chem. Phys. (2002).
38 H. E. Stanley, Introduction to Phase Transitions and Critical Phenomena, Clarendon Press-Oxford, Oxford, 1971.
39 S.-K. Ma, Modern Theory of Critical Phenomena, Benjamin/Cummings, Reading, MA, 1976.
40 J. J. Binney, N. J. Dowrick, A. J. Fisher, and M. E. J. Newman, The Theory of Critical Phenomena: An Introduction

to the Renormalization Group, Oxford University Press, Oxford, 1993.

41 A. A. Migdal, Sov. Phys.-JETP 42, 413 (1976).
42 A. A. Migdal, Sov. Phys.-JETP 42, 743 (1976).
43 K. J. Wilson and J. Kogut, Phys. Rep. 12, 75 (1974).
44 P.-G. de Gennes, Scaling Concepts in Polymer Physics, Cornell University Press, New York, 1979.
45 M. E. Fisher, Rev. Mod. Phys. 70, 653 (1998).

12

FIG. 1. (a) A sample signal u (n). (b, c) The one-dimensional Haar scaling function φ (x) and wavelet (diﬀerencing) function
ψ (x). (d, e) The ﬁrst-level scaling coeﬃcients s (n) and δ (n) produced from the original signal u (n) using the Haar pair,
following downsampling of the signal.

FIG. 2. The two-dimensional orthogonal Haar wavelets. The coeﬃcient in all cases is 1/2, times the sign indicated in each
quadrant. Note that the scaling function φ is built from the one-dimensional Haar scaling function, while the wavelet functions
are built from the one-dimensional wavelet function.

FIG. 3. (a) Average absolute magnetization |m| =

i |σi| of the 4 × 4 Ising model at zero external ﬁeld as a function of
temperature, as computed by an exact enumeration using no wavelet transform (solid line), and using one and two iterations of
the two-dimensional Haar wavelet (dot-dashed and dotted lines, respectively). (b) Error in the average absolute magnetization
of the 4 × 4 Ising model for one and two iterations of the two-dimensional Haar wavelet versus an exact enumeration.

P

FIG. 4. Free energy A of the 4 × 4 Ising model at zero external ﬁeld as a function of temperature, as computed by an exact
enumeration using no wavelet transform (solid line), and using one and two iterations of the two-dimensional Haar wavelet
(dashed and dot-dashed lines, respectively).

FIG. 5. Entropy of the 4 × 4 Ising model at zero external ﬁeld as a function of temperature, as computed by an exact
enumeration using no wavelet transform (solid line), and using one and two iterations of the two-dimensional Haar wavelet
(dashed and dot-dashed lines, respectively). The bottom of the y-axis corresponds to the zero-temperature limit of S = ln 2.

FIG. 6. Heat capacity of the 4 × 4 Ising model at zero external ﬁeld as a function of temperature, as computed by an exact
enumeration using no wavelet transform (solid line), and using one and two iterations of the two-dimensional Haar wavelet
(dashed and dot-dashed lines, respectively).

FIG. 7. Heat capacity of a 32 × 32 Ising model, illustrating the power-law divergence in the vicinity of the critical point

(identiﬁed by the arrow).

13

This figure "fig1.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/physics/0212079v1

This figure "fig2.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/physics/0212079v1

This figure "fig3.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/physics/0212079v1

This figure "fig4.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/physics/0212079v1

This figure "fig5.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/physics/0212079v1

This figure "fig6.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/physics/0212079v1

This figure "fig7.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/physics/0212079v1

