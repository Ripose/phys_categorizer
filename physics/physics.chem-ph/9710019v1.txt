7
9
9
1
 
t
c
O
 
8
1
 
 
]
h
p
-
m
e
h
c
.
s
c
i
s
y
h
p
[
 
 
1
v
9
1
0
0
1
7
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Numerical Comparisons of Three Recently Proposed Algorithms

in the Protein Folding Problem

Ulrich H.E. Hansmann#,†, 1 and Yuko Okamoto†, 2

#Swiss Center for Scientiﬁc Computing (SCSC)
Eidgen¨ossische Technische Hochschule (ETH) Z¨urich, 8092 Z¨urich, Switzerland

† Department of Theoretical Studies, Institute for Molecular Science
Okazaki, Aichi 444, Japan

ABSTRACT

We compare numerically the eﬀectiveness of three recently proposed algorithms, mul-
ticanonical simulations, simulations in a 1/k-ensemble, and simulated tempering, for the
protein folding problem. For this we perform simulations with high statistics for one of
the simplest peptides, Met-enkephalin. While the performances of all three approaches is
much better than traditional methods, we ﬁnd that the diﬀerences among the three are
only marginal.

Key Words: Monte Carlo, generalized ensemble, protein folding, multiple-minima prob-
lem, global energy minimization

1 e-mail: hansmann@ims.ac.jp
2 e-mail: okamotoy@ims.ac.jp

INTRODUCTION

While there has been a considerable progress in numerical simulations of biological macro-

molecules over the last thirty years (for a recent review see, for instance, Ref. [1]), the

prediction of their low-energy conformations from the ﬁrst principles remains a formidable

task. The numerical calculation of physical quantities depend on how comprehensively

the phase space of the system is explored. However, the energy landscape of the system of

peptides and proteins is characterized by a multitude of local minima separated by high

energy barriers. At low temperatures traditional Monte Carlo and molecular dynamics

simulations tend to get trapped in one of these local minima. Hence, only small parts of the

phase space are sampled (in a ﬁnite number of simulation steps) and physical quantities

cannot be calculated accurately. A common approach to alleviate this multiple-minima

problem is to identify the global minimum in the free energy (which should corrospond

to the native conformation of a protein) with the lowest potential energy conformation,

ignoring entropic contributions, and to search for this conformation with powerful opti-

mization techniques such as Monte Carlo with minimization, [2] genetic algorithms, [3]

or simulated annealing.[4] Since simulated annealing was ﬁrst introduced to the protein

folding problem,[5]-[8] the eﬀectiveness was tested with many peptides and proteins, and

it is now one of the most popular optimization methods used in the ﬁeld (for a recent

review see Ref. [9]).

It is claimed that a variety of recently proposed methods like the multicanonical

approach,[10, 11] entropic sampling,[12] simulated tempering,[13, 14] and simulations in a

so-called 1/k-ensemble[15] allow a much better sampling of the phase space than previous

methods. Actually, two of these methods, multicanonical approach and entropic sampling,

are mathematically identical as shown in Ref. [16]. The multicanonical algorithm was ﬁrst

applied to the protein folding problem in Ref. [17]. In Ref. [18] the authors showed that

this new ansatz yields indeed to an improvement over simulated annealing. The method

was also applied to the studies of the coil-gobular transitions of a model protein [19]

and the helix-coil transitions of homo-oligomers of nonpolar amino acids [20]. Simulated

tempering was applied to the study of a model heteropolymer. [21]

Applications of simulated tempering and the 1/k − ensemble to the protein folding

2

problems are still missing. Also missing is a quantitative comparison of the eﬀectiveness

of these three new methods. In the present article we try to ﬁll in this gap. By simulating

one of the simplest peptides, Met-enkephalin, with high statistics, we study the numerical

performances of the three methods.

In particular, the eﬃciency of ﬁnding the global-

minimum-energy conformation and calculating thermodynamic quantities is studied in

detail.

METHODS

Algorithms

Although the algorithms are explained in the original papers, we brieﬂy summarize here

the ideas and implementations of the three approaches for completeness.

Simulations in the canonical ensemble weight each conﬁguration with the Boltzmann
factor wB(T, E) = e− ˆβE and yield the usual bell-shaped probability distribution of energy

at temperature T :

PB(T, E) ∝ n(E) wB(T, E) = n(E) e− ˆβE ,

(1)

where n(E) is the density of states (spectral density) and ˆβ = 1/kBT is the inverse

temperature (we set the Boltzmann constant kB to unity hereafter).

Using local updates, the probability for the system to cross an energy barrier is pro-
portional to e− ˆβ∆E in the canonical ensemble. Here, ∆E is the height of the energy
barrier. Hence, at low temperatures (large ˆβ) simulations will easily get trapped in one

of the local minima and very long simulations are necessary to calculate thermodynamic

quantities accurately. In general, one can think of two strategies to alleviate this problem.

First, one can look for improved updating scheme. For instance, a kind of global updating

scheme called the cluster update method [22, 23] is popular in spin systems. No such

global updates are known for proteins. Secondly, one can perform the simulation in a

”generalized ensemble”, where the above diﬃculty does not arise. The latter approach is

the one that is investigated in the present article.

In the multicanonical approach [10, 11] conﬁgurations with energy E are updated with

a weight:

wmu(E) ∝

= e−S(E) ,

(2)

1
n(E)

3

where

S(E) = log n(E)

is the microcanonical entropy. A simulation with this weight factor will produce a uniform

distribution of energy,

Pmu(E) ∝ n(E) wmu(E) = const ,

resulting in a free random walk in the energy space. This allows the simulation to escape

from any energy barrier, and even regions with small n(E) can be explored in detail.

Unlike in a canonical simulation the weight wmu(E) is not a priori known (in fact,

the knowledge of the exact weight is equivalent to obtaining the density of states n(E),

i.e., solving the system), and one needs its estimator for a numerical simulation. Hence,

the multicanonical ansatz consists of three steps: In the ﬁrst step the estimator of the

multicanonical weight factor wmu(E) is calculated. Then one performs with this weight

a multicanonical simulation with high statistics. In this way information is collected over

the whole energy range. We remark that there is no explicit temperature dependence

in simulations of the multicanonical ensemble. However, from this simulation one can

not only locate the energy global minimum but also obtain the canonical distribution

at any inverse temperature ˆβ = 1

T for a wide range of temperatures by the re-weighting

This allows one to calculate the expectation value of any physical quantity O at temper-

techniques:[24]

ature T by

PB(T, E) ∝ Pmu(E) w−1

mu(E) e− ˆβE .

< O >T = Z

dE O(E)PB(T, E)

.

dE PB(T, E)

Z

The crucial step is the calculation of the estimator for the multicanonical weight

factor wmu(E). It is obtained by an iterative procedure. The improved estimator of the

multicanonical weight for the i-th iteration is calculated from the histogram of energy

distribution P (i−1)

(E) and the weight w(i−1)

mu

mu

of the preceeding simulation as follows:

(3)

(4)

(5)

(6)

(7)

w(i)

mu(E) =

w(i−1)
P (i−1)
mu

mu (E)
(E)

.

4

The ﬁrst iteration is a canonical simulation at suﬃciently high temperature T0 = 1
, with
ˆβ0
mu(E) = e− ˆβ0E. For details, see Refs. [18] and [20]. The method for calculating the
w(1)

multicanonical weight factor is by no means unique. While it is quite general, it has the

disadvantage that it requires iterations of short simulations, the number of which is not

Performing simulations in a so-called 1/k-ensemble is a way of sampling the (micro-

known a priori.

canonical) entropy S uniformly:

This equation implies that

P1/k(S) = const .

P1/k(E) = P1/k(S)

dS
dE

∝

dS
dE

= ˜β(E) ,

˜β(E) ≡

1
˜T (E)

=

d log n(E)
dE

.

where ˜β(E) stands for the eﬀective inverse temperature3 and is deﬁned by

There is again no explicit temperature dependence in simulations of the 1/k ensemble; it

can be said that simulations in both multicanonical and 1/k ensembles include information

of all temperatures. If the simulation is restricted to a certain energy interval, Eq. (10)

deﬁnes the corresponding temperature range (assuming n(E) is a monotonous function

of E) over which reliable results can be obtained.

In their original paper, Hesselbo and Stinchcombe [15] proposed that conﬁgurations

where the function k(E) is deﬁned as the integral of density of states with respect to

are assigned a weight

energy E:

This implies that

w1/k(E) =

1
k(E)

,

k(E) =

dE′ n(E′) .

E

−∞

Z

P1/k(E) ≡ n(E)w1/k(E) =

n(E)
k(E)

=

d log k(E)
dE

.

3 We remark that the term “multicanonical algorithm” was inspired by this eﬀective temperature.
In the early work, Berg and co-workers used for the multicanonical weight the speciﬁc parametrization
exp(− ˜β(E) E − α(E)), approximating S(E) = log n(E) by straight lines between adjacent energy bins.

5

(8)

(9)

(10)

(11)

(12)

(13)

Since the density of states n(E) is a rapidly increasing function of energy, we have

log k(E) ≈ log n(E) for wide range of values of E. Hence, Eqs. (9) and (13) are equiv-

alent, and a random walk in the entropy space is realized. Since the entropy S(E) is a

monotonically increasing function of energy, a random walk in entropy implies a random

walk in energy space (with more weight towards low-energy region; compare Eqs. (2) and

(11)). Hence, a simulation in 1/k-ensemble can escape from any energy barrier. Hesselbo

and Stinchcombe claim that the 1/k-sampling is superior to the multicanonical algorithm

in the sense that a fewer number of sampling is necessary for the former.[15]

In numerical work, energy is discretized and integrals are replaced by sums. Again,

the weight w1/k(E) is not a priori known and its estimator has to be calculated. It is

obvious that the method described above for determination of the multicanonical weight

factor is also suited for the calculation of the weight in the 1/k-ensemble. In addition, it

follows from the deﬁnitions of the weights, Eqs. (2), (11), and (12), that one can calculate

w1/k(E) from wmu(E), and vice versa. Thermodynamic quantities at any temperature

can be calculated by Eq. (6) with the re-weighting techniques of Eq. (5), in which Pmu(E)

and wmu(E) are replaced by P1/k(E) and w1/k(E), respectively.

The third approach is simulated tempering, which was ﬁrst introduced under the name

method of expanded ensembles by Luyabartsev et al. [13], but became more popular under

the former name proposed by Marinari and Parisi in Ref. [14]. In this ansatz temperature

itself becomes a dynamical variable. Temperature and conﬁguration are both updated

wST (T, E) = e−E/T −g(T ) ,

where the function g(T ) is chosen so that the probability distribution of temperature is

with a weight:

given by

PST (T ) =

dE n(E) e−E/T −g(T ) = const .

Z

Hence, in simulated tempering the temperature is sampled uniformly, while simulations

in multicanonical and 1/k ensembles respectively sample energy and entropy uniformly.

A random walk in temperature space is realized, allowing the simulation to escape from

(14)

(15)

6

any energy barrier. The last equation, Eq. (15), implies that

eg(T ) ∝

dE n(E) e−E/T .

Z

(16)

The function g(T ) is therefore proportional to the logarithm of the canonical partition

function at temperature T . Again, the weight wST (T, E) is not a priori known and

its estimator has to be calculated. We remark, however, that Eq. (16) allows easily

the calculation of the function g(T ) and therefore of the weight wST (T, E), once the

multicanonical weight wmu(E) = n−1(E) is given. Likewise, the multicanonical weight

wmu(E) can in principle be calculated from g(T ) by the inverse Laplace transformation.

In the numerical work the temperature is discretized and restricted to a certain inter-

val [Tmin, Tmax]. Integrals are replaced by sums. We also found it convenient to choose

the temperature points Ti not equidistant, but so that the increment of adjacent temper-

ature points decreases exponentially with decreasing temperature. Of course, this implies

that we do not sample in a uniform way in temperature but by a monotone function of

temperature.

Given the parameters gi = g(Ti) a simulated tempering simulation may use convential

Metropolis algorithm [25] with two kinds of Monte Carlo updates:

• Updates of conﬁgurations (conformations) at a ﬁxed temperature Ti with probability

min{1, exp[−(Enew − Eold)/Tn]}.

• Updates of temperatures with a ﬁxed conﬁguration (conformation) with probability

min{1, exp[−E(1/Tnew − 1/Told) − (g(Tnew) − g(Told))]}.

Using these updates, one can perform a simulated tempering simulation.

Crucial for this method is again the determination of the parameters gi (i = 1, · · · , n).

Given the temperature points Ti (i = 1, · · · , n with T1 = Tmax ≥ Ti ≥ Tn = Tmin), gi can

be calculated by the following iterative procedure:

1. Start with a short canonical simulation of m1 MC sweeps updating only conﬁgura-

tions at temperature T1 = Tmax and calculate the average energy < E >T1. Formally,

this can be regarded as a simulated tempering simulation at a ﬁxed temperature T1

with weight wST (T, E) = e−E/T1−g1 and g1 = 0.

7

2. Calculate new parameters gj according to:

gj + log(mj) ,

gj+ < E >Ti

1
Ti+1

 

−

1
Ti !

1 ≤ j ≤ i

,

j = i + 1

j > i + 1

gj = 



∞ ,

(17)

3. Start a new simulation, now updating both conﬁgurations and temperatures, with

weight wST (T, E) = e−E/Tj−gj and sample the distribution of temperatures Tj in the

histogram mj = m(Tj). For T = Ti+1 calculate the average energy < E >Ti+1.

4. If the histogram mj is approximately ﬂat in the temperature range T1 ≥ Tj ≥ Ti+1,

set i = i + 1. Otherwise, leave i unchanged.

5. Iterate the last three steps until the obtained temperature distribution mj becomes

ﬂat over the whole temperature range [Tn = Tmin, T1 = Tmax].

Once the weight factor wST (T, E) is obtained, we make a production run with high

statistics. Physical quantities have to be sampled for each temperature point separately.

Their expectation values at temperature T are then calculated in the usual way by

< O >T = Z

dx O(x) e−E(x)/T

dx e−E(x)/T

,

(18)

Z
where x labels the conformations, and only those conformations that were obtained at

temperature T are included in the integral. Expectation values at intermediate tempera-

tures can be calculated by the reweighting techniques.[24]

Peptide Preparation and Potential Energy Function

Met-enkephalin has the amino-acid sequence Tyr-Gly-Gly-Phe-Met. For our simulations

the backbone was terminated by a neutral NH2– group at the N-terminus and a neutral –

COOH group at the C-terminus as in the previous works of Met-enkephalin.[2, 7, 26, 27,

17] The potential energy function Etot that we used is given by the sum of the electrostatic

term Ees, 12-6 Lennard-Jones term EvdW , and hydrogen-bond term Ehb for all pairs of

atoms in the peptide together with the torsion term Etors for all torsion angles:

Etot = Ees + EvdW + Ehb + Etors,

(19)

8

Ees =

EvdW =

Ehb =

332qiqj
ǫrij

,

Aij
r12
ij

Cij
r12
ij

−

−

Bij
r6
ij !

Dij
r10
ij !

,

,

X(i,j)

X(i,j)  

X(i,j)  

Xl

Etors =

Ul (1 ± cos(nlχl)) ,

(20)

(21)

(22)

(23)

where rij is the distance between the atoms i and j, and χl is the l-th torsion angle.

This Etot was used in the actual simulations of the three algorithms. The parameters

(qi, Aij, Bij, Cij, Dij, Ul and nl) for the energy function were adopted from ECEPP/2.[28]-

[30] The computer code KONF90 [31] was used. The peptide-bond dihedral angles ω were

ﬁxed at the value 180◦ for simplicity, which leaves 19 angles φi, ψi, and χi as independent

variables. We remark that KONF90 uses a diﬀerent convention for the implementation of

the ECEPP parameters (for example, φ1 of ECEPP/2 is equal to φ1 − 180◦ of KONF90).

Therefore our energy values are slightly diﬀerent from those of the original implementation

of ECEPP/2.

Computational Details

Preliminary runs showed that all methods need roughly the same amount of CPU time

for a ﬁxed number of MC sweeps (about 15 minutes for 10,000 sweeps on an IBM RS6000

320H). Hence, we compared the diﬀerent methods by performing simulations with the

same number of total MC sweeps. By setting this number to 1,000,000 sweeps we tried

to ensure high statistics. One MC sweep updates every torsion angle of the peptide once.

In the case of simulated tempering we chose 30 temperature points which were expo-

nentially distributed between Tmin = 50 K and Tmax = 1000 K, i.e., Ti = Tmax × γ(i−1)

(i = 1, · · · , 30) with γ = (Tmin/Tmax)1/29. This speciﬁc choice of temperature points was

made because we found in preliminary runs that for an equidistant distribution of temper-

atures we either needed a very large number of intermediate temperature points or could

not obtain reliable estimates for gi = g(Ti). Even with the above choice of temperature

points we needed 150,000 sweeps to calculate the simulated tempering parameters gi.

In our earlier work [17] we found that we needed 40,000 sweeps to calculate the mul-

ticanonical weight for Met-enkephalin. To better compare the diﬀerent methods we tried

9

to improve the weights by further iterations till the total number of sweeps was again

150,000. Although the weight for 1/k-ensemble can also be determined by the iterative

procedure, here we just calculated it from the obtained multicanonical weight by means

of Eq. (12) to save computation time.

All thermodynamic quantities were then calculated from a production run of 1,000,000

MC sweeps for each of the three methods which followed 10,000 sweeps for thermalization.

At the end of every second sweep we stored the energy of the actual conformation for

future analysis of thermodynamic quantities. In all cases, the simulations started from

completely random initial conformations (“Hot Start”).

RESULTS AND DISCUSSION

We start the Results section by demonstrating some of the basic features of the three

methods. As explained above, we expect for all three algorithms that simulations result

in a (weighted) random walk in energy space. In Fig. 1 we show the time series of energy

from the production runs of 1,000,000 MC sweeps for the three methods. They all exhibit

a random walk between low energy states and high energy states. In Ref. [27] it was shown

that with the energy parameters of KONF90, conformations with potential energies less

than −11 kcal/mol essentially have the same structure (with small deviations in dihedral

angles), which is the conformation with the global-minimum energy. The random walks

in Fig. 1 all reached this lowest-energy state many times. The numbers of independent

such visits will be examined in detail below.

By comparing Eqs. (2) and (11), one expects that the random walk in 1/k-ensemble

is supposed to be biased towards the low-energy region, while that in multicanonical

ensemble does not have any bias (free random walk). This tendency is apparent in the

random walks in Fig. 1; that of 1/k-ensemble spends more time in the low-energy region.

In Fig. 2 histograms of energy distribution for the three methods are shown. As

expected, the distribution is essentially ﬂat for multicanonical ensemble, it increases with
decreasing energy for 1/k-ensemble. As implied by Eq. (9), P1/k(E) × ˜T (E) is a ﬂat
curve (data not shown). Here, ˜T (E) is the eﬀective temperature deﬁned in Eq. (10).

The distribution of energies for simulated tempering given in Fig. 2 is also ﬂat, but

has the tendency to increase as energy decreases. The ﬂat distribution does not imply

10

uniform sampling of temperature, since our temperature points are not equidistant. For

equidistant temperature points we would expect a distribution which is proportional to

the reciprocal of the speciﬁc heat.

In 1/k-ensemble a free random walk in entropy space is expected to be realized (see

Eq. (8)). In Fig. 3a the time series of the function S(E) = log n(E) is shown. A random

walk between small S and large S is indeed observed. In Fig. 3b we display the probability

distribution of entropy for both simulations of multicanonical and 1/k ensembles. This

should be compared with Fig. 2, where we displayed histograms of energy distribution.

The multicanonical simulation yields a curve which increases with entropy, while in the

1/k ensemble we observe a ﬂat distribution, indicating that entropy was indeed uniformly

sampled.

In simulated tempering the weight is chosen so that a 1d random walk in the temper-

ature points Ti is obtained (see Eq. (15)). This can be seen in Fig. 4, where we display

the time series of temperature for simulated tempering. As expected, a random walk

between high and low temperatures is observed. Since all temperatures should appear

with the same weight, we expect that the distribution of temperatures is essentially ﬂat.

The simulation results conﬁrmed this within the deviations of factor 2 from ﬂatness (data

not shown). As in the case of the multicanonical approach, one has to make a trade-oﬀ

between the numerical eﬀort one is willing to put into determination of weights and the

deviation from a ﬂat probability distribution one is willing to accept. We allowed for

diﬀerences of less than one order of magnitude.

A major advantage of all three methods studied in this paper is that they allow

calculations of thermodynamic quantities at any temperature from just one simulation

run, once the weights are determined (see Eqs. (6) and (18)). As examples we show

in Fig. 5 the average potential energy < E >T and the speciﬁc heat C as functions of

temperature. The latter quantity is deﬁned by

C(T ) =

< E2 >T − < E >2
T
N T 2

,

(24)

where N(= 5) is the number of amino acids in the peptide. All three methods yield the

same values at most of the temperature values within the (small) error bars. These results

11

demonstrate that the three methods are equally well suited for calculation of thermody-

namic quantities. It also proves that our estimates of these quantities are reliable (since

they were calculated from independent simulation data obtained by diﬀerent methods;

there is no systematic hidden bias). This is especially important for the low temperature

region where comparison with canonical simulation is not possible. Note that the average

potential energy at the lowest-temperature region is about −12 kcal/mol, which is the

global-minimum energy value for the energy function in KONF90.[27] The value at a high

temperature, say T = 1000 K, is as large as ≈ 16 kcal/mol. The energy ﬂuctuation δE

at this temperature is about 5 kcal/mol (calculated from the value of C from Eq. (24) by

δE =

5C/ ˆβ2). Hence, the random walks in Fig. 1 have reached the high-energy region

q

with energy values that would be obtained at temperatures higher than 1000 K.

The behavior of the speciﬁc heat is also reasonable. The peak at T ≈ 300 K implies

that this temperature is most relevant for the folding of the peptide. The zero-temperature

limit of the speciﬁc heat agrees with that of the harmonic approximation to the potential

energy, where equipartition theorem can be used:

Here, NF is the number of degrees of freedom (number of torsion angles) and we have set

again kB = 1. The above speciﬁc heat is deﬁned to be the derivative of average energy

per residue with respect to temperature:

< E >= NF

.

T
2

C =

d(< E > /N)
dT

=

NF
2 N

.

(25)

(26)

For Met-enkephalin NF = 19 (number of free torsion angles) and N = 5, and we have

C = 1.9. The zero-temperature limit extrapolated in Fig. 5 agrees with this value.

A comparison of Figs. 1 and 4 gives us a way of comparing the performance of the

three methods in terms of sampling the ground-state conformations. It is evident that

low energy (temperature) states which are separated in the time series by high energy

(temperature) states are uncorrelated. The number of such “tunneling” events is therefore

a lower limit for the number of independent low-energy states visited in the simulation.

We deﬁne a tunneling event as the walk in the simulation between a conformation with

energy E ≤ −11.0 kcal/mol (i.e., a ground-state conformation) (or T = 50 K in the

12

case of simulated tempering) to a conformation with energy above E = 20.0 kcal/mol

(or T = 1000 K for simulated tempering) and back to the ground-state region. For each

tunneling event the lowest energy, EGS, obtained during the corresponding cycle was

monitored. Table 1 summarizes our results.

In our production runs of each 1,000,000

MC sweeps we observed 23 tunneling events for the multicanonical simulation, 27 for

the simulation in the 1/k-ensemble, and 19 in the case of simulated tempering. These

numbers correspond to tunneling times (average number of MC sweeps needed for a

tunneling event) of 40324, 35664, and 47874 MC sweeps for multicanonical, 1/k-ensemble,

and simulated tempering simulations. Note that the number of tunneling events from the

multicanonical simulation is higher than the one quoted in Ref. [18], where we found only

18 tunneling events and a tunneling time of 54136. We assume that this improvement is

due to the improvement of the multicanonical weight. It is interesting to observe that the

number of tunneling events (and therefore independent ground-state conformations found

in the course of simulation) is larger for the 1/k ensemble than for the multicanonical

simulation. The observed diﬀerences may be due to large statistical ﬂuctuations (see

the standard deviations of tunneling times in the last row of Table 1). In any case the

diﬀerences in tunneling times which we found are too small to establish a ranking of the

performances among the three methods.

We conclude that all three methods, while not diﬀering much from each other, are much

more eﬃcient in ﬁnding independent ground-state structures than traditional methods.

In Ref. [18] we made a comparison of multicanonical algorithms with simulated annealing,

including annealing versions of the multicanonical simulations.[32] Multicanonical anneal-

ing simpliﬁes the determination of weight factors and can be used to search groundstates,

but does not allow estimation of thermodynamic quantities. Here we also performed

annealing simulations in 1/k-ensemble and simulated tempering. Twenty independent

annealing runs with 50,000 MC sweeps were made for the two methods. An annealing

simulation in 1/k-ensemble was done as in the same manner as for multicanonical anneal-

ing. [18] Namely, an upper bound in energy Ewall is introduced, above which a simulation

is not allowed to enter. The weight is updated so that the energy distribution becomes

ﬂat in the interval (Ewall − ∆E, Ewall), where ∆E, sampling energy interval, is a constant.

13

The upper bound Ewall is lowered once after each iteration so that Ewall = E0 + ∆E,

where E0 is the lowest energy found in the preceeding iteration. A simulated tempering

annealing simulation is implemented similarly by replacing energy by temperature in the

above procedure (for details of the annealing algorithms, see Ref. [18]).

The lowest energies obtained by each annealing run are summarized for the three

methods and compared with simulated annealing in Table 2, where the values for mul-

ticanonical annealing and simulated annealing were taken from Ref. [18]. The results

are all similar with high probability ( 75 – 90 % ) of ﬁnding the energy global mini-

mum in contrast with the moderate probability (around 40 %) of those by Monte Carlo

simulated annealing without much ﬁne-tuning of the annealing schedule.[18] To compare

diﬀerent annealing schedules we varied the number of independent runs and MC sweeps

per run keeping their product constant. The results are shown in Table 3, where data

for multicanonical annealing and simulated annealing were taken from Ref. [18]. Again

our results do not allow a ranking of the generalized ensemble algorithms, but shows that

they perform better than simulated annealing.

In order to obtain an optimal annealing schedule, one has to monitor the speciﬁc heat.

One has to lower the temperature very slowly where the speciﬁc heat has a peak so that

a wide variety of conformations are sampled. ¿From Fig. 5 one ﬁnds that the present

system of Met-enkephalin has a peak of speciﬁc heat at ≈ 300 K. This temperature

in turn corresponds to the average potential energy of ≈ −1 kcal/mol, as is shown in

Fig. 5. Since the lowest energy is about −12 kcal/mol, we conclude that the sampling

energy interval ∆E [18] for the annealing simulations in multicanonical and 1/k ensembles

should be more than 11 (−1 −(−12)) kcal/mol. The results in Table 2 were obtained with

∆E = 15 kcal/mol. As for the simulated tempering annealing simulation, we conclude

that the corresponding sampling temperature interval ∆T should be at least ∆T = 250

(300 − Tmin) K. The results in Table 2 were obtained with ∆T = 300 K. These analyses

give some hint for the determination of optimal annealing conditions.

Finally, in Fig. 6 we show the time series of energy from typical annealing runs for

multicanonical algorithm, 1/k-ensemble, simulated tempering, and simulated annealing.

From the Figure we can understand why the performances of the former three algorithms

14

were better than a regular simulated annealing with naive exponential annealing schedule

of Ref. [31] (without reheating). Namely, as the simulation proceeds, the size of energy

ﬂuctuations is ﬁxed to be a preset ﬁnite value for the former three methods, while it

decreases towards zero for the latter. Hence, the chance of getting trapped in an energy

local minima becomes higher and higher as the simulation proceeds for Monte Carlo

simulated annealing.

CONCLUSIONS

We have performed simulations with high statistics for a simple peptide, Met-enkephalin,

to compare numerically the performances of three new algorithms in the protein folding

problem. All three methods have in common that simulations are performed in an ex-

tended ensemble instead of the ususal canonical ensemble. They all require as a ﬁrst step

the calculation of estimators for the not a priori known probability weight factors. Using

an analytical transformation of the obtained distribution to a canonical distribution, any

thermodynamic quantity at any temperature can in principle be calculated from one sim-

ulation run. We demonstrated that the calculated thermodynamic quantities over a wide

range of temperatures were identical for the three methods. In particular, the agreement

persisted into the diﬃcult, low-temperature regime, where regular canonical simulations

will necessarily get trapped in one of huge number of energy local minima. Hence, one

can cross-check the low-temperature results obatined from one of the three methods by

those from another. Furthermore, by comparing the eﬃciency of the three methods in

ﬁnding independent ground-state structures, we found that the three methods are equally

more eﬀective than traditional methods.

We conclude that all three methods are equally well suited for the simulation of pep-

tides and proteins. Temperature, energy, or entropy is also by no means the only variables

in which a uniform sampling is possible, nor is there any restriction on one variable. The

three studied algorithms are only special cases of a larger class of similar methods, which

we may call ”simulations in generalized ensemble”.

Acknowledgements:

Our simulations were performed on a cluster of fast RISC workstations at SCRI (The

15

Florida State University, Tallahassee, USA) and computers at the Computer Center of

the Institute for Molecular Science (IMS), Okazaki, Japan. This work is supported, in

part, by the Department of Energy, contract DE-FC05-85ER2500, by the Schweizerische

Nationalfonds (Grant 20-40’838.94), and by Grants-in-Aid for Scientiﬁc Research from

the Japanese Ministry of Education, Science, Sports, and Culture. Part of this work was

done while one of us (U.H.) was a visitor to IMS. U.H. would like to thank the members

of IMS for the kind hospitality extended to him and the Japan Society for the Promotion

of Science (JSPS) for a generous travel grant.

References

[1] M. V´asquez, G. N´emethy and H.A. Scheraga, Chem. Rev., 94, 2183 (1994).

[2] Z. Li and H.A. Scheraga, Proc. Nat. Acad. Sci. U.S.A., 84, 6611 (1987).

[3] For a review see S. Forrest, Science, 261, 872 (1993).

[4] S. Kirkpatrick, C.D. Gelatt, Jr. and M.P. Vecchi, Science, 220, 671 (1983).

[5] M. Nilges, A.M. Gronenborn, A.T. Br¨unger, and G.M. Clore, Protein Engng, 2, 27

(1988).

4373 (1988).

[6] S.R. Wilson, W. Cui, J.W. Moskowitz, and K.E. Schmidt, Tetrahedron Lett., 29,

[7] H. Kawai, T. Kikuchi, and Y. Okamoto, Protein Eng., 3, 85 (1989).

[8] C. Wilson and S. Doniach, Proteins, 6, 193 (1989).

[9] S.R. Wilson and W. Cui, in The Protein Folding Problem and Tertiary Structure

Prediction, K.M. Merz, Jr. and S.M. Legrand, eds. (Birkh¨auser, 1994) pp. 43–70.

[10] B.A. Berg and T. Neuhaus, Phys. Lett., B267, 249 (1991); Phys. Rev. Lett., 68, 9

(1992).

[11] B.A. Berg, Int. J. Mod. Phys., C3, 1083 (1992).

16

[12] J. Lee, Phys. Rev. Lett., 71, 211 (1993); Phys. Rev. Lett., 71, 2353(E) (1993).

[13] A.P. Lyubartsev, A.A.Martinovski, S.V. Shevkunov, and

P.N. Vorontsov-

Velyaminov, J. Chem. Phys., 96, 1776 (1992).

[14] E. Marinari and G. Parisi, Europhys. Lett., 19, 451 (1992).

[15] B. Hesselbo and R.B. Stinchcombe, Phys. Rev. Lett., 74, 2151 (1995).

[16] B.A. Berg, U.H.E. Hansmann, and Y. Okamoto, J. Phys. Chem., 99, 2236 (1995);

but see also the reply by M.H. Hao and H.A. Scheraga, J. Phys. Chem., 99, 2238

(1995).

A, 212, 415 (1994).

[17] U.H.E. Hansmann and Y. Okamoto, J. Comp. Chem., 14, 1333 (1993).

[18] U.H.E. Hansmann and Y. Okamoto, J. Phys. Soc. Jpn., 63, 3945 (1994); Physica

[19] M.H. Hao and H.A. Scheraga, J. Phys. Chem., 98, 4940 (1994).

[20] Y. Okamoto, U.H.E. Hansmann, and T. Nakazawa, Chem. Lett., 1995, 391;

Y. Okamoto and U.H.E. Hansmann, J. Phys. Chem., 99, 11276 (1995).

[21] A. Irb¨ack and F. Potthast, J. Chem. Phys., 103, 10298 (1995).

[22] R.H. Swendsen and J.S. Wang, Phys. Rev. Lett., 58, 86 (1987).

[23] R.G. Edwards and A. Sokal, Phys. Rev., D38, 2009 (1988).

[24] A.M. Ferrenberg and R.H. Swendsen, Phys. Rev. Lett., 61, 2635 (1988); Phys. Rev.

Lett., 63 , 1658(E) (1989), and references given in the erratum.

[25] N. Metropolis, A.W. Rosenbluth, M.N. Rosenbluth, A.H. Teller, and E. Teller, J.

Chem. Phys., 21, 1087 (1953).

[26] B. von Freyberg and W. Braun, J. Comp. Chem., 12, 1065 (1991).

[27] Y. Okamoto, T. Kikuchi, and H. Kawai, Chem. Lett., 1992, 1275.

17

[28] F.A. Momany, R.F. McGuire, A.W. Burgess, and H.A. Scheraga, J. Phys. Chem.,

79, 2361 (1975).

[29] G. N´emethy, M.S. Pottle, and H.A. Scheraga, J. Phys. Chem., 87, 1883 (1983).

[30] M.J. Sipple, G. N´emethy, and H.A. Scheraga, J. Phys. Chem., 88, 6231 (1984).

[31] H. Kawai, Y. Okamoto, M. Fukugita, T. Nakazawa, and T. Kikuchi, Chem. Lett.,

1991, 213; Y. Okamoto, M. Fukugita, T. Nakazawa, and H. Kawai, Protein Engng.,

4, 639 (1991).

[32] J. Lee and M.Y. Choi, Phys. Rev., E50, R651 (1994).

18

TABLE CAPTIONS:

Table 1: Estimated ground-state energies EGS (in kcal/mol) of each tunneling event as

obtained by the three algorithms. tmin is the sweep when the simulation ﬁrst entered the

groundstate region (E ≤ −11.0 kcal/mol) in the corresponding tunneling event. < ttun >

is the average time in Monte Carlo sweeps between these tunneling events. The numbers

in brackets are the standard deviation of the corresponding quantities.

Table 2: Lowest energy (in kcal/mol) obtained by the 20 annealing runs of the three

algorithms. For comparison, the results from simulated annealing are also included. For

all cases, the total number of Monte Carlo sweeps per run was 50,000. nGS is the number

of runs in which a conformation with E ≤ −11.0 kcal/mol was obtained. The data for

multicanonical annealing and simulated annealing were taken from Ref. [18].

Table 3: Number of runs that reached ground-state conformations for the three algorithms.

Keeping the total number of MC sweeps constant we varied the number of independent

runs. For comparison, simulated annealing data are included. The data for multicanoni-

cal annealing and simulated annealing were taken from Ref. [18].

19

Table 1.

tmin
24830
49472
160546
228340
240648
272908
294894
319722
330868
484056
503570
549780
623528
628398
651510
663014
681694
694916
815442
885534
911926
918322
949836
952284

ntu
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
< ttun >

Multicanonical Ensemble

Simulated Tempering

EGS
−11.8
−11.7
−12.0
−11.9
−11.9
−11.8
−11.3
−12.1
−11.1
−11.7
−11.9
−11.7
−11.5
−11.8
−11.1
−11.5
−11.9
−11.3
−11.8
−11.1
−11.6
−11.7
−11.5
−11.2

tmin
12596
66286
106646
163430
183162
237592
273200
408646
446152
455142
465150
514524
639764
648672
665176
691068
746726
778272
899104
922208

EGS
−12.0
−11.8
−11.9
−12.0
−11.9
−11.7
−11.9
−11.3
−11.8
−11.8
−11.9
−11.8
−11.3
−11.4
−11.9
−11.8
−11.9
−12.0
−11.8
−11.8

1/k-Ensemble
EGS
tmin
−11.8
2162
29094 −11.7
56382 −12.0
85790 −12.0
121798 −12.0
168464 −11.6
174704 −11.8
209170 −12.0
236218 −11.9
299008 −12.0
341488 −12.1
389804 −12.0
450304 −12.1
500868 −11.7
506178 −11.9
516248 −11.9
578230 −12.0
588002 −11.6
638984 −12.0
691742 −11.2
696882 −11.9
705466 −11.8
759824 −11.9
803662 −12.1
875652 −11.6
890076 −12.0
922426 −11.9
965106 −12.0
35664(19633)

40324(39826)

47874(37777)

20

Run Multicanonical

Simulated Tempering Simulated Annealing

Table 2.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
nGS

−11.6
−12.0
−10.2
−10.1
−11.9
−12.0
−11.9
−11.7
−11.8
−11.9
−12.0
−12.1
−12.0
−11.8
−11.3
−11.9
−12.0
−11.9
−11.9
−11.6
18/20

1/k
−10.3
−11.7
−11.3
−11.6
−12.1
−11.8
−10.9
−10.4
−11.7
−11.4
−11.3
−11.9
−11.4
−12.0
−11.6
−11.5
−11.7
−9.3
−11.6
−10.5
15/20

−11.8
−11.7
−11.5
−11.4
−11.1
−11.1
−11.6
−11.5
−11.4
−11.5
−11.3
−10.5
−12.0
−9.0
−11.8
−10.9
−11.4
−10.7
−11.1
−11.7
16/20

−11.7
−8.6
−12.1
−8.8
−7.4
−8.9
−12.1
−12.2
−7.1
−7.5
−9.9
−7.3
−8.4
−10.6
−10.3
−12.2
−12.2
−9.1
−11.9
−12.1
8/20

21

Table 3.

Number of Runs
× Number of MC Sweeps
10 × 100, 000
20 × 50, 000
50 × 20, 000
100 × 10, 000

Multicanonical

1/k

Simulated Tempering Simulated Annealing

10
18
21
28

9
15
22
29

9
16
17
20

5
8
10
13

22

FIGURE CAPTIONS:

FIG. 1: Time series of energy E (kcal/mol) from a simulation of 1,000,000 MC sweeps by

multicanonical, 1/k-sampling, and simulated tempering algorithms.

FIG. 2: Probability distribution of energy E (kcal/mol) from simulations by the three

methods. The data rely on 1,000,000 MC sweeps for each simulation.

FIG. 3a: Time series of entropy S from a 1/k-ensemble simulation of 1,000,000 MC sweeps.

FIG. 3b: Probability distribution of entropy S from simulations in multicanonical and

1/k ensembles. The data rely on 1,000,000 MC sweeps for each simulation.

FIG. 4: Time series of temperature T (K) from a simulated tempering simulation of

1,000,000 MC sweeps.

FIG. 5: Average energy < E >T (kcal/mol) and speciﬁc heat C as a function of temper-

ature T (K) calculated from the simulations of multicanonical ensemble, 1/k-ensemble,

and simulated tempering. The data rely on 1,000,000 MC sweeps for each method. The

energy scale is displayed on the ordinate on the left-hand side and the speciﬁc heat on

the right-hand side. The average energy is a monotonically increasing function of tem-

perature, whereas the speciﬁc heat has a maximum around 300 K.

FIG. 6: Time series of energy E (kcal/mol) from an annealing simulation of 50,000 MC

sweeps by multicanonical, 1/k-sampling, simulated tempering, and simulated annealing

algorithms.

23

