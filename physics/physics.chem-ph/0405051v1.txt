4
0
0
2
 
y
a
M
 
1
1
 
 
]
h
p
-
m
e
h
c
.
s
c
i
s
y
h
p
[
 
 
1
v
1
5
0
5
0
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Reconstruction of thermally-symmetrized quantum autocorrelation functions from
imaginary-time data

Cristian Predescu∗
Department of Chemistry and Kenneth S. Pitzer Center for Theoretical Chemistry,
University of California, Berkeley, California 94720
(Dated: February 16, 2014)

In this paper, I propose a technique for recovering quantum dynamical

information from
imaginary-time data via the resolution of a one-dimensional Hamburger moment problem.
It is
shown that the quantum autocorrelation functions are uniquely determined by and can be recon-
It is demonstrated that the derivatives at
structed from their sequence of derivatives at origin.
origin can be evaluated by Monte Carlo simulations via estimators of ﬁnite variances in the limit
of an inﬁnite number of path variables. Finally, a Maximum Entropy inversion algorithm for the
Hamburger moment problem is discussed and applied for the task of computing the quantum rate
of reaction for a one-dimensional symmetric Eckart barrier.

PACS numbers: 02.70.-c, 05.30.-d
Keywords: quantum correlation function, quantum dynamics, rate of reaction, Hamburger moment problem,
analytic continuation

I.

INTRODUCTION

β~, provided that

In chemical physics, the quantum dynamical informa-
tion measured in experiments can generally be expressed
in terms of quantum correlation functions of the type

CO(t) =

e−βHO†eiHt/~Oe−iHt/~
tr (e−βH)

tr

(cid:0)

R,

t

∈

,

(cid:1)

(1)

∈

whenever the linear response theory provides a good ap-
proximation of the measuring physical process.1 The op-
erator H stands for the Hamiltonian of the system, a
self-adjoint and bounded from below operator, whereas
R and β = 1/(kBT ) > 0 are the real time and the
t
inverse temperature, respectively. O† denotes the ad-
joint of the operator O. Because of their importance,
correlation functions have become the object of investi-
gation of many research groups in the last thirty years,
research spurred in part by signiﬁcant advances in Monte
Carlo techniques, path-integral methods, and computa-
tional resources. Of the numerical techniques utilized
for the computation of quantum correlation functions for
large-dimensional systems, we shall brieﬂy discuss the an-
alytic continuation method, which, similarly to the ap-
proach advocated in the present paper, attempts to re-
formulate the problem in terms of quantities that can be
evaluated by path-integral Monte Carlo techniques. For
the non-specialist, this discussion also serves the purpose
of putting the main result of the paper in its scientiﬁc
context.

The normalization term tr

in Eq. (1) is not
relevant for our discussion and we drop it from now on.
Using trace invariance in Eq. (1), we obtain

(cid:1)

(cid:0)

e−βH

CO(t) = tr

e−(β+it/~)H O†eiHt/~
h

i

O

,

t

R.

∈

(2)

Eq. (2) is mathematically well-deﬁned on the strip of the
complex plane determined by the equation 0 < Im(t) <

(cid:1)

(cid:0)

tr

<

(3)

e−β1H O†e−β2H O

,
∞
In these conditions, Baym and
for all β1, β2 > 0.
Mermin2 have argued that the function CO(t) is ana-
lytic on the aforementioned domain. In addition, CO(t)
is uniquely determined on this domain by the values of
CO(t) on the purely imaginary interval (0, iβ~), values
that can be computed eﬃciently by path-integral Monte
Carlo techniques (via the Feynman-Kac formula). Fi-
nally, the correlation function CO(t) is uniquely deter-
mined at all points of continuity on the frontier of the
β~, frontier that obviously includes
strip 0
the real axis.

Im(t)

≤

≤

Berne and Harp3 have pointed out that the computa-
tion of thermally-symmetrized quantum correlation func-
tions

GO(t) = tr

e−βcH O†e−βcH O

,

(4)

(cid:16)

(cid:17)

it/~, might be an
with βc = β/2 + it/~ and βc = β/2
easier computational task, yet the correlation functions
GO(t) and CO(t) carry essentially the same information,
because their Fourier transforms satisfy the simple rela-
tion

−

ˆGO(ω) = e−β~ω/2 ˆCO(ω).

Certain quantities of physical interest may not even re-
quire the computation of direct and inverse Fourier trans-
forms. For the ﬂux-ﬂux (F) correlation functions, Miller,
Schwartz, and Tromp4 have shown that the time integrals
over the interval [0,
] of the CF (t) and GF (t) functions
are equal and so, for the determination of the quantum
rate of reaction,4,5,6 it does not matter which of the cor-
relation functions is utilized.
(Though we shall strive
to maintain generality whenever appropriate, the strat-
egy advocated in the present paper best applies to the

∞

−

ﬂux-ﬂux autocorrelation function, for which only short-
time information is needed. Thus, the ﬂux-ﬂux autocor-
relation function is the standard example in the present
paper.) As Eq. (3) implies, GO(t) is well-deﬁned in
the strip of the complex plane deﬁned by the equation
< β~/2. Baym and Mermin’s argument can by
Im(t)
|
|
extended to justify that GO(t) is analytic in this strip and
admits a unique analytic continuation from the values of
iβ~/2, iβ~/2).
GO(t) on the purely imaginary interval (
The most common strategy for performing the analytic
continuation is based on the inversion of a two-sided real
Laplace transform with noisy input data. The inversion
problem is ill-posed and, as a consequence, the inversion
algorithms are highly unstable. The lack of continuity of
the inverse Laplace transform with the input data causes
any inversion algorithm to amplify the errors in the in-
put data in an exponential fashion. Because these er-
rors are of statistical nature, one is inclined to believe
that it is virtually impossible to recover any useful dy-
namical information. However, most notably by use of
Maximum Entropy techniques,7,8 various research groups
have been successful in obtaining limited but useful and
sometimes surprisingly reliable quantum dynamical in-
formation, whether in the form of spectra9,10,11,12,13 or
quantum rates of reaction.4,14,15

0

{

≥

µk; k

In the present paper, the computation of thermally-
symmetrized quantum autocorrelation functions is re-
duced to an inverse Hamburger moment problem (see
Section 2.3.e of Ref. 16 for the deﬁnition of the Ham-
burger moment problem). In this respect, it is ﬁrst shown
that the sequence of derivatives at origin of the autocor-
relation functions is a sequence of moments
,
}
up to a normalization factor. In fact, the quantum auto-
correlation function is the characteristic function of the
probability distribution from which the moments µk are
derived.
It is demonstrated that the sequence of mo-
ments uniquely determines the underlying probability
distribution and, consequently, the quantum autocorre-
lation function. Thus, the computation of any autocor-
relation function from its derivatives at origin involves
the resolution of an inverse Hamburger moment prob-
lem, which is, of course, a highly unstable inverse prob-
lem. However, any of a number of previously studied
inversion algorithms, especially those that preserve by
construction the positivity of the underlying probability
distribution,17 can be applied. Of particular importance
are again the techniques based on Jaynes’ Maximum En-
tropy principle,18,19,20 techniques that restate the inver-
sion problem as an entropy maximization problem. It is
worth mentioning that the algorithms based on the Maxi-
mum Entropy principle can be modiﬁed to accommodate
additional physical insight into the problem. Such nu-
merical “tricks” are dependent upon the nature of the
speciﬁc correlation function and will be investigated in
future work.

The second part of the present article is concerned with
the computation of derivatives at origin of correlation
functions. A general strategy for developing estimators

2

having ﬁnite variance in the limit of an inﬁnite num-
ber of path variables is discussed and illustrated for the
case of the ﬂux-ﬂux autocorrelation function. This strat-
egy follows the general guidance of Predescu and Doll of
burying the time dependence of paths into the potential
part of the Feynman-Kac formula.21 As implemented in
the present paper, the computation of the derivatives re-
quires the utilization of ﬁnite-diﬀerence schemes. Such
an approach has been successfully utilized in recent work
for the numerical evaluation of several thermodynamic
energy and heat-capacity estimators.22 The additional
problem we must face in the present paper is that the
utilization of ﬁnite-diﬀerence schemes for derivatives be-
yond a certain order requires extended precision arith-
metic, which may be a serious programming nuisance.
Alternative techniques, as for instance Lyness’ method,23
are possible but they require analytic continuation of the
potential in d-dimensional complex spaces. Such alter-
natives will be investigated in future work.

Some of the diﬀerences between the numerical tech-
niques based upon the real
inversion of a two-sided
Laplace transform and the technique advocated in the
present paper are the nature of the input data and the
way these data are computed. The expectation is that
the computation of derivatives by way of estimators is
a strategy superior to merely evaluating the imaginary-
time correlation function on a grid. For instance, the
Taylor series at origin of the thermally-symmetrized cor-
relation function GO(t) has a radius of convergence of at
least β~/2, as demonstrated in Section II. The common
practice is that the computation of the imaginary-time
correlation function for diﬀerent values of the time pa-
rameter is done in more or less uncorrelated Monte Carlo
runs. If the number of Monte Carlo steps for each time
is kept ﬁxed and the mesh of the grid is decreased, in the
limit of inﬁnitely many points on the grid, one does not
even recover a continuous function, much less an analytic
function. To the contrary, the computation of derivatives
at origin via estimators is performed in the same Monte
Carlo run and the Taylor series associated with the inﬁ-
nite sequence of derivatives at origin is always convergent
to some analytic function on a disk of radius β~/2, for
any number of Monte Carlo steps. Therefore, the latter
technique preserves the crucial property of analyticity of
the correlation functions on the disk of radius β~/2.

The present paper is limited to demonstrating that the
advocated technique actually works. Short of the analysis
performed in the preceding paragraph, we shall postpone
any issues of eﬃciency for future studies. In particular,
these studies will have to address the scaling of the vari-
ance of the estimators with the order of the derivatives,
the dimensionality of the system, and the inverse tem-
perature. However, the numerical results presented in
Section IV (these results are quantum rates for a sym-
metric Eckart barrier) show that the technique discussed
in the present paper is a useful tool for obtaining quan-
tum information of known computational diﬃculty.

3

II. RECONSTRUCTION ALGORITHM

Proof. Consider the standard inequality

In this section, we demonstrate that the sequence
of derivatives at origin of any autocorrelation function
uniquely determines the respective autocorrelation func-
tion, although the reconstruction algorithms involve the
resolution of a Hamburger moment problem. The actual
quantity that is recovered is the power spectrum of the
autocorrelation function, power spectrum that can be in-
terpreted as a probability distribution.

(cid:0)

R

Z

A.

Input data

Let us show that GO(t) is well-deﬁned on the strip

< β~/2 in the complex plane, whenever

Im(t)
|
|

MO(β1, β2) = tr

e−β1H O†e−β2H O

<

,
∞

(5)

for all β1, β2 > 0. With the help of the spectral decom-
position

(cid:1)

e−βH =

e−βE

E
|

E

dE,
|

ih

Eq. (4) becomes

GO(t) =

e−βcE−βcE

′

E

O
|

E′
|

i|

|h

2dEdE′,

(7)

R

R

Z

Z

whereas the condition given by Eqs. (3) or (5) now reads

MO(β1, β2) =

R

R

Z

Z

e−β1E−β2E

′

E

O
|

E′
|

i|

|h

2dEdE′ <

,
∞
(8)

for all β1, β2 > 0. From the inequality

GO(t)
|

=

R

R

Z

Z

| ≤

R

R

Z

Z
e−β(E+E

′

e−βcE−βcE
(cid:12)
(cid:12)
)/2
(cid:12)

E

′

O
|

E′
|

|h

(cid:12)
(cid:12)
(cid:12)
i|

E

O
|

E′
|

i|

|h

2dEdE′

2dEdE′ = GO(0),

(9)

.
∞

one concludes that the integral appearing in Eq. (7) is
absolutely convergent for all t
0, because GO(0) =
MO(β/2, β/2) <

≥

Im(t)
|
|

In these conditions, Baym and Mermin’s have argued
< β~/2. In
that GO(t) is analytic on the strip
fact, the analyticity of the autocorrelation function fol-
lows easily from Eq. (5) and from the absolute conver-
gence of the integral appearing in Eq. (7). Nevertheless,
for our algorithm, we only need analyticity at origin to-
gether with a stronger statement on the radius of conver-
gence of the Taylor series about origin. This is ensured
by the following proposition.

Proposition 1 GO(t) is diﬀerentiable at origin in-
ﬁnitely many times and the radius of convergence of the
Taylor series about origin is at least β~/2.

(6)

where

Dk =

1
~k

GO(t)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

R

R

Z

Z

and

Mr =

= 2

R

R

Z
Z
dE

∞

R
Z

E

Z

n−1

∞

∞

ez

−

Xk=0

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

zk
k! (cid:12)
(cid:12)
(cid:12)
(cid:12)
z
(cid:12)
|

(

≤

≤

Xk=n
/r)n
|

1
z
k! |

k =
|

Xk=n
z
(
|

≤

1
k!

rk

∞

Xk=n

1
k!

k
z
rk rk
|
|

/r)n er,
|

which is valid for all
z
|
positive number r < ~β/2. Then, for all t with
we have

. Pick an arbitrary
< r,

r <

| ≤

t
|

∞

|

eit(E−E
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

′

)/~

n−1

−

Xk=0

1
k!

k

it
~

(E

E′)k

−

(cid:18)
t
(
|

(cid:19)
/r)n er|E−E
|

′

(cid:12)
(cid:12)
(cid:12)
|/~
.
(cid:12)
(cid:12)

≤
The last inequality implies

n−1

−

Xk=0

(it)k
k!

Dk

n

Mr,

t
|
|
r

≤

(cid:18)

(cid:19)

(10)

e−β(E+E

)/2 (E

′

E′)k

E

O
|

E′
|

i|

|h

2dEdE′

(11)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

−

e−β(E+E

)/2er|E−E

′

′

|/~

E

O
|

E′
|

i|

|h

2dEdE′

dE′e−(β/2−r/~)E

′

−(β/2+r/~)E

E

O
|

E′
|

2
i|

|h

2MO(β/2

r/~, β/2 + r/~) <

≤

−

.
∞

The ﬁnitude of the last term follows from Eq. (5) because
0 < r < β~/2.

Since Mr does not depend upon n, an easy inductive
argument over n and Eq. (10) show that the terms Dk
are ﬁnite. Moreover, letting n
in Eq. (10), we learn
that

→ ∞

GO(t) =

(it)kDk

(12)

1
k!

∞

Xk=0

for all t with
proof is concluded.

t
|

|

< r. Since r < β~/2 is arbitrary, the
✷
t). There-
0. In these conditions, a little

−

From Eq. (7), we notice that G0(t) = G0(

fore, D2k+1 = 0 for all k
≥
thought shows that Eq. (12) can also be written as

GO(it) =

1
(2k)!

t2kD2k,

∞

Xk=0

(13)

the right-hand side series being convergent at least on
< ~β/2. Thus, the numbers D2k
the disc of equation
are positive [by Eq. (11)] and are the even derivatives of
the imaginary-time correlation function GO(it).

t
|

|

To summarize, the input data for the algorithm con-
sidered in the present paper is the sequence of even
derivatives of the imaginary-time autocorrelation func-
tion GO(it). This sequence, denoted by D2k, consists
of positive numbers computable by path-integral Monte
Carlo simulations.

B. The function that is reconstructed

The function (distribution) that is reconstructed is the
power spectrum of the auto-correlation function GO(t).
The power spectrum is deﬁned through the identity

ˆGO(ω) =

e−iωtGO(t)dt

(14)

1
2π

R

Z
and is generally deﬁned as a non-negative tempered dis-
tribution. With the help of Eq. (7), one computes

1
2π

(cid:20)

R

Z

ˆGO(ω) =

e−β(E+E

′

)/2

eit[−ω+(E−E

′

)/~]dt

R

R

Z

Z

E

×|h
δ[

O
|

E′
|

i|
ω + (E

2dEdE′ =

e−β(E+E

E′)/~]

R

Z
E

R

Z
O
|

|h

E′
|

i|

2dEdE′.

(cid:21)
)/2

′

−
×
Simple manipulations lead to

−

ˆGO(ω) = ~e−βω~/2

e−βE

E + ω~

O
|

E
|

i|

2dE,

(15)

R

Z

|h

which shows that the power spectrum is a non-negative
distribution.

By means of Eq. (14), one easily proves that the sym-
metry of GO(t) implies the symmetry of ˆGO(ω). In ad-
dition, with the help of the inverse Fourier transform

GO(t) =

eiωt ˆGO(ω)dω,

(16)

R

Z

one also proves that

D2k = (

1)k d2kGO(t)
dt2k

−

=

ˆGO(ω)ω2kdω.

R

Z

We summarize the ﬁndings of the present subsection

into the following proposition.

Proposition 2 The prescription

dPO(ω) =

ˆGO(ω)dω

(17)

1
D0

deﬁnes a symmetric probability measure on R. Thus, the
odd moments µ2k+1 of the measure are zero. The even
moments of the probability measure dPO(ω) are ﬁnite and
equal to

µ2k ≡

R

Z

ω2kdPO(ω) =

D2k
D0

,

k

∀

≥

1.

(18)

4

C. The moment problem to be solved

{

Surely, the reader has already anticipated that the
problem we want to solve is the following Hamburger
moment problem: Determine the symmetric probability
measure dPO(ω) on R, the even moments of which are
. However, in or-
given by the sequence
D2k/D0, k
der for the problem to be correctly formulated, we must
show that there exists a unique symmetric probability
measure of even moments

{
The existence is automatically guarantied by the pre-
scription [ ˆGO(ω)/DO]dω, the physical power spectrum,
which furnishes an example. For uniqueness, we cite
the following theorem (Theorem 3.11 from Section 2.3
of Ref. 16).

D2k/D0, k

≥

≥

1

1

}

}

.

Theorem 1 If lim supk→∞ µ1/2k
, then there
is at most one distribution function PO(ω) with µk =

2k /2k <

∞

ωkdPO(ω) for all positive integers k.

R
The hypothesis of this theorem is slightly less general
than the celebrated Carleman’s 1922 condition24

∞

Xk=1

1/µ1/2k

2k =

,
∞

which, of course, is also suﬃcient for the proof of Theo-
rem 2. Necessary and suﬃcient conditions for a sequence
of positive numbers to be a moment sequence have been
given by Hamburger in a series of papers from 1920 to
1921.25 He has also produced suﬃcient and necessary
conditions for the problem to be determinate (that is,
for the solution to be unique).

We then have the following theorem.

Theorem 2 There exists a unique symmetric probabil-
ity measure dPO(ω) of even moments
,
}
which is the one associated with the physical power spec-
trum. Consequently, the sequence of positive numbers
uniquely determines the autocorrelation
D2k, k
{
function GO(t) on the whole real axis.

D2k/D0, k

≥

≥

{

}

0

1

Proof. Let t = ~β/4 and a = G0(it). From Eq. (13) we
a(2k)!/t2k. With the help of Stirling’s

learn that D2k ≤
formula, we compute

lim sup
k→∞

1
2k

(cid:18)
[(2k)!]1/2k
2k

×

D2k
D0 (cid:19)
1
t

=

=

1

·

e

t

1/2k

1/2k

1
t

≤

lim
k→∞

1
2k "

lim
k→∞

a
D0 (cid:19)
(cid:18)
(2k)2k√4πk
e2k

1/2k

(4πk)1/4k =

lim
k→∞

<

e

t

∞

#

1

·

(19)

and the proposition follows from Theorem 1 and the
uniqueness of the inverse Fourier transforms of proba-
bility distributions (so-called characteristic functions of
the respective probability measures, according to Sec-
✷
tion 2.3.a of Ref. 16).

In particular, Theorem 2 shows that the dynamics on
the whole line is in principle uniquely determined by the
sequence of derivatives at origin of the imaginary-time
correlation function. Of course, this also follows from
Baym and Mermin’s analytic continuation result, but the
proof we have performed is more direct in the sense that
it connects the uniqueness with the numerical technique
in a straightforward fashion. The reader will appreciate
this from the following theorem, which gives general cri-
teria for the pointwise recovery of the correlation function
GO(t) on the whole real axis.

Theorem 3 Let dPO,n(ω) be a sequence of symmetric
probability measures such that

ω2kdPO,n(ω) = D2k/D0

lim
n→∞

R

Z
1. Then

for each k

≥

lim
n→∞

GO,n(t) = GO(t),

R.

t
∀

∈

Observation. Of course, by GO,n(t) we understand,
up to a multiplication factor of D0, the characteristic
function of the measure dPO,n(ω). The characteristic
function is deﬁned by

R

R

GO,n(t) = D0

eiωtdPO,n(ω).

Z
Remembering Eqs. (16) and (17), we see that GO(t) is
also a characteristic function, namely that of the measure
dPO(ω), because

GO(t) = D0

eiωtdPO(ω).

Z
Characteristic functions of measures are always continu-
ous, fact that follows easily from the dominated conver-
gence theorem.

∈

Proof of Theorem 3. Theorem 3.12 from Section 2.3 of
Ref. 16 asserts that the sequence of probability measures
dPO,n(ω) converges weakly to dPO(ω), because Eq. (19)
holds true. The ﬁrst part of the continuity theorem (The-
orem 3.4 from Section 2.3 of the same reference) states
that the weak convergence of the probability measures
implies pointwise convergence of the corresponding char-
R. The last observa-
acteristic functions at all times t
✷
tion concludes the proof of the theorem.
In a sense, Theorem 3 says that the pointwise values
of the correlation functions are the easiest to obtain. Ba-
sically, any procedure that is capable of reproducing the
ﬁrst n moments of the true probability distribution leads
to convergence of the correlation functions, in the limit of
large n. Other properties, as for instance certain integral
values involving correlation functions, are more diﬃcult
to obtain. Given the general approach put forward in the
present section, we are now ready to discuss the two main
computational aspects of the technique: the computation
of the sequence of even derivatives of the imaginary-time
correlation function and the numerical resolution of the
associated Hamburger moment problem.

5

III. DERIVATIVES OF THE IMAGINARY-TIME
CORRELATION FUNCTIONS

|

t
|

According to Proposition 1, the Taylor series about
origin of the imaginary-time correlation function GO(it)
< β~/2 of the
is convergent in the disk of equation
complex plane. As the well-known example of the free
particle ﬂux-ﬂux correlation function (see Eq. 55) demon-
strates, in general, one cannot expect convergence be-
yond this radius. Thus, for the purpose of computing
derivatives in origin of the imaginary-time correlation
function, we are forced to restrict the range of values
of t on which GO(it) is “sampled” to the real interval
β~/2, β~/2). We now turn our attention to the prob-
(
−
lem of constructing estimators for the high-order deriva-
tives of GO(it). We shall illustrate the general strategy
for the derivation of estimators for the particular case of
the ﬂux-ﬂux autocorrelation function. The reader needs
notice that, following the prescription of Predescu and
Doll,21 we strive to bury the time dependence into the
potential part of the various estimators in order for these
estimators to have ﬁnite variance in the limit of an inﬁ-
nite number of path variables.

For a one-dimensional system, the imaginary-time ﬂux-

ﬂux autocorrelation function reads4,6

GF (it) = tr

e−(β/2+t/~)H ˆF e−(β/2−t/~)H ˆF

,

(20)

(cid:17)

[δ(ˆx

xs)ˆp + ˆp δ (ˆx

xs)]

(21)

−

−

(cid:16)

ˆF =

1
2m0

where

and

ˆp =

~

∂
∂x

i
are self-adjoint operators (therefore, ˆF † = ˆF ). The ﬂux
operator ˆF corresponds to the dividing surface passing
through xs (actually, a “dividing point” in this one-
dimensional case). Setting βt = β/2 + t/~, Eq. (20) takes
the form

GF (it) =

∂2ρ
∂x∂x′ (x, x′; βt)

2

(cid:20)

ρ (x, x′; β−t)

~
2m0 (cid:19)
∂2ρ
∂x∂x′ (x, x′; β−t) ρ (x, x′; βt)
∂ρ
∂ρ
∂x′ (x, x′; βt)
∂x
∂ρ
∂ρ
∂x′ (x, x′; β−t)
(x, x′; βt)
∂x

(x, x′; β−t)

(cid:18)

+

−

−

(22)

,

x′=x=xs

(cid:21)(cid:12)
(cid:12)
(cid:12)
(cid:12)

where, of course, ρ(x, x′; βt) is the density matrix at the
inverse temperature βt.

Let us consider the one-dimensional Feynman-Kac

formula21,26

ρ(x, x′; βt) = ρf p(x, x′; βt)Ee−βt

1

0 V [xr(u)+σtB

0

u]du,

R

(23)

6

where

which expresses the density matrix as the expected value
of a functional of the standard Brownian bridge B0
u. In
x)u and σt = (~2βt/m0)1/2,
Eq. (23), xr(u) = x + (x′
−
whereas ρf p(x, x′; βt) stands for the density matrix of a
similar free particle at the inverse temperature βt. By
explicit computation, from Eq. (22) and the Feynman-
Kac formula, one derives the equation

GF (it) = EE′e−β−t
2

~
2m0 (cid:19)

×

(cid:18)

1

0 V (xs+σ−tB

u)du−βt

0

1

0 V (xs+σtB

0
u

′)du

R
ρf p(0; β−t)ρf p(0; βt)

R

0
t

F

′

B0

⋆, B0
⋆

, (24)

(cid:16)

(cid:17)

0
t

F

(cid:16)

′

B0

⋆, B0
⋆

=

(cid:17)

(1

u)du

−

(cid:21)

1

1
2σ2
−t

+

1
2σ2
t
1

+β2
−t

+ β2
t

0

V ′

xs + σtB0
u
(cid:20)Z
(cid:16)
xs + σ−tB0
u

udu

1

V ′

β−tβt

β−tβt

0

(cid:20)Z

1

1

0
(cid:20)Z

0
(cid:20)Z
1

0
(cid:21) (cid:20)Z

(cid:0)
V ′

(cid:1)
xs + σ−tB0
u

udu

(cid:0)

V ′

xs + σtB0
u
(cid:16)

(cid:1)

′

udu

0
(cid:21) (cid:20)Z

1

0
(cid:21) (cid:20)Z

β−t

V ′′

xs + σ−tB0
u

−

−

−

0
Z

(cid:0)

′

udu

1

V ′

xs + σtB0
u

′

(cid:17)
V ′

0
(cid:21) (cid:20)Z

(cid:16)
xs + σ−tB0
u

1

(cid:0)
V ′

V ′

(cid:1)
′
xs + σtB0
u
(cid:16)
(cid:17)
xs + σ−tB0
u

(1

u)du

−

−

−

(1

u)du

(cid:17)

(cid:21)

(cid:21)

(cid:21)

(cid:17)
u(1

(cid:1)

u)du

βt

−

−

(cid:0)

1

0
Z

V ′′

(cid:1)
xs + σtB0
u

′

(cid:16)

(cid:17)

u(1

u)du.

−

(1

u)du

(25)

In Eq. (24), the symbols E and E′ denote the ex-
pected values against the independent standard Brown-
′, respectively. In Eq. (25), V ′(x)
ian bridges B0
and V ′′(x) denote the ﬁrst and the second derivatives of
the potential V (x), respectively.

u and B0
u

Now, Eq. (24) can be rearranged as

GF (it) = EE′e−(β/2)[

R

1
0 V (xs+σ0B

0
u)du+

1
0
0 V (xs+σ0B
u

′)du]

R

1
8πm0 F

′
t

×

′

B0

⋆, B0
⋆

, (26)

(cid:16)

(cid:17)

where

and

′

B0

⋆, B0
⋆

′
t

F

(cid:16)

0
t

=

1
β−tβt F
e−(β/2)[∆−t(B

p

′

B0

⋆, B0
⋆

(cid:16)
0
0
⋆)+∆t(B
⋆

(cid:17)
′)],

(cid:17)

×

∆t

B0
⋆

=

V

xs + σ0B0
u

du

(cid:0)

(cid:1)
2βt
β

−

(cid:0)
xs + σtB0
u

(cid:1)
du.

V

(cid:0)

(cid:1)

1

0
Z
1

0
Z

(27)

(28)

Anticipating the use of Monte Carlo techniques for the
evaluation of imaginary-time correlation functions and
related properties, we introduce the normalization factor

R

0
u)du+

1
8πm0

NF =

1
0 V (xs+σ0B

1
0
0 V (xs+σ0B
u

EE′e−(β/2)[
R

′)du].
(29)
In principle, the factor
NF can be evaluated in a
separate Monte Carlo simulation, although for the
one-dimensional example presented later in the paper,
we have employed the numerical matrix multiplication
technique.27,28 If rate constants rather than absolute
rates of reaction are desired, one seeks to evaluate the ra-
NF and the partition function of the reactant
tio between
side, Qr. A Monte Carlo approach to the computation
of such ratios has been recently presented in Ref. 29.

In any case, the main diﬃculty in the computation
of quantum correlation functions does not reside in the
evaluation of the normalization coeﬃcient
NF . There-
fore, for the remainder of the present paper, we shall
focus our attention on the Monte Carlo evaluation of the
ratios

7

(30)

GF (it)
NF

=

′
t

F

D

(cid:16)

′

B0

⋆, B0
⋆

=

(cid:17)E

1

EE′e−(β/2)[
R
EE′e−(β/2)[
R

0 V (xs+σ0B

u)du+

0 V (xs+σ0B

0

1

0
u

′)du]

′
t

′

B0

⋆, B0
⋆

1
0 V (xs+σ0B0

u)du+

R

F
1
0 V (xs+σ0B0
u

′

(cid:16)
)du]

,

(cid:17)

R

or related quantities. For the purpose of computing av-
erages of the type given by Eq. (30), it turns out that it
is useful to replace the estimating function
with the symmetric form

⋆, B0
⋆

B0

F

′
t

′

(cid:17)

(cid:16)

1
2

F
h

′

B0

⋆, B0
⋆

=

′
−t

′

B0

⋆, B0
⋆

+

′
t

F

′

B0

⋆, B0
⋆

.

Ft

(cid:17)

(cid:16)

(cid:16)

(31)
(cid:17)
As follows from the equation GF (
it) = GF (it), this re-
placement does not change the value of GF (it). However,
in the next paragraph, we shall prove that the resulting
estimator has a smaller variance.

(cid:17)i

−

(cid:16)

It follows from Eqs. (25) and (27) that

′

B0

⋆, B0
⋆

′
−t

F

(cid:16)

=

′
t

F

(cid:17)

(cid:16)

′

B0
⋆

, B0
⋆

(cid:17)

and therefore,

′

B0

⋆, B0
⋆

=

′
t

′

B0
⋆

, B0
⋆

(cid:17)
′
⋆, B0
⋆

B0

′

(cid:16)
B0
⋆

, B0
⋆

(cid:17)

.

1
2

F
h
=
Ft

Ft
+

(cid:16)
′
t
F

(32)

(33)

(cid:16)

(cid:17)i
(cid:17)
is not only sym-
Consequently, the function
Ft
metric with respect to time inversion, as follows directly
from Eq. (30), but also with respect to the exchange of
′. Let us write
variables B0
as the

(cid:16)
⋆, B0
B0
⋆

B0

⋆ and B0
⋆

⋆, B0
⋆

(cid:16)

(cid:17)

′
t

′

′

F

(cid:16)

(cid:17)

sum between its symmetric and its antisymmetric parts

′

B0

⋆, B0
⋆

=

′

B0

⋆, B0
⋆

(cid:17)
⋆, B0
B0
⋆

Ft
′

(cid:16)
− F

′
t

′
t

F

+

(cid:16)
1
2

′
t

F
h

(cid:17)
′
, B0
B0
⋆
⋆

.

(cid:16)

(cid:17)
Since antisymmetric functions integrate to zero against
a symmetric probability measure, and since the products
of symmetric and antisymmetric functions are antisym-
metric, we have

(cid:17)i

(cid:16)

′
t

B0

⋆, B0
⋆

2

′

(cid:28)

+

F
1
4

(cid:16)

′
t

F

(cid:28)h

(cid:16)

(cid:29)
(cid:17)
⋆, B0
B0
⋆

′

2

′

B0

⋆, B0
⋆

′
t

′

B0
⋆

(cid:17)
, B0
⋆

(cid:29)
2

.

=

Ft

(cid:28)

− F

(cid:17)

(cid:16)

(cid:16)

(cid:29)

(cid:17)i

The last equation and the equality

′

B0

⋆, B0
⋆

′
t

F

=

Ft

′

B0

⋆, B0
⋆

=

GF (it)
Gd(0)

,

(cid:16)

D

D

(cid:17)E

(cid:16)
which was discussed in the previous paragraph, clearly
demonstrate that the estimator given by Eq. (31) has
a variance smaller than that of the estimator given by
Eq. (27).

(cid:17)E

To summarize, by Monte Carlo simulations, one may

compute averages of the type

GF (it)
NF

=

Ft
D

(cid:16)

′

B0

⋆, B0
⋆

=

(cid:17)E

1
0 V (xs+σ0B

0
u)du+

1
0
0 V (xs+σ0B
u

′)du]

EE′e−(β/2)[
R
EE′e−(β/2)[
R

1
0 V (xs+σ0B0

u)du+

R

R

Ft
1
0 V (xs+σ0B0
u

′

(cid:16)
)du]

′

B0

⋆, B0
⋆

,

(cid:17)

(34)

where

Ft

×

′

B0

⋆, B0
⋆

=

2

1
β−tβt

(cid:17)
(cid:16)
e−(β/2)[∆t(B

0

0
⋆)+∆−t(B
p
⋆

F
n
′)] +

(cid:16)

0
t

0
−t

′

B0

⋆, B0
⋆

F
(cid:16)
0
0
⋆)+∆t(B
e−(β/2)[∆−t(B
⋆

B0

⋆, B0
⋆
′)]

(cid:17)
′

(cid:17)
.

×

(35)

o
is symmetric under

′

B0

⋆, B0
⋆

(cid:17)

Ft

(cid:16)

The estimating function

′

′

=

B0

B0

F−t

⋆, B0
⋆

time inversion — that is,
Ft
— as well as under the exchange of the variables B0
′.
B0
⋆
The construction of estimators for derivatives in origin
is straightforward and follows from Eq. (34). By Monte
Carlo simulations, one may compute the following aver-
ages

⋆, B0
⋆
⋆ and
(cid:17)

(cid:16)

(cid:16)

(cid:17)

1

NF

dk
dtk GF (it)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

t=0

1

0 V (xs+σB

EE′e−(β/2)[
R
EE′e−(β/2)[
R

0

u)du+

1

0 V (xs+σB

0
u

′)du] dk

R
1
0 V (xs+σB0

u)du+

dtk Ft
1
0 V (xs+σB0
u

(cid:16)
′
)du]

′

B0

⋆, B0
⋆

R

t=0

.

(cid:17) (cid:12)
(cid:12)
(cid:12)

8

(36)

where σ±t = σtσ−t/σ0, are clearly simpler to express in
the new coordinate system. Moreover, transformations
of the type shown by Eq. (37) are consistent with the
aforementioned advice of Predescu and Doll that the time
dependence of paths should be buried into the potential
part of the Feynman-Kac formula whenever possible.

′

(cid:17)

(cid:16)

∈

B0

(
−

⋆, B0
⋆

is well-deﬁned for all t

In this respect, the reader should notice that the function
β~/2, β~/2) and
Ft
is inﬁnitely diﬀerentiable on this interval provided that
the potential V (x) is also diﬀerentiable inﬁnitely many
times. In practical applications, the time derivatives ap-
pearing in Eq. (36) are to be computed by ﬁnite diﬀer-
ence. We shall further discuss this matter in Section IV.
We now describe the construction of estimators for the
case of a d-dimensional system. For deﬁniteness, we shall
assume that the physical coordinates have been rescaled
such that all masses are equal to the common value m0.
Perhaps after a reorientation of the system of axes so that
the ﬁrst coordinate x1 is along the reaction coordinate,
the reactants and products are assumed to be separated
in the conﬁguration space Rd by an hyperplane of equa-
tion x1 = xs. For the remainder of this section, when
dealing with expressions involving the density matrix, it
turns out that it is more convenient to work with the pair
of position coordinates (x, z), with z = x′
x, rather
than with the standard (x, x′) pair. This is so because
identities of the type

−

dx′ρf p(x, x′; βt)ρf p(x, x′; β−t)f (x′

x)

−

R

Z

=

1
2πσ0 Z

R

2

dze−z

f (zσ±t) ,

(37)

0
t

F

(cid:16)

x, z, B0

⋆, B0
⋆

′

=

1
2σ2

−t,0

1
2σ2
t,0

+

1

(cid:17)

With these clariﬁcations, we leave it for the reader
to demonstrate that the multidimensional analogues of
the various quantities necessary for the construction of
derivative estimators are as follows. With the under-
standing that the quantities V ′(x) and V ′′(x) now denote
the ﬁrst order and the second order partial derivatives
against the reaction coordinate x1, the multi-dimensional
analogue of Eq. (25) is

+β2
t

+β2
−t

0
(cid:20)Z

V ′

x + σ±tzu + σtB0
u
(cid:16)
V ′

(cid:17)
x + σ±tzu + σ−tB0
u

1

1

′

udu

0
(cid:21) (cid:20)Z

udu

0
(cid:21) (cid:20)Z

′

V ′

x + σ±tzu + σtB0
u
(cid:16)
V ′

(cid:17)
x + σ±tzu + σ−tB0
u

1

(1

u)du

−

(cid:21)

(1

u)du

−

(cid:21)

β−tβt

β−tβt

0
(cid:20)Z

1

1

0

(cid:20)Z

0

(cid:20)Z
1

−

−

−

0

Z

(cid:0)

(cid:0)
V ′

(cid:1)
x + σ±tzu + σ−tB0
u

udu

1

(cid:0)
V ′

(cid:1)
′
x + σ±tzu + σtB0
u

(1

u)du

(38)

(cid:0)

V ′

x + σ±tzu + σtB0
u
(cid:16)

(cid:1)

′

udu

0
(cid:21) (cid:20)Z

1

0

(cid:21) (cid:20)Z

(cid:17)
(cid:16)
x + σ±tzu + σ−tB0
u

V ′

(1

u)du

−

−

(cid:21)

(cid:21)

(cid:17)
u(1

(cid:1)

u)du

βt

−

−

(cid:0)

1

0
Z

(cid:1)

V ′′

x + σ±tzu + σtB0
u
(cid:16)

′

(cid:17)

u(1

u)du.

−

β−t

V ′′

x + σ±tzu + σ−tB0
u

The quantities B0
independent d-
dimensional standard Brownian bridges (d-dimensional
vector valued stochastic processes, the components of

u and B0
u

′ are

which are independent one-dimensional standard Brow-

nian bridges). We also deﬁne

The normalization coeﬃcients

NF now reads

9

1

V

0
Z
1

(cid:0)

2

∆t

x, z, B0
⋆

=

V

x + σ0zu + σ0B0
u

du

(cid:0)

(cid:1)
2βt
β

−

0
Z

(cid:0)
x + σ±tzu + σtB0
u

(cid:1)
du.

(39)

(cid:1)

as well as

Ft

(cid:16)

e−(β/2)[∆t(x,z,B

⋆)+∆−t(x,z,B
p

0

×

x, z, B0

⋆, B0
⋆

′

=

0
−t

x, z, B0

⋆, B0
⋆

′

1
β−tβt
′)] +

0
⋆

F

n

(cid:16)
x, z, B0

⋆, B0
⋆
(cid:16)
0
⋆)+∆t(x,z,B
e−(β/2)[∆−t(x,z,B

F

0
t

0
⋆

′

(cid:17)
′)]

(cid:17)
(40)

(cid:17)

×

.

o

NF =

1
8πm0 (cid:18)

1
2πσ0 (cid:19)

d−1

ZS

dxdzEE′e−kzk

2

e−(β/2)[
R

1

0 V (x+σ0zu+σ0B

0
u)du+

1

0 V (x+σ0zu+σ0B

0
u

′)du]

(41)

R

−

2)-dimensional hyperplane

where the integration against the variables x and z is
done on the (d
, which is
the subset of the space Rd
Rd deﬁned by the equations
×
x1 = xs and z1 = 0. Therefore, the symbol dx stands for
dxd, whereas dz stands for
the Lebesgue measure dx2 · · ·
d)1/2
1 +
dzd. The Euclidian norm
dz2 · · ·
d)1/2, since the
= (z2
can be replaced by

= (z2
+ z2

k
2 +

+ z2

· · ·

S

z
k
· · ·

z
k

k

coordinate z1 is kept constant and equal to zero during
integration.

In these conditions, up to the value of the normal-
NF , the derivatives in origin of the
ization coeﬃcient
ﬂux-ﬂux autocorrelation functions can be determined by
Monte Carlo integration, as implied by the equation

=

1

NF

Dk
NF

=

S dxdzEE′e−kzk
R

dk
dtk GF (it)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

t=0
e−(β/2)[
R

1

0 V (x+σ0zu+σ0B

0
u)du+

1

0 V (x+σ0zu+σ0B

0
u

′)du] dk

R
1
0 V (x+σ0zu+σ0B0

u)du+

1
(cid:16)
0 V (x+σ0zu+σ0B0
u

′

)du]

x, z, B0

⋆, B0
⋆

′

dtk Ft

S dxdzEE′e−kzk2 e−(β/2)[
R

R

R

t=0

.

(42)

(cid:17) (cid:12)
(cid:12)
(cid:12)

IV. SOLVING THE INVERSE MOMENT
PROBLEM: A NUMERICAL EXAMPLE

Until now, we have demonstrated that the sequence of
derivatives at origin completely and uniquely character-
izes the correlation function. Moreover, the sequence of
derivatives can be computed by Monte Carlo simulation
via estimators that have ﬁnite variance in the limit of an
inﬁnite number of path variables (of course, for analytic
potentials). At this point, it is natural to address the
problem of recovering the correlation functions from the
sequence of computed moments.

More precisely,

let us assume that we have com-
puted the set of even and nonnegative derivatives
D0, D2, . . . , D2n and that we have calculated the mo-

ments µ2k = D2k/D0, for 1
n. At the very least,
≤
we would like to construct a sequence of symmetric prob-
ability distributions dPO,n(ω) such that

≤

k

ω2kdPO,n(ω),

(43)

µ2k =

Z
n and n

R

k

≤

≤

≥

1. Indeed, if Eq. (43) is sat-
for all 1
isﬁed, then so is the hypothesis of Theorem 3, theorem
that further guaranties that the correlation functions are
fully recovered (pointwise) in the limit n
. However,
many times, the pointwise reconstruction of the correla-
tion functions does not suﬃce. For example, in the case
of the ﬂux-ﬂux correlation function, the chemical physi-
cists are usually interested in computing the absolute rate
of reaction, which is the time integral of the correlation

→ ∞

function

∞

k(T )Qr(T ) =

GF (t)dt.

(44)

0
Z
Because the ﬁrst n even moments do not uniquely de-
termine a symmetric probability distribution, we have
freedom in choosing the reconstruction algorithm in such
a way that not only the pointwise values of the corre-
lation functions but also various integral expressions are
recovered in the limit n

.
→ ∞
Although the optimal reconstruction algorithm de-
pends upon the nature of the correlation functions and of
the quantum information being sought, we shall discuss
and utilize in the present paper a choice that is based
on the Maximum Entropy approach. The Maximum En-
tropy method18,30 suggests that a useful criterion is to
chose the symmetric probability distribution that maxi-
mizes the entropy. In information theory, such a prob-
ability distribution is the least biased one that is com-
patible with the partial information represented by the
known ﬁrst moments. One of the advantages of the Max-
imum Entropy algorithm is that it can be modiﬁed so
that to incorporate additional physical information that
depends upon the nature of the quantum results being
sought. Such approaches will be discussed in future work.
The most basic application of the Maximum Entropy
method leads to the following inversion algorithm.30,31
The power spectrum ˆGO(ω) of the correlation function is
approximated by the expression

ˆGO,n(ω) = exp

(45)

n

λj ω2j

,




−




j=0
X

where the coeﬃcients λ0, . . . , λn play the role of Lagrange

multipliers and can be determined from the equations



D2k =

ˆGO,n(ω)ω2kdω,

0

k

≤

≤

n.

(46)

R

Z

Notice that the form of the approximant given by
Eq. (45) ensures both the positivity and the symmetry of
the power spectrum, properties that have been demon-
strated in Section II. Then, the entropy of ˆGO,n(ω) is
given by

H

=

ˆGO,n
h

i

−

R

Z

ˆGO,n(ω) ln

ˆGO,n(ω)
i
h

dω =

λjD2j.

n

j=0
X

The system of equations (46) can be replaced by

λ0 = ln

1
D0 Z

R

(cid:20)

e−

n
j=1 λj ω

2j

dω

P

(cid:21)

and

D2k = D0

n
j=1 λj ω

2j

dω

P
j=1 λj ω2j
n

dω

R w2ke−
R e−

R

P

R

,

1

k

n.

(49)

≤

≤

(47)

(48)

10

It is then a simple exercise to verify that Eqs. (49) are
satisﬁed for all 1
n provided that the λj’s represent
the coordinates of the minimum of the entropy functional

≤

≤

k

H

ˆGO,n
h

i

= D0 ln

1
D0 Z

R

exp





n



−



j=1
X
n

+

j=1
X

λjω2j

dω








λjD2j,

(50)

which is a convex function of λ1, . . . , λn. Due to the con-
vexity of the function that is minimized, the minimum
of Eq. (50), if it exists, is unique. The necessary and
suﬃcient conditions for the existence of the minimum
are known in literature.30,31 In the present article, the
minimization of Eq. (50) has been carried out with the
help of Newton’s steepest descent technique. The Hes-
sian matrix is evaluated explicitly and utilized to predict
the direction along which to line-minimize. The Golden
Section search is utilized to optimize along the computed
direction. As discussed in Ref. 31, the computation of the
coeﬃcients λj is unstable and, depending upon the num-
ber of even derivatives considered, may require extended-
precision arithmetics.

In order to demonstrate the accuracy of the proposed
technique, we apply the Maximum Entropy approach de-
scribed in the preceding paragraph to the problem of
computing the quantum rate of reaction for a symmetric
Eckart barrier at various temperatures. The parameters
for the Eckart barrier are chosen to correspond approxi-
mately to the H + H2 reaction.32 The potential is

V (x) = V0 sech(ax)2,

(51)

with the parameters V0 = 0.425 eV, a = 1.36 a.u., and
m0 = 1060 a.u.

We have evaluated the ﬂux-ﬂux correlation function
and its ﬁrst ﬁve even derivatives at origin by Monte Carlo
simulations, as described in Section III. The derivatives
′) appearing in Eq. (36) are re-
Ft(B0
of the estimator
placed by numerical approximations computed via cen-
′) is sym-
Ft(B0
tral diﬀerence. Remembering that
metric under the transformation t
t, the ﬁnite-
7→ −
diﬀerence formulas take on the general form

⋆, B0
⋆

⋆, B0
⋆

d2k
dt2k Ft(B0

′

⋆, B0
⋆

) =

1
τ 2k

ck,jFjτ (B0

⋆, B0
⋆

′

)+

(τ 12−2k),

O

(52)
where the coeﬃcients cj,k are given in Table I. Numerical
experiments have demonstrated that a time step of

5

j=0
X

τ =

1
64

~β
2

(53)

is suﬃcient for a determination of the derivatives to an
accuracy of less than 2%.

Regarding the computation of derivatives by ﬁnite-
diﬀerence, the range of values of τ that can be utilized

depends on the order of the derivatives as well as on
the numerical precision with which the computations are
conducted. For the present paper, we have employed
the IEEE ﬂoating-point data type double (64 bit) for
the representation of real numbers. Increasing the order
of the derivatives beyond 10 requires use of specialized
extended-precision data types. Although the theoretical
decrease in computing speed with the size of the data
type (and, consequently, with the order of the “com-
putable derivatives”) is a small order polynomial, the
codes become more diﬃcult to program. However, with
the advent of programming languages that allow for op-
erator overloading, this might change in the near future,
once better and faster libraries implementing extended-
precision data types are developed.33

2k

0

4

8

10

ck,0

1

ck,1

0

ck,2

0

ck,3

0

ck,4

0

ck,5

0

2 −5269/1800

10/3

−10/21

5/63

−5/504

1/1575

1529/120 −1669/90 4369/630 −541/420 1261/7560 −41/3780

6 −1023/20

154

−252

323/4

−252

420

−39

136

−240

87/8

−46

90

−19/12

13/120

26/3

−20

−2/3

2

TABLE I: Numerical values for the coeﬃcients ck,j appearing
in the ﬁnite-diﬀerence approximations of the derivatives of
order 2k.

Many times, the chemical physicist takes the diﬀer-
ent approach of constructing models (and, therefore, em-
pirical inversion techniques) that have already incorpo-
rated additional physical input.34 In such cases, the ﬁ-
nite number of derivatives that can be computed using
the data type double may suﬃce for many practical pur-
poses. This is why we have considered appropriate to
table the coeﬃcients cj,k for the reader’s convenience.
General rules for computing derivatives of arbitrary or-
ders and accuracy have been discussed elsewhere.35 Ac-
cording to Eq. (52), the accuracy of the ﬁnite-diﬀerence
scheme is largest for the small-order derivatives and de-
creases for the larger-order derivatives, if all the infor-
′)
mation contained in the 6 points at which
is evaluated is to be taken into consideration. This is
to our advantage, because the low-order derivatives are
computed with increased precision despite the relatively
large value of the discretization step τ demanded by the
higher-order derivatives.

Ft(B0

⋆, B0
⋆

For the sake of an example, in Table II, we present
the Monte Carlo estimates of the ﬁrst ﬁve even deriva-
tives at origin for the Eckart barrier at the temperature
of 100 K. The derivatives have been evaluated in 10
million Monte Carlo points with the help of the estima-
tors introduced in Section III. For the discretization of
the Feynman-Kac formula, we have employed Predescu’s
fourth-order path-integral technique36 with a number of
64 path variables. We mention that, at this temperature,
the Monte Carlo sampling has required the use of par-
allel tempering,37,38 which has successfully coped with
the sparse sampling problem caused by the crossing and

11

recrossing of the barrier by the Brownian paths. As a
matter of fact, by Monte Carlo integration, we have com-
NF and the associated statistical
puted the ratios D2k/
errors (two standard deviations). The quantity
NF has
been evaluated with the help of the numerical matrix
multiplication technique,27,28 which has provided essen-
tially exact results. Thus, the relative errors reported
in Table II are equal to the relative errors of the ratios
D2k/
NF and are, therefore, representative of the vari-
ances of the estimating functions utilized in the Monte
Carlo simulation.

Order

0

2

4

6

8

10

Value 5.787E-17 2.389E-22 4.010E-27 1.395E-31 7.985E-36 6.781E-40

Error

2.5%

2.4%

2.4%

2.7%

3.9%

6.1%

TABLE II: Derivatives (second row) and relative errors (third
row) for the symmetric Eckart barrier at 100 K. The errors
are twice the percentile relative value of the standard devia-
tion. The errors do not include the systematic errors due to
the utilization of ﬁnite-diﬀerence approximations, which have
been estimated to increase the ﬁnal errors with less than 2%.

Once the power spectrum ˆGF,n(ω) is determined, the
absolute rate of reaction can be computed from Eq. (44),
as the quantity

k(T )Qr(T ) =

GF,n(t)dt

∞

0
Z
1
2

=

∞

−∞

Z

GF,n(t)dt = π ˆGF,n(0). (54)

Let us remember that

GF,n(t)

GF (t),

→

R,

t
∀

∈

for all reconstruction algorithms that satisfy the hypoth-
esis of Theorem 3. However, as already mentioned sev-
eral times, this does not automatically imply pointwise
convergence in the frequency domain. Sure enough, con-
vergence in the frequency domain is necessary only for
the purpose of computing the absolute rate of reaction
as the time integral of the ﬂux-ﬂux autocorrelation func-
tion, the power spectrum of which is continuous at origin.
It is not required for other autocorrelation functions. Be-
cause it depends on the physical signiﬁcance of the cor-
responding autocorrelation functions and on the nature
of the quantum information that is sought, the develop-
ment of optimal reconstruction algorithms is a case by
case problem.

It is beyond the purpose of this paper to conduct any
mathematical proofs related to the pointwise convergence
of the power spectrum of the ﬂux-ﬂux correlation func-
tions. However, the percentile relative errors for the ab-
solute rates of reaction presented in Table III strongly
suggest that the Maximum Entropy algorithm discussed
in previous paragraphs is viable for the purpose of com-
puting rates of reaction. The errors decrease as the tem-
perature is lowered, but the reader may notice that the

relative errors are suﬃciently small to make the algo-
rithm useful even in the tunneling regime of temperatures
(T < 300 K).

At large temperatures, the relative errors converge to
the relative errors for a free particle. The thermally-
symmetrized ﬂux-ﬂux autocorrelation function for the
free particle is4,6

Its power spectrum reads

GF (t) =

1
βh

(β~/2)2
[t2 + (β~/2)2]3/2 .

ˆGF (ω) =

1
βh

ω~β
2π

K1

ω~β
2

,

(cid:19)

(cid:18)

(55)

(56)

where K1(x) denotes the respective modiﬁed Bessel func-
tion of the second kind. The function xK1(x) is contin-
uous at origin, indeed, but its even derivatives in origin
are not deﬁned. Therefore, the function xK1(x) is diﬃ-
cult to approximate around origin by smooth functions
of the type given by Eq. (45). Thus, for example, a useful
direction for future research is to modify the Maximum
Entropy algorithm so that to properly account for the
known high-temperature limit.

Temperature

Order of
derivatives 100 K 200 K 300 K 500 K 1000 K 2000 K ∞
-25.7 -27.6
8.4
-15.0 -17.1
2.5
-11.9 -13.4
0.0

-18.3
-7.7
-5.4

-13.8
-4.9
-2.9

-2.1
1.8
1.3

-2.3
-0.8
0.3

2
6
10

TABLE III: Percentile relative errors for the absolute rates
of reaction computed using all derivatives up to the maxi-
mum orders of 2, 6, and 10, respectively. The errors are given
as functions of temperature. Whenever the minimization al-
gorithm did not converge properly while using the maximal
number of derivatives, a smaller number of derivatives has
been utilized. The relative errors for the high-temperature
limit are those for the free particle case (which are indepen-
dent of temperature).

V. SUMMARY AND DISCUSSION

A new technique for extracting quantum dynamical in-
formation from imaginary-time data has been proposed.
The technique consists in solving a symmetric Hamburger
moment problem with even-order moments related to the
even-order derivatives at origin of the quantum auto-
correlation function. We have demonstrated that these
derivatives at origin uniquely determine the autocorrela-
tion function. The derivatives can be computed by Monte

12

Carlo simulations with the help of estimators of ﬁnite
variance. The pointwise reconstruction of the autocor-
relation functions can be performed by those inversion
algorithms that satisfy the hypothesis of Theorem 3, al-
though additional care is needed if other quantities, as for
instance certain integral values, are also sought. A Maxi-
mum Entropy inversion algorithm for the Hamburger mo-
ment problem has been presented and numerically tested
for the problem of computing absolute rates of reaction
for a symmetric Eckart barrier.

Perhaps, the most important step in the present de-
velopment is the realization that the derivatives at origin
of the imaginary-time autocorrelation functions are com-
putable solely by Monte Carlo simulations. As argued
in the introduction, the sequence of derivatives at origin
represents a set of data that is more suitable for the prob-
lem of extracting quantum dynamical information than
the mere Monte Carlo evaluation of the imaginary-time
autocorrelation function on a grid. However, future re-
search is necessary in order to quantify in precise manner
the eﬃciency of the new algorithm.
In particular, the
scaling of the variances of the Monte Carlo estimators
with the degree of the derivatives, the dimensionality of
the physical system, and the temperature must be deter-
mined.

The numerical results presented in Section IV demon-
strate that the derivatives at origin of autocorrelation
functions contain useful information that can be utilized
in at least two ways. One may employ this informa-
tion together with various inversion techniques for the
Hamburger moment problem. In this respect, I believe
that inversion algorithms based on the Maximum En-
tropy principle will be most useful, especially because
such algorithms can be modiﬁed so that to incorporate
additional physical information (as, for instance, a cer-
tain limiting behavior). If only a small number of deriva-
tives are computed, the chemical physicist has also the
option of developing certain physical models depending
on parameters that can be determined from matching the
known derivatives. Which of these two ways will be the
most successful for practical applications remains to be
seen.

Acknowledgments

The author acknowledges support from National Sci-
ence Foundation through Grant No. CHE-0096576. He
also wishes to express a special thanks to Professor
William H. Miller for suggestions and stimulating dis-
cussions concerning the present development.

∗

Electronic address: cpredescu@comcast.net

1 J. D. Doll, M. Eleftheriou, S. A. Corcelli, and David L.

Freeman, Quantum Monte Carlo Methods in Physics and
Chemistry, edited by M.P. Nightingale and C.J. Umrigar,
NATO ASI Series, Series C Mathematical and Physical
Sciences, Vol. X, (Kluwer, Dordrecht, 1999).

2 G. Baym and D. Mermin, J. Math. Phys. 2, 232 (1961).
3 B. J. Berne and G. D. Harp, Adv. in Chem. Phys. 17, 63

13

20 A. Tagliani, J. Math. Phys. 35, 5087 (1994).
21 C. Predescu and J. D. Doll, J. Chem. Phys. 117, 7448

(2002).

22 C. Predescu, D. Sabo, J. D. Doll, and D. L. Freeman, J.

Chem. Phys. 119, 12119 (2003).

23 J. N. Lyness, Math. Comput. 22, 352 (1968).
24 T. Carleman, Le Fonctions Quasi-Analytiques (Gauthier-

25 H. Hamburger, Math. Ann. 81, 235 (1920); 82, 120 (1921);

82, 168 (1921).

26 B. Simon, Functional Integration and Quantum Physics

(Academic, London, 1979).

27 A. D. Klemm and R. G. Storer, Aust. J. Phys. 26, 43

28 D. Thirumalai, E. J. Bruskin, and B. J. Berne, J. Chem.

29 T. Yamamoto and W. H. Miller, J. Chem. Phys. 120, 3086

30 E. T. Jaynes, in The Maximum Entropy formalism, edited
by R. D. Levine and M. Tribus (MIT Press, Cambridge,
1978), pp. 15-118.

31 A. Tagliani, J. Comput. Appl. Math. 90, 157 (1998).
32 W. H. Miller, Y. Zhao, M. Ceotto, and S. Yang, J. Chem.

33 Y. Hida, X. S. Li, and D. H. Bailey, in Proceedings of the
15th IEEE Symposium on Computer Arithmetic, IEEE
Computer Society, 2001, pp. 155-162.

34 N. F. Hansen and H. C. Andersen, J. Chem. Phys. 101,

6032 (1994).

179 (1999).

909 (1995).

(1996).

36 C. Predescu, Phys. Rev. E 69, 056701 (2004).
37 C. J. Geyer and E. A. Thompson, J. Am. Stat. Assoc. 90,

38 K. Hukushima and K. Nemoto, J. Phys. Soc. Jpn. 65, 1604

4 W. H. Miller, S. D. Schwartz, and J. W. Tromp, J. Chem.

Villars, Paris, 1926).

Phys. 79, 4889 (1983).

5 W. H. Miller, J. Chem. Phys. 61, 1823 (1974).
6 W. H. Miller, J. Phys. Chem. A 102, 793 (1998).
7 J. E. Gubernatis, M. Jarrell, R. N. Silver, and D. S. Sivia,

Phys. Rev. B 44, 6011 (1991).

8 M. Jarrel and J. E. Gubernatis, Phys. Rep. 269, 113

(1973).

9 D. Thirumalai and B. J. Berne, J. Chem. Phys. 79, 5029

Phys. 79, 5063 (1983).

10 E. Gallicchio and B. J. Berne, J. Chem. Phys. 101, 9909

(2004).

(1970).

(1996).

(1983).

(1994).

11 D. Kim, J. D. Doll, and J. E. Gubernatis, J. Chem. Phys.

12 D. Kim, J. D. Doll, and D. L. Freeman, J. Chem. Phys.

13 G. Krilov, E. Sim, and B. J. Berne, J. Chem. Phys. 114,

Phys. 119, 1329 (2003).

106, 1641 (1997).

108, 3871 (1998).

1075 (2001).

112, 2605 (2000).

2824 (2001).

14 E. Rabani, G. Krilov, and B. J. Berne, J. Chem. Phys.

15 E. Sim, G. Krilov, B. J. Berne, J. Phys. Chem. A 105,

(Duxbury, New York, 1996).

17 G. A. Athanassoulis and P. N. Gavriliadis, Prob. Engng.

Mech. 17, 273 (2002).

18 E. T. Jaynes, Phys. Rev. 106, 620 (1957).
19 H. K. Kesavan and J. N. Kapur, Entropy Optimization
Principles with Applications (Academic Press, London,
1992).

16 R. Durrett, Probability: Theory and Examples, 2nd ed.

35 I. R. Khan and R. Ohba, J. Comput. Appl. Math. 107,

