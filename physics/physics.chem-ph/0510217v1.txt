5
0
0
2
 
t
c
O
 
4
2
 
 
]
h
p
-
m
e
h
c
.
s
c
i
s
y
h
p
[
 
 
1
v
7
1
2
0
1
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Eﬃcient computation of the ﬁrst passage time distribution of the generalized master
equation by steady-state relaxation

David Shalloway∗
Biophysics Program, Dept. of Molecular Biology and Genetics,
Cornell University, Ithaca, New York 14853, USA

Anton K. Faradjian
Department of Physics, Cornell University, Ithaca, New York 14853, USA

The generalized master equation or the equivalent continuous time random walk equations can
be used to compute the macroscopic ﬁrst passage time distribution (FPTD) of a complex stochastic
system from short-term microscopic simulation data. The computation of the mean ﬁrst passage time
and additional low-order FPTD moments can be simpliﬁed by directly relating the FPTD moment
generating function to the moments of the local FPTD matrix. This relationship can be physically
interpreted in terms of steady-state relaxation, an extension of steady-state ﬂow. Moreover, it is
amenable to a statistical error analysis that can be used to signiﬁcantly increase computational
eﬃciency. The eﬃciency improvement can be extended to the FPTD itself by modelling it using a
Gamma distribution or rational function approximation to its Laplace transform.

PACS numbers: 02.50.Ey, 02.70.-c, 05.10.-a, 82.20.Uv

I.

INTRODUCTION

The ﬁrst passage time distribution (FPTD) [1] con-
cisely describes the kinetics of macroscopic transitions of
complex macromolecular systems; e.g., the transition of
a disordered heteropolymer from random to speciﬁcally-
absorbed conformations [2] or the dynamics of protein
folding [3, 4]. If a statistical ensemble of systems is pre-
pared at time t = 0 in an initial metastable macroscopic
state (macrostate) i and Pf (t) is the probability that an
ensemble member is in absorbing ﬁnal macrostate f at
time t, then the FPTD is

ϕ(τ ) = dPf (t)/dt

|t=τ .

We assume that f is the only absorbing state and that
the system is ergodic, so

(1)

(2)

The mean ﬁrst passage time (MFPT) is the ﬁrst moment
τ ϕ
h

, where

i ≡ hh

ii

τ

∞

Z
0

ϕ(τ )dτ = Pf (

) = 1 .

∞

x(τ ) dτ ,

i ≡ Z
0

∞

∞

x
h

x

hh

ii ≡ Z
0

x(τ )ϕ(τ ) dτ .

−1 [5, 6].

τ

hh

ii

It determines the transition rate as

Except for the simplest models, ϕ(τ ) and its moments
can not be analytically computed. Moreover, direct nu-
merical computation, e.g. by molecular or stochastic dy-
namics, is often unaﬀordable. For example, proteins typ-
105 conformational degrees-of-freedom
ically have 103

−

∗Electronic address: dis2@cornell.edu

and the macroscopic timescales of interest can be > 1012
times larger than the microscopic timescale [7], so huge
amounts of computational eﬀort would be needed for di-
rect simulation.

Coarse-graining can overcome these problems. The
essential idea is to subdivide the macroscopic transi-
tion into a network of discrete intermediate mesoscopic
transitions that are fast enough for feasible computation
(e.g., using Monte Carlo [8] or molecular dynamics [9]
methods) yet slow enough (relative to the microscopic
timescale) for approximation by a ﬁrst-order stochastic
equation.

The simplest approximation of this sort is a Markovian
master equation [1] for P (t), the N -vector that speciﬁes
ensemble probability over the intermediate mesoscopic
states and initial and ﬁnal states (see [10] and references
therein for examples in the context of protein folding).
However, this approach will only be accurate when each
mesoscopic transition can be characterized as a simple
Poisson process. This is not the case for many important
problems because of fractal or quasi-diﬀusive dynamics or
because the timescale that would be needed to achieve
the Markovian limit is too long for direct computation
[11, 12].

The non-Markovian classical generalized master equa-
tion is a more robust approximation that can be used in
this situation [13, 14, 15]. Assuming injection at t = 0 of
ensemble members into initial state i, it is

dP (t)
dt

= δ(t

0+)ˆǫi − Z

0

−

Γ(τ )

P (t

τ )dτ ,

(3)

·

−

∞

×

where Γ(τ ) is the N
N matrix of transition functions
which include memory eﬀects and ˆǫs denotes the basis
vector that has component s equal to 1 and all other
components equal to 0. The ﬁrst term, along with the
boundary condition P (
) = 0, initializes the system

−∞

with no memory at t = 0. Conservation of probability
and causality imply that

1

·

Γ(τ ) = 0 , Γs′s(τ )

0

(s′

= s) ,

≤

(where 1 is the N -vector with all components equal to
1) and s and s′ take values corresponding to i, f , and all
the intermediate mesoscopic states. Therefore

1

·

dP (t)/dt = δ(t

0+) .

−

Since f is absorbing,

Γ(τ )

ˆǫf = 0 .

·

(4)

(5)

If Γ(τ ) can be analytically computed (e.g., by projection
[16, 17]), then Eqs. (1) and (3) can be used to compute
ϕ(τ ).

When Γ(τ ) can not be computed, an approach us-
ing numerical simulations can be employed [9]. By ini-
tializing multiple simulations in state s and determin-
ing the distribution of waiting times for ﬁrst-transitions
to the other mesoscopic states, simulations can be used
N local FPTD matrix
to determine K(τ ), the N
(sometimes called the “ﬁrst-jump waiting time” matrix).
= s′) is the probability density that, af-
−
ter arriving at state s, a system waits for an interval
τ before ﬁrst leaving and that it goes to s′. For com-
pact notation, we deﬁne the diagonal elements of K(τ )
as Kss(τ )
s′6=s Ks′s(τ ). Thus, like Γ(τ ), K(τ ) sat-
isﬁes

Ks′s(τ ) (s

≡ −

×

P

1

·

K(τ ) = 0 , Kss′ (τ )

ˆǫf = 0 ,
(6)
and, by its deﬁnition and the assumption that f is the
only absorbing state,

= s), K(τ )

≤

·

0 (s′

∞

Z
0

Kss(τ ) dτ = 1

(s

= f ) .

(7)

K(τ ) is the kernel of an alternative representation of
stochastic dynamics with memory—the generalized con-
tinuous time random walk (CTRW). Originally intro-
duced to describe random walks on lattices [18, 19], the
CTRW was generalized [20, 21] to a form that can be
extended to memory-dependent stochastic processes on
a mesoscopic network of arbitrary connectivity. In our
notation and assuming t = 0 initialization in state i this
is

dP (t)
dt

∞

− Z

0

= Q(t)

KD(τ )

Q(t

τ )dτ

(8a)

Q(t) = δ(t

0+)ˆǫi +

−

Z
0

K6D(τ )

Q(t

τ )dτ ,(8b)

−

·

∞

−

·

where KD and K6D are the matrices comprised, respec-
tively, of the diagonal or oﬀ-diagonal elements of K, and
the boundary conditions are P (
) = 0. Eq.
(8b) implies that Qs(t)dt is the probability that an en-
semble member makes a transition to state s within the

) = Q(

−∞

−∞

2

interval [t, t + dt), and Eq. (8a) states that dP (t)/dt is
the diﬀerence between the incoming and outgoing prob-
ability ﬂows.

Eqs. (3) and (8) provide equivalent descriptions of the
temporal evolution of P (t) [13, 15], and comparing their
Laplace transforms shows that

Γ(u) = u

K(u)

[I

K(u) =
e

Γ(u)
e

·
−
[uI +

KD(u)]−1
ΓD(u)]−1 ,
e

(9a)

(9b)

e

e

·
e
where I is the identity matrix and we denote the Laplace
∞
0 e−uτ g(τ ) dτ . However,
transform of g(u) as ˜g(u)
R
even though Eq. (9a) determines
K(u), the
inverse Laplace transform needed to determine Γ(τ ) can
be diﬃcult, if not impossible, to compute. Thus, even
though Eqs. (3) and (8) are formally equivalent, only
the CTRW formulation provides a practical way to use
mesoscopic numerical simulations to compute ϕ(τ ).

Γ(u) from

≡

e

e

Faradjian and Elber [9] have recently demonstrated the
feasibility of integrating Eqs. (8) with K(τ ) determined
by molecular dynamics to compute transitions along a
single reaction-coordinate. However, computing ϕ(τ ) by
this approach is computationally wasteful since it is de-
termined to high temporal resolution even though the
experimentally relevant information is usually contained
in only a few of its low-order moments. The unnecessary
price paid is that the complete functional form of K(τ )
must be determined by many (expensive) numerical sim-
ulations.

In Sec. II we present a fundamental new relationship
between the FPTD moments and those of K(τ ) or Γ(τ ).
We show in Sec. III that this relationship can be un-
derstood as an extension of the steady-state ﬂux-over-
population method [5, 22] of computing rate constants
to the case of steady-state relaxation.
In Sec. IV we
show that combining this relationship with statistical er-
ror analysis yields a more accurate and eﬃcient computa-
tional algorithm. In Sec. V we demonstrate how ϕ(τ ) can
be modelled using a few of its moments and a Gamma
distribution or a rational function approximation to its
Laplace transform.

II. THE FPTD MOMENT GENERATING
FUNCTION

The Laplace transform of ϕ(τ ) gives the FPTD mo-

ment generating function:

∞

Xk=0

αk

hh

τ k
ii
k!

= ˜ϕ(

α) .

−

(10)

We assume, as is true in most cases of interest, that
s, s′) and ϕ(τ ) decays faster than e−αmaxτ as
Γs′s(τ ) (
∀
for some positive αmax (corresponding to the
τ
slowest process in the system):

→ ∞

lim
τ →∞

Γs′s(τ )eαmaxτ = lim
τ →∞

ϕ(τ )eαmaxτ = 0 .

(11)

6
6
6
6
−

Thus, ˜ϕ(
α) is analytic in a neighborhood about 0 and
can be diﬀerentiated to yield all moments. (This assump-
tion is not essential, but simpliﬁes the discussion. If it
is not true, the analysis will still be valid for the ﬁnite
moments.)

Taking the Laplace transform of Eq. (1) gives

˜ϕ(

α) =

−

αˆǫf ·

P (

α) .

−

−
P (

e

Eq. (2) implies that ˆǫf ·
α) is not analytic at α = 0,
so expanding ˜ϕ(
α) using this form is delicate [23]. To
avoid this inconvenience, we use Eq. (4) to rewrite Eq.
(1) in a form that does not explicitly involve Pf (t):

−

−

e

ϕ(τ ) = δ(τ

= δ(τ

0+)
0+)

1

1

·

·

−

−

−

−

dP (t)/dt

Π
d ¯P (t)/dt

·

t=τ ,

|t=τ

(13)

(cid:12)
(cid:12)

where

Π

I

ˆǫf ⊗

ˆǫf

−
is the projection operator into the dynamic subspace of
non-absorbing states s

= f and we use the notation

≡

¯A
¯M

A

M

Π
Π

·
·

≡
≡

Π

·

to denote projected vectors ¯A and matrices ¯M . Eq. (13)
relates the FPTD to the loss of probability from the dy-
namic states. Its Laplace transform is

˜ϕ(

α) = 1 + α1

¯P (

α) .

(14)

−

·

−

e

This form is advantageous because Eqs. (1), (2), (4), and
(11) imply that

¯P (t) eαmaxt = 0 ,

lim
t→∞

(15)

so

α) is analytic at α = 0.

¯P (
To complete the solution, we express ¯P in terms of
e

−

by projecting Eq. (3) [using Π
from Eq. (5)] and taking its Laplace transform to get

Γ

·

·

·

¯Γ
¯P , which follows
e

P = ¯Γ

u

¯P (u) = ˆǫi −
e

e

·

e

¯Γ(u)

¯P (u) .

The solution is

¯P (u) = [uΠ +

¯Γ(u)]−1

ˆǫi ,

·

(16)

e

e

where the use of the matrix pseudo-inverse (i.e., the in-
verse within the dynamic subspace) is implied here and
below. Combining this with Eq. (14) gives

˜ϕ(

α) = 1

−

α1

[αΠ

¯Γ(

α)]−1

−

·

−

−

ˆǫi

·

The right-hand-side is analytic at α = 0 because
invertible within the dynamic subspace.

Using Eq. (9a), we reexpress this in terms of

e

(17)

¯Γ(0) is

e
¯K:

˜ϕ(

α) =

−

1

¯K(

α)

[Π +

−

·

−

·

e

α)]−1

e
ˆǫi .

·

(18)

¯K6D(
e

−

3

K(

Since
α) is analytic at α = 0 even without projec-
tion, Eq. (18) can equivalently be written in unprojected
form as [24]

−

e

˜ϕ(

α) = ˆǫf ·

−

[I +

K6D(

α)]−1

ˆǫi .

−

·

(12)

e
Equations (17) and (18) provide the fundamental rela-
tionship between the FPT moment generating function
and Γ and K.

III. THE MOMENT GENERATING FUNCTION
AND STEADY-STATE RELAXATION

To elucidate the physical signiﬁcance of Eq. (17), we
compare the computation of the MFPT using the gen-
eralized master equation with the computation of the
transition rate (MFPT−1) using the steady-state ﬂux-
over-population method [5, 22]. The latter computes the
rate as the magnitude of the ﬂux of systems divided by
the total dynamic population in a steady-state situation.
We begin to relate the generalized master equation to
the steady-state by noting that the solution of Eq. (3),
P (t), gives the response of a linear system to an impulse
and so is the Green’s function for the general solution:
If systems are injected continuously at a non-negative
rate r(t) beginning at t = 0, the resultant population
distribution vector P [r; t] will satisfy

dP [r; t]
dt

= θ(t)r(t)ˆǫi − Z

0

Γ(τ )

P [r; t

τ ]dτ

(19)

·

−

∞

with boundary condition P [r,
side step-function). This has the solution

−∞

] = 0 (θ is the Heavi-

P [r; t] =

P (t

t′)r(t′)dt′ .

(20)

t

Z
0

−

Unlike the Green’s function P (t), which satisﬁes 1
·
P (t) = 1 (t > 0), the general solution P [r; t] is unnormal-
t
ized; the total population is 1
0 r(t′)dt′,
which can increase without bound as t
because of
R
the accumulation of systems in f . To avoid this compli-
cation, we follow the approach used above and focus on
the projected dynamic population vector ¯P [r; t], which
is bounded.

P [r; t] = θ(t)

→ ∞

·

≫

α−1

The steady-state case corresponds to the asymptotic
(t
max) regime with r(t) = j, where j is a positive
constant. More generally, we consider steady-state re-
laxation: the asymptotic regime with r(t) = j exp(
αt)
(α

0). Eqs. (15) and (20) imply the asymptotic form

−

≥
¯P [je−αt; t]

je−αt ¯P∞[α]

∼

(α

0 , t

≥

≫

α−1

max) ,

where ¯P∞[α] is a vector constant. Substituting this into
the projected form of Eq. (19), multiplying by exp(αt)/j
and taking the limit t

gives

→ ∞

∞

α ¯P∞[α] = ˆǫi − Z

−

0

eατ ¯Γ(τ )dτ

¯P∞[α]

·

6
with solution

¯P∞[α] =

[αΠ

¯Γ(

α)]−1

ˆǫi ,

−
e
where the pseudo-inverse is again implied. Comparing
this with Eq. (16) implies that

−

−

·

¯P (

α) = ¯P∞[α] ,

−
so Eq. (14) implies that

e

ϕ(

α) = 1 + α1

¯P∞[α] .

−

·

(21)

We see that the Laplace transform of ¯P (t), and hence
the FPTD generating function, is simply related to the
steady-state relaxation dynamic population vector. The
steady-state calculation of the transition rate is a special
case of this more general relationship: Eqs. (10) and (21)
imply that

τ

= 1

¯P∞[0] .

(22)

hh

ii

·
Since j ¯P∞[0] is the steady-state solution for constant ﬂux
j and its inner product with 1 is the sum over the pop-
ulation in all the dynamic states, Eq. (22) states that
the MFPT is the total dynamic population over the ﬂux.
This is equivalent to the statement [5, 22] that the tran-
sition rate is the ﬂux-over-(dynamic) population.

IV. EFFICIENT CALCULATION OF THE FPTD
MOMENTS

Eqs. (10) and (17) imply that

= 1, in agreement

with Eq. (2). Expanding Eq. (17) to ﬁrst order gives

ϕ
i
h

τ

= 1

¯Γ(0)−1

ˆǫi = 1

¯Γ
· h

−1
i

ˆǫi .

(23)

·

·

e

ii

hh

·
The same result would be obtained if we ignored all mem-
ory eﬀects and approximated Γ(τ )
, which is
i
equivalent to replacing the generalized master equation
with a regular master equation having Γ =
. Diﬀer-
i
ences between the moments of these two equations only
appear in higher order.

Γ
δ(τ )
h

Γ
h

≈

When only K(τ ) is known, we can use Eq. (9a) or

expand Eq. (18) to reexpress Eq. (23) in terms of ¯K:
¯K
τ ¯KDi · h
· h

−1
i
ii
To use this relationship to compute
from numerical
simulation data, the time-averages on its right-hand-side
can be approximated by

= 1

(24)

·
τ

ˆǫi .

hh

ii

hh

τ

τ ¯KDiss ≈
h
¯K
h

is′s ≈

τ s
i ,

ns

n−1
s

Xi=1
ns′s/ns

(25a)

(25b)

where ns is the number of simulations that were ini-
tiated in state s, ns′s is the number of those simula-
tions that made their ﬁrst transition to state s′ and

4

τ

ii

hh

→

τ
hh

: i = 1, . . . , ns}

τ s
is the set of ﬁrst transition times
i
{
for the simulations initiated in s. This result is much
easier to compute than numerically solving the CTRW
Eqs. (8) and then integrating Eq. (1) to compute
.
ii
Moreover it does not introduce quantization error, as
occurs when numerically solving Eqs. (8); its estimate
equals that which would be obtained using the
for
CTRW equations in the limit where the numerical quan-
tization size h
0. To prove this, note that we have
already proved that Eq. (24) and the CTRW calcula-
tion are equivalent when the exact K(τ ) and moments
are used. These exact values would be obtained in the
limit of an inﬁnite amount of simulation data. The re-
sult obtained with a ﬁnite amount of simulation data
can be viewed as an approximation to the exact result.
Alternatively, it can be viewed as the exact result for
the problem in which Ks′s(τ ) is proportional to a sum
of δ-functions, each corresponding to one of the wait-
ing times in the set
of numeri-
{
cally computed local ﬁrst passage times from s to s′ i.e.,
ns′ s
τ s
]. The numerical K(τ )
i=1 δ[τ
Ks′s(τ ) =
i
−
−
computed in the limit h
0 and the moments of K
→
computed using Eqs. (25) are both exact for this modi-
ﬁed problem, and thus must yield the same result.

: i = 1, . . . , ns′s}

n−1
s

τ s
i

P

s

s

′

′

A.

Improving accuracy and eﬃciency by sampling

adjustment

i

τ

hh

−

−

and

¯K
h

The accuracy of the steady-state computation of

ii
will depend on the quality of the statistical estimation of
τ ¯KDi
provided by Eqs. (25). The simplest way
h
to use these equations would be to follow the procedure
used to estimate K(τ ) in the CTRW approach and to
initiate the same number of simulations in each state;
1), where ntot is the total number of
i.e., ns = ntot/(N
simulations to be performed. (The denominator is N
1
because no simulations are initiated in the ﬁnal state.)
However, this procedure is not optimal because it does
not account for diﬀerences in the sensitivity of the result
to errors in diﬀerent states. For example, the inverse
−1 appearing in Eq. (24) can be particularly
matrix
i
sensitive to errors in small matrix elements corresponding
to bottlenecks in the probabilistic ﬂow where there tend
to be fewer transitions in the “forward” direction. Since
the expected root-mean-square (rms) statistical errors of
is′s are inversely proportional to
the matrix elements
ns, overall accuracy will be improved if ns is increased
for the bottleneck states while being decreased for other
states to keep ntot constant.

¯K
h

¯K
h

We can use Eq. (24) to analyze the dependence of σ2,
the variance of
, on the ns and thereby to quantita-
tively optimize eﬀort allocation. To simplify notation we
deﬁne

hh

ii

τ

¯Ks′si
,
τ ¯KDiss .
s′ are multinomial probabilities governing ﬁrst tran-

ps
s′
≡ −h
φs ≡ h

The ps

s′6=s ps

sitions out of state s, which by Eqs. (6) and (7) satisfy
s′ = 1. Accounting for the reduction in the stan-
dard error of the mean resulting from repeated sampling,
P
making the approximation that the statistical errors in
φs are independent of those in the ps
s′ [25], and using the
propagation of errors formula, we estimate

σ2 =

n−1
s 

Xs6=f



2

∂
τ
ii
hh
∂φs (cid:19)

(cid:18)

σ2
τ ;s +

∂
τ
ii
hh
∂ps
s′′

σ2
s;s′′s′

Xs′′,s′6=s

∂
τ
ii
hh
∂ps
s′
(26)





where σ2

τ ;s is the variance of the

and

τ s
i }
s′ ] (s′′ = s′)
ps
ps
s′ [1
−
= s′)
(s′′
ps
s′′ ps
s′

{

(cid:26)

−

σ2
s;s′′s′ =

(s′′, s′

= s)

is the approximate multinomial variance tensor for state
s [26]. Since the cost of a simulation is proportional to
its duration, the expected cost of ns simulations initiated
at state s will be nsφs. Minimizing σ2 with respect to
the ns while maintaining a constant total cost implies the
optimality conditions

ns = c φ−1/2

s v
u
u
t

(cid:18)

2

τ
∂
ii
hh
∂φs (cid:19)

σ2
τ ;s +

τ
∂
hh
ii
∂ps
s′′

σ2
s;s′′s′

τ
∂
hh
ii
∂ps
s′

Xs′′,s′6=s

P

(27)
s6=f nsφs = cost.
where c is a constant chosen so that
Eq. (27) determines the ns as explicit functions of the φs,
σ2
τ ;s, and ps
s′. To estimate these parameters, we can ﬁrst
perform a pilot run with a small number of simulations
for each state. More simulations can then be added to
the pilot simulations so that the combined set satisﬁes
Eqs. (27) [27]. Eq. (26) can be used to estimate the error
of the ﬁnal result computed with the combined set of
simulations to determine if the accuracy goal has been
met.

Empirically, we have found that eﬃciency can be fur-
ther improved to a small extent by replacing the max-
imum likelihood estimator of the ps
s′ used in Eq. (25b)
by a Bayes-Laplace estimator (Appendix A). This esti-
mator was used in the example discussed below but only
gave noticeable improvement for the low-accuracy (e.g.,
25–50%) results [28].

B. Example

We compared the eﬃciency of the sampling-adjusted
steady-state procedure with that of the standard CTRW
procedure using the two-dimensional entropic barrier
model studied by Faradjian and Elber [9]. They com-
puted the FPTD for transitions under Brownian dy-
namics with potential energy function U (x, y) = x6 +
100y2)] from an initial state
y6 exp(
−
with x =
1 to a ﬁnal state with x = 0.714 at kT =
0.5 and friction coeﬃcient γ = 0.1 The “exact” value of
was computed using the CTRW method with ﬁve

100x2)[1

exp(

−

−

−

τ

hh

ii

5

P

linearly-ordered intermediate states and ns = 5, 000 nu-
merical simulations initiated at each state (i.e., a total
of ntot = 30, 000 simulations were used with cost =
maxcost = 5, 000
s6=f φs). To assess the accuracy of
the method as cost was decreased, we used their simu-
lation data to determine the geometric rms error [30] of
when fewer simulations were
the CTRW estimates of
ii
used corresponding to maxcost/cost = 2, 4, 8, 16, 32, 64,
128, and 256. For each value of cost CTRW estimates of
were computed for 4,000 random data subsets, and
τ
hh
their geometric rms error was computed relative to the
“exact” value [29].

hh

ii

τ

To assess the performance of the sample-adjusted
steady-state procedure for a speciﬁed cost, we ﬁrst per-
formed a pilot run (with ns the same for all states)
costing 1/4 cost, used the estimated values of φs, σ2
τ ;s,
and ps
s′ and Eqs. (27) to optimize the distribution across
states of additional simulations costing 3/4 cost, and
using Eqs. (24), (25a), and the Bayes-
evaluated
Laplace proportions estimator (Appendix A) with the
combined set of simulations. This procedure was re-
peated 4,000 times to estimate the geometric rms error.
Additional tests showed that the results were not highly
sensitive to the size of the pilot run.

τ
hh

ii

The geometric rms errors for both methods as a func-
tion of cost are plotted in Fig. 1 and show that the sam-
pling adjustment increased eﬃciency slightly more than
two–fold. For example, cost = maxcost/8 was needed
12% accuracy using the standard CTRW
to achieve
method, while only maxcost/16 was needed for
11%
accuracy with the adjusted steady-state method. Exami-
nation of the optimized ns showed that this gain occurred
4–fold increase in the sampling frequency at
because a
∼
√4–fold improvement in the as-
a bottleneck caused a
sociated dominating error.

∼

∼

∼

The extent of sampling adjustment in this problem was
limited because there were only ﬁve mesoscopic states
among which eﬀort could be reallocated. Larger adjust-
ments, and larger gains in eﬃciency, may be possible in
larger problems if the increase in the number of meso-
scopic states exceeds the relative increase in the number
of bottlenecks. Such gains could be particularly impor-
tant for very costly problems (e.g., those arising when
studying protein conformational transitions).

τ k ¯K
h

Expressions analogous to Eq. (24) for the higher FPT
moments can be obtained by analytically expanding Eq.
(18) in terms of the
[31]. Although the optimal
i
sampling conditions for simultaneously computing multi-
ple moments diﬀer from Eqs. (27), we expect that beneﬁt
will still be achieved even if sampling is adjusted using
these equations. Of course, even better results will be
obtained if the optimization analysis is extended to the
multiple moment case.

6
6
V. EFFICIENT MODELLING OF THE FPTD

In some cases we will need to compute not just the mo-
ments, but also ϕ(τ ) to a low temporal resolution com-
mensurate with experimental results. We can extend the
eﬃciency improvement obtained in the moment compu-
tations to this case by modelling the FPTD using a few
of its low-order moments and an appropriate functional
expansion.

A. Modelling using the Gamma distribution

A Gamma distribution of the form

f (β, γ; τ ) =

β(βτ )γ−1e−βτ
Γ(γ)

,

(where β > 0, γ > 0; here Γ denotes the Euler Gamma
function, not the transition matrix) provides a simple
model. It decays exponentially as t
, thereby match-
ing the expected asymptotic behavior of ϕ(τ ), and it is
simple to choose β and γ so as to match the ﬁrst two
moments of the FPTD [32]:

→ ∞

τ kf
h

i

=

τ k

hh

ii

k = 1, 2

(28a)

τ

ii

ii

)2

[The denominator of the expression for γ is equal to

−
, and so is guaranteed to be positive.] Additional
hh
moments could be included by modelling ϕ(τ ) as a sum
of Gamma distributions, but problems with non-unique
parameter ﬁtting can arise.

(τ

hh

B. Modelling using a rational function
approximation to ˜ϕ

In some cases better results can be obtained by ap-

proximating ˜ϕ(u) as a rational function

˜ϕ(u)

Rm,n(u) =

≈

1 + p1u + . . . pmum
1 + q1u + . . . qnun

(n > m) .

(29)
Here we have ﬁxed the zeroth-order terms in the numer-
ator and denominator so that Rm,n(0) = ˜ϕ(0) = 1, as
m > 1 so that
required by Eq. (2). We require n
limu→∞ Rm,n(u) vanishes at least as fast as s−2, implying
that its inverse Laplace transform will vanish at the ori-
gin, corresponding to ϕ(0) = 0. Since the only singulari-
ties of Rm,n(u) are poles, the inverse Laplace transform
is easy to compute. Moreover, if the only poles are on the
negative real axis (not guaranteed), the inverse transform
will be the sum of decaying exponentials, thereby provid-
ing a natural model for ϕ(τ ). We use this property as a

−

6

validity check and do not accept (potentially overﬁtted)
approximations that have poles oﬀ the negative real axis.
The pi and qi are ﬁxed by requiring that ˜ϕ(u) =
Rm,n(u) at m+n non-zero values of uk (k = 1, . . . , m+n).
appropriately we note that the most
To choose the
important structure of ϕ(τ ) occurs at scale τ
.
ii
Therefore, the important structure of ˜ϕ(u) will occur at
−1. Thus we choose uk = k/
scale u
and re-
quire

uk}

∼ hh

τ
hh

∼ hh

ii

ii

{

τ

τ

˜ϕ(k/

) =

τ
hh

ii

hh

e−kτ /hhτ ii

ii

= Rm,n(k/

τ
hh
(k = 1, . . . , m + n) .

ii

)

(30)

The statistical error of the exponential moments grows
as k increases because the exponential will down-weight
a larger fraction of the data points. This limits the accu-
racy of the “high-frequency” components of the moment-
modelled ϕ(τ ) to be the same as that of the directly in-
tegrated ϕ(τ ) [33].

The ﬁrst moment of ϕ obtained using Eq. (29) will be
close to, but will not exactly match the MFPT. An exact
match can be obtained by replacing Eq. (29) with the
constrained rational function

˜ϕ(u)

Rhhτ ii

m,n(u)

≈
=

1 + p1u + . . . pmum

1 + (

τ

+ p1)u + q2u2 + . . . qnun

hh

ii

(n > m) .

(31)

dRhhτ ii
m,n(u)
du

(32)

=

τ
−hh

,

ii

(cid:12)
(cid:12)
u=0
(cid:12)
(cid:12)
so the ﬁrst moment of its inverse Laplace transform will
(cid:12)
exactly equal the MFPT. The constraint on the deriva-
tive of Rhhτ ii
m,n replaces the use of the k = 1 constraint
in Eq. (30), so when Eq. (31) is used we only match
Rhhτ ii
In most
cases the estimates obtained using Eqs. (29) or Eqs. (31)
will be similar. The two lowest-order approximations of
this type are those involving the MFPT and either one
or two exponential moments corresponding to approxi-
mating ϕ(α) as Rhhτ ii

m,n(uk) = ˜ϕ(uk) for k = 2, . . . , m + n [34].

0,2 (α) or Rhhτ ii

0,3 (α).

We illustrate the method using the two-dimensional
model discussed above. In Fig. 2 we compare the FPTD
computed by Faradjian and Elber [9] using the CTRW
method with the approximated FPTD’s computed us-
ing the MFPT and either zero, one or two exponential
moments. The single-exponential ﬁt obtained using the
MFPT alone [i.e., exp(
)] misses much important
τ
hh
detail, but a fairly good representation is obtained by ad-
ditionally matching just one exponential moment using
ϕ(α)
0,2 (α). The ﬁt obtained with the MFPT plus
two exponential moments (m = 0, n = 3) is practically
indistinguishable from the exact ϕ(τ ). The next higher
order approximations have imaginary poles. This pro-
vides an indication of overﬁtting and (correctly) suggests
that the approximation should not be extended further.

Rhhτ ii

t/

−

≈

ii

⇒
γ =

hh
β = γ/

2

τ

hh

ii

τ 2

ii − hh
τ
ii
hh

2

τ

ii

This satisﬁes

(28b)

(28c)

While this procedure has worked on a few tested cases,
as with all parameterized modelling approaches, success
depends on a reasonable match between the form of the
parameterized approximation and the true distribution.
This can not be guaranteed but is a reasonable assump-
tion since most FPTDs are expected to have distributions
qualitatively like that shown in Fig. 2.

VI. SUMMARY

Mesoscopic coarse graining and the CTRW equations
can be used to compute the macroscopic FPTD, ϕ(τ ), of
a complex stochastic system from short-term, and hence
aﬀordable, microscopic numerical simulations of its dy-
namics. In many cases interest will focus on the MFPT
and possibly a few additional low-order FPTD moments.
Instead of integrating the CTRW equations over time
to compute ϕ(τ ), a procedure that requires the full func-
tional form of K(τ ) to be estimated, and then integrating
again to compute the moments, we have shown that the
FPTD moments can be computed simply and directly
from the moments of ¯K. This method is simpler and
eliminates the quantization error inherent in the numeri-
cal solution of the CTRW equations in the time-domain.
It can physically be viewed as an adaptation and exten-
sion of the steady-state ﬂux-over-population method of
computing transition rates, so we call it steady-state re-
laxation.

The steady-state expressions for the FPTD moments
are simple enough for straightforward statistical error
analysis, which permits the accuracy of the computed
moments for a given amount of simulation data to be
estimated. This analysis can also be used to optimize
the allocation of computational eﬀort over the diﬀerent
mesoscopic states and to thereby reduce the total cost
of the numerical simulations required for ﬁxed accuracy.
This is important since computability of the FPTD in
large problems will often be limited by this cost. Such
optimization improved eﬃciency over two-fold in a test

7

problem with ﬁve mesoscopic states, and greater im-
provements are possible in problems with more states.
This improvement can be extended to the FPTD itself
by modelling it using either a Gamma distribution or a
rational-function approximation to its Laplace transform.

ACKNOWLEDGMENTS

We are indebted to Ron Elber for may helpful discus-

sions. T.F. was supported by NIH grant GM059796.

APPENDIX A: BAYES-LAPLACE ESTIMATOR

In some cases (e.g., when numerical simulations are

τ

hh

particularly costly), the goal may be just to estimate
ii
to rough accuracy (e.g, 25–50%) using the smallest pos-
sible number of simulations. In such cases the ns may
be small and there may be large fractional errors in the
¯K
is′s whose eﬀects are ampliﬁed by the matrix inver-
h
sion. Because the inversion is nonlinear, the maximum
likelihood estimator used in Eq. (25b) may not be opti-
mal and it is worth considering other possibilities. One
alternative is the Bayes-Laplace estimator [35]

¯K
h

is′s ≈

ns′s + 1
ns + νs

,

¯K
h

where νs is the number of states to which s can make
transitions. This is the mean Bayesian estimate of
is′s
using a non-informative prior distribution (i.e., making
the a priori assumption that a system in state s is equally
likely to make a transition to any of the connected states
s′). This estimator has a bias away from very small
¯K
is′s, suggesting that it may reduce the error of the
h
inverted matrix. This surmise was empirically found to
be true in the example of Sec. IV B, but the improvement
was only noticeable when the error was > 25% [28].

[1] N.G. Van Kampen, Stochastic Processes in Physics and

74, 3951 (1995).

Chemistry (North-Holland, Amsterdam, 1992).

[9] A.K. Faradjian and R. Elber, J. Chem. Phys. 120, 10880

[2] A.J. Golumbfskie, V.S. Pande, and A.K. Chakraborty,

(2004).

Proc. Natl. Acad. Sci. USA 96, 11707 (1999).

[10] F. Despa, D.J. Wales, and R.S. Berry, J. Chem. Phys.

[3] C.-L. Lee, G. Stell, and J. Wang, J. Chem. Phys. 118,

122, 024103 (2005).

[4] C.-L. Lee, C.-T. Lin, G. Stell, and J. Wang, Phys. Rev.

33, 7 (2001).

959 (2003).

E 67, 041905 (2003).

62, 251 1990.

60, R1 (1999).

[5] P. H¨anggi, P. Talkner, and M. Borkovec, Rev. Mod. Phys.

[6] P. Reimann, G. J. Schmid, and P. H¨anggi, Phys. Rev. E

[7] C.L. Brooks III, M. Karplus, and B.M. Pettitt, Proteins:
A Theoretical Perspective of Dynamics, Structure, and
Thermodynamics (John Wiley & Sons, New York, 1988).
[8] R.S. Berry and R. Breitengraser-Kunz, Phys. Rev. Lett.

[11] A. Sadana and T. Vo-Dinh, Biotechnol. Appl. Biochem.

[12] W.Y. Yang and M. Gruebele Nature 423, 193 (2003).
[13] V.M. Kenkre and R.S. Knox, Phys. Rev. B 9, 5279

(1974).

[14] The term “generalized master equation” has been used in
multiple contexts. It is often used to describe the time-
evolution of the quantum density matrix [1], but here
we are only interested in the classical form (i.e., corre-
sponding to a diagonal density matrix). The form of the
generalized master equation presented in Eqn. (8) of Ref.

8

the multinomial parameters with a single binomial pa-
rameter for each s 6= i, f .

[27] In principle, a better procedure might be to adaptively
adjust Eqs. (27) as more samples are gathered. However,
in the example of Sec. IV B eﬃciency did not depend sen-
sitively on the size of the pilot, so an adaptive procedure
may not give much further improvement.

[28] When the maximum likelihood estimator of Eq. (25b)
was used instead of the Bayes-Laplace estimator, the geo-
metric rms error for cost = maxcost/256 increased from
52% to 62% and the error for cost = maxcost/128 in-
creased from 37% to 41%. The change in the other values
was insigniﬁcant.

[29] To reduce computational time and eliminate quantization
errors, the CTRW values for inﬁnitesimal quantization
length were actually computed using the equivalent Eqs.
(24) and (25) with ns = nrmtot/6.

[30] hhτ ii is a positive quantity and we expect errors in its cal-
culation will be roughly lognormally distributed (this was
empirically veriﬁed for the example), so the rms geomet-
ric error is an appropriate error measure. For exact value
hhτ ii and Ntot computed values hhτ iii (i = 1, . . . , Ntot), the
geometric rms error is exp[N −1
i=1 log2(hhτ iii/hhτ ii)]−
tot
1.
′ ¯Ki (0 ≤ k′ < k), so
only one additional set of moments of ¯K(τ ) needs to be
computed for each additional FPT moment.

[31] hτ kϕi depends on hτ k ¯KDi and hτ k

Ntot

P

[32] We have found empirically that a slightly better ﬁt for the
same computational cost is obtained by determining β
and γ by matching the MFPT and the second exponential
moment hexp(−2τ /hhτ ii)f i = hh exp(−2τ /hhτ ii)ii, rather
than using Eqs. (28). Moreover, this procedure is slightly
simpler to use since it is not even necessary to expand
Eq. (18) to second order.

[33] Since it is only the magnitude of uk, not the number
of interpolation points, that limits statistical accuracy,
the interpolation points could be made denser with no
signiﬁcant increase in computational cost. However, this
is not expected to greatly improve accuracy.

[34] Matching the constrained rational function is numerically
equivalent to matching an unconstrained rational func-
tion at the points u = {0, δ, 2, 3, . . .}, where δ is a small
number. Matching at u = 0 ensures that Rhhτ ii
m,n (0) = 1
and matching at u = δ ensures Eq. (32). This can be
done using standard rational interpolation software or
algorithms.

[35] A.B. Gelman, J.S. Carlin, H.S. Stern and D.B. Rubin,
Bayesian Data Analysis (Chapman & Hall/CRC, Boca
Raton, 1997).

13 only deﬁnes P (t) for t > 0. Eq. (3) here is a minor ex-
tension that deﬁnes P (t) for all t while being equivalent
for t > 0.

[15] R. Zwanzig, J. Stat. Phys. 30, 255 (1983).
[16] R. Zwanzig, in Lectures in Theoretical Physics, edited by
W.E. Brittin, B.W. Downs, and J. Downs (Interscience,
New York, 1961).

[17] R. Kubo, M. Toda, and N. Hashitsume, Statisti-
cal Physics II; Nonequilibrium Statistical Mechanics
(Springer-Verlag, Berlin 1978).

[18] E.W. Montroll and G.H. Weiss, J. Math. Phys. 6, 167

(1965).

[19] J.W. Haus and K.W. Kehr, Phys. Rep. 150, 263 (1987).
[20] H. Scher and M. Lax, Phys. Rev. B 7, 4491 (1973).
Eqs. (8) are a simple extension of the on-lattice equa-
tions of this reference to the case of general network con-
nectivity. While Eq. (8a) is commonly written as an in-
tegral equation, we use the integro-diﬀerential form to
highlight the relationship to Eq. (3). For convenience,
we also extend the upper limits of the integrals from t
to ∞. This has no eﬀect since the boundary conditions
and homogeneity of the equations for t < 0 imply that
P (t < 0) = Q(t < 0) = 0.

[21] J. Klafter and R. Silbey, Phys. Rev. Lett. 44, 55 (1980).
[22] L. Farkas, Phys. Chem. (Leipzig) 125, 236 (1927).
[23] Using Eq. (12) instead of Eq. (14) would yield ˜ϕ(−α) =
Γ(−α)−αI]−1 · ˆǫi instead of Eq. (17). This expres-
−αˆǫf ·[
sion has a removable singularity at α = 0 that slightly
complicates the analysis.

e

[24] E. Vanden-Eijnden (unpublished result communicated by
R. Elber) has noted that Eq. (18) can also be derived by
using the Laplace transforms of Eqs. (8) rather than the
Laplace transform of Eq. (3).

[25] φs is not fully independent from the ps

s′ because the mean
waiting time for leaving s may depend on the state to
which a transition is made. We can account for this by
replacing φs in Eq. (26) with
s′ φs′s, where φs′s ≡
′
ns′s
hτ ¯Kis′s ≈ (ns′s)−1
s
i=1 τ s
P
is the mean waiting time
i
for the subset of ﬁrst transitions out of s that go to s′,
and replace Eq. (27) with

s′ ps

P

ns = cφ−1/2

s

×

2

∂hhτ ii
∂φs′s (cid:19)

σ2
τ ;s′s +

∂hhτ ii
∂ps
s′′

σ2

s;s′′s′

∂hhτ ii
∂ps
s′

.

Xs′′,s′6=s

v
u
u
t

(cid:18)

Xs′6=s

′

s

i }, σ2

However, this requires estimation of the φs′s and the
variances of the {τ s
τ ;s′s, which will require larger
amounts of simulation data than estimation of φs and
σ2
τ ;s alone. We expect that this formula will be slightly
better for optimizing the eﬃciency of high-accuracy re-
sults where enough simulations will be available to es-
timate the additional parameters, but it could be less
eﬀective than Eq. (27) for optimizing inexpensive low-
accuracy results if not enough simulations were available
to accurately estimate them. This is probably splitting
hairs since we expect that, in most cases, overall error
will be dominated by the error in estimating h ¯Ki−1 which
will not be aﬀected by this change.

[26] The sums over s′ and s′′ need only include the states to
which state s makes transitions. In the special case where
the states are connected in a linear order (i.e., K is tri-
diagonal), the expression can be simpliﬁed by replacing

9

FIG. 1: Dependence of the geometric rms error of the calcu-
lated MFPT on the total cost of the simulation for the CTRW
and sampling-adjusted steady-state methods applied to the
two-dimensional entropic barrier model studied by Faradjian
and Elber [9]. The error for the CTRW method can not be
accurately estimated for ns = 39 and ns = 19 because too
many trials have sparse patterns of transitions that fail to
connect the initial and ﬁnal states.

FIGURES

C(cid:13)T(cid:13)R(cid:13)W(cid:13)

Sa(cid:13)m(cid:13)p(cid:13)l(cid:13)i(cid:13)n(cid:13)g(cid:13)-(cid:13)a(cid:13)d(cid:13)j(cid:13)u(cid:13)st(cid:13)e(cid:13)d(cid:13)
 (cid:13) (cid:13) (cid:13)s(cid:13)t(cid:13)e(cid:13)a(cid:13)d(cid:13)y(cid:13)-(cid:13)s(cid:13)t(cid:13)a(cid:13)t(cid:13)e(cid:13)

0.(cid:13)6(cid:13)

0.(cid:13)5(cid:13)

0.(cid:13)4(cid:13)

0.(cid:13)3(cid:13)

0.(cid:13)2(cid:13)

0.(cid:13)1(cid:13)

 

r
o
(cid:13)r
(cid:13)r
(cid:13)e
(cid:13) 
(cid:13)S
(cid:13)M
(cid:13)R
(cid:13)c
(cid:13)r
i
t
(cid:13)e
(cid:13)m
(cid:13)o
(cid:13)e
G

0(cid:13)

1

(cid:13)2
(cid:13)/
(cid:13)1
 

(cid:13)4
(cid:13)/
1

(cid:13)8
(cid:13)/
1

(cid:13)6
(cid:13)1
(cid:13)/
1

(cid:13)2
(cid:13)3
(cid:13)/
1

(cid:13)4
(cid:13)6
(cid:13)/
1

(cid:13)8
(cid:13)2
(cid:13)/(cid:13)1
1

(cid:13)6
(cid:13)5
(cid:13)/(cid:13)2
1

R(cid:13)e(cid:13)l(cid:13)a(cid:13)t(cid:13)i(cid:13)ve (cid:13)t(cid:13)o(cid:13)t(cid:13)a(cid:13)l(cid:13) (cid:13)c(cid:13)o(cid:13)s(cid:13)t(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
jHtL

FIG. 2: Comparison of the approximated and exact FPTDs
for the two-dimensional entropic barrier model studied by
Faradjian and Elber [9]. The exact FPTD is displayed (solid
line) along with the approximated FPTDs obtained by ap-
proximating the Laplace transform by a rational function
matched to the MFPT alone (ﬁne dotted line) or to the MFPT
plus one (dashed line) or two (dotted line, indistinguishable
from solid line) exponential moments.

10

t

