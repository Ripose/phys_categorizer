1
0
0
2
 
b
e
F
 
1
2
 
 
]
h
p
-
m
e
h
c
.
s
c
i
s
y
h
p
[
 
 
1
v
9
6
0
2
0
1
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Trial function optimization for excited states of van der Waals
clusters

M. P. Nightingale and Vilen Melik-Alaverdian
Department of Physics, University of Rhode Island, Kingston RI 02881, USA

A method is introduced to optimize excited state trial wave functions.
The method is applied to ground and vibrationally excited states of bosonic
van der Waals clusters of upto seven particles. Employing optimized trial
wavefunctions with three-body correlations, we use correlation function Monte
Carlo to estimate the corresponding excited state energies.

I. INTRODUCTION

In this paper we address the problem of computing energies of vibrationally excited
states by means of quantum Monte Carlo methods. We propose a method and apply it to
bosonic van der Waals clusters. As do other quantum Monte Carlo methods, our approach
has the ability to deal with systems with strong anharmonicities due to quantum mechanical
ﬂuctuations. For such systems conventional variational, normal mode, and basis set methods
fail in the treatment of vibrational states. In contrast to other Monte Carlo methods, the
one discussed here does not require a priori knowledge of nodal surfaces.

Our method1 relies on the use of optimized trial functions for the excited states. In this
paper the optimization method is explained in detail. In applications, once the optimized
trial functions have been constructed, we use correlation function Monte Carlo to reduce
systematically the variational bias of the energy estimates. In principle, the imaginary time
spectral evolution (POITSE) method,2 (also see the paper by Whaley in this volume) could
be used with the optimized excited state wavefunctions we discuss here, and it would be
interesting to compare the relative merits of these two projection methods.

II. ONE STATE

We consider clusters of atoms of mass µ, interacting pairwise via a Lennard-Jones poten-
2r−6 and the
tial. In dimensionless form, the pair potential can be written as v(r) = r−12
= P 2/2m + V , where P 2/2m and V are the total kinetic and potential
Hamiltonian as
energy operators. The only parameter is the dimensionless mass m−1 = ¯h2/µσ2ǫ, which
is proportional to the square of the de Boer parameter,3 a dimensionless measure of the
importance of quantum ﬂuctuations.

H

−

We use the position representation and denote by R, the 3Nc Cartesian coordinates of
the Nc atoms in the cluster. Suppose we have a real-valued trial function ˜ψ(R). Typically,
this trial function may have 50-100 parameters and it may depend non-linearly on these
parameters. First we recall how this state can be optimized by minimization of the variance
of the local energy

(R) deﬁned by

E

˜ψ(R)

H

≡ E

(R) ˜ψ(R).

(1)

Following Umrigar et al.,4 one can minimize the variance

(2)

(3)

(4)

(5)

(6)

(7)

χ2 =

(

)2

,

H − hHi
which in the position representation can be written as the variance of the local energy. Note
that χ2 is nothing but the square of the uncertainty in the energy, so that χ2 = 0 for any
eigenstate of the Hamiltonian

h

i

.

The minimization of χ2 can be done by means of a Monte Carlo procedure with the

H

1. Select a sample of conﬁgurations R1, . . . , Rs from the probability density ψ2

g (to be

following steps:

deﬁned).

2. Evaluate:

where

3. Find

from least-squares solution of

E

for σ = 1, . . . , s:

ˆψ(R1)
...
ˆψ(Rs)

B = 





and B′ = 










ˆψ(R) =

and ˆψ ′(R) = H

˜ψ(R)
ψg(R)

ˆψ ′(R1)
...
ˆψ ′(Rs)



,





˜ψ(R)
ψg(R)

ˆψ(Rσ) =

ˆψ(Rσ),

H

E

s

=

σ=1
X

s

E

ˆψ(Rσ)

ˆψ(Rσ)

H

.

ˆψ(Rσ)2

σ=1
X

s

ˆψ(Rσ)

[
H

− E

ˆψ(Rσ)]2

.

χ2 =

σ=1
X

ˆψ(Rσ)2

s

σ=1
X

4. Vary the parameters in the trial function to minimize χ2, the normalized sum of

squared residues deﬁned by the previous step:

For the purpose of optimizing only the groundstate, the best choice for the guiding func-
tion ψg, which is used to generate the sample of conﬁgurations, is the optimized groundstate
wavefunction itself. Since this function is only known at the end of the optimization, one
uses a reasonable initial guess, if available. Otherwise, a few bootstrap iterations may be
required.

For optimization of excited states, one can use a power of the optimized groundstate trial
wavefunction. We use a power which is roughly in the range from one half to one third. This
has the eﬀect of increasing the range of conﬁgurations sampled with appreciable probability.
The goal is to produce a sample that has considerable overlap with the all excited states of
interest.

III. SEVERAL STATES

Next we consider the problem of ﬁnding the ‘best’ linear combination of a number of
given elementary basis functions β1, . . . , βn. Before we continue, we should explain our
terminology, since it reﬂects the procedure that will be used. We shall form linear combina-
tions of the elementary basis functions. These linear combinations depend on any non-linear
parameters that appear in the elementary basis functions; the linear combinations will be
optimized with respect to the non-linear parameters by means of the general non-linear
trial function optimization procedure described in Section II. Finally, these optimized ba-
sis functions which will serve as the basis functions in a correlation function Monte Carlo
calculation,5,6 and we shall return to this in more detail later.

If the ‘best’ linear combinations of elementary basis functions are deﬁned in the sense that
for such linear combinations the expectation value of the energy is stationary with respect
to variation of the linear coeﬃcients, the solution to this problem is well known. Being a
linear problem, the solution requires for its implementation traditional linear algebra.7 The
featured matrices consist of the matrix of overlap integrals of the elementary basis functions,
and the matrix of the Hamiltonian sandwiched between them. The trouble, of course, is
that the required matrix elements can only be estimated by means of Monte Carlo methods
for the cluster problem and the elementary basis functions we employ.

Stationarity of the energy is equivalent to the least-squares principle that is used in the
following algorithm. The latter can be used with a very small sample of conﬁgurations, but
in the limit of an inﬁnite sample it produces precisely the solution for which the energy is
stationary.

To ﬁnd the optimal linear coeﬃcients perform the following steps:

1. Select a sample of conﬁgurations R1, . . . , Rs from the probability density ψ2

g (as dis-

cussed previously).

2. Evaluate:

and

where

B = 

ˆβ1(R1)
...
ˆβ1(Rs)

· · ·
...

· · ·

ˆβn(R1)
...
ˆβn(Rs)



,









ˆβ ′

ˆβ ′

1(R1)
...
1(Rs)

· · ·
...

· · ·

ˆβ ′

ˆβ ′

n(R1)
...
n(Rs)



,





B′ = 




ˆβi(R) =

βi(R)
ψg(R)

and ˆβ ′

i(R) = H

βi(R)
ψg(R)

(8)

(9)

(10)

3. Find

from least-squares ﬁt to

for σ = 1, . . . , s and i = 1, . . . , n.

4. Find the eigensystem of E and write

E = (

E ij)n

i,j=1

ˆβi(Rσ) =

ˆβj(Rσ)

E ji,

H

n

Xj=1

E ij =

n

Xi=1

d (k)
i

˜Ek ˆd (k)
j

,

where the ˆd (k)
value ˜Ek.

i

and d (k)

j

are components of left and right eigenvectors of E with eigen-

This algorithm yields an approximate expression for the eigenstate for energy Ek:

ψ(k)(R)

˜ψ(k)(R) =

βi(R) d (k)

i

.

≈

Xi

In addition, one has the following approximate inequality7

The inequality holds rigorously in the absence of statistical noise, i.e., if an inﬁnite Monte
Carlo sample is used or if by other means the quantum mechanical overlap integrals and
matrix elements, corresponding to the matrices N and H deﬁned in Eq. (17), are evaluated
exactly.

In the ideal case that the basis functions are linear combinations of no more than n true
eigenfunctions of the Hamiltonian, the previous algorithm yields the true eigenvalues, even
for a ﬁnite Monte Carlo sample, unless it fails altogether for lack of suﬃcient independent
data.

To ﬁnd the least-squares solution for E from Eq. (12) we write the latter in the form

˜Ek.

Ek <
∼

B′ = BE.

Multiply through from the left by BT , the transpose of B, and invert to obtain

E = (BT B)−1(BT B′)

N−1H.

≡

It is simple to verify that indeed this yields the least-squares solution of Eqs. (12).

It is is well-known that the solution for E as written in Eq. (17) is numerically unstable.8
This is a consequence of the fact that the matrix N is ill conditioned if the βk are nearly
linearly dependent, which indeed is the case for our elementary basis functions. The solution

(11)

(12)

(13)

(14)

(15)

(16)

(17)

to this problem is to use a singular value decomposition to obtain a numerically deﬁned and
regularized inverse B−1. In terms of the latter, one ﬁnds from Eq. (17)

More explicitly, one uses a singular value decomposition to write9

E = B−1B′.

B = USVT ,

where U and V are square orthogonal matrices respectively of order s, the sample size, and
n, the number of elementary basis functions, while Sr is a rectangular s
n matrix with
σr > 0; r is chosen
zeroes everywhere except for its leading diagonal elements σ1 ≥
such that the remaining singular values are suﬃciently close to zero to be ignored. In our
applications, we ignored all singular values σk with σk < 103σ1ǫdbl, where ǫdbl is the double
precision machine accuracy. This seems a reasonable choice, but we have no compelling
argument to justify it.

σ2 ≥

×

From Eq. (19) one obtains

where Ur is the s
likewise obtained from V; and Sr is the r

×

r matrix consisting of the ﬁrst r columns of U; Vr is the n

r matrix

r upper left corner of S.

×

(20)

×

E = VrS−1

r UT

r B′,

IV. ELEMENTARY BASIS FUNCTIONS

We used elementary basis functions of the general form introduced in Ref. 10. Rotation
and translation symmetry are built into these functions by writing them as functions of
all interparticle distances. First of all, we introduce a scaling function with values that
change appreciably only in the range of interparticle distances that occur in the cluster
conﬁgurations with appreciable probability. For this purpose we ﬁrst introduce a piecewise
linear function f . This function has three parameters: x1 < x2 < x3, which deﬁne the four
linear segments of the continuous function f :

−

≤

1 for x
x1,
0 for x = x2,
x3.
1 for x

≥

f (x) = 




The parameters are determined by the relevant length scales of the system. The parameter
x1 sets the scale for how close two atoms can get with reasonable probability; x2 roughly
equals the most likely interparticle distance; and x3 is the distance at which one expects the
onset of the long distance asymptotic regime. Possibly, one could drop x2 and use a simpler
function consisting of three linear segments only.

The function f has no continuous derivatives and cannot be used directly as a scaling

function. Instead, we use the generalized Gaussian transform

ˆf(x) =

f (x′) exp

∞

−∞

Z

(x

x′)2

−
2cx

−

dx′,

(18)

(19)

(21)

(22)

with c = 0.1.

In their most general form the wavefunctions in Ref. 10 contain ﬁve-body correlations,
but in the work reported here we have only used three-body correlations and for completeness
we shall describe the construction of these functions explicitly.

Choose three of the Nc atoms. Suppose they have labels α, β, and γ and Cartesian

coordinates rα, rβ and rγ. This deﬁnes three scaled interatomic distances

Deﬁne three invariants as sums of powers of these variables

ˆrα = ˆf (
ˆrβ = ˆf (
ˆrγ = ˆf (

rβ −
|
rγ −
|
rα −
|

)
)
)

rγ|
rα|
rβ|





Ip = ˆr p

α + ˆr p

β + ˆr p
γ

(23)

(24)

with p = 1, 2, 3. Clearly, any polynomial in the invariants I1, I2 and I3 is symmetric with
respect to permutation of the labels α, β, and γ. A convenient property of these variables is
that the reverse is also true: any symmetric polynomial in the three scaled distances can be
written as a polynomial in the invariants I1, I2 and I3. This makes it simple to parameterize
these symmetric polynomials.

In terms of the invariants we deﬁne ‘minimal polynomials’ si as follow: pick a monomial
in I1, I2, and I3 and sum over all possible ways of choosing three atoms α, β, and γ. These
polynomials are minimal in the sense that one cannot omit any single term without violating
the bosonic symmetry.

In addition to bosonic symmetry, we impose short and long-distance boundary conditions.

This yields the following form for the elementary basis functions

βi(R) = si(R) exp

aj sj(R)

κk rστ +

(25)





Xj

−

σ<τ  
X

1
5 √m r5

στ !


with

m ˜Ek
Nc

.

−

(26)

κk =

1 v
u
u
t

2
Nc −
As discussed in detail in Ref. 10, the r−5
στ term in the exponent and its coeﬃcient are chosen
so that, when two atoms approach each other, the strongest divergence in the local energy,
i.e. the Lennard-Jones r−12 divergence, is canceled by the divergence in the local kinetic
energy. The energy ˜Ek is determined self-consistently by iteration; one or two iterations
typically suﬃce. The speciﬁc form of the decay constant is chosen on the basis of two
assumptions. The energy is assumed to be proportional to the number of atom pairs in the
cluster.11 This is reasonable for small clusters, but for larger ones this should probably be
modiﬁed to reﬂect the expectation that the energy is proportional to the average number
of nearest neighbor pairs. The second assumption is that if one atom is far away from all
others, the wave function can be written as the product of an Nc −
1 cluster wavefunction
and an exponentially decaying part that carries a fraction of the total energy equal to the
number of bonds connecting that atom to the others.

The aj in Eq. (25) are non-linear variational parameters. Their optimal values are re-
optimized for each excited state. In principle, one could optimize all non-linear parameters,
including those that appear in the scaling function and the factors that impose the boundary
conditions. However, it has been our experience that this produces strongly correlated
variational parameters and results in unstable ﬁts.

V. REDUCTION OF VARIATIONAL ERRORS

The linear and non-linear optimization procedures described above are used to gener-
ate basis functions for a correlation function Monte Carlo calculation,12 which increases the
statistical accuracy of the energy estimates and reduces the systematic errors due to imper-
fections of the variational functions. The number of these basis functions is much smaller
than the number of elementary basis functions that appear in the linear combinations. The
advantage of not using all elementary basis can be understood as follows.

Suppose that the optimization phase yields states

˜ψ(k)

with k = 1, . . . , n′ < n. Corre-

lation function Monte Carlo in a statistical sense yields the basis functions

|

i

As t increases, the spectral weight of undesirable excited states, i.e., states k with Ek > En′ is
decreased. That is desirable, but at the same time all basis states approach the groundstate
and therefore become more nearly linearly dependent. More explicitly, one has Monte Carlo
estimates of the following the generalization of Eq. (17)

˜ψ(i)(t)

|

i ≡

e−H

˜ψ(i)

t

|

.

i

E(t) = N(t)−1H(t),

Nij(t) =

˜ψ(i)(t)

˜ψ(j)(t)

h

|

i

Hij(t) =

˜ψ(i)(t)

˜ψ(j)(t)

h

|H|

.

i

with

and

(27)

(28)

(29)

(30)

Again, trouble is caused by an ill-conditioned matrix, which in this case is N(t), and in-
creasingly so for increasing values of the projection time t. Obviously, the better are the
and the fewer is their number, the less severe is this problem. We should
trial states
also point out in this context that the singular value decomposition cannot be used in this
case. The reason is that the analogs of the matrices B and B′ become too big to store for
Monte Carlo samples of the size required in the correlation function Monte Carlo runs.

˜ψ(i)

i

|

VI. RESULTS

In Table I we compare results obtained with our Monte Carlo method with results of
Leitner et al.,11 which were obtained by the discrete variable representation (DVR) method.
With the exception of the ﬁfth state of Ne, the Monte Carlo results agree with or improve

the DVR results. In some cases, the disagreement can be attributed to lack of convergence
of the DVR results.13 The discrepancy for the ﬁfth state of Ne may be an illustration of a
weakness of the correlation function Monte Carlo method, as it is commonly implemented,
namely the diﬃculty of estimating the statistical and systematic errors.

There can be problems both with obtaining reliable estimates of the statistical errors and
with making sure that one has convergence as a function of projection time t [cf. Eq. (28)].
This is a consequence of the fact that the data for diﬀerent values of the projection time
are strongly correlated since they are obtained from the same Monte Carlo data. Correlated
noise may introduce false trends or obscure true ones, a problem that in principle can be
solved by performing independent runs for diﬀerent projection times, but that would greatly
increase the computation time.

Unreliable statistical error estimates may come about because the correlation function
Monte Carlo calculation takes the form of a pure-diﬀusion Monte Carlo14,15 calculation.
The algorithm used for the latter features weights consisting of a number of ﬂuctuating
factors proportional to the projection time t. Consequently, as the projection time t in-
creases, the variance of the estimators increases and they acquire a signiﬁcantly non-Gaussian
distribution,16 which renders error bars computed in the standard way increasingly mislead-
ing. Conceivably, one could reduce the severity of this eﬀect by using branching random
walks,17 as is done in standard diﬀusion Monte Carlo, or by means of reptation Monte
Carlo.18

In Table II we present results for the energies of the ﬁrst ﬁve levels of Ar clusters of sizes
four through seven. Our method allows one to go beyond seven atom clusters, but, as one can
see from Table II, the statistical errors increase with system size. To obtain more accurate
results for larger clusters it would probably be helpful to include higher order correlations
in the wavefunction, since the degrees of the polynomials were chosen suﬃciently high that
increasing then further no longer improves the quality of the trial functions.

Figure 1 contains three energy levels as a function of mass for four particle clusters. The
harmonic approximation implies that for large masses the energy will be a linear function of
m− 1
2 . We expect the energy to vanish quadratically in the vicinity of the dissociation limit.
The results are therefore plotted using variables that yield linear dependence both for large
masses and for energies close to zero.19 As the of the energy levels approaches zero, both the
optimization and the projection methods begin to fail, and correspondingly data points are
missing. Again, the use of trial wavefunctions with four-body correlations is likely to yield
more accurate results for smaller masses.

In the elementary basis functions, we typically used polynomials of degree ten in the
prefactors and of degree three in the exponent. The diﬀusion Monte Carlo runs used on the
order of a million steps with a time step of a couple of tenths. The longer runs typically
took a few hours on a four processor SGI Origin 200.

TABLE I. Vibrational energy levels Ek of noble gas trimers; the estimated errors are a few units

in the least signiﬁcant decimal.

TABLE II. Vibrational energy levels Ek of Ar clusters; the estimated errors are a few units in

the least signiﬁcant decimal.

DVR
-1.718
-1.220
-1.138
-1.035
-0.898

Ar5
-7.785 1
-7.567
-7.501
-7.39
-7.36

Ar3

MC
-2.553 289 43
-2.250 185 5
-2.126 361
-1.996 43
-1.946 7

Ar6
-10.887 9
-10.561
-10.51
-10.46
-10.35

DVR
-2.553
-2.250
-2.126
-1.996
-1.947

Ar7
-14.191
-13.969
-13.80
-13.74
-13.71

k

1
2
3
4
5

k
1
2
3
4
5

Ne3

MC
-1.719 560
-1.222 83
-1.142 0
-1.038
-0.890

Ar4
-5.118 11
-4.785
-4.674
-4.530
-4.39

0

-0.5

-1

-1.5

-2

1
2

Ek|

−|

k = 1 :
k = 2 :
k = 3 :

✸
+
✷

+
✸

✸

+
✸

✷
+
✸

✷
+
✸

✷
+
✸

✷
+
✸

✷
+
✸

✷
+
✸

✷
+
✸

✷
+
✸

✷
+
✸

✛

Ar
❄

✻

0

0.05

-2.5

Ne
❄

Kr

He
❄

0.1

0.15

0.2

0.25

0.3

0.35

m− 1

2

−

√

FIG. 1.

Ek for lowest three vibrational levels (k = 1, 2, 3) of four particle clusters vs m− 1
2 .
The estimated errors for most energies are smaller, than the plot symbols. Results for level k = 3
become unreliable near He and have not been included. The vertical arrows indicate Kr, Ar, Ne,
and He; the horizontal arrow indicates the classical value -√6.

−

ACKNOWLEDGMENTS

This research was supported by the (US) National Science Foundation (NSF) through
Grant DMR-9725080. It is our pleasure to thank David Freeman and Cyrus Umrigar for
valuable discussions.

1 M. P. Nightingale and V. Melik-Alaverdian, submitted to Phys. Rev. Lett. .
2 D. Blume, M. Lewerenz, P. Niyaz, and K.B. Whaley, Phys. Rev. E 55, 3664 (1997). D. Blume
and K. B. Whaley, J. Chem. Phys. 112, 2218 (2000) and references therein.
3 J. de Boer, Physica, 14, 139 (1948).
4 C.J. Umrigar, K.G. Wilson, and J.W. Wilkins, Phys. Rev. Lett. 60, 1719 (1988); C.J. Umrigar,
K.G. Wilson, and J.W. Wilkins, in Computer Simulation Studies in Condensed Matter Physics,
Recent Developments, edited by D.P. Landau K.K. Mon and H.B. Sch¨uttler, Springer Proceedings
in Physics (Springer, Berlin, 1988).
5 D.M. Ceperley and B. Bernu, J. Chem. Phys. 89, 6316 (1988).
6 B. Bernu, D.M. Ceperley, and W.A. Lester, Jr., J. Chem. Phys. 93, 552 (1990); W.R. Brown,
W.A. Glauser, and W.A. Lester, Jr., J. Chem. Phys. 103, 9721 (1995).
7 J.K.L. MacDonald, Phys. Rev. 43, 830 (1933).
8 W.H. Press, B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling, Numerical Recipes, (Cambridge

University Press, Cambridge 1992), Section 2.6.

9 G.H. Golub and C.F. van Loan, Matrix computations (Second Edition), (Johns Hopkins Univer-

sity Press, 1989) Chapter 5.5.

10 Andrei Mushinski and M. P. Nightingale, J. Chem. Phys. 101, 8831, (1994).
11 D.M. Leitner, J.D. Doll, and R.M. Whitnell, J. Chem. Phys. 94, 6644 (1991).
12 D.M. Ceperley and B. Bernu, J. Chem. Phys. 89, 6316 (1988).
13 D.M. Leitner, private communication.
14 M. Caﬀarel and P. Claverie, J. Chem. Phys. 88, 1088 (1988); ibid. p. 1100.
15 C.J. Umrigar, M.P. Nightingale, and K.J. Runge, J. Chem. Phys. 99, 2865 (1993) and references
therein; we used a single, weighted walker, and an accept reject step with τeﬀ = τ for accepted
moves and τeﬀ = 0 for rejected ones.

16 J.H. Hetherington, Phys. Rev. A 30, 2713, 1984.
17 M. P. Nightingale in Quantum Monte Carlo Methods in Physics and Chemistry, edited by M. P.
Nightingale and C. J. Umrigar, (NATO Science Series, Kluwer Academic Publisher, Dordrecht,
1999), p. 1.

18 S. Baroni and S. Moroni, in Quantum Monte Carlo Methods in Physics and Chemistry, edited
by M. P. Nightingale and C. J. Umrigar, (NATO Science Series, Kluwer Academic Publisher,
Dordrecht, 1999), p. 313.

19 M. Meierovich, A. Mushinski, and M.P. Nightingale, J. Chem. Phys. 105, 6498 (1996).

