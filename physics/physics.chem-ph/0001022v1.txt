0
0
0
2

 

n
a
J
 

0
1

 
 
]
h
p
-
m
e
h
c
.
s
c
i
s
y
h
p
[
 
 

1
v
2
2
0
1
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Quantum Monte Carlo Methods in Statistical Mechanics

Department of Physics, University of Rhode Island, Kingston, Rhode Island 02881, USA

Vilen Melik-Alaverdian and M.P. Nightingale

(January 15, 2014)

Abstract

This paper deals with the optimization of trial states for the computation
of dominant eigenvalues of operators and very large matrices.
In addition
to preliminary results for the energy spectrum of van der Waals clusters,
we review results of the application of this method to the computation of
relaxation times of independent relaxation modes at the Ising critical point
in two dimensions.

I. INTRODUCTION

The computation of eigenvalues and eigenstates of operators and large matrices is a
ubiquitous problem.
In this paper we review recent applications of the Quantum Monte
Carlo methods that we have developed for this purpose. The reader is referred to other
papers for introductory or more technical discussions of earlier work. [1–4]

II. MATHEMATICAL PRELIMINARIES

For an operator G, the power method can be used to compute the dominant eigenstate

and eigenvalue, |ψ0i and λ0.

This well-know procedure can be summarized as follows:

1. Choose a generic initial state |u(0)i of the appropriate symmetry.

2. Iterate:

|u(t+1)i =

1
ct+1

G|u(t)i,

where ct puts |u(t)i in standard form.

For projection time t → ∞ the following is almost always true:

1. Eigenstate:

|u(t+1)i → |ψ0i

1

(1)

(2)

2. Eigenvalue:

ct → λ0

To see this, expand the initial state in normalized eigenstates

|u(0)i = Xk

w(0)

k |ψki

with spectral weights w(0)

k . Then |u(t)i has spectral weights

λ0!t
k ∼   λk
w(t)

.

(3)

(4)

(5)

This method can be implemented by means of a Monte Carlo method and, unlike varia-
tional Monte Carlo, it has the advantage of producing unbiased results for large projection
times t. The disadvantage is, however, that at the same time the statistical noise increases
exponentially, unless G is a Markov (stochastic) matrix, or can be explicitly transformed to
one. The statistical errors grow with the extent to which G fails to conserve probility, and
to alleviate this problem, approximate dominant eigenstates can be used.

In the case of Markov matrices, computation of the dominant eigenvalue is of no interest,
since it is equals unity, but sampling the corresponding eigenstate has numerous applications.

A. Subspace iteration

Given a set of basis states, one can construct trial states as linear combinations to
obtain approximate excited or, more generally, sub-dominant states and the corresponding
eigenvalues. These are computed by solving a linear variational problem.
In a Monte
Carlo context, the Metropolis method can be used to evaluate the required matrix elements.
Subsequently, a variation of the power method can again be used to remove systematically
the variational bias. [5–7] Again, the price to be paid for reduction of the variational bias
is increased statistical noise, a problem that can be mitigated by the use of optimized trial
states.

The linear variational problem to be solved for the computation of excited states is the
such

following one. Given n basis functions |uii, ﬁnd the n × n matrix of coeﬃcients D(j)
that

i

| ˜ψji =

D(j)

i

|uii

n

Xi = 1

(6)

are the “best” variational approximations for the n lowest eigenstates |ψii of some Hamilto-
nian H. In this problem we shall, at least initially, use the language of quantum mechanical
systems, where one has to distinguish the Hamiltonian from the imaginary-time evolution
operator G = exp(−τ H).
In the statistical mechanical application discussed below, we
shall encounter only the equivalent of the latter, which is the Markov matrix governing the
stochastic dynamics. In the expressions to be derived below, the substitution HGp → Gp+1

2

will produce the expressions required for the statistical mechanical application, at least if
we assume that the non-symmetric Markov matrix that appear in that context has been
symmetrized, which can always be accomplished if detailed balance is satisﬁed.

Given these basis states, one seeks the “best” solution to the linear variational problem
in Eq. (6) in the sense that for all i the Rayleigh quotient h ˜ψi|H| ˜ψii/h ˜ψi| ˜ψii is stationary
with respect to variation of the coeﬃcients of the matrix D. The solution is that the matrix
of coeﬃcients D(j)

i has to satisfy the following generalized eigenvalue equation

where

Hki D(j)

i = ˜Ej

n

Xi = 1

Nki D(j)

i

,

n

Xi = 1

Hki = huk|H|uii, and Nki = huk|uii.

(7)

(8)

We note a number of important properties of this scheme. Firstly, the basis states |uii in
general are not orthonormal. Secondly, it is clear that any nonsingular linear combination of
the basis vectors will produce precisely the same results, obtained from the correspondingly
transformed version of Eq. (7). The ﬁnal comment is that the variational eigenvalues bound
the exact eigenvalues from above, i.e., ˜Ei ≥ Ei, where we assume E1 ≤ E2 ≤ . . .. One
recovers exact eigenvalues Ei and the corresponding eigenstates, if the |uii span the same
space as the exact eigenstates, or in other words, have no admixtures of more than n states.
The required matrix elements can be computed using the standard variational Monte
Carlo method. The power method can subsequently be used to reduce the variational bias.
Formally, one simply deﬁnes new basis states

|u(p)

i i = Gp |uii

(9)

and substitutes these new basis states for the original ones. In quantum mechanical appli-
cations, where G = exp(−τ H), the corresponding matrices

and

H (p)

ki = hu(p)

k |H|u(p)
i i

N (p)

ki = hu(p)

k |ui

(p)i

(10)

(11)

can be computed by pure-diﬀusion Monte Carlo. [8] We note that, Monte Carlo yields these
matrix elements up to an irrelevant overall normalization constant.

As an explicit example illustrating the nature of the Monte Carlo time-averages that
one has to evaluate in this approach, we write down the expression for N (p)
ij as used for the
computation of eigenvalues of the Markov matrix relevant to the problem of critical slowing
down, discussed in detail in the next section. One estimates this matrix as

N (p)
ij ∝ Xt

ui(St)
ψB(St)

uj(St+p)
ψB(St+p)

,

(12)

where the St are conﬁgurations forming a time series that is designed to sample the distri-
bution of a system in thermodynamic equilibrium, i.e., the Boltzmann distribution ψ2
B. It

3

turns out that in this particular case, this distribution, the dominant eigenstate, has suﬃ-
cient overlap with the magnitude of the sub-dominant states so that one can compute all
matrix elements N (p)

simultaneously without introducing a separate guiding function [5].

ij

ij

The expression given in Eq. (12) yields the u/ψB-auto-correlation function at lag p.
The expression for H (p)
is similar, and represents a cross-correlation function involving the
conﬁgurational eigenvalues of the Markov matrix in the various basis states. Compared
to the expressions one usually encounters in applications to quantum mechanical problems,
Eq. (12) takes a particularly simple form in which products of ﬂuctuating weights are absent,
because one is dealing with a probability conserving evolution operator from the outset in
this particular problem.

III. UNIVERSAL AMPLITUDE RATIOS IN CRITICAL DYNAMICS

Before continuing our general discussion, we temporarily change the topic to introduce
stochastic dynamics of critical systems. What make such systems interesting, is that one
can distinguish universality classes in which behavior does not depend on many of the
microscopic details. For static critical phenomena, it is known that universality classes can
be identiﬁed by dimensionality, symmetry of the order parameter, and the range of the
interactions. For dynamical phenomena, there are additional features such as whether or
not the dynamics is local or subject to conservation laws.

On approach of a critical point, the correlation length ξ diverges. The dynamical ex-
ponent z governs the corresponding divergence of the correlation time τ by means of the
relation τ ∝ ξz. Since the critical exponent z is one of the universal quantities, it has
been used to identify universality classes. Unfortunately, z does not vary by much from one
universality class to another, and this poses a serious computational problem in terms of
the accuracy required to obtain signiﬁcant diﬀerences. One of the outcomes of the work
reviewed here is that there are other quantities within computational reach, namely univer-
sal amplitude ratios. [4] These ratios may serve as additional, and possibly more sensitive
identiﬁers of universality classes. We shall consider various systems belonging to a single
universality class, and we assume that the representatives of the class are parameterized by
κ.

If a thermodynamic system is perturbed out of equilibrium, diﬀerent thermodynamic
quantities relax back at a diﬀerent rates. More generally, there are inﬁnitely many indepen-
dent relaxation modes for a system in the thermodynamic limit. The Monte Carlo methods
reviewed here have been used to compute relaxation times of Ising models on square L × L
lattices at the critical point. [4]

Let us denote by τκi(L) the relaxation time of mode i of a system of linear dimension
L. As indeed scaling theory suggests, it turns out that the relaxation time has the following
factorization property

τκi(L) ≈ mκAiLz,

(13)

where mκ is a non-universal metric factor, which diﬀers for diﬀerent representatives of the
same universality class as indicated; Ai is a universal amplitude which depends on the mode
i; and z is the universal dynamical exponent introduced above.

4

Formulated as a computational problem, one has the following.

Suppose S =
(s1, ..., sL2), with si = ±1, is a spin conﬁguration and ρt(S) is the probability of ﬁnding S
at time t. The probability distribution evolves in time according to

ρt+1(S) = XS′

P (S|S′)ρt(S′).

(14)

The detailed structure of the Markov matrix P is of no immediate importance for the
current discussion. All that matters is that it satisﬁes detailed balance, has the Boltzmann
distribution ψ2
B as its stationary state. Also, P is a single-spin ﬂip matrix, i.e. P (S|S′)
vanishes if S and S′ diﬀer by more than a single spin. The desired relaxation time of mode
i is given by

τi(L) = −L−2/ ln λi(L),

(15)

where λi is an eigenvalue of Markov matrix P . We obtained the previous expression by
assuming a single-spin ﬂip Markov matrix, so that the L2 in the denominator produces a
relaxation time measured in units of sweeps, i.e. ﬂips per spin.

IV. TRIAL STATE OPTIMIZATION

To verify Eq. (13), it is important to obtain estimates that are exact within the range of
the estimated error. For this purpose we use a set of optimized variational basis functions,
to which we subsequently apply the projection procedure described in Section 2 to remove
the variational bias.

As mentioned, the Monte Carlo projection increases the statistical noise, and the solution
to this problem is to improve the variational basis functions. We shall now discuss how this
is done and we consider the problem using the language of the Schr¨odinger equation.

We ﬁrst consider the ground state and review how one can optimize a many-, say 50-

parameter trial function ψT(R). [9] The local energy E(R) is deﬁned by

The variance of the local energy is given by

HψT(R) ≡ E(R)ψT(R).

χ2 = h(H − E)2i = Z |ψT(R)|2[E(R) − E]2 dR / Z |ψT(R)|2 dR.

(16)

(17)

A property that we shall exploit later is that χ2 = 0 for any eigenstate, not just the ground
state.

The following sums up the Monte Carlo optimization procedure for a single state:

1. Sample R1, . . . , Rs from ψT

2 a typical sample size has s ≈ 3, 000.

2. Approximate the integrals in Eq. (17) by Monte Carlo sums.

3. Minimize χ2 as follows, while keeping this sample ﬁxed. For each member of the sample

R1, . . . , Rs:

5

4. Compute ψT(R1), . . . , ψT(Rs).

5. Compute HψT(R1), . . . , HψT(Rs).

6. Find E from least-squares ﬁt of

HψT(Rσ) = EψT(Rσ), σ = 1, . . . , s.

(18)

7. Minimize the sum of squared residues of Eq. 18.1

This procedure can be generalized immediately to a set of basis functions, as required
to implement Eq. (6). The only new ingredient is a guiding function ψ2
g that has suﬃcient
overlap with all basis states used in the computation. For this purpose one can conveniently
use the groundstate raised to some appropriate power less than unity.

This yields the following algorithm to optimize basis states for n dominant eigenvalues:

1. Sample R1, . . . , Rs from ψ2
g.

2. Compute the arrays

3. Compute the arrays

u(1)(R1)
u(2)(R1)

...







, . . . ,


u(1)(Rs)
u(2)(Rs)

...

.




Hu(1)(R1)
Hu(2)(R1)

...







, . . . ,


Hu(1)(Rs)
Hu(2)(Rs)

...

.




(19)

(20)

4. Find the matrix elements E ij from the appropriately weighted least-squares ﬁt to

Hu(i)(Rσ) =

n

Xj = 1

E iju(j)(Rσ), σ = 1, . . . , s.

(21)

5. Vary the parameters to optimize the ﬁt, as explained below.

In case of a perfect ﬁt, the eigenvalues of the truncated Hamiltonian matrix E =
i,j = 1 are the required eigenvalues, but in real life one has to optimize the parameters of

(E ij)n
the basis functions, which can be done as follows:

1. Divide the sample in blocks and compute one Hamiltonian matrix E per block.

1Once the parameters are changed from the values they had in step 1, one should use an appro-
priately weighted sum of squared residues. [9]

6

2. Minimize the variance of the E-spectra over the blocks.

The variance vanishes if the basis functions u(i) are linear combinations of n eigenstates of H.
This gives rise to a computational problem, viz., the variance is near-invariant under linear
transformation of the u(i). This approximate “gauge invariance” gives rise to near-singular,
non-linear optimization problem. This can be avoided by simultaneously minimizing the
variance of both the spectrum of the “local” Hamiltonian matrix E and the local energy E
of the individual basis functions.

Finally, the variational bias of the eigenvalue estimates obtained with the optimized basis

states is reduced by using Monte Carlo to make the substitution discussed previously

|u(i)i → e−Hτ |u(i)i.

(22)

For this purpose, one has to use the short-time approximation of exp(−Hτ ). [5] To apply
the preceding scheme to the problem of critical dynamics, all one has to do is to make use
of the fact the analog of the quantum mechanical evolution is the symmetrized Markov ˆP
of stochastic dynamics, which is deﬁned as

ˆP (S|S′) =

1

ψB(S)

P (S|S′)ψB(S′),

in terms of which we have the correspondence

e−Hτ → ˆP t.

(23)

(24)

V. XE TRIMER: A TEST CASE

As an example that illustrates the accuracy one can obtain by means of the optimization
schemes discussed above, we present results for a Xe trimer interacting via a Lennard-Jones
potential. To be precise, we write the Hamiltonian of this system in reduced units as

H = −

1
2m

(r−6

ij − 2)r−6
ij ,

∇2 +Xi<j

(25)

where the rij denote the dimensionless interparticle distances. We deﬁne Xe to correspond
to m−1 = 7.8508 × 10−5, which probably to four signiﬁcant ﬁgures [10] agrees with Leitner
et al.. [11]

Table I shows results for variational energies of the lowest ﬁve completely symmetric
states of a Lennard-Jones Xe trimer. The results are compared with results obtained by the
discrete variable representation truncation-diagonalization method. [11] The basis functions
used in this computation are of the same general form used in earlier work with an additional
polynomial prefactor for excited states. [12,13]

Clearly, we obtain consistently lower reduced energies, which we attribute to lack of

convergence of the results of Leitner et al. [14]

7

k
0
1
2
3
4

Ek
-2.845 241 50
-2.724 955 8
-2.675 065
-2.608 612
-2.592 223

TABLES

σ
1 ×10−8
1 ×10−7
1 ×10−6
2 ×10−6
3 ×10−6

Leitner et al.
-2.844
-2.723
-2.664
-2.604
-2.580

TABLE I. Variational reduced energies compared with estimates of Leitner et al.

VI. CRITICAL POINT DYNAMICS: RESULTS

Next we brieﬂy address the issue of the choice of trial functions for the eigenstates of

symmetrized Markov matrix ˆP . We write

u(S) = f (S) × ψB(S).

(26)

For the modes we considered, f (S) was chosen to be a rotationally and translationally
invariant polynomial in long-wavelength Fourier components of S, the lowest-order one of
which is simply the magnetization. Corresponding to the order parameter and energy-like
modes, we considered polynomials either odd or even under the transformation S → −S.

We brieﬂy discuss some of the results that illustrate the validity of Eq. (13). Figure 1.
shows plots of the eﬀective amplitudes for the three dominant odd, and two dominant even
modes of three diﬀerent Ising models on L × L lattices. Of the three Ising models we
studied, the ﬁrst one, the NN model, had nearest-neighbor couplings only. The other two
also had next-nearest-neighbor couplings. In one of them, the equivalent neighbor or EQN
model, both couplings were of equal ferromagnetic strengths. In the third or NEQ model,
the nearest-neighbor coupling was chosen ferromagnetic and of twice the magnitude of the
antiferromagnetic next-nearest-neighbor coupling.

8

10

1

0.1

ALi

FIGURES

⋆ ⋆ ⋆ ⋆ ⋆ ⋆ ⋆ ⋆ ⋆ ⋆ ⋆ ⋆ ⋆ ⋆ ⋆ ⋆
✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸
s

s

s

s

s

s

s

s

s

s

s

s

s

s

s

s

❜

❜

❜

❜

❜

❝

+ + + + + + + + + + + + + + + +
✉ ✉ ✉ ✉ ✉ ✉ ✉ ✉ ✉ ✉ ✉ ✉ ✉ ✉ ✉ ✉
❜
❜
✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷
✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸ ✸
❝
× × × × × × × × × × × × × × × ×
+ + + + + + + + + + + + + + + +
❡ ❡ ❡ ❡ ❡ ❡ ❡ ❡ ❡ ❡ ❡ ❡ ❡ ❡ ❡ ❡
△ △ △ △ △ △ △ △ △ △ △ △ △ △ △ △
✷
r
✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷ ✷
r

❝

❝

❝

❝

❝

❝

❝

❝

❝

❝

❝

❝

❝

❝

❜

❜

❜

❜

❜

❜

r

r

r

r

r

r

r

r

r

r

r

r

❜

r

❜

❜

r

0.01

4

6

8

10

14

16

18

20

12

L

FIG. 1.

Universality of relaxation-time amplitudes, shown in a plot of the eﬀective,
size-dependent amplitudes ALi on a logarithmic scale. To separate data points for the three mod-
els, the NEQ data were displaced to the left and the EQN data to the right. The data collapse
predicted by Eq. (13) was produced by ﬁtting the metric factors of the NN and NEQ models.
Amplitudes of odd and even states alternate in magnitude.

To obtain estimates of the amplitudes of the relaxation modes, we ﬁt the computed

correlation times to expressions of the form

τi(L) ≈ Lz

αkiL−2k.

nc

Xk = 0

(27)

In our computation of the non-universal metric factors, this quantity was set equal to
unity by deﬁnition for the EQN model. Table II shows the metric factors computed for each
mode separately as the ratio of the computed amplitudes. In agreement with the scaling
prediction in Eq. (13), the computed metric factors depend only on the model but not on
the mode.

TABLE II. Non-universal metric factors mκ, as deﬁned in Eq. (13), computed for the NN and
NEQ models. The modes indicated by o1, o2, and o3 are odd under spin inversion; the remaining
two, e2 and e3, are even.

o1
e2
o2
e3
o3

NEQ

2.389(1)
2.394(2)
2.393(2)
2.391(2)
2.385(4)

9

NN

1.5569 (5)
1.5569 (5)
1.5567 (6)
1.554 (2)
1.554 (2)

Finally we mention that the spectral gaps of the Markov matrix vary over a considerable

range

1 − λi(L) ≈ L−(d+z) ≈ L−4.17,

(28)

from approximately 3 × 10−3 for L = 4 to 3 × 10−6 for L = 21. For details of the
i.e.
numerical analysis based on Eq. (27) we refer the interested reader to Ref. [4]. Suﬃce it to
mention that the value obtained for the universal dynamic critical exponent z featured in
Eq. (13) is z = 2.167 ± 0.002 which is indistinguishable from 13/6.

ACKNOWLEDGMENTS

This work was supported by the (US) National Science Foundation through Grants
DMR-9725080 and CHE-9625498. It is a pleasure to acknowledge helpful e-mail exchanges
with David Leitner.

10

REFERENCES

[1] M.P. Nightingale and C.J. Umrigar, Monte Carlo Eigenvalue Methods in Quantum Me-
chanics and Statistical Mechanics, in Advances in Chemical Physics, Vol. 105, Monte
Carlo Methods in Chemistry, edited by David M. Ferguson, J. Ilja Siepmann, and Don-
ald G. Truhlar, series editors I. Prigogine and Stuart A. Rice, Chapter 4 (John Wiley
and Sons, New York 1999).

[2] M.P. Nightingale and C.J. Umrigar (eds.), Quantum Monte Carlo methods in Physics
and Chemistry, NATO Science Series, Series C: Mathematical and Physical Sciences -
Vol. 525 (Kluwer Academic Publishers, Dordrecht, 1998).

[3] M. P. Nightingale and H.W.J. Bl¨ote, Phys. Rev. Lett. 76, 4548 (1996).
[4] M. P. Nightingale and H.W.J. Bl¨ote, Phys. Rev. Lett. 80, 1007 (1998). Also see

http://xxx.lanl.gov/abs/cond-mat/9708063.

[5] D.M. Ceperley and B. Bernu, J. Chem. Phys. 89, 6316 (1988).
[6] B. Bernu, D.M. Ceperley, and W.A. Lester, Jr., J. Chem. Phys. 93, 552 (1990).
[7] W.R. Brown, W.A. Glauser, and W.A. Lester, Jr., J. Chem. Phys. 103, 9721 (1995).
[8] M. Caﬀarel and P. Claverie, J. Chem. Phys. 88, 1088 (1988); ibid. p. 1100. Also see S.

Baroni and S. Moroni in Ref. [2].

[9] C.J. Umrigar, K.G. Wilson, and J.W. Wilkins, Phys. Rev. Lett. 60, 1719 (1988);
Computer Simulation Studies in Condensed Matter Physics, edited by D.P. Landau,
K.K. Mon, and H.-B. Sch¨uttler, Springer Proceedings in Physics Vol. 33 (Springer-
Verlag, Berlin, 1988), p.185.

[10] This number was obtained by using mass and Lennard-Jones parameters of Ref. [11],
as given in Table I and the fundamental physical constants of E.R. Cohen and B. N.
Taylor, in the supplement to the August 1999 issue of Physics Today, BG5.

[11] D.M. Leitner, J.D. Doll, and R.M. Whitnell, J. Chem. Phys. 94, 6644 (1991).
[12] Andrei Mushinski and M. P. Nightingale, J. Chem. Phys. 101, 8831 (1994).
[13] M. Meierovich, A. Mushinski, and M.P. Nightingale, J. Chem. Phys. 105, 6498 (1996).
[14] Indeed recent,
improved computations by Leitner (private communication) produce

lower energies than the results quoted in Table II of Ref. [11].

11

