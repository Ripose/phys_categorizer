Eﬃciency of diﬀerent numerical methods for solving Redﬁeld

equations

Ivan Kondov, Ulrich Kleinekath¨ofer, and Michael Schreiber

Institut f¨ur Physik, Technische Universit¨at, D-09107 Chemnitz, Germany

Abstract

The numerical eﬃciency of diﬀerent schemes for solving the Liouville-
von Neumann equation within multilevel Redﬁeld theory has been studied.
Among the tested algorithms are the well-known Runge-Kutta scheme in two
diﬀerent implementations as well as methods especially developed for time
propagation: the Short Iterative Arnoldi, Chebyshev and Newtonian propa-
gators. In addition, an implementation of a symplectic integrator has been
studied. For a simple example of a two-center electron transfer system we dis-
cuss some aspects of the eﬃciency of these methods to integrate the equations
of motion. Overall for time-independent potentials the Newtonian method is
recommended. For time-dependent potentials implementations of the Runge-
Kutta algorithm are very eﬃcient.

PACS: 02.60.Cb, 31.70.Hq, 34.70.+e
Keywords: Liouville-von Neumann equation, Redﬁeld theory, electron trans-
fer, Runge-Kutta, Chebyshev

0
0
0
2

 

p
e
S
6
1

 

 
 
]
h
p
-
m
e
h
c
.
s
c
i
s
y
h
p
[
 
 

1
v
9
5
0
9
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Typeset using REVTEX

1

I. INTRODUCTION

Besides classical and semi-classical descriptions of dissipative molecular systems several
quantum theories exist which fully account for the quantum eﬀects in dissipative dynamics.
Among the latter are the reduced density matrix (RDM) formalism [1–5] and the path
integral methods [6, 7]. Here we concentrate on the Redﬁeld theory [8, 9], in which one
has to solve a master equation for the RDM. It is obtained by performing a second order
perturbation treatment in the system-bath coupling as well as restricting the calculation to
the Markovian limit. With this approach the quantum dynamics of an “open” system, e.g.,
the exchange of energy and phases with the surroundings modeled as a heat bath, can be
described. The unidirectional energy ﬂow into the environment is called dissipation. Within
this theory it is possible e.g. to simulate the dissipative short-time population dynamics
usually detected by modern ultrafast spectroscopies.

Because the Redﬁeld theory is a Markovian theory the time evolution of the RDM is
governed by equations containing no memory kernel. In the original Redﬁeld theory [8, 9]
the secular approximation was performed. In this approximation it is assumed that every
element of the RDM in the energy representation is coupled only to those elements that
oscillate at the same frequency.
In the present study we do not perform this additional
approximation.

For larger systems numerical implementations for solving the Redﬁeld equation are nu-
merically very demanding and therefore require that one ﬁnds the most appropriate way
to perform the time evolution of the RDM. Straightforward one can construct and directly
diagonalize the Liouville superoperator. For processes with a time-independent Hamilto-
nian the rates, i.e. the characteristic inverse times of an exponential decay of the occupation
probability of the excited states, can be obtained in this way. In such an approach a huge
number of ﬂoating point operations will be involved and the overall computational eﬀort
will scale as N 6 where N is the size of the basis of vibronic states. Furthermore the direct
diagonalization can be numerically unstable, but nevertheless has been successfully used (see
e.g. [10]). Another strategy suggests solving N 2 ordinary diﬀerential equations and requires
products between the Liouville superoperator and the RDM which scale as N 4 (see e.g. [11]).
This is also numerically demanding for larger systems. Assuming a bilinear system-bath cou-
pling the numerical eﬀort can be reduced considerably by rewriting the Redﬁeld equation
in such a form that only matrix-matrix multiplications are needed [12] rather than applying
a superoperator onto the RDM. Hence, a computational time scaling of N 3 and a storage
requirement of N 2 is achieved. In the present paper our numerical studies will be based on
this approach.
If one wants to reduce the scaling of the numerical eﬀort with increasing number of
basis functions even more one has to go to stochastic wave function methods [13–16]. They
prescribe certain recipes to unravel the Redﬁeld equation and to substitute the RDM by a
set of wave functions which evolve partially stochastically in time. The method will have
the typical scaling of the well developed and optimized wave function propagators, i.e. N 2.
It has been applied, for example, to electron transfer systems [17–19] and shown to give
accurate results. Direct solutions and the stochastic wave packet simulations have already
been compared numerically [20, 21]. All these ﬁrst studies were restricted to dissipation
operators with Lindblad form [22]. Breuer et al. [23] showed that the stochastic wave function

2

approach can also be applied to Redﬁeld master equations without the secular approximation
and for non-Markovian quantum dissipation.
In particular for complex systems with a
large number of levels its practical application is very advantageous. Between the direct
and the stochastic methods to solve the Redﬁeld equation the accuracy diﬀers especially
because direct RDM integrators are numerically “exact” while the stochastic wave function
simulation methods have statistical error. The scope of this work are small and medium size
problems. Therefore we compare the diﬀerent numerical algorithms for a direct integration
of the Redﬁeld equation. But when using stochastic methods for density matrix propagation
one has to solve Schr¨odinger-type equations with a non-Hermitian Hamiltonian. For that
purpose the same algorithms as investigated here can be used.
In this sense the present
study is also of importance for solving Redﬁeld equations by means of stochastic methods.
Here we use diﬀerent numerical schemes to solve the Liouville-von Neumann equation.
The performance of the well-known Runge-Kutta (RK) scheme is studied in two diﬀerent
implementations: as given in the Numerical Recipes [24] and by the Numerical Algorithms
Group [25]. Compared to these general-purpose solvers are more special algorithms which
have been applied previously to the time evolution of wave packets and density matrices. For
density matrices these are the Short-Iterative-Arnoldi (SIA) propagator [12, 26], the short-
time Chebyshev polynomial (CP) propagator [11], and the Newtonian polynomial (NP)
propagator [27, 28]. The latter propagator is also used as a reference method because of
its high accuracy. In addition, a symplectic integrator (SI), which was originally developed
for solving classical equations of motion and extended to wave packet [29, 30] and density
matrix propagation [31], is tested.

Besides the propagation algorithm one has to determine the appropriate representation
in which to calculate the elements of the RDM and the Liouville superoperator. The choice
depends strongly on the type of physical problem that one considers. Coordinate (grid) rep-
resentation has an advantage when dealing with complicated potentials, e.g. non-bonding
potentials. For the problem of dissociation dynamics in the condensed phase the grid repre-
sentation has been applied based on a Lindblad-type master equation [32]. Other examples
using grids are works of Gao [33] and Berman et al. [27]. Convenient treatment of electron
transfer dynamics is done in state representation, because one can model the system using
a set of harmonic diabatic potentials [34]. Other authors [12, 35, 36] choose the adiabatic
eigenstates of the whole system as a basis set to treat similar problems. A comparative anal-
ysis of the beneﬁts and drawbacks of the diabatic and adiabatic representation in Redﬁeld
theory will be given elsewhere [37]. From the viewpoint of numerical eﬃciency we focus on
both representations in the present article.

The paper is organized as follows. In the next section we will make a short introduction
to the model system and a discussion on the versions of the Redﬁeld equation and the
numerical scaling that they exhibit. In Section III the methods for propagation used in this
work are brieﬂy reviewed. In Section IV we compare the eﬃciency of several propagators in
solving a simple electron transfer problem with multiple levels. A summary is given in the
last section.

3

II. THE REDFIELD EQUATION AND ITS SCALING PROPERTIES

In the RDM theory the full system is divided into a relevant system part and a heat
bath. Therefore the total Hamiltonian consists of three terms – the system part HS, the
bath part HB and the system-bath interaction HSB:

H = HS + HB + HSB.

(2.1)

The separation into system and bath allows one to formulate the system dynamics,
described by the Liouville-von-Neumann equation, in terms of the degrees of freedom of
the relevant system. In this way one loses the mostly unimportant knowledge of the bath
dynamics but gains a great reduction in the size of the problem. Such a reduction together
with a second order perturbative treatment of the system-bath interaction HSB and the
Markov approximation leads to the Redﬁeld equation [1, 2, 8, 9]:

˙ρ = −

i
¯h

[HS, ρ] + Rρ = Lρ.

(2.2)

In this equation ρ denotes the reduced density operator and R the Redﬁeld tensor. If one
assumes bilinear system-bath coupling with system part K and bath part Φ

HSB = KΦ

one can take advantage of the following decomposition [2, 12]:

˙ρ = −

i
¯h

[HS, ρ] +

1
¯h2{[Λρ, K] + hK, ρΛ†i}.

(2.3)

(2.4)

Here the system part K of the system-bath interaction and Λ together hold equivalent
information as the Redﬁeld tensor R. The Λ operator can be written in the form

Λ = K

∞

Z

0

dτhΦ(τ )Φ(0)ieiωτ = KC(ω) .

(2.5)

The two-time correlation function of the bath operator C(τ ) = hΦ(τ )Φ(0)i and its
Fourier-Laplace image C(ω) can be relatively arbitrarily deﬁned and depend on a micro-
scopic model of the environment. Diﬀerent classical and quantum bath models exist. Here
we take a quantum bath [26], i.e. a large collection of harmonic oscillators in equilibrium,
that is characterized by a Bose-Einstein distribution and a spectral density J(ω):

C(ω) = 2π(cid:20)1 + (cid:16)e¯hω/kB T − 1(cid:17)−1(cid:21) [J(ω) − J(−ω)] .

(2.6)

Now we look for bases that span the degrees of freedom of the relevant system. Let us
consider atomic or molecular centers m at which the electronic states |mi of the system
are localized. Their potential energy surfaces (PESs) will be approximated by harmonic
oscillator potentials, displaced along the reaction coordinate q of the system. As such a
coordinate one can, for example, choose a normal mode of the relevant system part which
is supposed to be strongly coupled to the electronic states. The centers are coupled to each

4

other with constant coupling vmn. For example two such coupled centers are sketched in
Fig. 1. The coupled surfaces |1i and |2i are assumed to describe excited electronic states.
The electron transfer takes place after an excitation of the system from its ground state |gi.

Using this microscopic concept we deﬁne K as the system’s coordinate operator

K = q = Xm

(2ωmM/¯h)−1/2 (cid:16)a†

m + am(cid:17) |mihm|

(2.7)

where am and a†
m are the boson operators for the normal modes at the center m, M is the
reduced mass and ωm are the eigenfrequencies of the oscillators. In the same picture the
Hamiltonian of the relevant system reads

HS = Xmn{δmn (cid:20)Um + (cid:18)a†

mam +

1

2(cid:19) ¯hωm(cid:21) + (1 − δmn) vmn}|mihn| .

(2.8)

From this point on we consider two possible state representations in order to calculate the
matrix elements of ρ and the operators HS, K and Λ. The diabatic (local) basis is a direct
product of the eigenstates |Mi of the harmonic oscillators and the relevant electronic states
|mi (Fig. 1, left panel). The intercenter coupling vmn gives rise to oﬀ-diagonal elements of
the Hamiltonian matrix

hmM|HS|nNi = (cid:20)Um + (cid:18)M +

1

2(cid:19) ¯hωm(cid:21) δmnδM N + (1 − δmn) vmnhmM|nNi ,

(2.9)

where Um are the energies of the minima of the diabatic PESs. Other important properties
of the diabatic representation are the equidistance in the level structure and the diagonal
form of the system-bath interaction operator HSB. This determines the tridiagonal band
form of the operator K.

When neglecting the inﬂuence of the intercenter coupling on the dissipation a very eﬃ-
cient numerical algorithm can be derived [34,38]. Of course, for strong intercenter couplings
the populations hmM|ρ|mMi at long times deviate from their expected equilibrium values.
But even for very small couplings there are cases in which the population does not converge
to its equilibrium value [37]. Therefore this neglect of the inﬂuence of the intercenter cou-
pling on the dissipation has to be handled with care. On the other hand this approximation
makes the extension of the present electron transfer model to many modes conceptually
much easier [17, 18].

The matrix elements of the operators in the dissipative part of Eq. (2.4) read

hmM|K|nNi = (2ωmM/¯h)−1/2 δmn (cid:16)δM +1,N√M + 1 + δM −1,N√M(cid:17)

and

hmM|Λ|nNi = hmM|K|nNiC(ωmM nN ) .

In Eq. (2.11) ωmM nN denote the transition frequencies of the system

¯hωmM nN = hmM|HS|mMi − hnN|HS|nNi.

(2.10)

(2.11)

(2.12)

Since the system can emit or absorb only at the eigenfrequencies of the system oscillators
ωm the spectral density of the bath J(ω) is eﬀectively reduced to a few discrete values

5

J(ω) = Pm γmδ(ω − ωm). The advantage of this approach lies in the scaling behavior with
the number of basis functions. As shown in Fig. 2 it scales like N 2.3 where N is the number
of basis functions. This is far better than the scaling without neglecting the inﬂuence of the
intercenter coupling on the dissipation as described below.

If the system Hamiltonian HS is diagonalized it is possible to use its eigenstates as a basis
(Fig. 1, right panel), in which to calculate the elements of the operators in Eq. (2.4). Of
course there will be no longer any convenient structure in K or Λ, so that the full matrix-
matrix multiplications are inevitable. For this reason the computation of Lρ(t) scales as
N 3, where N is the number of eigenstates of HS. There appears to be a minimal number
N0 below which the diagonalization of HS fails or the completeness relation for |mMi is
violated. Nevertheless, the beneﬁt of this choice is the exact treatment of the system-bath
interaction. Denoting the unitary transformation that diagonalizes HS by U one has

ǫ = U †HSU

(2.13)

where ǫ is a diagonal matrix containing the eigenvalues. In this way it is straightforward to
obtain the matrices for ρ and K. Equation (2.6) for C(ω) still holds but a new deﬁnition of
the spectral density J(ω) is necessary because of the non-equidistant adiabatic eigenstates.
The bath absorbs over a large region of frequencies and this is characterized in the model
by J(ω). One needs the full frequency dependence of J(ω) which we take to be of Ohmic
form with exponential cut-oﬀ:

J(ω) = ηΘ(ω)ωe−ω/ωc.

(2.14)

Here Θ denotes the step function and ωc the cut-oﬀ frequency.
In this study all system
oscillators have the same frequency ω1 (see Table I) and the cut-oﬀ frequency ωc is set to be
equal to ω1. The normalization prefactor η is determined such that

∞

Z

0

dωJ(ω) = γ1 .

(2.15)

Equation (2.14) together with Eq. (2.6) yields the correlation function in adiabatic repre-
sentation.

The introduced representations allow us to consider the numerical eﬀort for a single
computation of the right hand side of Eq. (2.4), i.e. of Lρ(t). In the diabatic representation
its computation can be approached using two diﬀerent algorithms.
It is possible to per-
form matrix-matrix multiplication only on those elements of K and Λ which have nonzero
contributions to the elements of Lρ(t) (Fig. 2, solid line). This is advantageous because of
the tridiagonal form of K in diabatic representation and shows the best scaling properties,
namely N 2.3. In the same representation but performing the full matrix-matrix multiplica-
tions in Eq. (2.4) (Fig. 2, dashed line) the scaling behavior is slightly worse than the same
operation in adiabatic representation (Fig. 2, dotted line). This is due to the non-diagonal
Hamiltonian HS in the former case that makes the computing of the coherent term (see
Eq. (2.2)) more expensive. Below we will take the full matrix-matrix multiplication to eval-
uate Lρ(t) in both representations. We do this to concentrate on the various propagation
schemes, not the unequal representations. Nevertheless there are performance changes in the
diﬀerent representations because of the disparate basis functions and forms of the operators
in these basis functions.

6

III. THE DIFFERENT PROPAGATION SCHEMES

A. Runge-Kutta method

The RK algorithm is a well-known tool for solving ordinary diﬀerential equations. Thus,
this method can be successfully applied to solve a set of ordinary diﬀerential equations for
the matrix elements of Eq. (2.4). It is based on a few terms of the Taylor series expansion.
In the present work we use the FORTRAN77 implementation as given in the Numerical
Recipes [24] which is a ﬁfth-order Cash-Karp RK algorithm and will be denoted as RK-NR.
As alternative the RK subroutine from the Numerical Algorithms Group [25] which is based
on RKSUITE [39] was tested with a 4(5) pair. It will be referred to as RK-NAG. Both RK-
NAG and RK-NR involve terms of ﬁfth order and use a prespeciﬁed tolerance τ as an input
parameter for the time step control. The tolerance τ and the accuracy of the calculation are
not always simply proportional. Usually decreasing τ results in longer CPU times.

In our previous work [40] a time step control mechanism diﬀerent from those used in RK-

NAG and RK-NR was tested. Discretizing the time derivative in Eq. (2.2) and requiring

ρ(ti+1) − ρ(ti)

∆t

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

+ Lρ(ti)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

< τ

(3.1)

one only has to call the propagation subroutine once and to store the previous RDM. In
addition one has to calculate the action of the Liouville superoperator L onto the RDM but
the numerical eﬀort for this is small compared to a call of the propagation subroutine. It was
shown in Ref. [40] that this time step control is the most eﬃcient for propagation with the
coherent terms in Eq. (2.2) only but disadvantageous for problems with dissipation. This is
the reason why we do not include this algorithm in the present study.

B. Short Iterative Arnoldi propagator

The SIA propagator [12,26] is a generalized version of the Short Iterative Lanczos propa-
gator [41] to non-Hermitian operators. With the Short Iterative Lanczos algorithm the wave
function can be propagated by approximating the time evolution operator in Krylov space,
which is generated by consecutive multiplications of the Hamiltonian on the wave function.
In analogy the Krylov space within the SIA method is constructed by recursive applications
of the Liouville superoperator onto the RDM ρn = Lnρ(t). In this way it is tailored for the
RDM at every moment in time. The Liouville superoperator, denoted by l in Krylov space,
has Hessenberg form

where the orthogonal transformation matrix V is constructed iteratively using the so-called
Lanczos procedure [12]. The Krylov representation l can be easily diagonalized to L with
the help of a transformation matrix S:

Since the diagonalization is performed in the Krylov space the numerical eﬀort depends
on its dimension which can be chosen small in practice. Having thus derived a diagonal
operator eLt the calculation of ρ(t) is straightforward.

L ≈ V lV T ,

eLt ≈ V SeLtS−1V T .

7

(3.2)

(3.3)

C. Symplectic integrator

The SIs were originally developed for solving classical equations of motion [42]. The time
evolution of a classical Hamiltonian system can be viewed as a canonical transformation
and SIs are sequences of canonical transformations. Recently it was shown that the time
evolution of wave packets [29,30] and density matrices [31] can also be performed using SIs.
In order to rewrite the Redﬁeld equations in the form of coupled canonical variables that
are analogous to classical equations of motion one deﬁnes the functions [31]

the operator

Q(t) = ρ(t) ,
P (t) = ˙ρ(t) ,

W = −

1
¯h2L2 ,

and the Hamiltonian function

G(Q, P ) =

1
2

[P T P + QT W Q] .

Doing so one obtains equations of motion analogous to the classical ones

d
dt
d
dt

P (t) = −

∂G(Q, P )

∂Q

= −W Q(t) ,

Q(t) =

∂G(Q, P )

∂P

= P (t) .

Rewriting this into the SI algorithm of order m yields [31]

Pi = Pi−1 +

Qi = Qi−1 +

bi∆t
¯h3 L2Qi−1
ai∆t

Pi

¯h

(3.4)
(3.5)

(3.6)

(3.7)

(3.8)

(3.9)

(3.10)

(3.11)

for i = 1, . . . , m. Diﬀerent sets of coeﬃcients {ai} and {bi} are given in the literature. Here
we choose the McLachlan-Atela fourth-order method [43]. The coeﬃcients for this method
are listed in Ref. [44]. A comparison of the McLachlan-Atela fourth-order method with the
McLachlan-Atela third-order method [43] and Ruth’s third-order method [42] has been given
elsewhere [31].

D. Newton polynomial scheme

Another way to solve Eq. (2.2) is by a polynomial expansion of the time-evolution opera-
tor. Such methods are well established and approved for wave-function propagation [28,41].
Recently the Faber [45] and NP [27] algorithms have been applied to propagate density ma-
trices and it has been shown that they behave very similarly [45]. The main idea of the NP
method is the representation of the Liouville superoperator by a polynomial interpolation

8

eLt ≈ PNp−1(L) ≡

Np−1

Xn=0

anρn =

Np−1

Xn=0

n−1

an

Yj=0

(L − λj)

(3.12)

of order Np where the ρn are computed recursively and an are the n-th divided diﬀerences.
The interpolation points λj can be chosen to form a rectangular area in the complex plane
(see Fig. 3) which contains all eigenvalues of L. This interpolation scheme is uniform, i.e., the
accuracy in energy space is approximately the same in the whole spectral range of L. This is
in contrast to schemes such as the SIA propagator which are nonuniform approximations. A
consequence of this property is the very high accuracy which can be achieved with uniform
propagators. This is why we take a high-order NP expansion as reference solution. Since the
quality of the approximation of the time evolution operator is equivalent to a scalar function
with the same interpolation points λj, one can, before performing the actual calculation,
check the accuracy on a scalar function. For the calculation with the NP propagator we set
the truncation limit of the expansion to 10−15, i.e., the sum in Eq. (3.12) is truncated when
the residuum fulﬁlls an||ρn|| < 10−15 [28].

E. Chebyshev polynomial scheme

As a last contribution to the present study we will examine the CP propagator. Re-
cently it was studied by Guo et al. [11] for density matrices. The Liouville superoperator is
approximated by a series of CPs Tk(x). Generally the CPs diverge for non-real arguments.
For propagators of the kind e−iHt it has been shown [28] that the CPs may tolerate some
imaginary part in the eigenvalues of H. The stability region has the form of an ellipse
with a center at the origin and a very small half-axis in imaginary directions [28]. In con-
trast, the eigenvalues of the Liouville superoperator are spread over the negative real half
of the complex plane and symmetrically with respect to the real axis (see Fig. 3). The real
components for the system that we consider are one order of magnitude smaller than the
imaginary components. This is why we make the expansion along the imaginary axis and
use an expression similar to that already applied to wave function propagation [41]:

eLt ≈ eL+∆t

Np−1

Xn=0

(2 − δn0)Jn(L−∆t)Tn( ˜L) .

(3.13)

Here the expansion coeﬃcients Jn are the Bessel functions of the ﬁrst kind, and ˜L is the
appropriately scaled Liouville superoperator: ˜L = (L − L+)/L−, where L− and L+ are the
half span and the middle point of the spectrum of L. Since the spectrum is symmetric with
respect to the real axis, L+ = 0. The time evolution of ρ is given by

Np−1

ρ(t + ∆t) ≈

Xn=0

(2 − δn0)Jn(L−∆t)˜ρn .

The Chebyshev vectors ˜ρn are generated by means of a recurrence procedure:

˜ρn = 2 ˜L˜ρn−1 + ˜ρn−2, ˜ρ0 = ρ(t) and ˜ρ1 = ˜L˜ρ0 .

(3.14)

(3.15)

9

For the CP and NP methods one has to adjust the values of the spectral parameters L−
and L+. One can obtain some knowledge about the spectrum of L by an approximate diag-
onalization, e.g. by Krylov subspace methods. For instance, Fig. 3 shows an approximate
spectrum of L appropriately scaled so that all eigenvalues lie within the rectangle formed
by the Newtonian interpolation points.

IV. PERFORMANCE OF PROPAGATION METHODS

The aim of this section is to compare the diﬀerent numerical methods described above
for propagating the RDM in time. The calculations were performed for both RK methods
with diﬀerent tolerance parameters τ and for the SI as well as the NP, CP, SIA propagators
with diﬀerent timesteps. The number of expansion terms Np in NP and CP propagators is
170 and 64, respectively. The dimension of the Krylov space for the SIA method was set
to 12 because smaller as well as larger values are less eﬃcient for the example studied here.
All computations were made on Pentium III 550 MHz personal computers with intensive
use of BLAS and LAPACK libraries. The code was compiled using the PGF90 Fortran
compiler [46]. For estimation of the computational error of all methods the NP algorithm
with 210 terms was chosen as a benchmark.

In this work we consider only two centers m = 1, 2 which is the minimal model to describe
the main physics of an electron transfer reaction. A basis size of 16 levels per center satisﬁes
the completeness relation and presents no diﬃculties during the diagonalization of HS. The
electronic coupling was v12 = 0.1 eV. We choose γ1 = γ2 = 1.57863 × 10−2 eV˚A−2 and
M = 20mp where mp is the proton mass. The temperature T = 298 K is used. In Table I
the parameters for the system oscillators are given.
The process that is simulated involves the following scenario. A Gaussian wave packet
is prepared as initial state by a vertical transition from the lowest vibrational level of the
ground electronic state |gi to the ﬁrst (upper) center |1i:

ρ1M 1N (t = 0) = h1M|g0ihg0|1Ni .

(4.1)

g − q0

The energy distribution of the occupied eigenstates by the wave packet depends on the
displacement q0
1 between the PESs of |gi and |1i. During the pulse the two excited
electronic states |1i and |2i are assumed to be decoupled.
In this way one can simulate
the absorption of electromagnetic radiation from a pulse with vanishing width. Right after
the pulse is over, the wave packet starts moving on the excited PESs and spreading. The
relevant system part begins losing energy to the bath and dephasing. The population on
the upper center starts decaying. When the damping is not too strong, as for the model
parameter studied here, a damped oscillation of the population between the two excited
PESs can be seen. We assume no coupling to the ground state after the pulse. After a
certain time the system reaches its equilibrium state.

In all cases the RDM was propagated for a total time period of 3 × 105 a.u. which is
suﬃcient for complete relaxation to equilibrium. It was compared to the RDM ρref evaluated
by the NP algorithm at the same points in time. The relative error ε(t) of each method at
a certain moment in time t has been estimated using a formula similar to that proposed for
wave functions by Leforestier et al. [41]:

10

.

(4.2)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

1 −

Tr (ρ(t)ρref(t))

Tr (ρ2

ref (t))

ε(t) = (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

As the error ε we deﬁne the maximum value of ε(t) over the total propagation time. For more
details we refer to our previous paper [40]. Other error measures (see for example [11, 47])
can be used as well but they will have the same qualitative behavior.

As an index for the numerical eﬀort two possibilities were explored. The ﬁrst one is a
direct measurement of the CPU time of the total propagation (Fig. 4). It may look quite
diﬀerent on other computer architectures or even on the same architecture but under changed
operation conditions. An evidence of the performance (Fig. 4) will be expressed by means
of CPU time versus the error ε.

Another approach to describe the numerical eﬀort has been proposed [11] and is called
eﬃciency factor.
It is deﬁned as the ratio between the timestep ∆t and the number of
operations Lρ(t) within this timestep. Because of the deﬁnition it is a machine independent
quantity. The larger the eﬃciency factor, the better the performance of the algorithm.
Because the RK algorithms propagate with variable timestep we cannot directly use the
deﬁnition of the eﬃciency factor. Instead we deﬁne a quantity α as the total number Nc of
Lρ(t)-evaluations divided by the total time for the propagation:

α = Nc/(Ns∆t) .

(4.3)

Here Ns denotes the total number of timesteps. The inverse of α will have the meaning of
an eﬃciency factor for an averaged timestep ∆t. We should point out that Nc does not take
into account the eﬀort for summation of the diﬀerent contributions.
In particular in the
case of the NP method the summation of the diﬀerent terms in the polynomial expansion
Eq. (3.12) can be non-negligible. This can be seen in the diﬀerent relative performance of
the propagators shown in Figs. 4 and 5. We consider both the CPU time and the quantity
α as measures of the numerical eﬀort.

Contributions from the algorithm to calculate Lρ(t) also inﬂuence the CPU time. As
discussed above, in all computations represented in Figs. 4 and 5 the full matrix-matrix
multiplications in Eq. (2.4) were performed. The performance of the CP, NP, SI and SIA
methods is only inﬂuenced very little by the choice between diabatic and adiabatic repre-
sentation. Both RK implementations are less eﬃcient in the adiabatic than in the diabatic
representation, though the RK-NAG scheme has still the best performance besides the NP
algorithm. The RK-NR scheme has an advantage for computation in diabatic rather than
in adiabatic representation especially for medium precision requirements. In that range the
performance curves of the RK methods exhibit a shoulder for the adiabatic case which seems
to result from a numerical artifact.

Because the error of the SIA algorithm is not uniformly distributed in energy space [48]
we could expect some diﬀerence in its performance in diabatic and adiabatic representation.
But because the coupling v12 chosen here is not very large, the eigenstates of the coupled
system are just slightly disordered (see Fig. 1, right plot) and hence the performance of the
SIA algorithm is almost not changed.

The uniformity, stability and high accuracy of the CP propagator for wave functions is
well known [41, 47, 48]. The CP approach to density matrix propagation was introduced
by Guo and Chen [11]. Using a damped harmonic oscillator as model system and starting

11

from a pure state they established that the relative error can reach the machine precision
limits (10−15) for suﬃciently small stepsize. However, for the system of coupled harmonic
potentials studied here and using an initial RDM with non-zero oﬀ-diagonal elements the
error saturates at ε ≈ 10−8 (see Fig. 4).
It was not possible to decrease this saturation
limit of ε neither by increasing the order of the CP nor by decreasing the timestep. This
saturation limit seems to depend strongly on the imaginary part of the eigenvalues of L. For
large timesteps the CP method loses its stability and one needs to estimate the eﬃciency
range of Np, ∆t and L−. Turning oﬀ the dissipation we could reach much higher accuracy
with the CP propagator as expected.

The SI is easy to implement. The expansion coeﬃcients are ﬁxed and can be taken
from literature. At the same time the ﬁxed coeﬃcients seem to limit the accuracy. For not
too high accuracy the performance of the SI is as good as that of the other propagators in
adiabatic representation. In diabatic representation its performance is a little worse. But
we were not able to achieve very high accuracy with this method. This might be due to the
special version, the fourth order McLachlan-Atela method, which we chose.

As already highlighted [45] the NP scheme is very stable for arbitrary spectral properties
of L. The only restriction is that the spectrum must be conﬁned within the area formed
by the interpolation points. In our investigation the NP propagator performs with a good
accuracy for timesteps of 1500 a.u. (Np = 170) which is 10 times larger than the step size
of the CP scheme. Higher order expansions might be even more eﬃcient but the numerical
implementation gets tricky and easily unstable. For timesteps of 100 a.u. and Np = 50
the NP algorithm is already numerically exact but computational very expensive (see the
arrows in Fig. 4 and Fig. 5). For problems with time-dependent Hamiltonians (e.g. non-
stationary external ﬁelds with relatively small amplitude) the RK and SIA methods will be
more eﬃcient with small timestep.

At the end we should point out that there exists no ultimate method to determine the
performance of a certain numerical approach which could be valid for diﬀerent platforms.
Tuning and optimization features are generally not portable and this may cause even diﬀerent
scaling behavior and hence a diﬀerent method of preference. That is the reason why the
generality of the results is limited to similar computation platforms and even to systems
with similar properties of the corresponding Liouville superoperator. But on the other hand
this study can give hints on the performance of the diﬀerent algorithms in general.

V. SUMMARY

In the present work an estimation of the numerical eﬃciency of several methods for
density matrix propagation has been given. The example of electron transfer in a two-center
system has been used for this purpose. A speciﬁc measure of the numerical eﬀort has been
introduced in order to compare methods with ﬁxed timestep and such ones with timestep
control (RK). Besides the method of reference (NP) the RK-NAG approach shows best
performance for both cases of adiabatic and diabatic representation. The advantage of the
SIA propagator is that the accuracy improves with decreasing the timestep in all cases we
investigated. That is not the case with the CP propagator which exhibits a saturation of
accuracy and is therefore not convenient for very small timesteps. The easy-to-implement SI

12

gives reasonable performance for not too high accuracy. The present SI seems to be limited
in accuracy due to the ﬁxed coeﬃcients.

The present studies were restricted to state bases. Of course similar calculations can be
done on a grid which is especially useful for complicated or unbound potentials. In these
cases another propagator, the split operator [49], should be taken into account. This operator
has the advantage that its performance does not (directly) depend on the spectral range of
the Hamiltonian or Liouville operator. So it may perform very well for problems with a
large spectral range although it cannot be applied to operators which have mixed terms
in coordinate and momentum operators. The use of the mapped Fourier method [50] may
reduce the number of grid points signiﬁcantly and ﬁrst wave packet propagations with this
method have been done [51, 52]. Recently the multi-conﬁguration time-dependent Hartree
method has been established to treat density matrix operators [53]. This method might be
favorable for multi-dimensional systems.

The presented methods can be used for various applications in the ﬁeld of dissipative
molecular dynamics in condensed phases, where the RDM approach provides a good way
of describing processes in systems with one or more degrees of freedom. This includes the
electron transfer processes mentioned in the introduction as well as exciton transfer processes
[54]. It can also be used to simulate pump-probe experiments [19], surface scattering of atoms
[52], etc. Also coherent control schemes in dissipative environments can be studied [55]. So
the numerical studies given here can be applied to a broad range of problems in physics,
chemistry, and biology.

ACKNOWLEDGMENTS

We thank C. Kalyanaraman and D. G. Evans for help with the implementation of the

symplectic integrator. Financial support of the DFG is gratefully acknowledged.

13

REFERENCES

[1] K. Blum, Density Matrix Theory and Applications, 2nd ed. (Plenum Press, New York,

1996).

[2] V. May and O. K¨uhn, Charge and Energy Transfer in Molecular Systems (Wiley-VCH,

Berlin, 2000).

[3] W. B. Davis, M. R. Wasielewski, R. Kosloﬀ, and M. A. Ratner, J. Phys. Chem. A 102,

9360 (1998).

[4] R. Kosloﬀ, M. A. Ratner, and W. W. Davis, J. Chem. Phys. 106, 7036 (1997).
[5] D. Kohen, C. C. Marston, and D. J. Tannor, J. Chem. Phys. 107, 5236 (1997).
[6] U. Weiss, Quantum Dissipative Systems, 2nd ed. (World Scientiﬁc, Singapore, 1999).
[7] N. Makri, J. Phys. Chem. A 102, 4414 (1998).
[8] A. G. Redﬁeld, IBM J. Res. Dev. 1, 19 (1957).
[9] A. G. Redﬁeld, Adv. Magn. Reson. 1, 1 (1965).
[10] J. M. Jean, R. A. Friesner, and G. R. Fleming, J. Chem. Phys. 96, 5827 (1992).
[11] H. Guo and R. Chen, J. Chem. Phys. 110, 6626 (1999).
[12] W. T. Pollard and R. A. Friesner, J. Chem. Phys. 100, 5054 (1994).
[13] J. Dalibard, Y. Castin, and K. Mølmer, Phys. Rev. Lett. 68, 580 (1992).
[14] B. Garraway and P. Knight, Phys. Rev. A 49, 1266 (1994).
[15] H.-P. Breuer and F. Petruccione, Phys. Rev. E 52, 428 (1995).
[16] H.-P. Breuer and F. Petruccione, Phys. Rev. Lett. 74, 3788 (1995).
[17] B. Wolfseder and W. Domcke, Chem. Phys. Lett. 235, 370 (1995).
[18] B. Wolfseder and W. Domcke, Chem. Phys. Lett. 259, 113 (1996).
[19] B. Wolfseder, L. Seidner, W. Domcke, G. Stock, M. Seel, S. Engleitner, and W. Zinth,

Chem. Phys. 233, 323 (1998).

[20] P. Saalfrank, Chem. Phys. 211, 265 (1996).
[21] H.-P. Breuer, W. Huber, and F. Petruccione, Comp. Phys. Comm. 104, 46 (1997).
[22] G. Lindblad, Commun. Math. Phys. 48, 118 (1976).
[23] H.-P. Breuer, B. Kappler, and F. Petruccione, Phys. Rev. A 59, 1633 (1999).
[24] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery, Numerical Recipes
in Fortran, 2nd ed. (Cambridge University Press, Cambridge, 1992), here we used sub-
routines rkqs and rkck.

[25] The Numerical Algorithms Group Ltd, Fortran Library, Mark 18 (Oxford, UK); here

we used subroutines d02pvf and d02pdf.

[26] W. T. Pollard, A. K. Felts, and R. A. Friesner, Adv. Chem. Phys. 93, 77 (1996).
[27] M. Berman, R. Kosloﬀ, and H. Tal-Ezer, J. Phys. A 25, 1283 (1992).
[28] G. Ashkenazi, R. Kosloﬀ, S. Ruhman, and H. Tal-Ezer, J. Chem. Phys. 103, 10005

(1995).

[29] S. K. Gray and J. M. Versosky, J. Chem. Phys. 100, 5011 (1994).
[30] S. K. Gray and D. E. Manolopoulos, J. Chem. Phys. 104, 7099 (1996).
[31] C. Kalyanaraman and D. G. Evans, Chem. Phys. Lett. 324, 459 (2000).
[32] I. Burghardt, J. Phys. Chem. A 102, 4192 (1998).
[33] S. Gao, Phys. Rev. B 57, 4509 (1998).
[34] O. K¨uhn, V. May, and M. Schreiber, J. Chem. Phys. 101, 10404 (1994).
[35] J. M. Jean and G. R. Fleming, J. Chem. Phys. 103, 2092 (1995).
[36] J. M. Jean, J. Phys. Chem. A 102, 7549 (1998).

14

[37] I. Kondov, U. Kleinekath¨ofer, and M. Schreiber, (in preparation).
[38] V. May and M. Schreiber, Phys. Rev. A 45, 2868 (1992).
[39] R. W. Brankin, I. Gladwell, and L. F. Shampine, RKSUITE: A suite of Runge-
Kutta codes for the initial value problems for ODEs, math. SoftReport 92-S1 (Southern
Methodist University, Dallas, 1992).

[40] M. Schreiber, I. Kondov, and U. Kleinekath¨ofer, J. Mol. Liq. 86, 77 (2000).
[41] C. Leforestier, R. H. Bisseling, C. Cerjan, M. D. Feit, R. Friesner, A. Guldberg, A.
Hammerich, G. Jolicard, W. Karrlein, H.-D. Meyer, N. Lipkin, O. Roncero, and R.
Kosloﬀ, J. Comp. Phys. 94, 59 (1991).

[42] R. D. Ruth, IEEE Trans. Nucl. Science 30, 2669 (1983).
[43] R. I. McLachlan and P. Atela, Nonlinearity 5, 541 (1992).
[44] S. K. Gray, D. W. Noid, and B. G. Sumpter, J. Chem. Phys. 101, 4062 (1994).
[45] W. Huisinga, L. Pesce, R. Kosloﬀ, and P. Saalfrank, J. Chem. Phys. 110, 5538 (1999).
[46] The Portland Group, Inc. (PGI), PGF90, Version 3.0 (Portland, USA).
[47] P.
C.

Sch¨utte,
Chebyshev Approximation for Wave Packet Dynamics: better than expected, preprint
No. SC 96-47 (Konrad-Zuse-Zentrum f¨ur Informationstechnik Berlin, 1996); available
via http://www.zib.de/bib/pub/pw/index.en.html.

Nettesheim,

W.

Huisinga,

and

[48] R. Kosloﬀ, Annu. Rev. Phys. Chem. 45, 145 (1994).
[49] B. Garraway and K.-A. Suominen, Rep. Prog. Phys. 58, 365 (1995).
[50] E. Fattal, R. Baer, and R. Kosloﬀ, Phys. Rev. E 53, 1217 (1996).
[51] U. Kleinekath¨ofer and D. J. Tannor, Phys. Rev. E 60, 4926 (1999).
[52] M. Nest, U. Kleinekath¨ofer, M. Schreiber, and P. Saalfrank, Chem. Phys. Lett. 313,

665 (1999).

[53] A. Raab and H.-D. Meyer, J. Chem. Phys. 112, 10718 (2000).
[54] T. Renger and V. May, Phys. Rev. Lett. 78, 3406 (1997).
[55] C. J. Bardeen, J. Che, K. R. Wilson, V. V. Yakovlev, V. A. Apkarian, C. C. Martens,

R. Zado, B. Kohler, and M. Messina, J. Chem. Phys. 106, 8486 (1997).

15

TABLES

TABLE I. Parameters of the system oscillators used for the computations.

Um, eV
−0.60
0.25
0.05

m, ˚A
q0
0.000
0.125
0.363

ωm, eV
0.1
0.1
0.1

Center |mi
|0i ≡ |gi
|1i
|2i

16

FIGURES

|2〉

q

|g〉

|e〉

q

|1〉

|g〉

FIG. 1. Potential energy surfaces (PESs) for a model electron transfer system. Diabatic PESs

are plotted on the left side, and the PES of the adiabatic excited state |ei on the right side.

6

4

2

e
m

i
t
 

U
P
C

0

20

30

40

50

Number of basis states

FIG. 2. Scaling behavior of the product Lρ(t). Solid line – tridiagonal form of K in diabatic
representation, dotted line – adiabatic representation, dashed line – diabatic representation with
full matrix-matrix multiplications. The CPU time is scaled so that it is equal to 1 for N = 50 in
diabatic representation.

17

2

1

0

−1

y
r
a
n
g
a
m

i

I

−2
−0.25

−0.15

−0.05

0.05

Real

FIG. 3. Scaled spectrum L/L− of the Liouville superoperator for the model of electron transfer.
Approximate eigenvalues obtained in Krylov subspace are plotted as dots. Open squares denote
the interpolation points λj for the NP scheme.

RK−NR
RK−NAG
SIA
CP
NP
SI

7500

]
s
[
 
,

U
P
C

5000

2500

0
10−13

10−9

ε

10−5

10−1

10−14

10−10

10−6

10−2

ε

FIG. 4. Numerical performance of diﬀerent numerical propagators. Results obtained in the
diabatic (adiabatic) representation are shown on the left (right) plot. The arrows represent the
numerical performance for the NP propagator with 50 terms and timestep 100 a.u.

18

RK−NR
RK−NAG
SIA
CP
NP
SI

1.5

1

0.5

α

0
10−13

10−9

ε

10−5

10−1

10−14

10−10

10−6

10−2

ε

FIG. 5. Numerical performance of diﬀerent numerical propagators. The numerical eﬀort α is
deﬁned in Section IV. Results obtained in the diabatic (adiabatic) representation are shown on the
left (right) panel. The arrows represent the numerical performance for the NP propagator with 50
terms and timestep 100 a.u.

19

