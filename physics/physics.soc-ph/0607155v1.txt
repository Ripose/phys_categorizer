6
0
0
2
 
l
u
J
 
7
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
5
5
1
7
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Cooperation Networks: Endogeneity &
Complexity∗

Simon Angus†

July 2006

Manuscript Only (Under Review)

Abstract

Insights from the Complex Systems literature are employed to de-
velop a computational model of truly endogenous strategic network
formation. Artiﬁcial Adaptive Agents, implemented as Finite State
Automata (FSA), play a modiﬁed two-player IPD game with an op-
tion to further develop the interaction space as part of their strategy.
Several insights result from this minor modiﬁcation: ﬁrst, I ﬁnd that
network formation is a necessary condition for cooperation to be sus-
tainable but that both the frequency of interaction and the degree to
which edge formation impacts agent mixing are both necessary condi-
tions for cooperative networks. Second, within the FSA-modiﬁed IPD
frame-work, a rich ecology of agents and network topologies is observed
and described. Third, the system dynamics are investigated and reveal
that initially simple dynamics with small interaction length between
agents gives way to complex, a-periodic dynamics with self-organized
critical properties when interaction lengths are increased by a single
step.

Keywords: cooperation; networks; prisoners’ dilemma; Artiﬁcial
Adaptive Agents; Finite State Automata; complexity science; self-organized
criticality

JEL codes: C71, C73, D83, D85

∗This work was initiated at the Santa Fe Institute Graduate Workshop on Compu-
tational Social Sciences and Complexity, Santa Fe, New Mexico. My sincere thanks go
to John Miller and Scott Page and the other participants for their input, advice and tu-
ition over this stimulating time; in particular, to John, for his warm guidance on this
project. All errors in this work, whether factual, computational, or other, are solely the
responsibility of the author.

†Post:

School of Economics, John Goodsell Building,

the University of New
E-mail (preferred): s. angus@ unsw. edu. au ;

South Wales, 2052 NSW, Australia;
Phone +61 2 9385 3334; Fax +61 2 9313 6337.

1

⇐ Fig 1
about here

1 INTRODUCTION

1

Introduction

The strategic literature has seen a long-standing interest in the nature of
cooperation, with many contributions considering the simple but insightful
two-player Prisoner’s Dilemma (PD) game,

2

(1)

II

C
(a, a)
(c, b)

D
(b, c)
(d, d)

I

C
D

where c > a > d > b and a > (b + c)/2.1 Traditionally,2 such games
were analysed under an uniform interaction speciﬁcation such that agents
met equiprobably to play a single (or repeated) two-player game such as
in (1).3
In graph-theoretic terms, such matching can be thought of as a
choice of one edge out of n(n − 1)/2 edges in a complete graph of size n
More recently however, authors have relaxed this condition,
(Fig. 1).
and have analysed strategic games of cooperation and coordination under
both non-uniform interaction and non-uniform learning environments. Here,
some form of topological imposition, other than the complete graph, such
as uni-dimensional play on a line, circle, or higher-dimensional interaction
on a regular graph (e.g. a torus) is usually applied, with more recent con-
tributions allowing for richer (statistical) graph environments such as so-
called ‘small-world’ graphs.4 The topological signiﬁcance of the interacting
space has been stressed by these authors as it appears to inﬂuence the de-
gree to which cooperation can be sustained. For instance, Anderlini and
Ianni (1996) and Anderlini and Ianni (1997) ﬁnd that diﬀerent actions of
a pure coordination game survive in the long-run at diﬀerent locations on
the interaction space; whilst Kirchamp (2000) computationally studies in-
teracting agents on a torus playing the PD and coordination games, with
cooperation and non-risk-dominant coordination outcomes observed respec-
tively. Consequently, and reﬂecting a burgeoning interest in networks of
all kinds, much attention has been paid to the study of realistic social net-
works (Barabasi et al., 2002; Baum et al., 2003), with statistical network
characterisation (Watts and Strogatz, 1998; White et al., 2004) and clique
analysis similarly receiving interest (Girvan and Newman, 2001; Tyler et al.,
2003).

However, apart from a few exceptions5, authors have not allowed the
interaction environment itself to vary, either (for example) due to some

1As in Axelrod and Hamilton (1981).
2See for example, within an evolutionary game theoretic framework, Kandori (1992).
3In the following discussion, we shall refer to this case as ‘uniform interaction’.
4For example, Elgazzar (2002); Kirchamp (2000); Masuda and Aihara (2003); Stocker

et al. (2002).

5See for example Bala and Goyal (2000); Dutta et al. (1998); Ely (2002); Jackson and

Watts (2002); Mitchell (1999); Slikker and van den Nouweland (2000).

1 INTRODUCTION

3

exogenous schedule or as a result of processes endogenous to the model.
Clearly, such modelling features comprise an highly desirable step towards
treating realistic economic and social networks.6 In this vein, two directions
of causality are apparent, ﬁrst with respect to how a changing interaction
environment might aﬀect strategic outcomes for agents (the ‘topological’
eﬀect); and second, how agents through their own strategic actions might
impact on the very interaction space itself (the ‘agency’ eﬀect).

Such a system of interacting agents, with heterogeneity in agent be-
haviour and interaction proﬁles ﬁts well into the so-called ‘science of com-
plexity’.7 This approach seeks to identify and study systems whose com-
ponents interact in some non-uniform, (and usually) non-linear manner. In
particular, due to the inherent unpredictability of such non-equilibrium sys-
tems, agent-based computational modeling techniques provide an extremely
useful method of enquiry especially where non-rational learning based be-
havior is also suspected (Arthur, 1994; Holland and Miller, 1991).8

The current paper reﬂects such an approach. Speciﬁcally, both con-
straints concerning agent rationality and rigid agent interactions are relaxed
within a fundamentally agent-based modelling framework. Moreover, in con-
trast to one related approach in the literature (see below), agents are given
strategic abilities to change the interaction space themselves (i.e. to change
interaction probabilities) during pair-wise game-play. It is in this sense that
a ‘network’ arises in the model, and hence, such a network is said to be a
truly endogenous feature of the modelling framework; a feature which to my
knowledge has not been previously handled with boundedly rational agents.
The key insights of the present work can be summarised as follows: ﬁrst,
an analytic analysis without network formation reveals that the modiﬁcation
to the standard iterated PD (IPD) framework introduced below does not
change the canonical behaviour of the system; second, that when network
formation is aﬀorded, stable cooperation networks are observed, but only
if both a type-selection and enhanced ‘activity’ beneﬁt of the network is
present; third, that the extended system under certain interaction lengths
is inherently self-defeating, with both cooperation and defection networks
transiently observed in a long-run speciﬁcation; and fourth, that the network
formation process displays self-organized criticality and thus appears to drive
the complex dynamics observed in the long-run.

The rest of the paper is organised as follows: ﬁrst, a discussion of related
literature is presented; second, the model is introduced, paying particular
attention to the modelling of agents and incorporation of network form-

6Consider, for example, the guanxi business network in China documented in (Standi-

ﬁrd and Marshall, 2000) and (Fan, 2002).

7Non-technical introductions can be found in (for example) Lewin (1993) or Coveney
and Highﬁeld (1996), or a survey of economic applications is found in Tesfatsion (2003).
8See also applications of artiﬁcial adaptive agents to organizational problems in Choi

(2002); Marsili et al. (2004); Stocker et al. (2002).

2 RELATED LITERATURE

4

ing behaviour; third, analysis is performed analytically on the basic (non-
network forming) model before extension to incorporate network formation
is performed on both a short- and long-run time horizon; and ﬁnally, some
concluding observations and a discussion of possible extensions is made.

2 Related Literature

The current speciﬁcation, where a non-uniform interaction structure is
allowed, is related in intention to the preferential partner selection (choice)
and optional rejection of an oﬀer to interact (refusal) literature (or IPD/CR
when the game is the IPD). Here, the emphasis is on how the added mech-
anism of choice and refusal aﬀects the emergence of cooperation in IPD
games. Such a mechanism is seen as more realistic, from both a biolog-
ical, and social perspective9. For example, Ashlock and co-workers 1996
construct a computational model (see below) to consider the eﬀects on co-
operative behaviour with varying levels of preferential selection, ﬁnding that
most ecologies converge to full cooperative behaviour but that ‘wallﬂower’
ecologies are possible if intolerance to defection is high, or costs to social
exclusion is low.10 Such ﬁndings are supported to some extent by the exper-
imental work of Hauk and Nagel (2001) who ﬁnd that cooperative behaviour
increases over time under unilateral choice of partners (opponent must ac-
cept to play).

Similarly, authors have considered cooperation (or corruption) arising in
informal networks. In these studies, a ‘network’ is used to describe a (proper)
subset of agents in the population who are then distinguished from the ma-
jority in some way. Taylor’s ‘old-boy network’ model (Taylor, 2000) studies
networked agents to be those of a certain type – the qualiﬁed/competent
type. Membership of this network is conferred upon the individual after
‘showing their colours’ in an interaction. The mixing of agents is population-
wide, and therefore, in this model, the ‘network’, although giving important
type information for future transactions, plays no more part in the inter-
action space, nor does the actual topology of the network matter.11 Since
there is no network exit criterion, nor behavioural dynamic, Taylor ﬁnds
that networks are rarely socially optimal (as opposed to anonymous trans-
actions) since a bleeding of the ‘good’ types from the general population
ensues (compare (Kali, 1999)).

However, these approaches suﬀer from the constraints imposed by the
analytic framework, thus only allowing one (informal) connected component
to form with such formation not endogenised; authors assume that where

9See the introduction to Smucker et al. (1994) on such observations.
10See also, Tesfatsion’s work on trading games with endogenous partner selection (Tes-

fatsion, 1997).

11As is perhaps clear, this is not a network in the sense of a formal graph with an edge
set, but can be thought of as a disjoint graph with the ‘network’ comprising a complete
connected component.

3 THE MODEL

5

networks are sustainable they will form.

Perhaps the closest work to the current paper, and bridging the IPD/CR
– endogenous network literature, is a second paper by Smucker et al. (1994).
Here, a similar computational model to that previously mentioned is used,
but in addition to considering the strategic implications of various levels of
choice and refusal, they also perform some characterisation of the evolving
network of interactions. In the SSA model, agents are modeled as 16 state
Moore machines12 who are programmed to play the IPD. However, and
signiﬁcantly for the present study, the ‘network’ in the SSA model is deﬁned
by a simple global rule – if the number of interactions between two players
is (statistically) signiﬁcantly larger than the mean interaction count for the
whole population, then an edge is assigned between these players. Thus,
for SSA, the ‘network’ is more a record of ‘acceptable payoﬀ outcomes’
rather than a functional entity which shapes future interactions. This is an
acknowledged limitation of the work.

The present work aims to address many of the mentioned shortcomings
of the literature. First, by implementing network formation as a strategic
and therefore inherently endogenous process; second, and following on from
the ﬁrst, by allowing for multiple networks to form simultaneously (rather
than one connected component only); and third, by implementing agent
strategies as ﬁnite state automata, both bounded rationality and learning
are incorporated.

3 The Model

3.1 Overview

Agents are modeled as ﬁnite state automata (FSA) with a maximum number
of feasible states. As with normal renditions of these automata, each agent
has an initial state which is not contingent on the opponent they are playing,
and each state describes both their action for that state, and their state
transition contingent on the play of their opponent.

Agents begin with a uniform interaction environment (a null-graph) and
within a period undergo at least some minimum number of interactions with
other agents to play the IPD. Within each interaction, agents are able to
inﬂuence the interaction environment by signaling to their opponent that
they wish to break the interaction and reveal their positive or negative re-
sponse to their opponent. If both players play positive signals, an edge is
assigned between them, and the two agents will meet each other with higher

12[As in (Miller, 1996, p.91)] A Moore machine is deﬁned by the four-tuple {Q, qo, λ, δ}
where Q is the set of internal states; qo is the initial state; λ is a mapping from each state
to the subsequent action to be played λ : Q ↔ Si, for example, in the PD, Si ∈ {C, D};
and δ is the transition function that maps from the current internal state of the machine
to the new internal state, contingent on the opponent’s reported move, δ : Q × S∼i ↔ Q,
S∼i ∈ {C, D} being the opponent’s reported move last period (in this case, for the PD).

3 THE MODEL

6

probability in the future. The exact value of this probability is contingent
on how many other agents each has already formed a link with.

In this way, the concept of ‘partner-scarcity’ is incorporated: though
link-formation increases the probability that two agents will meet again, it
does not guarantee it. Consequently, successful agents must either protect
themselves completely from exploitative players through link formation, or
display a depth of complexity in their strategy that can manage playing
against undesirable opponents (or a combination of the two).

At the end of a period, total payoﬀs are determined for each agent, and
an ‘elite’ fraction of the population is retained for the next period, with the
remainder being replaced by new agents.13 New agents are generated from a
combination of existing elite behaviours and new behaviours (a type of learn-
ing) followed by mistake-making/innovation. Elite agents retain their links
between periods (so long as they are to fellow elites) whereas entrants begin
with no links, beﬁtting the concepts of incumbency and network dynamism.
In this way, links are established within a period by mutual agreement
between two agents. However, links can only be broken when an agent leaves
the population after selection, severing all pre-existing links.

3.2 Details

Let N = {1, . . . , n} be a constant population of agents and denote by i and
j two representative members of the population. Initially, members of the
population are uniformly paired to play the modiﬁed IPD game G described
below. When two agents are paired together, they are said to have an
interaction. Within an interaction, agents play the IPD for up to a maximum
of τ iterations, receiving a payoﬀ equal to the sum of the individual payoﬀs
they receive in each iteration of the IPD. An interaction ends prematurely
if either player plays a ‘signal’ thus unilaterally stopping the interaction.
A strategy for a player s describes a complete plan of action for their play
within an interaction, to be explained presently. In addition to the normal
moves of cooperate (C) and defect (D), an agent can also play one of two
signal actions, #s and #w respectively. Thus, in any one iteration of the
IPD, the action-set for an agents is {C, D, #s, #w}. As mentioned above,
the playing of a signal by either player leads to the interaction stopping,
possibly prior to τ iterations being reached. The playing of a signal can
thus serve as an exit move for a player.

The interpretation of the two types of signal is as follows. Although
initial pairing probabilities between all players are uniform random, agents
can inﬂuence these interaction probabilities through the use of the signals.

13Alternatively, one can think of this as a stead-state strategy framework, whereby the
stock of agents is constant between periods, but some fraction decide to update their
strategies. In what follows we shall continue to think in terms of ‘entrants’ (new agents),
though either interpretation is equally valid.

3 THE MODEL

Formally, let some agent i maintain a preference vector,

f i : f i

j ∈ {ps, p0, pw} ∀ j ∈ N/i

(cid:8)

where f i
j is the preference status of agent i towards agent j and ps > p0 > pw
are natural and denote strengthen, untried and weaken preferences respec-
Initially all entries are set to p0 for all j ∈ N/{i}. A probability
tively.
vector ri for each agent is constructed from the preference vector by simple
normalisation onto the real line,

(cid:9)

ri : ri

j =

(

∀ j ∈ N/{i}

,

)

f i
j
f i

P

such that each opponent occupies a ﬁnite, not-zero length on the line [0, 1]
with arbitrary ordering. Since we study here a model of mutual network/trust
formation, preferences can be strengthened only by mutual agreement. Specif-
ically, if agents i and j are paired to play the IPD, then when the interaction
ends in iteration t ≤ τ ,

j = f j
f i

i =

if si
ps
pw else ,

(

t = sj

t = #s ,

where si
t denotes the play of agent i in iteration t. That is, in all cases
other than mutual coordinated agreement, the two agents will lower their
relative likelihood of being paired again (though the playing of #w might
cause the interaction to end prematurely with the same result). Payoﬀs for
each iteration of the PD are given by (5) below.

G(I, II) =

I

C

D

(3, 3)
(5, 0)

(0, 5)
(1, 1)

II

· · ·

· · ·

#s
(0,0)
...
(0,0)

#w
(0,0)
...
(0,0)

#s
C
D
#w

The playing of signals, is costly: the instantaneous cost for that period

is the foregone payoﬀ from a successful iteration of the IPD.

7

(2)

(3)

(4)

(5)

Let two agents i and j be chosen to play (5) in some period and let maximum
interaction length τ = 3. Consider the following interaction,

3.3 Example

Pi
C
D

Pj
C
C
#(s) C

πi
3
5
0
8

πj
3
0
0
3

Iteration
1
2
3
πx

P

3 THE MODEL

8

note that i played an unrequited strengthen signal in the third (last) itera-
tion; both players’ interaction preference entries would be set to pw.

3.4 Game Play

In a period each agent is addressed once in uniformly random order to un-
dergo m interactions with players drawn from the rest of the population
(N/{i}). An agent is paired randomly in accordance with their interaction
probability vector ri with replacement after each interaction. Preference
and probability vectors are updated after every interaction.

Thus, it is possible that, having previously interacted with all agents, an
agent retains only one preferred agent, whilst all others are non-preferred,
causing a high proportion (if not all) of their m interactions to be conducted
with their preferred partner. However, it is to be noted that the value of m
is only a minimum number of interactions for an agent in one period, since
they will be on the ‘receiving end’ of other agents’ interactions in the same
period. In this way, agents who incur an immediate cost of tie strengthening
(foregoing iteration payoﬀs) can gain a long-term beneﬁt through further
preferential interactions.

At the end of T periods, the population undergoes selection. A fraction
θ of the population is retained (the ‘elites’), whilst the remainder (1 − θ) are
replaced by new agents as described below. Selection is based on a ranking
by total agent payoﬀs over the whole period. Where two agents have the
same total payoﬀ in a period, the older player remains.14

3.5 Agent Modeling

Each agent is modeled as an k (maximum) state FSA.15 Since the interaction
will stop immediately after either player plays the signal # each state must
include two transition responses only: R(C) and R(D). For example, an
agent’s ﬁrst three states might take the form (schematic representation given
in Fig. 2) ,

State P R(C) R(D)

1
2
3

C
C
D

1
2
1

3
1
3

⇐ Fig 2
about here

where the ﬁrst state could be read as,

‘play C next, if the opponent plays D, go to state 3; else, stay in
state 1.’

14Following SSA Smucker et al. (1994).
15To facilitate the computational modeling of this environment, agent strategies were
encoded into binary format. See Miller et al. (2002) for an analogous description of this
method for FSA.

4 RESULTS & DISCUSSION

9

An agent will have k such states as part of their ‘strategy’. By convention,
the ﬁrst state is taken as the initial one.

It can be shown16 that the maximum number of states τ possible for an
FSA playing some game with count |R| feasible transition responses lasting
at most τ rounds is simply,

k(R, τ ) =

|R|t ,

(6)

τ −1

t=0
X

hence, under this regime, the maximum interaction length τ and the number
of opponent plays requiring a response deﬁnes the maximal FSA length.
However, it is to be noted that there is no guarantee that all k states for
a given agent will be accessed (consider the example given immediately
above, state 2 is present but is strategically redundant). In this way, FSA
give a tangible sense of ‘strategic complexity’ when it comes to individual
strategies. An agent who uses all of their k > 1 states as part of their
strategy will no-doubt display a deeper strategy in action, than an agent
who is playing merely (say) all-c. Of course, such complexity of strategy
may or may not correspond to relative success in the population.17

After each period, a fraction θ will stay in the population, with the re-
maining agents being ﬁlled by new entrants. Here, the process of imitation
and innovation/mistake-making is implemented via two foundational pro-
cesses from the genetic algorithm (GA) literature.18
Initially, two agents
are randomly selected (with replacement) from the elite population. A one-
point crossover operator is applied to each agent, and two new agents are
formed. The strategy encoding (bit-strings) of these new agents then un-
dergo point mutations at a pre-determined rate (5 bits per 1000). This
process (random selection, crossover and mutation) continues until all the
remaining spots are ﬁlled.

4 Results & Discussion

4.1 Uniform interactions

To begin, we study a static uniform interaction space to check any un-
wanted outcomes due to the modiﬁed IPD set-up. In this situation, rather
than agents upgrading their preference vector after each interaction, the

16Consider a single-rooted logic tree where each node is a state, and each branch some
transition. Without any re-use of states, the tree can be at most τ − 1 nodes deep. Now
observe that after the initial node (call this layer t = 0) each new layer will produce rt
new nodes. The result follows.

17For example, it has been shown countless times before that the humble tit-for-tat
(play C until the opponent plays D, then switch to D until the opponent plays C, then
switch back to C, and so on.) strategy (and its variants) is often an extremely eﬀective
one against all manner of opponents, even though it can be represented by just two states!
18See, for example, Goldberg (2002) or for a non-technical introduction, Holland (1992).

4 RESULTS & DISCUSSION

10

preference vector is uniform and unchanged throughout the model. In this
way, the eﬀect of the modiﬁcation to the standard IPD framework can be
analysed. Under such a scenario, the action set for each agent reduces to
{C, D, #} since the signal action # has no interaction space interpretation,
but still provides a means of prematurely ending the interaction (thus we
may drop the sub-script).

To keep matters simple, we consider a model in which the maximum
interaction length τ = 2, which by (6) yields a maximum FSA state count
of k = 3. Under these conditions, a strategy will be composed simply of a
ﬁrst play, and response plays to C and D.

With uniform interaction probabilities, this model can be thought of
as a modiﬁed evolutionary game theoretic framework. The probability of
interacting with a certain agent type is directly equal to the proportional
representation in the population of that type. Modiﬁcation of the standard
framework is due to the genetic algorithm approach, the crossover operator
providing for imitation in addition to the more standard ‘random’ mutation
operator. However, in terms of evolutionary stable strategies, this modiﬁca-
tion is insigniﬁcant.

In this setting, no evolutionary stable strategy will include # as a ﬁrst
play, since the payoﬀ for such a strategy with any other agent is 0.19 This
leaves strategies in the form of a triplet,

s : {P1, R(C), R(D)} ,

where P1 ∈ {C, D} and R(.) indicate subsequent plays in response to either
C or D plays by the opponent R(.) ∈ {C, D, #}. In all, 18 unique strategies
can be constructed.

It is instructive to consider whether cooperative strategies might be evo-
lutionary stable in this scenario. Clearly, a strategy sC : {C, C, C} will yield
strictly worse payoﬀs than the strategy sD : {D, D, D} in a mixed environ-
ment of the two. It can be shown20 that the strategies sC# : {C, C, #} and
sCD : {C, C, D} (Figs. 3 and 4 , constitute the only two ESSs in an environ-
ment of sD,D,D only. However, both sC# and sCD are themselves susceptible
to attack by a ‘mimic’ agent such as sM = {C, D, D}, which itself will yield
to the familiar sD. In this way, even with the added facility of being able to
end the interaction prematurely, the only evolutionary stable strategy with
respect to the full strategy space is that of sD,D,D. Any intermediate resting
place for the community will soon falter and move to this end (Fig. 5).

19The interaction would end after the ﬁrst iteration, and G(#x|y) = 0 for all x ∈ {s, w}

and y ∈ {C, D, #(s), #(w)}.

20See Lemma 1 in Appendix.

⇐ Fig 3
about here
⇐ Fig 4
about here

⇐ Fig 5
about here

⇐ Fig 7
about here

4 RESULTS & DISCUSSION

11

4.2 Uniform Interactions: Computational Results

Computational experiments were run under uniform mixing as described
above as a method of model validation. Given the maximum interaction
length of τ = 2, results for strategies present as a fraction of the total
population are given in Figure 7 .21 As predicted above, the model shows the
clear dominance of sD under uniform mixing. Additionally, as predicted, the
initial ‘shake-out’ periods (t < 30) gave rise to interesting wave-like strategic
jostling. Agents playing cooperation ﬁrst, and replying to D with # were
the ﬁrst to have an early peak, if short-lived, which is not unexpected,
since playing the signal is not the best-response to any subsequent play.
Thereafter tft-nice (C) peaked, but were soon overcome by the turn-coat
type (who dominates tft-nice). However, as the stock of C players diminish,
‘turn-coat’ too, yields to the D-resp type strategies (such as tft-nasty (D)).
We may conclude then, that the presence of the signal play (#) does
little to aﬀect strategic outcomes in the standard IPD set-up; defection still
reigns supreme in the uniform IPD environment.

4.3 Non-uniform Interactions: Network Formation

From the preceding analysis, a natural question arises: under what circum-
stances, if any, do networks emerge? Whilst it is possible to think of the
network formation process as an aid to certain dominated behaviour (e.g.
mutual cooperation), it is not obvious to what degree the network must
shield certain players from hostile behaviour before their interaction com-
munity can be self-supporting.

Two factors that will clearly aﬀect the propensity for cooperative net-

works to arise, are:

1. The ‘impact’ of the network on the interaction space; to what extent a
strengthening signal actually changes mixing probabilities – formally,
the values of the preference set {p0, ps, pw}; and

2. The minimum number of interactions within a period over which two
agents can exploit a beneﬁcial relationship – formally, the value of m.

These two factors are related, since a low interaction impact may be com-
pensated for by an high absolute number of interactions within a period.

The impact of network formation decisions by agents was parametrised

in the computational experiments as follows,

pw = (1 − η)2
ps = (1 + η)2 ,

and

(7)

(8)

21Modelling notes: each plot-line represents the average result from 20 modelling runs
where in each run: n = 100 and m = 20 with 20 agents replaced after each period,
under roulette-wheel type selection of elites (with replacement) and p(mutation) = 0.5%.
Results were unchanged in substance for m ∈ {2, 5, 10}.

4 RESULTS & DISCUSSION

12

where η ∈ [0, 1). The choice of the expression is somewhat arbitrary, how-
ever, the current speciﬁcation retains symmetry about p0 = 1 for all values
of η and by taking the squared deviation from 1, the ratio ps/pw could be
easily varied over a wide range. For example, by choosing η = 0.8, we yield
pw = 0.04 and ps = 3.24, which gives a ratio of preferences in f i for agent i
for two agents with such values of 81. That is, the preferred agent (where
an edge is assigned for the purposes of visualisation) will be met around 80
times more regularly than the less preferred agent when i is being addressed.
To determine what conditions are favourable for network formation, a
second computational experiment was conducted, this time ‘turning up’ the
interaction space impact of any signalling play by the agents. Speciﬁcally,
the network tuning parameter η was varied in the range [0.2, 0.95] together
with the minimum interaction parameter m over [2, 20].

It was found that necessary conditions for sustainable network formation
were η & 0.8 and m & 10. In terms of the population, these accord with
a ratio of ps to pw (by (7) and (8)) of around 80 times,22 and a minimum
fraction of interactions per period of around 10% of the population.

Table 1. Mean values (over 20 trials) for ﬁnal period (50) agent de-
gree, hdi and fraction of PD plays where mutual cooperation resulted,
f (C, C). (see also Fig. 6).

hdi

f (C, C)

m(cid:31)η
10

14

18

20

0.80

0.000

0.004

0.90

0.95

0.80

0.90

0.95

0.000

0.000

0.0000

0.0000

0.0000

0.001

0.391

0.0001

0.0000

0.0058

2.441

11.859

8.587

0.0286

0.1109

0.0735

7.959

11.073

9.548

0.0914

0.0941

0.1185

Further, the fraction of mutual cooperative plays (of all PD plays) moved
in an highly correlated way with degree (see Table 1 and Fig. 6 ). It would
appear, therefore, that network formation in this model is due to agents who
play C ﬁrst, and P [R(C)] = #s.23 A closer look at the dynamics of prevalent
strategies under network forming conditions conﬁrms this conclusion (see
Fig. 8).

We study here an example (m, η) combination at m = 20, and η = 0.8
(see Fig. 8 ). Four agent types are of interest (along with the summed
the cooperative network forming type (C-NET); the
D-responder types):
defection network forming type (D-NET); and two types which engage in
an highly asymmetric relationship – the opportunist (D-OPP) and so-called
‘sucker’ (C-SCK) types. Again, the periodic rise and fall of strategy types

22That is, an agent is 80 times more likely to interact with a preferred agent rather than

a disliked agent in a given period.

23Recall, agents are free to form networks with any kind of behavioural basis.

⇐ Fig 6
about here

⇐ Fig 8
about here

⇐ Fig 9
about here
⇐ Fig 10
about here

4 RESULTS & DISCUSSION

13

is evident, but importantly, it can be seen that although C-NET, D-NET and
D-OPP appear to co-exist for a time, it is only the cooperative network form-
ing type who prevails in the long run.

To better understand these dynamics, a series of network snapshots for
one representative network formation trial under the above conditions is
shown in Figs. 9 and 10 . Here, at least four distinct phases are discernible.

Phase 1: Amorphous connected (Figs. 9(a) and 9(b))
The ex-
istence of many sucker types leads to a super network with high average
degree. In this case, almost all of the cooperative types have formed links to
at least one sucker type, whilst the opportunists are largely integrated into
the super network, with a range of agent types as adjacent nodes.

Phase 2: Segregated connected (Figs. 9(c) and 9(d))
The net-
work remains super connected, but clear segregation begins to occur, such
that agent-to-agent edges become highly assortative. Fewer sucker types
means that opportunists become competitive for activity in the network
(e.g. Fig. 9(d)). Cooperative and defection communities subsequently es-
tablish themselves (higher intra-community connectivity).

Phase 3: Segregated disjoint (Figs. 10(a), 10(b) and 10(b)) The
sucker type disappears, leading to a ‘shake-out’ in the population – the
over-supply of opportunist types is rectiﬁed, with only those who were able
to integrate with the defective community able to survive. The network is
now dis-joint, with highly deﬁned community characteristics. Further agent
survival depends on raw mutual payoﬀ characteristics.

Phase 4: Homogeneous connected (Figs. 10(d) and 10(e)) With
the signiﬁcantly higher intra-community payoﬀs yielded to the cooperative
community, edges here become highly dense, approaching a complete com-
ponent graph. The defective community disappears, with no possibility of
inﬁltration into the cooperative community (see discussion below). New
agents of cooperative network forming type are able to join and be inte-
grated. Some sucker–opportunist relationships arise on margins but are
short lived only.

4.3.1 Network Agent Types

A dissection of the prominent strategies that arose in the above experiment
was conducted on period 13 (Fig. 9(c)) . A comparison of the network
itself with the agent autopsies given in Fig. 11 makes clear the diﬀerence
between each agent’s activity in the network. Clearly, the interaction of the
opportunist and sucker types (Fig. 11(b) and 11(c) respectively) will lead to
tie-strengthening conditions, but with highly asymmetric payoﬀ outcomes.

⇐ Fig 11
about here

4 RESULTS & DISCUSSION

14

Importantly, however, the ‘robust-C’ type (agent 10 in period 13) is im-
mune to this play by responding with D to the opportunist’s D opening;
a transition that works equally well for agent 10 when facing the robust-D
type (agent 79 in period 13). For this reason, as can be seen in the agent net-
works presented so far, the cooperative types avoid tie-strengthening with
either the robust-D or the opportunist types, which in both cases ensures
adequate type-selection, but in the latter case, protects the cooperative net-
work forming types from the opportunist shake-out that was inevitable with
the decline of the sucker types in periods 13 to 17.

At the statistical level, these interactions are borne out in the periodic
struggle of the initial network dynamics (see Fig. 8). The initial rise of the
sucker types (establishing network ties to any other tie-strengthening agent)
provides fertile ground for the opportunist types, who in turn, support the
defection network types. However, over time, as each loses its respective
‘feed-stock’, network dynamics resolve in favour of the cooperative network
forming types.

It is important to note that within this boundedly-rational framework,
robust network formation is highly dependent on ‘purity’ of network struc-
tures. As can be seen in Fig. 12 , connected components that experience
longevity must be able to attain more than the going ‘outside’ payoﬀ rate
of 2 per interaction.24

As can be identiﬁed, connected components that have a high proportion
of sucker or opportunist types will yield large mean payoﬀs, but are very
short-lived (rarely having mean agent ages greater than 5 periods) due to the
volatile nature of payoﬀ asymmetries. On the other hand, the cooperative
networks who can overcome the short-term heterogeneous phase are very
likely to retain higher than 2 average payoﬀs and so be positively selected
for in the end-of-period strategy revision phase. Clearly, ensuring good
‘discipline’ within a cooperation network must be an high priority for the
sustainability for the agents therein.

Interestingly, it appears from the data presented, that although predom-
inantly defection type networks can yield very high payoﬀs, they will also
suﬀer a type diﬀerentiation problem, mixing easily with the opportunist
types. In the early stages of population dynamics, this a positive attribute
since it will provide these types with high period payoﬀs through greater
‘activity’ (more plays of the IPD), ensuring their individual survival. How-
ever, over time, with the propensity for opportunist types to lose valuable
payoﬀ opportunities with sucker types, the defection networks yield strictly
worse average payoﬀs than the ‘outside’ defection population, since they are
necessarily sacriﬁcing a unit of payoﬀ every time they re-aﬃrm/establish a
link with a fellow defection network type.

24The payoﬀ yield between two All-D types (for example) who play a two-iteration

IPD game, gaining 1 in each iteration.

⇐ Fig 12
about here

4 RESULTS & DISCUSSION

15

4.4 Multiple Equilibria & the Long Run

In the previous section, conditions were identiﬁed in which stable networks
were formed under parsimonious agent speciﬁcation (τ = 2 implying k =
3) to enable correlation with established results in the analytic literature.
Here, this constraint is relaxed and instead agents interactions of up to
four iterations of the IPD game (τ = 4) are considered and their long-run
dynamics studied. Recall, by increasing the length of the IPD game, the
maximal FSA state count increases markedly:
for τ = {3, 4} maximum
state count k = {7, 15}.

Previous conditions were retained, with η = 0.8 and m = 20, and each
trial allowed to run for 1000 periods. Since a full description of the state
is not feasible25 we consider an aggregate description of two fundamental
state characteristics, f (C, C) – the fraction of plays in a period where mu-
tual cooperation is observed (strategic behaviour); and hdi – mean agent
degree (network formation). Results are presented for ﬁve long-run trials in
Fig. 13. Under low interaction length the system moves within 100 steps to
one of two stable equilibria – either a stable cooperation network is formed
(as was studied in the previous section) or no network arises and a stable
defection population sets in. However, as the interaction length increases
(and so the associated complexity of behaviour that each agent can display),
the dynamics become increasingly erratic, with multiple, apparently stable,
equilibria visible in each case, but transient transitions between these equi-
libria observed. This situation is synonymous with that of complex system
dynamics.

To better see this transition, the locations of the system in f (C, C) − hdi
state-space were plotted (see Fig. 14). Here the transition from relatively
well-deﬁned attractors for τ = 2 to complex dynamics at τ > 2 is clear.
Indeed, ﬁve stationary locations are visible in Fig. 5 with location I, II and V
appearing to be transiently stable, with state trajectories both entering and
leaving these locations, whilst locations III and IV appear to be absorbing
for the system. Interestingly, these absorbing locations give rise to relatively
similar average network formation, but diﬀerent levels of cooperation, being
low and moderate respectively.

Similarly, but with greater clarity, the dynamics of τ = 4 shows very
erratic behaviour (Fig. 5), appearing to have only two absorbing locations,
IV and V, whilst each of I, II, and III appear to be transient. In this case, the
absorbing locations are very diﬀerent in character, being an almost complete
graph, but similarly defection-based in the ﬁrst case, or again, with high

25Consider that each time period, a population constitutes n × |s| bits, where |s| is the
length of a string needed to represent each agent’s strategy, and the network n(n − 1)/2
6
bits; taken together, gives rise to a possible 2n(n−1)/2+n|s| states, which for τ = 2 is 29×10
!
(It is possible to reduce this number by conducting automata autopsies, but the problem
remains.)

⇐ Fig 13
about here

⇐ Fig 14
about here

4 RESULTS & DISCUSSION

16

participation, but markedly cooperative in the second.

Surprisingly, such complex dynamics arise in a relatively simple model
of network formation. Recall, that the longest that any of the agent inter-
actions can be in these studies was just two, three or four iterations of the
modiﬁed Prisoner’s Dilemma given in (5). To be very sure that such dy-
namics are not a consequence of the encoding of the automata themselves,
an identical study was run with τ = 4, but setting η = 0 such that all inter-
actions would continue to be of uniform probabilities. However, in all cases,
the system moved to a zero cooperation regime within the ﬁrst 100 periods
and remained there. Clearly then, we conclude that endogeneity of network
formation is driving such complex dynamics as observed above.

4.5 Network Formation & Self-Organized Criticality

Next, given that the system displays complex dynamics for given values of
τ and that network endogeneity is critical to such dynamics, it is natural
to study the dynamics of network formation itself. For these purposes, the
size (node count) of the principle (largest) network component that exists
at the end of each period is studied. Example time-series for one τ = 4 run
In the ﬁrst ﬁgure, the size of the network itself is
are given in Fig. 15.
shown, whilst in the second, the ﬁrst diﬀerences are given (i.e. St − St−1). It
can be seen from this example, that changes in network size occur both on
many time-scales and to various degrees. Such phenomena is synonymous
with systems exhibiting critical behaviour (Bak et al., 1988); perturbations
to the system cause mostly small, damped outcomes, but can occasionally
have dramatic eﬀects, likened to a ‘domino-eﬀect’.

To investigate this feature, frequency distributions of average network
ﬂuctuation sizes D(∆S) were prepared for each interaction length. As can
be seen in Fig. 16 the distributions appear to follow a power-law behaviour,
that is of the form,

D(∆S) ∼ ∆S−α .

(9)

Such a relationship is often termed ‘scale-free’ since it indicates that the
same overall systemic dynamics are operating on all spatial scales; small
deviations build up over time and lead to large deviations in the long-run
due to connectivity within the system.

Spatial self-similarity is one feature of critical systems, the second is that
similar power-law scaling is observed in the temporal domain as well; nor-
mally manifesting as so-called ‘1/f ’ noise, which appears ubiquitous in na-
ture.26 A power spectrum was therefore prepared of the time-series network
size to study this possibility.27 Fig 17 gives the outcome of this analysis,

26Examples from the introduction to (Bak et al., 1988) include: light from quasars, the
intensity of sunspots, the current through resistors, the ﬂow of sand in an hour glass, the
ﬂow of the Nile river, and stock exchange price indexes.

27Suppose s(t) is the (discrete) times-series of some network size data (as per Fig. 15(a)),

⇐ Fig 15
about here

⇐ Fig 16
about here

⇐ Fig 17
about here

5 CONCLUSIONS

17

(10)

showing clear power-law scaling behaviour. Linear ﬁts were prepared for the
ﬁrst 10 data points28 with good agreement in all cases. Exponents of the
relationship,

S(f ) ∼ f −α ,

were found all found to be −1.8 ± 0.1.

Taken together, the spatial and temporal ﬁngerprints of criticality ob-
served in the network formation dynamics, indicate that the system is in-
deed very capable of the kind of complex dynamics observed and discussed
above, and that the network formation appears to be a key factor in such
behaviour. Furthermore, as has been proposed by various authors, rather
than such criticality arising from ﬁne tuning of system parameters such as
occurs in designed critical industrial systems (e.g. nuclear ﬁssion reactors),
the system appears to naturally move towards this critical state, and keep re-
turning to it over time. It is for this property that authors such as Bak et al.
(1988) have termed such phenomena ‘self-organized criticality’. Indeed, it
appears that such phenomena is a strong indicator of complex dynamics,
and may indeed be the necessary system state to give rise to the kind of
non-equilibrium processes observed in various dissipative systems.29

The existence of such dynamics in economic systems has recently received
growing interest.30 Indeed, power-law behaviour on both a macro (Canning
et al., 1998; Devezas and Modelski, 2003) and micro- interactions scale (Are-
nas et al., 2000; Scheinkman and Woodford, 1994) has been incorporated
into both models and empirical evidence, and some assert is fundamental to
our understanding and thus modelling of economic systems (Arthur, 1994).
Hence, the existence of such dynamics and features in the present model is
a pleasing indication that signiﬁcant features of realistic network formation
contexts has been incorporated.

5 Conclusions

In contrast to previous attempts at capturing the dynamics of strategic
network formation, the present model provides a relatively simple founda-
tion, but powerfully rich behavioural and topological environment within
which to study the dynamics of strategic network formation. Moreover, in
contrast to previous dynamic and strategic network models, by incorporat-

then using Matlab a Fast-Fourier-Transform, F (s) was performed with N = 28 points,
followed by the standard power-function, F F ′/N , where F ′ is the complex conjugate of
F . Figures show the resultant power spectra without the ﬁrst constant-shift term f (0),
and are cut below S(f ) ≤ 5 × 10−4.

28Fitting power-law models has received some interesting study in recent times due to
diﬃculties in forming goodness-of-ﬁt tests etc. Here we follow Goldstein et al. (2004) in
form, ﬁtting the linear speciﬁcation to only a selection of the primary points, thus avoiding
undue bias in the tails (which represent a very small mass of the spectrum).

29See for example, Langton (1992) for a discussion on this point.
30See for example, Krugman (1996).

5 CONCLUSIONS

18

ing the network formation decision-process into individual agent strategies, a
rich ecology of agent types and consequent network topologies was observed.
Signiﬁcantly, this model suggests that the network formation process must
deliver relatively symmetric payoﬀs to network members. If this is not true,
networks formed will likely be heterogeneous in nature, with disruptive edge
formation and breaking sequences which can eﬀectively destroy any beneﬁts
that the network might have conferred on members (e.g. the opportunist-
sucker network volatility of phases I and II mentioned above).

Analytical and subsequent computational components of the present pa-
per indicate that in this simple modiﬁed IPD set-up, cooperation is not sus-
tainable without the additional beneﬁts conferred by the type-selection and
type-protection network externalities. Speciﬁcally, agents require at least
some level of repetition of interaction within the current population to gain
suﬃcient incentives to form the network; and secondly, the ‘impact’ of the
network on the interaction space was found to be a necessary condition for
cooperative network formation, with network emergence only observed when
the network allows for relatively high (though not complete) discrimination
(probabilistically) from the wider population.

Furthermore, the dynamical properties of the present model have been
investigated and indicate that even with parsimonious descriptions of boundedly-
rational agent strategies, complex dynamics are observed, with multiple and
transient stationary locations a feature of the state space. These dynamics
increased in complexity with increasing interaction length. Additionally, ev-
idence on the ﬂuctuations in the size of networks over time indicates that the
network formation and decay processes themselves are likely the main driv-
ing force behind the complex system dynamics, with both spatial and tem-
poral scaling behaviour indicating the existence of so-called ‘self-organized
criticality’. To this author’s knowledge, this is the ﬁrst strategic network
formation model to produce and study such complex dynamics. Such ob-
servations clearly raise tantalising avenues for future work; I shall raise a
selection in ﬁnishing: do realistic cooperative networks display complex dy-
namics? if not, what mechanism of agency overcomes such instability? if
networks can be shown to have such dynamics (admittedly these data are
still largely out of reach) what are the implications for supporting coop-
erative institutions? and ﬁnally, given an autonomous, locally interacting
world, how should the social planner intervene in such networks to pursue
welfare maximizing aims?

A

B

D

C

Figure 1. Uniform matching, n = 4.

C

C

D

D

D
C

Figure 2. Example FSA: Tit-for-tat.

C

C

D

#

Figure 3. Agent strategy sC# : {C, C, #}.

C

C

D

D

Figure 4. Agent strategy sCD : {C, C, D}

C

C

D

#

D

D

C

C

D

D

Figure 5.
(Clock-wise from top) sC# is stable in the presence of sD only but is
susceptible to attack by sM which in turn will yield to sD, the ﬁnal evolutionary stable
strategy component.

0.12

0.1

0.08

)

C
C

,

(
f

0.06

0.04

0.02

0
0

2

4

8

10

12

6
d

Figure 6. Fraction of mutual cooperation per PD vs. average agent degree under each
condition listed in Table 1. Line (---) indicates simple OLS regression expected values.

10

20

30

40

50

Period

Figure 7. Population fraction of strategies under uniform mixing: (D-TFT) ‘nasty’ Tit-
for-tat; (C-TFT) ‘nice’ tft; (C-#) plays C, returns D with #; (C-TURN) ‘turn-coat’,
plays C, but D thereafter; (D-RESP) sum of all players who play D and return D with
D.

f

0.5

1

0.9

0.8

0.7

0.6

0.4

0.3

0.2

0.1

0
0

f

0.5

1

0.9

0.8

0.7

0.6

0.4

0.3

0.2

0.1

0
0

0.15

0.1

0.05

D−RESP 

C−# 

D−TFT 

C−TFT 

C−TURN 

0
0

5

10

15

20

25

30

D−RESP

C−NET

0.15

0.1

0.05

D−NET

C−SCK

D−OPP

0

0

5

10

15

20

25

30

10

20

30

40

50

Period

Figure 8. Example mean population fraction types playing various strategies (over
20 trials) under necessary network formation conditions (m = 20, η = 0.8): (C-NET)
robust cooperation; (D-NET) robust defection; (D-OPP) opportunist; (C-SCK) ‘sucker’;
and (D-RESP) mutual defector types.

79

26

39

71

86

56

33

21

45

82
38

9

92

1

36

89

42

85

96

100
50

12

29

53

22

8

53

90

27

18

69

47

80

60

37

4

30

18

54

25

51

13

10

77

84

17

88

29

54

39

56

61

71

38

82

96

36

21

12

9

45

33

88

1

84

98

47

89
85

80

60

42

22

51

37

17

8

10

72

27

77

69

14

62

90

(a) 10

95

(b) 12

4

47
6
79

56

30

81

78

27

100

82

13

79

100

96

82

1

38

4

56

30
86

29
9

33

21

12

45

50

88

53

85

47

51

27

8

10

77

90

69

22

80

54

42

95

84

(c) 13

42

17

67

63

61

71

95

54

84

18

53

97

92

43

19

10

77

24

(d) 16

17

18

92

80

8

1

69
51

70

16

Figure 9. Example network dynamics (m = 20, η = 0.8): network state at end of
indicated period; agent ID show next to each node; agent coloring as follows – (•)
robust cooperative; (•) robust defection; (•) opportunist; and (•) ‘sucker’ (see text
for explanation).

77

24

69

43

19

80

10

1

51

37

82

22

81

79

99

30

47

100

56

18

6

4

19

10

24

15

6

37

43

47

51

62

69

82

92

5

95

100

99

(a) 17

1

18

90

56

80

72

77

81

(b) 18

27

28

25

24

1522

3

31

30

33

34
36
37
40
41

43

45

14

10
5

1
92
91

88

53

87

80

79

68

47

5156 57 74 77

71

82

81

(c) 28

(d) 35

(e) 40

Figure 10. Example network dynamics (cont.): network state at end of indicated
period (see Fig. 9 for explanation). NB: Agent ID omitted for periods 35 and 40.

#(s)

#(s)

C

D

C

C

D

D

D

D

(a) ID

10

‘robust-C’

(b) ID 92 ‘op-
portunist’

C, D

C

#(s)

C

D

D

#(s)

(c) ID 85 ‘sucker’

(d) ID 79 ‘robust-D’

Figure 11. Example types visible in the network of period 13 above (see Fig. 9).

t
n

i
/
f
f
o
y
a
P

4.5

3.5

2.5

4

3

2

1

1.5

0.5

0
0

5

10

Age

15

Figure 12. Scatter plot, mean Payoﬀ per interaction vs. mean Age for each point which
represents a single connected component. Coloring indicates dominant (> 50%) type in
each component: (•) ‘suckers’; (•) ‘opportunists’; (•) defection network builders; and
(•) cooperation network builders. NB: line at interaction payoﬀ 2 indicates expected
payoﬀ for non-connected D-types. (Other parameters as for Fig. 8).

0.30

0.25

0.20

0.15

0.10

0.05

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0.7

0.6

0.5

0.4

0.3

0.2

0.1

(a,b,e) 

(a,b,e) 

0.00

0
10

1
10

2
10

3
10

0.00

0
10

1
10

(c,d) 

2
10

3
10

(a) τ = 2, hdi

(b) τ = 2, f (C, C)

0.30

0.25

0.20

0.15

0.10

0.05

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0.7

0.6

0.5

0.4

0.3

0.2

0.1

(c,d) 

(c) 

(a,b) 

(d) 

(e) 

(c) 

(e) 

(b) 

(d) 

(a) 

(c) 

(e) 

(b) 

(d) 

(a) 

(e) 

(d) 

(a) 

(b) 

(c) 

0.0

0
10

1
10

2
10

3
10

0.0

0
10

1
10

2
10

3
10

(c) τ = 3, hdi

(d) τ = 3, f (C, C)

0.0

0
10

1
10

2
10

3
10

0.0

0
10

1
10

2
10

3
10

(e) τ = 4, hdi

(f) τ = 4, f (C, C)

Figure 13. Long-run system dynamics under diﬀerent maximum interaction lengths
indicating increasing complexity; ﬁve trials shown at each value of τ (data smoothed
over 20 steps).

II 

II 

V 

IV 

III 

I 

I 

(a) τ = 2

(b) τ = 3

I 

II 

V 

IV 

III 

(c) τ = 4

Figure 14. State transitions, f (C, C) − hdi space. Contours indicate (log10) density
of time periods spent at (f, hdi) points over all trials; lines represent smoothed trial
trajectories (20 steps), coloring shows each trial.

 100

  90

  80

S

  70

  60

  50

  40

   0

  40

  30

  20

  10

S
∆

 

   0

 −10

 −20

 −30

 −40

   0

 200

 400

 600

 800

1000

 200

 400

 600

 800

1000

t

(a)

t

(b)

Figure 15. Example time series of principle component size (a) and change in size (b)
for τ = 4.

0
10

−1

10

)

 

S
∆
(
D

−2

10

−3

10

−4

10

0
10

0
10

−1

10

)

 

S
∆
(
D

−2

10

−3

10

1
10
∆ S

(a) τ = 2

2
10

−4

10

0
10

1
10
∆ S

2
10

(b) τ = 3

0
10

−1

10

)

 

S
∆
(
D

−2

10

−3

10

−4

10

0
10

1
10
∆ S

2
10

(c) τ = 4

Figure 16. Mean principle component network size distribution for each interaction
length. Lines given as guide only.

0
10

−1

10

)
f
(

S

−2

10

−3

10

−4

10

−3

10

1
10

0
10

−1

10

−2

10

−3

10

)
f
(

S

−4

10

−3

10

−2

10

−1

10

0
10

−2

10

−1

10

0
10

f

(b) τ = 3

(a) τ = 2

f

)
f
(

S

1
10

0
10

−1

10

−2

10

−3

10

−4

10

−3

10

−2

10

−1

10

0
10

f

(c) τ = 4

Figure 17. Mean power spectra of principle component network size for each interac-
tion length. Lines represent power-law ﬁts to ﬁrst 10 points with α = −1.9, −1.8, −1.7
for τ = 2, 3, 4 respectively.

32

(11)
(12)

(13)
(14)

(15)
(16)

(17)

5 CONCLUSIONS

Appendix 1

Lemma 1 For a population playing the IPD as given in G under uniform
interaction probabilities and maximum FSA state length τ = 2, the strategy
triplet sD : {D, D, D} is the only evolutionary stable strategy (ESS).

Proof To begin with, consider a population consisting of only two types of agents,

where one type is sD and the other the strategy triplet sS : {P S
1 is the agent’s play in state one and RS(x) represents the agent’s
where P S
play in response to opponent’s play x in the preceeding iteration. For conve-
nience, call these types D and S respectively.
Deﬁne the total payoﬀ to an agent X undergoing an interaction with agent
Y to be Π(X|Y ) and note that,

1 , RS(C), RS(D)}

1 ) + G(D|RS(D))

Π(D|S) = G(D|P S
Π(D|D) = 2 × G(D|D)
Π(S|D) = G(P S
Π(S|S) = G(P S

1 |D) + G(RS(D)|D)
1 ) + G(RS(P S
1 |P S

1 )|RS(P S

1 ))

Further, let α be the proportion of type S in the population. Then, the
expected interaction payoﬀs for each agent type with uniform mixing is given
by,

E[Π(S)] = αΠ(S|S) + (1 − α)Π(S|D)
E[Π(D)] = (1 − α)Π(D|D) + αΠ(D|S) .

Now suppose α → 1, if S is to be stable in the presence of D then it follows
from (15) and (16) that,

Π(S|S) ≥ Π(D|S),

which by (11) to (14) becomes,

G(P S

1 |P S

1 ) + G(RS(P S

1 )|RS(P S

1 )) ≥ G(D|P S

1 ) + G(D|RS(D)) .

(18)

Now suppose that P S

1 = C then by payoﬀs given in (5), (18) becomes,

G(RS(C)|RS(C)) ≥ G(D|RS(D)) + 2 ,

(19)

which implies that RS(C) must be C and that RS(D) 6= C. Hence, there
are only two candidates for S, namely sCD : {C, C, D} and sC# : {C, C, #}.
However, both sCD and sC# are not stable in the presence of the mimic agent
sM : {C, D, D} which itself does not satisfy the condition given in (18).
Suppose on the other hand that P S
of payoﬀs into (18)) that,

1 = D. This would imply (by substitution

G(RS(D)|RS(D)) ≥ G(D|RS(D))

which has no solution unless RS(D) = {D, #}.

5 CONCLUSIONS

33

(20)

Now, consider a population where α → 0 and suppose there exists some
strategy S′ such that E[Π(S′)] ≥ E[Π(D)] which again yields,

G(P S

1 |D) + G(RS(D)|D) ≥ 2 .

If P S

1 = C (20) becomes,

which has no solution. Likewise, if P S

1 = D we have,

G(RS(D)|D) ≥ 2

G(RS(D)|D) ≥ 1

which has a solution only if RS(D) = D, completing the proof. (cid:3)

REFERENCES

34

References

Anderlini, L. and Ianni, A. (1996). Path dependence and learning from

neighbors. Games and Economic Behavior, 13:141–177.

Anderlini, L. and Ianni, A. (1997). Learning on a torus. In Bicchieri, C.,
Jeﬀrey, R., and Skyrms, B., editors, The Dynamics of Norms, chapter 5,
pages 87–107. Cambridge University Press, New York.

Arenas, A., Diaz-Guilera, A., Perez, C. J., and Vega-Redondo, F. (2000).
Self-organized evolution in a socioeconomic environment. Physical Review
E, 61(4):3466–3469.

Arthur, W. B. (1994). Inductive reasoning and bounded rationality. Amer-

ican Economic Review, Papers and Proceedings, 84(2):406–411.

Ashlock, D., Smucker, M. D., Stanley, E. A., and Tesfatsion, L. (1996). Pref-
erential partner selection in an evolutionary study of prisoner’s dilemma.
BioSystems, 37:99–125.

Axelrod, R. and Hamilton, W. D. (1981). The evolution of cooperation.

Science, 211(4489):1390–1396.

Bak, P., Tang, C., and Wiesenfeld, K. (1988). Self-organized criticality.

Physical Review A, 38(1):364–374.

Bala, V. and Goyal, S. (2000). A noncooperative model of network forma-

tion. Econometrica, 68(5):1181–1229.

Barabasi, A. L., Jeong, H., Neda, Z., Ravasz, E., Schubert, A., and Vicsek,
T. (2002). Evolution of the social network of scientiﬁc collaborations.
Physica A: Statistical Mechanics and its Applications, 311:590–614.

Baum, J. A. C., Shipilov, A. V., and Rowley, T. J. (2003). Where do small
worlds come from? Industrial and Corporate Change, 12(4):687–725.

Canning, D., Amaral, L. A. N., Lee, Y., Meyer, M., and Stanley, H. E.
(1998). Scaling the volatility of gdp growth rates. Economic Letters,
60:335–341.

Choi, J.-K. (2002). Play locally, learn globally: The structural basis of
cooperation. Working Paper 02-12-066, Santa Fe Institute, Santa Fe,
New Mexico, USA.

Coveney, P. and Highﬁeld, R. (1996). Frontiers of Complexity. Faber and

Faber.

Devezas, T. and Modelski, G. (2003). Power law behavior and world system
evolution: A millennial learning process. Technological Forecasting and
Social Change, 70:819–859.

REFERENCES

35

Dutta, B., van den Nouweland, A., and Tijs, S. (1998). Link formation in
cooperative situations. International Journal of Game Theory, 27:245–
256.

Elgazzar, A. S. (2002). A model for the evolution of economic systems in
social networks. Physica A: Statistical Mechanics and its Applications,
303(3-4):543–551.

Ely, J. C. (2002). Local conventions. Advances in Theoretical Economics,

2(1):Article 1.

Fan, Y. (2002). Questioning guanxi: deﬁnition, classiﬁcation and implica-

tions. International Business Review, 11:543–561.

Girvan, M. and Newman, M. E. J. (2001). Community structure in social
and biological networks. Technical report, Santa Fe Institute and Cornell
University, 1399 Hyde Park Road, Santa Fe, NM 87501 and Clark Hall,
Ithaca, NY 14853-2501.

Goldberg, D. E. (2002). The Design of Innovation:

lessons from and for

competant genetic algorithms. Kluwer Academic Publishing, Boston.

Goldstein, M. L., Morris, S. A., and Yen, G. G. (2004). Problems with

ﬁtting to the power-law distribution. Cond-mat, (0402322 v3).

Hauk, E. and Nagel, R. (2001). Choice of partners in multiple two-person
prisoner’s dilemma games. The Journal of Conﬂict Resolution, 45(6):770–
793.

Holland, J. H. (1992). Genetic algorithms. Scientiﬁc American, pages 44–50.

Holland, J. H. and Miller, J. H. (1991). Artiﬁcial adaptive agents in economic
theory. American Economic Review, Papers and Proceedings, 81(2):365–
370.

Jackson, M. O. and Watts, A. (2002). The evolution of social and economic

networks. Journal of Economic Theory, 106:265–295.

Kali, R. (1999). Endogenous business networks. The Journal of Law, Eco-

nomics, & Organization, 15:615–636.

Kandori, M. (1992). Social norms and community enforcement. The Review

of Economic Studies, 59(1):63–80.

Kirchamp, O. (2000).

Spatial evolution of automata in the prisoners’

dilemma. Journal of Economic Behavior & Organization, 43:239–262.

Krugman, P. (1996). The Self-organizing Economy. Blackwells, Cambridge,

MA.

REFERENCES

36

Langton, C. G. (1992). Life at the edge of chaos. In Langton, C. G., Taylor,
C., Farmer, J. D., and Rasmussen, S., editors, Artiﬁcial Life II, volume 41
of Santa Fe Institute Studies in the Science of Complexity, New Mexico.
Santa Fe Institute, Addison-Wesley. Proceedings of the Workshop on
Artiﬁcial Life Held February, 1990 in Santa Fe, New Mexico.

Lewin, R. (1993). Complexity: Life on the Edge of Chaos. Phoenix, London.

Marsili, M., Vega-Redondo, F., and Slanina, F. (2004). The rise and fall of

a networked society: a formal model. PNAS, 101:1439–1442.

Masuda, N. and Aihara, K. (2003). Spatial prisoner’s dilemma optimally

played in small-world networks. Physics Letters A, 313:55–61.

Miller, J. H. (1996). The coevolution of automata in the repeated prisoner’s
dilemma. Journal of Economic Behavior & Organization, 29:87–112.

Miller, J. H., Butts, C. T., and Rode, D. (2002). Communication and
cooperation. Journal of Economic Behavior & Organization, 47:179–195.

Mitchell, G. T. (1999). Evolution of networks and the diﬀusion of new
technology. Technical report, Computational Laboratories Group at the
University of California, Santa Barbara, Department of Economics, Uni-
versity of California, Santa Barbara, CA 93106.

Scheinkman, J. A. and Woodford, M. (1994). Self-organized criticality and

economic ﬂuctuations. American Economic Review, 84(2):417–421.

Slikker, M. and van den Nouweland, A. (2000). Network formation models
with costs for establishing links. Review of Economic Design, 5:333–362.

Smucker, M. D., Stanley, E. A., and Ashlock, D. (1994). Analyzing so-
cial network structures in the iterated prisoner’s dilemma with choice
and refusal. Technical Report CS-TR-94-1259, University of Wisconsin-
Madison, Department of Computer Sciences, 1210 West Dayton Street,
Madison, WI.

Standiﬁrd, S. S. and Marshall, R. S. (2000). The transaction cost advantage
of guanxi-based business practices. Journal of World Business, 35(1):21–
42.

Stocker, R., Cornforth, D., and Bossomaier, T. R. J. (2002). Network struc-
tures and agreement in social network simulations. Journal of Artiﬁcial
Societies and Social Simulation, 5(4).

Taylor, C. R. (2000). The old-boy network and the young-gun eﬀect. Inter-

national Economic Review, 41(4):871–91.

REFERENCES

37

Tesfatsion, L. (1997). A Trade Network Game with Endogenous Partner
Selection, volume 6 of Advances in Computational Economics. Kluwer
Academic Publishers.

Tesfatsion, L. (2003). Agent-based computational economics. Working Pa-
per 1, Iowa State University, Department of Economics, Ames, Iowa.

Tyler, J. R., Wilkinson, D. M., and Huberman, B. A. (2003). Email as
spectroscopy: Automated discovery of community structure within orga-
nizations. Technical report, HP labs, 1501 Page Mill Road, Palo Alto,
CA, 94304.

Watts, D. J. and Strogatz, S. H. (1998). Collective dynamics of ‘small-world’

networks. Nature, 393:440–442.

White, D. R., Owen-Smith, J., Moody, J., and Powell, W. P. (2004). Net-
works, ﬁelds, and organizations: Micro-dynamics, scale and cohesive em-
beddings. Working Paper 04-03-009, Santa Fe Institute, Santa Fe, New
Mexico, USA.

