5
0
0
2
 
c
e
D
 
2
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
5
0
1
2
1
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Modeling self-organization of communication and topology in social networks

M. Rosvall1,2∗ and K. Sneppen2†
1)Department of Theoretical Physics,
Umeå University, 901 87 Umeå, Sweden
2)Niels Bohr Institute, Blegdamsvej 17,
Dk 2100, Copenhagen, Denmark

(Dated: December 16, 2013)

This paper introduces a model of self-organization between communication and topology in social networks,
with a feedback between different communication habits and the topology. To study this feedback, we let agents
communicate to build a perception of a network and use this information to create strategic links. We observe
a narrow distribution of links when the communication is low and a system with a broad distribution of links
when the communication is high. We also analyze the outcome of chatting, cheating, and lying, as strategies to
get better access to information in the network. Chatting, although only adopted by a few agents, gives a global
gain in the system. Contrary, a global loss is inevitable in a system with too many liars.

PACS numbers: 89.70.+c,89.75.Fb,89.65.Lm

Introduction

Model

Who communicates with whom and the social structure of
a society are strongly entangled. The social network reﬂects
the access to information that different parts of the system ex-
perience, and social mobility may be seen as a quest for bet-
ter information access. A reliable global perception of the
network, often achieved by informal communication with ac-
quaintances [1, 2, 3, 4, 5, 6, 7, 8], makes the social mobil-
ity meaningful [9, 10]. The small talk consists in its sim-
plest form of identifying who to get the information from, and
whom to transfer it to [11, 12, 13, 14, 15, 16]. To under-
stand the feedback between different communication habits
and the topology, we in this paper introduce an agent-based
model that self-organize the social network. That is, we al-
low agents to create new links to get easier access to some
parts of the system, based on interest and the information they
obtained through communication with already established ac-
quaintances [17, 18, 19].

After deﬁning the model in the next section, we show that
organized structures, that can make use of the small-world
properties of the network [20, 21, 22], emerge when the com-
munication is sufﬁciently high. This is followed by an inves-
tigation of consequences of manipulating information. What
are the gains or costs when the agents adopt individual strate-
gies to get better access to the system on, respectively, local
and global level? We investigate consequences of chatting,
cheating and lying, and ﬁnd, for example, that lying opens
for a communication analogue to the prisoners dilemma game
[23]. Finally we explore a few variants of the model and, for
example, show how separation of interests naturally leads to
modular networks in the model.

∗Electronic address: rosvall@tp.umu.se
†URL: http://cmol.nbi.dk

Let us now deﬁne the model in detail, formulated in the two

basic events:

• Communication: Select a random link and let the two
agents that it connects communicate about a random
third agent [24]. The two agents also update their in-
formation about each other.

• Rewiring: Select a random agent and let it use its in-
formation to form a link to shorten its distance to a
randomly chosen other agent. Subsequently a random
agent loses one of its links.

The communication event is typically repeated of the order
of number of links in the system for each rewiring event. Fig-
ure 1 and 2 illustrate the two elements in the model. The basic
variables in the network model are nodes represented by N
agents and L links that correspond to the available communi-
cation channels in the system. We let the agents communicate
and in that way build their own perception of where they are
relative to other agents in the network. Each agent, in Fig. 1
exempliﬁed by agent A, has a list of previously obtained infor-
mation with entries for each agent i =A, B, C,. . . For each en-
try i, the agent has a pointer to the agent that provided the most
recent information about i. This pointer is updated if someone
else comes with newer information about i [22]. Therefore we
also keep the age of all obtained information in A’s memory
(see clocks in Fig. 1). The age of an agent’s information about
itself is always 0. The age of any other information increases
proportional to the number of ongoing communication events
in the system. When two agents communicate about a third
agent the agent with the older information disregards this and
adopts the viewpoint of the agent with the newer information
by copying the age and changing the pointer. In Fig. 1 agent
A communicates with B about agent H, and adopts the view-
point of B because B’s information about H is newer. A sets
its clock for H to the same time as B, and change its pointer
for H to B. The age of the information serves as a qualiﬁer that

2

FIG. 1:
(color online) Communication as modeled in this paper:
Agents communicate with their neighbors in the network about a
third target agent, and estimate the quality of the information by its
age. The agent with the oldest information adopts the viewpoint of
the agent with the newest information. Here, agent A learns that B
has newer information about H, disregards its old information, and
change its pointer towards H to B. The information in the bottom
bubbles are A’s knowledge about the network based on communica-
tion with its neighbors before and after the communication event with
B: For each agent (top row) the time of the most recent information
is stored (middle row) together with the acquaintance that provided
the information (bottom row).

allows two communicating agents to estimate which of them
that have the most reliable information.

Figure 2 describes the second main feature of the model,
the social mobility. We implement the social constraints of
who can connect to whom by only allowing new links from an
agent to acquaintances of its acquaintances [25]. A randomly
chosen agent, here A, is interested in shortening its distance
to another randomly chosen agent in the system, here H. A
therefore asks B, the agent that provided A with the newest
information about H, about where the information came from.
B answers E and A builds a link to E (if there is no link be-
tween A and B, A builds a link to B and stops after that). The
creation of new links is balanced by random removal of links.
This is illustrated in Fig. 2, where C, chosen randomly, looses
its connection to D.

In the model, we thus have an interplay between the com-
munication backbone network and the perception that the
agents have of this network. The pointers of all agents, with
both real and outdated links, form the perception network. In
Fig. 3 we illustrate the concept of a communication backbone
and the perception network at low and high communication in
a small network with 25 nodes and 38 links. For relatively few
communication events per rewiring (much less than the num-

FIG. 2: (color online) Rewiring as modeled in this paper: Agents
create new contacts based on their available information (see Fig. 1).
In this example A uses B, the agent that A got the newest information
about H from, to get a better position relative to H. A then creates a
link to E, the agent that B got it information about H from. Thereafter
a random agent looses a random link, in this example the connection
between C and D.

ber of links in the system), the communication and perception
network diverge and the rewiring that the agents perform has
little to do with the real topology of the network. As a conse-
quence, any rewiring of the network will be random and the
network’s overall topology disorganize into a structure with
a narrow degree distribution [26] (see the two networks to
the right in Fig. 3). In contrast, a high communication im-
plies that new links are introduced as a direct function of the
present topology. They are typically directed towards highly
connected nodes since they provide new information. With
a tendency of building new links toward the majority of the
system, a reliable perception opens for positive feedback and
self-organization into a network with broad degree distribu-
tion (see the two networks to the right in Fig. 3).

Results

To quantify the interplay between the self-organization of
network topology and the overall communication level we in
Fig. 4 and 5 show degree distributions for simulations of a
system with N = 1000 agents, L = 2500 links, and different
values of the communication level C. C · L is the number of
communication events per rewiring event in the network, and
the degree k of a node is its number of links. We have also
simulated networks with different number of links and found
similar results with a tendency towards more pronounced non-
random features with fewer links.
In Figure 4 the number
of communication events per rewiring and link is varied be-
tween C = 10−4 and C = 100. At low communication level,
C < 1, the perception network has many more links than
the backbone network. As C approaches C ∼ 1 the percep-

(a)

(b)

Low communication

High communication

(c)

(d)

FIG. 3:
(color online) Illustration of the to types of social bonds in
the network at two different levels of communication. (a) and (b)
show the communication backbone over which agents communicate.
(c) and (d) show the perception network associated to the agents’
directions to other agents in the network. The pointers are colored
black when they are updated and coincide with active connections.
In the network with high communication (right panel), almost all
pointers overlap with the communication backbone.

tion network prunes its links whereas the backbone network
develops nodes with high degrees. At even higher values of
C the two networks converge toward the same broad degree-
distribution.

Beyond the degree distribution, we in Fig. 5 show the cor-
relation proﬁle (top), the average neighbor degree (middle)
and the number of triangles (bottom) as a function of degree
for low (left) and high (right) communication. In all cases
we compare with a randomized network where the degree se-
quence is identical to the model generated, but all other fea-
tures are reshufﬂed [27]. We chose C = 10−2 as the low and
C = 1 as the high communication level. The overrepresenta-
tion of links between nodes of high and low degree gives ex-
tended community structures. Triangles are overrepresented
around low-degree nodes and underrepresented around high-
degree nodes [20].

All the presented results until now are based on agents that
all are the same. At any time their social position will however
be different, because their sequence of communication and
rewirings is strongly inﬂuenced by the history of the system.
The presented model describes a social game where the aim is
to be central, and a winner is an agent with many connections
that provide short and reliable communication to other agents.
The fact that we observe agents with a wide range of degrees
reﬂects the diversity of the possible outcomes of the game, and
raises the questions about whether there are some particular

3

(b)

(d)

102

r
o
b
h
g
i
e
n
k

100

r
o
b
h
g
i
e
n
i
k
h

△
N

Links

Pointers

C = 10−4

C = 10−2

(a)

(c)

100

10−1

10−2

)
k
≥
(
P

10−3

1

10−1

10−2

)
k
≥
(
P

C = 1

10−3

1

C = 102

10

k

10

1

10

k

100

FIG. 4: (color online) Illustration of the feedback of communication
on the topology of both communication backbone and perception
network at 4 different levels of communication C. C = 1 corre-
sponds to on average 1 communication event per link and rewiring
event. Networks size is N = 1000 agents connected by L = 2500
links in the communication backbone.

(a)

(b)

0.5

102

(c)

random
real

(d)

(e)

(f)

2

1

101

102

101

100

10−1

100

101
k

102

100

101
k

102

FIG. 5:
(color online) The topology of the generated networks at
two different levels of communication C. C = 0.01 in left panel and
C = 1 in right panel. First row shows the correlation proﬁle, sec-
ond row the average neighbor degree as a function of degree and the
third row the clustering measured as the number triangles. All mea-
sures are compared with randomized counterparts of the networks
with unchanged degree-sequence.

strategies with which agents can improve their standing in the
network? Can acting like a winner make you more likely to
become a winner? Are there some particular situations where
agents systematically can attract additional connections and
become a hub?

A highly connected agent became highly connected be-
cause it attracted new links by providing new information
about other agents. To provide new information is essential to
win the game. We therefore investigate a number of individ-
ual strategies where agents attempt to convince other agents
about their attractiveness as an acquaintance.

Chatting represents an increased communication rate. We
let the chatters communicate twice as much as other agents
by increasing the probability that their links are chosen for a
communication event by a factor 2. Note that this also affects
their acquaintances because they share links with the chatters.
Cheating represents a decreased clock-speed. We let the
cheaters use clocks that run at half the speed of the other
agents’ clocks, and their information will thereby have a
slower aging. In practice they cheat by pretending that they
have newer information than they really have. Cheating might
be either deterministic (every time unit is half length) or
stochastic (a time unit is counted with probability 1/2).

Lying represents a pure lie about the age of the information
in a communication event. Instead of updating the clock, the
liars replace the time by a random number. Here we choose
the random number between 1 and 100 that represents the typ-
ical age of information about an agent within the second near-
est neighbor radius in a system with 1000 agents.

In all three strategies the information is manipulated to gain
a local advantage. However, there may also be a cost, both on
local and on global scale. This is what we examine in Fig. 6
and 7. Figure 6 shows the topological consequences on the
communication backbone and Fig. 7 the effect on the percep-
tion network, as we vary the number of strategic agents be-
tween 1 and the system size at communication level C = 1.
The right panel in Fig. 6 shows how the max degree of re-
spectively the strategic agents (black circles) and non-strategic
agents (orange squares) changes with Nstrategic. When less
than about 10 agents adopt any of the three strategies the
they gain in terms of degree. However, as the number of
liars increase, the overall network topology degenerates and
it becomes impossible to sustain hubs. Also the liars become
losers. A more global examination of the effect of the vari-
ous strategies are shown in left panel of Fig. 6. The efﬁciency
E = h1/diji is the average value of the reciprocal distance
[28] of, respectively, the strategic agents, and the non-strategic
agents. This measure of typical distances in the network allow
us to include also temporarely disconnected nodes. In terms
of efﬁciencies all strategies are successfully, and in addition
they also seem to beneﬁt the other agents by providing short
paths.

That the strategic agents become central in the communica-
tion backbone-network does not directly imply that they can
use their centrality. The use of various strategies may inﬂu-
ence the reliability of information that the agents have about
the system and thereby make long-distance communication
more difﬁcult. In Fig. 7 we examine the ability of agents to

4

103

102

101

102

101

102

)
x
a
m
k
(

e
e
r
g
e
d
m
u
m
i
x
a

M

communicate across the system. dcom in the left panel is the
average number of agents that participate in communicating
a message from an agent to another agent. For chatters, we
again see that everybody gains. For cheaters, on the other
hand, everybody gains if the cheating is deterministic, but
already a few agents with stochastic cheating (faded) makes
communication across the system less efﬁcient. The from Fig.
6 seemingly successful strategy of lying completely destroy
the communication abilities (Fig. 7(e)). One single liar makes
some beneﬁt of its strategy, but two liars are enough to not
only destroy for the nonliars, but also for the liars themselves.
To emphasize this result, we in the right panel of Fig. 7
show the reliability, Rroute, of the perception network. To
calculate Rroute, we send messages between any pairs of node
and let the intermediate agents route the messages with their
pointers. A message fails when it reaches an agent for the
second time and the path forms a loop. Rroute is the frac-
tion of messages that reach the target. The chatters are able

(a)

no chatters
nonchatters
chatters

Nchatters
no cheaters
noncheaters
cheaters

(c)

(b)

(d)

Nchatters

(e)

(f)

Ncheaters
no liars
nonliars
liars

Ncheaters

1

0.8

0.6

0.4

0.2

0

0.8

0.6

0.4

0.2

0

0.8

0.6

0.4

0.2

)
i
j
i
d
/

1

h
=
E

(
y
c
n
e
i
c
ﬁ
f
E

0
100

101

102

103

101

102

Nliars

Nliars

103101

FIG. 6:
(color online)Topological consequences of introducing
strategic agents, quantiﬁed through efﬁciency (deﬁned as E =
h1/dij i) respectively maximum degree of both the strategic (black
circles) and the remaining agents (orange squares). (a-b) Effect of
having Nchatters agents which communicate twice as much as the
remaining N −Nchatters agents in network. (c-d) Effect of Ncheaters
agents that cheat by running their internal clock at half the speed of
the other N − Ncheaters agents’ clocks. (e-f) Effect of a more bru-
tal strategy where Nliars agents always pretend that their information
about all other agents is very new (of the order of what the remaining
N − Nliars agents have for their nearest or next nearest neighbors).
The communication rate is C = 1 in a system with N = 1000 nodes
and L = 2500 links.

to keep perfect reliability, but the cheaters and especially the
liars destroy it. When there are 1000 deterministic cheaters
the reliability is again 100% (see Fig. 7(d)). This is because
it only corresponds to a rescaling of time when all agents are
deterministic cheaters. The liars, examined in Fig. 7(f), sys-
tematically destroy the signaling capacity of the network.

(a)

no chatters
nonchatters
chatters

Nchatters
no cheaters
noncheaters
cheaters

(c)

(b)

(d)

Nchatters

Ncheaters

Ncheaters

(e)

(f)

)
m
o
c
d
(

e
c
n
a
t
s
i
d
n
o
i
t
a
c
i
n
u
m
m
o
C

64
32
16
8
4
2
1
64
32
16
8
4
2
1
64
32
16
8
4
2
1
100

no liars
nonliars
liars
102

Nliars

101

0.2
1030

103

101

102

Nliars

FIG. 7: (color online)Perception consequences of introducing strate-
gic agents, quantiﬁed through communication distance, dcom and re-
liability of routed messages, Rroute. (a-b), (c-d), and (e-f), corre-
sponds to the same strategies as in Fig. 6. In (c-d) orange and black
correspond to the deterministic cheaters and the faded colors corre-
spond to the stochastic cheaters.

The presented model is the simplest in a family of models
based on an interplay between communication and dynamical
changes of topology. We have investigated a range of varia-
tions, including versions where each agent has a biased inter-
est in other agents. For example, we let an agent’s target of
interest be chosen inversely proportional to the age of the in-
formation about the target [29]. Thereby interests are focused
around the neighborhood and we observe an increase in the
number of triangles in the system. In another variant, we di-
vided the agents into several interest groups. By increasing
the probability to communicate and move inside the interest
group, the network develops a modular topology.

Discussion

In this work we have introduced a model framework that
allow us to investigate the interplay between social structures

5

and communication habits. We have shown that low commu-
nication leads to random networks with narrow degree dis-
tributions. Increased communication naturally gives nonran-
dom structures characterized in particular by social networks
with broad degree distributions.
In addition to developing
broad degree distributions, the networks also tend to orga-
nize highly connected agents to connect preferably to low con-
nected agents.

With the model, we have investigated how manipulating
information inﬂuence the social structure, quantiﬁed by the
topology of the emerging network. Firstly we increased the
communication frequency of individual agents. The result
was striking, the more an agent chats with its surroundings,
the better it performs. Increased chatting requires increased
effort, but our model shows that there is both a local and a
global gain to this effort.

Secondly we investigated the effect of cheating with the age
of the information a particular agent distributes. If an agent
only underestimated the time since it received the information,
the agent improved its position but at a cost to the remaining
system. As cheating does not cost more communication effort
of the agent, it is the cheap way to optimize the social posi-
tion selﬁshly. However, already a single cheater decreases the
overall reliability to send signals across the network, reﬂect-
ing a moderate global cost to this strategy.

Thirdly we investigated the more violent strategy of lying.
The lying agents pretend that they have recent information
about everybody else. The strategic agents in this way suc-
ceed to attract links and thereby become central in the com-
munication backbone network. However, only a single liar in
a system with non liars beneﬁt from the strategy. Lying is so
destructive that one liar is enough to break down the reliability
of the network and none is in reality a winner.

1

0.8

0.6

0.4

0.2

0

0.8

0.4

0.2

0

0.8

0.6

0.4

0.6

R

)
e
t
u
o
r

(
y
t
i
l
i
b
a
i
l
e
R

Summary

In a broad perspective the proposed model suggests an in-
formation theoretical perspective on social and possibly also
economic systems. By introducing an information game
based on social links and communication rules we present an
approach to the dynamics of human organization. Agents in a
network use information, obtained through communication in
the network, to form new links for better access to informa-
tion. The introduced feedback enables us to study the topo-
logical consequences of different communication habits. By
playing this communication game, we learn that communica-
tion, although not equally distributed, is a beneﬁt for every-
one. However, communication is expensive. Other cheaper
strategies are tempting, but a strategy based on lies easily
counteract the intention to have better access to information.
The social possibilities are not solely deﬁned by the position
in the network, but also by the quality of the surrounding in-
formation.

6

[1] D. Krackhardt and J. Hanson, Harv. Bus. Rev. 71, 104 (1993).
[2] F. Bass, Management Science 15, 215 (1969).
[3] J. J Brown, and P. H. Reingen, J. Cons. Res. 14, 350 (1987).
[4] D. Knoke, PoliticalNetworks: TheStructuralPerspective. New

York: Cambridge University Press (1990).

[5] E. Rogers and D. Kincaid, Communicationnetworks: Towarda
newparadigmforresearch. New York: The Free Press (1981).
[6] B. A. Huberman and J. O. Ledyard, Inform. Syst. Front. 5, 7

[7] M. Rosvall and K. Sneppen, submitted.
[8] M. Rosvall and K. Sneppen, Phys. Rev. Lett. 91, 178701 (2003).
[9] N. E. Friedkin, Social Forces 62, 54 (1983).
[10] P. S. Dodds, R. Muhamad and D. J. Watts Science 301, 827,

234 (1994).

(1981).

(2003).

(2003).

[11] S. Milgram, Psychol. Today 1, 61 (1967).
[12] T. Jeffrey and S. Milgram. Sociometry 32, 425 (1969).
[13] J. M. Kleinberg, Nature 406, 945 (2000).
[14] J. M. Kleinberg,

in T. G. Dietterich, S. Becker and Z.
Ghahrmani (eds.), Proceedings of the 2001 Neural Information
Processing Systems Conference, (MIT Press, Cambridge, MA
2002).

[15] J. M. Kleinberg, in Proceedings of the thirty-second annual
ACM symposium on Theory of computing table of contents
Portland, Oregon, United States (2000).

[16] D. J. Watts, P. S. Dodds, and M. E. J. Newman. Science 296,

1302 (2002).

(2003).

238701 (2005).

[17] D. Carpenter, K. Esterling and D Lazer, Ration. Soc. 15, 411

[18] N.E. Friedkin, Soc. Networks 3, 273 (1982).
[19] A. Trusina, M. Rosvall, and K. Sneppen, Phys. Rev. Lett. 94,

[20] D. Watts and S. Strogatz, Nature 393, 440 (1998).
[21] M. Kochen, Ed., “The Small World” (Ablex, Norwood, 1989).
[22] C. E. Perkins and P. Bhagwat, In Proc. ACM SIGCOMM 94,

[23] R. Axelrod, The Evolution of Cooperation. Science 211, 1390

[24] J R. Bergmann, DiscreetIndiscretions: TheSocialOrganization

ofGossip, (Aldine De Gruyter, New York, 1993).

[25] J. Davidsen, H. Ebel, and S. Bornholdt Phys. Rev. Lett. 88,

128701 (2002)

[26] P. Erd˝os and A. Rényi, Publ. Math. Debrecen 6, 290 (1959).
[27] S. Maslov and K. Sneppen, Speciﬁcityandstabilityintopology

ofproteinnetworks. Science 296, 910 (2002).

[28] V. Latora and M. Marchiori, Phys. Rev. Lett. 87, 198701 (2001).
[29] Javasimulation available at

http://cmol.nbi.dk/models/inforew/inforew.html

[30] We acknowledges the support of the Danmarks Grundforskn-

ingsfondcenter: “Models of Life" at NBI.

