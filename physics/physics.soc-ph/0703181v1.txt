7
0
0
2
 
r
a

M
 
8
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
1
8
1
3
0
7
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Preprint 1/2006

Least Squares Importance Sampling for Monte Carlo Security Pricing

Luca Capriotti∗
Global Modelling and Analytics Group, Investment Banking Division, Credit Suisse Group
One Cabot Square, London, E14 4QJ, United Kingdom
(Dated: February 2, 2008)

We describe a simple Importance Sampling strategy for Monte Carlo simulations based on a least
squares optimization procedure. With several numerical examples, we show that such Least Squares
Importance Sampling (LSIS) provides eﬃciency gains comparable to the state of the art techniques,
when the latter are known to perform well. However, in contrast to traditional approaches, LSIS
is not limited to the determination of the optimal mean of a Gaussian sampling distribution. As
a result, it outperforms other methods when the ability to adjust higher moments of the sampling
distribution, or to deal with non-Gaussian or multi-modal densities, is critical to achieve variance
reductions.

Keywords: Monte Carlo Simulations, Variance Reduction Techniques, Importance Sampling, Derivatives
Pricing.

I.

INTRODUCTION

The impressive development of the securities markets
has generated in the last few years a steady demand for
more and more structured ﬁnancial products. At the
same time, the level of sophistication and complexity of
the pricing models employed by investment ﬁrms has dra-
matically increased, in a continuous search for a possible
edge against competitors. As a result, an increasing frac-
tion of the models employed in practice is too complex to
be treated by analytic or deterministic numerical meth-
ods (trees or partial diﬀerential equations), and Monte
Carlo simulation becomes more often than ever the only
computationally feasible means of pricing and hedging.

Although generally easy to implement, Monte Carlo
simulations are infamous for being slow. In fact, being
stochastic in nature, their outcome is always aﬀected by
a statistical error, that can be generally reduced to the
desired level of accuracy by iterating the calculation for
long enough time. This comes with a high computa-
tional cost as such statistical uncertainties, all things be-
ing equal, are inversely proportional to the square root of
the number of statistically independent samples. Hence,
in order to reduce the error by a factor of 10 one has to
spend 100 times as much computer time. For this reason,
to be used on a trading ﬂoor, Monte Carlo simulations
often require to be run on large parallel computers with
a high ﬁnancial cost in terms of hardware, infrastructure,
and software development.

Motivated by this very practical necessity, several ap-
proaches to speed up Monte Carlo calculations, such as
Antithetic Variables, Control Variates, and Importance
Sampling, have been proposed over the last few years [1].
These techniques aim to reduce the variance per Monte
Carlo observation so that a given level of accuracy can be
obtained with a smaller number of iterations. In general,
this can be done by exploiting some information known

∗Electronic address: luca.capriotti@credit-suisse.com.

a priori on the structure of the problem at hand, like
a symmetry property of the Brownian paths (Antithetic
Variables), the value of a closely related security (Con-
trol Variates), or the form of the statistical distribution of
the random samples (Importance Sampling). Antithetic
Variables and Control Variates are the most commonly
used variance reduction techniques, mainly because of
the simplicity of their implementation, and the fact that
they can be accommodated in an existing Monte Carlo
calculator with a small eﬀort. However, their eﬀective-
ness varies largely across applications, and is sometimes
rather limited [1].

On the other hand, Importance Sampling techniques,
although potentially more powerful, have not been em-
ployed much in professional contexts until recently. This
is mainly because such techniques generally involve a big-
ger implementation eﬀort, and they are also less straight-
forward to include in a general Monte Carlo framework.
Moreover, when used improperly, Importance Sampling
can increase the variance of the Monte Carlo estimators,
thus making its integration in an automated environment
more problematic. Nonetheless, the potential eﬃciency
gains at stake are so large that the interest in ﬁnding
eﬃcient Importance Sampling schemes is still very high.
The idea behind Importance Sampling is to reduce the
statistical uncertainty of a Monte Carlo calculation by
focusing on the most important sectors of the space from
which the random samples are drawn. Such regions criti-
cally depend on both the random process simulated, and
the structure of the security priced. For instance, for a
deep out-of-the money Call option [2], the payoﬀ sampled
is zero for most of the iterations of a Monte Carlo sim-
ulation. Hence, simulating more samples with positive
payoﬀ reduces the variance. This can be done by chang-
ing the probability distribution from which the samples
are drawn, and reweighing the payout function by the
appropriate likelihood-ratio (Radon-Nikodyn derivative)
in order to produce an unbiased result of the original
problem [1].

Most of the work in Importance Sampling methods
for security pricing has been done in a Gaussian setting

[3, 4, 5, 6, 7, 8, 9, 10] such the one arising from the sim-
ulation of a diﬀusion process. In this framework, Impor-
tance Sampling is achieved by modifying the drift term
of the simulated process in order to drive the Brownian
paths towards the regions that are the most important
for the evaluation of the security. For instance, for the
Call option above, this can be obtained by increasing the
drift term up to a certain optimal level [3, 4]. The dif-
ferent approaches proposed in the literature, essentially
diﬀer in the way in which such change of drift is found,
and can be roughly divided into two families depending
on the strategy adopted. The ﬁrst strategy, common to
the so-called adaptive Monte Carlo methods [5, 8, 9, 10],
aims to determine the optimal drift through stochastic
optimization techniques that typically involve an itera-
tive algorithm. On the other hand, the second strategy,
proposed in a remarkable paper by Glasserman, Heidel-
berger, and Shahabuddin (GHS) [6], relies on a deter-
ministic optimization procedure that can be applied for
a speciﬁc class of payouts. This approach, although ap-
proximate, turns out to be very eﬀective for several pric-
ing problems, including the simulation of a single factor
Heath-Jarrow-Morton model [7], and portfolio credit sce-
narios [11].

In this paper, we propose the Least Squares Impor-
tance Sampling (LSIS), as an eﬀective and ﬂexible vari-
ance reduction method for Monte Carlo security pric-
ing. This approach, originally proposed in Physics for
the optimization of quantum mechanical wave functions
of correlated electrons [12], is applied here in a ﬁnancial
setting. In LSIS the determination of the optimal drift –
or more in general of the most important regions of the
sample space – is formulated in terms of a least squares
minimization. This technique can be easily implemented
and included in an existing Monte Carlo code, and simply
relies on a standard least square algorithm for which sev-
eral optimized libraries are available. We will show that
LSIS provides eﬃciency gains analogous to the ones of
previously proposed methods when the latter are known
to perform well. However, LSIS does not share some of
their limitations, and its range of applications includes
multi-modal problems and non-Gaussian sampling.

In the following Section, we begin by reviewing the
main ideas behind Importance Sampling in a generic
Monte Carlo framework. Then in Section III we special-
ize the discussion to the Gaussian setting, and we brieﬂy
review the recent adaptive strategies, and the GHS ap-
proach of Ref.[6]. The rationale of LSIS is introduced
in Section IV together with the essential implementation
details, and in Section V we present the results of our
numerical experiments. Here we perform a systematic
study of the variance reductions obtained by means of
LSIS for a variety of test cases, including a comparison
with recent Importance Sampling techniques. Finally, we
draw our conclusions in Section VI.

2

FIG. 1: Sampling probability density functions for a Euro-
pean Call option with T = 1, r = 0.05, σ = 0.3, X0 = K = 50
as obtained with LSIS [optimizing just the drift, LSIS(˜µ), and
both the drift and the volatility, LSIS(˜µ, ˜σ)], and the sad-
dle point approximation (GHS). On this scale the results for
LSIS(˜µ) and GHS are indistinguishable. The original (13) and
the optimal (9) sampling densities are also shown for compar-
ison.

II.

IMPORTANCE SAMPLING

Let us consider the general problem of estimating the
expectation value of a scalar function, G(Z), depending
on a d-dimensional real random vector Z = (Z1, . . . , Zd)
with joint probability distribution P (Z),

V = EP [G(Z)] =

dZ G(Z) P (Z) ,

(1)

ZD

where D is the domain of possible values of the state
variables Z [19].
In a ﬁnancial derivatives context,
G(Z) would typically represent the discounted pay-
out of a certain security, and P (Z) would be the risk
neutral-probability measure of an arbitrage free mar-
ket [13, 14, 15]. For instance, for the familiar Call op-
tion in the Black-Scholes framework [2] one has d = 1,
P (Z) = (2π)−1/2 exp (−Z 2/2) and

G(Z) = e−rT

X0 exp

(cid:18)

r − σ2
2 (cid:19)

(cid:20)(cid:18)

T + σZ

− K

(cid:21)

(cid:19)

+

(2)
where r is the risk-free interest rate, σ is the volatility,
X0 and K are respectively the spot and strike price, and
T the maturity of the option.

Whenever the dimension d of the state variable Z is
large (say d & 4) standard numerical quadrature ap-
proaches become highly ineﬃcient, and Monte Carlo
methods are the only feasible route for estimating ex-
pectation values of the form (1). To do so, one interprets
Eq. (1) as a weighted average of the payout function G(Z)
over the possible conﬁgurations Z with weights given
by the probability distribution P (Z). This immediately
leads to the simplest (and crudest) Monte Carlo estima-
tor which is obtained by averaging the payout function

3

Indeed, the Monte Carlo integration can be performed
by sampling an arbitrary probability distribution ˜P (Z)
provided that the integral is suitably reweighed. In fact,
using the identity

dZ G(Z) P (Z) =

dZ

ZD

G(Z)P (Z)
˜P (Z)

ZD

˜P (Z) ,

(6)

an alternative estimator of the expectation value (1) is
readily found as

V ≃ ˜V =

W (Zi) G(Zi)

Zi ∼ ˜P (Z) ,

(7)

1
Np

Np

Xi=1

with the weight function given by W (Z) = P (Z)/ ˜P (Z).
The variance of the new Monte Carlo estimator reads

˜Σ2 =

dZ (W (Z) G(Z) − V )2 ˜P (Z)

(8)

ZD

and critically depends on the choice of the sampling prob-
ability distribution ˜P (Z). For non-negative functions
G(Z), the optimal choice of ˜P (Z) is the one for which
˜Σ vanishes, namely:

Popt(Z) =

G(Z)P (Z) .

(9)

1
V

In fact, the Monte Carlo estimator corresponding to such
optimal sampling distribution reads

(4)

(5)

˜V ≃ 1
Np

Np

Xi=1

1
Np

Np

Xi=1

W (Zi)G(Zi) =

V ,

(10)

leading to a constant value V on each Monte Carlo repli-
cation, and resulting therefore in zero variance [21]. Un-
fortunately, such a choice is not really viable as the nor-
malization constant, V , is the expectation value (1) we
want to calculate in the ﬁrst place.

III. GAUSSIAN FRAMEWORK

The Importance Sampling approaches proposed in
the literature usually apply or are generally formulated
within a Gaussian setting, i.e., in a context where the
distribution P (Z) deﬁning the expectation value (1) is a
d-dimensional standard normal distribution. For exam-
ple, this is the case for a Monte Carlo simulation of a
vector diﬀusive process of the form [1]

dX(t) = µ(X(t), t) dt + σ(X(t), t) dWt ,

(11)

e.g., for the calculation of the price of an option de-
pending on the path followed by X(t) within a certain
time interval [0, T ]. Here the precess X(t) and the drift
µ(X, t) are both L-dimensional real vectors, Wt is a N -
dimensional standard Brownian motion, and the volatil-
ity, σ(X, t), is a L × N real matrix.

FIG. 2: Optimal drift vector as obtained with the LSIS and
the GHS procedures for an arithmetic Asian Call option (15),
Φ( ¯X) = ( ¯X
K +), on a lognormal asset (14) for M = 16
σ = 0.3, X0 = K = 50, r = 0.05, and T = 1.0.

−

over a sample of Np independent values of the random
variable Z generated according to the probability distri-
bution P (Z),

V ≃ ¯V =

G(Zi)

Zi ∼ P (Z) .

(3)

1
Np

Np

Xi=1

In particular, the central limit theorem [16] ensures that,
for big enough samples, the values of the estimator ¯V are
normally distributed around the true value, and converge
for Np → ∞ towards V namely

where Σ2 = EP
the estimator and can be similarly approximated by

− EP [G(x)]2 is the variance of

G(x)2
(cid:2)

(cid:3)

V ≃ 1
Np

Np

Xi=1

G(Zi) ± Σ
Np

,

p

Σ2 ≃ 1
Np

Np

Xi=1 (cid:0)

G(Zi) − ¯V

2

.

(cid:1)

Although Eq. (4) ensures the convergence of the Monte
Carlo estimator to the expectation value (1), its practical
utility depends on the magnitude of the variance, Σ2. In-
deed, the square root convergence in (4), implies that the
number of replications Np that are (asymptotically) nec-
essary to achieve a given level of accuracy is proportional
to the variance of the estimator [20]. Roughly speaking,
such quantity is relatively small whenever the function
G(Z) is approximately constant over the region of val-
ues of Z that is represented the most among the random
samples, i.e., the region that contains most of the prob-
ability mass of P (Z). This is generally not the case for
most of the pricing problems encountered in practice, and
the calculation of accurate estimates of the expectation
value (1) may require large sample sizes Np, thus becom-
ing computationally demanding.

However, the choice of extracting the random vari-
able Z according to the probability distribution P (Z),
although natural, is by no means the only possible one.

4

TABLE I: Comparison between LSIS, the adaptive Robbins-Monro (RM) algorithm (as quoted in Ref. [10]), and the saddle
point approach of Ref. [6] (GSH): price of a European Call option on a lognormal asset (14) for diﬀerent values of the volatility
σ, and of the strike price K. The variance reduction (VR) is deﬁned in Eq. (26). The parameters used are r = 0.05, X0 = 50,
T = 1.0, and the number of simulated paths is 1,000,000 for Crude MC, LSIS and GHS, 50,000 for RM. Results for LSIS obtained
by optimizing the drift only [LSIS(˜µ)], and both the drift and the volatility [LSIS(˜µ, ˜σ)] are reported. The uncertainties on
the least signiﬁcative digits of the option prices, and variance reductions are reported in parentheses. Note that in Ref. [10] no
error estimate was quoted for the RM results. However, from the ratio of the simulated paths, it is sensible to estimate the
errors on the RM variance reductions as about √20

4 times larger than those quoted for LSIS(˜µ).

≃

Crude MC
Price
21.4633(50)
3.4032(39)
0.2315(11)
21.598(15)
7.114(11)
3.4954(83)

LSIS(˜µ)

LSIS(˜µ, ˜σ)

RM

GHS

Price
21.46294(49)
3.4019(14)
0.23112(19)
21.5912(37)
7.1169(35)
3.4514(21)

VR
104(1)
7.8(1)
33.5(5)
16.4(1)
9.9(5)
15.6(1)

Price
21.46296(12)
3.4046(10)
0.23132(12)
21.5984(21)
7.1159(21)
3.4523(14)

VR
1700(100)
15(1)
84(5)
51(1)
27(1)
35(1)

Price
21.47
3.41
0.23
21.63
7.12
3.45

VR
112(4)
7.8(4)
31(2)
16.8(4)
11(2)
15.2(4)

Price
21.46294(50)
3.4018(14)
0.23126(19)
21.5973(39)
7.1146(35)
3.4508(22)

VR
100(1)
7.8(1)
33.5(5)
14.8(2)
9.9(1)
14.2(1)

TABLE II: Same as Table I for a European Put option.

Crude MC
Price
0.004235(98)
0.9636(19)
7.3052(46)
0.13397(83)
4.6794(65)
10.5203(97)

LSIS(˜µ)

LSIS(˜µ, ˜σ)

RM

Price
0.0041650(47)
0.96419(64)
7.3059(19)
0.13445(13)
4.6761(27)
10.5236(44)

VR
435(6)
8.8(1)
5.9(1)
41(1)
5.8(1)
4.9(1)

Price
0.0041616(41)
0.96436(38)
7.3056(11)
0.13448(10)
4.6767(16)
10.5266(26)

VR
571(9)
25(2)
17(1)
69(2)
16.5(5)
13.9(2)

Price
0.0042
0.97
7.31
0.13
4.68
10.54

VR
350(24)
9.6(4)
6.3(4)
38(4)
6.2(4)
4.8(4)

GHS

Price
0.0041650(47)
0.96385(63)
7.3047(19)
0.013440(13)
4.6761(27)
10.5223(46)

VR
435(6)
9.1(1)
5.9(1)
40.8(5)
5.8(1)
4.4(1)

σ
0.1

0.3

σ
0.1

0.3

K
30
50
60
30
50
60

K
40
50
60
30
50
60

Continuous time processes of the form (11) are typi-
cally simulated by sampling X(t) on a discrete grid of
points, 0 = t0 < t1 < . . . < tM = T , by means, for
instance, of a Euler scheme [22]

Xi+1 = Xi + µ(Xi, t) ∆ti + σ(Xi, t)

∆ti Zi+1 ,

(12)

p

where Xi = X(ti), ∆ti = ti+1 − ti, and Zi+1 is a N -
dimensional vector of independent standard normal vari-
ates.
In this representation, each discretized path for
the vector process X(t) can be put into a one to one
correspondence with a set of d = N × M independent
standard normal variables Z. Hence, the original prob-
lem of evaluating the expectation value of a functional of
the realized path of the process X(t) can be formulated
as in (1). More precisely, G(Z) is given by the discretized
payout functional, and the probability density is given by
a d-dimensional standard normal distribution

P (Z) = (2π)−d/2 e−Z

/2 ,

2

(13)

where Z 2 = Z · Z.

As a prototypical example of exotic option pricing
problem, treated as a test case for the most recently pro-
posed Importance Sampling strategies [6, 8, 9, 10], in the
following we will consider diﬀerent arithmetic Asian style
options under a Black-Scholes log-normal model [15]. In
this case, the underlying asset can be simulated on the
time grid relevant for the payout function by means of

the exact recursion

Xi+1 = Xi exp

(r − σ2/2)∆ti + σ
h

p

∆tiZi+1

,

(14)

i

where r is the risk free interest rate, σ is the constant
N × L real volatility matrix, and σ2 is a L-dimensional
N
vector of components σ2
j=1 σkj . For an arithmetic
Asian style claim, the discounted payout function is of
P
the form

k =

G(Z) = e−rT Φ( ¯X)

(15)

where ¯X = (1/M )
i=1 Xi, and Φ( ¯X) is some function
of L variables. Clearly, European style options are recov-
ered in the special case M = 1.

P

M

A. Gaussian Trial Distributions

The simplest possible strategy for Importance Sam-
pling in a Gaussian framework is to try to guide the
sampled paths towards the most important regions of
the conﬁguration space (i.e., where the contribution of
the integrand is the largest), by means of a change of the
drift terms of the process (11) or (12). The corresponding
trial probability density reads

˜P˜µ(Z) = (2π)−d/2 e−(Z−˜µ)

2

/2 ,

(16)

TABLE III: European Butterﬂy spread option (28) on a lognormal asset (14) for diﬀerent values of the spot price: comparison
between the saddle point approach of Ref. [6] (GHS), and LSIS with the optimization of both drift and volatility [LSIS(˜µ, ˜σ)]
The parameters used are r = 0.1, K1 = 45, K2 = 50, K3 = 55, T = 1.0, σ = 0.3, and the number of simulated paths is
1,000,000.

Crude MC
Price
0.15818(69)
0.4871(11)
0.6274(13)
0.5156(12)
0.32961(97)

GHS

LSIS(˜µ, ˜σ)

Price
0.15732(33)
0.48666(98)
0.6274(13)
0.5157(10)
0.32875(67)

VR
4.4(8)
1.26(1)
1.00(1)
1.44(1)
2.10(1)

Price
0.157659(40)
0.48703(11)
0.62750(11)
0.515636(93)
0.329281(73)

TABLE IV: Comparison between LSIS and the saddle point approach of Ref. [6] (GSH): price of Asian options (15) on a
lognormal asset (14) for diﬀerent values of the volatility σ, the strike K, and of the number of observation dates M . The
parameters used are r = 0.05, X0 = 50, T = 1.0, and the number of simulated paths is 1,000,000.

σ
0.1

0.3

0.1

0.3

K
45
50
55
45
50
55
45
50
55
45
50
55

Crude MC
Price
6.0565(29)
1.9198(22)
0.20272(74)
7.1545(77)
4.1730(63)
2.2135(48)
5.9967(28)
1.8467(21)
0.17519(67)
7.0257(75)
4.0271(61)
2.0849(46)

LSIS

GHS

Price
6.05522(88)
1.91994(80)
0.20235(16)
7.1531(26)
4.1714(20)
2.2115(13)
5.99510(87)
1.84522(78)
0.17448(14)
7.0204(25)
4.0222(19)
2.0794(13)

VR
10.86(5)
7.56(5)
21.4(2)
8.8(1)
9.9(1)
13.6(7)
10.4(5)
7.2(3)
23(2)
9.0(2)
10.3(5)
12.5(5)

Price
6.05537(89)
1.91914(83)
0.20237(16)
7.1529(27)
4.1712(21)
2.2116(14)
5.99500(85)
1.84525(81)
0.17443(14)
7.0204(26)
4.0220(20)
2.0794(13)

X0
30
40
50
60
70

M
16

16

64

64

5

VR
298(5)
100(5)
140(1)
166(2)
177(2)

VR
10.62(5)
7.03(5)
21.4(2)
8.13(1)
9.0(1)
11.8(7)
10.9(5)
6.7(3)
23(1)
8.3(2)
9.3(5)
12.5(5)

where ˜µ is a d-dimensional vector, and the weight func-
tion, as also expected from the Girsamov theorem [14],
is

W˜µ(Z) = exp

−˜µ · Z + ˜µ2/2
(cid:2)

(cid:3)

.

(17)

A variety of approaches for the determination of the
drift vector ˜µ minimizing the variance of the estima-
tor (8) has been recently proposed in the literature
[5, 6, 7, 8, 9, 10]. These can be roughly classiﬁed into
two families depending on the strategy adopted. The
ﬁrst strategy, common to the so-called adaptive Monte
Carlo methods, aims to determine the optimal drift vec-
tor though a stochastic minimization of the variance.
Such minimization diﬀers in details in the various meth-
ods but always involves an iterative procedure, to be per-
formed in a preliminary Monte Carlo simulation.

In particular, Su and Fu [8, 9], building upon pre-
vious work by Vazquez-Abad and Dufresne [5], used
a gradient-based stochastic approximation, dubbed in-
ﬁnitesimal perturbation analysis, in order to estimate the
optimal uniform shift of the drift for the diﬀusion (12),
minimizing the variance of the estimator (8). In the no-
tation of this Section, this translates in working with a
trial density of the form (16) where the drift vector ˜µ has
components all equal to a single optimization parameter.
The improvement of this method with respect to the one

of Ref. [5], is that the minimization is carried out un-
der the original probability measure (as we also do for
LSIS), while in the latter the minimization was formu-
lated under the trial probability measure. As a result,
the stochastic minimization applies also for non diﬀeren-
tiable payout, thus making the approach more general.
The application of this technique to partial average Asian
options in a Black-Scholes market, and to caplets under
the Cox-Ingersoll-Ross model provides signiﬁcative vari-
ance reductions [8, 9].

Along similar ideas, Arouna [10] has recently proposed
a diﬀerent stochastic optimization method for the deter-
mination of the optimal sampling density (16). Here, in
contrast to the previous approach, all the components
of the drift vector are independently optimized. The
method relies on a truncated version of the Robbins-
Monro algorithm that is shown to converge asymptot-
ically to the optimal drift, and to provide an eﬀective
variance reduction in a variety of cases. However, as re-
marked by the same author, a critical aspect of the prac-
tical implementation of the Robbins-Monro algorithm is
that it depends on the size of the iterative step. Hence,
a particular care needs to be taken in order for the algo-
rithm to be eﬃcient [23].

On the other hand, the second strategy, proposed by
Glasserman, Heidelberger, and Shahabuddin (GHS) [6],

TABLE V: Importance Sampling plus Stratiﬁcation. Comparison between LSIS, and the GHS approach of Ref. [6] for the
Asian Option of Table IV.

M
16

64

σ
0.3

0.3

LSIS+ SS

GHS + SS

K
45
50
55
45
50
55

Price
7.15284(25)
4.17122(18)
2.21183(11)
7.02075(23)
4.02251(17)
2.07967(13)

VR
950(20)
1225(15)
1900(100)
1060(30)
1290(30)
1320(100)

Price
7.15266(24)
4.17118(18)
2.21183(11)
7.02076(23)
4.02250(17)
2.07965(12)

6

VR
1030(10)
1225(30)
1900(50)
1060(30)
1290(30)
1470(100)

relies on a saddle point approximation to minimize the
variance of the estimator (8), or equivalently of its second
moment (in the original measure)

m2(˜µ) =

dZ W˜µ(Z) G(Z)2 P (Z) .

(18)

ZD

In fact, if the payout function G(Z) is positive deﬁnite, by
deﬁning F (Z) = log G(Z) one can approximate Eq. (18)
with the zero-order saddle point expansion

(2π)−d/2

dZ exp

ZD

2F (Z) − ˜µ · Z + ˜µ2/2 − Z 2/2
(cid:2)

(cid:3)

≃ C exp

max
Z∈D

h

2F (Z) − ˜µ · Z + ˜µ2/2 − Z 2/2
(cid:0)

(cid:1) i

,

where C is a constant. As a result, within this approxi-
mation, the problem of determining the optimal change
of drift boils down to ﬁnding the vector µ such that

max
Z∈D

2F (Z) − ˜µ · Z + ˜µ2/2 − Z 2/2
(cid:0)

(cid:1)

(19)

is minimum. It is easy to show that this is obtained by
choosing ˜µ⋆ = Z ⋆ where Z ⋆ is the point that solves the
optimization problem

max

F (Z) − Z 2/2
(cid:0)

(cid:1)

,

(20)

or equivalently, for which the payout times the origi-
nal distribution, G(Z)P (Z), is maximum, i.e., Z ⋆ corre-
sponds to the maximum of the optimal sampling density,
Eq. (9). The simplest interpretation of the saddle point
approach is therefore that it approximates the zero vari-
ance distribution by means of a normal density with the
same mode and variance.

The saddle point approach can be expected to be par-
ticularly eﬀective in reducing the variance of the Monte
Carlo estimator whenever the log payout function F (Z)
is close to be linear in the portion of the conﬁguration
space where most of the probability mass of P (Z) lays.
Moreover, GHS have also shown that stratifying [1] the
d-dimensional random vector Z along the optimal µ, pro-
vides a spectacular variance reduction in certain cases
[6, 7]. However, whenever the optimal sampling prob-
ability (9) cannot be accurately represented by a single
Gaussian with the same mode and variance, the saddle
point approximation is less beneﬁcial. In particular, as it

will be also illustrated in Sec. V, this approach turns out
to be less eﬀective whenever the structure of the payout
function G(Z) is such that the optimal sampling distri-
bution (9) has a width which is very diﬀerent from the
one of the original distribution, or is multi-modal.

In the following Section we describe an alternative least
squares strategy that is straightforward to implement and
ﬂexible enough to be applied in a generic Monte Carlo
setting. Indeed, the Least Squares Importance Sampling
(LSIS) is not limited to the determination of the opti-
mal change of drift in a Gaussian model.
Instead, it
can be applied to any Monte Carlo simulation provided
that a reasonable guess of the optimal sampling density
is available. For this reason, in the next Section we will
momentarily leave the Gaussian framework, and we will
describe the rationale of LSIS in a more general setting.

IV. LEAST SQUARES IMPORTANCE
SAMPLING

A practical approach to the search of an eﬀective Im-
portance Sampling distribution can be formulated in
terms of a non-linear optimization problem. To this pur-
pose, let us consider a family of trial probability densi-
ties, ˜Pθ(Z), depending on a set of Nθ real parameters
θ = (θ1, θ2, . . . , θNθ ) . The variance of the estimator cor-
responding to ˜Pθ(Z), Eq. (8), can be written in terms of
the original probability distribution P (Z) as

˜Σ2

θ = EP

Wθ(Z)G2(Z)
(cid:3)

(cid:2)

− EP [G(Z)]2 ,

(21)

with Wθ(Z) = P (Z)/ ˜Pθ(Z). Hence, the optimal Impor-
tance Sampling distribution within the family ˜Pθ(Z) is
the one for which the latter quantity, or equivalently the
second moment (18) or

EP

Wθ(Z)G2(Z)
(cid:3)
(cid:2)

,

is minimum. The crucial observation is that the Monte
Carlo estimator of this quantity,

N

′
p

m2(θ) ≃ 1
N ′
p

Wθ(Zi)1/2G(Zi)
(cid:17)

Xi=1 (cid:16)

2

Zi ∼ P (Z) ,

(22)

(23)

can be interpreted as a non-linear least squares ﬁt of a
set of N ′
p data points (xi, yi) with a function y = fθ(x)
parameterized by θ, with the correspondence yi → 0,
xi → Zi, and fθ(x) → Wθ(Z)1/2G(Z). The latter is a
standard problem of statistical analysis that can be tack-
led with a variety of robust and easily accessible numer-
ical algorithms, as the so-called Levenberg-Marquardt
method [17].

Alternatively, to improve the numerical stability of the
least-squares procedure, it is convenient in some situa-
tions to minimize, instead of (22), the pseudo-variance

Wθ(Z)1/2G(Z) − VT

2

(cid:21)

(cid:17)

S2(θ) = EP (cid:20)(cid:16)
≃ 1
N ′
p

N

′
p

Xi=1 (cid:16)

Wθ(Zi)1/2G(Zi) − VT

(24)

2

(cid:17)

where the constant VT is a guess of the option value.
Indeed, the minimization of (24) is equivalent to the one
of the real variance of the estimator (21) as

S2(θ) = ˜Σ2

θ + (EP [G(Z)] − VT )2 .

(25)

The algorithm for the determination of the optimal
sampling distribution within a certain trial family can
be therefore summarized as it follows:
• Generate a suitable number N ′

p of replications of
the state variables Z according to the original prob-
ability distribution P (Z);

• Choose a trial probability distribution ˜Pθ(Z), and

an initial value of the vector of parameters θ;

• Set xi → Zi, fθ(x) → Wθ(Z)1/2G(Z) and yi → 0
(resp. yi → VT ) and call a least squares ﬁtter, say
LSQ [x, y, fθ(X), θ] , providing the optimal θ = θ⋆
by minimizing the second moment of the estimator
m2(θ), Eq. (23) [resp. S2(θ), Eq. (24)].

Once the optimal parameters θ⋆ have been determined
through the least squares algorithm, one can perform an
ordinary Monte Carlo simulation by sampling the prob-
ability distribution ˜Pθ⋆(Z), and calculating expectation
values according to Eq. (7).

As it will be illustrated with the numerical examples of
Sec. V, this procedure does not add a signiﬁcant overhead
to the simulation, because just a relatively small number
of replications N ′
≪ Np is usually required to determine
p
the optimal parameter ˜θ⋆. This is due to the fact that the
conﬁgurations over which the optimization is performed
are ﬁxed. As a result of this form of correlated sampling
[12], the diﬀerence in the m2(θ)’s for two sets of values of
the parameters being optimized is much more accurately
determined than the values of the m2(θ)’s themselves.
This rather surprising feature is rooted in the fact that
the minimization of Eq. (23) as a means to optimize the
trail density, ˜Pθ(Z), can be justiﬁed in terms of a gen-
uine maximum likelihood criteria [18], and it is therefore

7

FIG. 3: Sampling probability density functions for a straddle
option (30) with r = 0.05, X0 = K = 50 , σ = 0.3, T = 1,
as obtained with LSIS [optimizing just the drift, LSIS(˜µ),
both the drift and the volatility , LSIS(˜µ, ˜σ), and using the
bi-modal trial density (31), LSISbm], and the saddle point
approximation (GHS). The original (13) and the optimal (9)
sampling densities also shown for comparison.

independent on how accurately m2(θ) approximates the
quantity (22).

Clearly, the fact that only a limited number of Monte
Carlo samples is required for the optimization of the trial
density limits the overhead introduced by the LSIS algo-
rithm. This makes LSIS a practical strategy for variance
reduction.

In the following we will demonstrate the eﬀectiveness
of this simple strategy by applying it to a variety of test
cases, and we will compare the present approach with the
ones most recently proposed in the literature [6, 8, 9, 10].

V. NUMERICAL EXAMPLES

A. European Options

We will start by considering European style options.
These are the simplest possible examples of ﬁnancial rel-
evance that allow one to illustrate the LSIS strategy. In
particular, we will consider ﬁrst standard Call and Put
options, written on a single underlying asset, X(t), fol-
lowing the log normal process (14). Here N = M =
L = 1, and ∆t0 = T . The payout function reads as in
Eq. (15) with ¯X → X1 ≡ X(T ), Φ(X) = (X − K)+ and
Φ(X) = (K − X)+ for the Call and the Put, respectively,
and K is the strike price.

In these cases, the probability distribution P (Z) is a
univariate Gaussian distribution, and the option value
(1) involves the integration of a function of a single vari-

able. As discussed in Sec. II, Importance Sampling tech-
niques seek a sampling probability density ˜Pθ(Z) as close
as possible to the optimal sampling distribution, Eq. (9)
(see Figure 1). The simplest choice for ˜Pθ(Z), in this
setting, is a Gaussian distribution of the form (16) (with
d = 1), so that the only parameter θ to optimize is the
drift ˜µ.

The LSIS algorithm described in Sec. IV is particu-
larly straightforward to implement, and involves a pre-
simulation stage in which a set of N ′
p standard normal
random numbers are generated and stored, and a least
squares optimization routine is invoked. As anticipated,
we found that the least squares ﬁtter was able to deter-
mine successfully the optimal ˜µ with as little as N ′
≃ 50
p
Monte Carlo replications, thus making the approach use-
ful in practice.

In Tables I and II we compare the results obtained
with LSIS with the ones obtained by means of the Rob-
bins Monro (RM) adaptive Monte Carlo (as quoted in
Ref. [10]), and the saddle point approach of GHS [6].
Here, as an indicator of the eﬃciency gains introduced
by the diﬀerent strategies of Importance Sampling, we
have deﬁned the variance ratio as

VR =

σ(Crude MC)
σ(IS)

(cid:18)

(cid:19)

2

(26)

where the numerator and denominator are the statistical
errors (for the same number of Monte Carlo paths) of the
Crude and the Importance Sampling estimators, respec-
tively. In particular, for this and the following examples,
we have estimated the uncertainties on the statistical er-
rors, and on the VR’s by performing a standard error
analysis of the outcome of several Monte Carlo simula-
tions for diﬀerent random number seeds.

We found that the diﬀerent methods produce a signi-
ﬁcative and comparable variance reduction. In particu-
lar, as it is intuitive, the change of drift is more eﬀective
for low volatility, and deep in and out of the money op-
tions. In this case, LSIS and GHS optimized trial dis-
tributions ˜P¯µ(Z) are very similar as shown Fig. 1. This
could be expected as, in this case, the optimal Impor-
tance Sampling distribution (9) can be eﬀectively approx-
imated by a Gaussian with the same mode and variance,
so that the GHS approach produces accurate results.

However, the LSIS method is not limited to Impor-
tance Sampling strategies based on a pure change of drift,
and one can easily introduce additional optimization pa-
rameters in the trial density. For instance, in this exam-
ple it makes sense to introduce the sampling volatility,
˜σ,

˜P˜µ,˜σ(Z) = (2π˜σ2)−1/2e−(Z−˜µ)

2

2

/2˜σ

.

(27)

As illustrated in Fig. 1, by adjusting both ˜µ and ˜σ, one
obtains a trial density closer to the optimal one. This
corresponds to an additional variance reduction up to
over one order of magnitude, as shown in Tables I and
II.

8

Another simple example in which the ability to adjust
the width of the sampling distribution proves eﬀective is
the Butterﬂy spread option,
Φ(X) = (X − K1)+ − 2(X − K2)− + (X − K3)+ , (28)

with K1 < K2 < K3.
In this case, a pure change of
drift can only force the expected end point of the sam-
pled paths X(T ) to fall in the money, K1 < X(T ) < K3.
However, for values of the volatility or the maturity large
enough, a signiﬁcative fraction of the sampled paths will
still results in a zero payout. Hence, a pure change of drift
is not very eﬀective in reducing the variance. This is il-
lustrated in Table III. Instead, by quenching the sampled
volatility one can increase the number of paths falling in
the money thus reducing the variance. For instance, in
the example of Table III, for S0 = 50 the saddle point
change of drift is very small, and does not alter the vari-
ance. Instead, by allowing the sampling volatility to vary,
we get ˜µ⋆ ≃ −0.02 and ˜σ⋆ ≃ 0.14, reducing the variance
by more than two orders of magnitude.

P(Z)

35.0

30.0

25.0

20.0

15.0

10.0

5.0

0.0

2.0

1.8

1.7

1.5

1.3

1.2

1.0

0.8

0.7

0.5

0.3

0.2

Z2

0.0

-0.2

-0.3

-0.5

-0.7

-0.8

-1.0

-1.2

-1.3

-1.5

-1.7

-1.8

-2.0

-2.0

2.0

1.0

Z1

0.0

-1.0

FIG. 4: Optimal sampling distribution, Eq. (9), for the Euro-
pean basket Call option (32) for r = 0.05, K = 100, X 0
1 = 100,
X 0

2 = 105, σ1 = σ2 = 0.3, T = 1.

B. Asian Call option

As a second example we consider here the single un-
derlying (L = 1) arithmetic Asian option Eq. (15), with a
Call payout, Φ(Z) = e−rT ( ¯X − K)+, and M observation
dates.

In this case, the calculation of the expectation value
(1) involves a multi-dimensional integral over the prob-
ability distribution (13). However, the implementation
of LSIS is not more diﬃcult than for the European pay-
out. Indeed, the fact that the sample points Zi are in
the present case M -dimensional vectors is practically ir-
relevant for the LSIS procedure. All the least square ﬁt-
ter needs is a method that, given a conﬁguration Zi and
the vector θ, provides the value of the target function
fθ(Zi) = Wθ(Zi)1/2G(Zi).

M
20

σ
0.2

0.3

TABLE VI: Comparison between LSIS, the adaptive Robbins-Monro (RM) method (as quoted in Ref. [10]), for the price of
an Asian Call option (15) on a lognormal asset (14) for diﬀerent values of the volatility σ, and of the strike price K. The
parameters used are r = 0.1, X0 = 50, T = 0.5, and the number of simulated paths is 1,000,000 for Crude MC and LSIS,
800,000 for RM. The uncertainties on the RM variance reductions are rough estimates based on the number of simulated paths.

σ
0.1

0.3

K
40
50
55
40
50
60

Crude MC
Price
10.7820(21)
1.6045(16)
0.04919(29)
10.8284(62)
3.1373(44)
0.3790(16)

LSIS

RM

Price
10.78243(22)
1.60398(61)
0.049204(54)
10.8277(17)
3.1352(15)
0.37861(35)

VR
91(2)
6.9(1)
28.8(5)
13(1)
8.6(1)
20.9(5)

Price
10.73
1.53
0.037
10.77
2.99
0.320

TABLE VII: Comparison between LSIS, the adaptive approach of Su and Fu (SF) (as quoted in Ref. [8]), for the price of a
partial average Asian Call option (15) and (29) on a lognormal asset (14) for diﬀerent values of the volatility σ, and of the
strike price K. The parameters used are r = 0.05, X0 = 100, T = 1.0, M = 365, M0 = 305, and the number of simulated paths
is 1,000,000 for Crude MC, and LSIS, and 50,000 for SF. The uncertainties on the SF variance reductions are rough estimates
based on the number of simulated paths.

LSIS

SF

K
100
110
120
130
140
150
160
170
100
110
120
130
140
150
160
170

Crude MC
Price
9.792(14)
5.413(11)
2.7758(77)
1.3038(52)
0.5861(35)
0.2421(22)
0.1003(14)
0.03761(84)
13.323(21)
9.182(18)
6.1041(15)
4.020(12)
2.5624(98)
1.6410(80)
1.0143(62)
0.6408(50)

Price
9.7816(46)
5.4256(33)
2.7669(20)
1.3096(12)
0.58298(61)
0.24592(30)
0.09973(14)
0.039000(64)
13.3527(65)
9.1564(54)
6.1258(39)
4.0034(31)
2.5769(23)
1.6325(13)
1.02355(90)
0.63681(61)

VR
9.3(1)
11.1(1)
14.8(2)
18.8(1)
33(1)
54(4)
100(8)
172(20)
10.4(5)
11.1(5)
14.8(5)
15.0(5)
18.1(7)
38(1)
47(2)
67(3)

Price
9.747
5.397
2.730
1.284
0.575
0.241
0.0980
0.0380
13.295
9.103
6.059
3.985
2.556
1.603
1.006
0.623

9

VR
58(2)
7.0(1)
6.0(5)
14(1)
9.0(1)
28.0(5)

VR
6.7(3)
8.2(3)
11.0(6)
17.0(4)
25(3)
44(12)
85(20)
173(80)
7(1)
8(1)
10(1)
12(3)
15(2)
22(2)
30(5)
36(6)

In order to compare LSIS with the other approaches
proposed in the literature we have considered a Gaussian
trial density of the form Eq. (16). Here such density
depends on as many parameters, ˜µ = (˜µ0, . . . , ˜µM−1),
as are the sampling dates in the Euler discretization of
the process (12). A typical outcome of the optimized
drift vector produced by the LSIS procedure is shown in
Fig. 2.

1. Comparison with the Saddle Point Approximation

As shown in Table IV, LSIS provides a very eﬀective
variance reduction for the Asian Call options considered,
similar to the one obtained with the approach of GHS.
This could be expected on general grounds as in the
case of the European Call and Put options. Indeed, it
is not diﬃcult to verify that the single asset Asian Call
option generates a single-mode optimal sampling den-

sity Popt(Z) ∝ G(Z)P (Z), with covariance close to one.
Hence, as discussed in the previous Section, the opti-
mal sampling density can be accurately represented by
a Gaussian distribution, and the saddle point method
provides an accurate approximation of the optimal drift
vector. Indeed, as shown Fig. 2, the optimal drift vec-
tors obtained with the LSIS and the GHS approaches
are quite similar, with an overlap of ∼ 0.99 when both
normalized to one.

As anticipated, we found that a few hundreds of Monte
Carlo conﬁgurations and 10-20 iterations of the least
squares ﬁtter, were typically enough to determine the
optimal drift vector in (16) for M ≃ 50, thus making
the overhead of the pre-simulation stage rather limited.
However, as the number of time steps – or more in gen-
eral the number of components of the drift vector – in-
creases, the complexity of the optimization problem in-
creases as well. Nevertheless, as suggested in Ref. [7],
one can signiﬁcantly reduce the computation time asso-
ciated with the optimization stage by approximating the

10

TABLE VIII: Importance Sampling results for the European style straddle (30) obtained by means of the saddle point ap-
proximation (GHS) and LSIS, with the optimization of the drift [LSIS(˜µ)], and the drift and the volatility [LSIS(˜µ, ˜σ)]. The
parameters used are r = 0.05, X0 = K = 50, σ = 0.3, T = 1, and correspond to the probability distributions sketched in Fig. 3.
The number of simulated paths is 1,000,000.

Crude MC
Price
11.803(10)

GHS

.

LSIS(˜µ)

LSIS(˜µ, ˜σ)

Price
11.800(33)

VR
0.10(1)

Price
11.8038(88)

VR
1.30(1)

Price
11.8047(55)

VR
3.00(2)

drift vector with a continuous function parameterized by
a small number of parameters. These are in turn tuned
by the least square algorithm in order to determine an
approximate optimal drift vector. We have found that a
particularly eﬀective realization of this approach is to ap-
proximate the drift vector by a piecewise linear function,
parameterized by its values where it changes slope (the
so-called knot points). For instance, in the present exam-
ples, optimizing over 4 to 8 equally spaced knot points
provides variance reductions practically indistinguishable
from the ones obtained by a full optimization. In addi-
tion, the drift vector generally changes continuously with
the market parameters. As a result, an additional com-
putational saving can be obtained by starting the pre-
simulation from a drift vector optimized for a case with
a similar set of parameters.

As anticipated in Sec. III A, Importance Sampling can
be also naturally combined with Stratiﬁed Sampling by
choosing the optimal drift vector as the stratiﬁcation di-
rection (for further details see Ref.[6]). This, as shown in
Table V, gives rise to a further reduction of the variance,
which can be of several order of magnitudes, depending
on the option parameters, thus resulting in quite remark-
able savings in computational time.

2. Comparison with Adaptive Monte Carlo approaches

It is also interesting to compare the LSIS results with
those obtained by means of the recently proposed adap-
tive Monte Carlo methods brieﬂy discussed in Sec. III A.
As illustrated in Table VI, we found that our approach
achieves variance reductions similar to the ones obtained
with the Robbins-Monro algorithm of Ref.[10]. However,
for the example considered, LSIS appears to perform bet-
ter for small values of the volatility and deep in and out of
the money options. This is particularly remarkable when
considering that the pre-simulation stage required by the
Robbins-Monro algorithm involves sampling a number of
Monte Carlo paths much larger than that required by the
LSIS approach. For instance, in the present example, the
number of iterations quoted in Ref. [10] is 400,000 while
the LSIS results were obtained by sampling just N ′
≃ 400
p
conﬁgurations. In addition, LSIS does not have any ex-
ogenous parameter to be ﬁne tuned in order to achieve an
eﬃcient optimization, thus making the approach easier to
be automated.

Finally, in order to compare with the adaptive Monte
Carlo approach of Su and Fu [8, 9], we have slightly mod-
iﬁed the Asian option example and considered a payout
depending on a partial average

¯X =

1
M − M0

M

Xi=M0

Xi ,

(29)

where M0 is the time step index corresponding to the ﬁrst
observation. The results we have obtained in this case are
reported in Table VII, and show that LSIS generally out-
performs the approach of Ref. [8, 9]. This is expected as
LSIS involves a more general class of sampling distribu-
tion (16) as the change of drift is not constrained to be
uniform along the simulation path.

C. Multi-modal Examples

All the examples considered in the previous Sections
were characterized by a single mode optimal sampling
distribution (9). In these cases, an Importance Sampling
strategy based on the Gaussian trial distributions (16) or
(27) provides good results. In this Section we will con-
sider instead option pricing problems that are character-
ized by multi-modal optimal sampling densities. These
are very common in practice, and typically arise if the
payout function G(Z) is not monotonic, or for claims
written on multiple assets. We will show that in these
cases a simple Importance Sampling strategy based on a
pure change of drift of a Gaussian density proves ineﬀec-
tive. In contrast, LSIS allows one to work with trial den-
sities tailored to the problem at hand, including multi-
modal distributions. As in Section V A, we begin by illus-
trating the eﬀectiveness of LSIS with a simple European
style payout.

1. Straddle

A simple example of a pricing problem characterized by
a multi-modal sampling density is the European straddle:

Φ(X) = (X − K)+ + (K − X)+ .

(30)

As illustrated in Fig. 3, the corresponding optimal sam-
pling distribution, Popt(Z) ∝ G(Z) exp (−Z 2/2), has two

well separated maxima. As a result, saddle point ap-
proaches based on a Gaussian distribution, e.g., centered
on the higher of the two modes, provide a poor approxi-
mation of the optimal sampling density. Indeed, as shown
in Table VIII, the saddle point method increases the vari-
ance with respect to the crude Monte Carlo estimator.
On the contrary, LSIS based on the simple trial density
(16) provides a small shift of the drift towards the higher
mode of the optimal distribution [Fig. 3]. This can be
easily understood. In fact, the best way to approximate
a bi-modal distribution by means of a Gaussian density
is to center the latter around the center of mass of the
former, in this case ˜µ ≃ 0.24. Yet, since the two maxima
of the optimal distribution are well separated, its overlap
with the trial density is still rather poor. As a result,
LSIS based on a trial density of the form (16) produces
only a small variance reduction. Better results can be ob-
tained by adjusting the width of the trial density. Indeed,
as also illustrated in Fig. 3, by increasing the standard
deviation of the sampling density one achieves a better
approximation of the optimal distribution. This leads to
a sizable reduction of the variance of a factor of 3.

An even better ansatz for the optimal density is clearly

represented by a bi-modal trial density of the form

˜P (Z) = (2π)−d/2

wa e−(Z−µa)
h

2

+ wb e−(Z−µb)

2

, (31)

i

where wa + wb = 1 (and d = 1 in this speciﬁc case)
that can be optimized over µa, µb, and wa. The simu-
lation of a density of this form is straightforward as it
simply implies choosing on each Monte Carlo step one
of the two Gaussian components in (31), and sample a
conﬁguration Zi according to it. This can be done by ex-
tracting an auxiliary uniform random number ξ ∈ [0, 1],
and extracting Zi according to the ﬁrst Gaussian com-
ponent if ξ < wa, and according to the second otherwise.
The optimized distribution obtained using this bi-modal
trial density is sketched in Fig. 3, and corresponds to
a further sizable reduction of the variance (Table VIII).
Remarkably, the same form of sampling density (31) can
be used also for Asian style straddles (here d = M , µa
and µb are M -dimensional vectors), and produces a very
eﬀective variance reduction, as illustrated in Table IX.

TABLE IX: Variance Reduction obtained with LSIS for a Eu-
ropean (M = 1), and Asian style (M = 16 and 64) strad-
dle (30) using the bi-modal sampling distribution (31). The
parameters used are r = 0.05, X0 = K = 50, σ = 0.3,
T = 1, and correspond for M = 1 to the probability dis-
tributions sketched in Fig. 3. The number of simulated paths
is 1,000,000.

M
1
16
64

Crude MC
Price
11.803(10)
7.0604(58)
6.8200(55)

LSIS

Price
11.8009(44)
7.0559(26)
6.8163(26)

VR
5.17(5)
4.98(5)
4.47(5)

11

TABLE X: Importance Sampling results for the Asian style
basket option (32) obtained by means of LSIS, using the bi-
modal sampling distribution (31). The parameters used are
r = 0.05, T = 1, X (1)
0 = 105, σ1 = 0.3, σ2 = 0.3,
and correspond (for K = 100 and M = 1) to the probability
distributions sketched in Fig. 4. The number of simulated
paths is 500,000.

0 = 100, X (2)

M
1

16

32

K
90
100
110
90
100
110
90
100
110

Crude MC
Price
34.555(41)
26.621(39)
19.749(36)
24.876(24)
16.428(22)
9.711(19)
24.537(23)
16.082(22)
9.381(18)

LSIS

Price
34.587(14)
26.589(15)
19.776(13)
24.8700(87)
16.4081(81)
9.6918(68)
24.5539(84)
16.0734(82)
9.3752(68)

VR
8.58(7)
6.76(3)
7.7(1)
7.6(1)
7.4(1)
7.8(1)
7.50(5)
7.2(1)
7.0(1)

2. Basket Call Options

Basket options are another very common class of con-
tingent claims that can give rise to multi-modal optimal
distributions. This is illustrated in Fig. 4 for a very sim-
ple European style Call option on the maximum of L = 2
underlying assets following the process (14)

Φ(X) = (max(X1, X2) − K)+ .

(32)

Also in this case, LSIS based on a bi-modal trial density
of the form (31) provides a signiﬁcative variance reduc-
tion that persists when introducing Asian features in the
payout (see Table X). We obtained similar results for
other multi assets options by generalizing the form of
the trial density (31).

VI. CONCLUSIONS

In this paper we have described a simple Importance
Sampling technique based on a least squares minimiza-
tion of straightforward implementation. The result-
ing strategy, dubbed Least Square Importance Sampling
(LSIS), provides an eﬀective variance reduction technique
that lends itself to a variety of applications.

We have presented several numerical examples in a
diﬀusive setting, and we have shown that LSIS, when
restricted to the optimization of the drift of a diﬀusion
process, provides variance reductions similar to those ob-
tained with existing approaches [6, 8, 9, 10]. However,
LSIS is not limited to the determination of the optimal
mean of a Gaussian sampling distribution. As a result, it
outperforms other approaches when the ability to adjust
the width of such distribution, or to sample non-Gaussian
and multi-modal densities, is important to achieve vari-
ance reductions.

The LSIS strategy can be applied to any Monte Carlo
setting provided that a reasonable ansatz for the opti-

mal sampling distribution is available. This makes LSIS
a ﬂexible Importance Sampling approach, that can be
used across a variety of ﬁnancial applications, ranging
from Value at Risk (VaR) estimation, to portfolio credit
risk management. This is currently the object of further
investigations.

discussions, and Paul Glasserman for an enlightening lec-
ture that inspired this work. The opinion and views ex-
pressed in this paper are uniquely those of the author,
and do not necessarily represent those of Credit Suisse
Group.

12

Acknowledgments

It is a pleasure to acknowledge Gabriele Cipriani,
David Shorthouse, and Mark Stedman for stimulating

[1] P. Glasserman, Monte Carlo Methods in Financial Engi-

neering (Springer, New York, 2004).

troduction to Derivative Pricing (Cambridge University
Press, Cambridge, 1996).

[2] J. C. Hull, Options, Futures and Other Derivatives

[16] O. Kallenberg, Foundations of Modern Probability

(Prentice Hall, New Jersey, 2002).
[3] R. Reider (1993), working paper.
[4] P. Boyle, M. Broadie, and P. Glasserman, Journal of Eco-

nomic Dynamics and Control 21, 1257 (1997).

[5] F. Vazquez-Abad and D. Dufresne, in Proceedings of 1998
Winter Simulation Conference, edited by D. Medeiros,
E. Watson, J. Carson, and M. Manivann (IEEE Press,
Washington DC, 1998), pp. 1493–1500.

[6] P. Glasserman, P. Heidelberger, and P. Shahabuddin,

Mathematical Finance 9, 117 (1999).

[7] P. Glasserman, P. Heidelberger, and P. Shahabuddin,

Journal of Derivatives 7, 32 (1999).

[8] Y. Su and M. C. Fu,

in Proceedings of 2000 Winter
Simulation Conference, edited by J. Joines, R. Barton,
K. Kang, and P. Fishwick (IEEE Press, Piscataway NJ,
2000), pp. 587–596.

[9] Y. Su and M. C. Fu, Journal of Computational Finance

[10] B. Arouna, Journal of Computational Finance 7, 1245

[11] P. Glasserman and J. Li, Management Science 51, 1463

5, 27 (2002).

(2003).

(2005).

[12] C. J. Umrigar, K. G. Wilson, and W. Wilkins, Physical

Review Letters 60, 1719 (1988).

(Springer, New York, 1997).

[17] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P.
Flannery, Numerical recipes in C++: the art of scien-
tiﬁc computing (Cambridge University Press, Cambridge,
2002).

[18] D. Bressanini, G. Morosi, and M. Mella, Journal Chem-

ical Physics 116, 5345 (2002).

[19] In the present discussion we will treat the Zi’s as contin-
uous variables, however all the results also apply if some
or all of them can assume only a discrete set of values.
For any of such variable, the symbol R dZi is to be inter-
preted as a sum over the possible outcomes.

[20] In particular, the Monte Carlo integration becomes un-
feasible if the variance of the estimator diverges, giving
rise to the so-called sign-problem instability. Although
this problem is the crux of Monte Carlo simulations in
several branches of the Physical Sciences, see, e.g., S.
Sorella and L. Capriotti, Physical Review B 61, 2599
(2000), this issue does not usually aﬀect ﬁnancial con-
texts.

[21] It is possible to show [17] that, when G(Z) does not have
a deﬁnite sign, the optimal sampling density has the sim-
ilar form Popt =
P (Z)/V , although in this case the
|
optimal variance is not zero.

G(Z)
|

[13] J. Harrison and D. Kreps, Journal of Economic Theory

[22] The use of other discretization schemes does not alter the

20, 381 (1979).

present discussion.

[14] M. Musiela and M. Rutkowski, Martingale Methods in

[23] B. Arouna, private communication.

Financial Modelling (Springer, New York, 2002).

[15] M. Baxter and A. Rennie, Financial Calculus: An In-

