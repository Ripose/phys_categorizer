5
0
0
2
 
r
p
A
 
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
4
1
0
4
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Hausdorﬀ clustering of ﬁnancial time series

Nicolas Basalto a, Roberto Bellotti b,c,d, Francesco De Carlo b,c,
Paolo Facchi b,c, Saverio Pascazio b,c

aInstitute for Advanced Studies at University of Pavia, Italy.
bDipartimento di Fisica, Universit`a di Bari, Italy.
cIstituto Nazionale di Fisica Nucleare, Sezione di Bari, Italy.
dTIRES, Center of Innovative Technologies for Signal Detection and Processing,
Bari, Italy.

Abstract

A clustering procedure, based on the Hausdorﬀ distance, is introduced and tested
on the ﬁnancial time series of the Dow Jones Industrial Average (DJIA) index.

Key words: Econophysics, clustering, Hausdorﬀ metric
PACS: 89.65.Gh

1 Introduction

Clustering consists in grouping a set of objects in classes according to their
degree of “similarity” [1]. This intuitive concept can be deﬁned in a number of
diﬀerent ways, leading in general to diﬀerent partitions. For this reason, it is
clear that a clustering procedure can be profoundly inﬂuenced by the strategy
adopted by the observer and his/her own ideas and preconceptions about the
data set. In this article we will focus on a linkage algorithm, that consists in
merging, at each step, the two clusters with the smallest dissimilarity, starting
from clusters made up of a single element and ending up in a single cluster
collecting all data. Our objective will be to cluster the ﬁnancial time series of
the stocks belonging to the Dow Jones Industrial Average (DJIA) index.

From a mathematical point of view, given a set of objects S ≡ {s}, an al-
location function m : S → {1, 2, . . . , k}, is deﬁned so that m(s) is the class

Email address: nicolas.basalto@unipv.it (Nicolas Basalto).

Preprint submitted to Elsevier Science

2 February 2008

label and k the total number of clusters (which we assume to be ﬁnite for
simplicity). The aim of a clustering procedure is to select, among all possible
allocation functions, the one performing the best partition of the set S into
subsets Gα ≡ {s ∈ S|m(s) = α}, (α = 1, . . . , k), relying on some measure of
similarity.

Clustering algorithms can be classiﬁed in diﬀerent ways according to the crite-
ria used to implement them. The so-called “hierarchical” methods yield nested
partitions, represented by dendrograms [2], in which any cluster can be fur-
ther divided in order to observe its underlying structure. Linkage algorithms,
in particular, are hierarchical. Other non-hierarchical (or “partitional”) meth-
ods are also possible [3,4,5], but will not be discussed here.

2 Hausdorﬀ clustering

In order to cluster a given data set we will use a distance function introduced
by Hausdorﬀ. Given a metric space (S, δ), with metric δ, the distance between
a point a ∈ S and a subset B ⊆ S is naturally given by

˜d(a; B) = inf
b∈B

δ(a, b)

(all subsets are henceforth considered to be non-empty and compact). Given
a subset A ⊆ S, let us deﬁne the function

˜d(A; B) = sup
a∈A

˜d(a; B) = sup
a∈A

inf
b∈B

δ(a, b),

which measures the largest among all distances ˜d(a; B), with a ∈ A. This
function is not symmetric, ˜d(A; B) 6= ˜d(B; A), and therefore is not a bona ﬁde
distance. The Hausdorﬀ distance [6] between two sets A, B ⊆ S is deﬁned as
the largest between the two numbers:

dH(A, B) = max{ ˜d(A; B), ˜d(B; A)}
δ(a, b), sup
b∈B

= max{sup
a∈A

inf
b∈B

δ(a, b)}

inf
a∈A

and is clearly symmetric.

In words, the Hausdorﬀ distance between A and B is the smallest positive
number r, such that every point of A is within distance r of some point of B,
and every point of B is within distance r of some point of A. The meaning of
the Hausdorﬀ distance is best understood by looking at an example, such as

(1)

(2)

(3)

2

Fig. 1. Hausdorﬀ distance between two sets A and B (black thick segments).
r1 = ˜d(B; A), r2 = ˜d(A; B). The Hausdorﬀ distance is equal to the larger radius r2.

that in Fig. 1. We emphasize that the Hausdorﬀ metric relies on the metric δ
on S.

If the data set is ﬁnite and consists of N elements, all distances can be arranged
in a N × N matrix δij and Eq. (3) reads

dH(A, B) = max{max
i∈A

min
j∈B

δij , max
j∈B

min
i∈A

δij},

(4)

which is a very handy expression, as it amounts to ﬁnding the minimum dis-
tance in each row (column) of the distance matrix, then the maximum among
the minima. The two numbers are ﬁnally compared and the largest one is the
Hausdorﬀ distance. This sorting algorithm is easily implemented in a com-
puter.

The Hausdorﬀ distance naturally translates in a linkage algorithm. At the ﬁrst
level each element is a cluster and the Hausdorﬀ distance between any pair of
points reads

dH({i}, {j}) = δij

(5)

and coincides with the underlying metric.

The two elements of S at the shortest distance are joined together in a single
cluster. The Hausdorﬀ distance matrix is recomputed, considering the two
joined elements as a single set. This iterative process goes on until all points
belong to a single ﬁnal cluster.

3

3 Comparison with single and complete linkage

It is interesting to notice that the partitions obtained by the Haudorﬀ linkage
algorithm are intermediate between those obtained by the more commonly
used “single” and “complete” linkage procedures: if A and B are two non
empty subsets of S, the single and complete linkage algorithms make use of
the following similarity indexes

(6)

(7)

(8)

(9)
(10)
(11)

dS(A, B) = inf

δ(a, b),

a∈A,b∈B

dC(A, B) = sup

δ(a, b),

a∈A,b∈B

respectively.

In order to compare these diﬀerent algorithms, it is useful to recall the math-
ematical deﬁnition of distance. Given a set S, a distance (or a metric) δ is a
non-negative application

d : S × S −→ R,

endowed with the following properties, valid ∀x, y ∈ S:

d(x, y) = 0 ⇐⇒ x = y,
d(x, y) = d(y, x),
d(x, y) ≤ d(x, z) + d(y, z),

∀z ∈ S.

Incidentally, notice that symmetry (10), as well as non-negativity, are not
independent assumptions, but easily follow from (9) and the triangular in-
equality (11).

It is not diﬃcult to prove from the very deﬁnition (3) that the Hausdorﬀ dis-
tance between compact and non-empty sets satisﬁes (9)-(11). On the other
hand, (6) and (7) are not distances: the former does not satisfy the triangu-
lar inequality (11), while the latter does not fulﬁl the basic requirement (9),
dC(A, A) 6= 0, for any compact set containing more than one point: in this
sense, it performs a sort of coarse graining over the data set. The Haussdorf
function, being a distance in a strict mathematical sense, enables us to rest
on sound mathematical ground.

The Hausdorﬀ distance has never been used (to the best of our knowledge)
in the context of clustering. It is a useful tool in the analysis of complex sets,
with complicated (and even fractal-like) structures. It is in such a case that

4

IBM: International Business Machines Corp

140

120

100

80

60

40

)
$
(
 
e
c
i
r
p

 

e
r
u
s
o
C

l

1999

2000

2001

2002

Year

Fig. 2. Time evolution of the closure price of a stock value (IBM), for the period
1998-2002.

one expects that Hausdorﬀ behave better than the other methods, since it
relies on rigorous mathematical concepts.

4 Application to Financial Data

We now apply the Hausdorﬀ linkage algorithm to a topic of growing interest:
the analysis of ﬁnancial time series. In particular, we focus on the N = 30
shares composing the DJIA index, collecting the daily closure prices of its
stocks for a period of 5 years (1998-2002). We chose this index for two rea-
sons. First, because these data are easily accessible. The second, and more
important reason is the “quality” (in the sense of reliability) of prices. The
DJIA index, indeed, aggregates the shares of some of the more valuable and
capitalized world corporations, so that their prices are highly contributed by
market makers. This means that we always expect to ﬁnd, even in the worst
possible scenario, a ﬁnancial intermediator (market maker) ready to quote
both bid and oﬀer prices for these assets. For this reason, these shares are
very frequently traded. In ﬁnancial terminology, they are said to be “liquid.”

Figure 2 displays the typical behavior of a stock value (IBM) for the investi-
gated time period. The companies of the DJIA stock market are reported in
Figure 3 (bottom right), together with the corresponding industries. We will
look at the temporal series of the daily logarithm closure price diﬀerences

Yi(t) ≡ ln Pi(t) − ln Pi(t − 1),

(12)

where Pi(t) is the closure price of the ith share at day t. Both Pi and Yi are
very irregular functions of time. In order to quantify the degree of similarity

5

AA

1

AXP

BA

CAT

C

0.37004

0.22458

0.3568

0.3508

1

0.35461

0.41916

0.61247

1

0.32852

0.26917

1

0.33937

1

AA

AXP

BA

CAT

C

Table 1
A part of the matrix of the correlation coeﬃcients cij (14) for the temporal series of
the daily logarithm price diﬀerences of the stocks composing the DJIA index (year
1998). The acronyms (tickers) are explained in Figure 3.

between two time series and use our linkage algorithm we adopt the following
metric function, that quantiﬁes the synchronicity in their time evolution [7,8,9]

dij = q2(1 − cij) ,

where cij are the correlation coeﬃcients computed over the investigated time
period:

(13)

(14)

cij =

hYiYji − hYiihYji

q(hY 2

i i − hYii2)(hY 2

j i − hYji2)

and the brackets denote the average over the time interval of interest (one year
in our case). Table 1 displays a part of the N × N matrix of the correlation
coeﬃcients (year 1998). It is worth stressing that almost all correlation coef-
ﬁcients are positive, with values not too close to 1, thus conﬁrming that, in
many cases, stocks belonging to the same market do not move independently
from each other, but rather share a similar temporal behavior. The distance
(13) is a proper metric in the “parent” space, ranging from 0 for perfectly
correlated series (cij = +1) to 2 for anticorrelated stocks (cij = −1). (The
representative points lie therefore on a hypersphere.)

5 Results and Discussion

Figure 3 shows the results of our analysis based on the Hausdorﬀ ansatz.
Rather than showing the dendrograms, we prefer to give a pictorial represen-
tation of the evolution of the stocks by using bubbles to represent clusters and
arrows to represent the movements of the stocks. Some innermost subclusters
are indicated with a dashed bubble and full (dashed) arrows denote future

6

Alcoa Inc.
AA
Boeing
BA
Caterpillar
CAT
Walt Disney
DIS
General Electrics
GE
Home Depot
HD
Hewlett-Packard
HPQ
INTC Intel Corporation
JNJ
KO
MMM Minnesota Mining
MRK Merck & Co.
Procter & Gamble
PG
T
AT&T
WMT Wal-Mart Stores

Basic Materials AXP
C
Capital Goods
DD
Capital Goods
Services
EK
Conglomerates GM
Services
Technology
Technology
Johnson & Johnson Healthcare
Coca Cola Inc.

American Express Co. Financial
Financial
Citigroup
Basic Materials
DuPont
Consumer C.
Eastman Kodak
Consumer C.
General Motors
Honeywell Intl.
Capital Goods
HON
Intl. Business Machine Technology
IBM
IP
Intl. Paper
JPM JP Morgan Chase
Consumer N.C. MCD McDonalds Corp.
Conglomerates MO
Healthcare
Consumer N.C.
Services
Services

Basic Materials
Financial
Services
Consumer N.C.
Technology
Services
Conglomerates
Energy

MSFT Microsoft
SBC
UTX
XOM Exxon Mobil

SBC Communications
United Technology

Philip Morris

Fig. 3. Clusters obtained by analyzing the daily logarithm closure price diﬀerence
time series during 1998-2002. The innermost subclusters are indicated with a dashed
bubble. Dashed arrows = past; full arrows = future. The position of the points rep-
resenting the stocks is not directly related to the distance matrix (13) and has no
eﬀective “spatial” meaning: the pictorial representation simply reﬂects the aggrega-
tion of points and subclusters into larger clusters. Bottom right: acronyms (tickers)
of the stocks and related industries (C. = Cyclical; N.C. = Non-Cyclical; Intl. =
International)

(past) movements. A small “exploding” star represents a bubble/cluster that
disappears.

It is very interesting and challenging to try and analyze, from a mere economic
viewpoint, some of the movements in the graphs, in order to catch some “a
posteriori” hints about the dynamics of the stocks. At ﬁrst sight, one clearly
recognizes that some of the clusters correspond to homogeneous groups of
companies belonging to the same industry: this is the case of the ﬁnancial ser-
vices ﬁrms {AXP, JPM C}, retail companies {HD, WMT}, companies dealing
with basic materials (AA, IP, DD), the technological core {IBM, INTC, MSFT,

7

HPQ} and the health care ﬁrms {JNJ, MRK}.

Moreover, one observes a large super-cluster made up of 10-15 stocks (ﬁnancial,
conglomerates, services, capital goods), containing some homogenous subclus-
ters, which is more or less stable during the whole 5-year period investigated.

It is worth stressing, between 1998 and 1999, the migration of the hi-tech
companies {IBM, INTC, MSFT} from this cluster. At the end of these two
years, they end up forming a separated cluster with HPQ, that remains stable
for all the following period. As is well known, 1999 is the year when the
high-tech bubble started to grow up. Even more interesting is the “path” of
Disney. During 1998 it is perceived to be linked to HP, which was (and still is)
its favorite supplier of hardware. Then, during the following years, it remains
more or less single, until, between 2001 and 2002, it rejoins HP into the high-
tech core. This evolution can probably be explained by remembering Disney’s
strategic eﬀorts to increase its Media Network segment, that consisted also in
a series of acquisitions (the last two: Fox Family Worldwide Inc. and Baby
Einstein Co).

We emphasize that these remarks are not an input of our analysis: our clus-
tering algorithm is purely mathematical, and no genuinely “economical” infor-
mation (e.g., on industrial homogeneity) was used at the outset. In this sense
the position and movements of the stocks in the ﬁgures are implied from the
market itself.

The deﬁnition of the mutual positioning of companies can have an immediate
pertinence in a matter of great interest for ﬁnancial institutions: the portfolio
optimization. In a few words (and without entering into complex matters),
portfolio theory suggests that in order to minimize the risk involved in a
ﬁnancial investment, one should diversify among diﬀerent assets by choosing
those stocks whose price time evolutions are as diverse as possible (it is never
safe to put all the eggs into a single basket). Moreover, this strategy must
be continuously updated, by changing weights and components, in order to
follow the market evolution. In the framework we presented, by investigating
the shares’ behavior and tracking the evolution of their mutual interactions, a
ﬁrst, crude portfolio-optimization rule that emerges would be: choose stocks
belonging to clusters that are as “distant” as possible from each other.

In conclusion, we have introduced a novel clustering procedure based on the
Hausdorﬀ distance between sets. This genuinely mathematical method was
used to investigate the time evolution of the stocks belonging to the DJIA
index. We found the resulting partitions through the 5-year period investigated
to be signiﬁcant from an economical viewpoint and suited to a meaningful a
posteriori analysis and interpretation. We believe that this technique is able to
extract relevant information from the raw market data and yield meaningful

8

hints for the investigation of the mutual time evolution of the stocks. For the
same reasons this procedure could be implemented as the ﬁrst step towards
an evolved portfolio selection and optimization procedure.

Acknowledgements. We thank Sabrina Diomede for a discussion and a per-
tinent remark.

References

San Diego, 1990).

New York, 1988).

[1] K. Fukunaga, Introduction to Statistical Pattern Recognition (Academic Press,

[2] A. K. Jain and R. C. Dubes, Algorithms for Clustering Data (Prentice Hall,

[3] A. Gersho and R. M. Gray, Vector Quantization and Signal Processing (Kluwer

Academic Publisher, Boston, 1992).

[4] R. O. Duda, P. E. Hart and D. G. Stork, Pattern Classiﬁcation (John Wiley &

Sons, New York, 2002).

[5] T. Hofmann and J. M. Buhmann, Pairwise Data Clustering by Deterministic
Annealing, IEEE Transaction on Pattern Analysis and Machine Intelligence,
19, 1 (1997).

[6] F. Hausdorﬀ, Grundz¨uge der Mengenlehre

(von Veit, Leipzig, 1914).

[Republished as Set Theory, 5th ed. (Chelsea, New York, 2001).]

[7] R. N. Mantegna, Eur. Phys. J. B 11, 193 (1999).

[8] R. N. Mantegna and H. E. Stanley, Introduction to Econophysics (Cambridge

[9] M. Bernaschi, L. Grilli and D. Vergni, Physica A 308, 381 (2002); L. Grilli,

University Press, 2000).

Physica A 332, 441 (2004).

9

