7
0
0
2
 
n
a
J
 
1
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
0
4
1
1
0
7
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Agent-based Models of Financial Markets
E. Samanidou1, E. Zschischang2, D. Stauﬀer3 , and T. Lux4

1 Deutsche Bundesbank, Referent Bankgesch¨aftliche Pr¨ufungen, Berliner Allee

40,D-40212 D¨usseldorf

2 HSH Nord Bank, Portfolio Mngmt. & Inv., Martensdamm 6, D-24103 Kiel
3 Institute for Theoretical Physics, Cologne University, D-50923 K¨oln
4 Department of Economics, University of Kiel, Olshausenstrasse 40, D-24118

Kiel

Abstract

This review deals with several microscopic (“agent-based”) models
of ﬁnancial markets which have been studied by economists and physi-
cists over the last decade: Kim-Markowitz, Levy-Levy-Solomon, Cont-
Bouchaud, Solomon-Weisbuch, Lux-Marchesi, Donangelo-Sneppen and
Solomon-Levy-Huang. After an overview of simulation approaches
in ﬁnancial economics, we ﬁrst give a summary of the Donangelo-
Sneppen model of monetary exchange and compare it with related
models in economics literature. Our selective review then outlines
the main ingredients of some inﬂuential early models of multi-agent
dynamics in ﬁnancial markets (Kim-Markowitz, Levy-Levy-Solomon).
As will be seen, these contributions draw their inspiration from the
complex appearance of investors’ interactions in real-life markets. Their
main aim is to reproduce (and, thereby, provide possible explana-
tions) for the spectacular bubbles and crashes seen in certain histori-
cal episodes, but they lack (like almost all the work before 1998 or so)
a perspective in terms of the universal statistical features of ﬁnancial
time series. In fact, awareness of a set of such regularities (power-law
tails of the distribution of returns, temporal scaling of volatility) only
gradually appeared over the nineties. With the more precise descrip-
tion of the formerly relatively vague characteristics ( e.g. moving from
the notion of fat tails to the more concrete one of a power-law with
index around three), it became clear that ﬁnancial markets dynamics
give rise to some kind of universal scaling laws. Showing similarities
with scaling laws for other systems with many interacting sub-units,
an exploration of ﬁnancial markets as multi-agent systems appeared to
be a natural consequence. This topic was pursued by quite a number
of contributions appearing in both the physics and economics liter-
ature since the late nineties. From the wealth of diﬀerent ﬂavors of
multi-agent models that have appeared by now, we discuss the Cont-
Bouchaud, Solomon-Levy-Huang and Lux-Marchesi models. Open re-
search questions are discussed in our concluding section.

1

1 Introduction

Physicists not only know everything, they also know everything better. This indis-
putable dogma does not exclude, however, that some economists published work
similar to what physicists now celebrate as “econophysics”, only much earlier, like
Nobel laureate Stigler [181] (which was not exactly agent based; nor are all econo-
physics models agent-based). Are econophysicists like Christopher Columbus, re-
discovering something which others had found earlier, and also getting things some-
what wrong, but nevertheless changing human history? As the team of authors
of this survey collects scientists from both disciplines, we do not attempt to give
a deﬁnite answer to this question, but simply review some inﬂuential models by
both physicists and economists, to allow a fair comparison. Long ago, according
to [94], economists like Walras and Pareto were inspired by Newtonian mechanics.
Stylized facts is the economist’s name for universal properties of markets, in-
dependent of whether we look at New York, Tokyo, or Frankfurt, or whether we
are concerned with share markets, foreign exchange markets or derivative markets.
The following is a collection of those “stylized facts” that are now almost univer-
sally accepted among economists and physicists: (i) There is widespread agreement
that we cannot predict whether the price tomorrow will go up or down, on the
base of past price trends or other current information. (ii) If today the market
had been very volatile, then the probability for observing a large change (positive
or negative) tomorrow is also higher than on average (volatility clustering). (iii)
The probability to have a large change in the market, by at least x%, decays with
a power law in 1/x. Fact (iii) has ﬁrst been discovered by Mandelbrot [138] who
proposed the Levy stable model for ﬁnancial returns. Over the recent years, the
majority opinion (see [196, 72] for dissent) among researchers in the ﬁeld has, how-
ever, converged to the view that the tails of the cumulative distribution of returns
are characterized by a power-law with exponent around 3. The underlying data
would, hence, possess ﬁnite variance in contradiction to the Levy stable model.
(iv) The q-th moments of the distribution of price changes are multifractal, i.e.,
their exponent is not a linear function of this index q (a rather new observation).
Facts (i) to (iii) can be found in surveys on the econometrics of ﬁnancial markets,
cf. de Vries [189] and Pagan [148]. Fact (iv) has been ﬁrst partially documented
in Ding et al.
[61] and has meanwhile also obtained the status of an universal
feature of all markets in the empirical ﬁnance literature (Lobato and Savin [125]).
Similar research on multiscaling (multifractality), albeit with diﬀerent analytical
tools, was conducted in numerous econophysics papers, starting with Mandelbrot
et al. [139], Vandewalle and Ausloos [186].

Although research in agent-based models started from a diverse range of inten-
tions (see below), much of the physics-inspired literature considered in this survey

2

aims at behavioral explanations of the above stylized facts. The more successful
ones, in fact, generate even numerically accurate and robust scaling exponents. It
appears worthwhile to point out that with these empirically relevant predictions,
the microscopic models meet Friedman’s [78] methodological request that a theory
“(...) is to be judged by its predictive power for the class of phenomena which it
is intended to explain”. Despite this conformity with the classical methodological
premise to which most economists pay homage, one might ﬁnd these models being
criticized sometimes because of their lack of “microfoundations”. The request of
microfoundations in this critique aims at a full-ﬂechted intertemporal optimization
as the base of agents’ economic activities which mostly is absent in agent-based
models. Hardcore proponents of such a microfoundation would dismiss any theo-
retical approach that falls short of complete optimization even if it yields successful
preditions. Needless to say that the proponents of agent-based models have a dif-
ferent view and the present authors would in particular stress the importance of
interaction as an alternative facet of microfoundations of macroscopic phenomena
in economics. A dogmatic dismissal of successful theories because of their violation
of modeling principles imposed a priori would be hard to square with Friedman’s
methodological premise to which the same economists would mostly subscribe.

After the pioneering computer simulations of market models from economists
like Stigler [181], numerous such models were published in the physics literature
since 1992. We concentrate here on those econophysics models which have raised
enough interest to be also investigated by others than the original authors them-
selves. These include the models of (i) Kim and Markowitz [105], of (ii) Levy, Levy,
Solomon [123, 117, 118, 122, 121, 119, 120], of (iii) Solomon, Levy and Huang [91],
of (iv) Cont and Bouchaud [56], of (v) Solomon and Weisbuch [170] (see also [171]),
and of (vi) Lux and Marchesi [133, 134], all conceived as models for modern (ﬁ-
nancial) markets, as well as the model for ancient barter and self-organization of
monetary exchange by Donangelo and Sneppen [63] (see also [62, 22, 23]. (Kim and
Markowitz are not econophysicists but used similar methods earlier; Markowitz got
a Nobel prize for portfolio theory but invented his own computer language decades
earlier [136].)

We start with the latter one since it (in its literal interpretation) refers to
prehistoric times. We neglect the now (in physics circles) widespread Minority
Games, as they arose from the question when best to visit the El Farol bar in
Santa Fe to avoid overcrowding. The weighted majority of the present authors
prefers to drink experimentally instead of simulating drinks, and thus we leave
these minority games to another review [59]. While according to the late Nobel
laureate Friedman an ultimate aim of models should be to predict the future, we
concentrate here on the easier task of explaining the past; a model which fails to
describe past reality is unlikely to make reliable predictions.

3

2 Overview

Research applying microscopic simulations in economics and ﬁnance stems from
several sources. 1 First, a number of authors in the economics “mainstream” have
resorted to some type of microscopic simulation in the course of their work on cer-
tain economic problems and models. The framework of Kim and Markowitz [105],
explored in detail in section 4, may serve as a prominent example. Like many
economists of that time, the authors were interested in explaining the sudden drop
of the U.S. stock market on 17th October 1987. A widespread explanation for
this event was the automatic overreaction of computer-based “dynamic hedging”
strategies that had become popular strategies of institutional investors in the years
before. However, models including the market interactions of many investors fol-
lowing such strategies are clearly hard to solve in an analytical manner. Therefore,
Kim and Markowitz decided to investigate the destabilizing potential of dynamic
hedging strategies via Monte Carlo simulations of a relatively complicated model
of price formation in an “artiﬁcial” ﬁnancial market (cf. Markowitz [141]). They
were, however, not the ﬁrst to rely on simulations of economic processes. Dur-
ing the ﬁfties, the well-known economist A. W. Phillips -who ﬁrst recovered the
so-called Phillips curve (i.e., the inverse relationship between unemployment and
inﬂation rate)- used a hydraulic machine for simulation of macroeconomic pro-
cesses (Phillips [150], see also [146]). Even earlier, we can ﬁnd simulations via
electronic circuits published in economics journals (Morehouse et al. [143]).

However, the ﬁrst simple Monte Carlo simulation of a ﬁnancial market ap-
peared in Stigler [181], who generated trading orders as random variables. Two
decades later, simulations of diﬀerent trading mechanisms played an important role
in the literature on the “microstructure” of ﬁnancial markets (Cohen et al. [54]).
The interest here was mainly in questions of eﬃciency and stability of diﬀerent
forms of market organization and regulation as well as the impact of introducing
computer-assisted trading. Like in the approach of Kim and Markowitz a few years
later, the sheer complexity of the models, because of the aim to reproduce many
features of real-life market, necessitated a simulation approach. Interestingly, the
microstructure literature later moved on to other questions, namely, analysis of
asymmetric information among traders. Luckily, Bayesian learning methods al-
lowed to tackle large classes of asymmetric information models in a rigorous math-
ematical manner. As a consequence, the leading textbook of the nineties, “Market
Microstructure Theory” by O’Hara [147], only reviews theoretical work and lacks
any reference to microscopic simulations.

1An inspiring source from a ﬁeld outside economics were the microscopic models of
social segregation and related social phenomena by Schelling ([160], [161]). Physicists
might recognize its dynamics as a variant of the Ising model.

4

Of course, it was only a matter of time, until models became so complicated
that they could not be solved analytically anymore and had to be supported by nu-
merical analysis. In the asymmetric information literature, interesting recent con-
tributions coming close to microscopic simulations deal with learning in ﬁnancial
markets (de Fontnouvelle [75], Routledge [156, 157]). Using diﬀerent variants of
adaptive learning mechanisms, these authors study how agents learn to use signals
about future market prices and how to make inferences from these signals. The key
interest is in whether or not the learning dynamics converges to a time-invariant
equilibrium that would obtain under “rational” (i.e., correct) expectations.

With its focus on the extraction of information from imperfect signals by fully
rational or learning investors, the dominant branch of models in ﬁnancial economics
neglected some of the most striking observations in real ﬁnancial markets. Namely,
there was no role at all in these models for features like chartist strategies (i.e.,
strategies looking for patterns in the plots of past prices) or herd behavior among
In some sense, all traders in traditional microstructure models behave
traders.
like fundamentalists in that they try to infer the correct “fundamental” value
of an asset from the limited amount of information they have. However, the
existence of both chartists and fundamentalists in real markets is too obvious
to be neglected and a long tradition of modeling the interaction of these two
types of traders exists in economics literature.
In fact, we can ﬁnd interesting
papers on this subject back in the ﬁfties (Baumol [27]) showing the destabilizing
potential of chartist strategies in a rigorous analytical analysis. The chartist versus
fundamentalist topic was later dropped because of the seeming lack of “rationality”
of agents’ behavior in these models, that means, the apparent ad-hoc nature of the
description of individual behavior together with Friedman’s [78] argument that
irrational traders should be wiped out due to their incurred losses. While this
argument has been often repeated in the economics literature, it is interesting
to note that quite a few authors almost immediately oﬀered counterexamples to
Friedman’s assertion [27] [104]. Nevertheless, we can only ﬁnd a few contributions
to this strand of literature in the seventies and eighties (Zeeman [202], Beja and
Goldman [28]) and as of the early nineties starting with Day and Huang [58] the
chartists-fundamentalists interaction regained its place as an important research
topic. The literature of the nineties has an abundant diversity of interacting agent
models incorporating these features in one or the other way. An early application
to foreign exchange markets is Frankel and Froot [76, 77] who combine a standard
monetary model of open economy macroeconomics with a chartist-fundamentalist
approach to expectation formation (replacing the usual assumption of “rational”
expectations in earlier models). Their aim is to provide a possible explanation
of the well-known episode of the dollar bubble over the ﬁrst half of the eighties.
They show that a deviation from the fundamental value can set into motion a

5

self-reinforcing interplay between forecasts and actual development: the initial
deviation between price and fundamental value will trigger the switch of some
agents from fundamentalist to chartist behavior. However, the more the market
composition changes in favor of the chartist group, the less pressure will exist
for prices to revert to their fundamental anchor values. Even laymen far from
economic theory or computer simulations may have learned from the information
technology bubble which burst in spring 2000, that not everything is fully rational
in real markets.

An important subsequent variation on Frankel and Froot’s theme is the more
elaborate model by DeGrauwe et al. [60] who show that this type of dynamics can
lead to chaotic behavior of exchange rates. Their model is one of the ﬁrst able to
explain some stylized facts other than the mere deviation from the fundamental
value. In particular, they show that their chaotic dynamics is hard to distinguish
from a pure random walk process and that it helps to explain the forward pre-
mium puzzle (the ﬁnding, that forward rates are a poor and biased predictor for
subsequent exchange rate movements).

Chaotic dynamics derived from the interaction of agents with diﬀerent pre-
diction functions for future price movements are the topic of a comprehensive
research project on “adaptive belief systems” starting with Brock and Hommes
[37] and extended in Brock and Hommes [36, 38, 39], Gaunersdorfer [79], Gauners-
dorfer and Hommes [80], Gaunersdorfer et al. [81], and Chiarella et al. [52] (see
also Hommes [88] for a review). While the early papers of this literature are mainly
concerned with various bifurcation routes of chaotic attractors in such systems, the
recent papers by Gaunersdorfer and Hommes [80] and Gaunersdorfer et al.
[81]
are concerned with a possible mechanism for volatility clustering emerging from
this theoretical set-up. They show that co-existence of diﬀerent attractors (e.g.,
a ﬁxed point and a cycle or chaotic attractor) in a deterministic dynamics will
lead to repeated switches between these attractors when small amounts of noise
are introduced. Since diﬀerent attractors are characterized by diﬀerent degrees of
volatility of prices, their varying inﬂuence on the overall time series generates a
perplexingly realistic picture of switches of the market from tranquil to volatile
phases and vice versa. Gaunersdorfer and Hommes [80] show that estimates of
GARCH models can produce quite similar results as with empirical data.

The adaptive belief dynamics has agents switching between predictors accord-
ing to their past performance. A group of alternative learning models have used
modern computer-learning techniques as models of human adaptation. The best-
known variant in the context of ﬁnancial markets is surely the Santa Fe Artiﬁcial
Stock Market (Arthur et al. [20], LeBaron et al. [116], Palmer et al. [149]),the au-
thors of which included a statistical physicist. In this model, traders are equipped
with a set of classiﬁers basically consisting of simple chartist and fundamentalist

6

rules. Particular forecasts of future returns are connected with certain combina-
tions of classiﬁers. Classiﬁers and forecasts are subjected to genetic operations
(selection, cross-over, mutation). Over time, successful combination of rules (clas-
siﬁers) should be maintained, whereas poor ones should be skipped in favor of
better ones. The set-up of this and similar models is notably diﬀerent from most
other applications of machine learning techniques: whereas usually classiﬁer sys-
tems, genetic programming, and neural networks are used to recover regularities
in data sets that are independent from their own learning activity, the artiﬁcial
ﬁnancial market application deals with interacting agents, who naturally inﬂuence
the performance of each others’ attempt at learning the market’s rules. The main
ﬁnding of the early work at the Santa Fe Institute was that the dominance of
either chartist or fundamentalist classiﬁers depends on the frequency of activa-
tion of the genetic operations. With more frequent activation, chartist behavior
was found to be dominating. LeBaron et al. [116] showed that the model repro-
duces some empirical features like leptokurtosis of returns and correlation between
volume and volatility. Other artiﬁcial markets include Chen and Yeh [50, 51],
who instead of classiﬁers systems use genetic programs as evolving models of their
agents and also can show consistency of simulated data with some empirical ﬁnd-
ings. Cincotti et al. [53] construct a more general framework that is designed to
accommodate various learning devices. Related research using genetic algorithm
learning in prominent economic models can be found in Arifovic [15], Arifovic and
Masson [17], Dawid [57], Szpiro [182], Lux and Schornstein [135] and Georges [82].
Le Baron [114, 115] has models closely related to the SFI model, but with learning
via neural networks and the interesting addition of variable memory length of the
agents (cf. the Levy-Levy-Solomon model reviewed in section 5).

Another strand of economic literature proposed to cope with the diversity of
behavioral variants using a statistical approach cf. Champernowne and Cowell
[46], Kirman [107], Aoki [10, 12], Ramsey [154], Lux [127], Foley [74] and Kaizoji
[100, 101, 102]. Only part of this work is concerned with ﬁnancial applications. A
wealth of applications of statistical physics tools to other branches of economics
can be found in Aoki’s books [10, 12, 14].

As concerns ﬁnance, perhaps the ﬁrst attempt at a microscopic approach with
stochastic features guided by work in statistical physics is Landes and Loistl [113].
Later work includes Youssefmir et al. [201], who reconsider the destabilizing po-
tential of trend-following behavior, and Kirman [106] combining the statistical
modeling of herding among speculators with an expectation formation `a la Frankel
and Froot. Similarly, Farmer and Joshi [73] reconsider the impact of several fre-
quently used trading strategies in price formation, and Carvalho [42] shows that
in a particular simpliﬁed variant of their model, emergence of a power-law for
extreme returns can be rigorously demonstrated. Another highly relevant contri-

7

bution is Aoki [13] who deals with a stochastic framework for market participation
with inﬁnitely many strategies or trading rules. Deriving the partition vector (the
number of types or clusters of agents) from a rather general speciﬁcation of the
entry and exit dynamics, he shows that often the sum of the fractions of agents in
the two largest groups will be close to 1. This may provide a theoretical rationale
for the conﬁnement to two trader groups in many models of speculative dynamics.
Another example of a statistical approach towards interacting agent dynamics
in ﬁnance is the work by Lux and Marchesi, reviewed below (section 9). The latter
group of models is, in fact, not too far from those proposed in the physics litera-
ture. Prominent early examples are the threshold dynamics (in the form of trigger
values for agents’ buy or sell decisions) by Takayasu et al.
[183] and Bak et al.
[24]. Their analysis is also concerned with scaling behavior of the resulting price
dynamics and reports some interesting features. A somewhat related model lead-
ing to intermittent bursts of activity is Ponzi and Aizawa [152]. Later additions to
that literature include the Cont-Bouchaud percolation model (reviewed in section
7), and related lattice-based set-ups by Iori [96] and Bornholdt [33]. Interestingly,
contributions in this vein have recently also been applied to other ﬁnancial phe-
nomenon like contagion of bankruptcies and systemic risk in the inter-bank lending
system (Heymann et al. [87], Iori and Jafarey [97], Aleksiejuk and Holyst [2]).

3 The Dynamics of Monetary Exchange

Before money was invented, exchange of goods would have required barter between
agents with coincident endowments and wants. However, at a more advanced level
of division of labor, one may trade by getting something one does already possess
but which, as judged from past experience, one will be able to sell later easily to
others. (The Latin word pecunia for money comes from pecus = cattle.) Donangelo
and Sneppen [63] in this sense started with traders who initially have a random
endowment of products. They then try to ﬁll the gaps in their inventories by
bartering with other traders, and keep in mind how often some speciﬁc product
was asked from them. In the case a trader has something to sell but already has
the product which the partner oﬀers for barter, the ﬁrst trader may opt to get a
product already in his/her inventory. This is done with a probability proportional
to the number of times this product was asked from this trader in recent times,
and this product then plays the role of money: we cannot eat the money we earn,
but we hope to buy food from it later.

For a suitable range of the number of units per trader and the number of dif-
ferentiated products available, traders have enough holes in their inventories to
barter, but after some time also trades involving money (in the above sense) play

8

an important role; and sometimes no trade at all is possible in an encounter of two
randomly selected traders. Which product evolves as the most desired “money”
thus depends on the random dynamics of the market, without outside interfer-
ence and without any special property of that product at the beginning. This
result conforms to physics ideas that “everything” can be described by random-
ness, whether it is Boltzmann statistics for thermodynamics, the built-up of social
hierarchies [32], or the value of the European currency. Economists may regard
this view as over-simpliﬁed.

For one variant of the model, the time-dependence could be quantiﬁed: A
stationary state is reached if every trader had several chances to trade with every
possible other trader. The distribution of times for which one currency stays on
top, then appears to follow a stretched exponential [179]. Other models for the
“statistical mechanics of money” are surveyed in [85].

From the economists’ point of view, the informational content of some of these
studies is somewhat questionable as there are practically no measurements of the
corresponding quantities in real economies. It is nevertheless interesting to note
that quite similar models have been brought up by economists some time ago.
Looking up contributions like the work by Jones [99] or the seminal paper by Kiy-
otaki and Wright [108], one ﬁnds almost the same structure as in the Donangelo
and Sneppen approach. This is not too surprising insofar as - although Donangelo
and Sneppen do not quote the rich literature that emerged from Kiyotaki’s and
Wright’s search model - their work can, in fact, be traced back to these sources.
A careful reading reveals that they draw their inspiration from an earlier paper
in the physics literature, Yasutomi [198], who studied a model along the lines of
Kiyotaki and Wright. It might have been useful to consult the by now volumi-
nous literature on search-equilibrium models in economics rather than start from
scratch with a similar pursuit. Be that is it may, the style of analysis in the early
papers by economists was clearly diﬀerent from that of Donangelo and Sneppen.
Following the then prevalent style of reasoning in their subject they were theoreti-
cal investigations into the nature of equilibria in an economy with a large number
of goods rather than truely dynamic model of the emergence of money. The ques-
tion pursued was under what conditions one would ﬁnd a “monetary” equilibrium
in which one of the available goods emerges as a medium of exchange and under
what conditions the economy remains stuck in a situation of barter trade. Like in
many other areas in economics, the demonstration of existence of multiple equi-
libria (barter vs. monetary equilibrium, as well as diﬀerent monetary equilibria)
pointed to the necessity of investigating out-of-equilibrium dynamics.

To give the reader a feeling of the typical approach pursued in economics, we
give a short sketch of the basic ingredients of the seminal Kiyotaki and Wright
model that has stimulated a whole branch of recent economics literature. The

9

set-up by Kiyotaki and Wright is, in fact, more that of an example than a gen-
eral model of a multi-good economy. In particular, it is assumed that there are
three commodities in the economy which are called goods 1, 2, and 3. There
is also an inﬁnite number of individuals who are specialized in both production
and consumption: type i (i = 1, 2, 3) agents derive pleasure (utility) only from
consumption of good i, and are able to produce only good i′
6= i. A typical ex-
ample used in many of the pertinent contributions has the following structure of

consumption and production:

1 2 3
i
i′ 2 3 1

.

This implies that there is no double “coincidence of wants” in the economy.
Therefore, intermediate trading of goods by agents who do not desire them as
consumption goods is required for the satisfaction of the need of these agents. It
is furthermore assumed that in every period there is a random matching process
that assigns every agent to a pair with one other agent within the economy. Pairs
of agents then have the chance to trade with each other (exchange their goods).
In the theoretical papers on this subject, the focus is on the detection and char-
acterization of steady state Nash equilibria: sets of trading strategies of each type
of agents together with the steady state distribution of goods resulting from these
strategies, so that each individual maximizes its expected utility under full infor-
mation (rational expectations) about the strategies pursued by other individuals.
There are also storage costs per period for goods that are not consumed by their
owners. The distribution of both the instantaneous utilities derived from consump-
tion and the storage costs are crucial for the types of Nash equilibria that exist in
this model. Those goods with lower storage costs are, then, more likely to emerge
as ”monneys” due to their more convenient properties (e.g.
shells rather than
pigs). A particular interesting situation is co-existence of so-called “fundamental”
and “speculative” equilibria. In the former, only goods with lower storage costs are
accepted by the agents (and, hence, they can be said to concentrate on fundamen-
tals in their trading decisions) while in the latter case also some low-storage costs
are traded against high-storage commodities. The motivation for this at ﬁrst view
unattractive exchange is higher marketability of the high-cost good. Accepting
high-storage costs in the hope of higher chances to exchange these goods against
their preferred one, the agents could be said to act out of a speculative motivation.
This second case is the more interesting one as it corresponds to the “emergence of
money”: certain goods are not traded because of their intrinsic values, but purely
because they are accepted by other agents. To solve for steady state equilibria
requires to consider the development of expected life time utility for each group of
agents:

10

E

∞

Xt=0

βt[I u

i (t)Ui − I D

i′ (t)Di − I C

ij (t)cij ]

(1)

where Ui is instantaneous utility from consumption, Di instantaneous disutility
from production (i.e., production costs), and cij the storage costs of good j for
type i. β < 1 is the discount factor and I u
ij are indicator functions
assuming the value 1 at any period t in which consumption, production or exchange
take place and 0 otherwise. Bellman’s approach to dynamic programming allows
to express this problem in terms of value functions of certain states. For example,

i and I c

i , I D

Vi(j) = −cij + max βE[Vi(j′)|j]

(2)

6= i and j′

could be used to denote the value for an individual of group i to currently own one
unit of good j. The value, Vi(j), of this scenario consists of an instantaneous disu-
tility, −cij, the negative storage costs incurred by this agent plus the discounted
value of the expected change of its situation in the next period, E[Vi(j′)|j]. Here
j′ could be identical to j (if (s)he does not accept the exchange possibilities of-
fered in the next period), to i (if (s)he is oﬀered her/his preferred good), or some
j′
6= j (if (s)he accepts another good oﬀered to him). Although this
formalism greatly facilitates the analysis, rigorous derivation of the type of Nash
equilibria sketched above is still a combinatorial nightmare. Of course, having
demonstrated the potential of this kind of model to generate speculative equilibria
as steady state solutions, the question emerges whether agents could detect these
proﬁtable trading possibilities. A number of authors have taken up the question of
whether reasonable dynamics could lead to a self-organization of the Kiyotaki and
Wright economy converging to either a fundamental or speculative equilibrium.
Contributions to the dynamics of exchange economies made use of classiﬁer sys-
tems [140] or genetic algorithms in order to describe the evolution of conventions
and self-organization of monetary exchange within an ensemble of uncoordinated
agents.

Besides articles with a computational approach of artiﬁcial and boundedly
rational agents one can also ﬁnd contributions with real agents in controlled lab-
oratory environments being rewarded with real money in dependence on their
utility gains [40, 66]. To the surprise and disappointment of some authors, both
in experiments with artiﬁcial agents [140] and human subjects one often [40, 65]
only ﬁnds emergence of fundamental equilibria. Strangely enough a kind of fun-
damental steady state even appeared in some set-ups in which the “speculative”
scenario is the unique equilibrium. Somewhat more favorable results concerning
the “emergence of money” are obtained in a recent paper by Basci [26] who allows
for imitative behavior.

11

Duﬀy [65] tried to combine artiﬁcial, agent-based simulations with laboratory
experiments with a view to the above mentioned problem. He uses results of
preliminary laboratory experiments for his computational approach which leads
to an improvement with respect to the speed of learning compared with earlier
experimental Kiyotaki-Wright environments [108].

Furthermore, Aoki [11] uses tools from statistical mechanics in his re-investigations

of the Kiyotaki-Wright approach. In this perspective, the Donangelo and Sneppen
approach appears to ﬁt well into an established line of economics research, on the
intriguing question: how could agents develop the idea of “money”? The early
stage of the study of out-of-equilibrium dynamics in this context warrants that a
great deal of collaborative work could still be done in this area in the future.

4 The First Modern Multi-Agent Model: Kim-

Markowitz and the Crash of ’87

After this digression into very fundamental questions of economic theorizing, we
turn to the major playground of multi-agent models in economics: artiﬁcial eco-
nomic life in the sense of computer-based stock or foreign exchange markets. Be-
sides some early Monte Carlo simulations like Stigler [181] or Cohen et al.
[54],
the ﬁrst “modern” multi-agent model is the one proposed by Kim and Markowitz
[105]. The major motivation of their microsimulation study was the stock market
crash in 1987 when the U.S. stock market decreased by more than twenty per-
cent. Since this dramatic decrease could not be explained by the emergence of
signiﬁcant new information, ensuing research concentrated on factors other than
information-based trading in determining stock price volatility (cf. [163]). But al-
though hedging strategies, and portfolio insurance in particular, have been blamed
to have contributed to the crash by increasing volatility [55], the theoretical work
on the link between portfolio insurance and stock market volatility was rather
limited at that time (e.g., [35]). In their simulation analysis, Kim and Markowitz,
therefore, tried to explore the relationship between the share of agents pursuing
portfolio insurance strategies and the volatility of the market.

4.1 The Model

The simulated market contains two types of investors, “rebalancers” and “portfolio
insurers”, and two assets, stocks and cash (with interest rate equal to 0). The
wealth w of each agent at time t is given as

wt = qtpt + ct

(3)

12

where qt is the number of stocks the agent holds at time t, pt is the price of the
stock at time t and ct denotes the cash holdings of the agent at time t. Rebalancers
aim at keeping one half of their wealth in stocks and the other half in cash, i.e.

target of rebalancers : qtpt = ct = 0.5wt.

(4)

Thus, the rebalancing strategy has a stabilizing eﬀect on the market: increas-
ing prices induce the rebalancers to raise their supply or reduce their demand;
decreasing prices have the opposite eﬀect. Portfolio insurers, on the other hand,
follow a strategy intended to guarantee a minimal level of wealth (the so-called
“ﬂoor” f ) at a speciﬁed insurance expiration date. They use the “Constant Pro-
portion Portfolio Insurance” (CPPI) method proposed by Black and Jones [31].
The method can be described as keeping the value of the risky asset in a constant
proportion to the so-called “cushion” s, which is the current portfolio value less
the ﬂoor, i.e.

target of portfolio insurers : qtpt = kst = k(wt − f )

(5)

where the CPPI multiple k is chosen greater than 1. The ﬂoor f is determined
as a fraction of the initial wealth and is, therefore, constant over the duration of
the insurance plan. Setting the multiple above 1 allows the investor to choose
her exposure to the risky asset in excess of the cushion, and hence to extend her
gains if prices increase. In case of falling prices, the cushion also decreases and the
stock position is reduced accordingly. Given a more or less continuous revaluation
of the portfolio structure, the ﬂoor is therefore (quite) safe.
In the presence of
falling stock prices, the falling wealth of the investor will eventually approach his
ﬂoor from above: since the right-hand side of (5) approaches zero in an extended
bear market, the fraction of the riskly asset in the investor’s portfolio will also
go the zero. With only riskless cash left in the portfolio, the designated ﬂoor,
then, constitutes, in fact, the lower bound to the value of his/her portfolio (if the
trading frequency is high enough). In this way, the Black-Jones formula imitates
the eﬀect of put options often applied in dynamic hedging strategies. Contrary to
the rebalancing strategy, the portfolio insurance strategy implies a procyclical and
therefore potentially destabilizing investment behavior: when prices fall, portfolio
insurers will strive to protect their ﬂoor by reducing their stock position, and
conversely, if prices increase, they will try to raise their stock position in order
to realize additional gains. Note that since wt on the right-hand side of (5) is
mainly governed by capital gains and losses, the multiple k shows the strength of
procyclical reactions of portfolio insurers on price changes.

Stock price and trading volume evolve endogenously according to demand and
supply. However, trading does not proceed continuously but at discrete points in

13

time. Each investor reviews her portfolio at random intervals. She rates her asset
positions using an individual price forecast computed according to the current
demand and supply situation in the following way:

1. If only asks (i.e. buy orders) exist, the investor estimates the price at 101%

of the highest ask price,

99% of the lowest bid price,

2. if only open bids (i.e. sell orders) exist, the investor estimates the price at

3. if both open asks and bids exist, the investor assumes that the price agreed
upon by buyers and sellers will be placed somewhere between open bid and
ask prices. More precisely it is assumed that her estimate of the new price is
the average between the highest ask and the lowest bid price of the previous
period, and

4. if neither asks nor bids exist, the investor assumes next period’s price to

equal the previous trading price.

Summarizing, the above assumptions amount to:

pi
est,t =

(6)

1.01 max(p1
ask,t, · · · , pn
ask,t),
pi
if
for all
bid,t = 0
and pi
ask,t 6= 0 for at least one

i = 1, ..., n
i,

0.99 min(p1
bid,t, · · · , pn
pi
if
ask,t = 0 for all
and pi
bid,t 6= 0 for at least one

bid > 0,
i = 1, ..., n
i,

for pi

bid,t)

0.5

h

ask,t) + min(p1

max(p1
ask,t, · · · , pn
for pi
bid > 0,
pi
if
ask,t 6= 0 for at least one
and pi
bid,t 6= 0 for at least one

i
i,

bid,t, · · · , pn

bid,t)
i






pt−1,

if pi

ask,t = 0 and pi

bid,t = 0

for all

i = 1, ..., n,

where i denotes the agent and n is the number of investors. In case the estimated
ratio between stocks and assets (relevant for rebalancers) or between stocks and
cushion (relevant for portfolio insurers) is higher than the target ratio (0.5 or k
for rebalancers and portfolio insurers respectively), the investor will place a sale
order with pi
ask,t = 0). Conversely, she will place a buy

bid,t = 0.99pi

est,t (i.e. pi

14

est,t

ask,t = 1.01pi

order if the evaluated ratio is smaller than the target ratio with pi
bid,t = 0).2 If matching counter-oﬀers exist, incoming buy or sell orders are
(i.e. pi
executed immediately (at the price of the particular counter-oﬀer). Otherwise,
they are put on a list and may be ﬁlled later during the trading day if suitable
oﬀers are made by other agents. Agents whose orders are open until the end of
the day have the possibility to re-evaluate their portfolio structure the next day
and to place a new order. A trading day is over when every agent who reviewed
her portfolio has had the chance to place an order and to trade. At the end of
each day agents who have lost their complete wealth (i.e., their cash plus the value
of stocks rated at the closing price) are eliminated and, thus, excluded from any
further trading activities.

4.2 Results

Every agent starts the simulation with the same value of her portfolio (i.e., $
100,000), half of it in stocks and half in cash. The price level at the start of the
simulation is $ 100. The CPPI multiple k and the insurance level g (i.e., the
proportion of ﬂoor to initial assets f ≡ g · w0 with w0 = p0q0 + c0 denoting the
level of initial wealth at time t = 0) are chosen in a way that portfolio insurance
agents start with their portfolio structure in equilibrium. The parameters for the
insurance plans are set at (ﬂoor / initial assets) = g = .75 (i.e., at expiration date
the losses should not exceed 25 % of the initial wealth) and k = 2. The duration
of the insurance plans is 65 trading days for every plan and each portfolio insurer.
Exogenous market inﬂuences are modeled by deposits and withdrawals of cash
occurring at randomly determined points in time (exponentially distributed with
a mean time of 10 trading days) and in random amounts (uniformly distributed
between $ –8,000 and $+8,000) for each investor. The time intervals between the
portfolio reviews are also determined by random draws for each investor (expo-
nentially distributed with a mean time of 5 trading days).

In the following, we provide the details of simulations in which we have repli-
cated and extended the results of Kim and Markowitz. Figure 1 and 2 show the
daily development of (closing) prices and trading volume for 0, 50 and 75 CPPI
agents, respectively, out of a total of 150 agents for the ﬁrst 800 trading days.
Compared with no CPPI agents, both trading volume and price ﬂuctuations are
generally higher in the cases of 50 and 75 CPPI investors. However, the time series
for much more than 50 and 75 CPPI agents exhibit a cyclical behavior inconsistent
with empirical data [69].

2Strictly speaking, agents allow for deviations from the target value within a certain

range which they tolerate.

15

0 CPPI Agents
50 CPPI Agents
75 CPPI Agents

e
c
i
r

P

200

180

160

140

120

100

80

60

40

20

0

100

200

300

500

600

700

800

400

Days

Figure 1: The daily development of prices (total number of agents: 150)

We have also studied the standard deviation of daily returns per trading period
each consisting of 65 trading days. As can be seen in Figure 3, for the ﬁrst periods
the volatility for 75 CPPI agents is much higher than for 0 or for just 25 CPPI
agents. But after about 15 trading periods the volatility for 75 CPPI agents
declines remarkably. We have observed a similar decline of volatility in the case of
50 CPPI agents (not displayed in the ﬁgure). The reason, however, for this strong
decrease in volatility in case of a high proportion of CPPI agents is simply that a
signiﬁcant number of agents become bankrupt in the course of the simulations.

Figure 4 shows a positive relationship between the proportion of bankrupt
agents and the initial share of CPPI agents. Moreover, there is also a positive re-
lation between the share of bankrupt CPPI agents in the total number of bankrupt
agents and the initial rate of CPPI agents. Thus, in the case of 25 CPPI agents
we had 13 bankrupt CPPI and 50 bankrupt rebalancing agents after 100 trading
periods (i.e., 6500 days), whereas, in the case of 75 CPPI agents the ratio was 67
CPPI agents to 11 rebalancers (Figure 4, upper panel).

The number of bankrupt investors is generally lower if we raise the total number
of agents to 1500 (Figure 4, lower panel). Thus, it appears to be a kind of ﬁnite-
size eﬀect. Nevertheless, in this setting we still observe a reduction of volatility

16

7000

6000

5000

4000

3000

2000

1000

)
s
e
r
a
h
S

 
f
o
 
r
e
b
m
u
N

l

(
 
e
m
u
o
V
 
g
n
d
a
r
T

i

0

0

0 CPPI Agents
50 CPPI Agents
75 CPPI Agents

17

100

200

300

500

600

700

800

400

Days

Figure 2: The daily development of trading volume (total number of agents:
150)

s
n
r
u
t
e
R

i

 
f
o
 
n
o
i
t
a
v
e
D
 
d
r
a
d
n
a
t
S

0.14

0.12

0.1

0.08

0.06

0.04

0.02

0

0 CPPI Agents
25 CPPI Agents
75 CPPI Agents

18

10

20

30

40

50

60

70

80

90

100

Trading Period

Figure 3: The standard deviation of daily returns per trading period (total
number of agents: 150)

0 CPPI /150 Agents
25 CPPI /150 Agents
75 CPPI /150 Agents

1000

2000

3000

4000

5000

6000

7000

Days

0 CPPI /1500 Agents
250 CPPI /1500 Agents
750 CPPI /1500 Agents

s
t

n
e
g
A

 
t

p
u
r
k
n
a
B

 
f

 

o
n
o

i
t
r
o
p
o
r
P

s
t
n
e
g
A

 
t
p
u
r
k
n
a
B

 
f
o
 
n
o
i
t
r
o
p
o
r
P

0.6

0.5

0.4

0.3

0.2

0.1

0.6

0.5

0.4

0.3

0.2

0.1

0

0

0

0

1000

2000

3000

4000

5000

6000

7000

Figure 4: The proportion of bankrupt investors to the total number of agents
(150 and 1500 respectively)

Days

19

0 CPPI Agents
250 CPPI Agents
750 CPPI Agents

s
n
r
u
e
R

t

 
f

o

 

n
o

i
t

i

 

a
v
e
D
d
r
a
d
n
a
t
S

0.18

0.16

0.14

0.12

0.1

0.08

0.06

0.04

0.02

0

10

20

30

40

50

60

70

80

90

100

Trading Period

Figure 5: The standard deviation of daily returns per trading period (total
number of agents: 1500)

in the case of a CPPI agents’ proportion equal to one half (i.e., 750 CPPI agents,
cf. Figure 5). Compared to the previous setting, the level of volatility is now
signiﬁcantly higher with CPPI agents (both 250 and 750 CPPI agents) than with-
out CPPI agents. From these experiments we conjecture that the impact of the
portfolio insurance strategy on market volatility generally increases with growing
market size.

Nevertheless, given that the model is intended to study the inﬂuence of portfo-
lio insurance on the market, the strong reduction in the number of active market
participants and, especially, the positive dependence of bankruptcies on the initial
share of CPPI agents, constitutes a serious deﬁcit of the model design. Presum-
ably however, the quality of the results could be improved by allowing bankrupt
agents to be replaced by new solvent agents.3

3Another way to prevent a large number of bankrupt agents is to choose an asymmetric
distribution for the amounts withdrawn and deposited on the accounts of the agents.
Actually, by just extending the limit of deposits from $ 8000 to $ 9000 (and keeping
the limit for withdrawals at $ –8000) we discovered a strong reduction in the number of
bankrupt agents.

20

0 CPPI Agents, beta=4
75 CPPI Agents, beta=4
0 CPPI Agents, beta=8
75 CPPI Agents, beta=8

s
n
r
u
e
R

t

 
f

o

 

n
o

i
t

i

 

a
v
e
D
d
r
a
d
n
a
t
S

0.2

0.18

0.16

0.14

0.12

0.1

0.08

0.06

0.04

0.02

0

10

20

30

40

50

60

70

80

90

100

Trading Period

Figure 6: The standard deviation of daily returns per trading period for
β = 4 and β = 8 (total number of agents: 150)

For a further set of simulations we replaced the individual bid and ask prices by
one uniform market price which is set by a market maker reacting on the diﬀerence
between supply and demand.4 Thus, in case of excess demand (supply) prices rise
(fall) proportional to the ratio of excess demand (supply) to the total number of
shares with proportionality factor β:

pt = pt−1(1 + β

EDt
STt

)

(7)

where ED is the excess demand and ST the total number of stocks in the market.
As shown in Figure 6, after about 15 trading periods, the volatility in case of 75
CPPI agents for a price adjustment speed β = 4 hardly diﬀers from the case with
no CPPI agents. By increasing the price adjustment speed to β = 8 the volatility
generally tends to increase (for both 0 and 75 CPPI agents). As in the previous
setting, in this modiﬁed setting the strong decline of volatility in the case of 75
CPPI agents is again due to the large number of bankrupt agents.

4A similar modiﬁcation of the model is described in Egenter et al. [69].

21

0 CPPI Agents, beta=4
75 CPPI Agents, beta=4
0 CPPI Agents, beta=8
75 CPPI Agents, beta=8

e
c
i
r

P

200

400

350

300

250

150

100

50

0

0

100

200

300

500

600

700

800

400

Days

Figure 7: The daily development of prices for β = 4 and β = 8 (total number
of agents: 150)

Also similar to the original setting, we ﬁnd almost cyclical price movements
for a high proportion of CPPI agents among our market participants (Figure 7).

4.3 Conclusions

Deviating from our parameter setting, the original simulations by Kim and Markowitz
start with the rebalancers’ portfolio structure in disequilibrium, i.e., rebalancers
initially have either too many or too few stocks. Additionally, in their setting,
deposits are higher on average than withdrawals. The basic result of this ap-
proach is the demonstration of the destabilizing potential of portfolio insurance
strategies. Kim and Markowitz, therefore, provide a theoretical foundation for the
academic discussions on the sources of the 1987 crash. Their model, of course, was
not designed to address other puzzles in empirical ﬁnance, like the “stylized facts”
summarized in the introduction. A comprehensive simulation study and statistical
analysis of model-generated data, in fact, showed that the time series characteris-
tics exhibit hardly any similarities with empirical scaling laws [159]. Taking into
account the pioneering character of this model and the intention of the authors

22

to provide a partial explanation of the crash of October ’87, our demands on this
paper should, however, not be set too high.

5 An Early ’Econophysics’ Approach: Levy-

Levy-Solomon

Kim and Markowitz obviously tried to simulate a market populated by traders who
pursue strategies found in real-life markets, and, therefore, gave a quite detailed
description of activity at the microscopic level. In contrast to this highly speciﬁc
set-up, more recent models deal with much more stylized and simple descriptions of
traders’ behavior. Historically, one of the ﬁrst of these approaches is a collaboration
of a group at Hebrew University including both economists and physicists. The
ﬁrst publication of their approach appeared in an economics journal in 1994 [117]
which was followed later by more detailed reports in physics and computer science
journals as well as a book [118, 122, 121, 119, 120].

5.1 The Model Set-Up

The model contains an ensemble of interacting speculators whose behavior is de-
rived from a rather traditional utility maximization scheme. At the beginning of
every period each investor i needs to divide up his entire wealth W (i) into shares
and bonds. Cash, credit, or short sales of stocks are not allowed. With X(i) denot-
ing the share of stocks in the portfolio of investor i, his wealth can be decomposed
as follows:

Wt+1 = X(i)Wt(i)

+ (1 − X(i))Wt(i)

(8)

with superimposed boundaries 0.01 < X(i) < 0.99.

sum of shares
{z

}

|

sum of bonds
{z

}

|

Additionally, the model assumes that the number of investors n as well as the
supply of shares NA are ﬁxed. In addition to an identical utility function U (Wt+1),
investors at the beginning also possess the same wealth and the same amount of
stocks. Whereas the bond, assumed to be riskless, earns a ﬁxed interest rate r, the
stock return Ht is composed of two components (bonds are riskless in economics
just like planets are point masses in the ﬁrst physics lectures). On the one hand,
either capital gains or losses can be the results of price variations pt. On the other
hand, the shareholder receives a daily or monthly 5 dividend payment Dt which

5The notion of the underlying time steps diﬀers in the available publications.

23

grows by a constant rate over time:

Ht =

pt − pt−1 + Dt
pt−1
In the base-line model, the preferences of investors are given by a logarithmic
utility function U (Wt+1) = ln Wt+1. This function fulﬁlls the usual characteristics
of a positively diminishing marginal utility. The consequence is an absolutely
diminishing risk aversion, so that the amount of money invested in stocks increases
with the wealth of an investor. The so-called “relative risk aversion” is constant
and the optimal proportion invested in stocks, therefore, is independent of the
wealth (see Arrow [98]). The share of stocks, therefore, remains constant.

(9)

Investors are assumed to form their expectations of future returns on the basis
of their recent observations. Their memory span contains the past k total stock
returns Ht. All investors with the same memory length k form an investor group
G. They expect that the returns in question will reappear in the next period with
a probability of 1/k. The corresponding expected utility function EU (XG(i)) has
to be maximized with respect to the share of stocks XG:

t−k+1

Xj=t

1
k





EU =

ln [(1 − XG(i))Wt(i)(1 + r) + XG(i)Wt(i)(1 + Hj)]

(10)

f (XG(i)) =

∂EU (XG(i))
∂XG(i)

=

t−k+1

Xj=t

1
XG(i) + 1+r
Hj −r

= 0

(11)



Like in most models, neither short-selling of assets nor buying ﬁnanced by
credit is allowed to the agents, so that the space of admissible solutions is restricted
to a share of stocks in the interval [0, 1]. Levy, Levy, Solomon, furthermore, impose
minimum and maximum fractions of shares equal to 0.01 and 0.99 in cases where
the optimal solution of the optimization problem would imply a lower (higher)
number. We, hence obtain either inner or outer solutions for XG(i) which are
depicted in Table 1. (Because of the maximum condition the ﬁrst derivative of f
is zero.)

When the optimum share of stocks is calculated for an investor group XG(i),
a normally distributed random number εi is added to the result in order to derive
each individual investor’s demand or supply. This stochastic component may be
interpreted as capturing the inﬂuence of idiosyncratic factors or of individual de-
viations from utility maximization from the economists’ point of view. However,
in the original papers it is motivated from a physics perspective as the inﬂuence
of the “temperature” of the market. From aggregation of the stochastic demand

24

Table 1. Inner and outer solutions

f (0)
< 0
> 0
> 0

f (1)
−
< 0
> 0

XG(i)
0.01

0.99

0.01 < X(i) < 0.99

functions of traders, the new stock price (and therefore, the total return Ht), can
be calculated as an equilibrium price. One now eliminates the “oldest” total return
from the investors’ memory span and adds the “new” entry when the simulation
process is ﬁnished for period t.

5.2 Previous Results

Models with only one investor group show periodic stock price developments (Fig-
ure 8) whose cycle length depends on the memory span k. This price development
can be explained as follows: Let us assume that, at the beginning of the simulation,
a random draw of the k previous total stock returns Ht occurs that encourages
investors to increase the proportion of shares held in their portfolio. The larger
total demand, then, causes an increase in price and therefore a new positive total
return results. According to the updating of data the oldest total return will be
dropped. This positive return causes the investor group to raise their stock shares
successively up to a maximum of 99%. At this high price level the price remains al-
most constant for a little longer than k periods until the extremely positive return
of the boom period drops from the investors’ memory span.

As explained above, the total return is composed of the capital gains or losses
and of the dividend. Since the dividend yield, D/p, is relatively small because of
the considerably high stock price, a relatively small (negative) total stock return
(caused by the noise term εi) suﬃces to make the riskless bond appear more
attractive. The desired share of stocks and with it the stock price, then, break
down. If such a crash happens with an ensuing extremely negative total return the
desired share of stocks drops to a minimum of 1%. Again, it takes another k periods
for the investors to forget about this extremely negative entry. Because of the
then available high real dividend rate, investing in shares becomes more attractive
compared to bonds. The total demand and the stock price start rising again and a
new price cycle begins. If two groups with diﬀerent memory spans are considered,
strict periodicity still remains a possible outcome. However, depending on the
choice of the memory spans, other dynamic patterns can appear. Looking at the
distribution of total wealth, a dominating inﬂuence on the share price development
by one group then does not necessarily mean that it also gains a dominant share

25

e
c
i
r

P

50

45

40

35

30

25

20

15

10

5

0

0

20

40

60

80

120

140

160

180

200

100

Days

Figure 8: With only one type of traders and a logarithmic utility function, the
typical outcome of the Levy, Levy, Solomon model is a cyclic development of
stock prices with periodic booms and crashes. Our own simulations produced
all the visible patterns emphasized in [117, 118, 121].

26

of total wealth.

The model outcome becomes more irregular with three (and more) investor
groups. For example, for the combination k = 10, 141, 256 and n = 100, Levy
and Solomon claimed to have found chaotic motion in stock prices. However,
Hellthaler [86] has shown that if the number of investors is increased from n = 100
to, for example, n = 1000, these chaotic stock price developments are replaced
by periodic motion again. This eﬀect persists if more than one type of stocks
is traded [109]. Furthermore, Zschischang and Lux [205] found that the results
concerning the wealth distribution for k = 10, 141 and 256 are not stable. While
Levy, Levy and Solomon argued that the group with k = 256 usually turned out to
be the dominant one, it is also possible that the investor group k = 141 will achieve
dominance (Figure 9). This shows an interesting extreme type of dependence of the
model outcome on initial conditions brought about by seemingly minor diﬀerences
within the ﬁrst few iterations: depending solely on the random numbers drawn as
the “history” of the agents at t = 0, we get totally diﬀerent long-run results for
the dynamics.

Of course, one would like to have microscopic models to provide an explanation
of the power-law behavior of both large returns and the time-dependence in various
powers of absolute returns. However, when investigating the statistical properties
of Levy, Levy and Solomon’s model, the outcome is as disappointing as with
the Kim and Markowitz framework: none of the empirical scaling laws can be
recovered in any of our simulations (see Zschischang [204] who investigates about
300 scenarios with diﬀerent utility functions, memory spans and varying number of
groups). Scaling laws have, however, been reported in related models of the same
group of authors, e.g. [123]. While the underlying philosophy of both approaches
is somewhat similar, their microscopic structure is quite diﬀerent.

As exempliﬁed in Figure 10, models which are claimed to have a chaotic price
development often have stock returns that appear to follow a Normal distribution
(Figure 10) and do not account for “clustered volatilities” (Figure 11). These
results are supported by standard tests of the Normal distribution and for the
absence of correlations of stock returns. Zschischang and Lux argue that in these
cases the Levy, Levy, Solomon model, instead of giving rise to low-dimensional
chaotic dynamics and strange attractors, can eﬀectively be viewed as a random
number generator [205].

The original papers are not entirely clear about the lengths of the time in-
crements of the model: they are sometimes denoted by “days” and sometimes by
“months”. Since at low frequencies, returns in real markets seem to approach a
Gaussian distribution, in such an interpretation, the Normality of returns gener-
ated from the model might even appear to be a realistic feature. However, the
mechanism for the emergence of a Gaussian shape is still diﬀerent from its ori-

27

h
t
l
a
e
W

 
f
o
 
e
r
a
h
S

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

k=141

k=256

28

k=10

5000

10000

20000

25000

30000

15000

Days

Figure 9: Development of the distribution of wealth with three groups char-
acterized by k = 10, 141, and 256, respectively. Depending on the initial
conditions, either the group with k = 256 or the group with k = 141 as in
the present case may happen to dominate the market

Returns
Normal Distribution

y
c
n
e
u
q
e
r
F

0.12

0.1

0.08

0.06

0.04

0.02

0

-1

-0.8

-0.6

-0.4

-0.2

0

0.2

0.4

0.6

0.8

1

Figure 10: Distribution of returns form a simulation with 6 groups character-
ized by memory spans k = 10, 36, 141, 193, 256, and 420. This is an example
with a stock price development described as “chaotic” in [121]. However, it
seems that the result is rather similar to pure randomness. The histogram is
drawn for 20,000 observations after an initial transient of 100,000 time steps.
The close similarity to the Normal distribution is conﬁrmed by statistical
measures: Kurtosis is 0.043 and skewness is -0.003. This yields a Jarque-
Bera statistic of 1.55 which does not allow to reject the Normal distribution
(signiﬁcance is 0.46%)

29

Raw Returns
Absolute Returns
Squared Returns

l

n
o
i
t
a
e
r
r
o
c
o
t
u
A

0.1

0.05

0

-0.05

-0.1

-0.15

-0.2

-0.25

-0.3

0

50

100

150

200

250

300

Lags (in Days)

Figure 11: Autocorrelations of raw, absolute and squared returns from the
simulation of a “chaotic” case of the Levy-Levy-Solomon model. As can
be seen, dependence in absolute and squared returns (as typical proxies for
market volatility) is as weak as with raw returns themselves. The underlying
scenario is the same as with Figure 10

30

gin in monthly returns in reality. The latter seems to be the consequence of the
aggregation of high-frequency returns whose distribution is within the domain of
attraction of the Normal distribution (because of its power-law exponent above 2).
In the LLS model, on the other hand, the Gaussian shape seems to originate from
the aggregation of random demand functions within the same period.

6 Financial Markets and the Distribution of

Wealth: Solomon-Levy-Huang

Again, the unrealistic time series characteristics of both the Kim and Markowitz
and the Levy, Levy, Solomon approach should not be taken too seriously: both
models are among the ﬁrst attempts at microscopic simulations of ﬁnancial markets
and their aims were more to provide mechanisms for bubbles and crashes than to
look at statistical features of the so generated time series. At least in the case
of Levy, Levy, Solomon, the authors initially were not aware at all of the scaling
laws characterizing ﬁnancial markets (personal communication by Sorin Solomon).
However, later on their model served as inspiration and starting point for the
analysis of statistical properties of simulated data. As an interesting example,
the inherent wealth dynamics in Levy, Levy, Solomon inspired a more thorough
analysis of the development of traders’ wealth in some kind of generalized Lotka-
Volterra systems.

This extension is based on a 1996 model [123, 168] which was re-investigated
more recently. The pertinent results have been presented in a series of recent papers
by Huang, Solomon and others. We thus call it the SLH model. Its mechanics
can be described as a random multiplicative process for the wealth of each trader,
with diﬀerent traders coupled through their average wealth somewhat similar to
predator-prey models.

Assume that all traders start with the same wealth but later each of them
speculates diﬀerently on the market and gains or loses amounts proportional to
his current wealth:

wi(t + 1) = λwi(t)

(i = 1, 2, . . . , N )

(12)

where λ is a number ﬂuctuating in a small interval D centered about unity. This
random multiplicative process has been discussed before. The new ingredient in
SLH is the “welfare state”: Nobody is allowed to fall below some poverty level
i wi(t)/N is the average wealth per trader at
wi = qW where W = W (t) =
that time. Thus this model is very simple, but nevertheless possesses many real-
istic properties. Physicists can identify it with a random walk on a logarithmic

P

31

(13)

(14)

(15)

wealth scale with one repelling boundary.6 Instead of this cut-oﬀ, the authors also
investigate the rule

wi(t + 1) = λwi(t) + aW (t),

which represents a rich society engaging in even redistribution of a certain fraction
a of overall wealth.

In the inﬁnite N limit the same relative wealth distribution

P

wi
W (cid:19)

(cid:18)

∝

wi
W (cid:19)

(cid:18)

−2−2a/D

exp

−aW
Dwi (cid:21)

(cid:20)

is obtained [155] for a more general and realistic model:

wi(t + 1) = λw(i) + aW (t) − c(W, t)wi(t)

where the arbitrary function c(W, t) parameterizes the general state of the econ-
omy: time periods during which −c(W, t) is large and positive correspond to boom
periods while periods during which it is negative correspond to recessions. Com-
plementarily, if one thinks of wi as the real wealth (as opposed to the nominal
number of dollars which could increase solely because of inﬂation) of each individ-
ual, an increase of the total amount of dollars in the system W (t) means that an
agent with individual wealth wi will suﬀer from a real loss due to inﬂation in an
amount proportional to the increase in average wealth and proportional to one’s
own wealth: −c(W, t)wi(t).

The following results are obtained: For inﬁnite markets, a power law ∝ 1/wα
was obtained for the probability of traders with wealth larger than some arbitrary
wealth w. The exponent for this power law is given by the cut-oﬀ: α = 1/(1− q). q
was deﬁned above as the ratio of the lowest allowed wealth to the average wealth.
Thus if q ∼= 1
3 we have α ∼= 1.5 in agreement with well-known empirical ﬁndings.
It would be interesting to see if in real economies this exponent and the analogous
one for the price ﬂuctuations depend on the lower cut-oﬀ for wealth: The more
egalitarian or socialist a country is, the higher will be q, and the higher will be
the exponent α, making extreme wealth inequalities and market ﬂuctuations less
probable.

The amount trader i invests on the stock market is proportional to the wealth
wi : George Soros produces more price changes than the present authors together
(we expect this to change in the near future). Thus the ﬂuctuations of the market

6This passage, having been contributed by D.S., obviously reﬂects the tendency of
physicists to know everything better. In fact, the remaining authors (although they are
only economists) see no reason why they should be unable to recognize a random walk
with a reﬂecting boundary.

32

price were at ﬁrst thought to have the same tail exponent α as the wealth distri-
bution. However, this is not true because the diﬀerent traders are not statistically
independent: the cut-oﬀ wi ≥ qW introduces a coupling via the average wealth
W .

Moreover, real markets are ﬁnite, and according to a 1999 review of micro-
scopic market models [175], the majority of these models get unrealistic properties
like periodic oscillations, if the market size goes to inﬁnity. In short, a few hundred
professional speculators and not the millions of non-speculative families dominate
most of the market movements. The thermodynamic limit, so traditional in sta-
tistical physics where a glass of beer contains 1025 molecules and where 5 × 1013
sites were already simulated [184], may, therefore, be very unrealistic for markets
or social science [185].

Indeed, simulations of the SLH model for 102 . . . 104 traders gave eﬀective
exponents α ≃ 3, i.e. close to the desired one for the price ﬂcutuations (not the
wealth distribution). These exponents are valid only in some intermediate range:
For small wealth the cut-oﬀ is important, and nobody can own more wealth than
is available in the whole market. We refer to the SLH papers for more details on
this approach [91, 167, 92, 30, 93, 169, 155, 126].

A somewhat related recent strand of literature has analysed simple monetary
exchange models. The main question pursued in this area is emergence of inequal-
ity within a pool of agents due to the randomness of their fortunes in economic in-
teractions. This line of research is represented, among others by [34], [45], [64, 29].
The structure of all these models is very simple: agents are randomly matched
in pairs and try to catch some of the other agent’s wealth in this encounter. A
random toss decides which of both opponents is the winner of this match. The
successful agent, then, leaves the battle ﬁeld with her/his wealth having increased
by a fraction of the other agent’s previous belongings. The above papers show that
this simple random exchange model (with only minor diﬀerences in the stochastic
formalisation in the above papers) leads to an endogeneous emergence of inequality
within an initially homogenous population. It is, however, worthwile to point out
that exactly the same process had already been proposed in [6] by sociologist John
Angle and has been extended in various ways in the pertinent literature over the
years ([7, 8, 9]). Needless to say that physicists would have gained by ﬁrst consult-
ing the literature on the subject before starting to duplicate well-established lines
of research. It might also be remarked that in the recent economics literature, a
number of more realistic models of wealth formation and agend-based models exist
(e.g.
[165]). A more extensive discussion of this class of model can be found in
[131].

33

7 Percolation Theory Applied to Finance: Cont-

Bouchaud

Together with the random walk model of Bachelier [21] hundred years ago, and
the random multiplicative traders of SLH, the Cont-Bouchaud model is one of the
simplest models, having only a few free parameters (compared, e.g., to the “terribly
complicated” Lux-Marchesi model reviewed below). Economists like biologists may
bemoan this tendency of physicists, but the senile third author from the physics
community likes it. Also, it is based on decades of percolation research in physics,
chemistry and mathematics, just as Iori’s random-ﬁeld Ising model uses many
years of physics experience in that area [95]. Obviously, with this type of models,
“econophysicists” have introduced new tools of analysis to ﬁnancial modeling.
As recent research in economics has focused on communication and information
among traders (e.g., [107, 25]), the random-ﬁeld and percolation models might be
welcome means for the investigation of information transmission or formation of
opinions among groups of agents.

In percolation theory, invented by the later chemistry Nobel laureate Paul
Flory in 1941 to explain polymer gelation (cooking of your breakfast egg), and
later applied by Broadbent and Hammersley to coal-dust ﬁlters, and by Stuart
Kauﬀman to the origin of life, each site of a large lattice is either occupied (with
probability p), or empty (with probability 1 − p).

Clusters are groups of occupied neighbors. A cluster is inﬁnite if its mass s (the
number of occupied sites belonging to that cluster) increases with a positive power
of the lattice size (and not only logarithmically). When the density p increases
from zero to one, at some sharp percolation threshold pc for the ﬁrst time (at least)
one inﬁnite cluster appears; for all p > pc we have exactly one inﬁnite cluster for
large and not too anisotropic lattices, ﬁlling a positive fraction p∞ of the whole
lattice. For all p < pc we have no inﬁnite cluster. At p = pc we ﬁnd incipient
inﬁnite clusters which are fractal.
If p approaches pc from above, the fraction
p∞ vanishes as (p − pc)β with some critical exponent β varying between zero and
unity for dimensionality going from one to inﬁnity. The Hoshen-Kopelman and the
Leath algorithm to produce and count percolation clusters are well documented
with complete programs available from DS.

The average number ns of clusters containing s sites each follows a scaling law

for large s close to the threshold pc

ns = s−τ f [(p − pc)sσ]

(16)

where the exponent τ varies from 2 to 2.5 if d goes from one to inﬁnity, and the
exponent σ stays close to 1/2 for 2 ≤ d ≤ ∞. The previous exponent β equals

34

(τ − 2)/σ. The details of the lattice structure do not matter for the exponents,
only for the numerical value of pc(∼= 0.5927464 for nearest neighbors on the square
lattice). On a Bethe lattice (Cayley tree), τ = 5
2 , β = 1, and the above
scaling function f for the cluster numbers is a Gaussian; these exponents are also
found for 6 < d ≤ ∞ and for the case that each site is a neighbor to all other sites
(i.e., a “random graph”) [144].

2 , σ = 1

The above model is called site percolation; one can also keep all sites occupied
and instead break the links between neighboring sites with a probability (1 −
p). This case is known as bond percolation and has the same exponents as site
percolation. Computer programs to count percolation clusters were published by
many, including the senile co-author [177, 178]. All this knowledge was available
already before percolation was applied to market ﬂuctuations.

In the Cont-Bouchaud market model, originally restricted to the mathemat-
ically solvable random graph limit and later simulated, as reviewed in [176], on
lattices with 2 ≤ d ≤ 7, each occupied site is a trader. A cluster is a group of
traders making joint decisions; thus the model simulates the herding tendency
of traders. At each time step, each cluster either trades (with probability 2a)
or sleeps (with probability 1 − 2a), and when it trades it either buys or sells an
amount proportional to the size s of the cluster i; thus a usually is the proba-
bility for the member of a cluster to be a buyer. The market price is driven by
the diﬀerence between the total supply and demand; the logarithm of the price
changes proportionally to this diﬀerence (or later [180, 203] to the square-root of
the diﬀerence). The concentration p is either ﬁxed or varies over the whole interval
between zero and unity, or between zero and pc. The results deteriorate [44, 48]
if the price change is no longer proportional to the diﬀerence between demand D
and supply S, but to the relative diﬀerence (D − S)/(D + S) or to a hyperbolic
tangent tanh[const·(D − S)]. However, the latter has been found to be a more
realistic description of the price impact of demand variations [151].

Some results are: If the activity a increases from small values to near its maxi-
mum value 1/2, the histogram of the price ﬂuctuations changes from an asymptotic
power law to something close to a Gaussian, similar to the crossover in real markets
when the observation time goes to inﬁnity. For small activities, the cumulative
probability to have a change by at least x%, varies in its tail as 1/xµ, with [180, 176]
µ = 2(τ + σ − 1) if we use Zhang’s square-root law and average over all p between
0 and pc. This exponent µ varies from 2.9 and 3.3 to 4 if d increases from two and
three to inﬁnity. Thus in the realistic dimensions of a city or bank building, d = 2
or 3, we get the desired µ ∼= 3. Figure 12 shows simulations giving this power law,
except for ﬂattening at small x and a cut-oﬀ due to ﬁnite market sizes at large
x. The curve through the data is the Student-t distribution following from Tsallis
statistics [173].

35

)
x
(
P

100000

1e+09

1e+08

1e+07

1e+06

10000

1000

100

10

1

100

10

x

Figure 12: Distributions of price changes from the Cont-Bouchaud percola-
tion model. The ﬁgure also compares P (x) with const/(3 + 0.06 ∗ x2)2. The
underlying data are averages from many 301 × 301 square lattices

36

)
e
c
i
r
p
 
l
a
i
t
i
n
i
 
/
 
e
c
i
r
p
(
g
o
l
 
*
 
t
s
n
o
c

800

600

400

200

0

-200

-400

-600

200000

205000

210000

215000

220000

230000

235000

240000

245000

250000

225000
time

Figure 13: Examples of price versus time in a modiﬁed Cont-Bouchaud
model, showing sharp peaks and ﬂat valleys [48]

Volatility clustering, positive correlations between trading volume and price
ﬂuctuations, as well as the observed asymmetry between sharp peaks and ﬂat val-
leys is seen if the activity increases (decreases) in a time of increasing (decreasing)
market prices. Nearly log-periodic oscillations are seen if a non-linear restoring
force (buy if the price was low) is combined with some hysteria (buy if the price
was rising). For more details we refer to the original papers following [56] reviewed
in [176].

After this review, more eﬀects were understood and variations were tried. The
crossover towards a Gaussian return distribution for increasing activity was ex-
plained [111]. Instead of lattices of various dimensions, the Barabasi network was
assumed as the home of the Cont-Bouchaud traders, with good results [112]. Ther-
modynamic Ising-like modiﬁcations [164], in the direction of the Iori model [95]
were proposed and gave reasonable histograms of price ﬂuctuations. The lack of
time-reversal invariance was recovered by putting some risk aversion psychology
into the buying and selling probabilities [47]. Multifractality was found [43] in
the higher moments of the return distributions for diﬀerent time intervals. Also a
combination of these various modiﬁcations worked reasonably though not ideally
[48]; see e.g. Figure 13.

37

Applications included triple correlations between Tokyo, Frankfurt and New
York markets [162] and the eﬀects of a small Tobin tax on all transactions [70,
197]. Two physicists, Ehrenstein and Stauﬀer and an economist, Westerhoﬀ ﬁrst
independently simulated how such a tax would inﬂuence the market. Depending on
parameters, either the total tax revenue has a maximum in the region of up to one
percent taxation, or it increases monotonically. Taking into account the tendency
of governments to overexploit available sources of tax income, they recommend
the Tobin tax only for the ﬁrst case, not the second. It then would reduce the
amount of speculation, but not by an order of magnitude [71]. Summarizing, it
therefore appears that the Cont-Bouchaud models and the subsequent variations
on their theme contributed by other authors have gone some way in explaining
important stylized facts of ﬁnancial markets. Nevertheless, economists often feel
somewhat uneasy about this approach. The reason is that its starting point is
known knowledge about the characteristics of certain graph-based dynamics (i.e.,
percolation models in statistical physics). The “explanation” of stylized facts in
economics is, then, achieved to some extend via a mere relabeling of known physical
quantities into new ones with an economic interpretation. Economists, of course,
would like to start with basic facets of economics interaction of real-life markets
rather than with a lattice-based architecture. Furthermore, the many attempts
at “improvements” of the model outlined above show that realistic results are
only obtained under extremely speciﬁc settings. Hence, it appears questionable
whether this framework really allows an explanation of empirical ﬁndings that is
“independent of microscopic details” as postulated in an econophysics manifesto
(Stanley et al. [174]).

8 Social Percolation and Marketing: Solomon-

Weisbuch

Nevertheless, scientists have a natural tendency to apply what they have learned
to as many diﬀerent problems as possible (maximizing thereby the number of their
publications). Percolation theory seems to be one of the discoveries one can use in
quite a number of ﬁelds. Besides ﬁnancial markets, another application concerns
“social percolation” and its use in marketing [170] which we review in the following
(departing shortly from our central subject of ﬁnancial markets).

As in the previous section, every site of a large lattice is randomly either
occupied or empty, and a cluster is a set of occupied neighbors. Now we identify
occupied sites with potential customers of one speciﬁc product, say, a Hollywood
movie. Each site i has a certain product quality requirement pi, and the product
has a certain quality q. The values of pi are homogeneously distributed between

38

zero and unity. Only those people visit this movie (or more generally, buy this
product) who regard its quality as suﬃcient, i.e. who have pi < q. We thus deﬁne
as occupied a site with pi < q, and then a site is occupied with probability q. All
sites i in a cluster have pi < q.

If all potential customers are immediately informed about the new product and
its quality q, then a fraction q of all sites will buy, a trivial problem. But since we
get so much advertising, we may mistrust it and consider buying a movie ticket
only if we hear from a neighbor about its quality q. Thus a site i buys if and only
if one of its nearest neighbors on the lattice has bought before, if i has not bought
before, and if pi < q (customers are assumed to have the same perception of the
quality of the product, i.e. the quality assessment q they tell their neighbors is the
same for all customers.) Initially, all occupied sites on the top line of the lattice
(top plane in three dimensions) are regarded as customers who have bought and
who thus know the quality q. In this way, geometry plays a crucial role, and only
those sites belonging to clusters which touch the upper line get informed about
the movie and see it. If and only if one cluster extends from top to bottom of
the lattice, we say that the cluster percolates or spans. And standard percolation
theory then predicts a spanning cluster if the occupation probability (or quality)
q is larger than some threshold pc, which is about 0.593 on the square lattice
[177, 158, 41]. (Instead of starting from the top and moving towards the bottom,
one may also start with one site in the center and move outwards. The cluster
then percolates if it touches the lattice boundary.)

In this way the decades-old percolation theory divides new products into two
classes: Hits and ﬂops [193], depending on whether or not the quality was high
enough to produce a spanning cluster. For a ﬂop, q < pc, only sites near the
initially occupied top line get informed that the new cluster exists, while for a hit,
q > pc, also customers “inﬁnitely” far away from the starting line buy the movie
ticket. In the case of a hit, except if q is only very slightly larger than pc, nearly all
customers with pi < q get the information and go to the movie; only a few small
clusters are then isolated from the spanning network and have no chance to react.
Figure 14 shows three examples, where one time step corresponds to one search
through all neighbors of previously occupied sites (Leath algorithm [178]).

In traditional marketing theories, as discussed in [83], one neglects the spatial
structure, and a growing market has an exponential time dependence until satu-
ration sets in. For averages over lattices with spanning clusters, instead we have
power laws in time [83]. In reality, both cases have been observed, in addition to
complicated behavior somewhat similar to the curve q = pc of Figure 13.

The ﬁrst modiﬁcation of this static percolation model is to assume that the
quality q changes in time: When a movie was successful (i.e. when the cluster
percolated), the producer lowers the quality of the next movie slightly; when it

39

100

s
r
e
y
u
b

10

1

0

50

100

150

200

250

time

Figure 14: Examples of social percolation starting with one central site oc-
cupied; q = pc − 0.05 (plus signs), q = pc (middle line), q = pc + 0.05 (upper
line). We plot logarithmically the number of new buyers in each time interval
[83]. For the ﬁrst four time steps the three buying curves agree, since the
same random numbers have been used.

40

was a ﬂop (no percolating cluster), q is slightly increased. With this dynamics,
like q → q ± 0.001, the q automatically moves to the threshold pc, an example of
self-organized criticality. In addition, we may assume [170] that also the pi change:
pi increases by a small amount if i just has seen a movie, and it decreases by the
same amount if the agent did not see a movie previously (in the second case one
has to distinguish whether the customer refused to buy because of pi > q or merely
was not informed about the movie.) In this case also the pi can move towards pc,
though slower than q, or they may be blocked at some intermediate value; also
instabilities can occur where q and all pi move towards inﬁnity. These diﬃculties
were clariﬁed by Huang [90], who also applied this model to stock markets [89].

Information through advertising inﬂuences the percolative phase transition

[153]. We refer to the literature cited above as well as to [84, 1, 195, 192]
[194, 166] for further details and modiﬁcations.

There is (of course) also a large body of economic research dealing with sim-
ilar problems. In fact, the analysis of irreversible lock-in and path dependence in
the adaption of new goods or new technologies is often based on mass-statistical
models. A prominent example is Arthur [18] who used nonlinear Polya urn models
as an abstract model of such processes. The application of similar ideas as an ex-
planation for geographical concentration of economic activity led to a remarkable
revival of the formerly dormant ﬁeld of regional economics over the nineties (cf.
Arthur [19], Krugman [110]). Multi-agent approaches to “hits” and “ﬂops” in the
movie industry (using Bose-Einstein dynamics) with empirical applications can be
found in De Vany and Walls [188] and De Vany and Lee [187].

With the next (and last) model we come back to ﬁnancial markets.

9 Speculative Interaction and the Emergence

of Scaling Laws: Lux-Marchesi

The model of Lux and Marchesi [133] has its roots in earlier attempts of economists
at introducing heterogeneity into stochastic models of speculative markets.
In-
spired by the analysis of herd behavior in ant colonies [107] and earlier applica-
tions of statistical mechanics to various problems in sociology and political sciences
(Weidlich and Haag [190, 191]), a stochastic model of trading in ﬁnancial markets
has been developed in [127]. The basic ingredient of this contribution was a kind of
mean-ﬁeld dynamics for the opinion formation process among speculators together
with a phenomenological law for the ensuing price adjustment in the presence of
disequilibria. Using the Master equation formalism, it could be shown that the
model is capable of generating “bubbles” with over- or undervaluation of the asset
as well as periodic oscillations with repeated market crashes. A detailed analysis

41

of the dynamics of second moments (variances and co-variances) was added in
[130] where the potential explanatory power of multi-agent models for the typical
time-variations of volatility in ﬁnancial markets was pointed out.

The group interactions in this model have been enriched in [129] by allowing
agents to switch between a chartist and fundamentalist strategy. This more com-
plicated dynamics was shown to give rise to chaotic patterns in mean values of the
relevant state variables (the number of agents in each group plus the market price).
Numerical analysis of simulated chaotic attractors showed that they came along
with leptokurtosis (fat tails) of returns, hence providing a possible explanation of
one of the ubiquitous stylized facts of ﬁnancial data.

Both microscopic simulations as well as more detailed quantitative analyses
of the resulting time series appeared in Lux and Marchesi [133, 134] and Chen
et al.
[49]. The fact that these key issues were approached quite lately in the
development of this market model to some extent reﬂects a broader trend in the
related literature: As already pointed out above, almost all the early simulation
models developed in economics had the initial goal of investigating the formation
of expectations of economic agents in out-of-equilibrium situations (where it is
hard to form “rational”, i.e., correct expectations about the future) and analyzing
the selection of equilibria in the presence of multiple consistent solutions of a
static framework. Interestingly, a development similar to that of the Lux-Marchesi
model can also be observed in the case of the Santa Fe Artiﬁcial Stock Market.
Although the latter was constructed by a group of researchers from economics,
physics, biology and computer science already in the eighties, an analysis of the
statistical properties of the resulting time series only appeared recently (LeBaron
et al., [116]).

The dynamics of the “terribly complicated” (D.S.) Lux-Marchesi model is il-

lustrated in Figure 15.

It is a kind of feedback between group dynamics and price adjustment in the
presence of imbalances between demand and supply. Starting with basic deﬁnitions
we denote by N the total number of agents operating in our artiﬁcial market, nc
the number of noise traders, nf the number of fundamentalists (nc + nf = N ), n+
the number of optimistic noise traders, n− the number of pessimistic noise traders
(n+ + n− = nc); p is the market price, pf the fundamental value.

The dynamics of the model are composed of the following elements:
1. noise traders’ changes of opinion from a pessimistic to an optimistic mood
and vice versa: the probabilities for these changes during a small time increment
∆t are given by π+−∆t and π−+∆t and are concretised as follows:

π+− = v1

exp(U1)

nc
N

42

optimistic

(cid:27)

6
qqqqqqqqqqqqqqq

chartists
pessimistic

?

(cid:27)

qqqqqqqqqqqqqqq

@@I@
@
@
revaluation
@
of
beliefs

@
@

-

-

fundamentalists

(cid:0)
(cid:0)

(cid:0)
(cid:0)

(cid:0)(cid:0)(cid:18)(cid:0)
(cid:0)
revaluation
of
beliefs

excess demand

@
@
@
@@R

@

(cid:0)
(cid:0)

(cid:0)
(cid:0)(cid:0)(cid:9)
(cid:0)

price adjustment

Figure 15: Flowchart of dynamics of the Lux-Marchesi model: agents are
allowed to switch between diﬀerent behavioral alternatives. The number of
individuals in these groups determines excess demand (the diﬀerence between
demand and supply). Imbalances between demand and supply cause price
adjustments which in turn aﬀect agents’ choices of strategies

nc
N

π−+ = v1

exp(−U1)

U1 = α1x +

α2
v1

dp
dt

1
p

(17)

nc

, and the actual price trend, dp
dt

(We denote by πab the rates from state a to state b, like a for optimism.) Here,
the basic inﬂuences acting on the chartists’ formation of opinion are the majority
opinion of their fellow traders, x = n+−n−
1
p . Pa-
rameters v1, α1, and α2 are measures of the frequency of revaluation of opinion
and the importance of “ﬂows” (i.e. the observed behaviour of others) and charts,
respectively. Furthermore, the change in asset prices has to be divided by the
parameter v1 for the frequency of agents’ revision of expectations since for a con-
sistent formalization one has to consider the mean price change over the average
interval between successive revisions of opinion. The transition probabilities are
multiplied by the actual fraction of chartists (that means, it is restricted to such
a fraction) because chartists are also allowed to interact with fundamental traders
in the second component of the group dynamics that follows below.

2. switches between the noise trader and fundamentalist group are formalised
in a similar manner. Formally, one has to deﬁne four transition probabilities,

43

(18)

(19)

(20)

(21)

where the notational convention is again that the ﬁrst index gives the subgroup
to which a trader moves who had changed her mind and the second index gives
the subgroup to which she formerly belonged (hence, as an example, π+f gives the
probability for a fundamentalist to switch to the optimistic chartists’ group):

π+f = v2

exp(U2,1), πf + = v2

exp(−U2,1)

π−f = v2

exp(U2,2), πf − = v2

exp(−U2,2).

n+
N
n−
N

nf
N
nf
N

The forcing terms U2,1 and U2,2 for these transitions depend on the diﬀerence
between the (momentary) proﬁts earned by using a chartist or fundamentalist
strategy:

U2,1 = α3 


dp
dt

r + 1
v2
p

− R − s ·

U2,2 = α3 


R −

dp
dt

r + 1
v2
p

− s ·





pf − p
p



(cid:12)
(cid:12)
(cid:12)

pf − p
p




(cid:12)
(cid:12)
(cid:12)



(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

The ﬁrst term of the U functions represents the proﬁt of chartists from the n+
group and n− group. The second term is the proﬁt of the fundamentalists. The
parameters v2 and α3 are reaction coeﬃcients for the frequency with which agents
reconsider appropriateness of their trading strategy, and for their sensitivity to
proﬁt diﬀerentials, respectively. Excess proﬁts (compared to alternative invest-
ments) enjoyed by chartists from the optimistic group are composed of nominal
dividends (r) and capital gains due to the price change (dp/dt). Dividing by the ac-
tual market price gives the revenue per unit of the asset. Excess returns compared
to other investment opportunities are computed by substracting the average real
return (R) received by the holders of other assets in our economy. Fundamentalists,
on the other hand, consider the deviation between price and fundamental value pf
(irrespective of its sign) as the source of arbitrage opportunities from which they
may proﬁt after a return of the price to the underlying fundamental value, so that
a large diﬀerence between p and pt induces traders to follow the fundamentalist
strategy. As the gains of chartists are immediately realised whereas those claimed
by fundamentalists occur only in the future (and depend on the uncertain time
for reversal to the fundamental value) the latter are discounted by a factor s < 1.
Furthermore, neglecting the dividend term in fundamentalists’ proﬁts is justiﬁed
by assuming that they correctly perceive the (long-term) real returns to equal the
average return of the economy (i.e. r/pf = R) so that the only source of excess
proﬁts in their view is arbitrage when prices are “wrong” (p 6= pf ). As concerns

44

the second U-function, U2,2 one considers proﬁts from the viewpoint of pessimistic
chartists who in order to avoid losses will rush out of the market and sell the as-
set under question. Their fall-back position by acquiring other assets is given by
the average proﬁt rate R which they compare with nominal dividends plus price
change (which, when negative, amounts to a capital loss) of the asset they sell.
This explains why the ﬁrst two items in the forcing term are interchanged when
proceeding from U2,1 to U2,2.

3. price changes are modelled as endogenous responses of the market to im-
balances between demand and supply. Assuming that optimistic (pessimistic)
chartists enter on the demand (supply) side of the market, excess demand (the
diﬀerence between demand and supply) of this group is:

with tc being the average trading volume per transaction. Fundamentalists’ sensi-
tivity to deviations between market price and fundamental value leads to a law of
the type:

EDc = (n+ − n−)tc

EDf = nf · γ

pf − p
p

(22)

(23)

with γ being a parameter for the strength of reaction. In order to conform with the
general structure of this framework, the price adjustment process is also formalised
in terms of (Poisson) transition probabilities. In particular, the transition proba-
bilities for the price to increase or decrease by a small percentage ∆p = ±0.001p
during a time increment ∆t are given by:7

π↑p = max[0, β(ED + µ)]

, π↓p = − min[β(ED + µ), 0]

(24)

where β is a parameter for the price adjustment speed and ED = EDc + EDf
is overall excess demand (the sum of excess demand by both noise traders and
fundamentalists).

This probabilistic rule for price adjustments is, in fact, equivalent to the tra-
ditional Walrasian adjustment scheme.
It can be shown that the mean value
dynamics of the price can be depicted by the textbook diﬀerential equation for the
dependence of price changes on overall excess demand:

dp/dt
p

= β · ED = β · (EDc + EDf )

(25)

7The increment ∆p has been chosen as small as possible in order to avoid artiﬁcial
lumpiness of price changes with concentration of the distribution of returns at a few values
only.

45

Note that these price changes feed back on agents’ decisions to follow one or
the other trading strategy: a price increase will reinforce optimistic beliefs and will
make formerly pessimistic chartists join a bullish majority. Similarly, price changes
might bring p closer to an assumed fundamental value, pf , which strengthens fun-
damentalist beliefs, or they might lead to larger deviations from pf which reinforces
the position of chartists. All in all, the resulting conﬁrmation or disappointment
of agents’ opinions together with changing proﬁtability of strategies will lead to
switches between groups altering the composition of the population and eﬀect-
ing excess demand of the following period. The model also allows for exogeneous
changes of the fundamental value:

4. changes of fundamental value: in order to assure that none of the stylised
facts of ﬁnancial prices can be traced back to exogenous factors, it is assumed that
the log-changes of pf are Gaussian random variables: ln(pf,t) − ln(pf,t−1) = εt and
εt ∼ N (0, σε). The Poisson type dynamics of asynchronous updating of strategies
In par-
and opinions by the agents can only be approximated in simulations.
ticular, one has to choose appropriately small time increments in order to avoid
artiﬁcial synchronicity of decisions. In [35, 108, 109] a simulation program with
some ﬂexibility in the choice of the time increment is used. Namely, time incre-
ments ∆t = 0.01 are used for “normal times”, while during volatility bursts the
precision of the simulations was automatically increased by a factor 5 (switching
to ∆t = 0.002) when the frequency of price changes became higher than average.
This procedure requires that all the above Poisson rates be divided by 100 or 500,
(depending on the precision of the simulation) in order to arrive at the probability
for any single individual to change his behaviour during [t, t + ∆t]. Similarly, it is
assumed that the auctioneer adjusts the prevailing price by one elementary unit
(one cent or one pence) with probabilities w↑p or w↓p during one time increment.
For the time derivative, dp/dt, the average of the prices changes during the inter-
val [t − 10∆t, t] has been used. Furthermore, occurence of the “absorbing states”
nc = 0 (nf = N ) and nc = N (nf = 0) was excluded by setting a lower bound to
the number of individuals in both the group of chartists and fundamentalists.

The overall results of this dynamics is easily understood by investigation of
the properties of stationary states (cf.
[134]), i.e., situations in which there are
no predominant ﬂows to one of the groups and the price remains constant. Such
a scenario requires that there is a balanced disposition among (chartist) traders,
i.e., we neither have a dominance of optimists over pessimists (nor vice versa) and
that the price is equal to the fundamental value (which makes fundamentalists in-
active). A little reﬂection reveals that in such a situation, there is no advantage to
either the chartist or fundamentalist strategy: no misprizing of the asset nor any
discernible trends exist. Hence, the composition of the population becomes inde-
terminate which implies that, in the vicinity of these stationary states, the group

46

dynamics is governed only by stochastic factors. 8 Hence, to a ﬁrst approximation
one can abstract from the economic forces which apparently become relevant only
in out-of-equilibrium situations. As detailed in [133, 134], the stationary states de-
scribed above may either be locally stable or unstable with the number of chartists
acting as a bifurcation parameter. Simulations show that temporary deviations
into the unstable region can be interpreted as intermittent behavior which gener-
ates clusters of volatility and numerically accurate power laws for the tail behavior
of raw returns as well as long-term dependence in absolute and squared returns.
Figure 16 illustrates the interplay between the dynamics of relative price changes
and the development of the number of chartists among traders.

As can be directly inferred from the graph, an increase of the number of
chartists leads to intermittent ﬂuctuations. Note also that the model incorpo-
rates self-stabilizing forces leading to a reduction of the number of chartists after
a period of severe ﬂuctuations. The reason is that large deviations of the price
from its fundamental value lead to high potential proﬁts of the fundamentalist
strategy which induces a certain number of agents to switch away from chartism.
Chen et al. [49] also show that the motion of the market price appears totally ran-
dom (judged by standard tests for determinism and nonlinearity) in tranquil times
but shows traces of non-linear structure during more volatile episodes [49]. This
feature appears to be in harmony with ﬁndings for the U.S. stock market [124].
Recent work in this area has come up with some rigorous results on the statistical
properties of simpler variants of this type of models and has used these character-
izations in order to estimate the parameters governing agent’s interactions, cf. [5]
[3] [4].

10 Discussion

While early attempts at microscopic simulations of ﬁnancial markets appeared un-
able to account for the ubiquitous scaling laws of returns (and were, in fact, not
devised to explain them), some of the recent models seem to be able to explain
some of the statistical properties of ﬁnancial data (usually denoted as “anomalies”
in economics). Nevertheless, there is still a number of important topics left to
future research: ﬁrst, the recent surge of newly available data on the intra-daily

8A similar indeterminacy in the number of agents in diﬀerent groups has been found in a
model of resource extraction (Youssefmir and Huberman [200]). They also emphasize that
this indeterminacy can lead to burst of activity (temporary large ﬂuctuations). Another
recent example of similar intermittent dynamics appears in an artiﬁcial foreign exchange
market in which agents are using genetic algorithms to adopt their portfolio strategy to
changing circumstances, cf. [16] [135].

47

Figure 16: Time series of returns (relative price changes, upper panel) and
the fraction of chartists (lower panel) from a typical simulation of the Lux-
Marchesi model

48

level has opened a Pandora’s box of new regularities on very small time scales
(cf. Dunis and Zhou [67]). While the ubiquitous scaling laws found in all markets
might be explained well by simple mechanisms beloved by physicists, the more
delicate intra-daily patterns may require more detailed models (denoted as “mon-
sters” in a workshop presentation of a paper by Maslov [142]). If physicists do
not want to stop half-way in their contribution to economics, they may probably
have to develop, as is typically done in economics, models with more institutional
background [137]. 9 Second, although we have a bunch of models for power-laws,
their generality is still restricted in one very important respect: the “interesting”
dynamics does only apply for a certain range of the population size N of specu-
lators and in most cases does not survive for realistically large N . This has been
shown for the Kim and Markowitz and Lux and Marchesi models in Egenter et al.
[69] and probably applies to most alternative approaches. A recent investigation
of Chen and Yeh’s artiﬁcial stock market also shows that their interesting results
tend to vanish when the number of traders increases (cf. Yeh [199]). In Lux and
Marchesi, the ﬁnite size eﬀect immediately becomes apparent by realizing that
the overall number of agents aﬀects excess demand and, therefore, the right-hand
side of the price-adjustment equation. However, although one might expect that
this leads to more severe ﬂuctuations with increasing N , the contrary is the case:
ﬂuctuations become dampened with higher N and ﬁnally die out altogether with
a cross-over of returns to a Normal distribution. Of course, linear dependence
of excess demand on N is not realistic. The task for future research is, there-
fore, to look for self-organizing forces in the market (maybe via the addition of
wealth dynamics) which may lead to an eﬀective conﬁnement of the level of excess
demand.

Have the econophysics papers reviewed here brought anything new to eco-
nomics? Certainly they did not invent microscopic and agent-based computer mod-
eling (http://www.complexity-research.org/mad) of markets or empirical analysis
of market ﬂuctuations. But the large number of enonophysicists pushed these
areas since physicists are more familiar with computer simulation and empirical
analysis than many mainstream economists more interested in exact mathematical
solutions. Of course, percolation and random ﬁeld Ising models are clear physics
contributions, and the introduction of multi-fractal processes as stochastic models
of ﬁnancial prices (a topic which is outside the scope of the present review) is con-
ceived as an important innovation by many economists. Here again, we ﬁnd that
economists have been aware of the multi-scaling of returns for some time [61, 128],
but suﬀered from a lack of appropriate models in their tool-box (cf. [132] for more
details on this issue).

9Similar probably to the development of statistical models of traﬃc ﬂows, cf. Nagel et

al. [145]

49

Have econophysicists made any predictions which were later conﬁrmed? If we
deﬁne as “prediction” something which has appeared in a journal on paper before
the predicted event was over, we exclude all private communications or e-prints,
and know only three cases: The warning published in September 1997 that a
“krach” should occur before the end of November [68] (it occurred in October);
the assertion that the Nikkei index in Tokyo should go up in 1999, which it did
by roughly the predicted amount, and the prediction that the U.S. stock market
should reach a lower turning point in early 2004 which did not happen [172]. Even
if “successful”, relatively vague predictions like the above are, of course, at best
interpreted as anecdotical evidence, but are surely not signiﬁcant from a statistical
perspective.

Have we become rich in this way? The senile co-author gained 50% in half
a year by believing the above predictions, and similar anecdotal evidence exists
from others. Interestingly, in this way the one contributer with a physics back-
ground seems to show a better performance in private portfolio management than
the three economists who rather concentrated on their academic and professional
careers. Of course success is often reported proudly while failures are kept as a
secret. In this way, certain strategies might appear successful simply because of
a bias in awareness of positive outcomes versus negative ones. More than half
of a century ago, the prominent economist Nicholas Kaldor [103] explained the
prevalence of chartist strategies by such a misperception of their track record. But
more reliable are the ﬂourishing companies like Prediction Company (New Mexico)
or Science-Finance (France) founded by physicists Farmer and Bouchaud, respec-
tively, together with economists, giving employment to 102 people. This seems
quite a success for theoretical physicists.

Acknowledgment

The authors are extremely grateful to Florian Heitger for his help with the

preparation of a Latex ﬁle of this review.

50

References

[1] E. Ahmed and H. A. Abdusalam. On social percolation and small world

network. European Physical Journal B, 16:569–571, 2000.

[2] A. Aleksiejuk and J. A. Ho lyst. A simple model of bankruptcies. Physica A,

299:198–204, 2001.

[3] S. Alfarano and T. Lux. A noise trader model as a generator of apparent

power laws and long memory. Macroeconomic Dynamics. in press.

[4] S. Alfarano, T. Lux, and F. Wagner. Time variation of higher moments
in ﬁnancial markets with heterogeneous agents: An analytical approach.
Journal of Economic Dynamics & Control. in press.

[5] S. Alfarano, T. Lux, and F. Wagner. Estimation of agent-based models: The
case of an asymmetric herding model. Computational Economics, 26:19–49,
2005.

[6] J. Angle. The surplus theory of social stratiﬁcation and the size distribution

of personal wealth. Social Forces, 65:293–326, 1986.

[7] J. Angle. The inequality process and the distribution of income to blacks

and whites. Journal of Mathematical Sociology, 17:77–98, 1992.

[8] J. Angle. How the gamma law of income distribution appears invariant under

aggregation. Journal of Mathematical Sociology, 31:325–358, 1996.

[9] J. Angle. The inequality process as a wealth maximizing process. Physica

A, 367:388–314, 2006.

[10] M. Aoki. New Approaches to Macroeconomic Modeling: Evolutionary
Stochastic Dynamics, Multiple Equilibria, and Externalities as Field Eﬀects.
Cambridge University Press, Cambridge UK, 1995.

[11] M. Aoki. On dynamic re-speciﬁcations of Kiyotaki-Wright model. In A. Kir-
man and J. B. Zimmermann, editors, Economics with Heterogeneous Inter-
acting Agents, Lecture Notes in Economics and Mathematical Systems, pages
109–120. Springer, Berlin Heidelberg, 2001.

[12] M. Aoki. Modeling Aggregate Behavior and Fluctuations in Economics. Uni-

versity Press, Cambridge, 2002.

[13] M. Aoki. Open models of share markets with two dominant types of partic-
ipants. Journal of Economic Behavior and Organization, 49:199–216, 2002.

51

[14] M. Aoki and H. Yoshikawa. Reconstructing Macroeconomics. Cambridge

University Press, Cambridge UK, 2006.

[15] J. Arifovic. The behaviour of the exchange rate in the genetic algorithm and
experimental economies. Journal of Political Economy, 104:510–541, 1996.

[16] J. Arifovic and R. Gencay. Statistical properties of genetic algorithm learning
in macroeconomic models. Journal of Economic Dynamics and Control,
24:981–1005, 2000.

[17] J. Arifovic and Masson P. Heterogeneity and evolution of expectations in a
model of currency crisis. Nonlinear Dynamics, Psychology, and Life Sciences,
8:231–257, 2000.

[18] W. B. Arthur. Competing technologies, increasing returns and lock-in by

historical events. Economic Journal, 99:116–131, 1989.

[19] W. B. Arthur. Silicon Valley locational clusters: When do increasing returns

imply monopoly? Mathematical Social Science, 19:235–251, 1991.

[20] W. B. Arthur, J. H. Holland, B. LeBaron, R. Palmer, and P. Tayler. Asset
pricing under endogenous expectations in an artiﬁcial stock market. Eco-
nomic Notes, 26:297–330, 1997.

[21] L. Bachelier. Th´eorie de la sp´eculation. Ann. Sci. Ecole Norm. Sup., 17:21–
86, 1900. English Translation in Cootner, P. H. (Ed.) The Random Character
of Stock Market Prices, MIT Press, Cambridge, 1964, 17-78.

[22] P. Bak, S. Norrelykke, and M. Shubik. Dynamics of money. Physical Review

E, 60:2528–2532, 1999.

[23] P. Bak, S. Norrelykke, and M. Shubik. Money and Goldstone modes. Quan-

titative Finance, 1:186–190, 2001.

[24] P. Bak, M. Paczuski, and M. Shubik. Price variations in a stock market with

many agents. Physica A, 246:430–453, 1997.

[25] A. V. Banerjee. A simple model of herd behavior. Quarterly Journal of

Economics, 107:797–817, 1992.

[26] E. Basci. Learning by imitation. Journal of Economic Dynamics and Con-

trol, 23:1569–1585, 1999.

[27] W. J. Baumol. Speculation, proﬁtability and stability. Review of Economics

and Statistics, 39:263–271, 1957.

52

[28] A. Beja and M. B. Goldman. On the dynamic behavior of prices in disequi-

librium. Journal of Finance, 35:235–248, 1980.

[29] E. Bennati. Rivista Internazionale di Science Economiche e Commerciali,

35:735, 1988.

[30] O. Biham, Z. F. Huang, O. Malcai, and S. Solomon. Long-time ﬂuctuations
in a dynamical model of stock market indices. Physical Review E, 64:026101,
2001.

[31] F. Black and R. C. Jones. Simplifying portfolio insurance. The Journal of

Portfolio Management, 14:48–51, 1987.

[32] E. Bonabeau, G. Theraulaz, and J. L. Deneubourg. Phase diagram of a

model of self-organizing hierarchies. Physica A, 217:373–392, 1995.

[33] S. Bornholdt. Expectation bubbles in a spin model of markets: Intermittency
from frustation across scales. International Journal of Modern Physics C,
12:667–674, 2001.

[34] J. P. Bouchaud and M. M´ezard. Wealth condensation in a simple model of

economy. Physica A, 282:536–545, 2000.

[35] M. J. Brennan and E.S. Schwartz. Portfolio insurance and ﬁnancial market

equilibrium. Journal of Business, 62:455–472, 1989.

[36] W. A. Brock and C. H. Hommes. Models of complexity in economics and
ﬁnance. In C. Hey, J. M. Schumacher, B. Hanzon, and C. Praagman, editors,
System Dynamics in Economic and Financial Models, pages 3–44. Wiley,
New York, 1997.

[37] W. A. Brock and C. H. Hommes. A rational route to randomness. Econo-

metrica, 65:1059–1095, 1997.

[38] W. A. Brock and C. H. Hommes. Heterogeneous beliefs and bifurcation
routes to chaos in a simple asset pricing model. Journal of Economic Dy-
namics and Control, 22:1235–1274, 1998.

[39] W. A. Brock and C. H. Hommes. Rational animal spirits. In P. J. J. Herings,
A. J. J. Talman, and G. van der Laan, editors, The Theory of Markets, pages
109–137. North Holland, Amsterdam, 1999.

[40] P. M. Brown. Experimental evidence on money as a medium of exchange.

Journal of Economic Dynamics and Control, 20:583–600, 1996.

53

[41] A. Bunde and Havlin S. Fractals and Disordered Systems. Springer, Berlin

Heidelberg, 1996.

[42] R. Carvalho. The dynamics of the linear random Farmer model. Instituto
Superior T´ecnico Lisbon, University College London, 2001. Manuscript.

[43] F. Castiglione and Stauﬀer D. Multi-scaling in the Cont-Bouchaud micro-

scopic stock market model. Physica A, 3000:531–538, 2001.

[44] A. Chakraborti. Market application of the percolation model: Relative price

distribution. International Journal of Modern Physics C, 13:25–29, 2002.

[45] A. Chakraborti and B. Chakrabarti. Statistical mechanics of money: How
saving propensities aﬀects its distribution. European Physical Journal B,
17:167–170, 2000.

[46] D.G Champernowne and F.A. Cowell. Economic Inequality and Income

Distribution. Cambridge University Press, Cambridge UK, 1999.

[47] I. Chang and D. Stauﬀer. Time-reversal asymmetry in Cont-Bouchaud stock

market model. Physica A, 299:547–550, 2001.

[48] I. Chang, D. Stauﬀer, and R. B. Pandey. Asymmetries, correlations and fat
tails in percolation market model. International Journal of Theoretical and
Applied Finance, 5:585–597, 2002.

[49] S. H. Chen, T. Lux, and M. Marchesi. Testing for nonlinear structure in an
’artiﬁcial’ ﬁnancial market. Journal of economic Behaviour and Organiza-
tion, 46:327–342, 2001.

[50] S. H. Chen and C. H. Yeh. Evolving traders and the business school with
genetic programming: A new architecture of the agent-based stock market.
Journal of Economic Dynamics and Control, 25:363–393, 2001.

[51] S. H. Chen and C. H. Yeh. On the emergent properties of artiﬁcial stock
markets: The Eﬃcient Market Hypothesis and the Rational Expectations
Hypothesis. Journal of Economic Behavior and Organization, 49:217–239,
2002.

[52] C. Chiarella, R. Dieci, and L. Gardini. Speculative behaviour and com-
plex asset price dynamics. Journal of Economic Behavior and Organization,
49:173–197, 2002.

[53] S. Cincotti, S. Focardi, M. Marchesi, and M. Raberto. Agent-based simula-

tion of a ﬁnancial market. Physica A, 299, 2001. 319-327.

54

[54] K. J. Cohen, S. F. Maier, R. A. Schwartz, and D. K. Whitcomb. The Mi-
crostructure of Securities Markets. Prentice-Hall, Englewood Cliﬀs New Jer-
sey, 1986.

[55] The Brady Commission. Report of the Presidential Task Force on Market
Mechanisms. U.S. Government Printing Oﬃce, Washington, DC, 1988.

[56] R. Cont and J. P. Bouchaud. Herd behaviour and aggregate ﬂuctuations in

ﬁnancial markets. Macroeconomic Dynamics, 4:170–196, 2000.

[57] H. Dawid. On the convergence of genetic learning in a double auction market.

Journal of Economic Dynamics and Control, 23:1545–1567, 1999.

[58] R. H. Day and W. Huang. Bulls, bears, and market sheep. Journal of

Economic Behavior and Organization, 14:299–329, 1990.

[59] A. De Martino and Marsili M. Statistical mechanics of socio-economic sys-
tems with heterogeneous agents. Journal of Physics A, 39:R465–R540, 2006.

[60] P. DeGrauwe, Dewachter H, and M. J. Embrechts. Exchange Rate Theory:
Chaotic Models of Foreign Exchange Market. Blackwell, Oxford, 1993.

[61] Z. Ding, R. Engle, and C. Granger. A long memory property of stock market
returns and a new model. Journal of Empirical Finance, 1:83–106, 1993.

[62] R. Donangelo, A. Hansen, K. Sneppen, and S. R. Souza. Modelling an

imperfect market. Physica A, 283:469–478, 2000.

[63] R. Donangelo and K. Sneppen. Self-organization of value and demand. Phys-

ica A, 276:572–580, 2000.

[64] A. Drˇagulescu and V. Yakovenko. Statistical mechanics of money. European

Physical Journal B, 17:723–729, 2000.

[65] J. Duﬀy. Learning to speculate: Experiments with artiﬁcial and real agents.

Journal of Economic Dynamics and Control, 25:295 – 319, 2001.

[66] J. Duﬀy and J. Ochs. Emergence of money as a medium of exchange: An
experimental study. American Economic Review, 89:847 – 877, 1999.

[67] C. Dunis and B. eds. Zhou. Nonlinear Modelling of High Frequency Time

Series. Wiley, New York, 1998.

[68] H. Dupois. Reporting on the Li`ege Research. Trends Tendences, 18 Sept.:8,

1997.

55

[69] E. Egenter, T. Lux, and D. Stauﬀer. Finite-size eﬀects in Monte Carlo
simulations of two stock market models. Physica A, 268:250–256, 1999.

[70] G. Ehrenstein. Cont-Bouchaud percolation model including tobin tax. In-

ternational Journal of Modern Physics C, 13:issue 10, 2002.

[71] G. Ehrenstein, F. Westerhoﬀ, and D. Stauﬀer. Tobin tax and market depth.

Quantitative Finance, 5:213–218, 2005.

[72] Z. Eisler and J. Kert´esz. Size matters: Some stylized facts of the market

revisited. European Physical Journal B, 51:145–154, 2006.

[73] J. D. Farmer and S. Joshi. The price dynamics of common trading strategies.

Journal of Economic Behavior and Organization, 49:149–171, 2002.

[74] D. K. Foley. A statistical equilibrium theory of markets. Journal of Economic

Theory, 62:321–345, 1994.

[75] P. de Fontnouvelle. Information dynamics in ﬁnancial markets. Macroeco-

nomic Dynamics, 4:139–169, 2000.

[76] J. Frankel and K. A. Froot. The dollar as an irrational speculative bub-
ble: A table of fundamentalists and chartists. Marcus Wallenberg Papers in
International Finance, 1:27–55, 1986.

[77] J. Frankel and K. A. Froot. Understanding the U.S. dollar in the eighties:
The expectations of chartists and fundamentalists. Economic Record, Special
Issue, December:24–38, 1986.

[78] M. Friedman. Essays in Positive Economics. Chicago University Press,

Chicago, 1953.

[79] A. Gaunersdorfer. Endogenous ﬂuctuations in a simple asset pricing model
with heterogeneous agents. Journal of Economic Dynamics and Control,
24:799–831, 2000.

[80] A. Gaunersdorfer and C. H. Hommes. A nonlinear structural model for
volatility clustering. In G. Teyssire and A. Kirman, editors, Long Memory
in Economics, pages 265–288. Springer, Berlin, 2007.

[81] A. Gaunersdorfer,

C. H. Hommes,

and

gener.
http://ﬁnance2.bwl.univie.ac.at/research/papers/ghw.zip,
Manuscript.

Bifurcation

routes

to

volatility

F. O. O. Wa-
clustering.
2000.

56

[82] C. Georges. Learning with misspeciﬁcation in an artiﬁcial currency market.

Journal of Economic Behaviour and Organisation, 60:70–84, 2006.

[83] J. Goldenberg, J. Libai, S. Solomon, N. Jan, and D. Stauﬀer. Marketing

percolation. Physica A, 284:335–347, 2000.

[84] A. K. Gupta and D. Stauﬀer. Social percolation on inhomogeneous spanning
network. International Journal of Modern Physics C, 11:695–706, 2000.

[85] B. Hayes. Follow the money. American Scientist, 90:400–405, 2002.

[86] T. Hellthaler. The inﬂuence of investor number on a microscopic market
model. International Journal of Modern Physics C, 6:845–852, 1995.

[87] D. Heymann, R. P. J. Perazzo, and A. Schuschny. Learning and con-
tagion eﬀects in transitions between regimes:
Some schematic multi-
agent models. http://www.econ.uba.ar./www/servicios/publicaciones/ jour-
nal2/CONTENTS/heymann/heymann.htm, 2001. Manuscript.

[88] C. H. Hommes. Stochastic consistent expectations equilibria. CeNDEF

Workshop Paper, 2001.

[89] Z. F. Huang. Self-organized model for information spread in ﬁnancial mar-

kets. European Physical Journal B, 16:379–385, 2000.

[90] Z. F. Huang. Stability in the social percolation models for two to four
dimensions. International Journal of Modern Physics C, 11:287–300, 2000.

[91] Z. F. Huang and S. Solomon. Power, Levy, exponetial and Gaussian-like
regimes in autocatalitic ﬁnancial systems. European Physical Journal B,
20:601–607, 2000.

[92] Z. F. Huang and S. Solomon. Finite market size as a source of extreme
wealth inequality and market instability. Physica A, 294:503–513, 2001.

[93] Z. F. Huang and S. Solomon. Stochastic multiplicative processes for ﬁnancial

markets. Physica A, 306:412–422, 2002.

[94] B. Ingrao and G. Israel. The Invisible Hand: Economic Equilibrium in the

History of Science. MIT Press, Cambridge MA, 2000.

[95] G. Iori. Avalanche dynamics and trading friction eﬀects on stock market

returns. International Journal of Modern Physics C, 10:1149–1162, 1999.

57

[96] G. Iori. A microsimulation of traders activity in the stock market: The role of
heterogeneity, agents’ interactions and trade frictions. Journal of Economic
Behavior and Organization, 49:269–285, 2002.

[97] G. Iori and S. Jafarey. Interbank lending, reserve requirements and system-
atic risk. http://137.73.14.173/ giulia/bank23.pdf, 2001. Manuscript.

[98] Arrow K. J. Essays in the Theory of Risk Bearing. North Holland, Amster-

dam, 1971.

[99] R. Jones. The origin and development of media of exchange. Journal of

Political Economy, 84:757–775, 1976.

[100] T. Kaizoji. Complex dynamics of speculative price. Complexitiy Interna-
tional, 6:http://www.csu.edu.au/ci/vol06/kaizoji/kaizoji.html, 1999.

[101] T. Kaizoji. A synergetic approach to speculative price volatility.

IEICE
Transactions on Fundamentals of Electronics, Communications and Com-
puter Sciences, E82-A:1874–1882, 1999.

[102] T. Kaizoji. Speculative bubbles and crashes in stock markets: an interacting-

agent model of speculative activity. Physica A, 287:493–506, 2000.

[103] N. Kaldor. Speculation and economic stability. Review of Economic Studies,

7:1–27, 1939.

[104] M. Kemp. Speculation, proﬁtability and price stability. Review of Economics

& Statistics, 45:175–189, 1963.

[105] G. Kim and H. M. Markowitz. Investment rules, margin and market volatil-

ity. Journal of Portfolio Management, 16:45–52, 1989.

[106] A. Kirman. Epidemics of opinion and speculative bubbles in ﬁnancial mar-
kets. In M. P. Taylor, editor, Money and Financial Markets, pages 354–368.
Blackwell, Cambridge, 1991.

[107] A. Kirman. Ants, rationality, and recruitment. Quarterly Journal of Eco-

nomics, 108:137–156, 1993.

[108] N. Kiyotaki and R. Wright. On money as a medium of exchange. Journal

of Political Economy, 97:924–954, 1989.

[109] R. Kohl. The inﬂuence of the number of diﬀerent stocks on the Levy-Levy-
Solomon model. International Journal of Modern Physics C, 8:1309–1316,
1997.

58

[110] P. Krugman. Geography and Trade. MIT Press, Cambridge, 1993.

[111] L. Kullmann and J. Kert´esz. Crossover to Gaussian behavior in herding
market models. International Journal of Modern Physics C, 12:1211–1215,
2001.

[112] L. Kullmann and J. Kert´esz. Preferential growth: Solution and application

to modelling stock market. Physica A, 299:121–126, 2001.

[113] T. Landes and O. Loistl. Complexity models in ﬁnancial markets. Applied

Stochastic Models and Data Analysis, 8:209–228, 1992.

[114] B. LeBaron. Empirical regularities from interacting long and short memory
investors in an agent based stock market. IEEE Transactions on Evolution-
ary Computation, 5:442–455, 2000.

[115] B. LeBaron. Evolution and time horizons in an agent-based stock market.

Macroeconomic Dynamics, 5:225–254, 2001.

[116] B. LeBaron, W. B. Arthur, and R. Palmer. The time series properties of
an artiﬁcial stock market. Journal of Economic Dynamics and Control,
23:1487–1516, 1999.

[117] M. Levy, H. Levy, and S. Solomon. A microscopic model of the stock market:

Cycles, booms, and crashes. Economics Letters, 45:103–111, 1994.

[118] M. Levy, H. Levy, and S. Solomon. Microscopic simulation of the stock
market: The eﬀect of microscopic diversity. Journal de Physique I, 5:1087–
1107, 1995.

[119] M. Levy, H. Levy, and S. Solomon. New evidence for the power law distri-

bution of wealth. Physica A, 242:90–94, 1997.

[120] M. Levy, H. Levy, and S. Solomon. Microscopic Simulation of Financial

Markets. Academic Press, New York, 2000.

[121] M. Levy, N. Persky, and S. Solomon. The complex dynamics of a simple
stock market model. International Journal of High Speed Computing, 8:93–
113, 1996.

[122] M. Levy and S. Solomon. Dynamical explanation for the emergence of power
law in a stock market. International Journal of Modern Physics C, 7:65–72,
1996.

59

[123] M. Levy and S. Solomon. Power laws are logarithmic Boltzmann laws. In-

ternational Journal of Modern Physics C, 7:595–601, 1996.

[124] P. J. F. de Lima. Nonlinearities and nonstationarities in stock returns. Jour-

nal of Business and Economic Statistics, 16:227–236, 1998.

[125] I. N. Lobato and N. E. Savin. Real and spurious long-memory properties of
stock market data. Journal of Business and Economics Statistics, 16:261–
283, 1998.

[126] Y. Louzoun and S. Solomon. Volatility driven market in a Generalized Lotka-

Volterra formalism. Physica A, 302:220–233, 2001.

[127] T. Lux. Herd behaviour, bubbles and crashes. Economic Journal, 105:881–

896, 1995.

[128] T. Lux. The stable Paretian hypothesis and the frequency of large returns:
An examination of major German stocks. Applied Financial Economics,
6:463–475, 1996.

[129] T. Lux. Time variation of second moments from a noise trader/infection
model. Journal of Economic Dynamics and Control, 22:1–38, 1997.

[130] T. Lux. The socio-economic dynamics of speculative markets: Interacting
agents, chaos, and the fat tails of return distributions. Journal of Economic
Behavior and Organization, 33:143–165, 1998.

[131] T. Lux. Emergent statistical wealth distributions in simple monetary ex-
In A. Chatterjee, S. Yarlagadda, and
change models: A critical review.
B. Chakrabarti, editors, Econophysics of Wealth Distributions. Springer,
Berlin, 2005.

[132] T. Lux and M. Ausloos. Market ﬂuctuations I: Scaling, multiscaling and their
possible origins. In A. Bunde, J. Kropp, and H. J. Schellnhuber, editors, The
science of disasters: climate disruptions, heart attacks, and market crashes.
Springer, Berlin Heidelberg, 2002.

[133] T. Lux and M. Marchesi. Scaling and criticality in a stochastic multi-agent

model of a ﬁnancial market. Nature, 397:498–500, 1999.

[134] T. Lux and M. Marchesi. Volatility clustering in ﬁnancial markets: A micro-
simulation of interacting agents. International Journal of Theoretical and
Applied Finance, 3:67–702, 2000.

60

[135] T. Lux and S. Schornstein. Genetic learning as an explanation of styl-
ized facts of foreign exchange markets. Journal of Mathematical Economics,
41:169–196, 2005.

[136] Markowitz H. M. Simscript: A Simulation Programming Language. Prentice

Hall, Englewood Cliﬀs NJ, 1963.

[137] R. Madhavan. Market microstructures: A survey. Journal of Financial

[138] B. Mandelbrot. The variation of certain speculative prices. Journal of Busi-

Markets, 3:205–258, 2000.

ness, 35:394–419, 1963.

[139] B. Mandelbrot, A. Fisher, and L. Calvet. A multifractal model of asset
returns. Cowles Foundation for Research and Economics, 1997. Manuscript.

[140] R. Marimon, E. McGrattan, and T. J. Sargent. Money as a medium of
exchange in an economy with artiﬁcially intelligent agents. Journal of Eco-
nomic Dynamics and Control, 14:329–373, 1990.

[141] H. M. Markowitz. Stock market simulator sms1: Program description.

Baruch College Working Paper Series 88-24, 1988.

[142] S. Maslov. Simple model of a limit order-driven market. Physica A, 278:571–

578, 2000.

[143] N. F. Morehouse, R. H. Strotz, and S. J. Horowitz. An electro-analog method
Inventory oscillations.

for investigating problems in economic dynamics:
Econometrica, 18:313–328, 1950.

[144] F. Mori and T. Odagaki. Percolation analysis of clusters in random graphs.

Journal of the Physical Society of Japan, 70:2485–2489, 2001.

[145] K. Nagel, J. Esser, and Rickert M. Large-scale traﬃc simulations for trans-
portation planning. In Stauﬀer D., editor, Annual Review of Computational
Physics VII, pages 151–202. World Scientiﬁc, Singapore, 2000.

[146] W. T. Newlyn. The Phillips/Newlyn hydraulic model. Yorshire Bulletin of

Economic and Social Research, 2:111–127, 1950.

[147] M. O’Hara. Market Microstructure Theory. Blackwell, Cambridge, 1995.

[148] A. Pagan. The econometrics of ﬁnancial markets. Journal of Empirical

Finance, 3:15–102, 1996.

61

[149] R. G. Palmer, W. B. Arthur, J. H. Holland, B. LeBaron, and P. Tayler.
Artiﬁcial economic life: A simple model of stock market. Physica D, 75:264–
274, 1994.

[150] A. W. Phillips. Mechanical models in economic dynamics. Economica,

17:283–305, 1950.

[151] V. Plerou, P. Gopikrishnan, X. Gabaix, and H. E. Stanley. Quantifying stock
price response to demand ﬂuctuations. Physica Review E, 66:027104, 2002.

[152] A. Ponzi and Y. Aizawa. Criticality and punctuated equilibrium in a spin
system model of a ﬁnancial market. Chaos, Solitons & Fractals, 11-11:1739–
1746, 2000.

[153] A. Proykova and D. Stauﬀer. Social percolation and the inﬂuence of mass

media. Physica A, 312:300–304, 2002.

[154] J. B. Ramsey. On the existence of macro variables and of macro relationships.
Journal of Economic Behavior and Organisation, 30:275–299, 1996.

[155] P. Richmond and S. Solomon. Power laws are disguised Boltzmann laws.

International Journal of Modern Physics C, 12:333–343, 2001.

[156] B. R. Routledge. Adaptive learning in ﬁnancial markets. The Review of

Financial Studies, 12:1165–1202, 1999.

[157] B. R. Routledge. Genetic algorithm learning to choose and use information.

Macroeconomic Dynamics, 5:303–325, 2001.

[158] M. Sahimi. Applications of Percolation Theory. Taylor and Francis, London,

1994.

[159] E. Samanidou. Portfolio-Insurance-Strategien und Finanzmarktvolatilit¨at:
Das Mikrosimulationsmodell von Kim und Markowitz. Diploma thesis, De-
partment of Economics, University of Bonn, 2000.

[160] T. C. Schelling. Dynamic models of segregation. Journal of Mathematical

Sociology, 1:143–186, 1971.

[161] T. C. Schelling. Micromotives and Macrobehavior. W. W. Norton, New

York, 1978.

[162] C. Schulze. The domino eﬀect for markets. International Journal of Modern

Physics C, 13:207–208, 2002.

62

[163] G. W. Schwert. Stock volatility and the crash of ‘87. Review of Financial

Studies, 3:77–102, 1990.

[164] L. R. da Silva and D. Stauﬀer. Ising-correlated clusters in the Cont-Bouchaud

stock market model. Physica A, 294:235–238, 2001.

[165] J. Silver, E. Slud, and K. Takamoto. Statistical equilibrium wealth dis-
tributions in an exchange economy with stochastic preferences. Journal of
Economic Theory, 106:417–435, 2002.

[166] S. Sinha and S. Raghavendra. Hollywood blockbusters and long-tailed dis-

tributions. European Physical Journal B, 42:293–296, 2004.

[167] S. Solomon. Generalized Lotka Volterra (GLV) models of stock markets.
In G. Ballot and Weisbuch G., editors, Applications of Simulation to Social
Sciences, pages 301–322. Hermes Science, Paris, 2000.

[168] S. Solomon and M. Levy. Spontaneous scaling emergence in generic stochas-
tic systems. International Journal of Modern Physics C, 299:188–197, 1996.

[169] S. Solomon and R. Richmond. Power laws of wealth, market order volumes

and market returns. Physica A, 299:188–197, 2001.

[170] S.

Solomon

and

G. Weisbuch.

Social

percolation.

http://xxx.lanl.gov/abs/adap-org/9909001, 1999.

[171] S. Solomon, G. Weisbuch, Arcangelis L. de, N. Jan, and D. Stauﬀer. Social

percolation models. Physica A, 277:239–247, 2000.

[172] D. Sornette and W.-X. Zhou. The US 2000-2002 market descent: how much

longer and deeper? Quantitative Finance, 2:468–481, 2002.

[173] A. M. C. de Souza and C. Tsallis. Student’s t- and r-distributions: Uniﬁed
derivation from an entropic variational principle. Physica A, 236:52–57, 1997.

[174] M. H. R. Stanley, L. H. N. Amaral, S. V. Buldyrev, S. Havlin, H. Leschorn,
P. Maass, M. A. Salinger, and H. E. Stanley. Can statistical physics con-
tribute to the science of economics? Fractals, 4:415–425, 1996.

[175] D. Stauﬀer. Finite-size eﬀects in lux-marchesi and other microscopic mar-
ket models. http://ciclamino.dibe.unige.it/wehia/papers/stauﬀer.zip, 1999.
WEHIA e-print.

[176] D. Stauﬀer. Percolation models of ﬁnancial market dynamics. Advances in

Complex Systems, 4:19–27, 2001.

63

[177] D. Stauﬀer and A. Aharony. Introduction to Percolation Theory. Taylor and

Francis, London, 1994.

[178] D. Stauﬀer and N. Jan. Percolation simulation: Large lattices, varying
dimensions. In D. Stauﬀer, editor, Annual Reviews of Computational Physics
VIII, pages 287–300. World Scientiﬁc, Singapore, second edition, 2000.

[179] D. Stauﬀer and J. P. Radomski. Scaling in the Donangelo-Sneppen model

for evolution of money. Physica A, 291:583–586, 2001.

[180] D. Stauﬀer and D. Sornette. Self-organized percolation model for stock

market ﬂuctuation. Physica A, 271:496–506, 1999.

[181] G. J. Stigler. Public regulation of the securities market. Journal of Business,

37:117–142, 1964.

[182] G. G. Szpiro. The emergence of risk aversion. Complexity, 2:31–39, 1997.

[183] H. Takayasu, H. Miura, T. Hirabayashi, and K. Hamada. Statistical proper-
ties of deterministic threshold elements - the case of market price. Physica
A, 184:127–134, 1992.

[184] D. Tiggemann. Simulation of percolation on massively-parallel computers
(and phd thesis 2006). International Journal of Modern Physics C, 12:871–
878, 2001.

[185] R. Toral and C. J. Tessone. Finite size eﬀects in the dynamics of opinion

formation. Communications in Computational Physics, 2:177–195, 2007.

[186] N. Vandewalle and M. Ausloos. Coherent and random sequences in ﬁnancial

ﬂuctuations. Physica A, 246:454–459, 1997.

[187] A. de Vany and C. Lee. Quality signals in information cascades and the
dynamics of the distribution of Motion Picture box oﬃce revenues. Journal
of Economic Dynamic Control, 25:593–614, 2001.

[188] A. de Vany and D. Wall. Box-Einstein dynamics and adaptive contracting

in the motion picture industry. Economic Journal, 106:1493–1514, 1996.

[189] C. G. de Vries. Stylized facts of nominal exchange rate returns. In F. van der
Ploeg, editor, The Handbook of International Macroeconomics, pages 348–
389. Blackwell, Oxford, 1994.

[190] W. Weidlich. Physics and Social Science - The Approach of Synergetics.

Physics Reports, 204:1–163, 1991.

64

[191] W. Weidlich. Socio-Dynamics: A Systematic Approach to Mathematical

Modelling in the Social Science. Taylor and Francis, London, 2002.

[192] G. Weisbuch and S. Solomon. Self-organized percolation and critical sales
International Journal of Modern Physics C, 11:1263–1272,

[193] G. Weisbuch and D. Stauﬀer. Hits and ﬂops dynamics. Physica A, 287:563–

[194] G. Weisbuch and D. Stauﬀer. Adjustment and social choice. Physica A,

ﬂuctuations.
2000.

576, 2000.

323:651–662, 2003.

[195] G. Weisbuch, D. Stauﬀer, and Solomon S. Social percolators and self-
In A. Kirman and J. B. Zimmermann, editors, Eco-
organized criticality.
nomics with Heterogeneous Interacting Agents, Lecture Notes in Economics
and Mathematical Systems, pages 43–55. Springer, Berlin Heidelberg, 2001.

[196] R. Weron. Levy-stable distributions revisited: Tail index above 2 does not
International Journal of Modern Physics C,

exclude levy stable regime.
12:209–223, 2001.

[197] F. Westerhoﬀ. Heterogeneous traders and the Tobin tax. Journal of Evolu-

tionary Economics, 13:53–70, 2003.

[198] A. Yasutomi. The emergence and collapse of money. Physica A, 82:180–194,

1995.

[199] C. H. Yeh. The inﬂuence of market size in an artiﬁcial stock market: The ap-
proach based on genetic programming. I-Shou University, 2001. Manuscript.

[200] M. Youssefmir and A. Huberman. Clustered volatility in multiagent dynam-
ics. Journal of Economic Behavior and Organization, 32:101–118, 1997.

[201] M. Youssefmir, B. A. Hubermann, and T. Hogg. Bubbles and market crashes.

Computational Economics, 12:97–114, 1998.

[202] E. C. Zeeman. On the unstable behaviour of stock exhanges. Journal of

Mathematical Economics, 1:39–49, 1974.

[203] Y. C. Zhang. Toward a theory of marginally eﬃcient markets. Physica A,

269:30–44, 1999.

[204] E. Zschischang. Mikrosimulationsmodelle f¨ur Finanzm¨arkte: Das Modell
von Levy und Solomon. Diploma thesis, University of Bonn, Department of
Economics, University of Bonn, 2000.

65

[205] E. Zschischang and T. Lux. Some new results on the Levy, Levy and Solomon

microscopic stock market model. Physica A, 291:563–573, 2001.

66

