6
0
0
2
 
r
a

M
 
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
7
0
0
3
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Emergence of cooperation induced by preferential learning

Jie Ren1, Wen-Xu Wang2, Gang Yan3, and Bing-Hong Wang2∗
1Department of Physics,
2Department of Modern Physics,
3Department of Electronic Science and Technology,
University of Science and Technology of China,
Hefei, 230026, PR China
(Dated: February 2, 2008)

The evolutionary Prisoner’s Dilemma Game (PDG) and the Snowdrift Game (SG) with preferen-
tial learning mechanism are studied in the Barab´asi-Albert network. Simulation results demonstrate
that the preferential learning of individuals remarkably promotes the cooperative behavior for both
two games over a wide range of payoﬀs. To understand the eﬀect of preferential learning on the
evolution of the systems, we investigate the time series of the cooperator density for diﬀerent pref-
erential strength and payoﬀs.
It is found that in some speciﬁc cases two games both show the
1/f -scaling behaviors, which indicate the existence of long range correlation. We also ﬁgure out
that when the large degree nodes have high probability to be selected, the PDG displays a punctu-
ated equilibrium-type behavior. On the contrary, the SG exhibits a sudden increase feature. These
temporary instable behaviors are ascribed to the strategy shift of the large degree nodes.

PACS numbers: 87.23.Kg, 02.50.Le, 87.23.Ge, 89.75.CC

I.

INTRODUCTION

Cooperation is ubiquitous in real world, ranging from
biological systems to economic and social systems [1].
However, the unselﬁsh, altruistic actions apparently con-
tradict Darwinian selection. Thus, understanding the
conditions for the emergence and maintenance of co-
operative behavior among selﬁsh individuals is a cen-
tral problem [2]. Game theory together with its ex-
tensions [3, 4, 5, 6, 7, 8], considered to be an impor-
tant approach, provides a useful framework for inves-
tigating this problem. Two simple games, Prisoners’
Dilemma Game (PDG) [9] and Snowdrift Game (SG)
[10], as metaphors for characterizing the evolution of
cooperative behavior have drawn much attention from
not only social but also biological and physical scientists
[11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25].
In the original PDG, each of two players may chose ei-
ther to cooperate or defect in any one encounter. If they
both cooperate, both obtain a payoﬀ of R, whereas mu-
tual defection results in pay-oﬀ P for both players. If one
player defects while the other cooperates, defector gains
the biggest pay-oﬀ T , while cooperator gets S. The rank-
ing of four pay-oﬀ values is T > R > P > S. The SG
is a game of much biologically interesting. This game
diﬀers from the PDG mainly in the order of P and S, as
T > R > S > P , which are more favorable to sustain
cooperative behavior.

However, in these two games, the unstable coopera-
tive behavior is opposite to the observations in the real
world. This disagreement thus motivates a variety of
suitable extensions of basic model rules to explain the

∗Electronic address: bhwang@ustc.edu.cn

emergence of cooperation. Some previous works have
suggested that the introduction of “tit-for-tat” [6, 14]
strategy can remarkably enhance the cooperative behav-
ior. More recently, Nowak and May [13] found that the
PDG with simple spatial structure can induce the emer-
gence of cooperation, and in particular, spatial chaos
is observed. In contrast, the work of Hauert and Doe-
beli [23] demonstrates the spatial structure often inhibits
the evolution of cooperation in the SG. Inspired by the
idea of spatial game, much attention has been given to
the interplay between evolutionary cooperative behav-
ior and the underlying structure [16, 17, 18, 19, 22, 25].
Since the surprising discovery of “small world” [26] and
“scale-free” [27] structural properties in real networked
systems, evolutionary games are naturally considered on
the networks with these two kinds of structural features
[16, 20, 21, 22, 25]. Interestingly, it is found that compar-
ing with the square lattices, Scale-free networks provide
a unifying framework for the emergency of cooperation
[25].

In the two games with network structure, such as
square lattices (spatial structure), small world and scale-
free structure, players interact only with their immediate
neighbors. In each round, the score of each individual is
the sum of the payoﬀs in the encounters with its neigh-
bors. At the next generation, all the individuals could up-
date their strategies (cooperate or defect) synchronously
according to either the deterministic rule introduced by
Nowak and May [13] or the stochastic evolutionary rule
by Szab´o and T˝oke [17].

In this paper, we focus on the PDG and SG on scale-
free networks mainly according to the stochastic update
rules. However, we argue that such as in the social sys-
tem, individual may not completely randomly choose a
neighbor to learn from it. “Rich gets richer” is a common
feature in social and natural system, which reveals the ex-

istence of preferential mechanism. It is indeed the pref-
erential attachment mechanism of Barab´asi and Albert
model (BA for short) [27] leads to the scale-free struc-
tural property in good accord with the empirical obser-
vations. Thus, in the present work, we present a prefer-
ential learning rule, the probability of which is governed
by a single parameter, for better mimicking the evolu-
tion of real world system. The probability of choosing
a neighbor for each individual depends on the degree of
that neighbor. This assumption takes into account that
the status of individuals can be reﬂected by the degree
of them in various communities in nature and society,
e.g. the leader usually interacts with large quantities of
individuals.
Interestingly, we ﬁnd that the preferential
learning mechanism promotes the cooperative behavior
of both the PDG and SG. Several attractive properties for
some speciﬁc parameter values are observed, such as the
1/f -like noise of evolutionary cooperator density for both
two games, which indicates the long range correlation of
cooperation. In the SG, for some speciﬁc cases, the de-
gree of cooperation displays a punctuated equilibrium-
type behavior instead of steady state. In contrast, the
PDG exhibits an absolutely diﬀerent property of sudden
jumps of cooperation. These two distinct behaviors are
both attributed to the eﬀect of leaders, i.e. the individ-
uals with large connectivity.

The paper is arranged as follows. In the following sec-
tion we describe the model in detail, in Sec. III simu-
lations and analysis are provided for both the PDG and
SG , and in Sec. IV the work is concluded.

II. THE MODEL

We ﬁrst construct the scale-free networks using the BA
model which is considered to be the most simple and
general one. Starting from m0 fully connected nodes,
one node with m links is attached at each time step in
such a way that the probability Πi of being connected
to the existing node i is proportional to the degree ki
of that node, i.e., Πi = ki/ Pj kj with summation over
all the existing nodes. Here, we set m = m0 = 2 and
network size N = 5000 for all simulations. The degree
distribution of BA networks follows a power law P (k) ∼
k−3[27].

We consider the evolutionary PDG and SG on the net-
works. Without losing generality, we investigate the sim-
pliﬁed games with a single payoﬀ parameter following
previous works [13, 17, 23]. Figure (1) illustrates the
encounter payoﬀs of both the PDG and SG. Each indi-
vidual is placed on a node of the network and plays the
games only with their immediate neighbors simultane-
ously. The total payoﬀ of each player is the sum over all
its encounters.

During the evolutionary process, each player is allowed
to learn from one of its neighbors and update its strategy
in each round. As mentioned early, each player chooses a
neighbor according to the preferential learning rule, i.e.,

2

FIG. 1: The payoﬀs: In the PDG, when two cooperators (C)
encounter, both earn 1. While two defectors (D) encounter,
both earn 0. When a cooperator encounters a defector, the
defector earns b and the cooperator 0. In the SG, it is the
same as PDG when two cooperators or defectors encounter.
However, when a cooperator meets a defector the cooperator
scores 1 − r and the defector scores 1 + r.

the probability Pi→j of i selecting a neighbor j is

Pi→j =

kα
i
Pj kα
j

,

(1)

where α is a tunable parameter and the sum runs over
the neighbors of i. One can see when α equals zero, the
neighbor is randomly selected so that the game is re-
duced to the original one. While in the case of α > 0,
the individuals with large degree have advantages to be
selected; Otherwise, the small degree individuals have
larger probability to be selected. In social and natural
systems, some individuals with high status and reputa-
tion may have much stronger inﬂuence than others and
the status of individuals can be reﬂected by the degree of
them. Thus, the introduction of the preferential learning
intends to characterize the eﬀect of inﬂuential individuals
on the evolution of cooperation. In parallel, we also in-
vestigate the performance of the systems with tendency
of learning from the individuals with small degree.

After choosing a neighbor y, the player x will adopt
the coplayer’s strategy with a probability depending on
the normalized total payoﬀ diﬀerence presented in Ref.
[21] as

W =

1
1 + exp[(Mx/kx − My/ky)/T ]

,

(2)

where Mx and My are the total incomes of player x and
y, and T characterizes the noise eﬀects,including ﬂuctu-
ations in payoﬀs, errors in decision, individual trials, etc.
This choice of W takes into account the fact of bounded
rationality of individuals in sociology and reﬂects nat-

3

 

 

 

 r=0.2  

 r=0.5  

 r=0.7  

 r=0.9

 r=0.4  

 r=0.6  

 r=0.8  

 r=1

C

0.5

1.0

0.9

0.8

0.7

0.6

0.4

0.3

0.1

0.0

0.2

 b=1.05

 b=1.0

 b=1.1

 b=1.2

 b=1.3

 

C

0.6

1.2

1.0

0.8

0.4

0.2

0.0

-10

-5

0

5

10

-10

-5

0

5

10

FIG. 2:
PDG as a function of parameter α for diﬀerent value of b.

(color online). The cooperator density rhoC of the

FIG. 3: (color online). The cooperator density ρC of the SG
as a function of parameter α for diﬀerent value of r.

ural selection based on relative ﬁtness in terms of evo-
lutionism. The ratio of total income of individual and
its degree, i.e., Mx/kx denotes the normalized total pay-
oﬀ. This normalization avoids an additional bias from
the diﬀerent degree of nodes.
In the next section, we
perform the simulations of the PDG and SG respectively
and our goal is to ﬁnd how the preferential learning aﬀect
the evolutionary cooperative behaviors of both PDG and
SG.

III. SIMULATION RESULTS

The key quantity for characterizing the cooperative be-
havior of the system is the density of cooperators ρC.
Hence, we ﬁrst investigate ρc as a function of the tunable
parameter α for diﬀerent payoﬀ parameter b in the PDG,
as shown in Fig. 2. The simulation results were obtained
by averaging over last 10000 time steps of entire 20, 000
time steps. Each data point results from an average over
20 simulations for the same type of network structure.
In the initial state, the strategies of C and D are uni-
formly distributed among all the players. We ﬁgure out
that, comparing with the case of no preferential learning,
i.e.,α = 0, the cooperation is remarkably promoted not
only for positive value of α, but also for negative α in
a wide range of b. For negative α, the ρc monotonously
increases with the decrease of α and ﬁnally ρc reaches a
upper limit for very small α. In contrast, in the case of
positive α, we ﬁnd that ρC increases dramatically and
there exists a maximal value of ρc, which indicates that
although the leaders with large degree play a key role in
the cooperation, very strong inﬂuence of leaders will do
harm to the persistence of cooperation and make indi-
viduals to be selﬁsh. One can also ﬁnd that the larger
the value of b, the larger the value of α corresponding to

the maximal ρc. Moreover, an interesting phenomenon
is observed in Fig. 2, that is when b is small, positive
α leads to better cooperative behavior than the negative
one; However, for large b, the system performs better
when choosing negative α. These results imply that if the
income of defectors is only little more than that of coop-
erators, the leader’s eﬀect will considerably enhances the
cooperation; While if the selﬁsh behavior is encouraged
in the system (large b), the inﬂuential individuals will
leads to the imitation of selﬁsh behavior and reduce the
cooperator density in a certain extent. On the contrary,
restriction of leader’s inﬂuence (negative α decreases the
selected probability of large degree individuals by their
neighbors) results in better cooperation.

In parallel, we investigate the eﬀect of preferential
learning upon the SG. The simulation results are demon-
strated in Fig. 3. Similar to the PDG, ρc is improved
by the introduction of preferential learning for nearly the
entire range of r from 0 to 1. In both sides of α = 0,
ρc reaches an upper limit, which means that in the case
of strong leader’s inﬂuence or without leaders, coopera-
tion can be promoted to the highest level for the wide
middle range of b. Contrary to the PDG, for very large
r, the system still performs cooperative behavior, which
is attributed to the fact that the rule of SG favors the
cooperators, that is the cooperators yet gain payoﬀ 1 − r
when meeting defectors. Combining the above simula-
tion results of both the PDG and SG, we can conclude
that the preferential learning mechanism indeed plays an
important role in the emergence of cooperation.

In the following, we analyze the time series of the coop-
erator density to give detailed description of the systems’
evolutionary behavior. We ﬁrst study the PDG for nega-
tive value of parameter α. Surprisingly, for some speciﬁc
values of b and α, 1/f -like noise is found. A prototyp-
ical example is exhibited in Fig. 4. The 1/f -like noise

4

 

 

 

 

0.8

0.7

0.6

0.5

0.4

0.2

-8

10

-10

10

-12

10

-14

10

C

m
u
r
t
c
e
p
s
 
r
e
w
o
p

 

 

1.0

0.8

C

0.6

0.4

0.2

0.0

m
u
r
t
c
e
p
s
 
r
e
w
o
p

-8

10

-10

10

-12

10

-14

10

0.3

(a)

(a)

0

5000

10000

15000

20000

0

5000

10000

15000

20000

time step

 

time step

 

 b=1.0;   = - 1

  =   5;  r =0.5

(b)

 slope=1.06

(b)

 slope=0.94

-3

-2

-1

-3

-2

-1

10

10

10

10

10

10

frequency

frequency

(a) Time series of cooperator density rhoC of the
FIG. 4:
PDG for b = 1.0 and α = −1. (b) Power spectrum analysis
of (a).

FIG. 5: (a) Time series of cooperator density rhoC of the SG
for r = 0.5 and α = −5. (b) Power spectrum analysis of (a).

is observed frequently in real-world systems, including
healthy physiologic systems [28, 29, 30], economical sys-
tems [31, 32], as well as traﬃc systems [33]. However,
as far as we know, 1/f pattern hasn’t been reported in
the study of evolutionary games. The 1/f noise denotes
that the power spectrum of time series varies as a power-
law S(f ) ∼ f −φ with the slope φ = 1. The spectrum
exponent φ characterizes the nature of persistence or the
correlation of the time series. φ = 2 indicates zero corre-
lation associated with Brownian motion, where as φ = 0
corresponds to a completely uncorrelated white noise.
φ > 2 indicates positive correlation and persistence i.e.,
if the process was moving upward (downward) at time t,
it will tend to continue to move upward (downward) at
future times t′; φ < 2 represents negative correlation and
anti-persistence. The intermediate case, S(f ) ∼ f −φ, is a
“compromise” between the small-time-scale smoothness
and large-time-scale roughness of Brownian noise. Figure
4 (a) shows the time evolution for b = 1.0 and α = −1,
i.e. the case of restriction of leader’s inﬂuence. In this
case, the density of cooperators remains stable with fre-
quently ﬂuctuations around the average value. Figure 4
(b) is the power spectrum analysis of the time series of
cooperator density. A prototypical 1/f -like noise is found
with the ﬁtted slope φ = 1.06. This result indicates when
the small degree individuals have large probability to be
followed, i.e., suppress the inﬂuential leader’s eﬀect, the
nontrivial long range correlation of evolutionary cooper-
ative behavior emerges. The similar phenomenon is also
observed in the SG for the case of negative α, as shown
in Fig. 5. The emergence of the 1/f scaling is associ-
ated with the parameter values α = −1 and r = 0.5.
The discovered 1/f noise for both two games is partly
ascribed to the lack of inﬂuence of leaders. Suppose that

if the individuals with large connectivity are chosen with
large probability, their strategy will be easily followed by
a large number of persons, because those leaders usually
gain very high income. Since the inﬂuential ones only
take the minority, the evolutionary cooperative behav-
ior will mainly determined by the minority. Besides, the
strategies of those leaders are usually ﬁxed due to their
very high score, the long range correlation of the ﬂuctu-
ation of cooperator density is broken.

Then we investigate the evolutionary behavior of both
the SG and PDG in the case of positive α. For the SG,
when the parameter α is close to zero, for arbitrary b, the
level of cooperation remains stable with relatively small
ﬂuctuations around the average value. This property is
remarkably changed for large value of α, which means the
inﬂuence of leaders becomes strong. As shown in Fig. 6,
for α = 5 and r = 0.5, the equilibrium is punctuated
by sudden drops of cooperator density. After a sudden
drop, the cooperation level ρC will gradually increase un-
til ρC reaches the average value. The occurrence of these
punctuated equilibrium-type behavior is ascribed to the
strong inﬂuence of a small amount of leaders. As we
have mentioned, the leader nodes usually get large pay-
oﬀs, thus they tend to hold their own strategies and are
not easily aﬀected by their neighbors. However, those
inﬂuential individuals still have small probability to fol-
low their neighbors’ strategies. If an event that a leader
shift his strategy to defector occasionally happens, the
successful defector strategy will rapidly spread from the
leader to his vicinities. Due to the connection heterogene-
ity of the scale-free networks, i.e., the leaders have large
amount of neighbors, the imitation of a successful self-
ish behavior of the leader triggers the rapidly decrease
of cooperator density. After the occurrence of a sud-
den drop, defectors become the majority and the selﬁsh

 

 

r=0.5;  =5

0

50000

100000

150000

200000

time step

FIG. 6: The time evolution of cooperator density of the SG
with r = 0.5, α = 5 exhibits the punctuated equilibrium-type
behavior.

 b=1.5;  =1

c

0.5

0.8

0.7

0.6

0.4

0.3

0.2

0.15

0.10

C

0.05

0.00

0

2000

4000

6000

8000

10000

time step

FIG. 7: The sudden increase of cooperator density of the
PDG with b = 1.5, α = 1.

leader nearly gain nothing. Then under the inﬂuence of

 

 

5

the other leaders with cooperate strategies, the coopera-
tor density will slowly recover to the steady state.

The evolutionary behavior of the PDG for the posi-
tive α also exhibits nontrivial feature as shown in Fig.
7. Contrast to the SG, the cooperation level shows some
sudden increases. The mechanism that induces the tem-
porary instability of cooperator density is the same as
that of the sudden drops of the SG. The strategy shift
of inﬂuential nodes plays the main role in the occurrence
of the sudden increase. Opposite to the SG, the payoﬀ
matrix of the PDG favors the defect behavior, thus the
cooperation level is quite low. An occasional strategy
shift from defect to cooperate of a leader will lead to the
imitation of its neighbors and a sudden increase occurs.
However, the high cooperator density is instable in the
PDG for large b, hence the sudden increase will rapidly
decrease to the average value.

IV. CONCLUSION AND DISCUSSION

We have investigated the cooperative behavior of the
evolutionary games resulting from the preferential mech-
anism. Comparing with the cases of random selection,
i.e., α = 0, preferentially selecting large degree nodes or
small degree ones can promote the cooperator density of
both the PDG and the SG over a wide range of payoﬀs.
For the cases of negative value of α, the systems perform
the behavior of long range correlation, which is quanti-
ﬁed by the 1/f scaling of power spectrum. Interestingly,
in the case of positive value of α, i.e., the large degree
nodes have high probability to be selected for imitation,
the SG exhibits a punctuated equilibrium-type behavior
which is qualiﬁed by the occasional occurrence of sudden
drops. In contrast to the SG, the PDG shows temporary
instable behavior with the existence of sudden increase.
The mechanism that leads to the instabilities of cooper-
ation for both games are the strategy shift of inﬂuential
nodes and the imitation of their neighbors. The insta-
ble behavior indicates that the strong inﬂuence of leader
individuals will do harm to the evolutionary cooperative
behavior of the systems. The present work implies that
the existence of the preferential learning mechanism plays
an important role in the emergence of cooperation in the
heterogeneous networked systems.

[1] A. M. Colman, Game Theory and its Applications in the
Social and Biological Sciences (Butterworth-Heinemann,
Oxford, 1995).

15 (1973).

[2] R. Dawkins, The Selﬁsh Gene (Oxford University Press,

New York, 1984).

[5] J. Maynard Smith and G. Price, Nature (London) 246,

[6] R. Axelrod, The Evolution of Cooperation (Basic books,

Oxford, 1989).

[3] J. von Neumann and O. Morgenstern, Theory of Games
and Economic Behaviour (Princeton University Press,
Princeton, 1944).

[4] J. Nash, Econometrica 18, 155 (1950).

[7] J. Hofbauer and K. Sigmund, Evolutionary Games
and Population Dynamics (Cambridge University Press,
Cambridge, U.K., 1998).

[8] C.

Hauert,
on

torials

“Virtuallabs:
evolutionary

Interactive

tu-
theory”,

game

http://www.univie.ac.at/virtuallabs.

[9] R. Axelrod and W. D. Hamilton, Science 211, 1390

[23] C. Hauert and M. Doebeli, Nature 428, 643 (2004).
[24] M. Doebeli, C. Hauert and T. Killingback, Science 306,

[10] R. Sugden, The Economics of Rights, Co-operation and

[25] F. C. Santos and J. M. Pacheco, Phys. Rev. Lett. 95,

Welfare (Blackwell, Oxford, U.K., 1986).

[11] P. E. Turner and L. Chao, Nature (London) 398, 441

[26] D. J. Watts and S. H. Strogatz, Nature (London) 393,

859 (2004).

098104 (2005).

440 (1998).

6

(1981).

(1999).

(1992).

(1993).

(2002).

[12] P. E. Turner and L. Chao, Am. Nat. 161, 497 (2003).
[13] M. Nowak and R. M. May, Nature (London) 359, 826
(1992); Int. J. Bifurcation Chaos Appl. Sci. Eng. 3, 35
(1993).

[14] M. Nowak and K. Sigmund, Nature (London) 355, 250

[15] M. Nowak and K. Sigmund, Nature (London) 364, 56

[16] B. J. Kim, A. Trusina, P. Holme, P. Minnhagen, J. S.
Chung, and M. Y. Choi, Phys. Rev. E 66, 021907 (2002).

[17] G. Szab´o and C. T¨oke, Phys. Rev. E 58, 69 (1998).
[18] G. Szab´o and C. Hauert, Phys. Rev. Lett. 89, 118101

[19] G. Szab´o and C. Hauert, Phys. Rev. E 66, 062903 (2002).
[20] G. Szab´o and J. Vukov, Phys. Rev. E 69, 036107 (2004).
[21] J. Vukov and G. Szab´o, Phys. Rev. E 71, 036133 (2005).
[22] C. Hauert and G. Szab´o, Am. J. Phys. 73, 405 (2005).

[27] A.-L. Barab´asi and R. Albert, Science 286, 509 (1999).
[28] C.-K. Peng, S. Havlin, H.E. Stanley, and A.L. Gold-

berger, Chaos 5, 82 (1995).

[29] P.C. Ivanov, L.A.N. Amaral, A.L. Goldberger, S. Havlin,
M.G. Rosenblum, Z.R. Struzik, and H.E. Stanley, Nature
(London) 399, 461 (1999).

[30] L.A.N. Amaral, P.C. Ivanov, N. Aoyagi, I. Hidaka, S.
Tomono, A.L. Goldberger, H.E. Stanley, and Y. Ya-
mamoto, Phys. Rev. Lett. 86, 6026 (2001).

[31] R. F. Voss, 1/f noise and fractals in Economic time series

(Springer-Verlag, 1992).

[32] P. Bak, How Nature Works (Oxford University Press,

[33] B. Tadi´c, S. Thurner, and G. J. Rodgers, Phys. Rev. E

Oxford, 1997).

69, 036102 (2004)

