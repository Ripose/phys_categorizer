5
0
0
2
 
t
c
O
 
4
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
3
4
1
0
1
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Vertex similarity in networks

E. A. Leicht, Petter Holme, and M. E. J. Newman
Department of Physics, University of Michigan, Ann Arbor, MI 48109, U.S.A.

We consider methods for quantifying the similarity of vertices in networks. We propose a measure
of similarity based on the concept that two vertices are similar if their immediate neighbors in the
network are themselves similar. This leads to a self-consistent matrix formulation of similarity that
can be evaluated iteratively using only a knowledge of the adjacency matrix of the network. We test
our similarity measure on computer-generated networks for which the expected results are known,
and on a number of real-world networks.

PACS numbers: 89.75.Fb, 89.75.Hc

I.

INTRODUCTION AND BACKGROUND

The study of networked systems, including computer
networks, social networks, biological networks, and oth-
ers, has attracted considerable attention in the recent
physics literature [1, 2, 3]. A number of structural prop-
erties of networks have been the subject of particularly
intense scrutiny, including the lengths of paths between
vertices [4, 5, 6, 7], degree distributions [8, 9, 10], com-
munity structure [11, 12, 13, 14], and various measures
of vertex centrality [4, 15, 16, 17].

Another important network concept that has received
comparatively little attention is vertex similarity. There
are many situations in which it would be useful to be able
to answer questions such as “How similar are these two
vertices?” or “Which other vertices are most similar to
this vertex?” Of course, there are many senses in which
two vertices can be similar. In the network of the World
Wide Web, for instance, in which vertices represent Web
pages, two pages might be considered similar if the text
appearing on them contains many of the same words.
In a social network representing friendship between indi-
viduals, two people might be considered similar if they
In
have similar professions, interests, or backgrounds.
this paper we consider ways of determining vertex simi-
larity based solely on the structure of a network. Given
only the pattern of edges between vertices in a network,
we ask, can we deﬁne useful measures that tell us when
two vertices are similar? Similarity of this type is some-
times called structural similarity, to distinguish it from
social similar, textual similarity, or other similarity types.
It is a basic premise of research on networks that the
structure of a network reﬂects real information about the
vertices the network connects, so it appears reasonable
that meaningful structural similarity measures might ex-
ist. Here we show that indeed they do and that they can
return useful information about networks.

The problem of quantifying similarity between vertices
in a network is not a new one. The most common ap-
proach in previous work has been to focus on so-called
structural equivalence. Two vertices are considered struc-
turally equivalent if they share many of the same network
neighbors. For instance, it seems reasonable to conclude
that two individuals in a social network have something

in common if they share many of the same friends. Let Γi
be the neighborhood of vertex i in a network, i.e., the set
of vertices that are directly connected to i via an edge.
Then the number of common friends of i and j is

σunnorm =

Γi
|

Γj

,
|

∩
indicates the cardinality (i.e., number of ele-
, for instance, is simply
|

where
ments in) the set x, so that
Γi
|
equal to the degree of vertex i.

x
|
|

(1)

The quantity σunnorm can be regarded as a rudimentary
measure of similarity between i and j. It is, however, not
entirely satisfactory. It can take large values for vertices
with high degree even if only a small fraction of their
neighbors are the same, and in many cases this runs con-
trary to our intuition about what constitutes similarity.
Commonly therefore one normalizes in some way—for in-
stance so that the similarity is one when Γi = Γj. We
are aware of at least three previously-proposed ways of
doing this [18, 19, 20]:

,

Γi
σJaccard = |
Γi
|
Γi
σcosine = |

∩
∪
∩
Γi
| |
|
Γi
p
σmin = |
∩
Γi
min(
|

Γj
|
Γj
|
Γj
|
Γj
|
Γj

| |

,

|
Γj

.

)
|

(2a)

(2b)

(2c)

The ﬁrst of these, commonly called the Jaccard index,
was proposed by Jaccard over a hundred years ago [18];
the second, called the cosine similarity, was proposed
by Salton in 1983 and has a long history of study in
the literature on citation networks [19, 21, 22]. (Mea-
sures nonlinear in σunnorm are also possible. For example,
Refs. [23] and [24] propose measures involving √σunnorm
and σ2

unnorm, respectively.)

There are, however, many cases in which vertices oc-
cupy similar structural positions in networks without
having common neighbors. For instance, two store clerks
in diﬀerent towns occupy similar social positions by
virtue of their numerous professional interactions with
customers, although it is quite likely that they have none
of those customers in common. Two CEOs of companies
occupy similar positions by virtue of their contacts with
other high-ranking oﬃcers of the companies for which

v

i

j

FIG. 1: A vertex j is similar to vertex i (dashed line) if i has
a network neighbor v (solid line) that is itself similar to j.

they work, although again none of the individual oﬃcers
need be common to both companies. Considerations of
this kind lead us to an extended deﬁnition of network
similarity known as regular equivalence. In this case ver-
tices are said to be similar if they are connected to other
vertices that are themselves similar. It is upon this idea
that the measures developed in this paper are based.

Regular equivalence is clearly a self-referential con-
cept: one needs to know the similarity of the neighbors
of two vertices before one can compute the similarity of
the two vertices themselves. It comes as no surprise to
learn, therefore, that traditional algorithms for comput-
ing regular equivalence have an iterative or recursive na-
ture. Two of the best known such algorithms, REGE and
CATREGE [25], proceed by searching for optimal match-
ing between the neighbors of the two vertices, while other
authors have formulated the calculation as a optimization
problem [26].

In this paper, we take a diﬀerent approach, construct-
ing measures of similarity using the methods of linear
algebra. The fundamental statement of our approach is
that vertices i and j are similar if either of them has
a neighbor v that is similar to the other—see Fig. 1.
Coupled with the additional assumption that vertices are
trivially similar to themselves, this gives, as we will see,
a sensible and straightforward formulation of the con-
cept of regular equivalence for undirected networks. The
method has substantial advantages over other similarity
measures: it is global—unlike the Jaccard index and re-
lated measures, it depends on the whole graph and allows
vertices to be similar without sharing neighbors; it has
a transparent theoretical rationale, which more complex
methods like REGE and CATREGE lack [25]; it avoids
the convergence problems that have plagued optimiza-
tion methods; and it is comparatively fast, since its im-
plementation can take advantage of standard, hardware
optimized, linear algebra software.

Some previous authors have also considered similarity
measures based on matrix methods [27, 28]. We discuss
the diﬀerences between our measure and these previous
ones in Section II C.

This paper is organized as follows: In Section II we
present the derivation of our structural similarity mea-
sure.
Section III we test the measure on a number
of networks, including computer-generated graphs (Sec-
tions III A and III B) and real-world examples (Sec-

2

tions III C and III D).
clusions.

In Section IV we give our con-

II. A MEASURE OF SIMILARITY

The fundamental principle behind our measure of
structural similarity in networks is that i is similar to
j if i has a network neighbor v that is itself similar to j
(Fig. 1). Alternatively, swapping i and j, we could say
that j is similar to i if it has a neighbor v that is similar
to i. Despite the apparent asymmetry between i and j in
these statements we will see that they both lead to the
same similarity measure, which is perfectly symmetric.

Our deﬁnition of similarity is clearly recursive and
hence we need to provide some starting point for the re-
cursion in order to make the results converge to a useful
limit. The starting point we choose is to make each ver-
tex similar to itself, which is natural in most situations.
Our deﬁnition of similarity will thus have two compo-
nents: the neighbor term of the previous paragraph and
the self-similarity.

Thus our ﬁrst guess at the form of the similarity (we
will improve it later) is to write the similarity Sij of ver-
tex i to vertex j as

Sij = φ

AivSvj + ψδij,

(3)

v
X

where Aij is an element of the adjacency matrix of the
network taking the value

Aij =

1
0

(cid:26)

if there is an edge between i and j,
otherwise,

(4)
and φ and ψ are free parameters whose values control the
balance between the two components of the similarity.

Considering Sij to be the ij element of a similarity

matrix S, we can write Eq. (3) in matrix form as

S = φAS + ψI,

(5)

−

where I is the identity matrix. Rearranging, this can also
φA]−1. As we see, the parameter ψ
be written S = ψ[I
merely contributes an overall multiplicative factor to our
similarity. Since in essentially all cases we will be con-
cerned not with the absolute magnitude of the similarity
but only with the relative similarity of diﬀerent pairs of
vertices, we can safely set ψ = 1, eliminating one of our
free parameters, and giving

S = [I

φA]

−1.

(6)

−
This expression for similarity bears a close relation to the
matrix-based centrality measure of Katz [29]. In fact, the
Katz centrality of a vertex is equal simply to the sum of
that vertex’s similarities to every other vertex. This is a
natural concept: a vertex is prominent in a network if it
is closely allied with many other vertices.

We can also consider the similarity of i and j when j

pair i, j:

has a neighbor v that is similar to i. In that case,

Sij = φ

SivAvj + ψδij.

(7)

v
X

It is trivial to show however that this leads to precisely
the same expression, Eq. (6), for the similarity in the end.
Thus our deﬁnition provides only one similarity value for
any pair of vertices, given by the symmetric matrix S of
Eq. (6).

The remaining parameter φ in Eq. (6) is still free. To
shed light on the appropriate value for this parameter,
let us expand the similarity as a power series thus:
S = I + φA + φ2A2

+ . . .

(8)

(cid:2)

Al
ij is equal to the number
Noting that the element
of (possibly self-intersecting) network paths of length l
(cid:3)
from i to j, this equation gives us an alternative, term-
by-term interpretation of our similarity measure. The
ﬁrst term says that a vertex is identically similar to itself.
The second term says that vertices that are immediate
neighbors of one another have similarity φ. The third
term says that vertices that are distance two apart on
the network have similarity φ2. And so forth.

But notice also that vertices that have many paths of a
given length are considered more similar than those that
have few. The similarity of vertices i and j acquires a
contribution φ2 for every path of length 2 from i to j. We
note however that some pairs of vertices are expected to
have one or even many such paths between them: vertices
with very high degree, for instance, will almost certainly
have one or several paths of length two connecting them,
even if connections between vertices are just made at
random. So simple counts of number of paths are not
enough to establish similarity. We need to know when a
pair of vertices has more paths of a given length between
than we would expect by chance.

This suggests a strategy for choosing φ. We will nor-
malize each term in our series by dividing the number of
paths of length l (given by the power of the adjacency
matrix) by the expected number of such paths, were ver-
tices in the network connected at random. Then each
term will be greater or less than unity by a factor rep-
resenting the extent to which the corresponding vertices
have more or fewer paths of the appropriate length than
would be expected by chance. In fact, there is no sin-
gle choice of the parameter φ that will simultaneously
achieve this normalization for every term in the series
but, as we will show, there is a choice that achieves it
approximately for every term, and exactly in the asymp-
totic limit of high terms in the series, if we allow a slight
(and with hindsight sensible) modiﬁcation of Eq. (6).

A. Expected number of paths

Let us generalize the series, Eq. (8), to allow an in-
dependent coeﬃcient for each term and for each vertex

3

(9)

∞

Sij =

Cij
l

Al

l=0
X

(cid:2)

ij .
(cid:3)

The zeroth-order coeﬃcient Cij
0

And let us choose (for the moment) each coeﬃcient to
be equal to 1 over the expected number of paths of the
corresponding length between the same pair of vertices
on a network with the same degree sequence as the net-
work under consideration, but in which the vertices are
otherwise randomly connected. Such a network is called
a conﬁguration model, and the conﬁguration model has
been widely studied in the networks literature [30, 31, 32].
is trivial: there are
no paths of length zero between vertices i and j unless
i = j, in which case there is exactly one such path. So
Cij
0 = δij. The ﬁrst-order term is more interesting. If
vertices i and j have degrees ki and kj respectively, then
we can calculate the expected number of paths of length
one between them as follows. For any of the ki edges
emerging from vertex i, there are 2m places where it
could terminate, where m is the total number of edges
in the network. Of these, kj end at vertex j and hence
result in a direct path of length one from i to j. Thus for
each edge emerging from i there is a probability kj /2m of
a length-one path to j, and overall the expected number
of such paths is kikj /2m. Thus

Cij

1 =

2m
kikj

.

(10)

Now consider the second-order term in the series. A
path of length two between i and j must go through
a single intermediate vertex v, whose degree we denote
kv. Using the argument of the preceding paragraph, the
expected number of paths of length one from i to v is
kikv/2m. This uses up one of the edges emerging from
1 remaining edges and thus the expected
v, leaving kv
number of paths of length one from v to j, given that
there is already a path from i to v, is (kv
1)kj/2m.
−
The expected number of paths of length two from i to j
1)kj/(2m)2. Summing
via v is then the product kikv(kv
over all v, the total expected number of paths of length
two is

−

−

v
X
and

kikj
(2m)2

kv(kv

1) =

−

kikj
2m

k2
h

k

i

,

(cid:19)

i − h
k
i
h

(cid:18)

(11)

k2
h

i

k
h

where
are the mean degree and mean-square
degree of the network, and we have made use of the result
, where n is the total number of vertices in the
k
2m = n
i
h
network.

i

For paths of length three and greater, the calcula-
tions become more complicated. Since paths can be
self-intersecting, we have to consider topologies for those
paths that include loops or that traverse the same edge
more than once. While there is only one topology for
paths of length one or two between a speciﬁed pair of
vertices, there are four distinct topologies for paths of

o
w

t
h
)
j
t
i
g
σ
n
(
e
e
l
r
f
u
o
s
s
a
h
e
t
m
a
p
y
f
t
o
i
r
a
r
l
e
i
b
m
m
i
s
u
r
n
u
l
o
a
u
t
c
a

e
e
r
h
t
)
h
j
i
t
σ
g
n
(
e
e
l
r
u
f
o
s
a
s
e
h
m
t
a
p
y
t
f
i
o
r
a
r
l
e
i
m
b
m
i
s
u
r
n
u
o
l
a
u
t
c
a

0.2

0.15

0.1

0.05

0

0

5

4

3

2

1

0

0.50

i

j

j

i

i

i

j

j

i

i

j

j

FIG. 2: There is only one possibility topology for paths of
length one between distinct vertices, and only one for paths
of length two, but there are four possible topologies for paths
of length three.

length three (Fig. 2), and we must calculate and sum
the expected numbers of each of them to get the total
expected number of paths. The end result for paths of
length three is

kikj
2m "(cid:18)

k2
h

2

k

i

i − h
k
i
h

(cid:19)

+ ki + kj

1

.

#

−

(12)

As a check on our calculations, we compare our ana-
lytic expressions for the numbers of paths of length 2 and
3 to actual path counts for randomly generated networks
in Fig. 3. There is increased scatter in the numerical data
at longer path lengths because the graphs studied are ﬁ-
nite in size, but overall the agreement between analytic
and numerical calculations is good.

While this is rewarding, it is not possible to extend this
line of investigation much further. The expressions for
expected numbers of paths become more complicated as
path length increases and the numbers of distinct topolo-
gies multiply. So instead, we take a slightly diﬀerent ap-
proach.

The expected number of paths of length l from i to j
can be written as the jth element of the vector pl given
by

pl = Alv,

(13)

where the vector v has all elements zero except for vi =
In the limit of large l, the vector pl tends toward
1.
(a multiple of) the leading eigenvector of the adjacency
matrix, and hence in this limit we have pl+1 = λ1pl,
where λ1 is the largest eigenvalue of A. Thus the number
of paths from i to j increases by a factor of λ1 each time
we add one extra step to the path length. The ﬁrst step
of the path violates this rule: we know the number of
paths increases by exactly a factor of ki on the ﬁrst step.
Furthermore, since our paths are constrained to end at
vertex j, the last step must end at one of the kj edges
emanating from j, out of a total of 2m possible places
that it could end. This introduces a factor of kj/2m
into the expected number of paths. Thus, to within a
multiplicative constant, the number of paths of length l
from i to j, for large l, should be (kikj/2m)λl−1

.

1

This expression is not in general correct for small l.
It is however correct for the particular case l = 1 of
paths of length one (see Eq. (10)) and we expect it to

4

0.05

0.1
expected number of paths of length two

0.15

0.2

1

2

3

4

5
5.0

expected number of paths of length three

FIG. 3: (a) The actual number of paths of length two between
vertex pairs in a conﬁguration model versus the expected
number of paths, as determined from Eq. (11).
(b) Same
as in plot (a), but for paths of length three.

be approximately correct for other intermediate values of
l > 1. Guided by these results, we therefore choose the
constants Cij

l appearing in Eq. (9) to take the values:

Cij

l =

2m
kikj

−l+1
λ
1

,

(14)

1, with Cij

≥

0 = δij. These values approximate the
for l
desired values based on expected numbers of paths and
are asymptotically correct in the limit of large l.

B. Derivation of the similarity

There is one more issue we need to deal with with be-
fore we arrive at a ﬁnal expression for our similarity. If
we simply substitute Cij
from Eq. (14) into Eq. (9) we
l
produce a series that unfortunately does not converge.
Thus, to ensure convergence, we introduce an extra nu-

merical factor α, giving a series thus:

C. Comparison with previous similarity measures

Sij = δij +

−l+1
αlλ
1

Al

ij

2m
kikj

∞

l=1
X

=

1
(cid:20)

−

2mλ1
kikj (cid:21)

δij +

(cid:3)

(cid:2)
2mλ1
I
kikj (cid:20)(cid:18)

α
λ1

A

−

−1

(cid:19)

(cid:21)ij

.(15)

In physical terms, the eﬀect of the parameter α is to
reduce the contribution of long paths relative to short
ones. That is, for 0 < α < 1, our similarity measure
considers vertices to be more similar if they have a greater
than expected number of short paths between them, than
if they have a greater than expected number of long ones.
While this is a natural route to take, it does mean we have
introduced a new free parameter into our calculations.
This seems a fair exchange: we have traded the inﬁnite
number of free parameters in the expansion of Eq. (9) for
just a single such parameter. We discuss the appropriate
choice of value for α in Section III B.

The ﬁrst term in Eq. (15) is diagonal in the vertices
i and j and hence aﬀects only the similarity of vertices
to themselves, which we are not usually interested in, so
we will henceforth drop it. Thus, our ﬁnal expression for
the similarity is

Sij =

−1

2mλ1
I
kikj (cid:20)(cid:18)

α
λ1

A

−

(cid:19)

(cid:21)ij

.

(16)

Equivalently, we could write this in matrix form thus:

S = 2mλ1D−1

−1

D−1,

I
(cid:18)

−

α
λ1

A

(cid:19)

(17)

where D is the diagonal matrix having the degrees of the
vertices in its diagonal elements: Dij = kiδij.

This similarity measure takes exactly the form we pos-
tulated in Eq. (6) with φ = α/λ1, except for an over-
all multiplier, which is trivial, and the leading factor of
1/kikj, which is not. This factor compensates for the fact
that we expect there to be more paths between pairs of
vertices with high degree simply because there are more
ways of entering and leaving such vertices. Its presence
is crucial if we wish to compare the similarities of vertex
pairs having very diﬀerent degrees.

In practical terms, the calculation of the similarity
matrix is most simply achieved by direct multiplication.
Dropping the constant factor 2mλ1 for convenience, we
can rewrite Eq. (17) in the form of Eq. (3) thus:

DSD =

A(DSD) + I.

(18)

α
λ1

5

Several other authors have proposed vertex similarity
measures based on matrix methods similar to ours [27,
28].

Jeh and Widom [28] have proposed a method that they
call “SimRank,” predicated, as ours is, on the idea that
vertices are similar if their neighbors are similar. In our
notation, their measure is

Sij =

C
kikj

AiuAvj Suv,

(19)

u,v
X
where C is a constant. While this expression bears some
similarity to ours, Eq. (3), it has an important diﬀerence
also. Starting from an initial guess for Sij , one can iter-
ate to converge on a complete expression for the similar-
ity, and this ﬁnal expression contains terms representing
path counts between vertex pairs, as in our case. How-
ever, since the adjacency matrix appears twice on the
right-hand side of Eq. (19), the expression includes only
paths of even length. This can make a substantial diﬀer-
ence to the resulting ﬁgures for similarity. An extreme
example would be a bipartite network, such as a tree or a
square lattice, in which vertices are separated either only
by paths of even length or only by paths of odd length.
In such cases, those vertices that are separated only by
paths of odd length will have similarity zero. Even ver-
tices that are directly connected to one another by an
edge will have similarity zero. Most people would con-
sider this result counterintuitive, and our measure, which
counts paths of all lengths, seems clearly preferable.

Blondel et al. [27] considered similarity measures for
directed networks, i.e., based on asymmetric adjacency
matrices, which is a more complex situation than the one
we consider. However, for the special case of a symmetric
matrix, the measure of Blondel et al. can be written as

Sij = C

AiuAvj Suv,

(20)

u,v
X

where C is again a constant. This is very similar to the
measure of Jeh and Widom, diﬀering only in the omission
of the factor 1/kikj . Like the measure of Jeh and Widom,
it can be written in terms of paths between vertices, but
counts only paths of even lengths, so that again vertices
separated only by odd paths (such as adjacent vertices
on bipartite graphs) have similarity zero.

D. A measure of structural equivalence

Making any guess we like for an initial value of DSD,
such as DSD = 0, we iterate this equation repeatedly
until it converges. In practice, for the networks studied
here, we have found good convergence after 100 iterations
or less.

An interesting corollary of the theory developed in
the previous sections is an alternative measure of struc-
tural equivalence. The structural equivalence measures of
Eq. (2) can be viewed as similarity measures that count
only the paths of length two between vertex pairs; the
number of common neighbors of two vertices is exactly

j

i

σ
e
r
u
s
a
e
m
y
t
i
r
a
l
i

m

i
s

r
u
o

1.0×10

2

1.0×10

1

1.0×10

0

1.0×10

-1

0.0

j

i

σ
e
r
y
u
t
i
s
r
a
a
e
l
m
i
m
y
i
s
t
i
e
r
a
n
l
i
i
s
m
o
c
i
s

r
u
o

1.0×10

0

1.0×10

-1

1.0×10

-2

1.0×10

-3

0.0

equal to the number of paths of length two. Thus struc-
tural equivalence can be thought of as just one term—the
second-order term—in the inﬁnite series that deﬁnes our
measure of regular equivalence.

The measures of Eq. (2) diﬀer from one another in their
normalization. The developments outlined in this paper
suggest another possible normalization, one in which we
divide the number of paths of length two by its expected
value, Eq. (11), giving

σ =

2m
kikj (cid:18)

k
i
h
i − h
If we are concerned only with the comparative similarities
of diﬀerent pairs of vertices within a given graph, then
we can neglect multiplicative constants and write

k2
h

Γi
|

(21)

i (cid:19)

Γj

.
|

∩

k

σ = |

Γi

Γj

|

∩
kikj

Γi
= |
Γi
|

∩
| |

Γj
Γj

.

|
|

(22)

This is, we feel, in many ways a more sensible measure
of structural equivalence than those of Eq. (2). It gives
high similarity to vertex pairs that have many common
neighbors compared not to the maximum number possi-
ble but to the expected number of such neighbors, and
therefore highlights vertices that have a statistically im-
probable coincidence of neighborhoods. Of course, one
could deﬁne similar measures for paths of length 1 or 3 or
any other length. Or one could combine all such lengths,
which is precisely what our overall similarity measure
does.

III. TESTS OF THE METHOD

In this section we test our method on a number of dif-
ferent networks. Our ﬁrst example is a set of computer-
generated networks designed to have known similarities
between vertices. In following sections we also test the
method against some real-world examples.

A. Stratiﬁed model network

In many social networks, individuals make connections
with others preferentially according to some perceived
similarity, such as age or income. Such networks are said
to be stratiﬁed, and stratiﬁed networks present a perfect
opportunity to apply our similarity measure: ideally we
would like to see that given only the network structure
our measure can correctly identify vertices that are sim-
ilar in age (or whatever the corresponding variable is)
even when the vertices are not directly connected to one
another.

As a ﬁrst test of our measure, we have created artiﬁcial
stratiﬁed networks on a computer. Such networks oﬀer
a controlled structure for which we believe we know the
“correct” answers for vertex similarity.

6

0

1

2

3

4

5

6

7

8

9

age diﬀerence between vertices i and j

0

1

2

3

4

5

6

7

8

9

age diﬀerence between vertices i and j

FIG. 4: (a) A density plot of the similarities of all vertex pairs
not directly connected by an edge in our stratiﬁed network
model. The points give the average similarity as a function of
age diﬀerence and the line is a least-squares ﬁt to a straight
line. (b) A density plot of the cosine similarity values for the
same network.

In our model networks, each of n = 1000 vertices was
given one of ten integer “ages.” Then edges were created
between vertices with probability

P (∆t) = p0e

−a∆t,

(23)

where ∆t is the diﬀerence in ages of the vertices and p0
and a are constants, whose values in our calculations were
chosen to be p0 = 0.12 and a = 2.0. Thus the probabil-
ity of “acquaintance” between two individuals drops by
a factor of e2 for every additional year separating their
ages.

In order to calculate our similarity measure for this
or any network we need ﬁrst to choose a value of the
single parameter α appearing in Eq. (16). In the present
calculations we used a value of α = 0.97, which, as we will
see, is fairly typical. Since α must be strictly less than
one if Eq. (16) is to converge, α = 0.97 is quite close to
the maximum. We discuss in the following section why
values close to the maximum are usually desirable.

Figure 4a shows a density plot of the similarity values

7

,
(

)
e
g
)
a
j
σ
i
σ
σ
e
(
r
r
u
t
s
n
a
e
e
i
m
c
ﬃ
y
e
t
o
i
r
c
a
l
n
i
m
o
i
i
t
s
a
l
r
e
u
r
o
r
o
c

0.6

0.5

0.4

0.3

0.2

0.1

0

0

for all vertex pairs in the model network not directly con-
nected by an edge, on semi-log scales as a function of the
age diﬀerence between the vertices. The average similar-
ity as a function of age diﬀerence is also plotted along
with a ﬁt to the data. We exclude directly connected
pairs in the ﬁgure because it is trivial that such pairs
will have high similarity and most of the interest in our
method is in its ability to detect similarity in nontrivial
cases.

For comparison, we also show in Fig. 4b a density plot
of the cosine similarity, Eq. (2b), for the same network.
As the plot reveals, the cosine similarity is a much less
powerful measure. It is only possible for cosine similarity
to be nonzero if there exists a path of length two between
the vertices in question. Vertices with an age diﬀerence
of three or more rarely have such a path in this network
and, as Fig. 4b shows, such vertices therefore nearly all
have a cosine similarity of zero. Thus cosine similarity
ﬁnds only highly similar vertices in this case and entirely
fails to distinguish between vertices with age diﬀerences
between 3 and 9. Our similarity measure by contrast
distinguishes these cases comfortably.

B. Choice of α

Our similarity measure, Eq. (16), contains one free pa-
rameter α, which controls the relative weight placed on
short and long paths. This parameter lies strictly in the
range 0 < α < 1, with low values placing most weight
on short paths between vertices and high values plac-
ing weight more equally both on short and long paths.
(Values α > 1 would place more weight on long paths
than on short, but for such values the series deﬁning our
similarity does not converge.)

In order to extract quantitative results from our sim-
ilarity measure we need to choose a value for α. There
is in general no unique value that works perfectly for ev-
ery case, but experience suggests some reliable rules of
thumb. Our stratiﬁed network model, for instance, pro-
vides a good guide. Consider Fig. 5. In this ﬁgure we
have calculated the correlation coeﬃcient of the similar-
ity values for vertex pairs determined using our method
against the probabilities, Eq. (23), of connections be-
tween the vertices, which we consider to be a fundamen-
tal measure of vertices’ a priori similarity. As the ﬁgure
shows, the correlation is quite low for low values of α, but
becomes strong as α approaches one. Only as α gets very
close to one does the correlation fall oﬀ again. This ap-
pears to imply that a value of α = 0.9 or greater should
give the best results in this case. Furthermore, it ap-
pears that, for values of α in this range, the precise value
does not matter greatly, all values around the maximum
in the correlation coeﬃcient giving roughly comparable
performance.

This we have found to be a good general rule: val-
ues of α close to the maximum value of 1 perform the
best, with values in the range 0.90 to 0.99 being typical.

0.2

0.4

0.6

0.8

1

α

FIG. 5: The correlation coeﬃcient r(σ, σage) for correlation
between our similarity measure and the probability of connec-
tion, Eq. (23), in our stratiﬁed model, for a range of values of
α. The values given are averaged over an ensemble of graphs
generated from the model. The maximum value is found to
occur for α ≃ 0.97.

Within this range the results are not highly sensitive to
the exact value. We give another example to reinforce
this conclusion below.

The large typical values of α mean that paths of diﬀer-
ent lengths are weighted almost equally in our similarity
measure.
In other words, it appears that our measure
works best when long paths are accorded almost as much
consideration as short ones. This contrasts strongly with
structural equivalence measures like the Jaccard index
and the cosine similarity, which are based exclusively on
short paths—those of length two. We should be unsur-
prised therefore to ﬁnd that our method gives substan-
tially better results than these older measures, as the
example above shows.

C. Thesaurus network

We now consider two applications of our method to
real-world networks. The ﬁrst is to a network of words ex-
tracted from a supplemented version of the 1911 US edi-
tion of Roget’s Thesaurus [33]. The thesaurus consists of
a ﬁve-level hierarchical categorization of English words.
For example, the word “paradise” (level ﬁve) is cataloged
under “heaven” (level four), “superhuman beings and re-
gions” (level three), “religious aﬀections” (level two), and
“words relating to the sentient and moral powers” (level
one). Here we study the network composed of the 1000
level-four words, in which two such words are linked if
one or more of the level-ﬁve words cataloged below them
are common to both. For instance, the level-four words
“book” and “knowledge” are connected because the en-
tries for both in the thesaurus contain the level-ﬁve terms
“book learning” and “encyclopedia.”

In Table I we show the words most similar to the words
“alarm,” “hell,” “mean,” and “water,” as ranked ﬁrst by

8

word

our measure

cosine similarity

warning

alarm danger

omen
heaven
pain
discontent
compromise
generality
middle
plunge
air
moisture

hell

mean

water

32.014
25.769
18.806
63.382
28.927

omen
threat
prediction
pleasure
discontent
7.034 weariness

gravity
inferiority
littleness
dryness

20.027
19.811
17.084
33.593
25.267 wind
ocean
25.267

0.51640
0.47141
0.34816
0.40825
0.28868
0.26726
0.23570
0.22222
0.20101
0.44721
0.31623
0.31623

,
(

)
e
g
)
a
j
σ
i
σ
σ
e
(
r
r
u
t
s
n
a
e
e
i
m
c
ﬃ
y
e
t
o
i
r
c
a
l
n
i
m
o
i
i
t
s
a
l
r
e
u
r
o
r
o
c

0.25

0.2

0.15

0.1

TABLE I: The words most similar to “alarm,” “heaven,”
“mean,” and “water,” in the word network of the 1911 edition
of Roget’s Thesaurus, as quantiﬁed by our similarity measure
and by the more rudimentary cosine similarity of Eq. (2b).
For our measure we used a value of α = 0.98 for the single
parameter.

our similarity measure and second by cosine similarity.
We used a value of α = 0.98 in this case, on the grounds
that this value gave the best performance in other test
cases (see below).

Since cosine similarity can be regarded as a measure
of the number of paths of length two between vertices,
it tends in this example to give high similarity scores
for words at distance two in the thesaurus—synonyms
of synonyms, antonyms of synonyms, and so forth. For
example, cosine similarity ranks “pleasure” as the word
most similar to “hell,” probably because it is closely as-
sociated with hell’s antonym “heaven.” By contrast, our
measure ranks “heaven” itself ﬁrst, which appears to be
a more sensible association. Similarly, cosine similarity
links “water” with “dryness”, whereas our measure links
“water” with “plunge.”

D. Friendship network of high school students

As a second real-world test of our similarity measure,
we apply it to a set of networks of friendships between
school children. The network data were collected as part
of the National Longitudinal Study of Adolescent Health
(AddHealth) [34], and describe 90 118 students at 168
schools, including their school grade (i.e., year), race, and
gender, as well as their recent patterns of friendship. It
is well known that people with similar social traits tend
to associate with one another [35], so we expect there to
be a correlation between similarity in terms of personal
traits and similarity based on network position. This
gives us another method for checking the eﬃcacy of our
similarity measure.

The AddHealth data were gathered through question-
naires handed out to students at 84 pairs of Ameri-

0.9

0.92

0.94

0.96

0.98

1

α

FIG. 6: The correlation coeﬃcient for correlation between our
similarity measure and the age diﬀerence of all vertex pairs in
a single network, as a function of α. This plot is typical for
the school networks studied.

can schools, a school pair typically consisting of one
junior high school (grades 7 and 8, ages 12-14) and
one high school (grades 9-12, ages 14-18). Here we
look at a composite of the school pairs with vertices
from all six grades. Among other things, the question-
naires circulated during the study asked respondents to
“List your closest (male/female) friends. List your best
(male/female) friend ﬁrst, then your next best friend, and
so on.
(Girls/Boys) may include (boys/girls) who are
friends and (boy/girl) friends.” For each of the friends
listed the student was asked to state which of ﬁve listed
activities they had participated in recently, such as “you
spent time with (him/her) last weekend”. From these
answers a weight w(i, j) is assigned to every ordered pair
of students (i, j) such that w(i, j) is 0 if i has not listed j
as a friend or 1 + the number of activities conducted oth-
erwise. From these weights we construct an unweighted,
undirected friendship network by adding a link between
vertices i and j if w(i, j) and w(j, i) are both greater than
or equal to a speciﬁed threshold value W . As it turns out,
our conclusions are not very sensitive to the choice of W ;
the results described here use W = 2.

The networks so derived are not necessarily connected;
they may, and often do, consist of more than one com-
ponent for each school studied. To simplify matters we
here consider only on the largest component of each net-
work. The largest component in some of the networks
is quite small, however, so to avoid ﬁnite size eﬀects we
have focused on networks of more than 1000 students.

We ﬁrst test our similarity measure using the method
we used for the stratiﬁed network of Section III A: we
determine the linear correlation coeﬃcient between age
diﬀerence (measured as diﬀerence in grade) and our net-
work similarity measure, for all vertex pairs in a network.
We have calculated this correlation coeﬃcient for a range
of values of α, the free parameter in our measure, and for
a selection of diﬀerent networks. The results for one par-

≃

In this case the
ticular network are shown in Fig. 6.
correlation coeﬃcient is maximized for α
0.99, which
is again close to the maximum possible value of 1. For
other networks we ﬁnd maxima in the range from 0.96 to
0.99, which is in accord with the results of Section III B.
These correlations between age diﬀerence and network
similarity appear to indicate that our similarity measure
is able to detect some aspects of the social structure of
these networks. To investigate this further, we have taken
the optimal values of α from the correlation coeﬃcients
and used them to calculate the average similarity of ver-
tex pairs that have a known common characteristic, ei-
ther grade or race, comparing that average with the aver-
age similarity for vertex pairs that diﬀer with respect to
the same characteristic. The results are given in Table II.
For school A the average similarity for pairs of students
in the same grade is a factor of eight greater than that for
pairs in diﬀerent grades—an impressive diﬀerence. It is
possible, however, that this diﬀerence could result purely
from the contribution to the similarity from vertex pairs
that are directly connected by an edge. It would come as
no surprise that such pairs tend to be in the same grade.
To guard against this, we give in the fourth column of
Table II results for calculations in which all directly con-
nected vertex pairs were removed. Even with these pairs
removed we see that same-grade vertex pairs are on av-
erage signiﬁcantly more similar than pairs from diﬀerent
grades.

We have made similar calculations with respect to the
race of students. Students in school A did not appear to
have any signiﬁcant division along racial lines (columns
ﬁve and six of Table II), but this school was almost en-
tirely composed of students of a single race anyway, so
this result is not very surprising; it seems likely that the
numbers were just too small to show a signiﬁcant eﬀect.
School B was similar. Schools C and D, however, show
a marked contrast. In school C, the average similarity
for students of the same race is a factor of ﬁve greater
than the average similarity for students of diﬀerent races.
School C had a population split 2:1 between two racial
groups, in marked contrast with schools A and B. School
D similarly appears to be divided by race, although a
little less strongly. In this case there is a three-way split
within the population between diﬀerent racial groups.
Possibly this more even split with no majority group was
a factor in the formation of friendships between students
from diﬀerent groups.

IV. CONCLUSIONS

In this paper we have proposed a measure of structural
similarity for pairs of vertices in networks. The method
is fundamentally iterative, with the similarity of a vertex
pair being given in terms of the similarity of the vertices’
neighbors. Alternatively, our measure can be viewed as
a weighted count of the number of paths of all lengths
between the vertices in question. The weights appearing

9

similarity ratios

SG:DG SG:DG*

SR:DR SR:DR*

school
A
B
C
D

n

1090
1302
1996
1530

8.0
6.2
2.2
3.3

6.1
4.4
1.9
2.6

1.1
2.6
5.0
4.0

1.1
2.6
5.0
3.6

TABLE II: Network size n and ratios of average similarity
values for school networks in the AddHealth data set. The
column labeled SG:DG gives the ratio of average similarity
for students in the same grade (SG) to average similarity for
students in diﬀerent grades (DG). The column labeled SR:DR
gives the ratio of average similarity for students of the same
race (SR) to average similarity for students of diﬀerent races
(DR). Columns marked with asterisks (*) give values of the
same ratios but omitting vertex pairs connected directly by
an edge.

in this count are asymptotically equal to the expected
numbers of network paths between the vertices, which
we express in terms of the leading eigenvalue of the ad-
jacency matrix of the network and the degrees of the
vertices of interest. The resulting expression for our sim-
ilarity measure is given in Eq. (17).

We have tested our measure against computer-
generated and real-world networks, with promising re-
sults. In tests on computer-generated networks the mea-
sure is particularly good at discerning similarity between
vertices connected by relatively long paths, an area in
which more traditional similarity measures such as co-
sine similarity perform poorly. In tests on real-world net-
works the method was able to extract sensible synonyms
to words from a network representing the structure of
Roget’s Thesaurus, and showed strong correlations with
similarity of age and race in a number of networks of
friendship among school children. Taken together, these
results seem to indicate that the measure is capable of ex-
tracting useful information about vertex similarity based
on network topology.

The strength of similarity measures such as ours is
their generality—in any network where the function or
role of a vertex is related in some way to its structural sur-
roundings, structural similarity measures can be used to
ﬁnd vertices with similar functions. For instance, similar-
ity measures can be used to divide vertices into functional
categories [20, 36, 37] or for functional prediction in cases
where the functionality of vertices is partly known ahead
of time [38]. We believe that the application of similarity
measures to problems such as these will prove a fruitful
topic for future work.

Acknowledgments

This work was funded in part by the National Sci-
ence Foundation under grant number DMS–0405348, by
the James S. McDonnell Foundation, and by a gift to

the University of Michigan from Robert D. and Janet
E. Neary. P.H. acknowledges support from the Wenner-
Gren Foundation.

This work uses data from Add Health, a program
project designed by J. Richard Udry, Peter S. Bearman,
and Kathleen Mullan Harris, and funded by a grant P01-
HD31921 from the National Institute of Child Health and

Human Development, with cooperative funding from 17
other agencies. Special acknowledgment is due Ronald
R. Rindfuss and Barbara Entwisle for assistance in the
original design. Persons interested in obtaining data ﬁles
from Add Health should contact Add Health, Carolina
Population Center, 123 W. Franklin Street, Chapel Hill,
NC 27516–2524 (addhealth@unc.edu).

10

[1] R. Albert and A.-L. Barab´asi, Rev. Mod. Phys. 74, 47

(2002).

[2] S. N. Dorogovtsev and J. F. F. Mendes, Advances in

Physics 51, 1079 (2002).

[3] M. E. J. Newman, SIAM Review 45, 167 (2003).
[4] D. J. Watts and S. H. Strogatz, Nature 393, 440 (1998).
[5] F. Chung and L. Lu, Proc. Natl. Acad. Sci. USA 99,

15879 (2002).

(2003).

[6] R. Cohen and S. Havlin, Phys. Rev. Lett. 90, 058701

361 (1993).

[7] A. Fronczak, P. Fronczak, and J. A. Holyst, Phys. Rev.

14, 121 (1992).

E 70, 056110 (2004).

[8] A.-L. Barab´asi and R. Albert, Science 286, 509 (1999).
[9] S. N. Dorogovtsev, J. F. F. Mendes, and A. N. Samukhin,

Phys. Rev. Lett. 85, 4633 (2000).

[10] P. L. Krapivsky, S. Redner, and F. Leyvraz, Phys. Rev.

[11] M. Girvan and M. E. J. Newman, Proc. Natl. Acad. Sci.

Lett. 85, 4629 (2000).

USA 99, 7821 (2002).

[12] F. Radicchi, C. Castellano, F. Cecconi, V. Loreto, and
D. Parisi, Proc. Natl. Acad. Sci. USA 101, 2658 (2004).
[13] R. Guimer`a, M. Sales-Pardo, and L. A. N. Amaral, Phys.

Rev. E 70, 025101 (2004).

[15] M. E. J. Newman, Phys. Rev. E 64, 016132 (2001).
[16] K.-I. Goh, B. Kahng, and D. Kim, Phys. Rev. Lett. 87,

(2004).

278701 (2001).

formation Retrieval (McGraw-Hill, Auckland, 1983).
[22] L. Hamers, Y. Hemeryck, G. Herweyers, M. Janssen,
H. Keters, R. Rousseau, and A. Vanhoutte, Information
Processing and Management 25, 315 (1989).

[23] R. S. Burt, Social Forces 55, 93 (1976).
[24] D. S. Goldberg and F. P. Roth, Proc. Natl. Acad. Sci.

USA 100, 4372 (2003).

[25] S. P. Borgatti and M. G. Everett, Social Networks 15,

[26] V. Batagelj, P. Doreian, and A. Ferligoj, Social Networks

[27] V. D. Blondel, A. Gajardo, M. Heymans, P. Senellart,

and P. van Dooren, SIAM Rev. 46, 647 (2004).

[28] G. Jeh and J. Widom, in Proceedings of the 8th ACM
SIGKDD International Conference on Knowledge Dis-
covery and Data Mining (Association of Computing Ma-
chinery, New York, 2002), pp. 538–543.
[29] L. Katz, Psychometrika 18, 39 (1953).
[30] T.

in Proceedings of the Symposium on Ran-
dom Graphs, Pozna´n 1989, edited by A. M. Frieze and
T.  Luczak (John Wiley, New York, 1992), pp. 165–182.

 Luczak,

[31] M. Molloy and B. Reed, Random Structures and Algo-

rithms 6, 161 (1995).

Rev. E 64, 026118 (2001).

[33] S. Mawson, ed., Roget’s Thesaurus of English Words and

Phrases (T. Y. Crowell Co., New York, 1911).

[34] P. Bearman, J. Moody, and K. Stovel, Am. J. Soc. 110,

[35] J. M. McPherson, L. Smith-Lovin, and J. Cook, Ann.

[36] J. J. Luczkovich, S. P. Borgatti, J. C. Johnson, and M. G.

Everett, J. Theor. Biol. 220, 303 (2003).

[37] A. W. Wolfe, Connections 26, 105 (2005).
[38] P. Holme and M. Huss, J. Roy. Soc. Interface 2, 327

[17] P. Holme, B. J. Kim, C. N. Yoon, and S. K. Han, Phys.

44 (2004).

[18] P. Jaccard, Bulletin de la Soci´et´e Vaudoise des Sciences

Rev. Sociol. 27, 415 (2001).

Rev. E 65, 056109 (2002).

Naturelles 37, 547 (1901).

[19] G. Salton, Automatic Text Processing: The Transforma-
tion, Analysis, and Retrieval of Information by Computer
(Addison-Wesley, Reading, MA, 1989).

[20] E. Ravasz, A. L. Somera, D. A. Mongru, Z. N. Oltvai,

(2005).

and A.-L. Barab´asi, Science 297, 1553 (2002).

[21] G. Salton and M. J. McGill, Introduction to Modern In-

[14] L. Donetti and M. A. Mu˜noz, J. Stat. Mech. P10012

[32] M. E. J. Newman, S. H. Strogatz, and D. J. Watts, Phys.

