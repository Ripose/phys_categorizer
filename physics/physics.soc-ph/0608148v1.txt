Reﬂections on Modern Macroeconomics: Can We Travel Along a
Safer Road?∗

E. Gaﬀeo,1 M. Catalano,2 F. Clementi,2 , † D. Delli Gatti,3 M. Gallegati,2 and A. Russo4

1Department of Economics and CEEL,

University of Trento, Via Inama 5, 38100 Trento, Italy

2Department of Economics, Universit`a Politecnica delle Marche,

Piazzale Martelli 8, 60121 Ancona, Italy

3Institute of Economic Theory and Quantitative Methods,

Catholic University of Milan, Via Largo Gemelli 1, 20123 Milan, Italy

4Scuola Normale Superiore, Piazza dei Cavalieri 7, 56126 Pisa, Italy

(Dated: February 2, 2008)

Abstract

In this paper we sketch some reﬂections on the pitfalls and inconsistencies of the research pro-

gram—currently dominant among the profession—aimed at providing microfoundations to macroe-

conomics along a Walrasian perspective. We argue that such a methodological approach constitutes

an unsatisfactory answer to a well-posed research question, and that alternative promising routes

have been long mapped out but only recently explored. In particular, we discuss a recent agent-

based, truly non-Walrasian macroeconomic model, and we use it to envisage new challenges for

future research.

PACS numbers: 89.65.Gh

Keywords: equilibrium; agent-based economics; emergence

6
0
0
2
 
g
u
A
 
4
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
8
4
1
8
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

∗The title echoes [1], to which we are indebted for some of the observations here reported.
†Corresponding author: fabio.clementi@uniroma1.it

Typeset by REVTEX

1

I.

INTRODUCTION

In a recent paper [2], Steve Keen warns econophysicists against using modern economic

theory as a foundation for their work, boosting them instead to learn directly from the

British classical tradition (see [3] for an exact deﬁnition of the boundaries separating the

classical and the modern or neoclassical traditions). This paper follows Keen’s footsteps,

with a big caveat. On the one hand, we endorse an accusation repeatedly brought against

modern (neoclassical ) economic theory (known also as eﬃcient resource allocation theory),

that is to be empirically and logically ﬂawed.1 How the restricted vision of modern economics

came to dominate the profession till our days is a fascinating chapter of the history of science

which can not be addressed here (see [4, 5]). On the other hand, however, we would like to

underline that economics has been always characterized by the contemporaneous existence of

several competing research traditions, which now and then jumble together. During the last

sixty years it has not been unusual, for instance, to register that harsh criticisms to current

mainstream conceptions were advanced by scholars who actively contributed to put them

at the frontier of the economic discourse. In the war of the models [6] fought by economists

in the academic arena, neoclassicals have won several battles, but their opponents (e.g.,

Austrians, post-Keynesians, behavioralists) have never been completely defeated. On the

contrary, from time to time these latter succeed in converting to their side some generals of

the neoclassical army, who actively train recruits to innovative ﬁghting techniques.

The battleground we choose to exemplify our point is the research program launched

some forty years ago by the neoclassical school, according to which macroeconomics should

be explicitly grounded on microfoundations. Brieﬂy, economic phenomena at a macroscopic

level should be explained as the consequences of the activities undertaken by individual

decision makers. The methodological strategy that has so far gained supremacy is one

based on: i ) the precepts of the modern (i.e., rational choice-theoretic) tradition, and ii )

a solution (or closing) concept borrowed from Walrasian competitive general equilibrium

analysis.

1 Neoclassical economics is axiomatic. While it requires internal coherence, so that theorems can be logically
deduced from a set of assumptions, it abstracts from external coherence between theoretical statements
and empirical evidence. Of course, this implies an important epistemological detachment from falsiﬁable
sciences like physics.

2

Some of the key ﬂaws underlying item i ) has been presented in [2].

In turn, critical

words against item ii ) has been loudly pronounced, among the others, by eminent scholars

who spent most of their academic life in the neoclassical camp [7]. Admittedly, their criti-

cism was at one time well centered and largely neglected, probably because the alternative

methodology they suggested was so close to the mainstream that the disturbing theoretical

results they presented were seen as a nuisance, which could be easily addressed by painless

manipulations of the standard model. The alternative proposal we shall confront with the

Walrasian paradigm in what follows is deﬁnitely more radical. As a preliminary step, how-

ever, it seems worthwhile to review why Walrasian microfundations should be considered as

the wrong answer to what is probably the most stimulating research question ever raised in

economics, that is to explain how a completely decentralized economy composed of millions

of (mainly) self-interested people coordinate their actions.

II. ADAM, L´EON AND THE BUTCHER

Contrary to what is usually thought, the very idea that the economy is a (complex) self-

organizing system is not a new entry in the toolbox of economists got mixed up in complexity,

but it is the key message conveyed in 1776 by the founding father of the discipline, the

Scottish moral philosopher Adam Smith, according to whom:

“He [man] generally, indeed, neither intends to promote the public interest,

nor knows how much he is promoting it. By preferring the support of domestic

to that of foreign industry, he intends only his own security; and by directing

that industry in such a manner as its produce may be of the greatest value, he

intends only his own gain, and he is in this, as in many other cases, led by an

invisible hand to promote an end which was no part of his intention.

In civilized society he [man] stands at all times in need of the cooperation

and assistance of great multitudes, while his whole life is scarce suﬃcient to gain

the friendship of a few persons.

In almost every other race of animals each

individual, when it is grown up to maturity, is entirely independent, and in its

natural state has occasion for the assistance of no other living creature. But man

has almost constant occasion for the help of his brethren, and it is in vain for him

to expect it from their benevolence only. He will be more likely to prevail if he

3

can interest their self-love in his favour, and show them that it is for their own

advantage to do for him what he requires of them. Whoever oﬀers to another

a bargain of any kind, proposes to do this. Give me that which I want, and

you shall have this which you want, is the meaning of every oﬀer; and it is in

this manner that we obtain from one another the far greater part of those good

oﬃces which we stand in need of. It is not from the benevolence of the butcher,

the brewer, or the baker that we expect our dinner, but from their regard to their

self-love, and never talk to them of our own necessities but of their advantages.”

(Smith [8], p. 477 of the 1976 University of Chicago edition.)

Five points deserve to be emphasized. First, the notion of an invisible hand guiding

coordination towards aggregate order in a fully decentralized economy represents an ex-

planandum (i.e., our research question) of theoretical and empirical importance, both for

positive and normative reasons. Second, the explanation of economic phenomena is run in

terms of the actions and reactions of autonomous individuals and not of social categories.

This requires a conceptualization of decision-makers in terms of economic agents, rather than

social classes or races. Third, the economic agent (Smith’s man) envisaged in the quotation

above responds to incentives to improve utility, but he is never requested to maximize it as he

should do if endowed with substantive rationality. Fourth, Smith recognizes self-interest as

being the main force driving decentralized actors towards a coordinated aggregate position,

but he never concedes that greed is the only relevant human trait. Fifth, the work of the

invisible hand yields a social order, but neither is such an order a rest (i.e., an equilibrium)

nor is the best possible solution (i.e., an optimum).

As regards the ﬁrst two points—the key challenge of explaining how the invisible hand

works and the approach of methodological individualism,2 respectively—the profession has

reached a consensus to which we convincingly adhere. Moving to the last three points, how-

ever, we subscribe to the far less popular claiming that the theoretical approach developed

by the mainstream in dealing with them has proven to be inadequate. Instead of the idea

2 Actually, the path followed by methodological individualism has been rather bumpy, and what is nowadays
commonly accepted by its very notion is somewhat diﬀerent from the origins. After having brilliantly
repelled the attack of Marxians, the currently established version of methodological individualism is
illustrated by Arrow [9], who acknowledges that individual behavior is always mediated by social relations,
but also that social relations are the outcome of the actions of individual agents.

4

of a self-regulating order emerging from the interactions of many simpler components with-

out this “being part of their intentions”, the Holy Trinity of (marginalist) neoclassical eco-

nomics [10]—(substantive) rationality, greed and equilibrium—has soon became the elected

guiding principles of human behavior. In setting the methodological stage for the revolu-

tion—quickly turned into a dictatorship—dubbed Dynamic Stochastic General Equilibrium

(DSGE) macroeconomic theory, Robert Lucas and Thomas Sargent bluntly declared:

“An economy following a multivariate stochastic process is now routinely de-

scribed as being in equilibrium, by which is meant nothing more that at each

point in time (a) markets clears and (b) agents act in their own self-interest.

This development, which stemmed mainly from the work of K. J. Arrow [...]

and G. Debreu [...], implies that simply to look at any economic time series and

conclude that it is a disequilibrium phenomenon is a meaningless observation.

[...] The key elements of these models are that agents are rational, reacting to

policy changes in a way which is in their best interests privately, and that the

impulses which trigger business ﬂuctuations are mainly unanticipated shocks.”

(Lucas and Sargent [11], p. 7.)

The self-regulating order of Smith was therefore transformed into a competitive General

Equilibrium (GE) in the form elaborated in the 1870s by L´eon Walras [12], that is a con-

ﬁguration of (fully ﬂexible) prices and plans of action such that, at those prices, all agents

can carry out their chosen plans and, consequently, markets clear. In a continuous eﬀort of

generalization and analytical sophistication, modern (neoclassical) economists interested in

building microfundations for macroeconomics soon recurred to the reﬁnement proposed in

the 1950s by Arrow and Debreu [13], who showed that also individual intertemporal (on an

inﬁnite horizon) optimization yields a GE, as soon as the economy is equipped with perfect

price foresights for each future state of nature and a complete set of Arrow-securities mar-

kets [14], all open at time zero and closed simultaneously. Whenever these conditions hold

true, the GE is an allocation that maximizes a properly deﬁned social welfare function or,

in other terms, the equilibrium is Pareto-eﬃcient (First Welfare Theorem).3

As already anticipated, the weaknesses of the epistemological status of the GE model are

so deep to have been fully recognized at various stages by its very proponents. Since this

3 See [15] for a remarkable account of the origin and evolution of the GE concept.

5

awareness still encounters huge diﬃculties in being spread among the profession, however,

it seems worthwhile to provide a concise exposition of the main issues at hand.

1. The GE is neither unique nor locally stable under general conditions. This negative

result, which refers to the work of Sonnenschein [16], Debreu [17] and Mantel [18],

can be summarized along the following lines. Let the aggregate excess demand func-

tion F (p)—obtained from aggregating among individual excess demands f (p)—be a
mapping from the price simplex Π to the commodity space P N . A GE is deﬁned
as a price vector p∗ such that F (p∗) = 0. It turns out that the only conditions that
F (·) inherits from f (·) are continuity, homogeneity of degree zero and the Walras’ law

(i.e., the total value of excess demand is zero). These assure the existence, but neither

the uniqueness nor the local stability of p∗, unless preferences generating individual

demand functions are restricted to very special cases.

2. The existence of a GE is proved via the Brower’s ﬁx point theorem, i.e. by ﬁnding a
continuous function g (·) : Π → Π such that any ﬁx point for g (·) is also an equilibrium
price vector F (p∗) = 0. Suppose that we are interested in ﬁnding an algorithm, which,

starting from an arbitrary price vector p, chooses price sequences to check for p∗ and

halt when it ﬁnds it. In other terms, to ﬁnd the GE price vector F (p∗) = 0 means that

halting conﬁgurations are decidable. As this violates the undecidability of the halting

problem for Turing Machines, from a recursion theoretic viewpoint the GE solution is

uncomputable [19, 20]. Notice that the same problem applies, in spite of its name, to

the class of Computable GE models [21].

3. By construction, in a GE all transactions are undertaken at the same equilibrium

price vector. Economic theory has worked out two mechanisms capable to reach this

outcome. First, one can assume that buyers and sellers adjust costlessly their optimal

supplies and demands to prices called out by a (explicit or implicit) ﬁctitious auction-

eer, who continues to do his job until he ﬁnds a price vector which clears all markets.

Only then transactions take place (Walras’ assumption). Alternatively, buyers and

sellers sign provisional contracts and are allowed to freely (i.e., without any cost) re-

contract until a price vector is found which makes individual plans fully compatible.

Once again, transactions occur only after the equilibrium price vector has been estab-

lished (Edgeworth’s assumption). Regardless of the mechanism one adopts, the GE

6

model is one in which the formation of prices precedes the process of exchange, instead

of being the result of it, through a tˆatonnement process occurring in a meta-time. Real

markets work the other way round and operates in real time, so that the GE model

cannot be considered a scientiﬁc explanation of real economic phenomena [22].

4. It has been widely recognized since [23] that integrating money in the theory of value

represented by the GE model is at best problematic. No economic agent can individ-

ually decide to monetize alone; monetary trade should be the equilibrium outcome of

market interactions among optimizing agents. The use of money—that is, a common

medium of exchange and a store of value—implies that one party to a transaction

gives up something valuable (for instance, his endowment or production) for some-

thing inherently useless (a ﬁduciary token for which he has no immediate use) in the

hope of advantageously re-trading it in the future. Given that in a GE model actual

transactions take place only after a price vector coordinating all trading plans has

been freely found, money can be consistently introduced into the picture only if the

logical keystone of the absence of transaction costs is abandoned. By the same token,

since credit makes sense only if agents can sign contracts in which one side promises

future delivery of goods or services to the other one, in equilibrium markets for debt

are meaningless, both information conditions and information processing requirements

are not properly deﬁned, and bankruptcy can be safely ignored. Finally, as the very

notion of a GE implies that all transactions occur only when individual plans are mu-

tually compatible, and this has to be true also in the labor market, the empirically

observed phenomenon of involuntary unemployment and the microfoundation program

put forth by Lucas and Sargent are logically inconsistent.

5. The only role assigned to time in a GE model is that of dating commodities. Prod-

ucts, technologies and preferences are exogenously given and ﬁxed from the outset. The

convenient implication of banning out-of-equilibrium transactions is simply that of get-

ting rid of any disturbing inﬂuence of intermediary modiﬁcations of endowments—and

therefore of individual excess demands—on the ﬁnal equilibrium outcome.

The introduction of non-Walrasian elements into the GE microfoundations pro-

gram—such as ﬁxed or sticky prices, imperfect competition and incomplete markets leading

to temporary equilibrium models—yields interesting Keynesian features such as the break-

7

ing of the Say’s law and scope for a monetary theory of production, a rationale for ﬁnancial

institutions and a more persuasive treatment of informational frictions. As argued in [24],

however, all these approaches preserve a Walrasian perspective in that models are invariably

closed by a GE solution concept which, implicitly or (more often) not, implies the existence

of a ﬁctitious auctioneer who processes information, calculates equilibrium prices and quan-

tities, and regulates transactions. As a result, if the Walrasian Auctioneer (WA) is removed

the decentralized economy becomes dynamically incomplete, as we are not left with any

mechanism determining how quantities and prices are set and how exchanges occur.

In turn, the ﬂaws of the solution adopted by mainstream macroeconomists to overcome

the problems of uniqueness and stability of equilibrium on the one hand, and of analytically

tractability on the other one—i.e., the usage of a Representative Agent (RA) whose choices

summarize those of the whole population of agents—, are so pervasive and well known that

it seems worthless to discuss them here. Interested readers are referred to [25–27].

III. A CONSTRUCTIVE APPROACH TO MACROECONOMICS

The research methodology we endorse in trying to explain successes and failures of the

invisible hand consists in discarding the Walrasian GE approach to the microfoundation

program, as well as its RA shorthand version. Instead of asking to deductively prove the

existence of an equilibrium price vector p∗ such that F (p∗) = 0, we aimed at explicitly

constructing it by means of an algorithm or rule. From an epistemological perspective, this

implies a shift from the realm of classical to that of constructive theorizing [28].4 Clearly, the

act of computationally constructing a (fully or not) coordinated state—instead of imposing

it via the WA—for a decentralized economic system requires a complete description of goal-

directed economic agents and their interaction structure.

Agent-based computational economics (ACE)—that is the use of computer simula-

tions to study evolving complex systems composed of many autonomous interacting

agents—represents an eﬀective implementation of such a research agenda [29]. ACE allows

an explicit modeling of identiﬁable, goal-directed, adapting agents, situated in an explicit

space and interacting locally in it. In complex adaptive systems local interactions involves

4 Epstein (in [29]) prefers to talk of a generative approach to scientiﬁc explanation, but the meaning is

basically the same.

8

the spontaneous formation of macroscopic structures which can not be directly deduced by

looking at individual behaviors. The equilibrium of a system does not require any more that

every single element is in equilibrium by itself, but rather that the statistical distributions

describing aggregate phenomena are stable, i.e. in “[...] a state of macroscopic equilibrium

maintained by a large number of transitions in opposite directions” ([30], p. 356). A conse-

quence of the idea that macroscopic phenomena can emerge is that the strong reductionist

vision retained by neoclassicals is basically wrong. Once again, these concepts should be fa-

miliar to economists, at least to those who pay attention to the history of economic thought,

since they mirror the notion of spontaneous market order or catallaxy put forth by the Nobel

Prize in economics Friedrich von Hayek. According to him, a clear deﬁnition of the laws of

property, tort and contract is enough to regulate a set of trial and error exchange relation-

ships, which succeeds in coordinating the plans of an interdependent network of individuals

endowed with a multiplicity of competing ends. In contrast, Hayek argues that the notion

of competitive GE is “unfortunate, since it presupposes that the facts have already all been

discovered and competition, therefore, has ceased” ([31], p. 184).

It must be emphasized, however, that the abandonment of the GE solution concept does

not come at no cost. The optimality of a competitive GE associated with the First Wel-

fare Theorem implies that welfare comparisons between alternative macroeconomic states

can be meaningfully carried out. An operational method for performing aggregate welfare

comparisons also in macro ACE models has been advanced by Tesfatsion (in [29]). The

idea consists in deﬁning an ideal benchmark (for instance, the GDP in correspondence of

continual market clearing) and comparing it to the simulation outcomes. We can say the

system has reached a catallaxy if the distance between the simulated time series for GDP

and the ideal reference path diﬀers by less than a tolerance level τ .

IV. THE C@S PROJECT5

In [33] we grow a sequential economy populated by a ﬁnite number of ﬁrms i = 1, . . . , I,

workers/consumers j = 1, . . . , J, and banks b = 1, . . . , B, who undertake decisions at dis-

crete times t = 1, . . . , T on three markets, that is one for a homogeneous non-storable

5 The acronym stands for “Complex Adaptive Trivial System”. For an exposition of the key issues and

earlier results of this research program see [32].

9

consumption good, one for labor services and one for credit services. Notional prices and

quantities are chosen in an adaptive way, according to rules of thumb buﬀeted by idiosyn-

cratic random disturbances. All three markets are characterized by decentralized search and

matching processes, which imply individual, and a fortiori aggregate, out-of-equilibrium dy-

namics. Thus, due to the absence of any exogenously imposed market-clearing mechanism,

nothing prevents the economy from being characterized by a spontaneous order and the

contemporaneous occurrence of persistent involuntary unemployment, unsold production,

excess individual demands and credit rationing.

The sequence of events occurring in each period runs as follows.

a. At the beginning of any t, ﬁrms and banks check their ﬁnancial viability as inherited

from the past, and either they continue to operate if their neat wealth is positive, or

if it is lower or equal to zero they shut down due to bankruptcy. In the latter case, a

string of new ﬁrms/banks equal in number to the bankrupted ones enter the market.

Entrants are simply random copies of incumbents.

b. Starting from the demand it expects to face, De

it, each operating ﬁrm determines the

amount of output to be produced and the amount of labor to be hired. Expectations

on future demand are updated adaptively:

Dit−1 (1 + ρit)

if Dit−1 > Yit−1

De

it =

Dit−1

if Dit−1 = Yit−1

(IV.1)

Dit−1 (1 − ρit)

if Dit−1 < Yit−1






where Dit−1 was the demand faced by ﬁrm i during t − 1, Yit−1 was its supply, and ρit
is an idiosyncratic shock distributed on a positive support. The ith ﬁrm sets Yit = De
it

and, via the CRS technology Yit = aitLit, calculates its labor demand. Regardless of

the scale of output, production takes one whole period.

c. A fully decentralized labor market opens. Firms set their wage bids (actually each of

them sets a maximum wage, as a function of its own ﬁnancial soundness), and post

their vacancies on the basis of their labor demand. Workers, in turn, accept a job

only if the wage they are oﬀered is higher than their individual satisfying wage. A

sequential matching procedure determines whether unﬁlled vacancies and unemployed

10

workers remain after the labor market has closed. Firms then pay their wage bill Wit

in order to start production.

d. If internal ﬁnancial resources are in short supply for paying wages, ﬁrms can enter a

fully decentralized credit market and ﬁll in a ﬁxed number of applications to obtain

credit. We assume that due to prudential regulation, the total amount of loans supplied

by each bank is proportional to its equity. Banks allocate credit collecting individual

demands, sorting them in descending order according to the ﬁnancial viability of ﬁrms,

and satisfy them until all credit supply has been exhausted. The contractual interest

rate is calculated applying a mark-up (function of ﬁnancial viability) on a exogenously

determined baseline.

e. After production is completed, a market for goods opens. Any of the ith ﬁrm posts its

oﬀer price according to the adaptive rule:

Pit−1 (1 + ηit)

if Dit−1 > Yit−1

P s
it =

Pit−1

if Dit−1 = Yit−1

(IV.2)

Pit−1 (1 − ηit)

if Dit−1 < Yit−1






where ηit is an idiosyncratic random disturbance distributed on a positive support.

Prices are not allowed to be lower than expected average costs, however. The demand

for consumer goods is given by the whole labor income. Consumers muddle through

the market searching for a satisfying deal. When the consumer j identiﬁes a ﬁrm with

the lowest price in the neighborhood he can visit at no cost, he stops and concludes a

transactions. If a ﬁrm ends up with excess supply, it gets rid of the unsold goods at

zero costs.

f. Firms collect revenues, calculate proﬁts, update their net worth and, if internal re-

sources are enough, pay back their debt obligations. Firms employ part of retained

proﬁts in an R&D investment, aimed at increasing the productivity parameter ait.

Returns from the R&D investment are governed by a stochastic process.

The model is then completed with operational choices regarding procurement and match-

ing processes, rationing methods, search costs, and statistical distributions for random dis-

turbances. For instance, in structuring labor and goods markets we follow the lesson deliv-

ered by two distinguished scholars, Arthur Okun [34] and John Hicks [35], who suggested

11

50

100

150

200

250

300

350

400

450

500

50

100

150

200

250

300

350

400

450

500

13.56

13.54

13.52

13.5

13.48

13.46

13.44

13.42

13.4

)
n
o
i
t
c
u
d
o
r
p

d
e
t
a
g
e
r
g
g
A
(
g
o
l

13.38

0

0.03

0.025

0.02

0.015

0.01

t
n
e
m
y
o
l
p
m
e
n
U

Periods

(a)

Periods

(c)

Periods

(b)

(d)

0.045

0.04

0.035

0.03

e
t
a
r

n
o
i
t
a
ﬂ
n
I

0.025

0.02

0.015

0.01

0.005

0

-0.005

0

103

102

101

)
k
n
a
R
(
g
o
l

12

0.005

0

50

100

150

200

250

300

350

400

450

500

100

102

103

104

log(Production)

105

FIG. 1: Macroeconomic regularities emerging from simulations: (a) GDP (in log); (b) inﬂation

rate; (c) unemployment rate; (d) ﬁrms’ size distribution

to explicitly relate macroeconomic performance with non-Walrasian features like long-term

employer-worker relationships and buyer-seller ﬁdelity in customer markets. The great ﬂex-

ibility of the agent-based methodology we employ allows us to conduct experiments with

alternative assumptions in a computable laboratory. We refer to [33] for all other technical

details.

Panels (a) to (d) of FIG. 1 present some selected results from simulations. In spite of the

absence of any imposed GE closing of the model, the aggregate dynamics emerging from

decentralized market interactions among 1000 ﬁrms, 5000 worker/consumers and 100 banks

is far from being violently instable. Aggregate output or GDP (Panel a) follows a sustained

increasing path, and it mimics some well-known stylized facts of business cycle ﬂuctuations,

like alternating phases of smooth and large output variability, rare but signiﬁcant crises

(e.g., simulation periods 108–109, 354–362, 376–377), and segmented trends (e.g., periods

351–401 vs. 402–500). Both the CPI inﬂation rate (Panel b) and the unemployment rate

(Panel c) remain inside a stationary corridor. It seems interesting to note that the aggregate

stability is fully consistent with wide heterogeneity. In Panel (d), for instance, we report

the ﬁrms’ size distribution as emerging at period 500 from an original uniform distribution.

It clearly follows a power law, another renown regularity of industrial dynamics.

V. CONCLUSION

The preceding sections of this paper have been dedicated to four issues: 1) to intro-

duce a key research question fascinating economists since the beginning of the discipline,

that is that of explaining how millions of autonomous individuals with competing ends suc-

ceed in coordinating their economic activities by trading on fully decentralized markets;

2) to provide a critical assessment of the methodological solution endorsed by mainstream

macroeconomists, who try to reconcile individual behaviors and aggregate economic phe-

nomena (e.g., GDP, CPI, unemployment, income distribution) by means of Walrasian GE

analysis; 3) to brieﬂy discuss an alternative methodology, that is one rooted on an agent-

based constructive approach; 4) to present some results from recent work undertaken along

this latter and, according to us, much safer road to attain a reconciliation of micro and

macroeconomic theory.

In the remainder of this section, we shall discuss possible directions for future research.

Three lines seem particularly promising. The ﬁrst one consists in using our ACE macroecon-

omy as a computational laboratory in which market processes and institutions are allowed to

grow endogenously from scratch. This requires an explicit treatment of transaction and com-

munication costs, and a testable theory of how intermediaries (brokers and dealers) emerge.

While interesting work in the ACE literature already exists (see e.g.

[36, 37]), our main

concern is in assessing the endogenous co-evolution of markets, institutional arrangements

13

and macroeconomic dynamics. For instance, an interesting question is how job creation and

destruction and wage and price setting decisions at the ﬁrm level interact over the business

cycle in correspondence of alternative market structures. The second line of future inves-

tigation will deal with validation exercises [38]. From this viewpoint, we can distinguish

among: 1) descriptive output validation, when simulated data are compared with data from

real economies (e.g., macroeconomic time series and income distribution data for industrial-

ized countries); 2) predictive output validation, in which computationally generated output

is to be matched with yet-to-acquired real data. Clearly, predictive validation must come

with careful thinking about how to collect new data on possibly unexplored regularities;

3) input validation, insuring that market micro-structures, institutional arrangements and

behavioral rules incorporated into the model capture salient aspects of real-world economies.

This requires an interplay of ﬁeld-level data collection, human-based experiments and com-

putational design [39].

regulatory policies [40, 41].

Finally, the baseline model in its validated version can be used as a computational lab-

oratory to compare the welfare-increasing performance of alternative monetary, ﬁscal or

[1] Kirman A. P. (2006), Demand theory and general equilibrium: from explanation to introspec-

tion, a journey down the wrong road, mimeo, Princeton University.

[2] Keen S. (2003), Standing on the toes of pygmies: why econophysics must be careful of the

economic foundations on which it builds, Physica A, 324:108–116.

[3] Leijonhufvud A. (1998), Mr. Keynes and the Moderns, European Journal of the History of

[4] Leijonhufvud A. (2004), The metamorphosis of neoclassical economics, in Bellet M., Gloria-

Palermo S. and A. Zouache (eds.), Evolution of the Market Process: Austrian and Swedish

[5] Mirowski P. (2002), Machine Dreams. Economics Becomes a Cyborg Science. Cambridge,

[6] Freeman R. (1998), War of the models: which labour market insititutions for the 21st century?,

Economic Thought, 1:169–188.

Economics. London, Routledge.

Cambridge University Press.

Labour Economics, 5:1–24.

14

Econometrica, 22:265–290.

Economic Studies, 31:91–96.

Science. Cambridge, MIT Press.

[7] Hahn F. and R. Solow (1995), A Critical Essay on Modern Macroeconomic Theory. Cambridge,

[8] Smith A. (1776), An Inquiry into the Nature and Causes of the Wealth of Nations. New York,

[9] Arrow K. J. (1994), Methodological individualism and social knowledge, American Economic

MIT Press.

Modern Library.

Review, 84:1–9.

[10] Colander D. (2005), The future of economics: the appropriately educated in pursuit of the

knowable, Cambridge Journal of Economics, 29:927–941.

[11] Lucas R. and T. Sargent (1979), After Keynesian macroeconomics, Federal Reserve Bank of

Minneapolis Quarterly Review, 3, Spring issue.

[12] Walras L. (1874), El´ements d’´economie politique pure. Lausanne, Corbaz.

[13] Arrow K. J. and G. Debreu (1954), Existence of an equilibrium for a competitive economy,

[14] Arrow K. J. (1964), The role of securities in the optimal allocation of risk-bearing, Review of

[15] Ingrao B. and G. Israel (1990), The Invisible Hand. Economic Equilibrium in the History of

[16] Sonnenschein H. (1972), Market excess demand functions, Econometrica, 40:549–556.

[17] Debreu G. (1974), Excess demand function, Journal of Mathematical Economics, 1:15–23.

[18] Mantel R. (1974), On the characterization of aggregate excess demand, Journal of Economic

[19] Richter M. K. and K. Wong (1999), Non-computability of competitive equilibrium, Economic

[20] Velupillai K. V. (2000), Computable Economics. Oxford, Oxford University Press.

[21] Velupillai K. V. (2005), The foundations of computable general equilibrium theory, mimeo,

Theory, 7:348–353.

Theory, 14:1–28.

University of Trento.

[22] Arrow K. J. (1959), Towards a theory of price adjustment, in Abramovits M. (ed.), Allocation

of Economic Resources. Stanford, Stanford University Press.

[23] Debreu G. (1959), The Theory of Value. New York, John Wiley.

[24] Vriend N. (1994), A new perspective on decentralized trade, Economie Appliqu´ee, 46:5–22.

[25] Kirman A. P. (1992), Whom or what does the representative individual represent?, Journal

15

of Economic Perspectives, 6:117–136.

[26] Hartley J. E. (1997), The Representative Agent in Macroeconomics. London, Routledge.

[27] Gallegati M., Palestrini A., Delli Gatti D. and E. Scalas (2006), Aggregation of heteroge-

neous interacting agent: the variant representative agent framework, Journal of Economic

[28] Velupillai K. V. (2002), Eﬀectivity and constructivity in economic theory, Journal of Economic

Interaction and Coordination, 1:5–19.

Behavior and Organization, 49:307–325.

[29] Judd K. L. and L. S. Tesfatsion (2006), Handbook of Computational Economics, Vol. 2: Agent-

Based Computational Economics. Amsterdam, North Holland.

[30] Feller W. (1957), Introduction to Probability Theory and its Applications, Vol. 1. New York,

[31] Hayek F. A. (1978), New Studies in Philosophy, Politics, Economics and the History of Ideas.

Wiley.

Chicago, University of Chicago Press.

[32] Delli Gatti D., Gaﬀeo E., Gallegati M., Giulioni G. and A. Palestrini (2006), Emergent Macroe-

conomics. An Agent-based Approach to Business Fluctuations. Forthcoming.

[33] Gaﬀeo E., Catalano M., Delli Gatti D., Gallegati M. and A. Russo (2006), Macroeconomic

dynamics in an agent-based model, mimeo, Universit`a Politecnica delle Marche.

[34] Okun A. (1981), Prices & Quantities. A Macroeconomic Analysis. Washington, The Brookings

Institution.

[35] Hicks J. (1989), A Market Theory of Money. Oxford, Clarendon Press.

[36] Howitt P. and R. Clower (2000), The emergence of economic organization, Journal of Eco-

nomic Behavior and Organization, 41:55–84.

[37] Kirman A. P. and N. Vriend (2001), Evolving market structure: an ACE model of price

dispersion and loyalty, Journal of Economic Dynamics and Control, 25:459–502.

[38] Fagiolo G., Moneta A. and P. Windrum (2006), Empirical validation of agent-based models,

Journal of Economic Behavior and Organization, in press.

[39] Sunder S. (2006), Determinants of economic interaction: behavior and structure, Journal of

Economic Interaction and Coordination, 1:21–32.

[40] Delli Gatti D., Gaﬀeo E., Gallegati M. and A. Palestrini (2005), The apprentice wizard:

monetary policy, complexity and learning, New Mathematics and Natural Computation, 1:109–

128.

16

[41] Russo A., Catalano M., Gaﬀeo E., Gallegati M. and M. Napoletano (2006), Industrial dynam-

ics, ﬁscal policy and R&D: evidence from a computational experiment, Journal of Economic

Behavior and Organization, in press.

17

