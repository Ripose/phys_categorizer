7
0
0
2
 
b
e
F
 
3
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
0
1
1
2
0
7
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Critical transient in the Barab´asi model of human dynamics

A. Gabrielli, G. Caldarelli
SMC, INFM-CNR, Dipartimento di Fisica, Univ. “La Sapienza”, Piazzale A. Moro 2, 00185-Rome, Italy
and Istituto dei Sistemi Complessi CNR, via dei Taurini 19, 00185-Rome, Italy

We introduce an exact probabilistic description for L = 2 of the Barab´asi model for the dynamics
of a list of L tasks. This permits to study the problem out of stationarity, and to solve explicitly
the extremal limit case where a critical behavior for the waiting time distribution is observed. This
behavior deviates at any ﬁnite time from that of the stationary state. We study also the characteristic
relaxation time for ﬁnite time deviations from stationarity in all cases showing that it diverges in
the extremal limit conﬁrming that this deviations are important at all time.

PACS numbers:

Queueing theory is a very important branch of proba-
bility with fundamental applications in the study of dif-
ferent human dynamics [1]. Its capability in explaining
and modeling complex behaviors of such activities has
potentially important economical consequences. An ex-
ample is the prediction and organization of “queues” in
hi-tech communications. Queue stochastic dynamics are
traditionally modeled as homogeneous Poisson processes
[2]. This means that the probability to do a speciﬁc ac-
tion in the time dt is given by qdt, where q is the overall
activity per unit time, and there is no statistical correla-
tion between non overlapping time intervals. As a result,
the time interval between diﬀerent events is predicted to
be exponentially distributed. Actually, diﬀerent experi-
mental analysis [3, 4] have shown that for various human
activities the distribution of waiting times is better ﬁtted
by heavy tail distributions like the power laws character-
istic of Pareto processes. In order to reproduce such a
behavior Barab´asi [3] has introduced a simple model for
a task list with a heavy tail distribution of waiting times
in its stationary state and in a particular extremal limit.
In this paper we analyze the same model out of the sta-
tionary state introducing an exact step-by-step method
of analysis through which we ﬁnd the exact waiting time
distribution in the same extremal limit. We show that in
this limit the stationary state is reached so slowly that
almost all the dynamics is described by the transient.

In the Barab´asi model the list consists at any time in
a constant number L of tasks to execute. Each task has
a random priority index xi (i = 1, ...L) extracted by a
probability density function (PDF) ρ(x) independently
one of each other. The dynamical rule is the following:
with probability 0 ≤ p ≤ 1 the most urgent task (i.e.
the task with the highest priority) is selected, while with
complementary probability (1 − p) the selection of the
task is done completely at random. The selected task is
executed and removed from the list; it is then replaced
by a fresh new task with random priority extracted again
from ρ(x). For p = 0 the selection of the task at each time
step is completely random. Therefore the waiting time
distribution for a given task is P (τ ) = (1/L)(1 − 1/L)τ
and decays exponentially fast to zero with time constant
τ0 ≃ L. For p = 1 instead the dynamics is deterministic
selecting at each time step the task in the list with the

highest priority. Due to this extremal nature the statistics
of the dynamics for p = 1 does not depend on ρ(x). It
has been shown [3, 5] that the dynamics for 0 < p < 1
reaches a stationary state characterized by a waiting time
distribution P (τ ) which is proportional to τ −1 with a
p−dependent upper cut-oﬀ and amplitude. For p → 1
the cut-oﬀ diverges, but the amplitude vanishes, so that
in this limit from one side criticality (i.e. divergence of the
characteristic waiting time τ0) is approached, but from
the other P (τ ) looses sense due to the vanishing of its
amplitude. From simulations this behavior does not look
to depend on L, and the exact analytic solution for the
stationary state has been given for L = 2 in [5].

Here we propose a diﬀerent approach to the problem
for L = 2 able to give a complete description of the task
list dynamics also out of the stationary state. In this way
we ﬁnd the exact waiting time distribution for p = 1
which is characterized by power law tails, but with a dif-
ferent exponent from that found in [5] for the stationary
state. We also show that in this extremal limit the ﬁ-
nite time deviation from the trivial stationary state has
diverging relaxation times. Hence the waiting time dis-
tribution at any time is completely determined by these
deviations and diﬀers from the stationary one.

The method we use here is called Run Time Statistics
(RTS) [6] and it has been introduced originally to study
an important model of Self Organized Criticality (SOC):
the Invasion Percolation (IP) in dimension d = 2 [7, 8]
and related models [9]. For p = 1 this task list model can
be exactly mapped in Invasion Percolation (IP) in d = 1.
The latter has this formulation: consider a linear chain
of throats (see Fig.1), each of which is given, indepen-
dently of the others, a random number xi extracted from
the PDF ρ(x) and representing its capillarity (which is
inversely proportional to the diameter). At t = 0 the in-
vader ﬂuid is supposed to occupy only the central throat.
At each time step the growth interface is given by the
two non occupied throats in contact with the invaded
region. The invaded region grows by occupying the in-
terface throat with the maximal capillarity (i.e. minimal
diameter). In this way the interface is updated by elimi-
nating from it the selected throat and including the next
one in the direction of growth. This is exactly equivalent
to the task list problem for p = 1 and L = 2, with the

t=8 t=7 t=6 t=5

t=0 t=1

t=2

t=3

t=4

FIG. 1: The ﬁgure represents the ﬁrst eight time steps of IP
dynamics in d = 1. At each time step the throat of the growth
interface with the maximal capillarity (i.e. minimal diameter)
is occupied by the invader ﬂuid. The throats have random
capillarities, i.e. random diameters and, due to the extremal
nature of the dynamics, its statistical properties do not de-
pend on the PDF from which capillarities are extracted.

set of the already executed tasks given by the invaded
region, and the task list given by the two throats of in-
terface. Analogously the case of the task list with L > 2
can be mapped for p = 1 into the case of IP on a star-like
set of throats with L linear branches [10]. For 0 < p < 1
the task list problem would correspond to a sort of IP at
ﬁnite temperature [11] which introduces a source of noise
in the problem permitting random non extremal growths.
The quantity (1 − p) is a measure of such thermal noise
which vanishes for p = 1 and becomes maximal for p = 0.
In general for growth processes with quenched disor-
der it is very diﬃcult to factorize the statistical weight
of a growth path (i.e. selection sequence) into the prod-
uct of probabilities of the composing elementary steps.
The problem is that these single-step probabilities de-
pend upon all the past history of the process, i.e, dynam-
ics in quenched disorder present usually strong memory
eﬀects. This feature makes very diﬃcult to evaluate the
statistical weight of any possible history of the process
which is usually the elementary ingredient to perform
averages over the possible realizations of the dynamics.
To overcome this diﬃculty, RTS gives a step-by-step pro-
cedure to write the exact evolution of the probabilities of
the single steps conditional to the past history and the re-
lated conditional PDF of the random variables attached
to the growing elements (“task priorities” in this case).
Given two tasks with respective priorities x and y, we
call η(x, y) the probability conditional to these values to
execute the task with priority x. The form of η is de-
termined by the selection (i.e. growth in IP) rule of the
model. Given the deﬁnition of the Bar´basi model and
being θ(x) the Heaviside step function, we have:

2

from the list and replaced by a fresh new task with a
random priority extracted from ρ(x). The other task re-
mains instead in the list. We indicate the ﬁrst fresh task
with N (as “new”). The PDF of its priority conditional
to the past history is simply ρ(x) as it is new. The sec-
ond task is consequently indicated with O (as “old”),
and we call the PDF of its priority, conditional to the
past history of the task list, as pO(x, t). For all t > 0
and p > 0 it diﬀers from ρ(x). Given our particular form
(1) of η(x, y), pO(x, t) is, for p > 0, more concentrated
on the small values of x than ρ(x). At t = 0 the ini-
tial condition is pO(x, 0) = ρ(x). Since at each time-step
the task N is new, the priorities x and y of N and O
are statistically independent and their joint probability
factorizes into the product ρ(x)pO(y, t). Any realization
of the task list (i.e. a selection path) lasting τ steps can
be represented as a time ordered string of τ letters N
and O (e.g. N ON N ON O....). In particular the statisti-
cal weight of the selection path N N..N composed by τ
subsequent events N gives the probability that the wait-
ing time of the task O, from the beginning of the list
dynamics, is at least τ . In terms of IP in d = 1 this
path represents a growth avalanche in one single direc-
tion starting at t = 0 and lasting at least τ steps. We can
rewrite Eq. (2) for both the cases in which the task N or
O are selected at time t:

1
0
R

µN (t) =

1
0
R
µ0(t) = 1 − µN (t) =

1
0 dx dy ρ(x)pO(y, t)η(x, y)
R




1
0 dx dy pO(x, t)ρ(y)η(x, y)



(3)
R
For each of this two selection events we update conse-
quently the conditional PDFs of the priorities including
this last step in the past history conditioning probabili-
ties. As explained above, the conditional PDF of the new
task replacing the selected one is ρ(x). Instead the condi-
tional PDF pO(x, t+1) at time t+1 of the just unselected
task, still in the list, is diﬀerent in the two cases above. If
the task N is selected, the task O remains O also at the
next time-step (see Fig.2). We can use the rules of the
conditional probability to include the last selection step
in the “memory” of the past history:

pO(x, t + 1) =

pO(x, t)

dyρ(y)η(y, x) .

(4)

1
µN (t)

1

Z

0

η(x, y) = pθ(x − y) +

1 − p
2

.

If instead O is selected at time t, it is removed, and the
N at time t becomes the task O at time (t + 1):

(1)

If we now suppose that at the tth time-step of the se-
lection dynamics the variables x and y are statistically
independent and have respectively the PDFs conditional
to the past history of the process p(x, t) and q(y, t), we
can write the probability of selecting the task with pri-
ority x conditional to the past history as

µ(t) =

dx dy p(x, t)q(y, t)η(x, y).

(2)

1

1

Z

0 Z
0

When the selection is done the selected task is removed

pO(x, t + 1) =

ρ(x)

dypO(y, t)η(y, x) .

(5)

1
µO(t)

1

Z

0

The whole set of all possible selection paths can be rep-
resented as a non-Markovian binary branching process
whose realizations tree is represented in Fig.2. The initial
node (top vertex) represents the initial situation where
one has two tasks with completely random priorities [i.e.
distributed as ρ(x)]. From each node there is a bifurcation
of possible choices: either task N or O is selected. There-
fore each node of the tree represents the task list at the

end of the time ordered selection path connecting directly
the top vertex with the given node and is characterized
by path-dependent conditional PDF pO and probabilities
for the next bifurcation µN and µO. The exact statistical
weight of each path on the tree and the conditional PDF
pO at the end of it can be calculated by applying the
above RTS step-by-step procedure. Therefore the RTS
provides a complete mathematical description of the task
list dynamics. Note that the dynamics of the task list in
this model is a binary branching process with memory,
in the sense that the probabilities of a conﬁguration at a
given time depends for p > 0 on all the past history of
the list. This memory eﬀect is maximized for p = 1 when
the list dynamics becomes deterministic and extremal.

A very important quantity in this class of dynamics
is the average priority “histogram” [8, 11], that is the
statistical distribution of the priorities of the task list
at a given time t averaged over all the selection paths:
h(x, t) = [ρ(x) + hpO(x, t)it]/2. Hence, the evolution of
h(x, t) is directly given by that of ρ1(x, t) = hpO(x, t)it.
The equation for its time evolution can be found by ob-
serving that at each binary branching starting from a
node at time t of the tree we can say that with probabil-
ity µN (t) the priority conditional PDF pO(x, t) updates
as in Eq. (4) and with probability µO(t) as in Eq. (5), i.e.

πO(x, t + 1; t) = pO(x, t)

dyρ(y)η(y, x)

1

Z

0

1

Z

0

1

0

Z
1

Z

0

where πO(x, t+1; t) is the conditional PDF of the priority
of the task O at time (t + 1) conditional to the history
only up to time t. By applying this average from the ﬁrst
time step it is simple to show that:

ρ1(x, t + 1) = ρ1(x, t)

dyρ(y)η(y, x)

+ ρ(x)

dyρ1(y, t)η(y, x) .

(6)

This is exactly the basic equation used in [5] to study
the task list dynamics in the stationary state, i.e., when
ρ1(x, t+1) = ρ1(x, t). We show in the following that how-
ever in the limit p → 1 the stationary state is reached
only very slowly and that the waiting time distribution
is determined by the ﬁnite time deviation from the sta-
tionary state at all time. This waiting time distribution
is again a power law, but with a diﬀerent exponent with
respect to that found in [5]. We now solve exactly the
RTS for the case p = 1. For our calculation we use here
ρ(x) = 1 for x ∈ [0, 1] as in [5] because the path statistics,
as aforementioned, does not depend on ρ(x) for p = 1.
Hence Eqs. (3) above takes the simple form:

1

µe

N (t) =

0 dx (1 − x)pe
R
O(t) = 1 − µe
µe

N (t) =

1

O(x, t)

0 dx xpe

O(x, t) ,

R






3

1

t=0

t=1

t=2

4

2

N

N

O

5

3

O

N

6

O

7

N

O

N

O

N

O

N

O

t=3

8

9

10

11

12

13

14

15

FIG. 2: Tree representation of all the possible selection paths
(i.e. realizations of the dynamics). At each time step either
the fresh new task (N ) either the old one (O) is selected. In
general for p > 0 pO(x, t) at the end of a path depend on the
speciﬁc path. Only for p = 1, when information on priorities
and memory are maximal, pO(x, t) is the same for all paths.

where the superscript “e” stands for “extremal”. Analo-
gously Eqs. (4) and (5) for p = 1 read respectively

pe
0(x, t + 1) =

(1 − x)pe

O(x, t)

pe
0(x, t + 1) =

dx pe

O(x, t) .

µe

1
N (t)
1
µe
O(t) Z
x

1

t + 1
t + 2

µe
N (t) =
O(t) =
O(x, t) = (t + 1)(1 − x)t .
pe

; µe

1
t + 2

(7)

(8)

Since pe
O(x, t) is independent of the considered path,
ρ1(x, t) for p = 1 coincides with it. Note that µe
N (t →
∞) → 1 and ρ1(x, t) = pe
O(x, t→∞) → δ(x − 0+) [where
δ(x) is the Dirac delta function], i.e., in the inﬁnite time
limit the new fresh task is always selected as the old
one has vanishing priority with probability one. The fact
that both the µe’s and the pe’s at time t are the same for
each selection path of length t is a feature of the p = 1
case. This is not the case for 0 < p < 1 where instead
the conditional selection probability and priority PDFs
at time t depend on which speciﬁc selection path is con-
sidered. We now analyze the consequences of Eq. (7). It
permits to ﬁnd the waiting time distribution of a given
task entered the list at time t0. From Eq. (7) we ﬁnd
that for p = 1 the waiting time is τ = 0 with probability
P (τ = 0; t0) = (t0 + 1)/(t0 + 2). The probability that it
is still waiting after τ ≥ 1 steps, i.e. at time t0 + τ , is:

W (τ, t0) =

1
t0 + 2

τ −1

Yt′=1

t0 + t′ + 1
t0 + t′ + 2

=

1
t0 + τ + 1

,

which is the probability of the path ON N...N with one
O event at t0 and (τ − 1) subsequent N events. Hence

+ ρ(x)

dypO(y, t)η(y, x) ,

using pe
that, for any selection path, µe

O(x, 0) = ρ(x) in the above equations, one ﬁnds
N , µe

O becomes:

O and pe

the probability that the waiting time is exactly τ ≥ 1 is

P (τ ; t0) =

W (τ ; t0)
t0 + τ + 2

=

1
(t0 + τ + 1)(t0 + τ + 2)

,

(9)

which is the statistical weight of the selection path
ON N...N O with one O event at t0, (τ − 1) subsequent
N events and a ﬁnal O event. Note that this corresponds
in IP to the statistical weight of an avalanche starting
a time t0 and lasting τ steps. The probability P (τ ; t0)
decreases as τ −2 for τ ≫ t0 (a behavior conﬁrmed by
numerical simulations). Therefore the waiting time dis-
tribution for a task entered at time t0 is normalizable
in τ , but with diverging mean value. This behavior is
diﬀerent from the power law P (τ ) ∼ τ −1 found in [5]
for the stationary state for 0 < p < 1, which however
disappears for p → 1− as its amplitude vanishes in this
limit. For the opposite limit t0 ≫ τ ≫ 1 one can write
−2
−2
P (τ ; t0) ≃ t
0 (1 − 2τ /t0), which decreases as t
0 with t0.
This gives the rate of approach in the initial time t0 to
the trivial stationary state P (τ ; t0 → ∞) = 1 or 0 respec-
tively if τ = 0 or τ ≥ 1. This rate is very slow and there
is no characteristic time after which one can say that the
stationary state is attained in terms of τ dependence.

In order to study more in detail the approach to the
stationary state for all p and for p → 1, we analyze Eq. (6)
out of the stationary state. First of all we rewrite this
equation using the explicit form (1) of η(x, y) for this
model and ρ(x) = 1 for x ∈ [0, 1]:

ρ1(x, t + 1) = ρ1(x, t)

p(1 − x) +

(cid:20)

1

Z
x

1 − p

2 (cid:21)

1 − p
2

.

+ p

dyρ1(y, t) +

(10)

We now put ρ1(x, t) = ρ(s)
is the stationary solution found in Eq. (4) of [5]:

1 (x) + δρ1(x, t) , where ρ(s)

1 (x)

ρ(s)
1 (x) =

1 + p
1 − p

1
[1 + 2p
1−p x]2

(11)

4

p → 1 the PDF ρ(s)
1 (x) → δ(x − 0+) and it coincides with
Eq. (8) for t → ∞. Since ρ1(x, t) and ρ(s)
1 (x) are both nor-
1
0 dxδρ1(x, t) = 0. Therefore
malized to unity, we have
1
R
as a ﬁrst order approximation we put
x dy δρ1(y, t) ≃
−xδρ1(x, t). Taking also the continuous time approxima-
R
tion [δρ1(x, t + 1) − δρ1(x, t)] ≃ dδρ1(x, t)/dt, we can
rewrite Eq. (10) in terms of δρ1(x, t) as

dδρ1(x, t)
dt

≃ −

1 − p
2

(cid:18)

+ 2px

δρ1(x, t) .

(12)

(cid:19)

Hence δρ1(x, t) decays exponentially in time with an
x−dependent time constant inversely proportional to
[(1 − p)/2 + 2px]. For p < 1, at each x the perturba-
tion decays exponentially fast and the stationary state
is attained, while for p → 1 the time constants becomes
proportional to 1/x and the perturbation in the region
around x = 0 relaxes very slowly. But from Eq. (11) it
is exactly in this region that for p → 1 all the measure
ρ(s)(x) is concentrated. This conﬁrms our previous con-
clusion that for p → 1 the stationary state is very slowly
attained and ﬁnite time deviation from it play a funda-
mental role in determining the rate of decrease of the
waiting time distribution.

In this paper we have studied an interesting queue-
ing model of task list dynamics introduced by Bar´abasi.
Through a statistical method called RTS, we are able to
give a complete probabilistic description of the dynamics
even out of stationarity. We ﬁnd that for 0 < p < 1 ﬁnite
time deviations from stationarity relaxes exponentially
fast and, consequently, the dynamics is well described by
the stationary state. However for p → 1 the stationary
state becomes trivial and ﬁnite time deviations relaxes
so slowly that the task list dynamics has to be described
as an intrinsically non stationary dynamics. This is char-
acterized by power law waiting time distributions with
a characteristic exponent which is diﬀerent from the one
found [5] in the stationary state for 0 < p < 1.

and δρ1(x, t) is the ﬁnite time deviation from it. For

GC acknowledges support from EU Project DELIS

[1] HC Tijms, A First Course in Stochastic Models, Wiley

(1996).

Chichester, (2003).

[2] L. Breuer and D. Baum An Introduction to Queueing
Theory and Matrix-Analytic Methods. Springer Verlag
(2005).

[3] A.-L. Barab´asi, Nature (London) 207, 435 (2005).
[4] A. V´azquez, J. G. Oliveira, Z. Dezs˝o, K.-I. Goh, I. Kon-
dor, A.-L. Barab´asi Physical Review E 73, 036127 (2006).
[5] A. Vazquez, Physical Review Letters 95, 248701 (2005).
[6] M. Marsili, Journal of Statistical Physics, 77 733–
754,(1994); A. Gabrielli, M. Marsili, R. Caﬁero, L.
Pietronero, Journal of Statistical Physics, 84 889–893,

[7] D. Wilkinson and J.F. Willemsen, Journal of Physics A,

16, 3365-3376 (1983).

[8] A. Gabrielli, R. Caﬁero, M. Marsili, and L. Pietronero,

Phys. Rev. E, 54, 1406 (1996).

[9] M. Felici, G. Caldarelli, A. Gabrielli, and L. Pietronero,

Phys. Rev. Lett., 86, 1896 (2001).

[10] A. Gabrielli, F. Rao, G. Caldarelli, in preparation.
[11] A. Gabrielli, G. Caldarelli, L. Pietronero, Physical Re-

view E 62, 7638–7641 (2000)

