5
0
0
2
 
c
e
D
 
2
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
6
0
1
2
1
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Computing communities in large networks using random walks

Pascal Pons and Matthieu Latapy

LIAFA – CNRS and University Paris 7 – 2 place Jussieu, 75251 Paris Cedex 05, France
(pons, latapy)@liafa.jussieu.fr

Abstract

Dense subgraphs of sparse graphs (communities), which appear in most real-world complex
networks, play an important role in many contexts. Computing them however is generally expen-
sive. We propose here a measure of similarities between vertices based on random walks which
has several important advantages: it captures well the community structure in a network, it can
be computed eﬃciently, and it can be used in an agglomerative algorithm to compute eﬃciently
the community structure of a network. We propose such an algorithm, called Walktrap, which
log n) and space O(n2
runs in time O(mn2
)
in most real-world cases (n and m are respectively the number of vertices and edges in the input
graph). Extensive comparison tests show that our algorithm surpasses previously proposed ones
concerning the quality of the obtained community structures and that it stands among the best
ones concerning the running time.

) in the worst case, and in time O(n2

) and space O(n2

Keywords: complex networks, graph theory, community structure, random walks.

1

Introduction

Recent advances have brought out the importance of complex networks in many diﬀer-
ent domains such as sociology (acquaintance networks, collaboration networks), biology
(metabolic networks, gene networks) or computer science (internet topology, web graph,
p2p networks). We refer to [45, 42, 1, 31, 12] for reviews from diﬀerent perspectives and for
an extensive bibliography. The associated graphs are in general globally sparse but locally
dense: there exist groups of vertices, called communities, highly connected between them
but with few links to other vertices. This kind of structure brings out much information
about the network. For example, in a metabolic network the communities correspond
to biological functions of the cell [38]. In the web graph the communities correspond to
topics of interest [29, 18].

i, Ci

This notion of community is however diﬃcult to deﬁne formally. Many deﬁnitions
have been proposed in social networks studies [45], but they are too restrictive or cannot
be computed eﬃciently. However, most recent approaches have reached a consensus,
of the vertices of a graph G = (V, E)
and consider that a partition
}
V ) represents a good community structure if the proportion of edges inside
(
∀
the Ci (internal edges) is high compared to the proportion of edges between them (see
for example the deﬁnitions given in [19]). Therefore, we will design an algorithm which
ﬁnds communities satisfying this criterion. More precisley, we will evaluate the quality
of a partition into communities using a quantity (known as modularity [32, 33]) which
captures this.

C1, . . . , Ck

⊆

=

P

{

We will consider throughout this paper an undirected graph G = (V, E) with n =

V
|
|
vertices and m =
edges. We impose that each vertex is linked to itself by a loop (we
add these loops if necessary). We also suppose that G is connected, the case where it is
not being treated by considering the components as diﬀerent graphs.

E
|

|

1.1 Our approach and results

Our approach is based on the following intuition: random walks on a graph tend to get
“trapped” into densely connected parts corresponding to communities. We therefore begin

1

with some properties of random walks on graphs. Using them, we deﬁne a measurement
of the structural similarity between vertices and between communities, thus deﬁning a
distance. We relate this distance to existing spectral approaches of the problem. But
our distance has an important advantage on these methods: it is eﬃciently computable,
and can be used in a hierarchical clustering algorithm (merging iteratively the vertices
into communities). One obtains this way a hierarchical community structure that may
be represented as a tree called dendrogram (an example is provided in Figure 1). We
propose such an algorithm, called Walktrap, which computes a community structure in
(mnH) where H is the height of the corresponding dendrogram. The worst case is
time
(n)) and, as already
O
noticed in [8], H is generally small and tends to the most favourable case in which the den-
(n2 log n).
drogram is balanced (H =
We ﬁnally evaluate the performance of our algorithm with diﬀerent experiments which
show that it surpasses previously proposed algorithms in most cases.

(mn2). But most real-world complex networks are sparse (m =

(log n)). In this case, the complexity is therefore

O

O

O

O

1.2 Related work

Many algorithms to ﬁnd community structures in graphs exist. Most of them result from
very recent works, but this topic is related to the classical problem of graph partitioning
that consists in splitting a graph into a given number of groups while minimizing the cost
of the edge cut [17, 35, 28]. However, these algorithms are not well suited to our case
because they need the number of communities and their size as parameters. The recent
interest in the domain has started with a new divisive approach proposed by Girvan and
Newman [23, 33]: the edges with the largest betweenness (number of shortest paths passing
through an edge) are removed one by one in order to split hierarchically the graph into
(m2n). Similar algorithms were proposed by
communities. This algorithm runs in time
O
Radicchi et al [36] and by Fortunato et al [19]. The ﬁrst one uses a local quantity (the
number of loops of a given length containing an edge) to choose the edges to remove and
(m2). The second one uses a more complex notion of information centrality
runs in time
that gives better results but poor performances in

(m3n).

O

Hierarchical clustering is another classical approach introduced by sociologists for data
analysis [3, 15]. From a measurement of the similarity between vertices, an agglomera-
tive algorithm groups iteratively the vertices into communities (diﬀerent methods exist,
depending on the way of choosing the communities to merge at each step). Several ag-
glomerative methods have been recently introduced and we will use it in our approach.
Newman proposed in [32] a greedy algorithm that starts with n communities correspond-
ing to the vertices and merges communities in order to optimize a function called mod-
(mn) and
ularity which measures the quality of a partition. This algorithm runs in
(mH log n) (with our notations) [8]. The
has recently been improved to a complexity
algorithm of Donetti and Mu˜noz [10] also uses a hierarchical clustering method: they use
the eigenvectors of the Laplacian matrix of the graph to measure the similarities between
vertices. The complexity is determined by the computation of all the eigenvectors, in
(n3) time for sparse matrices. Other interesting methods have been proposed, see for

O

O

O

O
instance [46, 9, 39, 5, 7, 14].

Random walks themselves have already been used to infer structural properties of
networks in some previous works. Gaume [21] used this notion in linguistic context. Fouss
et al [20] used the Euclidean commute time distance based on the average ﬁrst-passage
time of walkers. Zhou and Lipowsky [48] introduced another dissimilarity index based on
the same quantity; it has been used in a hierarchical algorithm (called Netwalk). Markov
Cluster Algorithm [43] iterates two matrix operations (one corresponding to random walks)
bringing out clusters in the limit state. Unfortunately the three last approaches run
(n3) and cannot manage networks with more than a few thousand vertices. Our
in
approach has the main advantage to be signiﬁcatively faster while producing very good

O

2

results.

2 Preliminaries on random walks

The graph G is associated to its adjacency matrix A: Aij = 1 if vertices i and j are
Pj Aij of vertex i is the number of
connected and Aij = 0 otherwise. The degree d(i) =
its neighbors (including itself). As we discussed in the introduction, the graph is assumed
to be connected. To simplify the notations, we only consider unweighted graphs in this
R+ instead
paper. It is however trivial to extend our results to weighted graphs (Aij
of Aij

), which is an advantage of this approach.

0, 1

∈

∈ {

}

Let us consider a discrete random walk process (or diﬀusion process) on the graph G
(see [30, 4] for a complete presentation of the topic). At each time step a walker is on a
vertex and moves to a vertex chosen randomly and uniformly among its neighbors. The
sequence of visited vertices is a Markov chain, the states of which are the vertices of the
graph. At each step, the transition probability from vertex i to vertex j is Pij = Aij
d(i) . This
1A
deﬁnes the transition matrix P of random walk processes. One can also write P = D−
where D is the diagonal matrix of the degrees (

i, Dii = d(i) and Dij = 0 for i

= j).

The process is driven by the powers of the matrix P : the probability of going from
i to j through a random walk of length t is (P t)ij . In the following, we will denote this
probability by P t
It satisﬁes two well known properties of the random walk process
ij .
which we will use in the sequel:

∀

Property 1 When the length t of a random walk starting at vertex i tends towards in-
ﬁnity, the probability of being on a vertex j only depends on the degree of vertex j (and
not on the starting vertex i):

i,

∀

lim
t
+
→

∞

P t

ij =

d(j)
Pk d(k)

We will provide a proof of this property in the next section.

Property 2 The probabilities of going from i to j and from j to i through a random walk
of a ﬁxed length t have a ratio that only depends on the degrees d(i) and d(j):

i,

j, d(i)P t
∀
Proof : This property can be written as the matricial equation DP tD−
M T is the transpose of the matrix M ). By using P = D−
matrices D and A, we have: DP tD−
((D−

1A)T )t = (P t)T .

ij = d(j)P t
ji

1 = D(D−

1 = (AD−

1A)tD−

1 = (P t)T (where
1A and the symmetry of the
1)T )t =
1)t = (AT (D−
(cid:3)

∀

3 Comparing vertices using short random walks

3.1 A distance r to measure vertex similarities

In order to group the vertices into communities, we will now introduce a distance r between
the vertices that captures the community structure of the graph. This distance must be
large if the two vertices are in diﬀerent communities, and on the contrary if they are in
the same community it must be small. It will be computed from the information given
by random walks in the graph.

Let us consider random walks on G of a given length t. We will use the information
ij to go from i to j in t steps. The length t of the random

given by all the probabilities P t

3

6
walks must be suﬃciently long to gather enough information about the topology of the
graph. However t must not be too long, to avoid the eﬀect predicted by Property 1; the
probabilities would only depend on the degree of the vertices. Each probability P t
ij gives
ij and P t
some information about the two vertices i and j, but Property 2 says that P t
ji
encode exactly the same information. Finally, the information about vertex i encoded
i.. To compare two vertices i and j using these data, we must
n, which is nothing but the ith row of the
in P t resides in the n probabilities (P t
matrix P t, denoted by P t
notice that:

ik)1

≤

≤

k

•

•

•

ij will surely be
ij is high does not necessarily imply that i and j are in the

If two vertices i and j are in the same community, the probability P t
high. But the fact that P t
same community.
The probability P t
probability to go to high degree vertices.

ij is inﬂuenced by the degree d(j) because the walker has higher

Two vertices of a same community tend to “see” all the other vertices in the same
way. Thus if i and j are in the same community, we will probably have
jk.

P t

k, P t
∀

ik ≃

We can now give the deﬁnition of our distance between vertices, which takes into account
all previous remarks:

Deﬁnition 1 Let i and j be two vertices in the graph and

n

rij = v
u
u
t

X
k=1

(P t

ik −

P t
d(k)

jk)2

= (cid:13)
(cid:13)
(cid:13)

D−

1

2 P t

D−

1

2 P t

i.

−

j.(cid:13)

(cid:13)
(cid:13)

(1)

where

.
k

k

is the Euclidean norm of Rn.

One can notice that this distance can also be seen as the L2 distance [4] between the
two probability distributions P t
and should be denoted by rij (t). We will however consider it as implicit to simplify the
notations.

j.. Notice also that the distance depends on t

i. and P t

Now we generalize our distance between vertices to a distance between communities
in a straightforward way. Let us consider random walks that start from a community: the
starting vertex is chosen randomly and uniformly among the vertices of the community.
We deﬁne the probability P t

Cj to go from community C to vertex j in t steps:

P t

Cj =

1
C
|

|

X
C
i
∈

P t
ij

C. that allows us to generalize our distance:

V be two communities. We deﬁne the distance rC1C2 between

This deﬁnes a probability vector P t
Deﬁnition 2 Let C1, C2 ⊂
these two communities by:

C1.

D−

1

2 P t

D−

1

2 P t

−

C2.(cid:13)

(cid:13)
(cid:13)

n

= v
u
u
t

X
k=1

rC1C2 = (cid:13)
(cid:13)
(cid:13)

(P t

C1k −

P t
d(k)

C2k)2

This deﬁnition is consistent with the previous one: rij = r
i
}{
{
the distance between a vertex i and a community C: riC = r
i
}
{

j
}
C .

and we can also deﬁne

4

3.2 Relation with spectral approaches

Theorem 1 The distance r is related to the spectral properties of the matrix P by:

r2
ij =

λ2t
α (vα(i)

vα(j))2

−

n

X
α=2

where (λα)1
α
≤
the matrix P .

≤

n and (vα)1

α

≤

≤

n are respectively the eigenvalues and right eigenvectors of

In order to prove this theorem, we need the following technical lemma:

Lemma 1 The eigenvalues of the matrix P are real and satisfy:

1 = λ1 > λ2 ≥

. . .

≥

λn >

1

−

Moreover, there exists an orthonormal family of vectors (sα)1
vα = D−
the eigenvalue λα:

n such that each vector
2 sα are respectively a right and a left eigenvector associated to

2 sα and uα = D

≤

≤

α

1

1

α, P vα = λαvα and P T uα = λαuα
∀

1

1

∀

α,

2 AD−

α uβ = δαβ

β, vT
∀
1
Proof : The matrix P has the same eigenvalues as its similar matrix S = D
2 =
D−
2 . The matrix S is real and symmetric, so its eigenvalues λα are real. P is a
n
j=1 Pij = 1), so its largest eigenvalue is λ1 = 1. The graph G is
stochastic matrix (
connected and primitive (the gcd of the cycle lengths of G is 1, due to the loops on each
vertex), therefore we can apply the Perron-Frobenius theorem which implies that P has
a unique dominant eigenvalue. Therefore we have:

< 1 for 2

2 P D−

P

n.

α

1

The symmetry of S implies that there also exists an orthonornal family sα of eigen-
α sβ = δαβ (where δαβ = 1 if α = β and 0 otherwise). We
2 sα are respectively a right
(cid:3)

vectors of S satisfying
∀
then directly obtain that the vectors vα = D−
and a left eigenvector of P satisfying uT

2 sα and uα = D

β, sT
∀

α,

1

1

αvβ = δαβ.

λα
|

|

≤

≤

We can now prove Theorem 1 and obtain Property 1 as a corrolary:

Proof : Lemma 1 makes it possible to write a spectral decomposition of the matrix P :

P =

λαvαuT

α , and P t =

αvαuT
λt

α , and so P t

ij =

λt
αvα(i)uα(j)

n

X
α=1

n

X
α=1

When t tends towards inﬁnity, all the terms α
ﬁrst right eigenvector v1 is constant. By normalizing we have

2 vanish. It is easy to show that the
i, v1(i) =
and

≥

1
P k d(k)

√

j, u1(j) =

∀

d(j)
P k d(k)

√

. We obtain Property 1:

lim
t
+
→

∞

P t

ij = lim
t
+
∞
→

n

X
α=1

λt
αvα(i)uα(j) = v1(i)u1(j) =

d(j)
n
k=1 d(k)

P

i.:

Now we obtain the expression of the probability vector P t

n

X
α=1

∀

i. =

P t

n

X
α=1

λt
αvα(i)uα = D

1
2

λt
αvα(i)sα

n

X
α=1

We put this formula into the second deﬁnition of rij given in Equation (1). Then we
use the Pythagorean theorem with the orthonormal family of vectors (sα)1
n, and we

α

≤

≤

5

remember that the vector v1 is constant to remove the case α = 1 in the sum. Finally we
have:

n

X
α=1

r2
ij = (cid:13)
(cid:13)
(cid:13)
(cid:13)

λt
α(vα(i)

2
vα(j))sα(cid:13)
(cid:13)
(cid:13)
(cid:13)

−

=

n

X
α=2

λ2t
α (vα(i)

vα(j))2

−

(cid:3)

This theorem relates random walks on graphs to the many current works that study
community structure using spectral properties of graphs. For example, [41] notices that
the modular structure of a graph is expressed in the eigenvectors of P (other than v1)
that corresponds to the largest positive eigenvalues. If two vertices i and j belong to a
same community then the coordinates vα(i) and vα(j) are similar in all these eigenvectors.
Moreover, [40, 22] show in a more general case that when an eigenvalue λα tends to 1, the
coordinates of the associated eigenvector vα are constant in the subsets of vertices that
correspond to communities. A distance similar to ours (but that cannot be computed
directly with random walks) is also introduced: d2
. Finally,
[10] uses the same spectral approach applied to the Laplacian matrix of the graph L =
D

−
All these studies show that the spectral approach takes an important part in the
search for community structure in graphs. However all these approaches have the same
(n3) for a sparse
drawback: the eigenvectors need to be explicitly computed (in time
matrix). This computation rapidly becomes untractable in practice when the size of the
graph exceeds some thousands of vertices. Our approach is based on the same foundation
but has the advantage of avoiding the expensive computation of the eigenvectors: it only
needs to compute the probabilities P t
ij, which can be done eﬃciently as shown in the
following subsection.

n
α=2
P

t (i, j) =

vα(j))
t
λα

−
−|

(vα(i)

A.

O

1

2

|

3.3 Computation of the distance r
Once the two vectors P t
time
the distance rC1C2 is also computed in time

i. and P t

O

(n)

j. are computed, the distance rij can be computed in
C2.,

C1. and P t

(n) using Equation (1). Notice that given the probability vectors P t

O
The probability vectors can be computed once and stored in memory (which uses
(n2) memory space) or they can be dynamically computed (which increases the time
O
complexity) depending on the amont of available memory. We propose an exact method
and an approximated method to compute them.

Exact computation

Theorem 2 Each probability vector P t

Proof : To compute the vector P t
by the matrix P . This direct method is advantageous in our case because the matrix P is
generally sparse (for real-world complex networks) therefore each product is processed in
(n) and thus each of the n vectors P t
time
(cid:3)
is computed in time

i. can be computed in time
i., we multiply t times the vector P 0
i. (
i. is done in

i.(k) = δik)
i.

(m). The initialization of P 0

(tm) and space

(n + tm) =

k, P 0

(tm).

(n).

O

O

O

O

∀

O

O

Approximated computation

Theorem 3 Each probability vector P t

(K) with an relative error

O

( 1
√K

).

O

i. can be approximated in time

(Kt) and space

O

6

Proof : We compute K random walks of length t starting from vertex i. Then we
approximate each probability P t
K where Nik is the number of walkers that ended
on vertex k during the K random walks. The Central Limit Theorem implies that this
quantity tends toward P t
) when K tends toward inﬁnity. Each
O
(t) and constant space hence the overall
random walk computation is done in time
(cid:3)
computation is done in time

O
(Kt) and space

ik with a speed

ik by Nik

( 1
√K

(K).

O

O

The approximated method is only interresting for very large graphs. In the following

we will consider the exact method for the complexity and the experimental evaluation.

3.4 Generalizing the distance

We saw that our distance is directly related to the spectral properties of the transition
matrix P . We show in this section how one can generalize easily and eﬃciently this
distance to use another weighting of the eigenvectors. To achieve this, we only need to
deﬁne diﬀerent vectors

Pi., all the rest of the approach follows.

Theorem 4 Let us consider the generalized distance

b

n

X
α=2

r2
ij =
b

f 2(λα)(vα(i)

vα(j))2

−

where f (x) =

ckxk is any function deﬁned by a power series.

Pi. =

, where

∞k=0 ckP k

P

i., can be approximated in time

∞
X
k=0
1
D−
2

1
2

D−

−

Pj.

b

(cid:13)
(cid:13)
(cid:13)

Pi.

b

O

Then

rij = (cid:13)
(cid:13)
b
(cid:13)

O

Proof : We have

b

1
2

(rm) and space

(n) with relative error on each coordinate less than εr =

Pi. =

1
2

D−

P

∞k=0 ckP k
Pi.

D−

1
2

−

b

i. = D
Pj.

= (cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)

b

∞k=0 P

P

n

X
α=2

∞
X
k=0

b
rij = (cid:13)
(cid:13)
b
(cid:13)

n
α=1 ckλk

αvα(i)sα. Therefore :

ckλk

α(vα(i)

−

vα(j))sα(cid:13)
(cid:13)
(cid:13)

∞
X
k=r+1

ck.

And we can conclude because the vectors sα are orthonormal :

n

X
α=2

(cid:13)
(cid:13)
(cid:13)

∞
X
k=0

ckλk

α(vα(i)

−

vα(j))sα(cid:13)
(cid:13)
(cid:13)

2

=

n

X
α=2

f 2(λα)(vα(i)

vα(j))2 =

−

r2
ij
b

To compute the vectors, we approximate the series to the order r:
We only need to compute the successive powers
time

(rm) and space

i. for 0

(n).

≤

≤

k

P k
b

O

O

Pi.

i..
r
k=0 ckP k
≃ P
r which can be done in
(cid:3)

b

To illustrate this generalization, we show that it directly allows to consider continuous
random walks. Indeed, the choice of the length of the random walks (which must be an
integer) may be restrictive in some cases. To overcome this constraint, one may consider
the continuous random walk process: during a period dt the walker will go from i to
j with probability Pijdt. One can prove that the probabilities to go from i to j after
Id). For a given period length t, the associated
a time t are given by the matrix et(P
r2
vα(j))2 which corresponds to a function
distance is now
ij =
f (x) = et(x
1) =
b
P

n
α=2 e2t(λα
P
∞k=0 ckxk with ck = tke

1)(vα(i)
−t
.

−

k!

−

−

−

7

4 The algorithm

In the previous section, we have proposed a distance between vertices (and between sets
of vertices) to capture structural similarities between them. The problem of ﬁnding com-
munities is now a clustering problem. We will use here an eﬃcient hierarchical clustering
algorithm that allows us to ﬁnd community structures at diﬀerent scales. We present an
agglomerative approach based on Ward’s method [44] that is well suited to our distance
and gives very good results while reducing the number of distance computations.
, v

of the graph into n communities reduced
V
∈
to a single vertex. We ﬁrst compute the distances between all adjacent vertices. Then
this partition evolves by repeating the following operations. At each step k:

We start from a partition

P1 =

{{

}

}

v

•

•

•

k according to a criterion based on the

choose two communities C1 and C2 in
distance between the communities that we detail later,
merge these two communities into a new community C3 = C1 ∪
C1, C2}
new partition:
∪ {
update the distances between communities (we will see later that we actually only
do this for adjacent communities).

C2 and create the

k+1 = (

C3}

, and

\ {

P

P

P

)

k

P

1 steps, the algorithm ﬁnishes and we obtain

After n
. Each step deﬁnes
−
a partition
k of the graph into communities, which gives a hierarchical structure of
communities called dendrogram (see Figure 1(b)). This structure is a tree in which the
leaves correspond to the vertices and each internal node is associated to a merging of
communities in the algorithm: it corresponds to a community composed of the union of
the communities corresponding to its children.

n =

P

V

{

}

The key points in this algorithm are the way we choose the communities to merge, and
the fact that the distances can be updated eﬃciently. We will also need to evaluate the
k as the result of our algorithm. We
quality of a partition in order to choose one of the
will detail these points below, and explain how they can be managed to give an eﬃcient
algorithm.

P

4.1 Choosing the communities to merge.

This choice plays a central role for the quality of the obtained community structure.
In order to reduce the complexity, we will only merge adjacent communities (having at
least an edge between them). This reasonable heuristic (already used in [32] and [10])
limits to m the number of possible mergings at each stage. Moreover it ensures that each
community is connected.

We choose the two communities to merge according to Ward’s method. At each step
k, we merge the two communities that minimize the mean σk of the squared distances
between each vertex and its community.

k

r2
iC

σk =

X
C
i
∈

1
n X
C
∈P
This approach is a greedy algorithm that tries to solve the problem of maximizing σk
for each k. This problem is known to be NP-hard: even for a given k, maximizing σk
is the NP-hard “K-Median clustering problem” [16, 13] for K = (n
k) clusters. The
existing approximation algorithms [16, 13] are exponential with the number of clusters to
C1, C2}
,
ﬁnd and unsuitable for our purpose. So for each pair of adjacent communities
we compute the variation ∆σ(C1, C2) of σ that would be induced if we merge C1 and C2
C2. This quantity only depends on the vertices of C1
into a new community C3 = C1 ∪
and C2, and not on the other communities or on the step k of the algorithm:

−

{

∆σ(C1, C2) =

1
n (cid:16) X
C3
i
∈

r2
iC3 − X
C1
i
∈

r2
iC1 − X
C2
i
∈

r2
iC2 (cid:17)

(2)

8

Finally, we merge the two communities that give the lowest value of ∆σ.

4.2 Computing ∆σ and updating the distances.

The important point here is to notice that these quantities can be eﬃciently computed
thanks to the fact that our distance is a Euclidean distance, which makes it possible to
obtain the two following classical results [26]:

Theorem 5 The increase of σ after the merging of two communities C1 and C2 is directly
related to the distance rC1C2 by:

P t

1
n

Pi
∈

r2
C1C2

∆σ(C1, C2) =

C1.
C1(P t

C1||
C2|
|
C1|
C2|
+
i.) = 0 and (
C1. +
|
|
C2.. Then we consider the distance r as a metric in Rn (that contains the probability
P t
Proof : First notice that
vectors PC.) associated to an inner product < .
C2|
|
computations, we obtain :
i. >=
C3.

C2|
C1||
r2
iC1 + |
)2
C2|
C1|
+
(
|
|
This also holds if we replace C1 by C2 and C2 by C1. Therefore:

. >. Finally, after some elementary
|

C3. =

C3.

r2
iC3 =

X
C1
i
∈

X
C1
i
∈

X
C1
i
∈

r2
C1C2

C2|
|

C1|
|

C1|
|

P t
|

< P t

i.

)P t

P t

P t

P t

+

−

−

−

2

r2
iC3 =

C2|
C1||
r2
iC2 + |
C2|
C1|
+
|
|
We deduce the claim by replacing this expression into Equation (2).

r2
iC3 =

r2
iC3 +

r2
iC1 +

X
C3
i
∈

X
C1
i
∈

X
C2
i
∈

X
C1
i
∈

X
C2
i
∈

r2
C1C2

(cid:3)

O

This theorem shows that we only need to update the distances between communities

if we know the two vectors PC1. and PC2., the computation

to get the values of ∆σ:
of ∆σ(C1, C2) is possible in
(n). Moreover, the next theorem shows that if we already
know the three values ∆σ(C1, C2), ∆σ(C1, C) and ∆σ(C2, C), then we can compute
∆σ(C1 ∪
Theorem 6 (Lance-Williams-Jambu formula) If C1 and C2 are merged into C3 =
C1 ∪

C2 then for any other community C:

C2, C) in constant time.

∆σ(C3, C) =

C2|
)∆σ(C1, C) + (
|
|
C1|
+
|
Proof : We replace the four ∆σ of Equation (3) by their values given by Theorem 5. We
multiply each side by n(
, and obtain the equivalent
equation:

)∆σ(C2, C)
|
+

∆σ(C1, C2)
|

C
+
|
C2|
|

C1|
(
|

and use

C3|
|

C1|
|

C2
|
C

C
|

C
|

(3)

− |

=

+

C

C1

+

+

C

|

)

|

|

|

|

|

|

|

C3. is the barycenter of P t

r2
C2|
C2C −
|

+

)r2

C2|
|

C3C =

r2
C1|
C1C +
|

C1|
(
|
Then we use the fact that P t
C2|
weighted by
, therefore:
|
r2
r2
C2|
C1|
C2|
C1|
C2C = (
C1C +
|
|
|
|
r2
r2
C1|
C2|
C1C3 +
C2C3 = |
|
|
|

We conclude using

+

C1
C1

C2
|
C2

||
+

|

|

|

)r2

C3C +

+

C2|
|
C1||
C2|
|
C2|
C1|
+
C1. weighted by
|
|

r2
C1C2

and of P t

C1|
|

r2
C1|
C1C3 +
|
r2
C1C2.

r2
C2|
C2C3
|

C2.

(cid:3)

Since we only merge adjacent communities, we only need to update the values of ∆σ
between adjacent communities (there are at most m values). These values are stored in
(log m). Each
a balanced tree in which we can add, remove or get the minimum in
(n) with Theorem 5 or in constant
computation of a value of ∆σ can be done in time
time when Theorem 6 can be applied.

O

O

9

4.3 Evaluating the quality of a partition.

n of partitions into communities. We now
The algorithm induces a sequence (
≤
want to know which partitions in this sequence capture well the community structure.
The most widely used criterion is the modularity Q introduced in [32, 33], which relies
on the fraction of edges eC inside community C and the fraction of edges1 aC bound to
community C:

k)1

P

≤

k

Q(

) =

P

eC

a2
C

−

X
C
∈P

The best partition is then considered to be the one that maximizes Q.

However, depending on one’s objectives, one may consider other quality criterion of
a partition into communities. For instance, the modularity is not well suited to ﬁnd
communities at diﬀerent scales. Here we provide another criterion that helps in ﬁnding
such structures. When we merge two very diﬀerent communities (with respect to the
σk at this step is large. Conversely, if ∆σk is large
distance r), the value ∆σk = σk+1 −
then the communities at step k
1 are surely relevant. To detect this, we introduce the
increase ratio ηk:

−

ηk =

∆σk
∆σk

1

−

=

σk+1 −
σk
σk
−

σk

1

−

One may then consider that the relevant partitions
k are those associated with the
largest values of ηk. Depending on the context in which our algorithm is used, one may
take only the best partition (the one for which ηk is maximal) or choose among the best
ones using another criterion (like the size of the communities, for instance). This is an
important advantage of our method, which helps in ﬁnding the diﬀerent scales in the
community structure. However we used the modularity (which produces better results to
ﬁnd an unique partition and is not speciﬁc to our algorithm) in our experimental tests to
be able to compare our algorithm with the previouly proposed ones.

P

4.4 Complexity.

P

(mnt). Then, at each step

C. corresponding to the current

First, the initialization of the probability vectors is done in
k of the algorithm, we keep in memory the vectors P t
communities (the ones in the current partition). But for the communities that are not
in
k (because they have been merged with another community before) we only keep the
information saying in which community it has been merged. We keep enough information
to construct the dendogram and have access to the composition of any community with
a few more computation.
When we merge two communities C1 and C2 we perform the following operations:
P t

O

P t

C1

and remove P t

C1. and P t

C2..

C2). = |

C1.+

C1

+

|

|

C2
C2

|
|

|
|

|

C2.

Compute P t

(C1

∪

Update the values of ∆σ concerning C1 and C2 using Theorem 6 if possible, or
otherwise using Theorem 5.

•

•

(n), and therefore does not play a signiﬁcant role in
The ﬁrst operation can be done in
the overall complexity of the algorithm. The dominating factor in the complexity of the
algorithm is the number of distances r computed (each one in
(n)). We prove an upper
bound of this number that depends on the height of the dendrogram. We denote by h(C)
the height of a community C and by H the height of the whole tree (H = h(V )).

O

O

Theorem 7 An upper bound of the number of distances computed by our algorithm is
2mH. Therefore its global time complexity is

(mn(H + t)).

1inter-community edges contribute for 1

2 to each community.

O

10

2

3

(a)

4

9

1

7

5

6

8

10

11

12

13

16

15

14

(b)

6
1

5
1

4
1

3
1

2
1

1
1

0
1

9

8

7

6

5

4

3

2

1

0.4
0.2Q
0

k

(c)

ηk

5

3

1

Figure 1: (a) An example of community structure found by our algorithm using random
walks of length t = 3. (b) The stages of the algorithm encoded as a tree called dendrogram.
The maximum of ηk and Q, plotted in (c), show that the best partition consists in two
communities. The maximal values of ηk show also that communities of diﬀerent scales may
be relevant.

Proof : Let M be the number of computations of ∆σ. M is equal to m (initialization
of the ﬁrst ∆σ) plus the sum over all steps k of the number of neighbors of the new
community created at step k (when we merge two communities, we need to update one
H, the communities with the same
value of ∆σ per neighbor). For each height 1
height h are pairwise disjoint, and the sum of their number of neighbor communities is
less than 2m (each edge can at most deﬁne two neighborhood relations). The sum over
all heights ﬁnally gives M
2Hm. Each of these M computations needs at most one
≤
(n) (Theorem 5). Therefore, with the initialization, the global
computation of r in time
(cid:3)
complexity is

(mn(H + t)).

O

≤

≤

h

O

O

In practice, a small t must be chosen (we must have t =

(log n) due to the exponential
(mnH).
convergence speed of the random walk process) and thus the global complexity is
We always empirically observed that best results are obtained using length 3
8.
We moreover observed that the choice of t in this range is not crutial as the results are
often similar. Hence we think that a good empirical compromise is to choose t = 4 or
t = 5. We also advise to reduce this length for very dense graphs and to increase it for
very sparse ones because the convergence speed of the random walk process increase with
the graph density. Studying more formally the inﬂuence of t, and determining optimal
values, remains to be done.
The worst case is H = n

1, which occurs when the vertices are merged one by one
to a large community. This happens in the “star” graph, where a central vertex is linked
to the n
1 others. However Ward’s algorithm is known to produce small communities
of similar sizes. This tends to get closer to the favorable case in which the community
structure is a balanced tree and its height is H =

(log n).

O
≤

≤

−

−

t

However, this upper bound is not reached in practical cases. We evaluated the actual

O

11

Upper bounds

Practical tests

Method

2m(n

1)

−
2mH
without theorem 6
with theorem 6
with additional heuristics

Number of distances computed
282 000 000
2 970 000
321 000
277 000
103 000

Table 1: Number of distances computed according to upper bounds and practical tests.

number of distance computations done on graphs from the test set presented in Section 5.1.
We chose graphs with n = 3 000 vertices, their mean number of edges is m = 47 000 and
the mean height of the computed dendrograms is H = 31.6. We compared the worst case
1)) and the upper bound 2mnH with the actual number distances
upper bound 2(mn(n
−
computed with and without using Theorem 6.

We also considered an additional heuristics that consists in applying Theorem 6 when-
ever we only know one of the two quantities ∆σ(C1, C) or ∆σ(C2, C). In this case we
assume that the other one is greater than the current minimal ∆σ and we obtain a lower
C2, C). Later, if this lower bound becomes the minimal ∆σ then we
bound for ∆σ(C1 ∪
C2 is merged
(n). Otherwise if the community C3 = C1 ∪
compute the exact distance in
using another community than C the exact computation is avoided. This heuristics can
induce inexact merging ordering when the other unknown ∆σ is not greater than the
current minimal ∆σ, we observed in this test that this happened on 0.05% of the cases.
The results, transcribed in Table 1, show that in practical cases, the actual complexity
of our approach is signiﬁcantly lower than the upper bound we proved. However, this
upper bound can be reached in the pathological case of the star graph.

O

5 Experimental evaluation of the algorithm

In this section we will evaluate and compare the performances of our algorithm with
most previously proposed methods. This comparison has been done in both randomly
generated graphs with communities and real world networks. In order to obtain rigorous
and precise results, all the programs have been extensively tested on the same large set
of graphs.
The test compares the following community detection programs:

•

•

•

•

•

•

•

this paper (Walktrap) with random walk length t = 5 and t = 2,

the Girvan Newman algorithm [23, 33] (a divisive algorithm that removes larger
betweeness edges),

the Fast algorithm that optimize the modularity proposed by Newman and im-
proved in [8] (a greedy algorithm designed for very large graphs that optimizes the
modularity),

the approach of Donetti and Mu˜noz using the Laplacian matrix [10] and its new
improved version [11] (a spectral approach with a hierarchical algorithm),

the Netwalk algorithm [48] (another algorithm based on random walks),

the Markov Cluster Algorithm (MCL) [43] (an algorithm based on simulation of
(stochastic) ﬂow in graphs),

and the Cosmoweb algorithm [6] (a gravitational approach designed for web cluster-
ing).

We refer to Section 1.2 and to the cited references for more details on these algorithms.

12

5.1 Comparison on generated graphs

 1

 0.8

 0.6

 0.4

 0.2

’

R

 10000

 1000

 100

)
s
(
 
e
m
T

i

 10

 1

 0.1

 0.01

Walktrap t=5
Walktrap t=2
Fast Modularity
Donetti Munoz
Donetti Munoz (Laplacian)
Cosmoweb
Girvan Newman
Netwalk
Duch Arenas
MCL

 0
 100

 1000

 10000

 100000

 100

 1000

 10000

 100000

N

N

Figure 2: Quality and time performance of diﬀerent approaches in function of the size of the
graphs (N ). (Left) Mean quality of the partition found (R′). Right: Mean execution time (in
seconds).

Evaluating a community detection algorithm is a diﬃcult task because one needs
some test graphs whose community structure is already known. A classical approach is
to use randomly generated graphs with communities. Here we will use this approach and
generate the graphs as follows.

(these parameters give the number

The parameters we consider are :

the number k of communities and their sizes
of vertices N ),

Ci
|

|

the internal degree din(Ci) of each community,
and the wanted modularity Q.

•

•

•

In order to reduce the number of parameters, we consider that the external degrees are
din(Ci). One can check that the
proportional to the internal degrees:
expected modularity is then:

i, dout(Ci) = β

×

∀

1

Qe =

1 + β −

Pi(din(Ci)
Pi din(Ci)
(

)2
Ci
|
)2
Ci
|

× |

× |

We therefore obtain the wanted modularity by choosing the appropriate value for β.

Once these parameters have been chosen, we draw each internal edge of a given com-
munity with the same probability, producing Erd¨os-Renyi like communities. Then the
external degrees are chosen proprotionally to the internal degrees (with a factor β) and
the vertices are randomly linked with respect to some constraints (no loop, no multiple
edge).

13

P1,

P2) is the ratio of pairs of vertices correlated by the partitions

To evaluate the quality of the partition found by the algorithms, we compare them
to the original generated partition. To achieve this, we use the Rand index corrected by
Hubert and Arabie [37, 25] which evaluates the similarities between two partitions. The
Rand index R(
P1 and
P2 if they are classiﬁed in the
P2 (two vertices are correlated by the partitions
same community or in diﬀerent communities in the two partitions). The expected value
of R for a random partition is not zero. To avoid this, Hubert and Arabie proposed a
corrected index that is also more sensitive : R′ = R
where Rexp is the expected
−
Rmax
value of R for two random partitions with the same community size as
P2. This
P1 and
quantity can be eﬃciently computed using the following equivalent formula :

P1 and

Rexp

Rexp

−

R′(

P1,

P2) =

N 2

C1
|

i ∩

C2
2
j |

− X
i

C1
2
i |
|

C2
2
j |
|

X
j

X
i,j

1

2 N 2 


X
i

2 +

C1
i |
|

C2
j |
|

2



X
j

− X
i

2
C1
i |
|

2
C2
j |
|

X
j

Where (Cx
vertices.

i )1

i
≤

≤

kx are the communities of the partition

x and N is the total number of

P

This quantity has many advantages compared to the “ratio of vertices correctly identi-
ﬁed” that has been widely used in the past. It captures the similarities between partitions
even if they do not have the same number of communities, which is crucial here as we
will see below. Moreover, a random partition always gives the same expected value 0 that
does not depend on the number of communities.

We also compared the partitions using the modularity. However, the results and the
conclusions were very similar to those obtained with R′. In order to reduce the size of this
section and to avoid duplicated information, we only plotted the results obtained with
the corrected Rand index R′.

Homogeneous graphs Let us start with the most simple case where all the com-
munities are similar (same size and same density). Therefore we only have to choose
the size N of the graphs, the number k of communities, the internal degree din of com-
munities and the wanted modularity Q. The internal edges are drawn with the same
probability, producing a Poisson degree distribution. We generated graphs corresponding
to combinations of the following parameters:

•

•

•

100, 300, 1 000, 3 000, 10 000, 30 000, 100 000

,

{

sizes N in
number of communities, k = N γ with γ in
Ci
internal degree, din(Ci) = α ln(
|
wanted modularity Q in

) with α in
|
0.2, 0.3, 0.4, 0.5, 0.6

{

{
.

}
0.3, 0.42, 0.5

,

}

}

2, 4, 6, 8, 10

,

}

{

•
The ﬁrst comparison of the quality and time performances is plotted on Figure 2. For
each graph size, we plotted the mean corrected Rand index (R′) and the mean running
time. To avoid that some approaches can be advantaged (or disadvantaged) by particular
parameters, the mean has been computed over all the possible combinations of the pa-
rameters listed above. This ﬁrst comparison shows that our algorithm has the advantage
of being eﬃcient regarding both the quality of the results and the speed, while other
alorithms only achieve one of these goals. It can handle very large graphs with up to
300 000 vertices (this limitation is due to its memory requirements). Larger graphs can
be processed (without the same quality of results) with the Fast Modularity algorithm
that has been able to process a 2 million vertex graph.

We also plotted R′ on Figure 3 to observe the inﬂuence of the modularity of the gen-
erated partition on the results. These ﬁrst tests show that most previously proposed

14

N = 100

N = 300

N = 1000

N = 3000

N = 10000

N = 30000

’

R

’

R

1

.8

.6

.4

.2

0
1

.8

.6

.4

.2

0

.2

.3

.4

.5

.6

.2

.3

.4

.5

.6

.2

.3

.4

.5

.6

Q
Figure 3: Quality of the partition found in function of the modularity of the generated
partition for diﬀerent sizes N (same legend as Figure 2).

Q

Q

approaches have good performances on small graphs. But our approach is the only one
that allows to process large graphs while producing good results. Notice that the im-
proved approach of Donetti and Mu˜noz also produces very good results but requires more
computational time. This improved version [11] uses exactly the same eigen vectors as the
ones we use in our algorithm, which explains that the quality of the results are similar.
The MCL algorithm was diﬃcult to use in this intensive test since the user must choose
a granularity parameter for each input graph, which is a limitation of this algorithm. We
manually chose one parameter for each size of graph (hence the results are not optimal
and it can explain their ﬂuctuations), doing our best to ﬁnd a good one.

It is also interesting to compare the distribution of the size of the communities found to
the size of the generated communities. We plotted these quantities on Figure 4 for graphs
with N = 3000 vertices. We generated graphs with three diﬀerent sizes of communities
and the results can explain the limitations of some approaches. It seems for instance that
the Fast Modularity algorithm [8] produces communities that always have the same size
independantly of the actual size of the communities. Likewise, Cosmoweb [6] produces
too many very small communities (1 to 4 vertices).

Heterogeneous graphs The second set of graphs has diﬀerent kind of communities
(diﬀerent sizes and diﬀerent densities). The sizes of the communities are randomly chosen
according to a power law and the internal densities of each community is also randomly
chosen. We therefore have the two following additional parameters:

•

the range of internal degree, din(Ci) is uniformely chosen between αmin ln(
Ci
|
αmax ln(
) with (αmin, αmax) = (5, 7), (4, 8) and (3, 9), and
Ci
|
|
the community size distribution is a power law of exponent α in 2.1, 2.5 and 3.2
2The community sizes are chosen within a range [Smin..Smax] and the probability that a community has

) and
|

•

15

Large communities (273)

Medium communities (100)

Small communities (55)

Large communities (273)

Medium communities (100)

Small communities (55)

Walktrap t = 5
Fast Modularity
Donetti Munoz
As generated

Cosmoweb
Duch Arenas
MCL
As generated

1

.8

.6

.4

.2

0
1

.8

.6

.4

.2

d
n
u
o
f
 
s
e
i
t
i
n
u
m
m
o
c
 
f
o
 
o
i
t
a
R

d
n
u
o
f
 
s
e
i
t
i
n
u
m
m
o
c
 
f
o
 
o
i
t
a
R

0

  1

6

40

250

  1
1350  

6

40

250

  1
1350  

6

40

250

1350  

Size of the communities found
Figure 4: Distribution of the size of the communities for three diﬀerent numbers of generated
communities corresponding to 11, 30 or 55 communities on N = 3000 vertex graphs.

To study the inﬂuence of the heterogeneity of the communities, we generated graphs of
size N = 3000 with all combinations of the previous parameters (modularity, number
of communities) and of the two new ones. The three values of the above parameters
correspond to three levels of heterogeneity. Figure 5 shows that our approach is not
inﬂuenced by the heterogeneity of the communities, whereas the others are.

5.2 Comparison on real world networks

To extend the comparison between algorithms, we also conducted experiments on some
real world networks. However judging the quality of the diﬀerent partiton found is very
diﬃcult because we do not have a reference partition that can be considered as the actual
communities of the network. We only compared the value of the modularity found by the
diﬀerent algorithms. The results are reported in Table 2.

We used the following real world networks :

The Zachary’s karate club network [47], a small social network that has been widely
used to test most of the community detection algorithms.

The college football network from [23].

The protein interaction network studied in [27].

A scientists collabaration network computed on the arXiv database [50].

An internet map provided by Damien Magoni [24].

•

•

•

•

•

•

The web graph studied in [2]

size S is actualy proportional to (S + µ)
equal to a given N .

α

, with µ chosen such that the expected size of the overall graph is

16

1

.8

.6

.4

.2

0

1

.8

.6

.4

.2

)
s
e
i
t
i
s
n
e
d
 
s
u
o
e
n
e
g
o
r
e
t
e
h
(
 
’

R

i

)
s
e
z
s
 
y
t
i
n
u
m
m
o
c
 
s
u
o
e
n
e
g
o
r
e
t
e
h
(
 
’

R

WT5
WT2
FM
DM
DML

CW
GN
NW
DA
MCL

N = 100

N = 300

N = 1000

N = 3000

  6

[5:7]

[4:8]

[3:9]  

  6

[5:7]

[4:8]

[3:9]  

  6

[5:7]

[4:8]

[3:9]  

  6

[5:7]

[4:8]

[3:9]  

N = 100

0
  cst

N = 300

N = 1000

N = 3000

3

2.5

2.1  

  cst

3

2.5

2.1  

  cst

3

2.5

2.1  

  cst

3

2.5

2.1  

Inﬂuence of the heterogeneity of the graphs (for four sizes of graphs N =
Figure 5:
100, 300, 1 000, 3 000). On the x axis, left corresponds to homogeneous graphs and right cor-
responds to very heterogeneous graphs. The quality of the partition is plotted as a function
of diﬀerent parameters as described in the text. Top:
internal density given by the range
[αmin : αmax]. Bottom: community sizes given by the exponent of the power law distribution.

graph
nb vertices/mean degree
Walktrap (t = 5)
Walktrap (t = 2)
Fast Modularity
Donetti Mu˜noz
Donetti Mu˜noz (Laplacian)
Cosmoweb
Girvan Newman
Netwalk
Duch Arenas
MCL

karate
33/4.55
0.38/0s
0.38/0s
0.39/0s
0.41/0s
0.41/0s
-0.05/0s
0.40/0s
0.40/0.02s
0.41/0s
0.36/0s

foot
115/10.7
0.60/0s
0.60/0s
0.57/0s
0.60/0s
0.60/0s
0.33/0s
0.60/0.39s
0.60/0.07s
0.60/0.05s
0.60/0.05s

protein
594/3.64
0.67/0.02s
0.64/0.01s
0.71/0s
0.59/0.34s
0.60/1.37s
0.50/0.02s
0.70/6.93s
0.60/5.2s
0.69/1.9s
0.66/0.58s

arxiv
9377/5.14
0.76/4.61s
0.71/1.08s
0.77/1.65s
0.66/1460s
0.62/1780s
0.60/0.65
>40000s
>40000s
0.77/14000s
0.73/61.3s

internet
67882/8.12
0.76/1030s
0.69/273s
0.72/483s
–
–
0.47/6.82s
–
–
–
–

www
159683/11.6
0.91/5770s
0.84/468s
0.92/1410s
–
–
0.79/21s
–
–
–
–

Table 2: Performances on real world networks (modularity / time (in seconds)). The second
line shows the size of the graphs given by their number of vertices and their mean degree.

We reduced the sizes of these networks by only keeping the largest connected component
and by iteratively removing all the one-degree vertices (which do not provide signiﬁcant
information on community structures). This allowed us to run the comparison tests with
all the algorithms on smaller networks (Table 2 reports the size and the mean degree of
the graphs after this processing).

17

6 Conclusion and further work

O

We proposed a new distance between vertices that quantify their structural similarity
using random walks. This distance has several advantages: it captures much information
on the community structure, and it can be used in an eﬃcient hierarchical agglomerative
algorithm that detects communities in a network. We designed such an algorithm which
(mn2). In practice, real-world complex networks are
works in the worst case in time
sparse (m =
(log n)); in this
case the algorithm runs in

(n)) and the height of the dendrogram is small (H =

(n2 log n). An implementation is provided at [49].

O

O

O

Extensive experiments show that our method provides good results in various condi-
tions (graph sizes, densities, and number of communities). We used such experiments to
compare our algorithms to the main previously proposed ones. This direct comparision
shows that our approach has a clear advantage in term of quality of the computed parti-
tion and presents the best tradeoﬀ between quality and running time for large networks.
It however has the limitation of needing quite a large amount of memory, which makes
the Fast Modularity approach a relevant challenger of our method for very large graphs
(million vertices).

Our method could be integrated in a multi-scale visualization tool for large networks,
and it may be relevant for the computation of overlapping communities (which often
occurs in real-world cases and on which very few has been done until now [34]). We
consider these two points as promising directions for further work. Finally, we pointed
out that the method is directly usable for weighted networks. For directed ones (like the
important case of the web graph), on the contrary, the proofs we provided are not valid
anymore, and random walks behave signiﬁcantly diﬀerently. Therefore, we also consider
the directed case as an interesting direction for further research.

Acknowledgments

We ﬁrst want to thank our colleagues who provided us an implementation of their algo-
rithm. We also thank Annick Lesne and L.S. Shulman for useful conversation and Aaron
Clauset and Cl´emence Magnien for helpful comments on preliminary versions. This work
has been supported in part by the PERSI (Programme d’ ´Etude des R´eseaux Sociaux de
l’Internet) project and by the GAP (Graphs, Algorithms and Probabilities) project.

References

[1] R. Albert and A.-L. Barab´asi. Statistical mechanics of complex networks. Reviews

[2] R´eka Albert, Jeong Hawoong, and Barab´asi Albert-L´aszl´o. Diameter of the world

of Modern Physics, 74(1):47, 2002.

wide web. Nature, 401:130, 1999.

[3] M. S. Aldenderfer and R. K. Blashﬁeld. Cluster Analysis. Number 07-044 in Sage
University Paper Series on Quantitative Applications in the Social Sciences. Sage,
Beverly Hills, 1984.

[4] D. Aldous

and

J. A.

Fill.

Reversible Markov Chains

Random Walks
http://www.stat.berkeley.edu/users/aldous/RWG/book.html.

on Graphs,

chapter

2.

Forthcoming

and
book,

[5] Jim Bagrow and Erik Bollt. A local method for detecting communities. Physical

Review E, 2005 (to appear).

[6] T. Bennouas, M. Bouklit, and F. de Montgolﬁer. Un mod`ele gravitationnel
In 5`eme Rencontres Francophones sur les aspects Algorithmiques des

du web.
T´el´ecommunications (Algotel), Banyuls (France), 2003.

18

[7] Aaron Clauset. Finding local community structure in networks. Physical Review E,

72:026132, 2005.

[8] Aaron Clauset, M. E. J. Newman, and Cristopher Moore. Finding community struc-

ture in very large networks. Physical Review E, 70(6):066111, 2004.

[9] Luciano da Fontoura Costa.

Hub-based community ﬁnding.

arXiv:cond-

mat/0405022, 2004.

[10] L. Donetti and M. A. Mu˜noz. Detecting network communities: a new systematic and

eﬃcient algorithm. Journal of Statistical Mechanics, 2004(10):10012, 2004.

[11] L. Donetti and M. A. Mu˜noz.

Improved spectral algorithm for the detection of

network communities. arXiv:physics/0504059, 2005.

[12] S.N. Dorogovtsev and J.F.F. Mendes. Evolution of Networks: From Biological Nets

to the Internet and WWW. Oxford University Press, Oxford, 2003.

[13] P. Drineas, A. Frieze, R. Kannan, S. Vempala, and V. Vinay. Clustering large graphs

via the singular value decomposition. Machine Learning, 56(1-3):9–33, 2004.

[14] Jordi Duch and Alex Arenas. Community detection in complex networks using ex-

tremal optimization. arXiv:cond-mat/0501368, 2005.

[15] B. S. Everitt, S. Landau, and M. Leese. Cluster Analysis. Hodder Arnold, London,

4th edition, 2001.

[16] W. Fernandez de la Vega, Marek Karpinski, Claire Kenyon, and Yuval Rabani. Ap-
proximation schemes for clustering problems. In Proceedings of the thirty-ﬁfth annual
ACM Symposium on Theory of computing, STOC, pages 50–58. ACM Press, 2003.

[17] M. Fiedler. Algebraic connectivity of graphs. Czechoslovak Math. J., 23:298–305,

1973.

[18] G. W. Flake, S. Lawrence, C. L. Giles, and F. M. Coetzee. Self-organization and

identiﬁcation of web communities. Computer, 35(3):66–71, 2002.

[19] Santo Fortunato, Vito Latora, and Massimo Marchiori. Method to ﬁnd community

structures based on information centrality. Physical Review E, 70(5):056104, 2004.

[20] F. Fouss, A. Pirotte, and M. Saerens. A novel way of computing dissimilarities
between nodes of a graph, with application to collaborative ﬁltering. In Workshop
on Statistical Approaches for Web Mining (SAWM), pages 26–37, Pisa, 2004.

[21] B. Gaume. Balades al´eatoires dans les petits mondes lexicaux. I3 Information In-

teraction Intelligence, 4(2), 2004.

[22] B. Gaveau, A. Lesne, and L. S. Schulman. Spectral signatures of hierarchical relax-

ation. Physics Letters A, 258(4-6):222–228, July 1999.

[23] M. Girvan and M. E. J. Newman. Community structure in social and biological

networks. PNAS, 99(12):7821–7826, 2002.

[24] Micka¨el Hoerdt and Damien Magoni. Completeness of the internet core topology
collected by a fast mapping software. In Proceedings of the 11th International Con-
ference on Software, Telecommunications and Computer Networks, pages 257–261,
Split, Croatia, October 2003.

[25] L. Hubert and P. Arabie. Comparing partitions. Journal of Classiﬁcation, 2:193–218,

1985.

Publishing, 1983.

[26] M. Jambu and Lebeaux M.-O. Cluster analysis and data analysis. North Holland

[27] Hawoong Jeong, Sean Mason, Albert-L´aszl´o Barab´asi, and Zolt´an N. Oltvai. Cen-

trality and lethality of protein networks. Nature, 411:41–42, 2001.

19

[28] B. W. Kernighan and S. Lin. An eﬃcient heuristic procedure for partitioning graphs.

Bell System Technical Journal, 49(2):291–308, 1970.

[29] Jon Kleinberg and Steve Lawrence.

The structure of the web.

Science,

294(5548):1849–1850, 2001.

[30] L. Lov´asz. Random walks on graphs: a survey. In Combinatorics, Paul Erd˝os is
eighty, Vol. 2 (Keszthely, 1993), volume 2 of Bolyai Soc. Math. Stud., pages 353–
397. J´anos Bolyai Math. Soc., Budapest, 1996.

[31] M. E. J. Newman. The structure and function of complex networks. SIAM REVIEW,

45:167, 2003.

[32] M. E. J. Newman. Fast algorithm for detecting community structure in networks.

Physical Review E, 69(6):066133, 2004.

[33] M. E. J. Newman and M. Girvan. Finding and evaluating community structure in

networks. Physical Review E, 69(2):026113, 2004.

[34] Gergely Palla, Imre Derenyi, Illes Farkas, and Tamas Vicsek. Uncovering the over-
lapping community structure of complex networks in nature and society. Nature,
435:814–818, 2005.

[35] A. Pothen, H. D. Simon, and K.-P. Liou. Partitioning sparse matrices with eigenvec-

tors of graphs. SIAM J. Matrix Anal. Appl., 11(3):430–452, 1990.

[36] F. Radicchi, C. Castellano, F. Cecconi, V. Loreto, and D. Parisi. Deﬁning and

identifying communities in networks. PNAS, 101(9):2658–2663, 2004.

[37] W.M. Rand. Objective criteria for the evaluation of clustering methods. Journal of

the American Statistical association, 66:846–850, 1971.

[38] E. Ravasz, A. L. Somera, D. A. Mongru, Z. N. Oltvai, and A.-L. Barab´asi. Hierar-
chical Organization of Modularity in Metabolic Networks. Science, 297(5586):1551–
1555, 2002.

[39] J¨org Reichardt and Stefan Bornholdt. Detecting fuzzy community structures in
complex networks with a potts model. Physical Review Letters, 93:218701, 2004.
[40] L. S. Schulman and B. Gaveau. Coarse grains: The emergence of space and order.

Foundations of Physics, 31(4):713–731, April 2001.

[41] I. Simonsen, K. Astrup Eriksen, S. Maslov, and K. Sneppen. Diﬀusion on com-
plex networks: a way to probe their large-scale topological structures. Physica A:
Statistical Mechanics and its Applications, 336(1-2):163–173, May 2004.

[42] S. H. Strogatz. Exploring complex networks. Nature, 410:268–276, March 2001.
[43] Stijn van Dongen. Graph Clustering by Flow Simulation. PhD thesis, University of

[44] J. H. Ward. Hierarchical grouping to optimize an objective function. Journal of the

American Statistical Association, 58(301):236–244, 1963.

[45] S. Wasserman and K. Faust. Social network analysis. Cambridge University Press,

Utrecht, May 2000.

Cambridge, 1994.

[46] Fang Wu and Bernardo A. Huberman. Finding communities in linear time: A physics

approach. The European Physical Journal B, 38:331–338, 2004.

[47] Wayne W. Zachary. An information ﬂow model for conﬂict and ﬁssion in small

groups. Journal of Anthropological Research, 33:452–473, 1977.

[48] Haijun Zhou and Reinhard Lipowsky. Network brownian motion: A new method to
measure vertex-vertex proximity and to identify communities and subcommunities.
In International Conference on Computational Science, pages 1062–1069, 2004.

[49] http://liafa.jussieu.fr/~pons/.
[50] data set obtained from http://www.cs.cornell.edu/projects/kddcup/datasets.html.

20

