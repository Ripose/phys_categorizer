6
0
0
2
 
g
u
A
 
0
2
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
3
0
2
8
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

The Asymptotic Dependence of Elliptic Random
Variables

∗

Krystyna Jaworska

Institute of Mathematics and Cryptology, Military University of Technology
ul. Kaliskiego 2, 00-908 Warszawa, Poland

In this paper, we try to answer the question, whether for bivariate ellip-
tic random variable X = (X1, X2) the marginal random variables X1 and
X2 are asymptotically dependent. We show, that for some special form of
the characteristic generator of X the answer is positive.

keywords: dependence of extreme events, risk management,

PACS numbers: 89.65.Gh
MSC 2000: 91B28, 91B30, 62H05

1. Motivation

In order to give an answer to the question, ”What is the origin of the
interest of the asymptotic dependence of elliptic random variables?” one has
to go back several dozen years.
Already in the years 1950’s and 1960’s researchers discovered the non-normal
behaviour of ﬁnancial market data. In the early 1990’s an understanding
of the methodology underlying ﬁnancial or insurance extremes became very
important. Traditional statistics mostly concerns the laws governing aver-
ages. But when we look at the largest ( respectively the smallest) elements
in a sample, the assumption of normality seems not to be reasonable in the
number of applications, particularly in ﬁnance and insurance. And heavy-
tailed distributions have a chance to be more appropriate.
Why? Let X1, X2 be insurance claims due to ﬂood disasters (X1) and wind
storms (X2). Last year events taught us that very often the extreme values
of X1 are accompanied by extreme values of X2. In mathematical language
it means, thatX1 and X2 are asymptotically dependent. Traditional models

∗ Presented at FENS 2006

(1)

2

ArtFENS06

printed on February 2, 2008

Fig. 1. Log-returns of DAX and CAC.

based on multidimensional normal probability law give rise to quite oppo-
site conclusion. Therefore in modelling of extreme events more and more
often the researchers use the wider class of distributions, which includes the
normal distribution as a special case.
Let us now consider a simple example from ﬁnance market. On the ﬁgure
below you see daily log-returns of stock indices DAX and CAC ( horizontal
axis X1-DAX, vertical axis X2-CAC). The data cover the period from 1990
to 2004 (about 4000 data). The scatter plot assumes a shape of ”elliptic
cloud”. And the level sets of the probability density, of the random vector
(X1, X2), are ellipses. This empirical observation suggests, that the family
of elliptic distributions should be taken under consideration.
Furthermore we can ask how often we observe the situation, when the daily
log-returns of the both indices take the extreme values.
Let W (j) be the quantity of observations (x1,k, x2,k) such that
(x1,k > x1,j, x2,k > x2,j), where xi,j is the j-th order statistics of the random
variable Xi, i = 1, 2.

The graph of the function W (j) shows us, that X1 and X2 are asymp-
totically dependent. So the joint random variable (X1, X2) couldn’t be
normally distributed.

ArtFENS06

printed on February 2, 2008

3

Fig. 2. Graph of W (j).

2. Preliminaries

To begin with, we recall the basic deﬁnitions.

Let F be an univariate distribution function and F −1 its generalized inverse

F −1(u) = inf

R : F (x)

x
{

∈

u
}

≥

for all u

(0, 1).

∈

Definition 2.1. Let (X1, X2) be a random vector with marginal distribu-
tion functions F1 and F2.
The coeﬃcient of upper tail dependence of (X1, X2) is deﬁned to be

λU (X1, X2) = lim
u→1

P (X1 > F −1

1

X2 > F −1
(u)
|

2

(u))

,

provided, that the limit λU
[0, 1] exists.
If λU = 0 , then we say that X1 and X2 are asymptotically independent.
Otherwise ( that is λU > 0 or λU doesn’t exists ) we say that, they are
asymptotically dependent.

∈

For a pair of random variables upper tail dependence is a measure of
joint extremes. That is they measure the probability that one component is
at an extreme of size given that the other is at the same extreme, relative
to the marginal distributions.

4

ArtFENS06

printed on February 2, 2008

Lemma 2.1. If two continuously distributed random variables X1, X2 are
independent, then they are asymptotically independent.
Proof.

lim
u→1

P (X1 > F −1

1

X2 > F −1
(u)
|

2

(u)) = lim
u→1

P (X1 > F −1

1

(u)) = 0 .

Note that the bivariate normal distribution has the same property.

The tail behaviour can be also described in a ”symmetric way”.

Definition 2.2. The bivariate random variable X = (X1, X2) is said to
be regularly varying with index β > 0, if for all y > 0 and for every angle
[α0, α1]

X
P (
|

|

lim
t→∞

> ty, arg X
X
P (
|

|

∈
> t)

[α0, α1])

= y−βM (α0, α1).

where
M (α0, α1) is a certain measure on the interval [0, 2π).

Definition 2.3. If X is a bivariate random variable and, for some
µ
tion ψ : [0,

R2, some 2x2 nonnegative deﬁnite symmetric matrix Σ and some func-
R, the characteristic function is of the form

∈

)

∞

→

ϕ(t) = exp(it∗µ)ψ(t∗Σt)

,

then we say that X has an elliptical distribution with parameters µ, Σ and
ψ, and we write X

E2(µ, Σ, ψ).

∼

The function ψ is referred to as the characteristic generator of X.

Remark 2.1. The following widespread used distributions prove to be
elliptic:
1. the normal distribution

t2
ψ(t2) = exp( −
2

)

,

2. some α-stable with characteristic generator of the form

t
ψ(t2) = exp( −|
2

α
|

)

, 0 < α < 2 ,

3. T-Student distribution.

ArtFENS06

printed on February 2, 2008

5

Theorem 3.1. Let

3. Result

φ(t) = ψ(t∗Σt)

, t

R2

∈

be a characteristic function of a bivariate elliptically distributed random
variable X = (X1, X2).
1. Σ is a positive deﬁnite symmetric matrix,
2. ψ : R+ −→
R is such that:
ψ(r2) = ψ0(r2) + rβψ1(rγ), 0 < γ
R+ \
β
∈
ψ0, ψ1 ∈
k
0
≤
≤
∀

then the marginal random variables X1 and X2 are asymptotically depen-
dent .

ψ1(0)
= 0
∧
limt→∞ tk+ 1

2N,
C∞(R+)
4 + [β]

2 ψ(k)(t2) = 0,

ψ0(0) = 1,

2,

≤

∧

4. Concluding remarks

∈

(0, 2) , if X = (X1, X2) is elliptic and α- stable, then X1 and

1. For all α
X2 are asymptotically dependent.
2. The result is also valid for the characteristic generator of the form
ψ(r2) = ψ0(r2) + rβ1ψ1(rγ1) + ... + rβmψm(rγm), where
0 < β1 < β2 < ... < βm.

5. Proof of the Theorem

Lemma 5.1. Let us have the same assumptions as in theorem 3.1.
Then the asymptotics of the probability density of bivariate random variable
X = (X1, X2) formulates as follows

x

g(x) = c

−2−β + O(
||
||
= √x∗Σx , x = (x1, x2).

||

x

−3−β ) ,
||

x

||

|| → ∞

, c = const > 0 ,

x

||

||

Proof.

λ(u) = P (X1 > F −1

1

X2 > F −1
(u)
|

2

(u)) =

P (X1 > F −1

1

(u)
P (X2 > F −1

X2 > F −1
(u))

∧

2

2

(u))

6
6

ArtFENS06

printed on February 2, 2008

Let us denote F −1

j

(u) = asj, j = 1, 2; s1, s2 = const > 0, a >> 0

P (X1 > F −1

(u)

1

X2 > F −1
+∞

2

∧
+∞

=

Z

dx1 Z

(u)) = P (X1 > as1 ∧
dx2 ZR2

e−ix∗tψ(t∗Σt)dt

X2 > as2) =

as2
We calculate the asymptotics of the integral above, for a
Σ = A∗A.

Σ > 0 and symmetric =

as1

+

.

∞

−→

⇒
e−ix∗tψ(t∗Σt)dt =

ZR2

g(x) =

ZR2

after the change of the variables t = A−1w.
Next we substitute x = A∗y and obtain

e−ix∗A−1wψ(w∗w)(detΣ)−

−1
2 dw ,

g(A∗y) =

e−iy∗wψ(w∗w)(detΣ)−

−1
2 dw = (detΣ)

−1
2 G(y) .

ZR2

We change the variables a second time w1 = r cos ϕ, w2 = r sin ϕ , and let
us express y1, y2 in the form y1 =
Then

sin α, y2 =

cos α.

y
||

y
||

||

||

G(y) =

rψ(r2)dr

e−ir||y|| sin(ϕ+α)dϕ =

2π

Z
0

+∞

=

Z
0

rψ(r2)dr

e−ir||y|| sin ϕdϕ = 2π

+∞

Z

0

rψ(r2)J0(r

)dr ,

y
||

||

+∞

Z
0

2π+α

Z
α

where J0 is Bessel function.

J0(r

) =

y
||

||

[cos(r

y
||

|| −

) + O((r

y
||

)−1)]
||

,

π
4

1
πr

y
||

||
π

for r

y
||

|| −→ ∞

|

||| ≤

−

i

arg r

p
y
||

ǫ < π , cf.[4]

+∞

Z

0

rψ(r2)
y
πr
||

||

p

cos(r

y
||

|| −

)dr =

π
4

Re e

−iπ
4

+∞

Z

0

1
π

y
||

||

p

Now we compute the ﬁrst term of asymptotics of the integral

eir||y||r

2 ψ(r2)dr .

1

F (

y
||

||

) =

Z

0

+∞

eir||y||r

2 ψ(r2)dr , f or

1

y
||

|| −→ ∞

.

We assumed that the function ψ(r2) and its derivatives tend quickly to 0,
as r
. Therefore with the help of localization rule and Erdelyi Lemma

→ ∞

ArtFENS06

printed on February 2, 2008

7

cf.[4] we obtain

b

Z
0

a) Re[e

−iπ
4

1

eir||y||r

2 ψ0(r2)dr] = 0 ,

the asymptotics is trivial,

−iπ
4

b) e

b

Z

0

1

eir||y||r

2 +βψ1(rγ)dr =

= e

−iπ
4 ψ1(0)Γ(

iπβ

= ie

2 ψ1(0)Γ(

iπ( 3
2 +β)
2

iπ( 3
2 +β)
2

+ β)e

3
2
3
2
iπ( 3
2 +β)
2

+ β)e

y
||

||

−3
2 −β + +O(
y
||

||

−5
2 −β) =

y
||

||

−3
2 −β + O(
y
||

||

−5
2 −β)

,

iπβ

Re[ie

2 ψ1(0)Γ(

+ β)e

3
2

−3
2 −β] =

y
||

||

sin

−

πβ
2

ψ1(0)Γ(

+ β)

3
2

−3
2 −β

y
||

||

The expression above isn’t trivial, when β is not a natural even number.
Hence the ﬁrst term of the asymptotics of the integral G(y) is given by a
formula:

G(y) = 2√π(

)ψ1(0)Γ(

sin

πβ
2
−2−β + O(
y
||
||

y
||

+ β)

3
−2−β + O(
y
2
||
||
−3−β) f or
||

|| −→ ∞

y
||

.

−
y
= c1||

−3−β ) =
||

g(x) = c1(detΣ)

−1
2

(A−1)∗
||

||

−2−β

x

−2−β + O(
||
||

x

−3−β) .
||

||

Lemma 5.2. Under the assumptions of theorem 3.1 the bivariate random
variable X = (X1, X2) is regularly varying with the index β.

Thus

Proof.

X
P (
|

|

∈
> t)

> ty, arg X
X
P (
|
α0)

|
+∞
ty

[α0, α1])

α1
α0
2π
0
R
[r−1−β + O(r−2−β)] dr

+∞
ty
+∞
t

= R

R

R

[r−1−β + O(r−2−β)] dr

=

(α1 −
2π

R
+∞
t

R

rg(r, θ) dθ dr

rg(r, θ) dθ dr

=

=

α0

α1 −
2π

y−β

.

Lemma 5.2 implies the thesis of Theorem 3.1 cf.[5].

8

ArtFENS06

printed on February 2, 2008

REFERENCES

[1] P. Billingsley, Probability and Measure, John Wiley & Sons, Inc. 1979.
[2] J.-P. Bouchaud, M. Potters, Theory of Financial Risks:

from Statistical

Physics to Risk Management, Cambridge University Press 2000.

[3] Extremes and Integrated Risk Management, Ed. by Paul Embrechts, Risk

Books, 2000.

[4] M.W.Fiedoruk, Metod pierewala, Izd. Nauka, 1977.
[5] H.Hult, F.Lindskog, Multivariate Extremes, Aggregation and Dependence in

Elliptical Distributions, Adv.Appl.Prob.34.587-608(2002).

[6] J.L.Jensen, Saddlepoint Approximations, Oxford University Press, 1995.
[7] R.N.Mantegna, H.E.Stanley, An Introduction to Econophysics. Correlations

and Complexity in Finance, Cambridge University Press 2000.

