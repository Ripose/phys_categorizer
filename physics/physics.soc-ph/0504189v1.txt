5
0
0
2
 
r
p
A
 
6
2
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
9
8
1
4
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

Advances in Complex Systems
c(cid:13) World Scientiﬁc Publishing Company

HOW INDIVIDUALS LEARN TO TAKE TURNS: EMERGENCE OF
ALTERNATING COOPERATION IN A CONGESTION GAME AND
THE PRISONER’S DILEMMA

Dirk Helbing, Martin Sch¨onhof, Hans-Ulrich Stark

Institute for Transport & Economics, Dresden University of Technology
Andreas-Schubert-Str. 23, 01062 Dresden, Germany

Faculty of Physics and Center of Excellence for Complex Systems Research,
Warsaw University of Technology, Koszykowa 75, PL-00-662 Warsaw, Poland

Janusz A. Ho lyst

Received (received date)
Revised (revised date)

In many social dilemmas, individuals tend to generate a situation with low payoﬀs instead
of a system optimum (”tragedy of the commons”). Is the routing of traﬃc a similar
problem? In order to address this question, we present experimental results on humans
playing a route choice game in a computer laboratory, which allow one to study decision
behavior in repeated games beyond the Prisoner’s Dilemma. We will focus on whether
individuals manage to ﬁnd a cooperative and fair solution compatible with the system-
optimal road usage. We ﬁnd that individuals tend towards a user equilibrium with equal
travel times in the beginning. However, after many iterations, they often establish a
coherent oscillatory behavior, as taking turns performs better than applying pure or
mixed strategies. The resulting behavior is fair and compatible with system-optimal
road usage. In spite of the complex dynamics leading to coordinated oscillations, we
have identiﬁed mathematical relationships quantifying the observed transition process.
Our main experimental discoveries for 2- and 4-person games can be explained with a
novel reinforcement learning model for an arbitrary number of persons, which is based
on past experience and trial-and-error behavior. Gains in the average payoﬀ seem to be
an important driving force for the innovation of time-dependent response patterns, i.e.
the evolution of more complex strategies. Our ﬁndings are relevant for decision support
systems and routing in traﬃc or data networks.

Keywords: Game theory; reinforcement learning; multi-agent simulation.

1. Introduction

Congestion is a burden of today’s traﬃc systems, aﬀecting the economic prosper-
ity of modern societies. Yet, the optimal distribution of vehicles over alternative
routes is still a challenging problem and uses scarce resources (street capacity) in
an ineﬃcient way. Route choice is based on interactive, but decentralized individual
decisions, which cannot be well described by classical utility-based decision mod-
els [27]. Similar to the minority game [16,39,43], it is reasonable for diﬀerent people

1

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

2 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

to react to the same situation or information in diﬀerent ways. As a consequence,
individuals tend to develop characteristic response patterns or roles [26]. Thanks to
this diﬀerentiation process, individuals learn to coordinate better in the course of
time. However, according to current knowledge, selﬁsh routing does not establish
the system optimum of minimum overall travel times. It rather tends to estab-
lish the Wardrop equilibrium, a special user or Nash equilibrium characterized by
equal travel times on all alternative routes chosen from a certain origin to a given
destination (while routes with longer travel times are not taken) [71].

Since Pigou [53], it has been suggested to resolve the problem of ineﬃcient road
usage by congestion charges, but are they needed? Is the missing establishment of
a sytem optimum just a problem of varying traﬃc conditions and changing origin-
destination pairs, which make route-choice decisions comparable to one-shot games?
Or would individuals in an iterated setting of a day-to-day route choice game with
identical conditions spontaneously establish cooperation in order to increase their
returns, as the folk theorem suggests [6]?

How would such a cooperation look like? Taking turns could be a suitable so-
lution [62]. While simple symmetrical cooperation is typically found for the re-
peated Prisoner’s Dilemma [2,3,44–46,49,52,55,59,64,67,69], emergent alternating
reciprocity has been recently discovered for the games Leader and Battle of the
Sexes [11].a Note that such coherent oscillations are a time-dependent, but de-
terministic form of individual decision behavior, which can establish a persistent
phase-coordination, while mixed strategies, i.e. statistically varying decisions, can
establish cooperation only by chance or in the statistical average. This diﬀerence is
particularly important when the number of interacting persons is small, as in the
particular route choice game discussed below.

Note that oscillatory behavior has been found in iterated games before:

• In the rock-paper-scissors game [67], cycles are predicted by the game-

dynamical equations due to unstable stationary solutions [28].

• Oscillations can also result by coordination problems [1, 29, 31, 33], at the

cost of reduced system performance.

• Moreover, blinker strategies may survive in repeated games played by a
mixture of ﬁnite automata [5] or result through evolutionary strategies
[11, 15, 16, 38, 39, 42, 43, 74].

However, these oscillation-generating mechanisms are clearly to be distinguished
from the establishment of phase-coordinated alternating reciprocity we are inter-
ested in (coherent oscillatory cooperation to reach the system optimum).

Our paper is organized as follows: In Section 2, we will formally introduce the
route choice game for N players, including issues like the Wardrop equilibrium [71]
and the Braess paradox [10]. Section 3 will focus on the special case of the 2-person
route choice game, compare it with the minority game [1, 15, 16, 38, 39, 42, 43, 74],

aSee Fig. 2 for a speciﬁcation of these games.

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

Emergence of Taking Turns in A Congestion Game

3

and discuss its place in the classiﬁcation scheme of symmetrical 2x2 games. This
section will also reveal some apparent shortcomings of the previous game-theoretical
literature:

• While it is commonly stated that among the 12 ordinally distinct, symmet-
rical 2x2 games [11,57] only 4 archetypical 2x2 games describe a strategical
conﬂict (the Prisoner’s Dilemma, the Battle of the Sexes, Chicken, and
Leader) [11, 18, 56], we will show that, for speciﬁc payoﬀs, the route choice
game (besides Deadlock) also represents an interesting strategical conﬂict,
at least for iterated games.

• The conclusion that conservative driver behavior is best, i.e. it does not pay
oﬀ to change routes [7,65,66], is restricted to the special case of route-choice
games with a system-optimal user equilibrium.

• It is only half the truth that cooperation in the iterated Prisoner’s Dilemma
is characterized by symmetrical behavior [11]. Phase-coordinated asym-
metric reciprocity is possible as well, as in some other symmetrical 2x2
games [11].

New perspectives arise by less restricted speciﬁcations of the payoﬀ values.

In section 4, we will discuss empirical results of laboratory experiments with hu-
mans [12,18,32]. According to these, reaching a phase-coordinated alternating state
is only one problem. Exploratory behavior and suitable punishment strategies are
important to establish asymmetric oscillatory reciprocity as well [11, 20]. Moreover,
we will discuss several coeﬃcients characterizing individual behavior and chances for
the establishment of cooperation. In section 5, we will present multi-agent computer
simulations of our observations, based on a novel win-stay, lose-shift [50, 54] strat-
egy, which is a special kind of reinforcement learning strategy [40]. This approach is
based on individual historical experience [13] and, thereby, clearly diﬀers from the
selection of the best-performing strategy in a set of hypothetical strategies as as-
sumed in studies based on evolutionary or genetical algorithms [5,11,15,16,39,42,43].
The ﬁnal section will summarize our results and discuss their relevance for game
theory and possible applications such as data routing algorithms [35, 72], advanced
driver information systems [8, 14, 30, 37, 41, 63, 70, 73], or road pricing [53].

2. The Route Choice Game

In the following, we will investigate a scenario with two alternative routes between a
certain origin and a given destination, say, between two places or towns A and B (see
Fig. 1). We are interested in the case where both routes have diﬀerent capacities,
say a freeway and a subordinate or side road. While the freeway is faster when it is
empty, it may be reasonable to use the side road when the freeway is congested.

The “success” of taking route i could be measured in terms of its inverse travel
time 1/Ti(Ni) = Vi(Ni)/Li, where Li is the length of route i and Vi(Ni) the av-
erage velocity when Ni of the N drivers have selected route i. One may roughly

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

4 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

Origin

Route 1

Route 2

Destination

Fig. 1. Illustration of the investigated day-to-day route choice scenario. We study the dynamic
decision behavior in a repeated route choice game, where a given destination can be reached from
a given origin via two diﬀerent routes, a freeway (route 1) and a side road (route 2).

approximate the average vehicle speed Vi on route i by the linear relationship [24]

Vi(Ni) = V 0

1 −

i (cid:18)

Ni(t)
N max

i (cid:19)

,

i denotes the maximum velocity (speed limit) and N max
where V 0
i.e. the maximum possible number of vehicles on route i. With Ai = V 0
Bi = V 0

i Li), the inverse travel time then obeys the relationship

i /(N max

i

the capacity,
i /Li and

1/T (Ni) = Ai − BiNi ,

which is linearly decreasing with the road occupancy Ni. Other monotonously falling
relationships Vi(Ni) would make the expression for the inverse travel times non-
linear, but they would probably not lead to qualitatively diﬀerent conclusions.

The user equilibrium of equal travel times is found for a fraction

of persons choosing route 1. In contrast, the system optimum corresponds to the
maximum of the overall inverse travel times N1/T1(N1) + N2/T2(N2) and is found
for the fraction

N e
1
N

=

B2
B1 + B2

+

1
N

A1 − A2
B1 + B2

N o
1
N

=

B2
B1 + B2

+

1
2N

A1 − A2
B1 + B2

(1)

(2)

(3)

(4)

of 1-decisions. The diﬀerence between both fractions vanishes in the limit N →
∞. Therefore, only experiments with a few players allow to ﬁnd out, whether the
test persons adapt to the user equilibrium or to the system optimum. We will see
that both cases have completely diﬀerent dynamical implications: While the most
successful strategy to establish the user equilibrium is to stick to the same decision
in subsequent iterations [27, 65, 66], the system optimum can only be reached by a

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

Emergence of Taking Turns in A Congestion Game

5

time-dependent strategy (at least, if no participant is ready to pay for the proﬁts
of others).

Note that alternative routes can reach comparable travel times only when the
total number N of vehicles is large enough to fulﬁl the relationships P1(N ) <
P2(0) = A2 and P2(N ) < P1(0) = A1. Our route choice game will address this traﬃc
regime and additionally assume N ≤ N max
corresponds to a
complete gridlock on route i.

. The case Ni = N max

i

i

Finally, it may be interesting to connect the previous quantities with the vehicle
densities ρi and the traﬃc ﬂows Qi: If route i consists of Ii lanes, the relation with
the average vehicle density is ρi(Ni) = Ni/(IiLi), and the relation with the traﬃc
ﬂow is Qi(Ni) = ρiVi(Ni) = Ni/[IiTi(Ni)].

In the following, we will linearly transform the inverse travel time 1/Ti(Ni) in

order to deﬁne the so-called payoﬀ

Pi(Ni) = Ci − DiNi

(5)

for choosing route i. The payoﬀ parameters Ci and Di depend on the parameters
Ai, Bi, and N , but will be taken constant. We have scaled the parameters so that
we have the payoﬀ Pi(N e
i ) = 0 (zero payoﬀ points) in the user equilibrium and the
payoﬀ N1P1(N o
1 ) = 100N (an average of 100 payoﬀ points) in the
system optimum. This serves to reach generalizable results and to provide a better
orientation to the test persons.

1 ) + N2P2(N − N o

Note that the investigation of social (multi-person) games with linearly falling
payoﬀs is not new [33]. For example, Schelling [62] has discussed situations with
“conditional externality”, where the outcome of a decision depends on the indepen-
dent decisions of potentially many others [62]. Pigou has addressed this problem,
which has been recently focused on by Schreckenberg and Selten’s project SUR-
VIVE [7, 65, 66] and others [8, 41, 58].

The route choice game is a special congestion game [22, 47, 60]. More precisely
speaking, it is a multi-stage symmetrical N -person single commodity congestion
game [68]. Congestion games belong to the class of “potential games” [48], for
which many theorems are available. For example, it is known that there always
exists a Wardrop equilibrium [71] with essentially unique Nash ﬂows [4]. This is
characterized by the property that no individual driver can decrease his or her
travel time by a diﬀerent route choice. If there are several alternative routes from a
given origin to a given destination, the travel times on all used alternative routes in
the Wardrop equilibrium is the same, while roads with longer travel times are not
used. However, the Wardrop equilibrium as expected outcome of selﬁsh routing does
not generally reach the system optimum, i.e. minimize the total travel times. Nash
ﬂows are often ineﬃcient, and selﬁsh behavior implies the possibility of decreased
network performance.b This is particularly pronounced for the Braess paradox [10,
61], according to which additional streets may sometimes increase the overall travel

bFor more details see the work by T. Roughgarden.

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

6 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

time and reduce the throughput of a road network. The reason for this is the possible
existence of badly performing Nash equilibria, in which no single person can improve
his or her payoﬀ by changing the decision behavior.

In fact, recent laboratory experiments indicate that, in a “day-to-day route
choice scenario” based on selﬁsh routing, the distribution of individuals over the
alternative routes is ﬂuctuating around the Wardrop equilibrium [27,63]. Additional
conclusions from the laboratory experiments by Schreckenberg, Selten et al. are as
follows [65, 66]:

• Most people, who change their decision frequently, respond to their expe-

rience on the previous day (i.e. in the last iteration).

• There are only a few diﬀerent behavioral patterns: direct responders (44%),
contrarian responders (14%), and conservative persons, who do not respond
to the previous outcome.

• It does not pay oﬀ to react to travel time information in a sensitive way,
as conservative test persons reach the smallest travel times (the largest
payoﬀs) on average.

• People’s reactions to short term travel forecasts can invalidate these. Nev-
ertheless, travel time information helps to match the Wardrop equilibrium,
so that excess travel times due to coordination problems are reduced.

A closer experimental analysis based on longer time series (i.e. more iterations) for
smaller groups of test persons reveals a more detailed picture [26]:

• Individuals do not only show an adaptive behavior to the travel times on
the previous day, but also change their response pattern in time [26, 34].
• In the course of time, one ﬁnds a diﬀerentiation process which leads to the
development of characteristic, individual response patterns, which tend to
be almost deterministic (in contrast to mixed strategies).

• While some test persons respond to small diﬀerences in travel times, oth-
ers only react to medium-sized deviations, further people respond to large
deviations, etc. In this way, overreactions of the group to deviations from
the Wardrop equilibrium are considerably reduced.

Note that the diﬀerentiation of individual behaviors is a way to resolve the coor-
dination problem to match the Wardrop equilibrium exactly, i.e. which participant
should change his or her decision in the next iteration in order to compensate for
a deviation from it. This implies that the fractions of speciﬁc behavioral response
patterns should depend on the parameters of the payoﬀ function. A certain frac-
tion of “stayers”, who do not respond to travel time information, can improve the
coordination in the group, i.e. the overall performance. However, stayers can also
prevent the establishment of a system optimum, if alternating reciprocity is needed,
see Eq. (14).

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

Emergence of Taking Turns in A Congestion Game

7

3. Classiﬁcation of Symmetrical 2x2 Games

In contrast to previous laboratory experiments, we have studied the route choice
game not only with a very high number of repetitions, but also with a small number
N ∈ {2, 4} of test persons, in order to see whether the system optimum or the
Wardrop equilibrium is established. Therefore, let us shortly discuss how the 2-
person game relates to previous game-theoretical studies.

Prisoner´s
Dilemma

Chicken

Leader

Battle  
of the Sexes

Strategy 1

Stag Hunt

Harmony

Route Choice

−200

P
12

Notation:

1

0

2

P12

Strategy 2

P21

−200

Pure
Coordination

Deadlock

P
21

0

−200

Fig. 2. Classiﬁcation of symmetrical 2x2 games according to their payoﬀs Pij. Two payoﬀ values
have been kept constant as payoﬀs may be linearly transformed and the two strategies of the
one-shot game renumbered. Our choice of P11 = 0 and P22 = −200 was made to deﬁne a payoﬀ
of 0 points in the user equilibrium and an average payoﬀ of 100 in the system optimum of our
investigated route choice game with P12 = 300 and P21 = −100.

Iterated symmetrical two-person games have been intensively studied [12, 18],
including Stag Hunt, the Battle of the Sexes, or the Chicken Game (see Fig. 2).
They can all be represented by a payoﬀ matrix of the form P = (Pij ), where Pij
is the success (“payoﬀ”) of person 1 in a one-shot game when choosing strategy
i ∈ {1, 2} and meeting strategy j ∈ {1, 2}. The respective payoﬀs of the second
person are given by the symmetrical values Pji. Figure 2 shows a systematics of the
previously mentioned and other kinds of symmetrical two-person games [21]. The
relations

for example, deﬁne a Prisoner’s Dilemma. In this paper, however, we will mainly
focus on the 2-person route choice game deﬁned by the conditions

P21 > P11 > P22 > P12 ,

P12 > P11 > P21 > P22

(6)

(7)

(see Fig. 3). Despite some common properties, this game diﬀers from the minority
game [16, 39, 43] or El Farol bar problem [1] with P12, P21 > P11, P22, as a minority
decision for alternative 2 is less proﬁtable than a majority decision for alternative
1. Although oscillatory behavior has been found in the minority game as well [9,15,
16, 36, 43], an interesting feature of the route choice experiments discussed in the
following is the regularity and phase-coordination (coherence) of the oscillations.

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

8 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

a)

b)

Coop. Def.

c)

Coop. Def.

d)

Strategy 1

Cooperation

0 −300

Cooperation

0 −300

Route 1

1

0

2

P12

1

0

2

300

Strategy 2

P21

−200

Defection

100

−200

Defection

500

−200

Route 2

−100 −200

Fig. 3. Payoﬀ speciﬁcations of the symmetrical 2x2 games investigated in this paper. a) General
payoﬀ matrix underlying the classiﬁcation scheme of Fig. 2. b), c) Two variants of the Prisoner’s
Dilemma. d) Route choice game with a strategical conﬂict between the user equilibrium and the
system optimum.

The 2-person route choice game ﬁts well into the classiﬁcation scheme of sym-
metrical 2x2 games. In Rapoport and Guyer’s taxonomy of 2x2 games [57], the 2-
person route choice game appears on page 211 as game number 7 together with four
other games with strongly stable equilibria. Since then, the game has almost been
forgotten and did not have a commonly known interpretation or name. Therefore,
we suggest to name it the 2-person “route choice game”. Its place in the extended
Eriksson-Lindgren scheme of symmetrical 2x2 games is graphically illustrated in
Fig. 2.

According to the game-theoretical literature, there are 12 ordinally distinct,
symmetric 2x2 games [57], but after excluding strategically trivial games in the sense
of having equilibrium points that are uniquely Pareto-eﬃcient, there remain four
archetypical 2x2 games: the Prisoner’s Dilemma, the Battle of the Sexes, Chicken
(Hawk-Dove), and Leader [56]. However, this conclusion is only correct, if the four
payoﬀ values Pij are speciﬁed by the four values {1, 2, 3, 4}. Taking diﬀerent values
would lead to a diﬀerent conclusion: If we name subscripts so that P11 > P22,
a strategical conﬂict between a user equilibrium and the system optimum results
when

P12 + P21 > 2P11 .

(8)

Our conjecture is that players tend to develop alternating forms of reciprocity if this
condition is fulﬁlled, while symmetric reciprocity is found otherwise. This has the
following implications (see Fig. 2):

• If the 2x2 games Stag Hunt, Harmony, or Pure Coordination are repeated
frequently enough, we expect always a symmetrical form of cooperation.
• For Leader and the Battle of the Sexes, we expect the establishment of
asymmetric reciprocity, as has been found by Browning and Colman with a
computer simulation based on a genetic algorithm incorporating mutation
and crossing-over [11].

• For the games Route Choice, Deadlock, Chicken, and Prisoner’s Dilemma
both, symmetric (simultaneous) and asymmetric (alternating) forms of co-
operation are possible, depending on whether condition (8) is fulﬁlled or
not. Note that this condition cannot be met for some games, if one restricts

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

Emergence of Taking Turns in A Congestion Game

9

to ordinal payoﬀ values Pij ∈ {1, 2, 3, 4} only. Therefore, this interesting
problem has been largely neglected in the past (with a few exceptions,
e.g. [51]). In particular, convincing experimental evidence of alternating
reciprocity is missing. The following sections of this paper will, therefore,
not only propose a simulation model, but also focus on an experimental
study of this problem, which promises interesting new results.

4. Experimental Results

t

i

n
a
p
c
i
t
r
a
P

1
N

1

2

 2
 1
 0

Participant 1
Participant 2

i

2
s
n
o
1
s
2
c
e
1 D

i

f
f

o
y
a
P
e
v
i
t

 

l

a
u
m
m
u
C

 20000

 15000

 10000

 5000

 0

-5000

0

50

100

200

250

300

 0

 50

 100

 200

 250

 300

150
Iteration t

 150
Iteration t

Fig. 4. Representative example for the emergence of coherent oscillations in a 2-person route choice
experiment with the parameters speciﬁed in Fig. 3d. Top left: Decisions of both participants over
300 iterations. Bottom left: Number N1(t) of 1-decisions over time t. Note that N1 = 1 corresponds
to the system optimum, while N1 = 2 corresponds to the user equilibrium of the one-shot game.
Right: Cumulative payoﬀ of both players in the course of time t (i.e. as a function of the number
of iterations). Once the coherent oscillatory cooperation is established (t > 220), both individuals
have high payoﬀ gains on average.

Altogether we have carried out more than 80 route choice experiments with
diﬀerent experimental setups, all with diﬀerent participants. In the 24 two-person
[12 four-person] experiments evaluated here (see Figs. 4–15), test persons were in-
structed to choose between two possible routes between the same origin and des-
tination. They knew that route 1 corresponds to a ‘freeway’ (which may be fast
or congested), while route 2 represents an alternative route (a ‘side road’). Test
persons were also informed that, if two [three] participants would choose route 1,
everyone would receive 0 points, while if half of the participants would choose route
1, they would receive the maximum average amount of 100 points, but 1-choosers
would proﬁt at the cost of 2-choosers. Finally, participants were told that everyone
could reach an average of 100 points per round with variable, situation-dependent
decisions, and that the (additional) individual payment after the experiment would
depend on their cumulative payoﬀ points reached in at least 300 rounds (100 points
= 0.01 EUR).

Let us ﬁrst focus on the two-person route-choice game with the payoﬀs P11 =
P1(2) = 0, P12 = P1(1) = 300, P21 = P2(1) = −100, and P22 = P2(2) = −200
(see Fig. 3d), corresponding to C1 = 600, D1 = 300, C2 = 0, and D2 = 100. For
this choice of parameters, the best individual payoﬀ in each iteration is obtained by

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

10 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

i

t
n
a
p
c
i
t
r
a
P

1
N

1

2

 2
 1
 0

Participant 1
Participant 2

i

2
s
n
o
1
s
2
c
e
1 D

i

f
f
o
y
a
P
 
e
v
i
t
a
u
m
m
u
C

l

 20000

 15000

 10000

 5000

 0

-5000

0

50

100

200

250

300

 0

 50

 100

 200

 250

 300

150
Iteration t

 150
Iteration t

Fig. 5. Representative example for a 2-person route choice experiment, in which no alternating
cooperation was established. Due to the small changing frequency of participant 1, there were not
enough cooperative episodes that could have initiated coherent oscillations. Top left: Decisions of
both participants over 300 iterations. Bottom left: Number N1(t) of 1-decisions over time t. Right:
The cumulative payoﬀ of both players in the course of time t shows that the individual with the
smaller changing frequency has higher proﬁts.

choosing route 1 (the “freeway”) and have the co-player(s) choose route 2. Choosing
route 1 is the dominant strategy of the one-shot game, and players are tempted to
use it. This produces an initial tendency towards the “strongly stable” user equilib-
rium [57] with 0 points for everyone. However, this decision behavior is not Pareto
eﬃcient in the repeated game. Therefore, after many iterations, the players often
learn to establish the Pareto optimum of the multi-stage supergame by selecting
route 1 in turns (see Fig. 4). As a consequence, the experimental payoﬀ distribu-
tion shows a maximum close to 0 points in the beginning and a peak at 100 points
after many iterations (see Fig. 6), which clearly conﬁrms that the choice behavior
of test persons tends to change over time. Nevertheless, in 7 out of 24 two-person
experiments, persistent cooperation did not emerge during the experiment. Later
on, we will identify reasons for this.

 12

 10

 8

 6

 4

 2

y
c
n
e
u
q
e
r
F
 
e
t
u
o
s
b
A

l

i

s
t
n
a
p
c
i
t
r
a
P

 
f
o
 

 30

 25

 20

 15

 10

 5

y
c
n
e
u
q
e
r
F
 
e
t
u
o
s
b
A

l

i

s
t
n
a
p
c
i
t
r
a
P

 
f
o
 

 0
-100 -50

 0

 50

 100  150  200

 0
-100 -50  0  50  100  150  200  250  300

Average Payoff per Iteration (Iterations 1-50)

Average Payoff per Iteration (Iterations 250-300)

Fig. 6. Frequency distributions of the average payoﬀs of the 48 players participating in our 24
two-person route choice experiments. Left: Distribution during the ﬁrst 50 iterations. Right: Dis-
tribution between iterations 250 and 300. The initial distribution with a maximum close to 0 points
(left) indicates a tendency towards the user equilibrium corresponding to the dominant strategy of
the one-shot game. However, after many iterations, many individuals learn to establish the system
optimum with a payoﬀ of 100 points (right).

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

4.1. Emergence of cooperation and punishment

Emergence of Taking Turns in A Congestion Game

11

i

t
n
a
p
c
i
t
r
a
P

1
N

1

2

 2
 1
 0

Participant 1
Participant 2

i

2
s
n
o
1
s
2
c
e
1 D

i

f
f
o
y
a
P
 
e
v
i
t
a
u
m
m
u
C

l

 30000
 25000
 20000
 15000
 10000
 5000
 0
-5000

0

50

100

200

250

300

 0

 50

 100

 200

 250

 300

150
Iteration t

 150
Iteration t

Fig. 7. Representative example for a 2-person route choice experiment, in which participant 1 leaves
the pattern of oscillatory cooperation temporarily in order to make additional proﬁts. Note that
participant 2 does not “punish” this selﬁsh behavior, but continues to take routes in an alternating
way. Top left: Decisions of both participants over 300 iterations. Bottom left: Number N1(t) of
1-decisions over time t. Right: Cumulative payoﬀ of both players as a function of the number of
iterations. The diﬀerent slopes indicate an unfair outcome despite of high average payoﬀs of both
players.

In order to reach the system optimum of (−100 + 300)/2 = 100 points per it-
eration, one individual has to leave the freeway for one iteration, which yields a
reduced payoﬀ of –100 in favour of a high payoﬀ of +300 for the other individual.
To be proﬁtable also for the ﬁrst individual, the other one should reciprocate this
“oﬀer” by switching to route 2, while the ﬁrst individual returns to route 1. Estab-
lishing this oscillatory cooperative behavior yields 100 extra points on average. If
the other individual is not cooperative, both will be back to the user equilibrium of
0 points only, and the uncooperative individual has temporarily proﬁted from the
oﬀer by the other individual. This makes “oﬀers” for cooperation and, therefore,
the establishment of the system optimum unlikely.

Hence, the innovation of oscillatory behavior requires intentional or random
changes (“trial-and-error behavior”). Moreover, the consideration of multi-period
decisions is helpful. Instead of just 2 one-stage (i.e. one-period) alternative deci-
sions 1 and 2, there are 2n diﬀerent n-stage (n-period) decisions. Such multi-stage
strategies can be used to deﬁne higher-order games and particular kinds of su-
pergame strategies. In the two-person 2nd-order route choice game, for example, an
encounter of the two-stage decision 12 with 21 establishes the system optimum and
yields equal payoﬀs for everyone (see Fig. 8). Such an optimal and fair solution is
not possible for one-stage decisions. Yet, the encounter of 12 with 21 (“cooperative
episode”) is not a Nash equilibrium of the two-stage game, as an individual can
increase his or her own payoﬀ by selecting 11 (see Fig. 8). Probably for this reason,
the ﬁrst cooperative episodes in a repeated route choice game (i.e. encounters of
12-decisions with 21-decisions in two subsequent iterations) do often not persist (see
Fig. 9). Another possible reason is that cooperative episodes may be overlooked.
This problem, however, can be reduced by a feedback signal that indicates when

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

12 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

1

0

2

300

Route 1

11

21

22

12

2
300

11

0

3

3

12

4
−100 −200
2

4

300
1

600

200

100

Route 2

−100 −200

21

−100
1

200 −200

100

22

−200 −300 −300 −400

P (2)

Fig. 8. Illustration of the concept of higher-order games deﬁned by n-stage strategies. Left: Payoﬀ
matrix P = (Pij ) of the one-shot 2x2 route choice game. Right: Payoﬀ matrix
=
(Pi1j1 +Pi2j2 ) of the 2nd-order route choice game deﬁned by 2-stage decisions (right). The analysis
of the one-shot game (left) predicts that the user equilibrium (with both persons choosing route
1) will establish and that no single player could increase the payoﬀ by another decision. For two-
period decisions (right), the system optimum (strategy 12 meeting strategy 21) corresponds to
a fair solution, but one person can increase the payoﬀ at the cost of the other (see arrow 1), if
the game is repeated. A change of the other person’s decision can reduce losses and punish this
egoistic behavior (arrow 2), which is likely to establish the user equilibrium with payoﬀ 0. In order
to leave this state again in favour of the system optimum, one person will have to make an “oﬀer”
at the cost of a reduced payoﬀ (arrow 3). This oﬀer may be due to a random or intentional change
of decision. If the other person reciprocates the oﬀer (arrow 4), the system optimum is established
again. The time-averaged payoﬀ of this cycle lies below the system optimum.

(i1i2),(j1j2)

(cid:16)

(cid:17)

the system optimum has been reached. For example, we have experimented with a
green background color. In this setup, a cooperative episode could be recognized by
a green background that appeared in two successive iterations together with two
diﬀerent payoﬀ values.

The strategy of taking route 1 does not only dominate on the ﬁrst day (in the
ﬁrst iteration). Even if a cooperative oscillatory behavior has been established, there

s
p
u
o
r
G

 
f

 

o
n
o

i
t
r
o
p
o
r
P

 1

 0.8

 0.6

 0.4

 0.2

 0

Empirical Data
Fit Function

 0

 5  10  15  20  25  30  35  40  45  50

Required Cooperative Episodes n

Fig. 9. Cumulative distribution of required cooperative episodes until persistent cooperation was
established, given that cooperation occured during the duration of the game as in 17 out of 24
two-person experiments. The experimental data are well approximated by the logistic curve (9)
with the ﬁt parameters c2 = 3.4 and d2 = 0.17.

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

Emergence of Taking Turns in A Congestion Game

13

is a temptation to leave this state, i.e. to choose route 1 several times, as this yields
more than 100 points on average for the uncooperative individual at the cost of the
participant continuing an alternating choice behavior (see Figs. 7 and 8). That is,
the conditional changing probability pl(2|1, N1 = 1; t) of individuals l from route
1 to route 2, when the system optimum in the previous iteration was established
(i.e. N1 = 1) tends to be small initially. However, oscillatory cooperation of period
2 needs pl(2|1, N1 = 1; t) = 1. The required transition in the decision behavior
can actually be observed in our experimental data (see Fig. 10, left). With this
transition, the average frequency of 1-decisions goes down to 1/2 (see Fig. 10, right).
Note, however, that alternating reciprocity does not necessarily require oscillations
of period 2. Longer periods are possible as well (see Fig. 11), but have occured only
in a few cases (namely, 3 out of 24 cases).

p1(2|1,N1=1;t)
p2(2|1,N1=1;t)

y
t
i
l
i

b
a
b
o
r
P
n
o

 

i
t
i
s
n
a
r
T

 1

 0.8

 0.6

 0.4

 0.2

 0

i

i

s
n
o
s
c
e
D
-
1

 
f

o

 

n
o

i
t
r
o
p
o
r
P

 1

 0.8

 0.6

 0.4

 0.2

 0

 0

 50

 100  150  200  250  300

 0

 50

Iteration t

P1(1,t)
P2(1,t)
 100  150  200  250  300

Iteration t

Fig. 10. Left: Conditional changing probability pl(2|1, N1 = 1; t) of person l from route 1 (the
“freeway”) to route 2, when the other person has chosen route 2, averaged over a time window
of 50 iterations. The transition from initially small values to 1 (for t > 240) is characteristic and
illustrates the learning of cooperative behavior. In this particular group (cf. Fig. 4) the values
started even at zero, after a transient time period of t < 60. Right: Proportion Pl(1, t) of 1-
decisions of both participants l in the two-person route choice experiment displayed in Fig. 4.
While the initial proportion is often close to 1 (the user equilibrium), it reaches the value 1/2
when persistent oscillatory cooperation (the system optimum) is established.

How does the transition to oscillatory cooperation come about? The establish-
ment of alternating reciprocity can be supported by a suitable punishment strategy:
If the other player should have selected route 2, but has chosen route 1 instead, he
or she can be punished by changing to route 1 as well, since this causes an average
payoﬀ of less than 100 points for the other person (see Fig. 8). Repeated punishment
of uncooperative behavior can, therefore, reinforce cooperative oscillatory behavior.
However, the establishment of oscillations also requires costly “oﬀers” by switch-
ing to route 2, which only pay back in case of alternating reciprocity. It does not
matter whether these “oﬀers” are intentional or due to exploratory trial-and-error
behavior.

Due to punishment strategies and similar reasons, persistent cooperation is often
established after a number n of cooperative episodes. In the 17 of our 24 two-
person experiments, in which persistent cooperation was established, the cumulative

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

14 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

i

t
n
a
p
c
i
t
r
a
P

1
N

1

2

 2
 1
 0

Participant 1
Participant 2

2
1
2
1

i

s
n
o
s
c
e
D

i

f
f
o
y
a
P
 
e
v
i
t
a
u
m
m
u
C

l

 20000

 15000

 10000

 5000

 0

-5000

0

50

100

200

250

300

 0

 50

 100

 200

 250

 300

150
Iteration t

 150
Iteration t

Fig. 11. Representative example for a 2-person route choice experiment with phase-coordinated
oscillations of long (and varying) time periods larger than 2. Top left: Decisions of both participants
over 300 iterations. Bottom left: Number N1(t) of 1-decisions over time t. Right: Cumulative
payoﬀ of both players as a function of the number of iterations. The sawtooth-like increase in the
cumulative payoﬀ indicates gains by phase-coordinated alternations with long oscillation periods.

distribution of required cooperative episodes could be mathematically described by
the logistic curve

FN (n) = 1/[1 + cN exp(−dN n)]

(9)

(see Fig. 9). Note that, while we expect that this relationship is generally valid, the
ﬁt parameters cN and dN may depend on factors like the distribution of participant
intelligence, as oscillatory behavior is apparently diﬃcult to establish (see below).

4.2. Preconditions for cooperation

Let us focus on the time period before persistent oscillatory cooperation is estab-
lished and denote the occurence probability that individual l chooses alternative
i ∈ {1, 2} by Pl(i). The quantity pl(j|i) shall represent the conditional probability
of choosing j in the next iteration, if i was chosen by person l in the present one.
Assuming stationarity for reasons of simplicity, we expect the relationship

pl(2|1)Pl(1) = pl(1|2)Pl(2) ,

i.e. the (unconditional) occurence probability Pl(1, 2) = pl(2|1)Pl(1) of having alter-
native 1 in one iteration and 2 in the next agrees with the joint occurence probability
Pl(2, 1) = pl(1|2)Pl(2) of ﬁnding the opposite sequence 21 of decisions:

Moreover, if rl denotes the average changing frequency of person l until persistent
cooperation is established, we have the relation

Pl(1, 2) = Pl(2, 1) .

rl = Pl(1, 2) + Pl(2, 1) .

Therefore, the probability that all N players simultaneously change their decision
N
l=1 rl. Note that there are 2N such realizations
from one iteration to the next is
of N decision changes 12 or 21, which have all the same occurence probability
because of Eqn. (11). Among these, only the ones where N/2 players change from

Q

(10)

(11)

(12)

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

Emergence of Taking Turns in A Congestion Game

15

1 to 2 and the other N/2 participants change from 2 to 1 establish cooperative
episodes, given that the system optimum corresponds to an equal distribution over
both alternatives. Considering that the number of diﬀerent possibilities of selecting
N/2 out of N persons is given by the binomial coeﬃcient, the occurence probability
of cooperative events is

(at least in the ensemble average). Since the expected time period T until the
cooperative state incidentally occurs equals the inverse of Pc, we ﬁnally ﬁnd the
formula

Pc =

1
2N (cid:18)

N
N/2 (cid:19)

N

Yl=1

rl

T =

1
Pc

= 2N (N/2)!2

N !

N

Yl=1

1
rl

.

(13)

(14)

This formula is well conﬁrmed by our 2-person experiments (see Fig. 12). It gives
the lower bound for the expected value of the minimum number of required iter-
ations until persistent cooperation can spontaneously emerge (if already the ﬁrst
cooperative episode is continued forever).

2-Person Games

 100

 10

 1

 
 
 

n
 
s
e
d
o
s
p
E
e
v
i
t

 

i

 

a
r
e
p
o
o
C
d
e
r
i
u
q
e
R

 0.1

 0.1

 1

 10

 100

Expected Cooperative Episodes 

Fig. 12. Comparison of the required number of cooperative episodes y with the expected number
x of cooperative episodes (approximated as occurence time of persistent cooperation, divided by
the expected time interval T until a cooperative episode occurs by chance). Note that the data
points support the relationship y = x and, thereby, formula (14).

Obviously, the occurence of oscillatory cooperation is expected to take much
longer for a large number N of participants. This tendency is conﬁrmed by our 4-
person experiments compared to our 2-person experiments. It is also in agreement
with intuition, as coordination of more people is more diﬃcult. (Note that mean
ﬁrst passage or transition times in statistical phyisics tend to grow exponentially in
the number N of particles as well.)

Besides the number N of participants, another critical factor for the cooperation
probability are the changing frequencies rl: They are needed for the exploration of

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

16 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

innovative strategies, coordination and cooperation. Although the instruction of
test persons would have allowed them to conclude that taking turns would be a
good strategy, the changing frequencies rl of some individuals was so small that
cooperation within the duration of the respective experiment did not occur, in
accordance with formula (14). The unwillingness of some individuals to vary their
decisions is sometimes called “conservative” [7,65,66] or “inertial behavior” [9]. Note
that, if a player never reciprocates “oﬀers” by other players, this may discourage
further “oﬀers” and reduce the changing frequency of the other player(s) as well
(see the decisions 50 through 150 of player 2 in Fig. 4).

Our experimental time series show that most individuals initially did not know a
periodic decision behavior would allow them to establish the system optimum. This
indicates that the required depth of strategic reasoning [19] and the related com-
plexity of the game for an average person are already quite high, so that intelligence
may matter. Compared to control experiments, the hint that the maximum average
payoﬀ of 100 points per round could be reached “by variable, situation-dependent
decisions”, increased the average changing frequency (by 75 percent) and with this
the occurence frequency of cooperative events. Thereby, it also increased the chance
that persistent cooperation established during the duration of the experiment.

Note that successful cooperation requires not only coordination [9], but also in-
novation: In their ﬁrst route choice game, most test persons discover the oscillatory
cooperation strategy only by chance in accordance with formula (14). The chang-
ing frequency is, therefore, critical for the establishment of innovative strategies:
It determines the exploratory trial-and-error behavior. In contrast, cooperation is

i

.
p
c
i
t
r
a
P

1

N

.

i

p
c
i
t
r
a
P

1

N

1

2

 2
 1
 0

1

2

 2
 1
 0

0

50

100

150

200

250

300

2
1
2
1

i

s
n
o
s
c
e
D

i

2
1
2
1

i

s
n
o
s
c
e
D

i

i

t
n
a
p
c
i
t
r
a
P

1

N

1

2

3

4

 4
 3
 2
 1
 0

i

s
n
o
s
c
e
D

i

2
1
2
1
2
1
2
1

0

50

100

150

200

250

300

0

50

100

150

200

250

Iteration t

Iteration t

Fig. 13. Experimentally observed decision behavior when two groups involved in two-person route
choice experiments afterwards played a four-person game with C1 = 900, D1 = 300, C2 = 100,
D2 = 100. Left: While oscillations of period 2 emerged in the second group (bottom), another
alternating pattern corresponding to n-period decisions with n > 2 emerged in the ﬁrst group
(top). Right: After all persons had learnt oscillatory cooperative behavior, the four-person game
just required coordination, but not the invention of a cooperative strategy. Therefore, persistent
cooperation was quickly established (in contrast to four-person experiments with new participants).
It is clearly visible that the test persons continued to apply similar decision strategies (right) as
in the previous two-person experiments (left).

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

Emergence of Taking Turns in A Congestion Game

17

easy when test persons know that the oscillatory strategy is successful: When two
teams, who had successfully cooperated in 2-person games, had afterwards to play
a 4-person game, cooperation was always and quickly established (see Fig. 13).
In contrast, unexperienced co-players suppressed the establishment of oscillatory
cooperation in 4-person route choice games.

4.3. Strategy coeﬃcients

In order to characterize the strategic behavior of individuals and predict their
chances of cooperation, we have introduced some strategy coeﬃcients. For this,
let us introduce the following quantities, which are determined from the iterations
before persistent cooperation is established:

• ck

l = relative frequency of a changed subsequent decision of individual l if
the payoﬀ was negative (k = −), zero (k = 0), or positive (k = +).
l = relative frequency of individual l to stay with the previous decision if
the payoﬀ was negative (k = −), zero (k = 0), or positive (k = +).

• sk

The Yule-coeﬃcient

−

−
l
−
l

−

c
c

(15)

Ql =

l s+
l s+

l − c+
l s
l + c+
l s
with −1 ≤ Ql ≤ 1 was used by Schreckenberg, Selten et al. [65] to identify direct
responders with 0.5 < Ql ≈ 1 (who change their decision after a negative payoﬀ
and stay after a positive payoﬀ), and contrarian responders with −0.5 > Ql ≈ −1
(who change their decision after a positive payoﬀ and stay after a negative one). A
random decision behavior would correspond to a value Ql ≈ 0. However, a problem
−
arises if one of the variables c
l , or s
l assumes the value 0. Then, we have
Ql ∈ {−1, 1}, independently of the other three values. If two of the variables become
zero, Ql is sometimes even undeﬁned. Moreover, if the values are small, the resulting
conclusion is not reliable. Therefore, we prefer to use the percentage diﬀerence

l , s+

l , c+

−

Sl =

−
c
l
−
l + sl
l

c

−

c+
l
l + s+
c+

l

(16)

for the assessment of strategies. Again, we have −1 ≤ Sl ≤ 1. Direct responders
correspond to Sl > 0.25 and contrarian responders to Sl < −0.25. For −0.25 ≤
Sl ≤ 0.25, the response to the previous payoﬀ is rather random.

In addition, we have introduced the Z-coeﬃcient

Zl =

c0
l
l + s0
c0
for which we have 0 ≤ Zl ≤ 1. This coeﬃcient describes the likely response of
individual l to the user equilibrium. Zl = 0 means that individual l does not change
routes, if the user equilibrium was reached. Zl = 1 implies that person l always
changes, while Zl ≈ 0.5 indicates a random response.

(17)

,

l

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

18 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

 1

 0.8

 0.6

 0.4

 0.2

 0

-0.2

-0.4

2
 
t
n
a
p
c
i
t
r
a
P

i

i

 
f
o
 
t
n
e
c
i
f
f
e
o
C
S

-

Participant in Cooperating Group
Part. in Non-Cooperating Group

2
 
t
n
a
p
c
i
t
r
a
P

i

i

 
f
o
 
t
n
e
c
i
f
f
e
o
C
-
Z

 1

 0.8

 0.6

 0.4

 0.2

 0

 0

Participant in Cooperating Group
Part. in Non-Cooperating Group

-0.4 -0.2  0  0.2  0.4  0.6  0.8  1

 0.2

 0.4

 0.6

 0.8

 1

S-Coefficient of Participant 1

Z-Coefficient of Participant 1

Fig. 14. Coeﬃcients Sl and Zl of both participants l in all 24 two-person route choice games. The
values of the S-coeﬃcients (i.e. the individual tendencies towards direct or contrarian responses)
are not very signiﬁcant for the establishment of persistent cooperation, while large enough values
of the Z-coeﬃcient stand for the emergence of oscillatory cooperation.

Figure 14 shows the result of the 2-person route choice experiments (cooperation
or not) as a function of S1 and S2, and as a function of Z1 and Z2. Moreover,
Figure 15 displays the result as a function of the average strategy coeﬃcients

and

Z =

1
N

N

Xl=1

Zl

S =

Sl .

1
N

N

Xl=1

(18)

(19)

Our experimental data indicate that the Z-coeﬃcient is a good indicator for the
establishment of cooperation, while the S-coeﬃcient seems to be rather insigniﬁcant
(which also applies to the Yule coeﬃcient).

Cooperating Groups
Groups without Cooperation

i

 
t
n
e
c
i
f
f
e
o
C
-
Z
 
n
a
e
M

i

s
t
n
a
p
c
i
t
r
a
P

 
f
o
 

 1

 0.8

 0.6

 0.4

 0.2

 0

-0.4

-0.2

 0

 0.2

 0.4

 0.6

 0.8

Mean S-Coefficient of Participants

Fig. 15. S- and Z-coeﬃcients averaged over both participants in all 24 two-person route choice
games. The mainly small, but positive values of S indicate a slight tendency towards direct re-
sponses. However, the S-coeﬃcient is barely signiﬁcant for the emergence of persistent oscillations.
A good indicator for their establishment is a suﬃciently large Z-value.

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

Emergence of Taking Turns in A Congestion Game

19

5. Multi-Agent Simulation Model

In a ﬁrst attempt, we have tried to reproduce the observed behavior in our 2-
person route choice experiments by game-dynamical equations [28]. We have applied
these to the 2x2 route choice game and its corresponding two-, three- and four-
stage higher-order games (see Sec. 4.1). Instead of describing patterns of alternating
cooperation, however, the game dynamical equations predicted a preference for the
dominant strategy of the one-shot game, i.e. a tendency towards choosing route 1.
The reason for this becomes understandable through Fig. 8. Selecting routes
2 and 1 in an alternating way is not a stable strategy, as the other player can
get a higher payoﬀ by choosing two times route 1 rather than responding with 1
and 2. Selecting route 1 all the time even guarantees that the own payoﬀ is never
below the one by the other player. However, when both players select route 1 and
establish the related user equilibrium, no player can improve his or her payoﬀ in
the next iteration by changing the decision. Nevertheless, it is possible to improve
the long-term outcome, if both players change their decisions, and if they do it in
a coordinated way. Note, however, that a strict alternating behavior of period 2
is an optimal strategy only in inﬁnitely repeated games, while it is unstable to
perturbations in ﬁnite games.

It is known that cooperative behavior may be explained by a “shadow of the
future” [2, 3], but it can also be established by a “shadow of the past” [40], i.e.
experience-based learning. This will be the approach of the multi-agent simula-
tion model proposed in this section. As indicated before, the emergence of phase-
coordinated strategic alternation (rather than a statistically independent applica-
tion of mixed strategies) requires an almost deterministic behavior (see Fig. 16).
Nevertheless, some weak stochasticity is needed for the establishment of asymmetric
cooperation, both for the exploration of innovative strategies and for phase coor-
dination. Therefore, we propose the following reinforcement learning model, which
could be called a generalized win-stay, lose-shift strategy [50, 54].

t
n
e
g
A

1
N

1

2

 2
 1
 0

Agent 1
Agent 2

i

2
s
n
o
1
s
2
c
e
1 D

i

f
f
o
y
a
P
 
e
v
i
t
a
u
m
m
u
C

l

 20000

 15000

 10000

 5000

 0

-5000

0

50

100

200

250

300

 0

 50

 100

 200

 250

 300

150
Iteration t

 150
Iteration t

Fig. 16. Representative example for a 2-person route choice simulation based on our proposed
multi-agent reinforcement learning model with P max
av = −200. The parameter ν1
l
has been set to 0.25. The other model parameters are speciﬁed in the text. Top left: Decisions
of both agents over 300 iterations. Bottom left: Number N1(t) of 1-decisions over time t. Right:
Cumulative payoﬀ of both agents as a function of the number of iterations. The emergence of
oscillatory cooperation is comparable with the experimental data displayed in Fig. 4.

av = 100 and P min

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

20 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

Let us presuppose that an individual approximately memorizes or has a good
feeling of how well he or she has performed on average in the last nl iterations and
since he or she has last responded with decision j to the situation (i, N1). In our
success- and history-dependent model of individual decision behavior, pl(j|i, N1; t)
denotes agent l’s conditional probability of taking decision j at time t + 1, when i
was selected at time t and N1(t) agents had chosen alternative 1. Assuming that pl
is either 0 or 1, pl(j|i, N1; t) has the meaning of a deterministic response strategy:
pl(j|i, N1; t) = 1 implies that individual l will respond at time t+1 with the decision
j to the situation (i, N1) at time t.

Our reinforcement learning strategy can be formulated as follows: The response
strategy pl(j|i, N1, t) is switched with probability ql > 0, if the average individual
payoﬀ since the last comparable situation with i(t′) = i(t) and N1(t′) = N1(t)
at time t′ < t is less than the average individual payoﬀ P l(t) during the last nl
iterations. In other words, if the time-dependent aspiration level P l(t) [40,54] is not
reached by the agent’s average payoﬀ since his or her last comparable decision, the
individual is assumed to substitute the response strategy pl(j|i, N1; t) by

pl(j|i, N1; t + 1) = 1 − pl(j|i, N1; t)

(20)

with probability ql. The replacement of dissatisfactory strategies orients at historical
long-term proﬁts (namely, during the time period [t′, t]). Thereby, it avoids short-
sighted changes after temporary losses. Moreover, it does not assume a comparison
of the performance of the actually applied strategy with hypothetical ones as in most
evolutionary models. A readiness for altruistic decisions is also not required, while
exploratory behavior (“trial and error”) is necessary. In order to reﬂect this, the
decision behavior is randomly switched from pl(j|i, N1; t + 1) to 1 − pl(j|i, N1; t + 1)
with probability

νl(t) = max

l , ν1
ν0

l

(cid:18)

P max
P max

av − P l(t)
av − P min

av (cid:19)

≪ 1 .

(21)

av

av

and P max

Herein, P min
agents (simulated players). The parameter ν1
P l(t) = P min
time-averaged payoﬀ P l reaches the system optimum P

denote the minimum and maximum average payoﬀ of all N
l reﬂects the mutation frequency for
l when the

av , while the mutation frequency is assumed to be ν0

l ≤ ν1

max
av .

In our simulations, no emergent cooperation is found for ν0

l > 0
or odd values of nl may produce intermittent breakdowns of cooperation. A small,
but ﬁnite value of ν1
is important to ﬁnd a transition to persistent cooperation.
l
Therefore, we have used the parameter value ν1
l = 0.25, while the simplest possible
speciﬁcation has been chosen for the other parameters, namely ν0
l = 0, ql = 1, and
nl = 2.

l = 0. ν0

l = ν1

The initial conditions for the simulation of the route choice game were speciﬁed
in accordance with the dominant strategy of the one-shot game, i.e. Pl(1, 0) = 1 (ev-
eryone tends to choose the freeway initially), pl(2|1, N1; 0) = 0 (it is not attractive
to change from the freeway to the side road) and pl(1|2, N1; 0) = 1 (it is tempting

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

y
t
i
l
i

b
a
b
o
r
P
 
n
o
i
t
i
s
n
a
r
T

 1

 0.8

 0.6

 0.4

 0.2

 0

 100

 10

 1

 
 
 

i

n
 
s
e
d
o
s
p
E
 
e
v
i
t
a
r
e
p
o
o
C
 
d
e
r
i
u
q
e
R

Emergence of Taking Turns in A Congestion Game

21

i

i

s
n
o
s
c
e
D
-
1
 
f
o
 
n
o
i
t
r
o
p
o
r
P

 1

 0.8

 0.6

 0.4

 0.2

 0

 0

 50

 100  150  200  250  300

 0

 50

p1(2|1,N1=1)
p2(2|1,N1=1)

Iteration t

P1(1,t)
P2(1,t)
 100  150  200  250  300

Iteration t

Fig. 17. Left: Conditional changing probability pl(2|1, N1 = 1; t) of agent l from route 1 (the
“freeway”) to route 2, when the other agent has chosen route 2, averaged over a time window of 50
iterations. The transition from small values to 1 for the computer simulation displayed in Fig. 16
is characteristic and illustrates the learning of cooperative behavior. Right: Proportion Pl(1, t) of
1-decisions of both participants l in the two-person route choice experiment displayed in Fig. 16.
While the initial proportion is often close to 1 (the user equilibrium), it reaches the value 1/2 when
persistent oscillatory cooperation (the system optimum) is established. The simulation results are
compatible with the essential features of the experimental data (see, for example, Fig. 10).

to change from the side road to the freeway). Interestingly enough, agents learnt
to acquire the response strategy pl(2|1, N1 = 1; t) = 1 in the course of time, which
established oscillatory cooperation with higher proﬁts (see Figs. 16 and 17).

Note that the above described reinforcement learning model [40] responds only
to the own previous experience [13]. Despite its simplicity (e.g. the neglection of
more powerful, but probably less realistic k-move memories [11]), our “multi-agent”
simulations reproduce the emergence of asymmetric reciprocity of two or more
players, if an oscillatory strategy of period 2 can establish the system optimum.
This raises the question why previous experiments of the N -person route choice

s
p
u
o
r
G

 
f
o
 
n
o
i
t
r
o
p
o
r
P

 1

 0.8

 0.6

 0.4

 0.2

 0

 0

2-Agent Simulations

 0.1

 0.1

 1

 10

 100

Expected Cooperative Episodes 

Simulation Data
Fit Function

 10

 5
 15
Required Cooperative Episodes n

 20

 25

 30

Fig. 18. Left: Comparison of the required number of cooperative episodes with the expected number
of cooperative episodes in our multi-agent simulation of decisions in the route choice game. Note
that the data points support formula (14). Right: Cumulative distribution of required cooperative
episodes until persistent cooperation is established in our 2-person route choice simulations, using
the simplest speciﬁcation of model parameters (not calibrated). The simulation data are well
approximated by the logistic curve (9) with the ﬁt parameters c2 = 7.9 and d2 = 0.41.

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

22 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

game [27, 63] have observed a clear tendency towards the Wardrop equilibrium [71]
with P1(N1) = P2(N2) rather than phase-coordinated oscillations? It turns out
that the payoﬀ values must be suitably chosen [see Eq. (8)] and that several hun-
dred repetitions are needed. In fact, the expected time interval T until a cooperative
episode among N = N1 +N2 participants occurs in our simulations by chance is well
described by formula (14), see Fig. 18. The empirically observed transition in the
decision behavior displayed in Fig. 10 is qualitatively reproduced by our computer
simulations as well (see Fig. 17). The same applies to the frequency distribution of
the average payoﬀ values (compare Fig. 19 with Fig. 6) or to the number of expected
and required cooperative episodes (compare Fig. 18 with Figs. 9 and 12).

y
c
n
e
u
q
e
r
F
 
e
t
u
o
s
b
A

l

i

s
t
n
a
p
c
i
t
r
a
P

 
f
o
 

 14
 12
 10
 8
 6
 4
 2
 0
-100 -50

y
c
n
e
u
q
e
r
F
 
e
t
u
o
s
b
A

l

i

s
t
n
a
p
c
i
t
r
a
P

 
f
o
 

 35
 30
 25
 20
 15
 10
 5
 0
-100 -50  0  50  100  150  200  250  300

 0

 50

 100  150  200

Average Payoff per Iteration (Iterations 1-50)

Average Payoff per Iteration (Iterations 250-300)

Fig. 19. Frequency distributions of the average payoﬀs in our computer simulations of the 2-person
route choice game. Left: Distribution during the ﬁrst 50 iterations. Right: Distribution between
iterations 250 and 300. Our simulation results are compatible with the experimental data displayed
in Fig. 6.

5.1. Simultaneous and alternating cooperation in the Prisoner’s

Dilemma

Let us ﬁnally simulate the dynamic behavior in the two diﬀerent variants of the
Prisoner’s Dilemma indicated in Fig. 3b, c with the above experience-based rein-
forcement learning model. Again, we will assume P11 = 0 and P22 = −200. Ac-
cording to Eq. (8), a simultaneous, symmetrical form of cooperation is expected
for P12 = −300 and P21 = 100, while an alternating, asymmetric cooperation is
expected for P12 = −300 and P21 = 500. Figure 20 shows simulation results for the
two diﬀerent cases of the Prisoner’s Dilemma and conﬁrms the two predicted forms
of cooperation. Again, we varied only the parameter ν1
l , while we chose the sim-
plest possible speciﬁcation of the other parameters ν0
l = 0, ql = 1, and nl = 2. The
initial conditions were speciﬁed in accordance with the expected non-cooperative
outcome of the one-shot game, i.e. Pl(1, 0) = 0 (everyone defects in the beginning),
pl(2|2, N1; 0) = 0 (it is tempting to continue defecting), pl(1|1, N1 = 1; 0) = 0 (it is
unfavourable to be the only cooperative player), and and pl(1|1, N1 = 2; 0) = 1 (it is
good to continue cooperating, if the other player cooperates). In the course of time,

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

Emergence of Taking Turns in A Congestion Game

23

agents learn to acquire the response strategy pl(2|2, N1 = 0; t) = 0 when simulta-
neous cooperation evolves, but pl(2|2, N1 = 1; t) = 0 when alternating cooperation
is established.

0

50

100

200

250

300

 0

 50

 100

 200

 250

 300

t
n
e
g
A

1
N

t

n
e
g
A

1
N

1

2

 2
 1
 0

1

2

 2
 1
 0

150
Iteration t

150
Iteration t

i

2
s
n
o
1
s
2
c
e
1 D

i

i

2
s
n
o
1
s
2
c
e
1 D

i

f
f
o
y
a
P
 
e
v
i
t
a
u
m
m
u
C

l

 10000
 5000
 0
-5000
-10000
-15000
-20000
-25000

f
f

o
y
a
P
e
v
i
t

 

l

a
u
m
m
u
C

 20000
 15000
 10000
 5000
 0
-5000
-10000
-15000

Agent 1
Agent 2

Agent 1
Agent 2

 150
Iteration t

 150
Iteration t

0

50

100

200

250

300

 0

 50

 100

 200

 250

 300

Fig. 20. Representative examples for computer simulations of the two diﬀerent forms of the Pris-
oner’s Dilemma speciﬁed in Fig. 3b, c. The parameter ν1
l has been set to 0.25, while the other
model parameters are speciﬁed in the text. Top: Emergence of simultaneous, symmetrical coopera-
tion, where decision 2 corresponds to defection and decision 1 to cooperation. The system optimum
corresponds to P max
av = −200. Bottom: Emer-
gence of alternating, asymmetric cooperation with P max
av = −200. Left: Time
series of the agents’ decisions and the number N1(t) of 1-decisions. Right: Cumulative payoﬀs as
a function of time t.

av = 0 payoﬀ points, and the minimum payoﬀ to P min

av = 100 and P min

6. Summary, Discussion, and Outlook

In this paper, we have investigated the N -person day-to-day route-choice game.
This special congestion game has not been thoroughly studied before in the case
of small groups, where the system optimum can considerably diﬀer from the user
equilibrium. The 2-person route choice game gives a meaning to a previously uncom-
mon repeated symmetrical 2x2 game and shows a transition from the dominating
strategy of the one-shot game to coherent oscillations, if P12 + P21 > 2P11. How-
ever, a detailed analysis of laboratory experiments with humans reveals that the
establishment of this phase-coordinated alternating reciprocity, which is expected
to occur in other 2x2 games as well, is quite complex. It needs either strategic ex-
perience or the invention of a suitable strategy. Such an innovation is driven by
the potential gains in the average payoﬀs of all participants and seems to be based
on exploratory trial-and-error behavior. If the changing frequency of one or sev-
eral players is too low, no cooperation is established in a long time. Moreover, the
emergence of cooperation requires certain kinds of strategies, which can be char-
acterized by the Z-coeﬃcient (18). These strategies can be acquired by means of

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

24 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

reinforcement learning, i.e. by keeping response patterns which have turned out to
be better than average, while worse response patterns are being replaced. The pun-
ishment of uncooperative behavior can help to enforce cooperation. Note, however,
that punishment in groups of N > 2 persons is diﬃcult, as it is hard to target the
uncooperative person, and punishment hits everyone. Nevertheless, computer sim-
ulations and additional experiments indicate that oscillatory cooperation can still
emerge in route choice games with more than 2 players after a long time period
(rarely within 300 iterations) (see Fig. 21).

i

t
n
a
p
c
i
t
r
a
P

1

N

1

2

3

4

 4
 3
 2
 1
 0

2
1
2
1
2
1
2
1

i

s
n
o
s
c
e
D

i

t
n
e
g
A

1

2

3

4

 4
 3
 2
 1
 0

1

N

i

s
n
o
s
c
e
D

i

2
1
2
1
2
1
2
1

0

50

100

150

200

250

0

50

100

150

200

250

Iteration t

Iteration t

Fig. 21. Emergence of phase-coordinated oscillatory behavior in the 4-person route choice game
with the parameters speciﬁed in Fig. 13. Left: Experimental data of the decisions of 4 unexperienced
participants over 300 iterations. Right: Computer simulation with the reinforcment learning model.

Altogether, spontaneous cooperation takes a long time. It is, therefore, sensitive
to changing conditions reﬂected by time-dependent payoﬀ parameters. As a con-
sequence, emergent cooperation is unlikely to appear in real traﬃc systems. This
is the reason why the Wardrop equilibrium tends to occur. However, cooperation
could be rapidly established by means of advanced traveller information systems
(ATIS) [8, 14, 30, 37, 41, 63, 70, 73], which would avoid the slow learning process de-
scribed by Eq. (14). Moreover, while we do not recommend conventional congestion
charges, a charge for unfair usage patterns would support the compliance with indi-
vidual route choice recommendations. It would supplement the ineﬃcient individual
punishment mechanism.

Diﬀerent road pricing schemes have been proposed, each of which has its own
advantages and disadvantages or side eﬀects. Congestion charges, for example, could
discourage to take congested routes, which is actually required to reach minimum
average travel times. Conventional tolls and road pricing may reduce the trip fre-
quency due to budget constraints, which potentially interferes with economic growth
and fair chances for everyone’s mobility.

In order to activate capacity reserves, we therefore propose an automated route
guidance system based on the following principles: After speciﬁcation of their des-
tination, drivers should get individual (and, on average, fair) route choice recom-
mendations in agreement with the traﬃc situation and the route choice proportions

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

Emergence of Taking Turns in A Congestion Game

25

required to reach the system optimum. If an individual selects a faster route instead
of the recommended route it should use, it will have to pay an amount proportional
to the decrease in the overall inverse travel time compared to the system optimum.
Moreover, drivers not in a hurry should be encouraged to take the slower route i by
receiving the amount of money corresponding to the related increase in the overall
inverse travel time. Altogether, such an ATIS could support the system optimum
while allowing for some ﬂexibility in route choice. Moreover, the fair usage pattern
would be cost-neutral for everyone, i.e. traﬃc ﬂows of potential economic relevance
would not be suppressed by extra costs.

In systems with many similar routing decisions, a Pareto optimum characterized
by asymmetric alternating cooperation may emerge even spontaneously. This could
help to enhance the routing in data networks [72] and generally to resolve Braess-like
paradoxes in networks [17].

Finally, it cannot be emphasized enough that taking turns is a promising strat-
egy to distribute scarce resources in a fair and optimal way. It could be applied
to a huge number of real-life situations due to the relevance for many strategical
conﬂicts, including Leader, the Battle of the Sexes, and variants of Route Choice,
Deadlock, Chicken, and the Prisoner’s Dilemma. The same applies to their N -person
generalizations, in particular social dilemmas [23, 25, 40]. It will also be interesting
to ﬁnd out whether and where metabolic pathways, biological supply networks, or
information ﬂows in neuronal and immune systems use alternating strategies to
avoid the waisting of costly resources.

Acknowledgements

D.H. is grateful for the warm hospitality of the Santa Fe Institute, where the Social
Scaling Working Group Meeting in August 2003 inspired many ideas of this paper.
The results shall be presented during the workshop on “Collectives Formation and
Specialization in Biological and Social Systems” in Santa Fe (April 20–22, 2005).

References

1390 (1988).

1396 (1981).

[1] Arthur, W. B., Inductive reasoning and bounded rationality, American Econonmic

Review 84, 406–411 (1994).

[2] Axelrod, R. and Dion, D., The further evolution of cooperation, Science 242, 1385–

[3] Axelrod, R. and Hamilton, W. D., The evolution of cooperation. Science 211, 1390–

[4] Beckmann, M., McGuire, C. B. and Winsten, C. B. Studies in the Economics of

Transportation (Yale University Press, New Haven, 1956).

[5] Binmore, K. G., Evolutionary stability in repeated games played by ﬁnite automata,

Journal of Economic Theory 57, 278–305 (1992).

[6] Binmore, K., Fun and Games: A Text on Game Theory (Heath, Lexington, MA,

1992), pp. 373–377.

[7] Bohnsack, U., Uni DuE: Studie SURVIVE gibt Einblicke in das Wesen des Auto-

fahrers, Press release by Informationsdienst Wissenschaft (January 21, 2005).

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

26 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

[8] Bonsall, P.W. and Perry, T., Using an interactive route-choice simulator to investigate
driver’s compliance with route guidance information, Transpn. Res. Rec. 1306, 59–68
(1991).

[9] Bottazzi, G. and Devetag, G., Coordination and self-organization in minority games:
Experimental evidence, Working Paper 2002/09, Sant’Anna School of Advances Stud-
ies, May 2002.

[10] Braess, D., ¨Uber ein Paradoxon der Verkehrsplanung [A paradox of traﬃc assign-
ment problems]. Unternehmensforschung 12, 258–268 (1968). For about 100 related
references see http://homepage.ruhr-uni-bochum.de/Dietrich.Braess/#paradox
[11] Browning, L. and Colman, A. M., Evolution of coordinated alternating reciprocity in

repeated dyadic games, J. Theor. Biol. 229, 549–557 (2004).

[12] Camerer, C. F., Behavioral Game Theory: Experiments on Strategic Interaction

(Princeton University Press, Princeton, 2003).

[13] Camerer, C. F., Ho, T.-H., and Chong, J.-K., Sophisticated experience-weighted at-
traction learning and strategic teaching in repeated games, Journal of Economic
Theory 104, 137–188 (2002).

[14] Cetin, N., Nagel, K., Raney, B. and Voellmy, A., Large scale multi-agent transporta-
tion simulations, Computer Physics Communications 147(1–2), 559–564 (2002).
[15] Challet, D. and Marsili, M., Relevance of memory in minority games, Phys. Rev. E

62, 1862–1868 (2000).

[16] Challet, D. and Zhang, Y.-C., Emergence of cooperation and organization in an evo-

lutionary game, Physica A 246, 407–418 (1997).

[17] Cohen, J. E. and Horowitz, P. Paradoxial behaviour of mechanical and electrical

networks, Nature 352, 699–701 (1991).

[18] Colman, A. M., Game Theory and its Applications in the Social and Biological Sci-

ences (Butterworth-Heinemann, Oxford, 2nd ed., 1995).

[19] Colman, A. M., Depth of strategic reasoning in games, TRENDS in Cognitive Sciences

7(1), 2–4 (2003).

[20] Crowley, P. H., Dangerous games and the emergence of social structure: evolving
memory-based strategies for the generalized hawk-dove game, Behavioral Ecology 12,
753–760 (2001).

[21] Eriksson, A. and Lindgren, K. Cooperation in an unpredictable environment,
in Proceedings of Artiﬁcial Life VIII (eds. Standish, R. K., Bedau, M. A. and
Abbass, H. A.) 394–399 (MIT Press, Sidney, 2002) and poster available at
http://frt.fy.chalmers.se/cs/people/eriksson.html

[22] Garcia, C. B. and Zangwill, W. I., Pathways to Solutions, Fixed Points, and Equilibria

(Prentice Hall, New York, 1981).

[23] Glance, N. S. and Huberman, B. A., The outbreak of cooperation, Journal of Math-

ematical Sociology 17(4), 281–302 (1993).

[24] Greenshield, B. D., A study of traﬃc capacity, in Proceedings of the Highway Research

Board (Highway Research Board, Washington, D.C.), Vol. 14 (1935), pp. 448–477.

[25] Hardin, G., The tragedy of the commons, Science 162, 1243–1248 (1968).
[26] Helbing, D., Dynamic decision behavior and optimal guidance through information
services: Models and experiments, in Human Behaviour and Traﬃc Networks, eds.
Schreckenberg, M. and Selten, R. (Springer, Berlin, 2004), pp. 47–95.

[27] Helbing, D., Sch¨onhof, M., and Kern, D., Volatile decision dynamics: Experiments,
stochastic description, intermittency control, and traﬃc optimization. New Journal
of Physics 4, 33.1–33.16 (2002).

[28] Hofbauer, J. and Sigmund, K., The Theory of Evolution and Dynamical Systems

(Cambridge University Press, Cambridge, 1988).

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

Emergence of Taking Turns in A Congestion Game

27

[29] Hogg, T. and Huberman, B. A., Controlling chaos in distributed systems, IEEE

Transactions on System, Man, and Cybernetics 21(6), 1325–1333 (1991).

[30] Hu, T.-Y. and Mahmassani, H. S., Day-to-day evolution of network ﬂows under real-
time information and reactive signal control, Transportation Research C 5(1), 51–69
(1997).

[31] Iwanaga, S. and Namatame, A., The complexity of collective decision, Nonlinear

Dynamics, Psychology, and Life Sciences 6(2), 137–158 (2002).

[32] Kagel, J. H. and Roth, A. E. (eds.), The Handbook of Experimental Economics

[33] Kephart, J. O., Hogg, T., and Huberman, B. A., Dynamics of computational ecosys-

(Princeton University, Princeton, NJ, 1995).

tems, Phys. Rev. A 40(1), 404–421 (1989).

[34] Kl¨ugl, F. and Bazzan, A. L. C., Route decision behaviour in a commuting scenario:

Simple heuristics adaptation and eﬀect of traﬃc forecast, JASSS 7(1) (Jan. 2004).

[35] Korilis, Y. A., Lazar, A. A., and Orda, A. Avoiding the Braess-paradox in non-

cooperative networks, Journal of Applied Probability 36, 211–222 (1999).

[36] Laureti, P., Ruch, P., Wakeling, J., and Zhang, Y.-C., The interactive minority game:
a Web-based investigation of human market interactions, Physica A 331, 651–659
(2004).

[37] Lee, K., Hui, P. M., Wang, B. H., and Johnson, N. F., Eﬀects of announcing global
information in a two-route traﬃc ﬂow model, J. Phys. Soc. Japan 70, 3507–3510
(2001).

[38] Lo, T. S., Chan, H, Y., Hui, P. M., and Johnson, N. F., Theory of networked minority
games based on strategy pattern dynamics, Phys. Rev. E 70, 056102 (2004).
[39] Lo, T. S., Hui, P. M., and Johnson, N. F., Theory of the evolutionary minority game,

Phys. Rev. E 62, 4393–4396 (2000).

[40] Macy, M. W. and Flache, A., Learning dynamics in social dilemmas, Proceedings of

the National Academy of Sciences USA 99, Suppl. 3, 7229–7236 (2002).

[41] Mahmassani, H. S. and Jou, R. C., Transferring insights into commuter behavior
dynamics from laboratory experiments to ﬁeld surveys, Transportation Research A
34, 243–260 (2000).

[42] Mansilla, R., Algorithmic complexity in the minority game, Phys. Rev. E 62, 4553–

[43] Marsili, M., Mulet, R., Ricci-Tersenghi, F., and Zecchina, R., Learning to coordinate

in a complex and nonstationary world, Phys. Rev. Lett. 87, 208701 (2001).

[44] McNamara, J. M., Barta, Z., and Houston, A. I., Variation in behaviour promotes

cooperation in the prisoner’s dilemma game, Nature 428, 745–748 (2004).

[45] Michor, F. and Nowak, M. A., The good, the bad and the lonely, Nature 419, 677–679

4557 (2000).

(2002).

[46] Milinski, M., Semmann, D., and Krambeck, H.-J., Reputation helps solve the ‘tragedy

of the commons’, Nature 415, 424–426 (2002).

[47] Monderer, D. and Shapley, L. S., Fictitious play property for games with identical

interests, J. Econ. Theory 1, 258–265 (1996).

[48] Monderer, D. and Shapley, L. S., Potential games, Games and Economic Behavior

14, 124–143 (1996).

[49] Nowak, M. A., Sasaki, A., Taylor, C., and Fudenberg, D., Emergence of cooperation
and evolutionary stability in ﬁnite populations, Nature 428, 646–650 (2004).
[50] Novak, M. and Sigmund, K., A strategy of win-stay, lose-shift that outperforms tit-

for-tat in the Prisoner’s Dilemma game, Nature 364, 56–58 (1993).

[51] Nowak, M. A. and Sigmund, K. The alternating prisoner’s dilemma, J. theor. Biol.

168, 219–226 (1994).

February 2, 2008 5:30 WSPC/INSTRUCTION FILE

acs˙ﬁnal

28 D. Helbing, M. Sch¨onhof, H.-U. Stark, and J. A. Ho lyst

[52] Nowak, M. A. and Sigmund, K., Evolution of indirect reciprocity by image scoring,

Nature 393, 573–577 (1998).

[53] Pigou, A. C., The Economics of Welfare (Macmillan, London, 1920).
[54] Posch, M., Win-stay, lose-shift strategies for repeated games—Memory length, aspi-

ration levels and noise, J. Theor. Biol. 198, 183–195 (1999).
[55] Queller, D. C., Kinship is relative, Nature 430, 975–976 (2004).
[56] Rapoport, A., Exploiter, leader, hero, and martyr: the four archtypes of the 2x2 game,

[57] Rapoport, A. and Guyer, M., A taxonomy of 2x2 games, Gen. Systems 11, 203–214

Behav. Sci. 12, 81–84 (1967).

(1966).

[58] Reddy, P. D. V. G. et al., Design of an artiﬁcial simulator for analyzing route choice
behavior in the presence of information system, J. Math. Comp. Mod. 22, 119–147
(1995).

[59] Riolo, R. L., Cohen, M. D., and Axelrod, R., Evolution of cooperation without reci-

procity, Nature 414, 441–443 (2001).

[60] Rosenthal, R. W., A class of games possessing pure-strategy Nash equilibria, Inter-

national Journal of Game Theory 2, 65–67 (1973).

[61] Roughgarden, T. and Tardos, E., How bad is selﬁsh routing? Journal of the ACM

[62] Schelling, T. C., Micromotives and Macrobehavior (WW Norton and Co, New York,

[63] Schreckenberg, M. and Selten, R. (eds.), Human Behaviour and Traﬃc Networks

49(2), 236–259 (2002).

1978), pp. 224–231+237.

(Springer, Berlin, 2004).

[64] Schweitzer, F., Behera, L., and M¨uhlenbein, H., Evolution of cooperation in a spatial

prisoner’s dilemma, Advances in Complex Systems 5(2/3), 269–299 (2002).

[65] Selten, R. et al., Experimental investigation of day-to-day route-choice behaviour
and network simulations of autobahn traﬃc in North Rhine-Westphalia, in Human
Behaviour and Traﬃc Networks, eds. Schreckenberg, M. and Selten, R. (Springer,
Berlin, 2004), pp. 1–21.

[66] Selten, R., Schreckenberg, M., Pitz, T., Chmura, T., and Kube, S., Experiments
and simulations on day-to-day route choice-behaviour, see http://papers.ssrn.com/
sol3/papers.cfm?abstract id=393841.

[67] Semmann, D., Krambeck, H.-J., and Milinski, M., Volunteering leads to rock-paper-

scissors dynamics in a public goods game, Nature 425, 390–393 (2003).

[68] Spirakis, P., Algorithmic aspects of congestion games, Invited talk at the 11th Collo-
quium on Structural Information and Communication Complexity (Smolenice Castle,
Slovakia, June 21-23, 2004).

[69] Szab´o, G. and Hauert, C., Phase transitions and volunteering in spatial public goods

games, Phys. Rev. Lett. 89, 118101 (2002).

[70] Wahle, J., Bazzan, A. L. C., Kl¨ugl, F. and Schreckenberg, M., Decision dynamics in

a traﬃc scenario, Physica A 287, 669–681 (2000).

[71] Wardrop, J. G., Some theoretical aspects of road traﬃc research, in Proceedings of

the Institution of Civil Engineers II, Vol. 1 (1952), pp. 325–378.

[72] Wolpert, D. H. and Tumer, K., Collective intelligence, data routing and Braess’ para-

dox, Journal of Artiﬁcial Intelligence Research 16, 359–387 (2002).

[73] Yamashita, T., Izumi, K., Kurumatani, K., Eﬀect of using route information sharing
to reduce traﬃc congestion, Lecture Notes in Computer Science 3012, 86–104 (2004).
[74] Yuan, B. and Chen, K., Evolutionary dynamics and the phase structure of the mi-

nority game, Phys. Rev. E 69, 067106 (2004).

