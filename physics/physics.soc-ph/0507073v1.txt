5
0
0
2
 
l
u
J
 
0
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
3
7
0
7
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

On a multi-timescale statistical feedback model for volatility ﬂuctuations

Lisa Borland† and Jean-Philippe Bouchaud+∗
† Evnine-Vaughan Associates, Inc.,
456 Montgomery Street, Suite 800,
San Francisco, CA 94104, USA
+ Science & Finance, Capital Fund Management,
6-8 Bd Haussmann, 75009 Paris, France, and
Service de Physique de l’ ´Etat Condens´e,
Orme des Merisiers, CEA Saclay,
91191 Gif sur Yvette Cedex, France.

(Dated: February 2, 2008)

We study, both analytically and numerically, an ARCH-like, multiscale model of volatility, which
assumes that the volatility is governed by the observed past price changes over diﬀerent time scales.
With a power-law distribution of time horizons, we obtain a model that captures most stylized facts
of ﬁnancial time series: Student-like distribution of returns with a power-law tail, long-memory
of the volatility, slow convergence of the distribution of returns towards the Gaussian distribution,
multifractality and anomalous volatility relaxation after shocks. At variance with recent multifractal
models that are strictly time reversal invariant, the model also reproduces the time asymmetry of
ﬁnancial time series: past large scale volatility inﬂuence future small scale volatility. In order to
quantitatively reproduce all empirical observations, the parameters must be chosen such that the
model is close to an instability, meaning that (a) the feedback eﬀect is important and substantially
increases the volatility, and (b) that the model is intrinsically diﬃcult to calibrate because of the
very long range nature of the correlations. By imposing consistency of the model predictions with
a large set of diﬀerent empirical observations, a reasonable range of the parameters value can be
determined. The model can easily be generalized to account for jumps, skewness and multiasset
correlations.

I.

INTRODUCTION

The quest for a faithful mathematical model of price ﬂuctuations has been taunting researchers for more than a
century now, starting with Bachelier’s random walk model in 1900 [1]. Such an endeavour is important for a bevy of
reasons, both from the point of view of (a) fundamental economics (what is the cause of price variations and what
information do they reveal?) and (b) of ﬁnancial engineering, with option pricing, risk control and trading models as
obvious applications.

In an ideal world, “the” mathematical model of price changes should be simple enough to allow easy calculations
and calibration, yet rich enough to embrace all known stylized facts that the recent access to huge amounts of data
has helped establish. It is now widely accepted that price changes reveal (i) fat tails, well described by a power-law
decay of the probability distribution for large returns [2, 3, 4], (ii) long range memory in volatility ﬂuctuations or
volatility “clustering”, again described by a power-law decay (in time) of the autocorrelation of the volatility [5, 6, 7]
and (iii) asymmetric causal correlations between past price changes and future volatilities, often referred to as the
“leverage eﬀect” [8] (for reviews, see e.g.
[9, 10, 11, 12]). We discuss below other, somewhat related, stylized facts
that have been reported in the recent literature, such as multifractal scaling, critical relaxation of the volatility after
a shock (the ﬁnancial analogue of the Omori law for earthquakes), etc. More recently, some statistical asymmetry of
ﬁnancial time series under time reversal was pointed out [13] – in other words, ﬁnancial time series do distinguish
past from future. This might appear trivial but constitutes in fact, as we discuss below, a very strong constraint on
the family of eligible models for ﬁnancial time series – for example, Bachelier’s random walk model is strictly time
reversal symmetric.

Scores of diﬀerent models have been proposed to improve upon the simple Brownian motion model, which has
neither fat tails nor volatility clustering. L´evy processes allow one to superimpose jumps to the Brownian motion,
and therefore generate fat tails, but has no volatility clustering [10, 11, 14, 15]. GARCH models or simple stochastic
volatility models such as the Heston model allow one to get both fat tails and some sort of volatility clustering, but

∗Electronic address: bouchau@spec.saclay.cea.fr

not the long memory observed in the data [16, 17, 18, 19]. Models that mix jumps and stochastic volatility have
been investigated [20]. Multifractal stochastic volatility models, initiated by Mandelbrot, Fisher and Calvet [21] and
much studied since [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], seem to capture in a parsimonious way a
large amount of empirical properties. However, most multifractal models are again strictly time reversal symmetric
and lack an intuitive interpretation in terms of agent based trading models [35]. We in fact strongly believe that any
serious model of price ﬂuctuations should in ﬁne be justiﬁed by reasonable behavioral rules and market microstructure
eﬀects (see [36, 37, 38, 39, 40] for recent work in that direction). Quite recently, one of us (LB) has proposed, in
the context of option pricing, a “statistical feedback” process where the local volatility is large when price moves are
deemed rare, leading to a non-linear diﬀusion equation for the price [41]. This equation can be solved and leads to a
Student-Tsallis distribution for price changes at all times [42]. In its original form, however, the model breaks time
translation symmetry: there is a well deﬁned starting date and starting price. Although this can be used to price
options [41, 43] (in the spirit of the Hull-White model for interest rates [44]), the process has to be modiﬁed to be
interpreted as a bona ﬁde model of returns. Such an extension, and its modiﬁcation to account for long-range memory,
was proposed in [45] and recovers, following a diﬀerent route, a multiscale GARCH model proposed by Zumbach and
Lynch in 2003 [13, 46] (see [6, 47, 48] for earlier work in that direction). Numerical simulations of this model suggest
a very rich phenomenology, that seems to account for most stylized facts of ﬁnancial time series.

The aim of the present paper is to motivate this new model, discuss its relation with previous work, and investigate
in full details its statistical properties, both analytically and numerically. We focus in particular on the probability
distribution of returns which is the crucial ingredient for option pricing and risk control. Although not an exact result,
we ﬁnd that these distributions can be well ﬁtted by a Student-Tsallis form, with a lag-dependent tail exponent. We
reproduce in great details most empirical facts, including the anomalous relaxation of the volatility after a shock, and
the past/future asymmetry of the time series. The model can be generalized to include jumps, the leverage eﬀect, and
multi-stock correlations. We then discuss the issue of calibration. Within strict econometric standards, calibration is
extremely diﬃcult due to the long-memory nature of both the empirical volatility process and the theoretical models
that are constructed precisely to capture this long memory. We advocate the idea of ‘soft’ calibration, which in such
cases should consist in reproducing semi-quantitatively as many observables as possible. These observables should be
chosen to be robust to the details of the model speciﬁcation, and test diﬀerent “orthogonal” predictions of the model
(these statements will be made clearer in the course of the paper and in Section VI). Consequences for option pricing
are brieﬂy discussed, and will be the subject of another paper.

II. SET UP AND MOTIVATION OF THE MODEL

In the following, we will consider a discrete time model, with an elementary time scale equal to τ , for example τ =1
minute. [A continuous time version of the model will be discussed below]. The price at time ti = iτ will be noted pi.
xi.[59] The
We will conform to the standard of dealing with the log-price xi = ln pi and deﬁne returns as ri = xi+1 −
random return is constructed as the product of a time dependent volatility σi and a random variable ξi of zero mean
and unit variance:

ri = µτ + σiξi√τ ,

where µ is the average drift, which we will set to zero in the sequel, meaning that we measure all returns relative to
the average drift. The noise ξi can a priori have any probability distribution to account for high frequency kurtosis
and jumps, but for simplicity we will mostly focus in this paper on the case of a Gaussian noise. However, as we
discuss below, the introduction of jumps is needed to faithfully reproduce real price time series.

The seminal insight of ARCH or GARCH models [49] is that the volatility process reﬂects trading activity and is
subordinated to past price changes. Intuitively, the level of activity becomes high when past price changes are, in
some sense, anomalous. In the simplest ARCH model, this is expressed as:

i = σ2
σ2
0

1 + g

r2
i−1
σ2
0τ

,

(cid:20)
meaning that the volatility is equal to its ‘base level’ σ2
0 plus a contribution coming from the last price change. In
fact, we have written the feedback term in a way that expresses the comparison between the square of the last return
and its expected value, equal to σ2
0τ . If the last price change was small compared to usual, the volatility today is
close to its normal value, whereas in the other limit, the last return is deemed anomalous and leads to a potentially
large increase of today’s activity.

(cid:21)

An argument motivating Eq. (2) above is as follows. Suppose that some traders open positions (for example, long)
at time ti−1, when the price is pi−1. Such trades are often initiated with both a proﬁt objective and a risk limit,

2

(1)

(2)

 Symmetric
 Skewed

0.03

0.02

0.01

)
∆
(
P

0
−0.15

−0.05

0.05

0.15

 ∆

FIG. 1: Schematic shape of the distribution of stop loss/stop gain thresholds around the opening price of the trade. Plain line:
symmetric distribution; dotted line: asymmetric distribution, giving rise to the leverage eﬀect discussed in section V.

which would close the position at time ti if the price has moved up too much (stop gain) or down too much (stop
loss). It is very natural to hypothesize that to each opening trade are associated two thresholds, one above, one below
pi−1, that trigger a closing trade if exceeded. If many agents open both long and short trades at ti−1, one can expect
a quasi-continuous distribution of thresholds at pi−1(1 + ∆), more or less symmetrically distributed around pi−1,
triggering with equal probability sell back or buy back orders. The density P (∆) is, in the simplest case, even (but
see Section V for the inclusion of the leverage eﬀect) and obviously vanishes at ∆ = 0 since nobody opens a trade to
close it immediately (see Fig. 1). The width of P (∆) is given, in order of magnitude, by σ0√τ since this gives the
natural scale beyond which an event might be deemed anomalous. Hence, a relative change of price ri−1 will trigger
on the order of: [60]

Ni(ri−1)

P (∆)d∆

|ri−1|

≈

0
Z

i = σ2
σ2

0 + GNi/τ,

stop trades. These trades of random sign lead, on the next day, to an increase of the volatility as:

where G is the average square impact per trade, and σ2
that P (∆) extends over a range σ0√τ , one ﬁnally obtains a general single time scale ARCH model:

0 is the volatility due to all other trades. Taking into account

)
(cid:21)
depends on the detailed shape of P (∆). Taking for simplicity, in accordance with the above

1 +

(5)

G

(cid:20)

,

i = σ2
σ2
0

ri−1|
( |
σ0√τ

where the function
discussion,

G

P (∆) = P1

∆
|
|
2β2σ2
0τ

exp(

∆2
2β2σ2
0τ

−

),

(u) = 2gβ2

1

exp(

u2/2β2)

,

G

−

−

(where β is a number setting the width of the distribution of thresholds, and P1 the total number of opened trades)
ﬁnally leads to:

where g = GP1/2β2σ2
0τ is the ratio measuring the impact of all stop trades compared to that of all other trades. The
simplest ARCH model Eq. (2) corresponds to the limit u
β, that is, neglects saturation eﬀects related to the fact
≪
that stop limits are not placed arbitrarily far from the entry point (i.e. β is ﬁnite). When this saturation is neglected,

(cid:0)

(cid:1)

(u) is simply given by gu2 (but see below, Fig. 11).

G

3

(3)

(4)

(6)

(7)

4

(8)

(9)

(10)

(11)

(12)

(13)

Although the above feedback mechanism is most probably at play in ﬁnancial markets, a strong limitation of the
above model is to consider that all traders have the same time horizon, equal to τ in the above formulation. However,
it is well documented that the activity of ﬁnancial markets is fueled by traders with diﬀerent time horizons, from a
few hours to a few months or even years (see e.g. [13, 48]). Therefore, stop losses or proﬁt objectives are not placed
only around the last price pi−1 but around possibly all past prices pi−ℓ, ℓ = 1, 2, .... Correspondingly, the width of
the distribution of these thresholds is calibrated to the volatility of the price over the particular trading horizon, i.e.
σ0√ℓτ . The generalization of Eq. (5) to this situation therefore reads:

Expanding
(the inclusion of asymmetry will be discussed in Section V): [61]

Gℓ for small arguments ﬁnally leads to the symmetric version of the model studied in the present paper

∞

Xℓ=1

∞

Xℓ=1

"

"

σ2
i = σ2
0

1 +

Gℓ( |

xi−ℓ|

xi −
σ0√ℓτ

.

)
#

σ2
i = σ2
0

1 +

gℓ

xi−ℓ)2
(xi −
σ2
0ℓτ

,

#

ri = xi+1 −

xi = σiξi√τ .

gℓ = g/ℓα,

i = σ2
σ2

0 +

Xj<i,k<i

(i; j, k)

M

rjrk
τ

,

(i; j, k) =

M

∞

gℓ
ℓ

,

Xℓ=max(i−j,i−k)

with

The coupling constant gℓ is proportional to the number of trades Pℓ with horizon ℓ. Because traders with a longer
horizon have slower trading frequencies and under-react compared to short term traders, it is reasonable to imagine
that gℓ is a decaying function of ℓ. Both for simplicity and because it allows us to reproduce several stylized empirical
facts, we will choose gℓ to be an inverse power:

but other choices are possible. For example, Zumbach and Lynch have presented evidence that gℓ has additional
peaks on the day, week and month times scales. These authors have proposed a model very close in spirit to Eq. (9),
and discussed some of its properties. In fact, Eq. (9) is a special case in the family of quadratic ARCH models, where
the volatility is expressed as a general quadratic form of past returns:

which contains ARCH, GARCH, etc. Our speciﬁcation insists that only combinations of returns ‘reconstructing’
actual price changes over diﬀerent time scales occur in the above sum, because they correspond to quantities directly
observable to the crowd of traders, which, we argue, strongly inﬂuence the trading at time i. Our model corresponds
to a particular choice for

above:

M

−

whereas most ARCH models correspond a certain regression on past instantaneous square returns, i.e., to
K(i

(i; j, k) =
j)δjk, with a certain kernel function K, usually corresponding to an exponential moving average, K(ℓ) = αℓ.
With a power-law speciﬁcation for gℓ, and the choice of a Gaussian distribution for the noise term ξ in the deﬁnition
of returns, our model is fully determined by only four parameters: σ0 sets the volatility scale, τ sets the shortest
time scale over which feedback eﬀects are eﬀective, g measures the strength of these feedback eﬀects and α describes
the relative importance of short term traders and long time traders in the feedback process. It may however be that
the assumption of a Gaussian noise for ξ is insuﬃcient to account for the high frequency statistics of the returns.
In particular, one expects that true ‘jumps’ related to unexpected news are not described in terms of a volatility
feedback process.
In the
following sections, we will present several analytical and numerical results of the Gaussian version of this model,
and compare them to empirically known results. But before doing so, let us give the continuous time formulation
of the same model, which can be convenient for some applications, such as option pricing. Introducing the standard
Brownian noise dWt, one may write:

It is easy to extend the model in that direction and choose another distribution for ξ.

M

dxt = σtdWt,

(14)

with:

This model is well deﬁned as soon as α > 1, which is the case we will focus on in the sequel.

t = σ2
σ2

0 + gτ α

t

−∞

Z

dt′

(t

xt′ )2
t′ + τ )1+α .

(xt −
−

III. ANALYTICAL RESULTS

A. Unconditional distribution of the volatility

Although our model (Eq. (9)) expresses the volatility as a deterministic function of the past prices and the only
source of randomness comes from the noise ξi in Eq. (1), the volatility eﬀectively appears as a random variable, and
one can ask questions about its distribution, correlations, etc. The simplest question concerns the average value of
the volatility, which also coincides, for a stationary process, with the long term volatility of the price. Averaging will
always be denoted below with brackets
around the quantity which is averaged. For the average volatility, one
has (assuming stationarity) :

. . .
i
h

σ2
h

i

=

σ2
i i
h

= σ2

0 +

gℓ h

xi−ℓ)2
(xi −
ℓτ

i

= σ2

0 + [

σ2
gℓ]
h

.
i

∞

Xℓ=1

∞

Xℓ=1

This equation has a well behaved solution only if:

∞

z2 =

gℓ < 1,

Xℓ=1
where the above equation deﬁnes z2, the subscript ‘2’ refers to the fact that we study here the second moment of the
0. In
volatility. When z2 < 1, the square volatility is ampliﬁed by a factor 1/(1
1, on the other hand, the process becomes non stationary and the volatility grows without bound as
the case z2 ≥
time elapses. It is clear that the condition z2 < 1 can only be met if the sum of gℓ converges, which imposes that
the exponent α is larger than one. For α > 1, one ﬁnds z2 = gζ(α), which delimits a region in the plane g, α where
the process is stationary. In the following, we will often assume that α is larger than unity but close to it (which
is suggested by empirical data), and use in this limit a continuous approximation for discrete sums. In particular,
ζ(α)
0.9, meaning that the
square volatility is increased by a factor
0. Therefore feedback eﬀects might
be an important cause of the excess volatility in ﬁnancial markets [50, 51].

1). We will ﬁnd below that empirical data on stocks favors values of z2 ≈

z2) compared to the initial value σ2

10 compared to its initial value σ2

1/(α

0.85

−

−

−

≈

∼

−

6

In order to compute higher moments of the volatility, one needs in general to know the full temporal correlation of
the volatility, that we will establish in the next paragraph. Simpliﬁed, approximate calculations can be performed in
two extreme cases: (i) no temporal correlations (ii) full temporal correlations. This leads to an equation for
of
=rhs, where the right hand side is ﬁnite whenever α > 1, and can be computed if necessary
the form (1
i
k), which behaves,
(see below). The important discussion concerns the value of z4. We will denote Mk =
for large k, as k−α/(α
1). Using the results established below (see Eq. (26)), one can obtain a lower bound z4,<
and an upper bound z4,> on the value of z4. If correlations are neglected, one ﬁnds:

σ4
z4)
h

σ4
h

M

(0;

k,

−

−

−

−

i

z4 ≥

z4,< = 3g2

M 2
k .

∞

Xk=1

If on the other hand, if correlations are overestimated and taken to be constant in time, one ﬁnds an upper bound for
z4 that reads:

z4,> = g2

z4 ≤

∞

[
Xk=1

 

∞

∞

Mk]2 + 2

M 2

k + 4

Xk=1

Xk=1

1)M 2
k

(k

−

.

!

As long as z4 < 1, the fourth moment of σ is ﬁnite, but if z4 reaches unity, it does diverge, leading to an inﬁnite
kurtosis for the returns. For α = 1.15, we ﬁnd z4,< = 0.16 z2
2. This shows that the kurtosis κ is
certainly ﬁnite for z2 < 0.833; numerical simulations below suggest that κ indeed remains ﬁnite beyond that value.

2 and z4,> = 1.44 z2

5

(15)

(16)

(17)

(18)

(19)

6

(20)

(21)

(22)

(23)

(24)

The above argument is easily generalized to higher even moments of σ, leading to an equation (1

σ2n
z2n)
h

i

−

=rhs

with:

z2n,< = (2n

1)!! gn

M n
k ,

−

∞

Xk=1

(2gn/e)n, showing that however small
and a more cumbersome expression for z2n,>. For large n, one ﬁnds z2n,< ∼
the value of g, suﬃciently high moments of the volatility are divergent. Since ri = σiξi, the even moments of the
returns are given by:

−
therefore high moments of returns themselves diverge, suggesting that both the unconditional distribution of volatility
and returns have a power-law tail (possibly multiplied by a slow function), with an exponent equal to the order of the
last ﬁnite moment. We will conﬁrm this prediction numerically in the following section. Remember however that the
above discussion is only valid when the noise ξ is Gaussian; if ξ itself has a non zero kurtosis, then its contribution
should be taken into account.

i

r2n
h

= (2n

σ2n
1)!!
h

;
i

B. Temporal correlations of the volatility

A well known stylized fact is that the volatility is a ‘long-memory’ process, which means that the temporal correla-
tions of the square volatility decay as an inverse power of the time lag, ℓ−ν, with an exponent ν less than unity. This
property turns out to be extremely important because it is at the root of the very slow convergence of the distribution
of aggregated returns towards the Gaussian. More precisely, the kurtosis of the return xi −
xi−ℓ over scale ℓ, itself
decays as ℓ−ν instead of ℓ−1, which is the case when the volatility process has a short memory. Since the empirical
value of ν is, for stocks, on the order of ν = 0.2
0.3, the slowing down is substantial and essential to explain why
long dated options still have a smile.

−

We therefore turn to the calculation of the correlation function of the volatility, deﬁned as:

(ℓ) = h

F

i+ℓσ2
σ2
i i
2 −
σ2
i
h

1.

In the limit g2

1, one can quite easily perform a perturbative analysis that neglects terms of order g4, to get:

≪

(ℓ) = 2g2

F





X0<k<j

k1−α
(ℓ + j)1+α +

j2
k1+α(ℓ + j)1+α 

.

X0<j≤k



1 ﬁnally gives, for α > 1 but close enough to unity such that one can use continuous

An analysis of this result for ℓ
≫
integrals instead of discrete sums:

(ℓ)

F

∼

4g2Γ(2

α)Γ(2α

1)

−
α2Γ(α)

−

ℓ2−2α

≡ F∞ℓ−ν,

−

2. The volatility is a long memory process whenever ν

3/2.
leading to a kurtosis exponent ν = 2α
Comparison with empirical data, done below, suggests that α is in the range 1.1
(ℓ),
not restricted to small g2, can also be written down, although it is more cumbersome. For this calculation, one should
note that averages such as
j ic (where the subscript c denotes a connected average) are non trivial, since the
volatility randomness comes entirely from past returns themselves. This contrasts with many stochastic volatility
models where the volatility σi and the noise ξj are often chosen to be independent (unless one wants to model the
leverage eﬀect). In the present case, one ﬁnds, for j < i:
j ic = g2
i ξ2
σ2
h

1, i.e. 1 < α
≤
1.2. The exact equation for

σi−kσi−k′ ξi−kξi−k′ ξ2
k′)
h

j ic = 2g2

Mi−j,
i

i ξ2
σ2
h

≤
F

σ2
h

(25)

M

(0;

k,

−

−

−

Xk,k′>0
Now, the full self-consistent equation for

∞

Xk=1

reads:

F

∞

Xk>k′=1

(ℓ) = g2[3

(0) + 2]

MkMk+ℓ + 4g2

MkMk+ℓ[1 +

(k

k′) + 2g2Mk−k′ ]

F

+ 2g2

MkMk′+ℓ[

(k

k′) + 2g2Mk−k′ ] + g2

F

−

MkMk′ [

(ℓ

F

−

k′ + k) + 2g2Mℓ−k′+k]

(26)

F

−

∞

ℓ

Xk=1

Xk′=1

F

∞

Xk>k′=1

7

(27)

(28)

(29)

Specializing to ℓ = 0 leads to the fourth moment of the volatility studied in the above section. The two assumptions
made there to obtain a lower and an upper bound correspond to
(0), respectively.
For large ℓ, an asymptotic estimate of the various terms leads to the same decay as that predicted by the above
z2
∼ F∞ℓ−ν, with ν = 2α
perturbative calculation, i.e.,
2).
However, sub-dominant terms also appear, proportional to ℓ−2ν, ℓ−α, etc. The ﬁnite ℓ behaviour of
(ℓ) would require
to solve the above equation numerically.

F∞ increased by a factor 1/(1

2, and a prefactor

(0)δℓ,0 and

(ℓ) =

(ℓ) =

(ℓ)

−

−

F

F

F

F

F

F

From the knowledge of

one should take care of the terms involving
eﬀect. One ﬁnds, for the kurtosis of the returns on lag ℓ:

F

(ℓ) one can obtain the ℓ dependence of the kurtosis of the returns, following [11]. Again,
j ic, which, as we discuss below, lead to a new, perhaps unexpected

i ξ2
σ2
h

κ(ℓ) =

κ(1) + 6

1
ℓ 

(1

−

j
ℓ

)[

F

ℓ

j=1
X

(j) + 2g2Mj]

.






1, one ﬁnds, using Eq. (24), and for α close to 1:

For large lags ℓ

≫

κ(ℓ)

3
F∞
2α)(2

ℓ−ν.

α)

−

∼

(3

−

Therefore, one expects the returns to converge to Gaussian, but only on a very long time scale. Any measure of the
distance from a Gaussian – such as the mean absolute moment studied below – will tend to zero very slowly, as ℓ−ν,
see Figs 4-a, 4-b. If one now studies Eq. (27) for small values of ℓ, say ℓ = 2, one ﬁnds:

κ(2)

κ(1) = 3[

(1)

(0) + 2g2M1]

−

− F

F
(1)

In many models, the last term is absent, and since
(0), one usually ﬁnds that the kurtosis of aggregated
returns is less than the kurtosis of elementary returns. However, the third term in the above expression suggests
that one can observe, in some cases, a kurtosis that ﬁrst increases with lag before decaying to zero. We will see that
this is indeed the case in the numerical simulations of our model, although this eﬀect is, again, very sensitive to the
assumption that ξi is a purely Gaussian noise.

≤ F

F

C. Conclusion

The summary of this technical section is that the two major stylized facts (fat tails and volatility long-memory)
are present in our model. We have indeed shown that the distribution of returns and of the volatility have power-
law like tails, since high moments of these distributions diverge. We have also shown that the temporal correlation
of the volatility is decaying as a slow power law. The following sections will be to establish these properties more
quantitatively using numerical simulations, and to show that many more stylized facts can be reproduced by the
model. Finally, we will turn to the question of calibration and discuss how the model parameters can be chosen to ﬁt
empirical data.

IV. NUMERICAL RESULTS

≈

−

0.4 for many diﬀerent assets. For example, averaging over the 500 largest stocks of the NYSE leads to ν

We have established above that the volatility-volatility correlation function, and the kurtosis, decay at long times
as ℓ−ν with ν = 2(α
1). A large amount of empirical work on ﬁnancial time series suggest that ν is in the range
0.25,
0.2
−
while ν
0.3 for the S&P 500 Index [11]. We therefore choose to ﬁx α = 1.15 (corresponding to ν = 0.30) in most
of the numerical experiments that we have conducted. Other values of α are brieﬂy discussed, in particular in the
context of the model calibration. The choice α = 1.15, although guided by empirical data, immediately leads to a
numerical problem due to its proximity with the critical value α = 1 which separates a (theoretically) stationary
regime for α > 1 from a non stationary regime for α
1. The convergence of (say) the average volatility to its
asymptotic value is expected to occur at speed T 1−α, where T is the total length of the time series. For α = 1.15,
this is extremely slow: even for T = 106τ , one expects corrections of order 10% to the theoretical asymptotic results.
For this reason, and also to speed up the numerical calculation of the sum that determines the volatility (Eq. 9), we
have truncated the power-law memory kernel gℓ beyond ℓ = 5. 104. The total length of our simulations is usually 106
steps, but we discard the ﬁrst 15. 104 points of the series before we start measuring any observable. Although this is,
again, insuﬃcient to obtain very precise results for such low values of α, we believe that these numerical experiments

≤

≈

8

1500

1000

500

2

σ

 

0
2e+05

2.5e+05

3e+05
 time

3.5e+05

4e+05

FIG. 2: A typical time series (of length 2 105) of the volatility σ2, for z2 = 0.85 and α = 1.15. We have in fact shown a 300 τ
moving average of σ2

i , aimed at representing the ‘daily’ volatility within our model.

∼

are suﬃcient to obtain a good estimate of a host of diﬀerent interesting observables, in any case comparable in quality
to the corresponding estimates on real price time series. As will be clear below, we estimate that one day corresponds
300; therefore 106 time steps corresponds to 3000 trading days, or twelve years of data. In the
in our model to ℓ
following, the base volatility σ0 is set to σ0 = 1, any other value would only change the following results by a trivial
multiplicative factor on the returns. We will vary the coupling constant g, which we will in fact express in terms of
ℓ gℓ, since we know from the above discussion in section III that it is really z2 that measures the strength of
z2 =
1, we know from section III that the volatility will blow up and
feedback eﬀects on the volatility. In the limit z2 →
the process becomes non-stationary for all values of α. Therefore, studying numerically values of z2 too close to unity
z2)T ]1−α!), but, ironically, corresponds to the empirical
will also be diﬃcult (the convergence is now as slow as [(1
[0.60, 0.85] – smaller values of z2 lead to
situation. In the following, we restrict our simulations to the range z2 ∈
a process which is only weakly non Gaussian, whereas larger values of z2 give rise to a numerically very unstable
process, even though in theory the process should still be stationary on extremely long time scales. We will see below
that values of z2 as high as 0.9 might be needed to ﬁt the data, but we have not attempted to simulate the model for
such a large value.

P

−

Although the issue of calibration will be more deeply discussed in section VI, we will compare in this section our
numerical results to empirical data, averaged over a set of 252 US stocks, chosen among the most liquid ones, during
a four year time period: 2000-2003.

A. Volatility distribution and volatility correlations

1. Volatility distribution

We ﬁrst focus on the properties of the ‘true’ volatility σi, which we can of course measure numerically but is
unobservable directly in practice: only proxies of the volatility, obtained by averaging over several time steps, can be
studied. A typical time series of σ2 is shown in Fig. 2, and reveals apparent shocks and volatility clustering familiar
in ﬁnancial time series. We show in Fig. 3 the histogram of u = ln σ for diﬀerent values of z2. Obviously, since
0. We have found that the pdf P (u) of
σ > σ0 = 1, the probability distribution function (pdf) of u is zero when u
u can be very accurately ﬁtted by the following form (see Fig. 3):

≤

P (u) = Z exp

µu

Θ(u),

(

u0
u

)β

−

−
h

i

(30)

where Θ(u > 0) = 1 and Θ(u < 0) = 0. We have no detailed justiﬁcation for this speciﬁc functional form for
u
0. On the other hand, it is easy to show that the exponential tail for large positive u translates into a power-law
distribution for σ itself, decaying as σ−1−µ, which is indeed expected from our theoretical analysis. Correspondingly,

→

9

12

10

8

6

4

2

)
u
(
P
n
l
 

 

0

0

 Slope −3.5
 Log σ, z2=0.85
 Fit β
 Log σ
e
 Fit Student

1

2

 u=ln σ

3

FIG. 3: Histogram of u = ln σ for z2 = 0.85 and α = 1.15, and two ﬁts, using Eq. (30) – “Fit β” – and Eq. (31) – “Fit
3.5 for comparison with the tail of the distribution of u. The pluses correspond to the
Student”. We also show the slope µ =
histogram of the average volatility over 100 time steps, close to what one would determine empirically from price time series.

−

z2
0.60
0.65
0.70
0.75
0.80
0.85

(1

z2)−1

−
2.50
2.85
3.33
4.0
5.0
6.66

σ2
h
i
2.50
2.85
3.31
3.92
4.79
6.05

(0)
F
0.54
0.79
1.16
1.73
2.59
3.95

µ
5.70
5.27
5.02
4.72
4.42
4.03

β
0.75
0.70
0.60
0.54
0.51
0.50

u0
0.51
0.74
1.65
3.26
5.67
6.83

λ2 (ln)
0.45
0.57
0.69
0.85
1.03
1.24

λ2 (ζq)
1.8
2.45
3.1
3.7
4.2
5.5

TABLE I: Value of diﬀerent observables and ﬁt parameters for diﬀerent values of z2, at ﬁxed memory kernel (α = 1.15, or
ν = 0.3). The values of λ2 must be multiplied by 10−2. Note the 10% discrepancy between the theoretical and empirical value
when z2 reaches 0.85. The value of µ suggests that the kurtosis κ remains ﬁnite at least up to z2 = 0.85, in agreement
of
with our theoretical analysis; the numerical value of κ = 3
12 for z2 = 0.85. From this table, one can
extrapolate µ to be

3.6 and λ2 (ln) to be

0.015 for z2 = 0.9.

(0) is found to be

σ2

≈

F

h

i

≈

≈

the distribution of returns will also display the same power-law tail. The values of µ that we ﬁnd using the above ﬁt
are summarized in Table I. From Fig. 3, however, we see that the apparent slope of ln P (u) vs. u in the available
range of ‘large’ u values is slightly smaller than the value of µ obtained from a global ﬁt with Eq. (30). For example,
3
for z2 = 0.85, we ﬁnd µ
[4]. A slightly larger value of z2 = 0.9 would be in even better agreement with this empirical value of the exponent
(see Table I).

3.5, interestingly closer to the value reported for stocks µ

4, but the apparent slope is

≈

≈

≈

We have also tried to ﬁt P (u) assuming an inverse Gamma distribution for the pdf of σ [11, 52], which corresponds

to a Student distribution for the returns. In terms of u = ln σ, this reads:

P (u) = Z ′ exp

Ae−Bu

µu

,

(31)

−
(cid:2)
where A and B are parameters, and µ is the power-law tail of the return distribution. Of course, this distribution
cannot be exact in the present case since it takes non zero values when u < 0. Although it is deﬁnitely not as good a
ﬁt as Eq. (30), it is quite acceptable, meaning that returns are indeed close to being Student distributed in our model.
On the other hand, a log-normal distribution for σ is clearly inadequate to describe our data (it would correspond to
a parabola in Fig. 3.)

−

(cid:3)

From Table I, we see that (a) the numerical value of the average volatility is close to its theoretical value up to
0.75, beyond which a systematic underestimation of the true volatility σ2 is observed, which reaches 10% for
z2 ≈
z2 = 0.85; (b) the kurtosis κ = 3
(0) increases with z2, as expected, and seems to remain ﬁnite at least up to
z2 = 0.85, beyond which µ appears to drop below 4, signaling a divergence of κ (and correspondingly an even more
diﬃcult determination of the statistical properties of the system).

F

10

 σ2, α=1.15
 σ2, α=1.3
 US Stocks

1000

m
a
r
g
o
i
r
a
v
 

2

σ

100

1

0.4

0.3

0.2

0.1

m
a
r
g
o
i
r
a
v
 
g
o
L

 

0

0

10

100

1000

10000

100000

5

10

15

 l

 Log  l

 US Stocks
 ln σ

FIG. 4: Left: variogram of the square volatility for z2 = 0.85, α = 1.15 and α = 1.3 and ﬁt with power-laws with ν = 2(α
1).
We also show the data for US stocks with one day corresponding to 300τ for α = 1.15 and 80τ for α = 1.3, for which the
agreement is clearly not as good. Right: variogram of the log-volatility for z2 = 0.85, α = 1.15, and ﬁt with an aﬃne function
of ln ℓ, the slope of which yielding (twice) the intermittency parameter λ2, here found to be
0.0125, whereas the US data
suggests a larger value λ2
0.0165 – which would be matched by choosing z2 = 0.90, for which we estimate from Table I
λ2

0.015.

−

≈

≈

≈

2. Volatility correlations

We now turn to the temporal correlations of the volatility. Several characterizations of the “long-memory” property
are interesting to consider. Well studied quantities are correlations of diﬀerent powers of the volatility, or of the
logarithm of the volatility. In our model, we of course know exactly the volatility at any instant of time, whereas, as
pointed out above, in real conditions one only has access to price changes, from which a (noisy) proxy of the volatility
is constructed. We ﬁnd numerically that the shape of the correlation function can be noticeably diﬀerent for these
two quantities when the noise is large; this observation may be especially important for calibration.

From Table I, one sees that the average volatility is rather ill-determined in the cases most relevant for applications,
i.e. z2 and α both close to unity, variograms should be preferred to correlograms [11]. In other words, we will study
the following quantity:

1
n2 h
(cid:0)
These variograms are plotted in Figs. 4 a,b for the case n = 2 and n
0. This last case reproduces, thanks to
the 1/n2 normalization, the variogram of the logarithm of the volatility which has been much studied in the context
of multifractal models (see below). The case n = 2 is important because it can be analytically studied, as we did
in Section III, and because it is related to the kurtosis of the distribution of returns for diﬀerent time lags, which
determines the smile of option prices. Form Eq. (26), one ﬁnds that for large ℓ, one should observe:

σn
i −

Vn(ℓ) =

σn
i+ℓ

(32)

.
i

→

(cid:1)

2

2

2

∼

V2(ℓ)

F0 −

F∞ℓ−ν
When α is close to 1, ν is small and one should a priori be prepared to see corrections to the asymptotic result coming
from the ℓ−2ν contribution. Fig. 4-a however shows that, for z2 = 0.85 and ν = 0.3 our numerical result is rather well
ﬁtted by the dominant term of Eq. (33). The value of the apparent exponent ν however increases when z2 decreases
(in which case the contribution of the subleading term becomes more important). We also show the US stock data
0.25 [11]), which can be matched quite well with the model. In order to test the sensitivity
(that corresponds to ν
of V2(ℓ) to the value of α, we also show in Fig. 4-a the case α = 1.3, corresponding to ν = 0.6. The agreement with
empirical data is clearly not as good, a conclusion conﬁrmed by all other observables we studied.

∞ℓ−2ν + ...
′

(33)

−

≈

F

2

Another interesting quantity, less noisy than the square volatility, corresponds to n

0. As discussed below, this
log-variogram appears naturally in the context of multifractal models. The result for n = 0 is shown in Fig. 4-b; we
see that it can be ﬁtted approximately by the multifractal prediction [30]:

→

V0(ℓ)

2λ2 ln

∼

ℓ
L

,

(ℓ

L)

≪

(34)

11

 z2=0.70, 0.75, 0.80, 0.85
 Data (US Stocks)

ψ

κ

 Data (US Stocks)
 Gaussian limit
 z2=0.7, 0.75, 0.8, 0.85

0.8

0.75

0.7

0.65

1

15

10

5

0

1

10

100

1000

10000

1e+05

10

100

1000

10000

100000

 l

 l

FIG. 5: Evolution of two cumulants of the distribution of returns with the lag ℓ, for diﬀerent values of z2. Left: rescaled mean
absolute deviation Υ(ℓ). Note that the evolution is non-monotonous as a function of ℓ. Right: Excess kurtosis κ(ℓ). We have
also shown (symbols) the corresponding cumulants for US stocks, where we choose ℓ = 300 to correspond to one trading day,
as in Fig. 4.

where λ2 is called the intermittency parameter, and T = Lτ is usually called the integral time. The value of λ2 for
diﬀerent values of z2 is given in Table I, together with another determination of λ2 discussed below. For z2 = 0.85,
α = 1.15, we ﬁnd λ2
0.018 for the S&P100 Index, given
in [53]. This suggests that the optimal value of z2 might in fact be closer to 0.9, for which we estimate from Table I
λ2

0.015. This conclusion is reinforced by the analysis of section VI.

0.0125, whereas our US data gives λ2

0.0165, or λ2

≈

≈

≈

≈

B. Distribution of returns over diﬀerent time scales

Since the noise variable ξ is Gaussian, one can obtain the distribution of returns on the elementary time scale ℓ = 1
from the distribution of the instantaneous volatility σ. For example, an inverse Gamma distribution for σ leads to a
Student-Tsallis distribution for r. As discussed above, the actual distribution of volatility in our model appears to be
slightly diﬀerent from an inverse Gamma distribution; therefore the distribution of returns in our model will be close
to, but diﬀerent from, a Student distribution. On larger time scales, the distribution progressively becomes Gaussian.
However, the convergence is very slow precisely because of the long-memory of the volatility, parameterized by the
exponent ν. A way to quantify this convergence is to measure the cumulants of the distribution, for example the
excess kurtosis κ(ℓ), expected from our theoretical analysis to decay as ℓ−ν, or the rescaled mean absolute deviation
Υ(ℓ), deﬁned as:

Υ(ℓ) =

xi+ℓ −

1
σ2
h
p
2/π. These quantities are plotted as a function of ℓ in Figs. 5-a,b,
For a Gaussian distribution, one should ﬁnd Υ =
for diﬀerent values of z2 and for ν = 0.3. An a priori unexpected feature is that non-Gaussian eﬀects actually ﬁrst
increase for small ℓ, before decaying back to zero beyond a certain ℓ = ℓ∗
50. The origin of this non monotonicity
was discussed in section III and is clearly related to the assumption that the noise ξi is Gaussian. Any extra kurtosis
coming from unpredictable jumps in the price, not captured by the feedback mechanism of our model, will strongly
aﬀect the shape of Υ(ℓ) and κ(ℓ) on short time scales, and remove this non-monotonicity which, to the best of our
knowledge, is not observed on empirical data, even on very short time scales. Another possibility is to change the
shape of gℓ for small ℓ’s.

.
xi|i

ℓ h|
i

(35)

p

≈

Of course, the knowledge of κ and Υ is insuﬃcient to fully characterize the whole distribution on diﬀerent time
scales. We have in fact found that a Student-Tsallis distribution with a time dependent number of degrees of freedom
is an acceptable ﬁt of this distribution for all values of ℓ. In line the notation of ref. [41], we write this distribution
as:

∆(3−q)/(q−1)

Pℓ(∆) =

N

(∆2

0
0 + (q

−

1)∆2)1/(q−1) ,

∆ = xi+ℓ −

xi

(36)

with an ℓ dependent parameter q(ℓ). In the limit q
indeed given by Eq. (36), the relation between Υ and q reads:

→

1, the distribution becomes Gaussian. If the distribution is

Υ =

2(µ
π(µ

−
−

s

2)
1)2

Γ( 1+µ
2 )
Γ( µ
2 )

,

κ =

6

−

µ

,

4

(3

q)/(q

1). Using these relations, one can infer, from Fig. 5-a, the value of q that one should use for
with µ
diﬀerent times scales in order to get an approximate functional form for the distribution of returns. This is useful for
option pricing, for example [41].

≡

−

−

C. Multifractality

A property related to the systematic change of the distribution of returns with ℓ is multifractality, which means
that diﬀerent moments of price changes scale as a power of time, but with diﬀerent scaling exponents. More precisely,
multifractal scaling is the following property:

Mn(ℓ) =

xi+ℓ −
h|

xi|

n

= Anℓζn;

ℓ

L

i
where An are constants and ζn is an n-dependent exponent. In the monofractal case, where the distribution is the same
on all time scales up to a rescaling of the returns, then ζn = n/2 ζ2. The simplest example is obviously the (geometric)
Brownian motion, for which ζn = n/2. Any deviation from a linear behaviour of ζn is coined multifractality, for which
several explicit models were proposed recently [26, 27, 28, 29, 30, 31].

One example is the Bacry-Muzy-Delour (bmd) stochastic volatility model, which makes the following assumptions

≪

(38)

[30, 31]:

•

•

•

the log-volatilities ln σi are multivariate Gaussian variables (or more generally inﬁnitely divisible [31]).

the log-volatility variogram is given by Eq. (34)

the volatilities σi are independent from the (Gaussian) noises ξi.

From these assumptions, one can compute exactly the moments of the return distribution on diﬀerent time scales.

One ﬁnds that these are indeed given by Eq. (38), with:

ζn =

[1

n
2

λ2(n

2)],

−

−

whenever n < 1/λ2, beyond which the moments are inﬁnite. (All An’s can also be exactly computed [30]). These
assumptions and predictions were found to account rather well for some aspects of empirical data.

In the present section, we show that although our model is, strictly speaking, not multifractal, many of the mul-
tifractal predictions actually hold numerically quite accurately. This means that our model can account very well
for apparent multifractal properties of ﬁnancial time series, and in fact cures some of the deﬁciencies of standard
multifractal models (see below). First, we note that our model is not multifractal since the moments Mn(ℓ) can
be exactly computed to be sums of power-laws with diﬀerent exponents, and not a unique power-law (see [25] for a
related discussion). For example, M4(ℓ) is the sum of ℓ2, ℓ2−ν, ℓ2−2ν, etc., and therefore does not scale as a unique
power-law. However, as we show now, the numerical behaviour appears diﬃcult to distinguish from a unique, eﬀective
power-law. [62]

We have computed numerically Mn(ℓ) for ℓ > ℓ∗, where ℓ∗ corresponds to the maximum of κ(ℓ) or the minimum of
j ic, and Mn(ℓ)

Υ(ℓ) appearing in Figs. 5-a,b. In this regime, one can neglect the contribution of terms involving
can be expressed as:

i ξ2
σ2
h

Mn(ℓ)

(n

≈

−

1
2

)!!

ℓ

n/2

σ2
i

!

,
i

h 

i=1
X

which is the quantity that we studied numerically, because it is much less noisy than the direct calculation of moments
of returns. The results are shown in Fig. 6-a in a log-log representation, for z2 = 0.85 and α = 1.15, from which it
is obvious that pure power-laws are indeed excellent ﬁts. From the slope of these lines one obtains the exponents ζn,
shown for diﬀerent values of z2 in Fig 6-b. We note that:

12

(37)

(39)

(40)

13

ζ
n
Fit

0

2

 n

4

6

8

3

2

1

0

70

60

50

40

30

20

10

n

 

M
n
l
 

3

2

1

n

ζ

0

3

5

9

11

0

0

1

2

4

5

6

7
 ln l

 Data (US Stocks)
 z2= 0.6, 0.65, ..., 0.85

3
 n

FIG. 6: Left: Evolution of diﬀerent moments Mn(ℓ) of our model with ℓ in a log-log representation, which allows one to extract
from the slope of these lines, the exponents ζn shown in the inset. Also shown in the inset is the parabolic ﬁt suggested by the
bmd model, Eq. (39). Right: The exponents ζn as a function of n for diﬀerent values of the feedback parameter z2, and the
corresponding results of US stocks (triangles).

•

•

•

A parabolic ﬁt of ζn as a function of n, as in Eq. (39), gives an excellent representation of our data (see Fig
6-a, inset).

From this parabolic ﬁt, a value of λ2 can be extracted for diﬀerent values of z2. This value of λ2 is four times
larger than that extracted from the variogram of the log-volatility, in contradiction with the bmd model, where
both should be equal (see Table I). However, we note that a similar discrepancy with the bmd model is observed
on US stock data as well, but that both observables are fully compatible with our model with the same set of
parameters. The discrepancy with the log-normal bmd model is due to the underestimation of the probability
of large events in that model.

The intermittency parameter λ2, that gauges the degree of multifractality (i.e.
the deviation of ζn from a
straight line), increases as z2 increases. The multifractal spectrum extracted from US stock data corresponds to
λ2
0.055 and matches quite well our numerical points for z2 = 0.85. Similar values of λ2 have been reported
for other markets as well (see e.g. [24, 30]).

≈

The bmd multifractal model makes other, even more detailed predictions, about the relaxation of volatility after a

volatility shock. We now turn to this topic to show that our model can also reproduce these more subtle features.

D. Response to volatility shocks

A question of great importance for option pricing and risk management concerns ‘aftershocks’. It is well known
that after a large market move, the volatility remains high for a while. The precise question therefore is: conditioned
to a large volatility burst, how fast will the market revert back to normal? This has been addressed both empirically
and theoretically, within the context of the bmd model [53]. One ﬁnds that after a shock, the volatility reverts to its
normal level very slowly, as a power-law of the time ℓ after the shock:

∆σi+ℓ ∼

∆0ℓ−θ,

(41)

where i is the time of the initial shock, ∆σ the excess volatility over its average value, and ∆0 the amplitude of the
initial shock. For rather large shocks, the empirical data suggests θ
1/2 [53, 54], while θ decreases for smaller
shocks. Interestingly, the multifractal bmd model suggests that the exponent θ in fact depends continuously on the
amplitude of the initial shock, and decreases from the value 1/2 as the amplitude of the shock decreases [53]. This
prediction was found to be in remarkable agreement with empirical ﬁndings, giving strong support to the bmd picture.
We have therefore computed the volatility relaxation process within our model, following the methodology of [53].
We compute the average volatility a time ℓ after the shock, conditioned to a shock of a certain amplitude. The
relaxation curves are shown in Fig 7, again in the case z2 = 0.85, α = 1.15. We observe that the predictions of the
bmd model are again quite accurately veriﬁed by our model, which, by the same token, is an alternative candidate to
explain empirical results.

≈

14

−2

−3

)

s
2

e

2

0

σ

|

2

σ
(
n
l
 

s=+1

s=+0.5

−4

s=0

s=−0.5

−5

2

3

4
 ln l

5

6

FIG. 7: Evolution of σ2 conditioned to an initial volatility
lines are power-law ﬁts, with exponents θ(s =
quoted in [53] for the S&P100.

1/2)

≈

−

σ2

e2s, with s =

i
0.22, θ(s = 1/2)

h

1/2, 0, 1/2, 1 (from bottom to top). The dashed
0.30, very similar to the results

0.17 and θ(s = 1)

−

≈

≈

Another characterization of aftershocks inspired from research on earthquakes is the so-called Omori law, which
states that the probability of an aftershock larger than a certain threshold occurring a time ℓ after the main shock
decays as 1/ℓp, with p
1. This law was checked for stock markets in [55] on a handful of ‘signiﬁcant’ crashes. In
our model, crashes are self-generated and not related to external news, obviously absent from the model. We show
in Fig. 8 the numerically determined Omori law after large endogenous crashes, for which we obtain a signiﬁcantly
diﬀerent value of p
0.5, compatible with the value of θ reported above for large crashes. On the other hand, it is
easy to compute the volatility response to an exogenous crash, represented by a large instantaneous jump added ‘by
hand’ in the time series. If the amplitude of the jump at time i = 0 is J, the volatility after the crash is given by:

≈

≈

σ2
ℓ iJ ≈ h
h

σ2

i

+ gJ 2Mℓ.

(42)

ℓ−α, we ﬁnd that the probability of an aftershock larger than a given threshold also decays as ℓ−α for
Using Mℓ ∼
large enough ℓ. Since the value of α is close to unity, an approximate Omori law with p
1 will be observed after
anomalously large, exogenous crashes in our model. The distinction between endogenous and exogenous crashes,
suggested in [53], makes perfect sense in the context of the present model, where endogenous crashes are, in a precise
sense, the result of progressive volatility built up, resulting from the ARCH like feedback eﬀect. This volatility built
up is in fact related to the non monotonous behaviour of the kurtosis in our model.

≈

E. Time reversal symmetry

A question of general interest is whether ﬁnancial time series ‘know’ about the arrow of time, i.e. whether it
is possible to compute any observable that distinguishes past from future (see [56]). Although the answer of this
question would appear, to the layman, to be trivially yes, things turn out to be much more subtle, and of considerable
importance. For example, the usual Brownian motion, all L´evy processes and all multifractal models constructed up
to now (including Mandelbrot’s cascade, the bmd model or the version studied by Lux in [29]) are strictly invariant
under time reversal symmetry (trs)! Financial data, on the other hand, do reveal non trs eﬀects. A simple example,
on which we will expand in the next section V, is the leverage eﬀect, which is a causal correlation between past price
changes and future volatilities: a drop in price leads to an increased volatility. This eﬀect in turn leads to some
(negative) skewness in the distribution of returns (see below).

Here, we want to discuss a distinct eﬀect, recently evidenced by Zumbach and Lynch [13]. In order not to mix
this eﬀect with leverage, one can study FX rates between two large currencies, for example Euro vs. Dollar. In this
case, any leverage correlation or skewness, if present, is very small. In spite of this, there is a clear time asymmetry
in the volatility process: as shown in [13], the correlation between large scale, past volatilities and small scale future
volatilities is larger than between small scale, past volatilities and large scale future volatilities. This eﬀect was

15

2e+06

N

 

1e+06

 Data, z2=0.85, α=1.15
 N(l) = l1/2

0e+00

0

2000

4000

6000

8000

10000

 l

FIG. 8: This Omori plot shows the cumulative number of aftershocks (i.e. returns with an amplitude larger than a certain
√ℓ. Main shocks were deﬁned as returns larger than a third of the
threshold) following a main shock, and ﬁt with N (ℓ)
maximum return observed over the whole time series (of length 850,000), and aftershocks as returns larger than a third of the
main shock.

∼

 0.4

  0 . 4

 0.4

 0.5
 0.5

 0.4

 0.4

 0.4

 0.5

 0.5

 
0
.
5

 
0
.
5

 

0

.

5

 

0

.

5

 0.5

 0.5

 

0

.

5

5
.
0
 

 

0

.

5

 

0

.

5

l

r
_
o
v

102
9
8

5

4

3

2

7

6

5

4

3

2

2

3

4

5

6

7

8

9

2

3

4

5

102
vol_h

FIG. 9: Zumbach’s mugshot for our model: contour plot of the correlation between past volatility and future volatility, measured
on diﬀerent time scales. For a trs process, this mug-shot would appear symmetric around the diagonal, whereas empirical
data shows, as in this ﬁgure, that the region below the diagonal carries more correlation than the region above it.

also noted in [57], but on the example of the S&P 500 index for which the leverage eﬀect is very strong. We have
computed this correlation in our model, following the methodology outlined in [13], where the idea of ‘mug-shots’ was
introduced to represent graphically such past volatilities/future volatilities correlations. The mug-shot corresponding
to our model is shown in Fig. 9. It is clear that our model – almost by construction – captures such a non trs eﬀect.
This was already noted in [13] for a similar model.

We think that the time asymmetry revealed by Zumbach’s mug-shots is extremely important: ﬁrst, it imposes a
theoretical constraint on the eligible models of ﬁnancial time series that most of them fail to obey. Second, it is a
direct proof of the existence of feedback eﬀects in ﬁnancial markets: the history of past price changes does have a
direct impact on the decision and behaviour of traders – in plain contradiction with the eﬃcient markets dogma.

16

(43)

(44)

(45)

(46)

σ2
h

i

=

(47)

V. THE LEVERAGE EFFECT

Up to now, we have only discussed our feedback model under the assumption of a symmetric reaction of the market
participants to price changes. If negative price changes have a larger impact than positive price changes, i.e, if the
distribution of thresholds shown in Fig. 1 has some asymmetry, one will observe negative correlations between past
price changes and future volatilities (leverage eﬀect) and some skewness in the distribution of returns, totally absent
from the above model. The natural way to generalize Eq. (9) to account for such an asymmetry is to write:

σ2
i = σ2
0

1 + ϕ

"

(xi −

gℓ

xi−ℓ)

+

σ0√ℓτ

gℓ

xi−ℓ)2
(xi −
σ2
0ℓτ

,

#

∞

Xℓ=1

∞

Xℓ=1

where ϕ measures the strength of the asymmetry. The case ϕ = 0 reproduces the model studied above, while ϕ < 0
induces a leverage eﬀect. A suﬃcient condition on ϕ that ensures that σ2 always remains positive is to impose that
each term of the sum over ℓ contributes positively. Writing as an identity 1 =

∞
ℓ=1 gℓ/z2, one obtains:

X 2 + ϕX +

1
z2 ≥

0

X,

∀

P

or: z2ϕ2 < 4.

The leverage correlation can be deﬁned as:[8] [63]

1
3/2 h
r2
i
h
This quantity is found empirically to be close to zero for i
exactly this correlation function in our model, provided the distribution of ξi is even.

r2
.
i rji

j) =

−

≤

(i

L

One ﬁnds:

j and negative for i > j. It is not diﬃcult to compute

One should also note that the average volatility is unchanged by the leverage term ϕ. Therefore, using
σ2
0/(1

z2), we ﬁnally ﬁnd:

−

r2
i ri−ℓi
h

=

σ2
h

σ0τ 3/2ϕ
i

gj
√j

.

∞

Xj=ℓ

(ℓ) = ϕg√1

L

z2

−

j1/2+α ∼ℓ→∞ ℓ1/2−α.

1

∞

Xj=ℓ

The decay of the empirical leverage correlation with lag, although noisy, can be ﬁtted by a power-law of exponent
close to 0.5, not far from α
1/2 (see Fig. 10). A power-law decay of the leverage correlation was also proposed in
the context of the multifractal bmd model in [33, 34].

−

This quantity is important because it governs the behaviour of the skewness of the return distribution on diﬀerent

time scales. It is indeed easy to show that the normalized skewness of returns on scale ℓ,

(ℓ) is given by [11]:

S

(ℓ) =

S

3
√ℓ

ℓ

(1

−

j
ℓ

j=1
X

(j)

)
L

∼ℓ→∞ ℓ1−α

(1 < α < 3/2).

(48)

From the above expression, we see that even if the return distribution is symmetric on the smallest time scale
(
(1) = 0), a negative skewness appears for ℓ > 1 when ϕ < 0, and decays back to zero for very large lags. However,
S
once again, the proximity of the critical line α = 1 beyond which the process becomes non stationary, leads to a very
0.1, corresponding to
slow decay of the skewness. Empirically, for daily returns of individual stocks, one ﬁnds
ϕ

∼ −
The skewness of stock indices, on the other hand, is generally much larger (by a factor 10) than that of individual
stocks. This is due to an enhanced downside correlation, which should be modeled using the multi-asset model
discussed below.

1 when α = 1.15 and z2 = 0.85.

S ≈ −

Note that the extra asymmetric term introduced in this section actually contributes also to the volatility-volatility
z2)ϕ2/ℓν
computed above and also to the kurtosis. For large ℓ, this extra contribution behaves as (1

correlation
and adds to the dominant term computed in section III.

F

−

17

 Data (US stocks, 1996−2004)
 Power−law fit (−0.65)
 Power−law fit (−0.5)

101

)
τ
(
L
−

 
 

100

10

1

0

0

10−1

100

20

40

60

80

100

101
  Time (days)

102

FIG. 10: The leverage correlation
straight line corresponds to the best power-law ﬁt over the whole range and has slope
model for α = 1.15 is a slope of
for stocks is weak and hard to measure [8]. Inset: same data in a linear representation, with the prediction of our model.

(with a minus sign) as a function of lag, for US stocks, in a log-log representation. The
1/2, whereas the prediction of our
0.65 (dashed line). Note however the scatter in the empirical data points: the leverage eﬀect

−

−

L

VI. SOFT CALIBRATION WITH REAL TIME SERIES

We have shown in the above sections, using both analytical arguments and numerical simulations, that our model
Eq. (9) is able to reproduce semi-quantitatively many of the stylized facts of ﬁnancial time series that have been
reported and studied in the literature. We have in fact shown, in many of the above ﬁgures, empirical data that
match quite well, at least to the eye, the predictions of the model. What do we mean by ‘semi-quantitatively’ ? Can
one be more quantitative and calibrate, in a standard econometric sense, our model to empirical data?

We believe that our model is interesting precisely because it clearly underlines the limits of such an ambition. The
empirical data clearly suggests that any faithful statistical model of ﬁnancial time series must be somehow close to
being non-stationary. This is obvious from the very existence of option markets, which demonstrate the diﬃculty of
measuring and predicting the volatility, even on rather long periods: the at-the-money vol of long-dated options still
moves around quite a bit from day to day and there is a persistent smile, symptomatic of a long-memory extending
to a few years [11]. We have shown in the above ﬁgures that empirical data on stocks seem to favor values of z2 and α
that drive our model very close to instability. This means that even a million step long simulation of our theoretical
model for realistic parameters is insuﬃcient to determine the true value of the volatility to better than 5% (see Table
I); such an uncertainty aﬀects all the observables of the model. How can one believe that anything more precise than
this can be reached on real empirical data? Available time spans are necessarily restricted, true jumps and overnight
eﬀects make the returns even more kurtic, true seasonalities (day, week, month, quarters, years) certainly play a
role, and non-stationarities (for example, the acceleration of the trading frequency with time) plague any attempt to
represent the dynamics of ﬁnancial markets with ﬁxed values of the parameters on very long time scales. No test, and
no model, should aim at more precision than reality itself.

In this situation, we think that the only reasonable strategy is what one could call ‘soft calibration’, in the following
sense: instead of focusing on a few observables that one tries to reproduce as accurately as possible to calibrate the
model (which is always possible), one should instead ﬁnd a set of parameters that approximately accounts for as
many diﬀerent observations as possible, and cross check the overall consistency of the model. This consistency is
more important and more stringent than a perfect ﬁt of an intrinsically elusive target. Calibration in these extreme
conditions is an ill-posed problem that, we believe, must be supplemented by intuition on what is important and
plausibility.

(cid:24)
(cid:24)
A. Calibration on stylized facts

18

How does this work in practice for the model we studied? In the simplest version that we developed, the model
has three important parameters: τ , z2, α (the value of σ0 merely sets the scale of the returns, but has no bearing
on the structural properties of the model). Accounting for the leverage eﬀect adds one more parameter, ϕ. But we
already know, both from the numerical results that show that our model leads to a non-monotonous kurtosis, and
from common sense, that unpredictable jumps must be present and should be factored in through a non-Gaussian
noise term ξ, which most probably has itself fat, power-law tails [13, 58]. This adds at least another parameter, which
would play an important role in an extended formulation of the model. Neglecting for now this extra complication,
our strategy is based on the idea that diﬀerent observables probe diﬀerently the inﬂuence of all parameters. This is
if fact how we organized the numerical results of section IV:

•

•

•

•

•

•

The distribution of the volatility or of the returns probes primarily the value of z2. The tail exponent µ, and
any measure of non-Gaussianity helps restricting the range of acceptable values of z2 (see Fig. 3 and Table I).

The temporal correlations of the volatility is primarily sensitive to the value of α, and can be used to limit the
acceptable range of this parameter (see Fig. 4-a), whereas the correlation of the log-volatility is most sensitive
to the value of z2 (see Fig. 4-b and Table 1).

The evolution of the non-Gaussian cumulants κ and Υ is sensitive to z2, α, but also to the value of the elementary
1/300 day to be consistent with empirical data.
time scale τ (see Figs. 5-a,b). This has enabled us to ﬁx τ
Of course this leaves us with the task of curing the unfriendly looking short scale kurtosis, but as mentioned
above, this could be easily be dealt with a non-Gaussian noise ξ. This however means that the optimal value of
z2 would be slightly reduced, since part of the kurtosis would already be accounted for.

≈

The multifractal analysis provides a stringent cross-check of the choice of parameters, since the multifractal
spectrum ζn is quite sensitive to the value of z2 (see Figs 6-a,b).

The consistency of the model can be probed further by analyzing the response of the volatility to shocks of
diﬀerent amplitudes, and studying the Omori plots (see Figs 7, 8). An acceptable description of this rather
subtle statistics is, we believe, another useful constraint on the parameter range.

Interestingly, the leverage correlation is totally decoupled from other observables and can be determined inde-
pendently from the study of the asymmetry of the distribution of returns and asymmetric volatility correlations,
that allow one to ﬁx the parameter ϕ.
= 0 adds a contribution to the kurtosis of the
process].

[Note however that ϕ

Following these steps is how we ‘calibrated’ our model on the average behaviour of 252 liquid US stocks in the
four-year period 2000-2003. From Figs. 4-6, we see that the value α = 1.15 allows one to capture correct time
dependence of the volatility correlation and of the evolution of non-Gaussian cumulants, whereas the choice of z2 in
0.90 allows one to capture the correct level of non-Gaussianity and multifractality (the parameter λ2
the range 0.85
appearing in Table I and in Figs 6). These values of z2 and α allow us to reproduce quite satisfactorily the whole set of
observables that we have studied, in particular the Student-like shape of the distribution of returns with a power-law
tail index in the right range, and the slow decay of the volatility correlation and of the kurtosis. The choice of the
time scale τ is dictated by Figs. 4-5, and is found to be on the order of 1/300th of a day (a few minutes). The value
of both z2 and τ will probably be aﬀected by the inclusion of a non-Gaussian noise ξ – we leave the detailed study of
this eﬀect for future work.

−

B. Volatility prediction

There is another, more direct way to test the consistency of our model, which to some extent avoids the problem
of the non-Gaussian nature of the noise ξ (but is still confronted with the intrinsic problems of long memory and non
stationarity). The idea is to ﬁx the exponent α and to regress, on empirical data, an estimate of the daily square
volatility on the computed feedback strength, deﬁned as:

In practice, we have estimated a noisy proxy of square volatility of a stock as σ2
)2/4O2, where
|
O, H, L, C stand for Open, High, Low, Close. We have computed Xi using the open prices and truncated the sum

i = (H

O
|

L +

−

−

C

Xi =

∞

Xℓ=1

(xi −

xi−ℓ)2

.

ℓ1+α

(49)

6
 US Data (moving average)
 Linear fit

19

2

σ

4

8

6

2

0

0

50
 X

100

FIG. 11: Scatter plot of σ2
i vs. Xi computed daily for 252 US stocks during the four-year period 2000-2003. The coordinates
of each point were rescaled by the average square volatility of the stock during that time period. A moving average over 1500
points was performed, unveiling the nearly linear average behaviour of σ2
i on Xi, assumed in our model. One can even notice
a negative curvature for large X, as suggested by the saturation mechanism we invoked in section II to motivate the model.

over ℓ beyond 500 days, which of course is not very accurate because when α is close to one, the above sum converges
only very slowly.

i

σ2
h

σ2
h

vs. Xi/

We then plot for all stocks σ2
i /

. Using our data set, this gives
i

400, 000 points; the correlation
coeﬃcient between the two sets is found to be 0.285. This value is rather high in view of the roughness of our volatility
proxy. The result is shown in Fig. 11, where we have performed a moving average over 1500 points. As one can see
the assumption of a linear relation between σ2
i and X is rather remarkably borne out, over a rather large range of Xi.
From the slope and intercept of the linear relation, we obtain a direct estimate of z2, which we ﬁnd to be
0.9, quite
close indeed to our previous determination. This direct estimate shows that (a) the basic assumption of the model,
that past price changes feedback in the volatility as in Eq. (9), seems to be realistic; and (b) the model is indeed
rather close to an instability, with a feedback mechanism that leads to a substantial increase of the volatility.

∼

≈

The direct determination of α using this method is however diﬃcult: one could think of varying α and choosing the
value corresponding to the maximal correlation between Xi and σi. Unfortunately, the dependence of this correlation
coeﬃcient on α is weak and does not allow to extract a meaningful minimum, although one can see that α = 1.15
is indeed in the range where the correlation is largest. One could also extend the above method to account for the
leverage eﬀect and estimate directly the asymmetry parameter ϕ.

C. Summary

In summary, we have shown that using a variety of diﬀerent observables, the range of acceptable values for the
parameters of the model can be approximately determined. We have found that using these parameters, all stylized
facts can be quantitatively accounted for. Due to the proximity of the unstable regime, however, a very precise
determination of optimal parameters seems illusory. On the other hand, the basic assumption of our model, that past
price changes feedback in the volatility through Eq. (9), is rather convincingly supported by the results shown in Fig.
11.

VII. GENERALIZATION TO MULTIASSET MODELS

An interesting generalization of the above model concerns the multiasset situation, for example baskets of diﬀerent
stocks with cross-correlations both in the returns and in the volatility. An obvious generalization of our model to this
case reads:

xa
i+1 −

i = ra
xa

i = σa

i ξa
i ,

(50)

20

(52)

where i denotes the time index and a labels the stocks. The ξa
encoding the usual sectorial correlations. For the σa
Cab =

i ξb
ξa
i i
h

σa2
i = σa2
0

1 +

gℓ

∞

"

Xℓ=1

Xb

xb
H ab (xb
i−ℓ)
i −
0√ℓτ
σb

i ’s are characterized by certain correlation matrix
i ’s, we write, in full generality:
Gab (xb

(51)

∞

.

gℓ

+

i−ℓ)2
xb
i −
σb2
0 ℓτ

#

Xℓ=1

Xb

We leave the investigation of this rich model for future work; thanks to the matrix structure of the feedback eﬀect H
and G, one can reproduce a large variety of volatility cross-correlations and leverage eﬀects. Here, we note that the
average volatilities obey the following matrix equation:

δab −

Xb  

∞

Xℓ=1

gℓGab σa2
0
σb2
0 ! h

σb2

= σa2
0 ,

i

leading to a criterion for the stability of the model, which is that the smallest eigenvalue of the matrix on the left
hand side of this equation must remain positive, generalizing the above criterion 1

z2 < 1.

From Eq.(51) one can also estimate the leverage eﬀect for index returns, which can be much enhanced if the matrix
H ab has large oﬀ diagonal values compared to Gab, meaning that a downward move on any other stock b is perceived
as a source of risk for stock a, and triggers extra trades on all other stocks as well.

−

VIII. CONCLUSION AND PERSPECTIVES

In this work, we have proposed and studied, both analytically and numerically, a multiscale feedback model of
volatility. This ARCH-like model (similar to the one studied by Zumbach in [13]) assumes that the volatility is
governed by the observed past price changes on diﬀerent time scales, which, we argue, directly inﬂuence the activity
of traders. Assuming a power-law distribution of the time horizon of diﬀerent traders, we obtain a model that captures
most stylized facts of ﬁnancial time series: Student-like distribution of returns with a power-law tail, long-memory of
the volatility, slow convergence of the distribution of returns towards the Gaussian distribution, multifractality and
anomalous volatility relaxation after shocks. The model, at variance with recent multifractal models that are strictly
time reversal invariant, reproduces the time asymmetry of ﬁnancial time series revealed by Zumbach’s mug-shots:
past large scale volatility inﬂuence future small scale volatility.

The most important conclusion of our work is the following: in order to quantitatively reproduce empirical obser-
vations, the parameters must be chosen such that our model is ‘doubly’ close to an instability, i.e. two parameters are
close to values beyond which the process becomes non stationary. This means that (a) the feedback eﬀect is important
and substantially increases the volatility, and (b) that the model is intrinsically diﬃcult to calibrate because of the
very long range nature of the correlations and the slow convergence of all observables. However, by imposing the
consistency of the model predictions with a large set of diﬀerent empirical observations, a reasonable range of the
parameters value can be determined. Furthermore, the adequacy of the basic assumption of our model, i.e. that the
instantaneous volatility is directly related to a power-law superposition of past square returns on diﬀerent time scales,
can be directly assessed. The model can easily be generalized to account for jumps (a feature needed to correct an
unrealistic non monotonous behaviour of the kurtosis), skewness and multiasset correlations.

The interest of this type of models, compared to (multifractal) stochastic volatility models, is that their fundamental
justiﬁcation, in terms of agent based strategy, is relatively direct and plausible. We believe this is a strong constraint
which should guide the construction of any mathematical model of reality. On the other hand, our fundamental
assumption, Eq. (9), is in contradiction with the eﬃcient market hypothesis, which asserts that the price past history
should have no bearing whatsoever on the behaviour of investors. The large correlation that we ﬁnd between past
price changes and present volatility (see Fig. 11) indicates that this inﬂuence is in fact quite strong. This result is, in
our view, yet another direct piece of evidence against the eﬃcient market hypothesis, and a clear mechanism leading
to excess volatility in ﬁnancial markets.

Turning to ﬁnancial engineering applications, such as risk control and option pricing, our model provides a well
deﬁned procedure to ﬁlter the series past price changes, and to compute the probabilities of the diﬀerent future paths.
Similar models have been shown to fare rather well [46, 48]. Once ‘softly’ calibrated, the model can in principle be used
for VaR estimates and option pricing. However, its mathematical complexity does not allow, in general, for explicit
analytical solutions and probably one has to resort either to approximate treatments or to numerical, Monte-Carlo
methods. The diﬃculty of long-memory models is that the option price must be computed conditional to the whole
past history, which considerably complexiﬁes both analytical solutions and Monte-Carlo methods. In other words,
both the option price and the optimal hedge are no longer simple functions of the current price, but functionals of the
whole price history. Finding operational ways to account for this history dependence seems to us a major challenge,
on which we hope to work in the near future.

Acknowledgments

21

We want to thank D. Farmer and T. Lux for inviting us to write this paper, which was initiated by discussions
during the Leiden workshop: “Volatility in ﬁnancial markets”, October 2004. Discussions with J.F. Muzy and G.
Zumbach have been of great help. L.B. also thanks J. Evnine for ongoing discussions and support.

[1] L. Bachelier, Th´eorie de la sp´eculation (1900), Reprinted by J. Gabay, Editor, Paris 1995.
[2] T. Lux, The stable Paretian hypothesis and the frequency of large returns: an examination of major German stocks, Applied

Financial Economics, 6, 463, (1996).

[3] F. Longin, The asymptotic distribution of extreme stock market returns, Journal of Business, 69 383 (1996)
[4] V. Plerou, P. Gopikrishnan, L.A. Amaral, M. Meyer, H.E. Stanley, Scaling of the distribution of price ﬂuctuations of
individual companies, Phys. Rev. E60 6519 (1999); P. Gopikrishnan, V. Plerou, L. A. Amaral, M. Meyer, H. E. Stanley,
Scaling of the distribution of ﬂuctuations of ﬁnancial market indices, Phys. Rev. E 60 5305 (1999)

[5] A. Lo, Long term memory in stock market prices, Econometrica, 59, 1279 (1991).
[6] Z. Ding, C. W. J. Granger and R. F. Engle, A long memory property of stock market returns and a new model, J. Empirical

Finance 1, 83 (1993).

[7] Y. Liu, P. Cizeau, M. Meyer, C.-K. Peng, H. E. Stanley, Correlations in Economic Time Series, Physica A245 437 (1997)
[8] J.P. Bouchaud, A. Matacz, M. Potters, The leverage eﬀect in ﬁnancial markets: retarded volatility and market panic

Physical Review Letters, 87, 228701 (2001)

[9] D. M. Guillaume, M. M. Dacorogna, R. D. Dav´e, U. A. M¨uller, R. B. Olsen and O. V. Pictet, Finance and Stochastics
1 95 (1997); M. Dacorogna, R. Gen¸cay, U. M¨uller, R. Olsen, and O. Pictet, An Introduction to High-Frequency Finance
(Academic Press, London, 2001).

[10] R. Mantegna & H. E. Stanley, An Introduction to Econophysics, Cambridge University Press, 1999.
[11] J.-P. Bouchaud and M. Potters, Theory of Financial Risks and Derivative Pricing, Cambridge University Press, 2004.
[12] T. Lux, Market Fluctuations: Scaling, Multi-Scaling and Their Possible Origins in: A. Bunde and H.-J. Schellnhuber, eds.,
Theories of Disasters: Scaling Laws Governing Weather, Body and Stock Market Dynamics. Berlin: Springer (2003).
[13] G. Zumbach, P. Lynch, Market heterogeneity and the causal structure of volatility, Quantitative Finance, 3, 320, (2003).
[14] S. I. Boyarchenko, and S. Z. Levendorskii, Non-gaussian Merton-Black-Scholes Theory, World Scientiﬁc (2002)
[15] R. Cont, P. Tankov, Financial modelling with jump processes, CRC Press, 2004.
[16] S.L. Heston, A closed-form solution for options with stochastic volatility with applications to bond and currency options,

[17] J.-P. Fouque, G. Papanicolaou, G. and K. R. Sircar, Derivatives in ﬁnancial markets with stochastic volatility, Cambridge

[18] A. A. Dragulescu and V. M. Yakovenko, Probability distribution of returns in the Heston model with stochastic volatility,

[19] J. Perello, J. Masoliver, J.P. Bouchaud, Multiple time scales in volatility and leverage correlations: a stochastic volatility

[20] P. Carr, H. Geman, D. Madan, M. Yor, Stochastic Volatility for Levy Processes, Mathematical Finance, 13, 345 (2003).
[21] A. Fisher, L. Calvet, B.B. Mandelbrot, Multifractality of DEM/$ rates, Cowles Foundation Discussion Paper 1165.
[22] S. Ghashghaie, W. Breymann, J. Peinke, P. Talkner, Y. Dodge, Turbulent cascades in foreign exchange markets Nature

[23] F. Schmitt, D. Schertzer, S. Lovejoy, Multifractal analysis of Foreign emchange data, Applied Stochastic Models and Data

Rev. of Fin. Studies, 6, 327-343, 1993

University Press, 2000

Quantitative Finance 2, 443-453 (2002).

model, Appl. Math. Fin. 11, 1 (2004).

381 767 (1996).

Analysis, 15 29 (1999);

Solitons and Fractals, 11 2343 (2000).

[24] M.-E. Brachet, E. Taﬂin, J.M. Tch´eou, Scaling transformation and probability distributions for ﬁnancial time series, Chaos,

[25] J.P. Bouchaud, M. Potters, M. Meyer, Apparent multifractality in ﬁnancial time series, Eur. Phys. J. B 13, 595 (1999).
[26] L. Calvet, A. Fisher, Forecasting multifractal volatility, Journal of Econometrics, 105, 27, (2001).
[27] L. Calvet, A. Fisher, Multifractality in Asset Returns: Theory and Evidence, Review of Economics and Statistics 84,

381-406 (2002).

1, 632, (2001)

[28] T. Lux, Turbulence in ﬁnancial markets: the surprising explanatory power of simple cascade models, Quantitative Finance

[29] T. Lux, Multi-Fractal Processes as a Model for Financial Returns: Simple Moment and GMM Estimation, in revision for

Journal of Business and Economic Statistics

[30] J.-F. Muzy, J. Delour, E. Bacry, Modelling ﬂuctuations of ﬁnancial time series: from cascade process to stochastic volatility
model, Eur. Phys. J. B 17, 537-548 (2000); E. Bacry, J. Delour and J.F. Muzy, Multifractal random walk, Phys. Rev. E
64, 026103 (2001).

[31] J.F. Muzy and E. Bacry, Multifractal stationary random measures and multifractal random walks with log-inﬁnitely divisible

[32] For a inspiring recent account, see B. M. Mandelbrot, R. Hudson, The (mis)behaviour of markets, Perseus Books, Cambridge

scaling laws, Phys. Rev. E 66, 056121 (2002).

MA (2004)

22

[33] B. Pochart and J.P. Bouchaud, The skewed multifractal random walk with applications to option smiles, Quantitative

Finance, 2, 303 (2002).

[34] Z. Eisler, J. Kertesz, Multifractal model of asset returns with leverage eﬀect, e-print cond-mat/0403767
[35] L. Borland, J. P. Bouchaud, J.-F. Muzy, G. Zumbach, The dynamics of Financial Markets: Mandelbrot’s multifractal

cascades, and beyond, Wilmott Magazine, March 2005.

[36] T. Lux, M. Marchesi, Scaling and criticality in a stochastic multiagent model, Nature 397, 498 (1999); T. Lux, M. Marchesi,
Volatility Clustering in Financial Markets: A Microsimulation of Interacting Agents, Int. J. Theo. Appl. Fin. 3, 675 (2000).
[37] D. Challet, A. Chessa, M. Marsili, Y.C. Zhang, From Minority Games to real markets, Quantitative Finance, 1, 168 (2001)

and refs. therein; D. Challet, M. Marsili, Y.C. Zhang, The Minority Game, Oxford University Press, 2004.

[38] W. Brock, C. Hommes, Econometrica 65, 1059 (1997); C. Hommes, Financial markets as nonlinear adaptive evolutionary

systems, Quantitative Finance, 1, 149, (2001)

[39] C. Chiarella, X-Z. He, Asset price and wealth dynamics under heterogeneous expectations, Quantitative Finance, 1, 509,

B 31, 421 (2003).

(2001)

2004.

[40] I. Giardina, J.P. Bouchaud, Bubbles, Crashes and Intermittency in agent based market models, European Journal of Physics

[41] L. Borland, A Theory of non-Gaussian Option Pricing, Quantitative Finance 2, 415-431, (2002).
[42] Cf. M. Gell-Mann and C. Tsallis, Non extensive entropies – interdisciplinary applications, Oxford University Press, NY,

[43] L. Borland, J. P. Bouchaud, A non-Gaussian Option Pricing model with skew, Quantitative Finance, 4, 499-514 (2004)
[44] see, e.g. J. Hull, Futures, Options and other Financial Derivatives, Prentice Hall, 2004.
[45] L. Borland, A multi-time scale non-Gaussian model of stock returns, e-print cond-mat/0412526
[46] G. Zumbach, Volatility processes and volatility forecast with long memory, Quantitative Finance 4 70 (2004).
[47] R. T. Baillie, T. Bollerslev, H. O. Mikkelsen, Fractionally integrated GARCH, J. Econometrics, 31, 3 (1996); T. Bollerslev,

H. O. Mikkelsen, Modeling and pricing long memory in stock market volatility, J. Econometrics, 73, 3 (1996).

[48] M. Dacorogna, U. Muller, R. B. Olsen, O.Pictet, Modelling Short-Term Volatility with GARCH and HARCH Models,

Nonlinear Modelling of High Frequency Financial Time Series, 1998

[49] T. Bollerslev, R. F. Engle, D. B. Nelson, ARCH models, in R. F. Engle, D. McFadden, Edts, Handbook of Econometrics,

Vol. 4, Elsevier Science, Amsterdam (1994).

[50] R. J. Shiller, Do Stock Prices move too much to be justiﬁed by subsequent changes in dividends?, American Economic

Review, 71, 421 (1981); R. J. Shiller, Irrational Exuberance, Princeton University Press (2000).

[51] On feedback eﬀects on the volatility, see also: M. Wyart, J. P. Bouchaud, Self-referential behaviour, overreaction and

conventions in ﬁnancial markets, to appear in JEBO.

[52] S. Miccich`e, G. Bonanno, F. Lillo, R. N. Mantegna, Volatility in ﬁnancial markets: stochastic models and empirical results,

Physica A 314, 756, (2002).

[53] D. Sornette, Y. Malevergne, J.F. Muzy, What causes crashes, Risk Magazine, 67 (Feb. 2003).
[54] A. G. Zawadowski, J. Kertesz, G. Andor, Large price changes on small scales, e-print cond-mat/0401055
[55] F. Lillo and R. N. Mantegna, Power law relaxation in a complex system: Omori Law After a Financial Market Crash,

[56] Y. Pomeau, Sym´etrie des ﬂuctuations dans le renversement du temps, J. Physique 43 859 (1985).
[57] A. Arneodo, J.-F. Muzy, D. Sornette, Causal cascade in the stock market from the ‘infrared’ to the ‘ultraviolet’, Eur. Phys.

[58] see, e.g. J. Doyne Farmer, Laszlo Gillemot, Fabrizio Lillo, Szabolcs Mike, Anindya Sen, What really causes large price

[59] Note however that a model based on log-prices has no deep theoretical justiﬁcations and might not be the best representation

of reality. See [8, 11] for a detailed discussion of this point.

[60] The following argument is only intended to be qualitative. In reality, the trading range between ti−1 and ti is given by the
high minus low of that period, rather than the open to close; all thresholds with that interval will be hit. However, the
high-low is of the same order as the open-close ri−1 – in fact, for a random walk, the average high-low is exactly twice the
average

[61] It might actually be more consistent, at the level of the theoretical justiﬁcation of the model, to replace σ2

0 in the feedback
term by a moving average of the past volatility itself, since traders are sensitive to the recent level of volatility. This would
make the model more complicated, and we leave this extension for future investigation.

, a result due to Bachelier himself!
|

ri−1
|

[62] The marginal case α = 1 with a cut-oﬀ for ℓ > L is quite interesting and might in fact resemble the strictly multifractal

bmd model.

[63] A slightly diﬀerent normalization was actually used in [8].

Physical Review E 68, 016119 (2003)

J. B 2, 277 (1998)

changes?, e-print cond-mat/0312703.

