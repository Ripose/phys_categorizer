Risk Minimization through Portfolio Replication

Stefano Ciliberti1, 2 and Marc M´ezard1

1CNRS; Univ. Paris Sud, UMR8626,

LPTMS, ORSAY CEDEX, F-91405 (France)
2Science & Finance, Capital Fund Management,

6 bd Haussmann, 75009, Paris (France)

Abstract

We use a replica approach to deal with portfolio optimization problems. A given risk measure

is minimized using empirical estimates of asset values correlations. We study the phase transition

which happens when the time series is too short with respect to the size of the portfolio. We also

study the noise sensitivity of portfolio allocation when this transition is approached. We consider

explicitely the cases where the absolute deviation and the conditional value-at-risk are chosen as a

risk measure. We show how the replica method can study a wide range of risk measures, and deal

with various types of time series correlations, including realistic ones with volatility clustering.

6
0
0
2
 
g
u
A
 
3
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
5
3
0
8
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

1

I.

INTRODUCTION

The portfolio optimization problem dates back to the pioneering work of Markowitz [1]

and is one of the main issues of risk management. Given that the input data of any risk

measure ultimately come from empirical observations of the market, the problem is directly

related to the presence of noise in ﬁnancial time series. In a more abstract (model-based)

approach, one uses Monte Carlo simulations to get “in-sample” evaluations of the objective

risk function.

In both cases the issue is how to take advantage of the time series of the

returns on the assets in order to properly estimate the risk associated with our portfolio.

This eventually results in the choice of the risk measure, and a long debate in the recent years

has drawn the attention on two important and distinct clues: the mathematical property

of coherence [2], and the noise sensitivity of the optimal portfolio. The rational behind the

ﬁrst of these issues lies in the need of a formal (axiomatic) translation of the basic common

principles of risk management, like the fact that portfolio diversiﬁcation should always lead

to risk reduction. Moreover, requiring a risk measure to be coherent implies the existence

of a unique optimal portfolio and a well-deﬁned variational principle, of obvious relevance

in practical cases. The second issue is also a very delicate one. In a realistic experimental

set-up, the number N of assets included in a portfolio can be of order 102 to 103, while

the length of a trustable time series hardly goes beyond a few years, i.e. T

estimate of any extensive observable would require the condition N/T

1 to hold, but this

is rarely the case. Instead, the ratio of assets to data points, N/T , will be considered as a

103. A good

∼

≪

ﬁnite number.

In this note we address analytically the risk minimization problem by studying the depen-

dence of the optimal portfolio on the ratio N/T and on other potential external parameters.

We ﬁrst assume that the real distribution of returns is multinormal in order to keep the

problem tactable from the analytical point of view. Generalizations to more realistic re-

turns distributions are also presented. Our approch consists in writing down the empirical

estimate of the risk measure and then reformulating the problem from the point of view

of the statistical physics. We work out the analytical solution by means of the replica

method [3] and thus get some insights on the optimal portfolios. The analytical solution

conﬁrms previous results on the existence of a phase transition [4]. The ratio N/T plays

the role of a control parameter. When it increases, there exists a sharply deﬁned threshold

2

value where the estimation error of the optimal portfolio diverges. A ﬁrst account of our

method, limited to the Expected Shortfall risk measure, has appeared in ref. 5. Here we give

a more general presentation, studying other risk measures and more realistic distributions

of returns.

The paper is organized as follows. In section II we introduce the notations we will use

throughout the paper and we formulate the problem in its general mathematical form. In

section III we consider the case of the absolute deviation (AD) [6]. We present the replica

calculation of the optimal portfolio and compute explicitely a noise sensitivity measure

introduced in ref. 10.

In section IV we deal with portfolio optimization under Expected

Shortfall [2, 7], which was shown to have a non-trivial phase diagram [4] and then studied

analytically [5]. The striking point is that, for some values of the external parameters of

the problem, the minimization problem is not well deﬁned and thus cannot admit a ﬁnite

solution. We investigate here the same feature while considering realistic distribution of

returns, so as to take into account volatility clustering. The replica approch then turns into

a semi-analytic and extremely versatile technique. We discuss this point and then summarize

our results in section V.

II. THE GENERAL SETTING

We denote our portfolio by w =

, where wi is the position on asset i. We do

w1, . . . wN }

{

not impose any restriction to short selling: wi is a real number. The global constraint induced

by the total budget reads

i wi = N, where, due to a later mathematical convenience, we
have chosen a slightly diﬀerent normalization with respect to the previous literature. Calling

P

xi the return of the asset i and assuming the existence of a well-deﬁned probability density

function (pdf) p(x1, . . . xN ), one is interested in computing the pdf of the loss ℓ associated

to a given portfolio, i.e.

pw(ℓ) =

dxi p(x1, . . . xN ) δ

ℓ +

wixi

.

(1)

i

Z Y

N

i=1
X

 

!

The complete knowledge of this pdf would lead to the precise, though still probabilistic,

evaluation of the loss, thus allowing for a straightforward optimization over the space of

legal portfolios. This is actually a pretty diﬃcult task and one usually restricts to some

characteristic of this pdf (e.g.

its ﬁrst moments, its tail beahvior), so as to capture the

3

consequences of extremely bad events in the global loss. The actual p(x1, . . . xN ) is not known

in general, and integrals like the one in (1) are usually estimated by time series, coming

from market oservations or synthetically produced by numerical simulations. Whatever the

chosen risk measure then, one typically faces cost functions (to be optimized over all possible

portfolios) like

risk(w; N, T, λ) =

(2)

1
T

T

N

Fλ

"

τ =1
X

i=1
X

wix(τ )
i

,

#

where

x(1)
i

, x(2)
i

, . . . x(T )
i }

{

is the whole time series of the return i and where we denoted by

λ other possible external parameters of the risk measure. The best known example of risk

function is obtained by taking

measure is of course the variance, as ﬁrst suggested by Markowitz. In that case the risk
Fλ(z) = z2 in (2). The evaluation of the variance implies
an empirical evaluation of the covariance matrix σij of the underlying stochastic process,

and the extremely noisy character of any estimation of σij has been underlined a few years

ago [8, 9]. However, recent studies [10, 11] have shown that the eﬀect of the noise on

the actual portfolio risk is not as dramatic as one might have expected. More in detail, a

direct measure of this eﬀect was introduced and explicitely computed in the simplest case of

σij = δij. In the next section, we compute the same quantity as far as the absolute deviation

of the loss is concerned.

In the statistical physics approach, one studies the limit N, T

→ ∞
ﬁnite. One introduces the partition function at inverse temperature γ:

, while N/T

1/t is

≡

Z (N )
γ

[t, λ;

x(τ )
i }

{

] =

dwi e−γ risk[w;N,N t,λ] δ

N

Z

i=1
Y

N

 

i=1
X

wi −

N

!

,

(3)

from which any observable will be computed. For instance, the optimal cost (i.e.

the

minimum of the risk function in (2)) is computed from

e(t, λ) = lim
N→∞

min
w

risk[w; N, Nt, λ] = lim
N→∞

1
N

1
N

lim
γ→∞

1
−
γ

log Z (N )

γ

[t, λ;

x(τ )
i }

{

] .

(4)

It turns out that this expression depends on the actual sample (the time series

x(τ )
i }

{

) used

to estimate the risk measure. We are mainly interested in the average over all possible time

series of this quantity, which we assume to be narrowly distributed around its mean value.

Taking the average of eq. (4) means that we have to average the logarithm of the partition

function according to the pdf p(
). The so-called replica method allows to simpliﬁy this
task as follows. We compute E [Z n] for integer n and assume we can analytically continue

{

x(τ )
i }

4

this result to real n: then E [log Z] = limn→0(E [Z n]

1)/n. This is the strategy that we are

−

going to use in the next sections and that will allow to compute the optimal portfolio.

III. REPLICA ANALYSIS: ABSOLUTE DEVIATION

The absolute deviation measure AD

w; N, T

is obtained by choosing

Fλ(z) =

z

|

|

in (2).

No other external parameters λ are present here. We assume a factorized distribution

(cid:2)

(cid:3)

p

x(τ )
i }

{

(cid:2)

∼

(cid:3)

i,τ
Y

exp

N(x(τ )
2σ2

i )2
τ !

,

 −

where the volatilities

are distributed according to a pdf which we do not specify for

στ }

{

the moment. Following the replica method, we introduce n identical replicas of our portfolio

and compute the average of Z n:

n

dQabd ˆQabeN

E

Z n

γ (t)

∼

(cid:3)

Z

Ya,b=1

(cid:2)

n
a,b=1(Qab−1) ˆQab− N

2 Tr log ˆQ− T

2 Tr log Q+

τ log Aγ ({Qab};στ ) ,

P

Aγ(

Qab

; στ ) =

{

}

dua

τ exp

1
2σ2
τ

−

(cid:26)

Xab

(Q−1)abua

τ ub

γ

τ −

,

ua
τ |

|

(cid:27)

a
X

where we have introduced the overlap matrix

(5)

(6)

(7)

Qab =

wa

i wb
i ,

a, b = 1, . . . n ,

P

n

Z

a=1
Y

1
N

N

i=1
X

as well as its conjugate ˆQab, the Lagrange multipliers introduced to enforce (7). In the limit

N, T

, N/T = 1/t ﬁnite, the integral in (6) can be solved by a saddle point method.

→ ∞

Due to the symmetry of the integrand by permutation of replica indices, there exists a
= b, and the same for ˆQab. We

replica-symmetric saddle point [3]: Qaa = q1, Qab = q0 for a

expect the saddle point to be correct in view of the fact that the problem is linear. Under

this hypothesis, which will be only justiﬁed a posteriori by a direct comparison to numerical

data, the replicated partition function in (6) gets simpliﬁed into

dq0

d∆q exp

Nn Sγ(q0, ∆q)(1 +

(n))

,

(8)

E

Z n

γ (t)

∼

(cid:2)

(cid:3)

Sγ(q0, ∆q) =

Z
(1

Z
t)q0 −
2∆q

−

1

+

t

1

(cid:2)
−
2

log ∆q + t

log Aγ(q0, ∆q; στ ) ,

1
T

O
1
n

τ
X

2

(cid:3)

Aγ(q0, ∆q; στ ) =

e−s2/2q0

1 + n

du e

− u

2∆qσ

2
τ

+ s u
∆qστ

−γ|u|

ds
√2πq0

Z

+

(n2)

,

O

(cid:21)

(cid:20)

Z

5

6
where ∆q = q1 −
now assume that in the low temperature limit the overlap ﬂuctuations are of order 1/γ and

q0 and n is the number of replicas (which will eventually go to zero). We

introduce ∆ = γ∆q. One can show that if ∆ stays ﬁnite at low temperatures

lim
n→0

lim
γ→∞

1
nγ

log Aγ(q0, ∆/γ; στ ) = ∆2σ3
τ

ds e−s2σ2

τ ∆2/2q0(1

s)2 .

(9)

−

∞

1
Z

For the sake of clarity, we focus on the simple case στ = 1

τ . In the γ

limit, the

∀

→ ∞

saddle point equations for (8) are

= erf

1/

2q′
0

,

1
t

∆ =

(cid:16)
2t

(cid:17)
p
1/t
1
q′
0 +
−
2

 

"

q′
0
2π

r

e−1/2q′

0

(1 + q′
0)
2

−

(10)

−1/2

,

(11)

1

erf

1/

2q′
0

−

(cid:16)

(cid:16)

p

#!

(cid:17)(cid:17)

where q0 = q′

e(t) = 1/∆. Notice that (10) only admits a solution for t

0∆2. The minimum cost function, i.e. the average of eq. (4), is found to be
1. There is no solution to the

≥

minimization problem if the ratio of assets to data points, N/T , is smaller than 1. On the

other hand, once this condition is fulﬁlled, the equation (11) gives a ﬁnite ∆ at any t > 1.

The asymptotic behaviour of e(t) can be worked out analytically: we introduce δ

1

1/t

and consider the limit δ

1. This leads to

≪

e(t)

δ

1

≃ s

2 log δ  

−

−

log

4
π log δ

−
4 log δ
(cid:0)

!

(cid:1)

.

≡

−

(12)

The full solution and a comparison with numerics are shown in Fig. 1 (left).

We now address the issue of noise sensitivity, for which a measure was introduced in 10.

The idea is the following: Assume you know the true pdf of the loss (1) and you get some

optimal w(0) by minimizing the absolute deviation of ℓ. We want to compare the optimal

risk associated to w(0) with the one obtained by optimizing (2), i.e. the empirical estimation
of the same risk measure. A fair comparison is then qK −
w∗; N, T
w(0); N

q2
K(N, T ) =

1, with

(13)

,

where the w∗

i refer to the portfolio obtained by minimizing (2). This is the quantity which

we have computed by the replica approach.

In our calculation we have assumed to deal

with a factorized Gaussian distribution of returns (extensions to more realistic cases will

be presented in the next section) and it is straightforward to prove that in this case qK =

AD
AD
(cid:2)
(cid:2)

(cid:3)
(cid:3)

6

q
K

n
o
i
t
c
n
u
f
 
t
s
o
c

 3

 2.5

 2

 1.5

 1

 0.5

N = 64 
N = 128
N = 256
analytic

N = 64 
N = 128
N = 256
qK (var)
analytic

K
q

 2

 4

 3.5

 3

 2.5

 1.5

 0.5

 1

 0

 0

 0.2

 0.4

 0.6
1
t

 0.8

 1

 0

 0.2

 0.4

 0.8

 1

 1.2

 0.6
1
t

FIG. 1: Left: The analytic solution e(t) is compared with the results of numerical simulations,

where the constrained optimization is computed directly via linear programming methods [12].

Right: Numerical results for

N
i=1(w∗

i )2 compared to the analytic behaviour

q′
0∆. The curve

denoted by qK (var) represents the behaviour of qK in the variance minimization problem.

p

qP

i )2. This corresponds in our language to √q0 =

N
i=1(w∗
qP
1/t)−1/2 as 1/t
of qK in the variance minimization problem) are needed in order to reproduce the data

−
1−. Corrections to this leading behavior (which is instead the full shape

q′
0∆, which diverges like (1

p

→

(right panel of Fig. 1). The comparison with the Markowitz optimal portfolio (variance

minimization) indicates that the AD measure is actually less stable to perturbations: A

geometric interpretation of this result can be found in ref. 4. Beside this fact, the interesting

result is then the existence of a well deﬁned threshold value t = 1 at which the estimation

error becomes inﬁnite. This is due to the divergence of the variance of the optimal portfolio

in the regime t < 1, where any minimization attempt is thus totally meaningless.

IV. EXPECTED SHORTFALL

A. The minimization problem

For a ﬁxed value of β < 1 (β & 0.9 in the interesting cases) the expected-shortfall (ES)

of a portfolio w is obtained by choosing

(z)

zθ(z

VaR) in (2), where VaR stands here

F

∝

−

for the Value-at-Risk [13]. In practice, it is computed from the minimization of a properly

7

chosen objective function [14]:

ES

w; N, T, β

= min

v +

(cid:2)
(a +

a
|

|

≡

(cid:3)

v 




1
β)T

(1

−

T

N

v
τ =1 "−
X

−

i=1
X

wix(τ )
i

+

#

(14)

,






where [a]+

)/2. Optimizing the ES risk measure over all the possible portfolios

satisfying the budget constraint is equivalent to the following linear programming problem:

Cost function: E = (1

β)T v +

−

•

T
τ =1 uτ ;

P

Variables: Y

w1, . . . wN , u1, . . . uT , v

;

•

≡ {
Constraints: ut ≥

}
i=1 xitwi ≥
In a previous work [5] we solved the problem in the case where the historical series of returns

N
i=1 wi = N .

ut + v +

0 ,

0 ,

P

P

•

N

is drawn from the oversimpliﬁed probability distribution (5), with στ = 1

τ . Here we do a

∀

ﬁrst step towards dealing with more realistic data and assume that the series of returns can

be obtained by a sequence of normal distributions whose variances depend on time:

σt}

p

{
(cid:2)

(cid:3)

∼

Yτ,τ ′

−

(cid:0)

τ
(cid:1) Y

exp

στ στ ′G−1
τ,τ ′

q(στ ) ,

(15)

for some long range correlator Gτ,τ ′ which takes into account volatility correlations, and

q(στ ) equal e.g. to a lognormal distribution.

B. The replica solution

A straightforward generalization of the replica calculation presented in ref. 5 (and

sketched in the previous section for a similar problem) allows to compute the average optimal

cost for a given volatility sequence

, in the limit when N, T

and N/T = 1/t

σ1, . . . σT }

{

→ ∞

stays ﬁnite. This is given by

e(t, β) = min
v,q0,∆

1
2∆

(cid:20)

˜ε(t, β; v, q0|{

στ }

)

≡

t(1

β)v

−

where ∆

is x <

−

limγ→∞ γ∆q and the function g(x; σ) is equal to x2 if

≡
σ, and 0 otherwise. The minimization over v, q0 implies that

−

σ

≤

+ ∆ ˜ε(t, β; v, q0|{
q0
t
2√π
2

1
T

+

T

−

)

στ }

,

(cid:21)
+∞

−∞

τ =1 Z
X

(16)

ds e−s2

g(v/στ + s

2q0; στ ) , (17)

p
x < 0, to

2σx

σ2

−

−

∂ ˜ε/∂v = ∂ ˜ε/∂q0 = 0 .

(18)

8

As discussed in [5], the problem admits a ﬁnite solution if (17) is minimized by a ﬁnite value

of ∆. The feasible region is then deﬁned by the condition ˜ε(t, β; v, q

0 , where v

)

σt}

|{

≥

and q0 satisfy (18). This theoretical setup suggests the following semi-analytic protocol for

determining the phase diagram of realistic portfolio optimization problems.

1. Fix a value of β

[0, 1], and take N equal to the portfolio size you are interested in.

∈

2. For T = Tmin to Tmax, such that N/T

[0.1, 0.9], do the following:

(a) Generate a sequence

according to (15) and compute the ˜ε function

∈

σ1, σ2, . . . σT }

{

(b) Minimize ˜ε with respect to v and q0 according to (18).

(c) Repeat steps (a) and (b) for n samples, and compute the mean value

.

˜ε
i

h

3. Plot

vs. N/T and ﬁnd the value (N/T )∗ where this function changes its sign.

By repeating this procedure for several values of β we get the phase separation line (N/T )∗

in (17).

˜ε
i

h

vs. β.

C. Results

A simple way of generating realistic volatility series consists in looking at the return time

series as a cascade process [15]. In a multifractal model recently introduced [16] the volatility

covariance decreases logarithmically: this is achieved by letting στ = exp ξτ , where ξτ are

Gaussian variables and

=

ξτ i

h

−

λ2 log Tcut ,

ξτ ξτ ′

h

i − h

ξ2
τ i

= λ2 log

1 +

(19)

Tcut
τ

|

−

τ ′

|

,

λ quantifying volatility ﬂuctuations (the so-called ‘vol of the vol’), and Tcut being a large

cutoﬀ. A few samples generated according to this procedure are shown in Fig. 2.

The phase diagram obtained for diﬀerent values of λ2 is shown in Fig. 3. A comparison

with the phase diagram computed in absence of volatility ﬂuctuations shows that, while

the precise shape of the separating curve depend on the ﬁne details of the volatility pdf,

the main message has not changed: There exists a regime, N/T > (N/T )∗, where the small

number of data with respect to the portfolio size makes the optimization problem ill-deﬁned.

9

λ2 = 0.10

λ2 = 0.20

 0

 200

 400

 600

τ

 800

 1000

 0

 200

 400

 600

τ

 800

 1000

λ2 = 0.40

λ2 = 0.40

σ

 2

 4

 3

 1

 0

 20

 16

 12

 8

 4

 0

σ

 0

 200

 400

 600

τ

 800

 1000

 200

 400

 600

τ

 800

 1000

FIG. 2: The ﬁrst three panels show 3 realizations of volatility sequences of length T = 1024

according to the model (19). Diﬀerent panels correspond to diﬀerent values of λ2. The last panel

is a logarithmic representation of the λ2 = 0.40 data.

In the “max-loss” limit β

1, where the single worst loss contributes to the risk measure,

the threshold value (N/T )∗ = 0.5 does not seem to depend on the volatility ﬂuctuations.

→

As β gets smaller than 1, though, the presence of these ﬂuctuations is such that the feasible

regione becomes smaller than the ideal multinormal case.

V. CONCLUSIONS

In this paper we have discussed the replica approach to portfolio optimization. The rather

general formulation of the problem allows to deal with several risk measures. We have shown

here the examples of absolute deviation, expected shortfall and max-loss (which is simply

taken as the limit case of ES). In all cases we ﬁnd that the optimization problem, when

the risk measure is estimated by using time series, does not admit a feasible solution if the

ratio of assets to data points is larger than a threshold value. As discussed in ref. 4, this is

a common feature of various risk measures: the estimation error on the optimal portfolio,

originating from in-sample evaluations, diverges as a critical value is approached. In the

expected shortfall case, we have also discussed a semi-analytic approach which is suitable

σ

 6

 4

 2

 0

 4

 0

)
σ
(
g
o
l

-4

-8

 0

10

no fluct.
λ2 = 0.01
λ2 = 0.03
λ2 = 0.10
λ2 = 0.30

T
/
N

 0.6

 0.5

 0.4

 0.3

 0.2

 0.1

 0

 0

feasible region

 0.2

 0.4

 0.6

 0.8

 1

β

FIG. 3: The phase diagram corresponding to diﬀerent values of the parameter λ2. The full line

corresponds to the absence of ﬂuctuations in the volatility distributions (i.e. στ = 1

τ ).

∀

for describing realistic time series. Our results suggest that, as far as volatility clustering is

taken into account, the phase transition is still there, the only eﬀect being the reduction of

the feasible region. As a general remark, we have shown that the replica method may prove

extremely useful in dealing with optimization problems in risk management.

Acknowledgments. We thank I. Kondor and J.-P. Bouchaud for interesting discussions.

S. C. is supported by EC through the network MTR 2002-00319, STIPCO.

[1] H. Markowitz, Portfolio selection: Eﬃcient diversiﬁcation of investments, J. Wiley & Sons,

New York (1959).

[2] P. Artzner, F. Delbaen, J. M. Eber, and D. Heath, Mathematical Finance 9, 203–228 (1999).

[3] M. M´ezard, G. Parisi, and M. .A. Virasoro, “Spin Glass theory and Beyond”, World Scientiﬁc

Lecture Notes in Physics Vol. 9, Singapore (1987).

[4] I. Kondor, Lectures given at the Summer School on “Risk Measurement and Control”, Rome,

June 9-17, 2005; I. Kondor, S. Pafka, and G. Nagy, Noise sensitivity of portfolio selection

under various risk measures, submitted to Journal of Banking and Finance.

[5] S. Ciliberti, I. Kondor, and M. M´ezard, arXiv:physics/0606015.

11

[6] H. Konno, H. Yamazaki, Management Science 37, 519 (1991); H. Konno, T. Koshizuka, IIE

Transactions 37, (10) 893 (2005).

[7] C. Acerbi, and D. Tasche, Journal of Banking and Finance 26, 1487–1503 (2002).

[8] L. Laloux, P. Cizeau, J.-P. Bouchaud, and M. Potters, Phys. Rev. Lett. 83, 1467 (1999).

[9] V. Plerou, P. Gopikrishnan, B. Rosenow, L. Nunes Amaral, and H. Stanley, Phys. Rev. Lett.

83, 1471 (1999).

[10] S. Pafka, and I. Kondor, Europ. Phys. J. B27, 277 (2002).

[11] S. Pafka, and I. Kondor, Physica A319, 487 (2003).

[12] W. H. Press, S. H. Teukolsky, W. T. Wetterling, and B. P. Flannery, “Numerical Recipes in

C”, Cambridge University Press (Cambridge, UK, 1992).

[13] see http://www.gloriamundi.org for a complete source of references.

[14] R. Rockafellar, and S. Uryasev, The Journal of Risk 2, 21–41 (2000).

[15] B. B. Mandelbrot, J. Fluid Mech. 62, 331 (1974).

[16] J.-F. Muzy, J. Delour, and E. Bacry, Eur. Phys. J. B17, 537 (2000).

12

