5
0
0
2
 
p
e
S
 
2
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
4
1
0
9
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Transfer Entropy Analysis of the Stock
Market

Seung Ki Baek, Woo-Sung Jung ∗, Okyu Kwon, Hie-Tae Moon

Department of Physics, Korea Advanced Institute of Science and Technology,
Daejeon 305-701, Republic of Korea

Abstract

In terms of transfer entropy, we investigated the strength and the direction of in-
formation transfer in the US stock market. Through the directionality of the in-
formation transfer, the more inﬂuential company between the correlated ones can
be found and also the market leading companies are selected. Our entropy analy-
sis shows that the companies related with energy industries such as oil, gas, and
electricity inﬂuence the whole market.

Key words: Transfer Entropy, Information Flow, Econophysics, Stock Market

PACS: 05.20.Gg, 89.65.Gh, 89.70.+c

1 Introduction

Recently, economy has become an active research area for physicists. They
have investigated stock markets using statistical tools, such as the correlation
function, multifractal, spin-glass models, and complex networks [1,2,3,4]. As
a consequence, it is now found evident that the interaction therein is highly
nonlinear, unstable, and long-ranged.

All those companies in the stock market are interconnected and correlated, and
their interactions are regarded as the important internal force of the market.
The correlation function is widely used to study the internal inference of the
market [5,6,7]. However, the correlation function has at least two limitations:
First, it measures only linear relations, although a linear model is not a faithful

∗ Corresponding author. Fax: +82-42-869-2510.

Email address: wsjung@kaist.ac.kr (Woo-Sung Jung).

Preprint submitted to Elsevier Science

21 October 2012

representation of the real interactions in general. Second, all it says is only that
two series move together, and not that which aﬀects which: in other words, it
lacks directional information. Therefore participants located in hubs are always
open to interpretative ambiguity: they can be either the most inﬂuential ones
or the weakest ones subject to the market trend all along. To overcome those
limitations of the linear statistics, we rely in this study on the information
theoretic approach.

Information is already an important keyword in analyzing the market or in
estimating the stock price of a given company. It is quantiﬁed in rigorous
mathematical terms [8], and the mutual information, for example, appears
as meaningful choice replacing a simple linear correlation even though it still
does not specify the direction. The directionality, however, is required to dis-
criminate the more inﬂuential one between correlated participants, and can
be detected by the transfer entropy (TE) [9].

This concept of transfer entropy has been already applied to the analysis of
ﬁnancial time series by Marschinski and Kantz [10]. They calculated the in-
formation ﬂow between the Dow Jones and DAX stock indexes and obtained
conclusions consistent with empirical observations. While they examined in-
teractions between two huge markets, we may construct its internal structure
among all participants.

2 Theoretical Background

Transfer entropy [9] from J to I is deﬁned as follows:

TJ→I = X p(in+1, i(k)

n , j(l)

n ) log

p(in+1|i(k)

n , j(l)
n )
p(in+1|i(k)
n )

.

(1)

(2)

In terms of relative entropy, it can be rephrased as the distance from the
assumption that J has no inﬂuence on I (i.e. p(in+1|i(k)
n )).
One may rewrite Eq. (1) as:

n ) = p(in+1|i(k)

n , j(l)

TJ→I = H(i(k+1)

n+1 , j(l)

n ) − H(i(k)

n , j(l)

n ) − H(i(k+1)

n+1 ) + H(i(k)
n )

= hI(k; n) − hIJ (k, l; n),

from the property of conditional entropy. Then the second equality shows
that the transfer entropy measures the change of entropy rate with knowledge
of the process J. Eq. (2) is practically useful, since the transfer entropy is

2

decomposed into entropy terms and there has been already well developed
technique in entropy estimation.

There are two choices in estimating entropy of a given time series. First, the
symbolic encoding method divides the range of the given dataset into disjoint
intervals and assign one symbol to each interval. The dataset, originally contin-
uous, becomes a discrete symbol sequence. Marschinski and Kantz [10] took
this procedure and introduced the concept called eﬀective transfer entropy.
The other choice exploits the generalized correlation integral Cq. Prichard
and Theiler [11] showed that the following holds:

Hq(x, 2ǫ) ≈ − log2[Cq(x, ǫ)],

where ǫ determines the size of a box in the box-counting algorithm. We deﬁne
the fraction of data points which lie within ǫ of x(t) by

B(x(t), ǫ) =

Θ(ǫ − |x(t) − x(s)|),

1
N X

s6=t

where Θ is the Heaviside function, and calculate its numerical value by the
help of the box-assisted neighbor search algorithm [12] after embedding the
dataset into an appropriate phase space. The generalized correlation integral
of order 1 is then given by

(3)

(4)

(5)

log C1(x, ǫ) =

log B(x(t), ǫ).

1
N X

t

Notice that Hq is expressed as an averaged quantity along the trajectory
x(t) and it implies a kind of ergodicity which converts an ensemble aver-
age Pi pi log pi = hlog pii into a time average, log pi(t). Temporal correlations
are not took into consideration since the daily data already lacks much of its
continuity.

It is rather straightforward to calculate entropy from a discrete dataset using
symbolic encoding. But determining the partition remains as a series prob-
lem, which is referred to as the generating partition problem. Even for a two-
dimensional deterministic system, the partition lines may exhibit considerably
complicated geometry [13,14] and thus should be set up with all extreme cau-
tion [15]. Hence the correlation integral method is often recommended if one
wants to handle continuous datasets without over-simpliﬁcation, and we will
be taking this route. In addition, one has to determine the parameter ǫ. In
a sense, this parameter plays a role of deﬁning the resolution or the scale
of concerns, just as the number of symbols does in the symbolic encoding
method.

3

Before discussing how to set ǫ, we remark on the ﬁnite sampling eﬀect: Though
it is pointed out that the case of q = 2 does not suﬀer much from ﬁniteness
of the number of data [16], then the positivity of entropy is not guaranteed
instead[9]. Thus we choose the conventional Shannon entropy, q = 1 through-
out this paper. There have been works done [17,18,19] on correcting entropy
estimation. These correction methods, however, can be problematic when cal-
culating transfer entropy, since the ﬂuctuations in each term of Eq. (2) are not
independent and should not be treated separately [20]. We actually found that
a proper selection of ǫ is quite crucial, and decided to inactivate the correction
terms here.

A good value of ǫ will discriminate a ﬁnite eﬀect from zero. Without a priori
knowledge, we need to scan the range of ǫ in order to ﬁnd a proper reso-
lution which yields meaningful results from a time series. For reducing the
computational time, however, we resort to the empirical observation that an
airline company is quite dependent on the oil price, but not in the opposite
direction. Fig. 1 shows this unilateral eﬀect: the major oil companies, Chevron
and Exxon Mobile, have inﬂuence over Delta Airline. From ǫ ≃ 0.002 which
maximizes the diﬀerence between two directions (Fig. 2), we choose the ap-
propriate scale for analyzing the data. We set k = l = 1 in Eq. (1) since other
values does not make signiﬁcant diﬀerences.

3 Data Analysis

This study deals with the daily closure prices of 135 stocks listed on New York
Stock Exchange (NYSE) from 1983 to 2003, obtained through the website [21].
The companies in a stock market are usually grouped into business sectors or
industry categories, and our data contain 9 business sectors (Basic Materials,
Utilities, Healthcare, Services, Consumer Goods, Financial, Industrial Goods,
Conglomerates, Technology) and 69 industry categories. The following method
shows how the information ﬂows between the groups: Let i be the company
index of the group A, and j be that of the group B. The information ﬂow
between these two groups is deﬁned as a simple sum:

ρA→B = X
i,j

Ti→j.

(6)

Then the diﬀerence between ρA→B and ρB→A measures the disparity in inﬂu-
ences of the two groups.

Grouping into business sectors, however, does not exhibit clear directionality:
the inﬂuence of the A sector just alternates from that of the B sector. This
unclarity comes from the fact that a business sector contains so many diverse

4

companies that its directionality just cancels out. In the other hand, it can
be said that each of the business sectors forms an almost complete cluster [6]
and there are no signiﬁcant relations among them.

Hence we employ more detailed industry category grouping. Then we have to
exclude the categories which contain only one element, and Table 1 lists the
remaining industry categories we use.

As in our previous observation, it is veriﬁed again that oil companies and air-
line companies are related in a unilateral way: The category 20, Major Oil &
Gas, has continuing inﬂuence over the category 19, Major Airline, during the
whole 14 periods under examination (ρ20→19 > 0) . One can easily ﬁnd such
relations in other categories: for example, the category 20 always inﬂuences on
the categories 15 (Independent Oil&Gas), 22 (Oil&Gas Equipment&Services),
and 23 (Oil&Gas Reﬁning&Marketing). It also aﬀects the category 27 (Re-
gional Airlines) over 13 periods and maintains its power on the whole market
during 11 periods (Fig. 3).

It is well-known that economy greatly depends on the energy supply and
price such as oil and gas. Transfer entropy analysis quantitatively proves this
empirical fact. The top three inﬂuential categories (in terms of periods) are
the categories 10 (Diversiﬁed Utilities), 12 (Electric Utilities) and 20. The
ten companies in the categories 10 and 12 are again related to the energy
industry, such as those for holding, energy delivery, generation, transmission,
distribution, and supply of electricity.

On the contrary, an airline company is sensitive to the tone of the market.
These companies receive information from other categories almost all the time
(category 19: 11 periods, category 27: 12 periods). The category 8 (Credit
Services) and the category 9 (Diversiﬁed Computer Systems, including HP
and IBM) are also market-sensitive as easily expected.

4 Conclusion

We calculated the transfer entropy with the daily data of the US market.
The concept of transfer entropy provides a quantitative value of general cor-
relation and the direction of information. Thus it reveals how the information
ﬂows among companies or groups of companies, and discriminates the market-
leading companies from the market-sensitive ones. As commonly known, the
energy such as natural resources and electricity is shown to greatly aﬀect
economic activities and business barometer. This analysis may be applied to
predicting the stock price of a company inﬂuenced by other ones. In compar-
ison with the traditional tools like the correlation matrix theory, TE proves

5

its possibility as a promising measure to detect directional information.

We thank D.-H. Kim, H. Jeong and J.-S. Yang for helpful discussion.

Acknowledgements

References

[1] W.B. Arthur, S. N. Durlauf, D. A. Lane, The Economy as an Evolving Complex

System II, (Perseus Books, 1997)

[2] R. N. Mantegna, H. E. Stanley, An Introduction to Econophysics, (Cambridge

University Press, 2000)

Press, 2000)

[3] J.-P. Bouchaud, M. Potters, Theory of Financial Risks (Cambridge University

[4] B. B. Mandelbrot, Quant. Finance 1 (2001) 124.

[5] R. N. Mantegna, Eur. Phys. J. B, 11 (1999) 193

[6] J.-P. Onnela, A. Chakraborti, K. Kaski, J. Kert´esz, A. Kanto, Phys. Rev. E 68

(2003) 056110.

[7] W.-S. Jung, S. Chae, J.-S. Yang, H.-T. Moon, to be published in Physica A.

[8] C. E. Shannon, W. Weaver, The Mathematical Theory of Information

(University of Illinois Press, 1994).

[9] T. Schreiber, Phys. Rev. Lett 85 (2000) 461.

[10] R. Marschinski, H. Kantz, Eur. Phys. J. B 30 (2002) 275.

[11] D. Prichard, J. Theiler, Physica D 84 (1995) 476.

[12] H. Kantz, T. Schreiber, Nonlinear Time Series Analysis, (Cambridge University

Press, 1997).

[13] P. Grassberger, H. Kantz, Phys. Lett. A 113 (1985) 235.

[14] F. Christiansen, A. Politi, Phys. Rev. E 51 (1995) R3811.

[15] E. M. Bollt, T. Stanford, Y.-C. Lai, K. Zyczkowski, Phys. Rev. Lett. 85 (2000)

3524.

[16] P. Grassberger, I. Procaccia, Physica D, 9 (1983) 189.

[17] P. Grassberger, Phys. Lett. A 128 (1988) 369.

6

[18] H. Herzel, A. O. Schmitt, W. Ebeling, Chaos Solitons & Fractals 4 (1994) 97.

[19] M. S. Roulston, Physica D 125 (1999) 285.

[20] A. Kaiser, T. Schreiber, Physica D 166 (2002) 43.

[21] http://ﬁnance.yahoo.com

7

 

 

(a)

12

10

8

4

2

0

 

 

 DAL->XOM

 DAL->XOM

 XOM->DAL

 XOM->DAL

bit

6

 

bit

6

(b)

12

10

8

4

2

0

0.000

0.002

0.004

0.006

0.008

0.010

0.000

0.002

0.004

0.006

0.008

0.010

Fig. 1. Transfer entropy as function of ǫ between (a) Delta Airlines (DAL) and
Chevron (CVX) and (b) DAL and Exxon Mobil (XOM).

(a)

(b)

1.0

1.0

 

 

0.8

0.8

0.6

0.6

bit

 

bit

0.4

0.4

0.2

0.2

0.0

0.0

0.000

0.002

0.004

0.006

0.008

0.010

0.000

0.002

0.004

0.006

0.008

0.010

Fig. 2. The diﬀerence between (a) TDAL→CVX and TCVX→DAL and (b) TDAL→XOM
and TXOM→DAL

8

Table 1
Industry category index in alphabetic order

#

industry category

Aerospace/Defense

Auto Manufacturers

Beverages

Business Equipment

Chemicals

Communication Equipment

Conglomerates

Credit Services

Diversiﬁed Computer Systems

Diversiﬁed Utilities

Drug Manufacturers

Electric Utilities

Farm&Construction Machinery

Health Care Plans

Independent Oil&Gas

Industrial Metals&Minerals

Information Technology Services

Lumber, Wood Production

Major Airlines

Major Oil&Gas

21 Medical Instruments&Supplies

Oil&Gas Equipment&Services

Oil&Gas Reﬁning&Marketing

Personal Products

Processing Systems&Products

Railroads

Regional Airlines

Specialty Chemicals

Etc.

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

22

23

24

25

26

27

28

29

9

7
2

2
2

9
1

8
91

3
82

5
261

3
1

6
1

4
41

5
2

7
1

1
2

1
51

6
2

4
712

8
32

0
2

2
1

0
1

27
22
19
18
9
23
8
15
6
2
13
16
14
4
25
17
21
11
5
26
24
1
7
28
3
20
12
10

Fig. 3. ρij over the whole 14 periods. The degree of darkness represents the number
of periods when i is aﬀected by j, and ρii’s are left blank. For example, the category
10 aﬀects almost all the other categories and is aﬀected by the categories 12 and
25 in a few periods. The row of a market-leading category is bright on the average,
while that of a market-sensitive one is dark.

10

