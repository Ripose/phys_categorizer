Bayesian networks for enterprise risk assessment

C. E. Bonafede †, P. Giudici ††∗

University of Pavia

(Dated: February 2, 2008)

Abstract

According to diﬀerent typologies of activity and priority, risks can assume diverse meanings and

it can be assessed in diﬀerent ways.

In general risk is measured in terms of a probability combination of an event (frequency) and

its consequence (impact). To estimate the frequency and the impact (severity) historical data or

expert opinions (either qualitative or quantitative data) are used. Moreover qualitative data must

be converted in numerical values to be used in the model.

In the case of enterprise risk assessment the considered risks are, for instance, strategic, opera-

tional, legal and of image, which many times are diﬃcult to be quantiﬁed. So in most cases only

expert data, gathered by scorecard approaches, are available for risk analysis.

The Bayesian Network is a useful tool to integrate diﬀerent information and in particular to

study the risk’s joint distribution by using data collected from experts.

In this paper we want to show a possible approach for building a Bayesian networks in the

particular case in which only prior probabilities of node states and marginal correlations between

nodes are available, and when the variables have only two states.

Keywords: Bayesian Networks, Enterprise Risk Assessment, Mutual Information

6
0
0
2
 
l
u
J
 
5
2
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
6
2
2
7
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

1

INTRODUCTION

A Bayesian Net (BN) is a directed acyclic graph (probabilistic expert system) in which

every node represents a random variable with a discrete or continuous state [2, 3].

The relationships among variables, pointed out by arcs, are interpreted in terms of con-

ditional probabilities according to Bayes theorem.

With the BN is implemented the concept of conditional independence that allows the

factorization of the joint probability, through the Markov property, in a series of local terms

that describe the relationships among variables:

f (x1, x2, ..., xn) =

n
Q

i=1 f (xi|

pa(xi))

where pa(xi) denotes the states of the predecessors (parents) of the variable Xi (child)

[1, 2, 3, 6]. This factorization enable us to study the network locally.

A Bayesian Network requires an appropriate database to extract the conditional probabil-

ities (parameter learning problem) and the network structure (structural learning problem)

[1, 3, 13, 16].

dependencies among variables.

The objective is to ﬁnd the net that best approximates the joint probabilities and the

After we have constructed the network one of the common goal of bayesian network is

the probabilistic inference to estimate the state probabilities of nodes given the knowledge

of the values of others nodes. The inference can be done from children to parents (this is

called diagnosis) or vice versa from parents to children (this is called prediction) [2, 13, 15].

However in many cases the data are not available because the examined events can be

new, rare, complex or little understood. In such conditions experts’ opinions are used for

collecting information that will be translated in conditional probability values or in a certain

joint or prior distribution (Probability Elicitation) [11, 12, 16, 19].

Such problems are more evident in the case in which the expert is requested to deﬁne

too many conditional probabilities due to the number of the variable’s parents. So, when

possible, is worthwhile to reduce the number of probabilities to be speciﬁed by assuming

some relationships that impose bonds on the interactions between parents and children as

for example the noisy-OR and its variation and genralization [3, 9, 10, 14, 16].

In the business ﬁeld, Bayesian Nets are a useful tool for a multivariate and integrated

2

analysis of the risks, for their monitoring and for the evaluation of intervention strategies

(by decision graph) for their mitigation [3, 5, 7].

Enterprise risk can be deﬁned as the possibility that something with an impact on the

objectives happens, and it is measured in terms of combination of probability of an event

(frequency) and of its consequence (impact).

The enterprise risk assessment is a part of Enterprise Risk Management (ERM) where

to estimate the frequency and the impact distributions historical data as well as expert

opinions are typically used [4, 5, 6, 7]. Then such distributions are combined to get the loss

In this context Bayesian Nets are a useful tool to integrate historical data with those

coming from experts which can be qualitative or quantitative [19].

distribution.

OUR PROPOSAL

What we present in this work is the construction of a Bayesian Net for having an inte-

grated view of the risks involved in the building of an important structure in Italy, where the

risk frequencies and impacts were collected by an ERM procedure unsing expert opinions.

We have constructed the network by using an already existing database (DB) where the

available information are the risks with their frequencies, impacts and correlation among

them. In total there are about 300 risks.

In our work we have considered only the frequencies of risks and no impacts. With our

BN we construct the risks’ joint probability and the impacts could be used in a later phase

of scenario analysis to evaluate the loss distribution under the diﬀerent scenarios [5].

In table 1 there is the DB structure used for network learing and in which each risk is

considered as a binary variable (one if the risk exists (yes) and zero if the risk dosen’t exist

(not)). Therefore, for each considered risk in the network there will be one node with two

states (one

Y and zero

N).

≡

≡

TABLE I: Expert values database structure (Learning table)

PARENT CHILD CORRELATION PARENT FREQ.

CHILD FREQ.

RISK A RISK B

RISK A RISK C

ρAB = 0.5

ρAC = 0.3

P(risk A = Yes)=0.85 P(risk B = Yes)=0.35

P(risk A = Yes)=0.85 P(risk C = Yes)=0.55

The task is, therefore, to ﬁnd the conditional probabilities tables by using only the cor-

3

relations and the marginal frequencies. Instead, the net structure is obtained from table 1

by following the node relationships given by correlations.

The main ideas for ﬁnding a way to construct a BN have been: ﬁrst to ﬁnd the joint

probabilities as functions of only the correlations and the marginal probabilities; second to

understand how the correlations are linked with the incremental ratios or the derivatives

of the child’s probabilities as functions of the parent’s probabilities. This choice is due to

the fact that parent and child interact through the values of conditional probabilities; the

derivatives are directly linked to such probabilities and, therefore, to the degree of interac-

tion between the two nodes and, hence with the correlation.

Afterwards we have understood as to create equations, for the case with dependent par-

ents we have used the local network topology to set the equations.

We have been able to calculate the CPT up to three parents for each child. Although

there is the possibility to generalize to more than three parents, it is necessary to have more

data which are not available in our DB. So when four or more parents are present we have

decided to divide and reduce to cases with no more than three parents. To approximate

the network we have “separated” the nodes that give the same eﬀects on the child (as for

example the same correlations) by using auxiliary nodes [3]. When there was more than

one possible scheme available we have used the mutual information (MI) criterion as a dis-

criminating index by selecting the approximation with the highest total MI; this is the same

to choose the structure with the minimum distance between the network and the target

distribution [17, 18].

We have analyzed ﬁrst the case with only one parent to understand the framework, then

it has been seen what happens with two independent parents and then dependent. Finally

we have used the analogies between the cases with one and two parents for setting the

equations for three parents.

One parent case solution

The case with one parent (ﬁgure 1) is the simplest. Let P(F) and P(C) be the marginal

probability given from expert (as in table 1):

For the parent, F, we have: P(F=Y)=x, P(F=N)=1-x;

•

4

For the child, C, we have: P(C=Y)=y, P(C=N)=1-y;

•

The equations to ﬁnd either the conditional probabilities or the joint probabilities are:

FIG. 1: One parent scheme

CPT equation system Joint equation system

α1x + α2(1

x) = y;

c1 = ρM + xy;

−
α2 = k;

α1

−

α1 + α3 = 1;

α2 + α4 = 1;

−

xy;

xy;

c2 = y

c3 = x

c4 = 1

ρM

ρM

y

−

−

−

−

−
x + ρM + xy;

where k = ρq
probabilities.

V ar[C]
V ar[F ]; whit αi and ci we indicate respectively the conditional and the joint

Considering that probabilities ci and αi must be positive either the marginal probabilities

or the correlation value should be constrained. If the marginal probabilities are ﬁxed then

the correlation values must be constrained, which will be normally the case, as estimates of

probabilities are more reliable.

It is not possible to have any value of correlation given the marginal probabilities. Indeed,

as we want to maintain the marginal probabilities as ﬁxed by the expert, correlation limits

can be determined as follows:

ρ >

−

xy

M = A; ρ > y+x(1

−
M

y)

1

−

= D; ρ < x(1
−

y)

M = B; ρ < y(1

x)

M = C;
−

and the correlation interval will be:

ρ

[max(A, D); min(B, C)] ;

∈

Two parents case solutions

This case (ﬁgure 2) is more complicated than the one before. In this situation a further

diﬃculty is that the given expert correlations are only pairwise marginal and, therefore, we

need more information to ﬁnd the CPT.

5

For example the joint moment among the nodes which is not in the DB. Consequently

there can be more than one CPT, corresponding to diﬀerent values of the joint moment, for

the same marginal correlation and probability.

FIG. 2: Two independent parents (a) and dependent parents (b)

The joint moment becomes thus a project parameter to be set by using an appropriate

criterion. We deﬁne the standardized joint moment among three variables to be:

ρNiNjNk = E[(Ni

E[Nj])(Nk−
E[Ni])(Nj
−
−
3√V ar[Ni]V ar[Nj ]V ar[Nk]

E[Nk])]

.

To choose among such CPTs we have used the total mutual information (Itotal) by select-

ing that CPT with the ρNiNjNk that gives the minimum Itotal.

In this case we have to distinguish between independent and dependent parents. The

solutions are:

−

−

+(α3
∂f
∂x = (α1
∂f
∂z = (α1
−
2
f
∂
f
∂x∂z = ∂
α1 + α5 = 1

2

α2 + α6 = 1

α3 + α7 = 1

α4 + α8 = 1

CPT equation system for independent parents

Joint equation system for dependent parents

f (x, z) = (α1

α2

α3 + α4)xz + (α2

α4)x+

c1 = ρABF MABF + xyz + (ρAF MAF )z+

−
α4)z + α4 = y

−

−

+(ρBF MBF )x + (ρAB MAB)y

α2

α2

−

−

α3 + α4)z + (α2

α3 + α4)x + (α3

−

x(1−x)

α4) = (ρAF )(MAF )
α4) = (ρBF )(MBF )
α3 + α4) = (ρABF )(MABF )
x(1−x)z(1−z)

z(1−z)

−

∂z∂x = (α1

α2

−

−

c1 + c5 = ρBF MBF + zy

c1 + c3 = ρAF MAF + xy

c1 + c2 = ρAB MAB + xz

c1 + c2 + c3 + c4 = x

c1 + c5 + c6 + c2 = z

c1 + c3 + c5 + c7 = y

c8 = 1

7
i=1 ci

− P

where MBF =

p
and MABF = 3
p

−

−

z(1

z)y(1

y), MAF =

x(1

x)y(1

y), MAB =

x(1

x)z(1

z)

p

−

−

p

−

−

x(1

x)z(1

z)y(1

y). As before the αi and ci are respectively the

−

−

−

conditional and the joint probabilities.

The problem is now setting the marginal correlations when those given from experts are

not consistent with the marginal probabilities. Diﬀerently from the case with one parent

where the correlation belongs to an interval, with two parents the admissible pairs (ρAF , ρBF )

6

can be shown to belong to an area.

To approach this problem we have decided to decrease the values of the two correlations

ρBF and ρAF with a ﬁxed step by maintaining their relative diﬀerence. At each step we

veriﬁed the existence of a value of ρABF which supports the new pair (ρAF , ρBF ). If it exists

the process is stopped, otherwise it goes to the next step; and so on.

If the correlation ρAB is diﬀerent from zero (dependent parents), we can set it in advance

using the interval obtained for the case of one parent; afterward the ρAB’s value is used

into the joint equation system. Then we can work again only on the pair (ρAF , ρBF ) by

considering the same procedure for independent parents and selecting ρNiNjNk .

Three parents case solutions

As before two equation systems are obtained. One system for the case with independent

(see ﬁgure 3 a) parents by which the CPT is directly calculated; another one when there are

some correlations between parents (see ﬁgure 3 b) and in this case the joint probabilities

are calculated instead of the conditional ones. To deﬁne the equation systems the analogies

between the cases with one and two parents have been exploited.

FIG. 3: Three independent parents (a) and dependent parents (b).

The solutions for independent and dependent parents are in table 2. In such equations,

obviously, there will be more missing data which are all the standardized joint moments

among every two parents and the child and among all parents and the child. So what we do

in such a situation is to use the procedure for the case of two parents for each pair of nodes

and set the correlation values such that they will be feasible for the all couples. Note that

the correlation levels are now less than in previous cases. Moreover in this case the stan-

dardized joint moment among all variables is set at zero to make the research less complex.

Furthermore, diﬃculties arise when there are large diﬀerences among the parents’

7

marginal probabilities. Therefore, when there are more than three parents, we have de-

cided to split them. Parents are split from the others by using the mutual information

criterion [17, 18].

As before, for the case of dependent parents to select the feasible marginal correlations

and the standardized joint moments, we start to look for the admissible correlation between

the nodes with one parent (A and B), then for the nodes with two parents (C has B and

A as predecessor) and ﬁnally we set the joint moment and marginal correlations for the

node with three parents (F). Obviously, now the procedure is more complex and it is more

diﬃcult to select the parameters.

TABLE II: Equation systems for three parents scheme

CPT equation system for independent parents

Joint equation system for dependent parents

f (x, z, w) = (α1

α2

α3 + α4

α5 + α6 + α7

α8)xzw+ c1 = ρABCF MABCF + xyzw + ρABC MABC y + ρABF MABF w+

−

−
α6 + α8)xz + (α3

−

α4

α7 + α8)wz+

−

−

−

−

−

α7 + α8)wz + (α6

α8)z + (α4

α8)x+

+ρAC MAC zy + ρBC MBC xy + ρAF MAF xy+

+ρACF MACF z + ρBCF MBCF x + ρAB MABwy+

α8)w + α8 = y
−
(ρAF )√x(1−x)y(1−y)
x(1−x)
(ρBF )√z(1−z)y(1−y)
z(1−z)
(ρCF )√w(1−w)y(1−y)
w(1−w)

(ρABF )

(ρABF )

(ρABF )

3√x(1−x)z(1−z)y(1−y)
x(1−x)z(1−z)
3√w(1−w)z(1−z)y(1−y)
w(1−w)z(1−z)
3√w(1−w)x(1−x)y(1−y)
x(1−x)w(1−w)

(ρABCF )

4√w(1−w)z(1−z)y(1−y)x(1−x)
x(1−x)z(1−z)w(1−w)

+ρBF MBF xw + ρCF MCF xz

c1 + c2 + c3 + c4 + c5 + c6 + c7 + c8 = w

c1 + c2 + c3 + c4 + c9 + c10 + c11 + c12 = x

c1 + c2 + c5 + c6 + c9 + c10 + c13 + c14 = z

c1 + c3 + c5 + c7 + c9 + c11 + c13 + c15 = y

c1 + c2 = ρABC MABC + xyz + ρAB MABw + ρAC MAC z + ρBC MBC x

c1 + c9 = ρABF MABF + xyz + ρAF MAF z + ρBF MBF x + ρAB MAB y

c1 + c3 = ρACF MACF + xyz + ρAF MAF w + ρCF MCF x + ρAC MAC y

c1 + c5 = ρBCF MBCF + xyz + ρBF MBF w + ρCF MCF z + ρBC MBC y

c1 + c2 + c9 + c10 = ρAB MAB + xz

c1 + c2 + c3 + c4 = ρAC MAC + xw

c1 + c3 + c9 + c11 = ρAF MAF + xy

c1 + c2 + c5 + c6 = ρBC MBC + zw

c1 + c3 + c5 + c7 = ρCF MCF + wy

c1 + c5 + c9 + c13 = ρBF MBF + zy

c16 = 1

15
i ci

− P

+(α2

+(α5

α4

α6

−

−

−

−

2

+(α7
∂f
∂x =
∂f
∂z =
∂f
∂w =
f
∂
∂x∂z =
f
∂
∂w∂z =
∂
f
∂x∂w =
f
∂x∂w∂z =
α1 + α9 = 1

∂

2

2

3

α2 + α10 = 1

α3 + α11 = 1

α4 + α12 = 1

α5 + α13 = 1

α6 + α14 = 1

α7 + α15 = 1

α8 + α16 = 1

CONCLUSION

So far we have seen that using the equation systems for conditional and joint probabilities

the CPTs can be obtained. The method can be generalized to the case with more three

parents, but there are problems in setting more parameters (standardized joint moment)

and in looking for more complicated feasible marginal correlation areas.

8

So to develop a network we propose to use, separately, ﬁrstly the equations and procedure

for the one parent; secondly those for two parents distinguishing when they are dependent

and not. Finally we use the equations and the procedures, when possible, for the three

parents case by distinguishing also in this situation between dependent and independent

parents; otherwise we split one parent from the others by using the mutual information as

splitting index [17, 18].

We remark that we need to reduce to a more simple case those conﬁgurations with more

than three parents. We can achieve this trying to estimate a local approximate structure,

with only one, two and three parents, by ”separating” those that give diﬀerent eﬀects on

the child (as for instance diﬀerent incremental ratios). If there are more schemes available

for the substitution we select that with the highest MI (Itotal) [17, 18].

It is important to be noted that such method is modular, this is if we add or delete a

node we can use the appropiate system (one, two or three nodes) to according to we add or

delete a parent or a child.

ACKNOWLEDGMENTS

The authors acknowledge ﬁnancial support from the MIUR-FIRB 2006-2009 project and

MUSING project contract number 027097.

∗ †bonafede@eco.unipv.it; ††giudici@unipv.it; URL: www.datamininglab.it

[1] Heckerman D. (1996). A tutorial on learning with Bayesian networks. Microsoft Research tech.

report MSR-TR-95-06. Revised November 1996, from http://research.microsoft.com.

[2] Cowell R.G., Dawid A. P., Lauritzen S.L. and Spiegelhalter D.J. (1999). Probabilistic Networks

and Expert Systems. New York, USA: Springer.

[3] Jensen F.V. (2001). Bayesian Networks and Decision Graphs. New York, USA: Springer.

[4] Cruz M.G. (2002). Modeling, measuring and hedging operational risk. West Sussex, England:

[5] Alexander C.(Ed.). (2003). Operational Risk, regulation analysis and management. London,

John Wiley and Sons.

England: Prentice Hall.

9

[6] Giudici P. (2003). Applied Data Mining. West Sussex, England: John Wiley and Sons.

[7] Cruz M.G.(Ed.). (2004). Operational risk modeling and Analysis. London, England: Risk

Books.

[8] Fanoni F., Giudici P. and Muratori G.M. 2005. Operational risk: measurement, modelling

and mitigation. Milan, Italy: Il Sole 24 Ore.

[9] Zagorecki A., and Druzdzel M. (2004). An Empirical Study of Probability Elicitation un-

der Noisy-OR Assumption. In Proceedings of the Seventeenth International Florida Artiﬁcial

Intelligence Research Society Conference (FLAIRS 2004), pp 800-885.

[10] Francisco J.D., and Severino F.G. (2003). Eﬃcient Computation for the Noisy MAX. Inter-

national journal of intelligent systems, Vol. 18, pp 165-177.

[11] Wiegmann D.A. (2005). Developing a Methodology for Eliciting Subjective Probability Es-

timates During Expert Evaluations of Safety Interventions: Application for Bayesian Belief

Networks. Aviation Human Factors Division, October, from www.humanfactors.uiuc.edu.

[12] Daneshkhah A.R. (2004). Uncertainty in Probabilistic Risk Assessment: A Review. The Uni-

versity Of Sheﬃeld, August 9, from http://www.shef.ac.uk/beep/publications.html.

[13] Murphy K.P. (2001). An introduction to graphical models. A Brief Introduction to Graphical

Models and Bayesian Networks, May 10, from http://www.cs.ubc.ca.

[14] Agnieszka 0., Druzdzel M. and Wasyluk H. (2001). Learning Bayesian network parameters

from small data sets: application of Noisy-OR gates. International journal of Approximate

Reasoning, Vol. 27, pp 165-182.

[15] Jaakkola T.S. and Jordan M.I. (1999). Variational probabilistic inference and the QMR-DT

database. Journal of Artiﬁcial Intelligence Research, Vol. 10, pp 291-322.

[16] Druzdzel M.J. and van der Gaag L.C. (2000). Building Probabilistic Networks: Where Do the

Numbers Come From? IEEE Transactions on Knowledge and Data Engineering, Vol. 12(4),

pp 481-486.

[17] Williamson J. (2000). Approximating discrete probability distributions with Bayesian net-

works IEEE Transactions on Information Theory, Vol. 14(3), pp 462-467.

[18] Kleiter G.D. and Jirousek R. (1996). Learning Bayesian Networks under the Control of Mu-

tual Information Proceedings in Information Processing and Management of Uncertainty in

Knowledge-Based Systems, pp 985-990.

[19] Druzdzel M.J. and van der Gaag L.C. (1995). Elicitation of Probabilities for Belief Networks:

10

Combining Qualitative and Quantitative Information Proceedings of the Eleventh Conference

on Uncertainty in Artiﬁcial Intelligence, pp 141-148.

11

