6
0
0
2
 
l
u
J
 
0
3
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
3
8
2
7
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Complexity analysis of the stock market

Joongwoo Brian Park, ∗ Jeong Won Lee, ∗ Jae-Suk Yang,
Hang-Hyun Jo ∗∗and Hie-Tae Moon

Department of Physics, Korea Advanced Institute of Science and Technology,
Daejeon 305-701, Republic of Korea

Abstract

We studied complexity of the stock market by modeling ǫ-machine of Standard
and Poor’s 500 index from February 1983 to April 2006 using causal-state splitting
reconstruction algorithm. We found that the statistical complexity and the number
of causal states of constructed ǫ-machines have decreased for twenty years and that
the average memory length needed to predict the future optimally has become
shorter. These results support that the randomness of market has increased and the
information is delivered to the economic agents more rapidly in year 2006 than in
year 1983 and hence immediately applied to the market prices.

Key words: econophysics, computational mechanics, statistical complexity
PACS: 89.65.-s, 89.65.Gh, 89.75.-k

1 Introduction

Financial systems have been one of active research ﬁelds for physicists. This
interdisciplinary research area called econophysics has been investigated by
means of various statistical methods, such as the correlation function, mul-
tifractality, minimal spanning tree, and agent-based models [1,2,3,4,5,6]. Re-
cently many empirical time series in ﬁnancial markets become available and
has been also investigated by the rescaled range (R/S) analysis to test the
presence of correlations [7] and detrended ﬂuctuation analysis to detect long-
range correlations embedded in seemingly non-stationary time series [8,9] and
so on.
∗ The ﬁrst two authors contributed equally to this work.
∗∗Corresponding author.

Email address: kyauou2@kaist.ac.kr (Hang-Hyun Jo).

Preprint submitted to Elsevier Science

21 February 2014

In this paper we adopt the computational mechanics (CM) based on the in-
formation and computation theory to investigate the complexity of the stock
market. Despite its strong functionality, CM has been applied only to analyze
abstract models such as cellular automata [10,11] and Ising spin system [12],
or empirical data in the geomagnetism [13] and in the atmosphere [14]. We
believe that CM enables the complexities and structures of diﬀerent sets of
data to be quantiﬁably compared and that it directly discovers intrinsic causal
structure within the data [13]. This approach also shows how to infer a model
of the hidden process that generated the observed behavior.

We examined the tick data of Standard and Poor’s 500 (S&P500) index from
February 1983 to April 2006 by constructing deterministic ﬁnite automata
called “epsilon-machine” [15] from the time series and by calculating the statis-
tical complexity from the constructed machine. ǫ-machine can be constructed
by causal state splitting reconstruction (CSSR) algorithm [16]. The ǫ-machine
captures the patterns and regularities in the observations in a way that re-
ﬂects the causal structure of the process. With this model in hand, we can
extrapolate beyond the original observations to predict future behavior [17].
The constructed ǫ-machine is a step toward the eventual use of such machine
in ﬁnding eﬀective patterns embedded in the price index of stock market. We
analyzed the result in relation to eﬃcient market hypothesis (EMH).

2 Principles

2.1 ǫ-machine

At ﬁrst we introduce the basics regarding to the ǫ-machine and the statistical
complexity as one of complexity measures.

←→
S can be divided into two semi-inﬁnite halves, i.e. a future
An inﬁnite string
←−
−→
S and a history
S . A causal state is deﬁned as a set of histories that have the
same distribution of conditional probabilities for all the futures. ǫ is a function
that maps each history to a set of histories. Each set corresponds to a causal
state:

ǫ(←−s ) = {

←−
s′ | P (~SL = ~sL |
←−
←−
S , L ∈ Z+},
s′ ∈

~sL ∈ ~SL,

←−
S = ←−s ) = P (~SL = ~sL |

←−
S =

←−
s′ ),

(1)

where SL = Si, Si+1, · · · , Si+L, that is, L consecutive random variables tak-
ing values from the ﬁnite set A. The transition probability T (a)
ij denotes the

2

probability of generating a symbol a when making the transition from state Si
to state Sj [17,18]. The combination of the function ǫ from histories to causal
states with the labeled transition probabilities T (a)
is called the ǫ-machine [17],
ij
which represents a computational model underlying the given time series.

2.2 Statistical complexity and topological complexity

From the constructed ǫ-machine the Pr(Si), the probability of ﬁnding the
system in the ith state after the machine has been running inﬁnitely long is
calculated. Then the statistical complexity and the topological complexity are
deﬁned as

Cµ ≡ −

Pr(Si) log2 Pr(Si),

X
{Si}

(2)

(3)

C0 ≡ log2 kSk,
where S is the set of causal states and kSk is the number of states [18]. Cµ
measures the minimum amount of historical information required to make
optimal forecasts [12,14]. By the deﬁnitions of the statistical and topological
complexities, the topological complexity is the upper bound of the statistical
one. And the equality holds when the distribution is uniform, that is, for
all causal states Pr(Si) = 1/kSk. As the probability distribution of causal
states deviate from uniformity, the statistical complexity becomes smaller and
therefore far from the topological complexity. Finally, when dealing with the
ﬁnite series the length of considered string L in Eq. (1) should be limited to
a ﬁnite number.

3 Empirical data analysis

Using the CSSR algorithm, we construct the ǫ-machines for the S&P500 index
from February 1983 to April 2006 for a time window of one year and shifting
the window by one month. The time series of S&P500 index is shown in Fig.
1. In order to construct the ǫ-machine, the log return series of price index R =
R1R2 · · · Rt · · · are converted into a new binary time series F = F1F2 · · · Ft · · · .
Rt and Ft are deﬁned as following:

Rt ≡ ln Yt+∆t − ln Yt,

Ft ≡

0

1






for Rt < 0

for Rt > 0

,

3

(4)

(5)

where Yt is the price at time t and ∆t is the time interval which is set to a
quarter of one minute. We used only intra-day returns to avoid the discontinu-
ous jumps due to the overnight eﬀects. Before constructing the ǫ-machine, we
should decide the value of the block size L. According to Ref. [13], resolvable
but as yet unresolved structure is described as hidden structure. This hidden
structure can be resolved by increasing the ﬁnite memory of the machine,
which is equal to the block size L. On the other hand, it has been recom-
mended to set L lower than log2 N, where N is the total length of the series
when the series is composed of two symbols. We set L to 6, which give the
most reliable result among diﬀerent times. This indicates that the machine
has a memory of one and a half minute. In other words, one and a half minute
is enough time for the machine to be fully analyzed and constructed based on
this data.

Two diﬀerent ǫ-machines of the S&P500 index at diﬀerent times are depicted
in Figs. 2 and 3. Each numbered node represents a causal state, while each
arc joining one node to another is associated with transition. On each arc the
generated symbol is on the left side of the bar and the transition probability
of that symbol is on right side of the bar. For example, in Fig. 3 there is an
arc coming out from the 0th causal state, which goes back to itself and the
number on the arc reads (1 | 0.634742). This means that after the 0th causal
state, the generated symbol will be 0 with the probability of 0.634742. Since
there are only two symbols, 0 and 1, the probability of 0 being the generated
symbol would be 0.365258 and this is written as (0 | 0.365258). This case is
represented with an arc joining the 0th causal state and the 1st causal state.
The directions of these arcs tell us which causal state will be followed, after
the symbol 0 or 1 is added to the 0th causal state. In order to see more details,
we should investigate the histories of each causal state. The histories of each
causal state are shown in Table 1. The histories of the 0th causal states in
Fig. 3 can be found in the ﬁrst row of Table 2. If we add 1 on the right end
of each history and limit the length to 6, we can see that all the resulting
histories remain included in the 0th causal state (e.g., 000011 → 000111).
The opposite case of adding 0 on the right end, all of the resulting histories
are found in the 1st causal state (e.g., 000011 → 000110). The opposite case
is when a symbol 0 is followed by the 0th causal state. In conclusion, from
the constructed ǫ-machine we can predict not only the next generated symbol
with a certain probability but also the next ﬁnite consecutive symbols with a
probability that is a product of transition probabilities.

Next, we found that both the topological and statistical complexities of S&P500
index have a tendency of decreasing through time as shown in Fig. 4. Since the
time window is set to one year, many short term events in the stock market,
such as the Black Monday, do not aﬀect our analysis. Therefore we focus on
the long term behaviors of both complexities. Since the diﬀerence between the
topological and statistical complexities is not signiﬁcant for the whole range

4

of times, we can assume that the probability distribution of causal states is
almost uniform throughout time. Conclusively our main concern is reduced
to the decrease in the number of causal states, precisely, the total number of
causal states decreases from 42 in February 1983 to 4 in April 2005.

To ﬁnd the underlying principle of the decrease in the number of causal states
through time, we examine the histories of the causal states. Table 1 and 2 show
the histories of the causal states at February 1983 and at April 2005. There
are histories of length 5 and 6 composing each causal state, which will be
called s5 and s6 respectively. Only the recurrent states are listed in the Tables
because the transient ones are eliminated when constructing the ǫ-machines
[18]. All the s5 histories are included in s6 histories because the ǫ-machine is
a deterministic machine. Therefore we concentrate on the distribution of the
s6 histories for further discussion.

In February 1983, each causal state is composed of only a few s6 histories.
There are two causal states composed of three s6 histories, ﬁfteen causal states
composed of two s6 histories, and the rest of the causal states have only one
s6 history respectively. There are total sixty four s6 histories and these states
are categorized into forty two causal states. We noticed that most of the
s6 histories, which are grouped into the same causal state, have the same
consecutive symbols from the right end to some point. For example, the 1st
causal state is composed of two s6 histories, which are ‘000110’ and ‘100110.’
All the symbols from the right end to the second of the left end are the same
except the left end symbols. When there are two s6 histories in one causal
state, they have the same symbols from the right end up to ﬁve symbols.
When there are three s6 histories in one causal state, four symbols from the
right are common among them. According to Eq. (2), causal states are the
group of states with (at least approximately) the same transition probability.
We can interpret our discussion in this point of view. For instance, the 1st
causal state has two s6 histories that are the same except the left end symbol,
so the left end symbol does not change the transition probability. This means
that although the machine has a memory of length 6, we only need the past
5 symbols to predict the next generated symbol for this case. For the case
of causal states with one s6 histories, we need the whole memory of length
six or more to determine. Majority of the causal states falls under this case,
ﬁfteen causal states need memory length of ﬁve, and only two causal states
need memory length of four. Therefore it is reasonable to conclude that the
average memory length we need to predict the future at February 1983 was
six. This is equal to one and a half minute.

We analyze Table 2 in the same way. The causal states of the price index
at April 2005 are more simpliﬁed than the above case. Exactly sixty four s6
histories are grouped into four causal states. Each causal states is composed of
sixteen s6 histories. The common parts of the states are the last two symbols,

5

which is ‘11’ for the 0th causal state and ‘10’ for the 1st one and so on. The
ﬁrst four symbols of each history are all the possible matches of ‘0’s and ‘1’s.
The average memory length to predict the future at April 2005 was two.

In short, by examining the histories of the causal states, we found that the
average memory length needed to predict the future has decreased from six in
1983 to two in 2006. This can explain the decreasing topological complexity
and statistical complexity through time. We call the common part mentioned
above an ‘eﬀective pattern.’ The transitions between states are only aﬀected
by the eﬀective pattern so that each causal state should have a unique eﬀec-
tive pattern. As the average length of these eﬀective patterns becomes shorter,
the resulting number of eﬀective patterns decreases and so does the number
of causal states. Only the eﬀective patterns determine the causal states and
therefore contribute to predict the future. Although we had set the maximum
pattern length to six, the average length of the eﬀective pattern changes from
time to time. The length of the eﬀective pattern can be interpreted as a corre-
lation interval. In the year of 1983, we had to look back ﬁve or six steps from
the past to predict the price index at the next step. This means that the price
index is aﬀected by all the correlations between these intervals. However in
2006, we only need to look two steps behind to predict, which means that the
correlation interval has decreased.

The correlation interval is closely related to the decay time of information in
the stock market [19]. The velocity of information ﬂow in year 2006 became
faster than in year 1983. So information is rapidly delivered to the agents
and immediately applied to the market prices, which results in the decreasing
correlation interval. If all the available information is instantly processed as
soon as it reaches the market, then the market is said to be eﬃcient. The
behavior of the statistical complexity of S&P500 index for the twenty years
shows that the market is becoming closer to EMH.

4 Conclusions

The statistical complexity deﬁned in CM is the intuitive and powerful con-
cept to study complicated nonlinear sequences derived from physical systems.
We analyzed the statistical complexity of the S&P500 index from year 1983 to
year 2006 by using ǫ-machines constructed from the CSSR algorithm. The sta-
tistical complexity and the number of causal states of constructed ǫ-machines
have decreased for twenty years. These results support that the randomness
of market has increased and the information in year 2006 ﬂows faster than in
year 1983. So information was rapidly delivered to the agents and immediately
applied to the market prices. This indicates that the eﬃciency of the stock
market dynamics became close to EMH.

6

In this paper, we showed the possibility of applying computational mechanics
to the stock market. By constructing ǫ-machines from the empirical time series
in the ﬁnancial systems, we found out the average memory length needed
to predict the future with certain probabilities. In addition the statistical
complexity would be a powerful tool of comparing diﬀerent stock markets and
diﬀerent companies in a stock market too.

References

[1] W. B. Arthur, S. N. Durlauf, D. A. Lane (Eds.), The Economy as an Evolving

Complex System II, Perseus Books, 1997.

[2] R. N. Mantegna, H. E. Stanley, An Introduction to Econophysics: Correlations

and Complexity in Finance, Cambridge University Press, 2000.

[3] J.-P. Bouchaud, M. Potters, Theory of Financial Risks, Cambridge University

Press, 2000.

[4] B. B. Mandelbrot, Quant. Finance 1 (2001) 124-130.

[5] A. D. Martino, M. Marsili, arXiv:physics/0606107 (2006).

[6] T. Kaizoji, Physica A 287 (2000) 493-506.

[7] E. E. Peters, Chaos and order in the capital markets, Wiely, 1991.

[8] C.-K. Peng, S. V. Buldyrev, S. Havlin, M. Simons, H. E. Stanley, A. L.

Goldberger, Phys. Rev. E 49 (1994) 1685-1689.

[9] Y. Liu, P. Gopikrishnan, P. Cizeau, M. Meyer, C.-K. Peng, H. E. Stanley, Phys.

Rev. E 60 (1999) 1390-1400.

[10] J. E. Hanson, J. P. Crutchﬁeld, Physica D 103 (1997) 169-189.

[11] C. R. Shalizi, K. L. Shalizi, R. Haslinger, Phys. Rev. Lett. 93 (2004) 118701.

[12] J. P. Crutchﬁeld, D. P. Feldman, Phys. Rev. E 55 (1997) 1239-1242.

[13] R. W. Clarke, M. P. Freeman, N. W. Watkins, Phys. Rev. E 67 (2003) 016203.

[14] A. J. Palmer, C. W. Fairall, W. A. Brewer, IEEE Transactions on Geoscience

and Remote Sensing 38 (2000) 2056-2063.

[15] J. P. Crutchﬁeld, K. Young, Phys. Rev. Lett. 63 (1989) 105-108.

[16] C. R. Shalizi, K. L. Shalizi, arXiv:cs.LG/0406011 (2004).

[17] C. R. Shalizi, J. P. Crutchﬁeld, J. Stat. Phys. 104 (2001) 817-879.

[18] D. Feldman, A Brief Introduction to Information Theory, Excess Entropy and
Mechanics,

Computational
http://hornacek.coa.edu/dave/Tutorial/index.html, April 1998.

[19] J.-S. Yang, S. Chae, W.-S. Jung, H.-T. Moon, Physica A 363 (2006) 377-382.

7

Causal state Histories of

Histories of

Causal state Histories of

Histories of

number

length 5 (s5)

length 6 (s6)

number

length 5 (s5)

length 6 (s6)

00101

000101 100101

01000

10011

11011

10110

10100

11010

11101

11100

10000

10001

01101

11000

10010

11001

10111

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

010011 110011

001000

011011

010110

110100

111000

101010

110111

110110

111111

010000

011010 111010

011101 111101

011100 111100

010001 110001

001101 110010

011000

010010 110010

011001 111001

010100

010111

111011

0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

00110

00001

01100

01110

01111

11110

00011

01001

00111

01010

01011

10101

00010

000010 100010

100000

100001

000110 100110

001100 101100

001110 011110

001111 101111

101110

111110

011111

001011

000100

001010

110000

100100

101000

101011

000011 100011

001001 101001

000111 100111

8

010101 110101

Table 1
The histories of all the causal states of ǫ-machine constructed from the data in
February 1983

Causal state Histories of

Histories of

Causal state Histories of

Histories of

number

length 5 (s5)

length 6 (s6)

number

length 5 (s5)

length 6 (s6)

000011 100011

2

0

1

00011

00111

01011

01111

10011

10111

11011

11111

00010

00110

01010

01110

10010

10110

11010

11110

000111 100111

001011 101011

001111 101111

010011 110011

010111 110111

011011 111011

011111 111111

000110 100110

001010 101010

001110 101110

010010 110010

010110 110110

011010 111010

011110 111110

000010 100010

3

00001

00101

01001

01101

10001

10101

11001

11101

00000

00100

01000

01100

10000

10100

11000

11100

000001 100001

000101 100101

001001 101001

001101 101101

010001 110001

010101 110101

011001 111001

011101 111101

000000 100000

000100 100100

001000 101000

001100 101100

010000 110000

010100 110100

011000 111000

011100 111100

Table 2
The histories of all the causal states of ǫ-machine constructed from the data in April
2005

9

1600

1400

1200

1000

800

600

400

200

x
e
d
n
I
 
0
0
5
P
&
S

’85

’90

’00

’05

’95
Year

Fig. 1. The time series of S&P500 index from February 1983 to April 2006.

10

1 | 0.49167

39

1 | 0.510574

0 | 0.649667

14

0 | 0.507723

0 | 0.626168

12

1 | 0.479832

0 | 0.647339

37

0 | 0.50833

16

20

0 | 0.520168

0 | 0.60615

1 | 0.352661

33

0 | 0.516188

0 | 0.489426

1 | 0.559913

0 | 0.443314

1 | 0.492277

1 | 0.350333

1 | 0.373832

2

1 | 0.272548

11

0 | 0.697084

1

0 | 0.492574

3

1 | 0.302916

0 | 0.565028

1 | 0.577508

38

1 | 0.483812

0 | 0.519355

21

1 | 0.434972

13

0 | 0.51714

4

1 | 0.666582

28

0 | 0.358876

27

1 | 0.507426

0 | 0.396024

1 | 0.34462

0 | 0.562753

0 | 0.329464

1 | 0.362227

0 | 0.353785

0 | 0.422586

1 | 0.646215

1 | 0.39385

24

0 | 0.440087

19

1 | 0.485992

1 | 0.556686

0 | 0.514008

0 | 0.637773

17

1 | 0.48286

0 | 0.367754

1 | 0.641124

18

26

0 | 0.495

9

1 | 0.345015

0 | 0.367526

1 | 0.494925

1 | 0.387701

0 | 0.505075

0 | 0.612299

1 | 0.437247

0 | 0.727452

40

23

1 | 0.652422

0 | 0.422492

0 | 0.333418

1 | 0.764303

41

1 | 0.577414

22

1 | 0.670536

1 | 0.636036

1 | 0.579624

0 | 0.363964

0 | 0.420376

1 | 0.603976

35

1 | 0.505

31

1 | 0.480645

30

1 | 0.632246

5

7

1 | 0.632474

1 | 0.712529

0 | 0.287471 32

1 | 0.79733

0 | 0.20267

6

29

25

0 | 0.235697

0 | 0.347578

1 | 0.612022

34

0 | 0.387978

1 | 0.518223

0 | 0.481777

36

15

0 | 0.654985

0 | 0.65538

10

Fig. 2. ǫ-machine of S&P500 index in February 1983 constructed by CSSR algorithm.

0

8

11

0

1 | 0.634742

0 | 0.365258

1

0 | 0.597822

1 | 0.60027

3

0 | 0.63486

1 | 0.402178

0 | 0.39973

1 | 0.36514

2

12

Fig. 3. ǫ-machine of S&P500 index in April 2005 constructed by CSSR algorithm..

 

Cµ
C
0

6

5

4

3

2

 

’85

’90

’00

’05

’95
Year

Fig. 4. The temporal behaviors of the topological complexity C0 and the statistical
complexity Cµ of S&P500 index from February 1983 to April 2006.

13

