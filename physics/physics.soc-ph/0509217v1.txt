5
0
0
2
 
p
e
S
 
6
2
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
7
1
2
9
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Management Fads, Pedagogies, and other Soft
Technologies

Jonathan Bendor
Graduate School of Business, Stanford University, Stanford, CA 94305

Bernardo A. Huberman and Fang Wu
HP Labs, Palo Alto, CA 94304

December 8, 2013

Abstract

We present a model for the diﬀusion of management fads and other
technologies which lack clear objective evidence about their merits. The
choices made by non-Bayesian adopters reﬂect both their own evaluations
and the social inﬂuence of their peers. We show, both analytically and
computationally, that the dynamics lead to outcomes that appear to be
deterministic in spite of being governed by a stochastic process. In other
words, when the objective evidence about a technology is weak, the evo-
lution of this process quickly settles down to a fraction of adopters that is
not predetermined. When the objective evidence is strong, the proportion
of adopters is determined by the quality of the evidence and the adopters’
competence.

1

1 Introduction

In domains such as management and education, organizational practices often
seem to come and go in puzzling ways. They are introduced with fanfare,
but then they diﬀuse with little evidence that they work well. While they are
sometimes discarded at later times, they are so with little conclusive evidence
about their performance. Consider, for example, Quality Circles. Possibly as
many as 90 percent of the Fortune 500 companies had adopted QCs by 1985,
but by 1987 “more than 80% of the Fortune 500 companies that adopted QCs
in the 1980s had abandoned them by 1987” [Abr96, pp. 256]. Yet one is hard
pressed to ﬁnd hard evidence of their impact, even after the fact.

Fads are so common in American education that one observer reports that
“School leaders in a whimsical mood sometimes play a parlor game called ‘Spot
That Jargon,’ in which the goal is to name as many past educational fads as
possible. The list is usually impressive.” [Las98, MC04]

This paper examines the diﬀusion of such innovations or ideas. We call
them soft technologies, not because of their physical properties but because
evidence for or against them is equivocal, inconclusive, or even nonexistent. We
contend that the choices made by adopters are quasi-rational: they reﬂect both
an attempt to assess the imperfect data surrounding such innovations as well as
a reliance on social cues, i.e., what peers have done. We argue that these two
elements are linked by what could be called Festinger’s Hypothesis: the more
equivocal the evidence, the more people rely on social cues [Fes54, pp. 118].

In this paper we present a model that considers soft technologies as those for
which (1) the objective evidence is weak and (2) people rely heavily on the prior
choices of people in similar roles. We then show that the dynamics of the model
leads to outcomes that appear to be deterministic in spite of being governed
by a stochastic process. In other words, when the objective evidence for the
adoption of a soft-technology is weak, any sample path of this process quickly
settles down to a fraction of adopters that is not predetermined by the initial
conditions: ex ante, every outcome is just as (un)likely as every other. In the
case when the objective evidence is strong, the process settles down to a value
that is determined by the quality of the evidence. In both cases the proportion
of adopters of the technology never settles into either zero or one.

1.1 Related Work

In the most highly developed mathematical models of fads—economic theories
of “herding”—decision makers also use social cues but do so in perfectly rational
ways, via Bayesian updating.1 Though we agree that social cues matter we think
that the premise of Bayesianism exaggerates the rationality of agents facing the
diﬃcult decision of whether or not to adopt a soft technology. In particular,
1There is now a large literature on informational cascades triggered by fully rational agents:
see the annotated bibliography of Bikhchandani, Hirshleifer and Welch, available on the Web
[BHW96]. For seminal papers in this line of work see [Ban92, BHW92, Wel92].

2

there is little evidence for the claim that people are perfect Bayesians. A leading
experimental economist summarizes the evidence as follows:

Much research in cognitive psychology suggests that the way in
which people form judgments of probability departs systematically
from the laws of statistics and from Bayesian updating. (This should
not be surprising, because there is no reason to think that evolution
of brain processes like memory, language, perception, categorization,
and reasoning would have adapted us to use a rule that Bayes only
“discovered” a couple of hundred years ago.) Some research points
toward systematic departures, or “biases”, which spring from a small
number of “heuristics”, like anchoring, availability, and representa-
tiveness [Cam98, pp. 171].

Thus, the theoretical value of herding models—the intriguing demonstration
that what appears to be conformity behavior in the aggregate is consistent with
perfectly rational action of individuals—should not be confused with empirical
conﬁrmation of its micro-postulates. As a purely theoretical point it is inter-
esting to recognize that perfect information-processing by individual agents is,
under certain circumstances, consistent with conformity-like behavior. But we
suspect that to the extent that such models receive empirical support, the sup-
port will be “weak” in the sense that the data on conformity or herding will also
be consistent with a wide variety of other sensible-though-suboptimal forms of
individual information-processing. Again, Camerer’s assessment of Bayesianism
is pertinent:

As a descriptive theory, Bayesian updating is weakly grounded in
the sense that there is little direct evidence for Bayesian updating
which is not also consistent with much simpler theories. Most of the
evidence in favor of Bayesian updating boils down to the fact that if
new information favors hypothesis A over B, then the judged proba-
bility of A, relative to B, rises when the information is incorporated.
This kind of monotonicity is consistent with Bayesian updating but
also with a very wide class of non-Bayesian rules (such as anchoring
on a prior and adjusting probabilities up or down in light of the
information) [Cam98, pp. 171].

In this paper we propose a model that is consistent with all of Camerer’s ob-
servations and so is an alternative to canonical herding models. Thus our agents
exhibit normatively desirable and empirically plausible monotonicity properties:
in particular, the more the social cues favor innovation A over B, the more likely
it is that an agent will select A, ceteris paribus. Yet the reasoning that underlies
such choices is adaptively rational rather than fully rational. Moreover, unlike
many adaptive models of fads, the present model generates analytical solutions,
not just computational ones.2

2Many—perhaps most—adaptive models of fads are what has come to be called “agent-
based models” and it is virtually a deﬁning feature of such models that they be computational.
(For a survey of agent-based models, including several applied to fads, see [MW02].)

3

2 The Model

A world in which people can make mistakes (e.g., adopt an inferior method of
instruction, partly because many other school districts have already done so)
and where they are inﬂuenced by the possibly erroneous, possibly correct choices
of similar decision makers is inherently probabilistic. Hence our model is built
around a probabilistic choice process.

We assume that two alternatives, A and B, diﬀuse through a population of
decision makers.3 In every period one decision maker makes up his mind about
whether to adopt A or B; this choice is ﬁnal. (In this sense the formulation is
like most “contagion” models.) The diﬀusion continues until everyone in the
population has selected either A or B. To get the process going, we assume
that initially (t = 0) at least one person has made a choice, i.e., at least one
person already champions either A or B. However, we allow for the possibility
that either option may have multiple initial champions. (One could regard these
early champions as the inventors of the two alternatives.) A useful benchmark
case to keep in mind is a fair start, in which A and B are backed by the same
number of initial champions. The numbers of A- and B-champions at t = 0 will
be denoted by m0 and n0.

The heart of the model is how agents decide on which option to adopt. As
noted earlier, we assume that there are two components to the adoption deci-
sion. The ﬁrst is based on individual judgment; the second, on social inﬂuence.
Regarding the ﬁrst component, we assume that a person isolated from social
inﬂuence would choose the objectively superior option (labeled A in our model)
with probability p. Thus p reﬂects the quality of the evidence about the relative
merits of A versus B, plus whatever a priori bias (possibly due to a folk theory)
exists. If A’s superiority is obvious then p will be close to 1; if the two alterna-
tives are nearly interchangeable or if evaluation technologies are primitive then
p will be close to 1/2. If there is an a priori, theory-driven bias against A, then
p could be less than 1/2. In general p is in (0, 1).

We assume that the impact of social inﬂuence is linearly increasing in the
proportion of the “converted” who have adopted in a particular adoption. Thus,
if Mt denotes the number of people who by period t have chosen A and Nt
denotes the number who have selected B, then the social pressure to choose
A is simply Mt/(Mt + Nt). The social pressure to choose B is, of course,
Nt/(Mt+Nt).4 (We will use m0 and n0 to denote the initial number of adherents
to A and B, respectively.)

Since we are trying to construct a simple benchmark model that has a clean
structure, we assume that an agent’s choice is simply a weighted average of the
3We shall often interpret A and B as competing innovations, but the model allows for
diﬀerent interpretations. For example, one of the options could be the population’s status
quo alternative while the other is an innovation. We will return to this speciﬁc interpretation
in Section 5.

4This is consistent with a simple search process: if the decision maker looks for social cues
(i.e., the choices that the already-converted have made), then with probability Mt/(Mt +
Nt) the ﬁrst convert she bumps into is an A-adherent. And so with that probability she is
persuaded to adopt A (conditional on her choosing via social imitation).

4

above components (individual judgement and social inﬂuence). Thus

P [agent in period t + 1 chooses A] = α

p + (1

α)

(1)

·

−

Mt
Mt + Nt

1. Similarly, the probability that the chooser in period t + 1

where 0
≤
selects B is

α

≤

P [agent in period t + 1 chooses B] = α

(1

p) + (1

α)

(2)

·

−

−

Nt
Mt + Nt

.

Festinger’s hypothesis—that people are more open to social inﬂuence when
evidence is equivocal—amounts here to assuming that α and p are positively
correlated if p > 1/2 and negatively correlated if p < 1/2. We believe that this
is a sensible proposition but we do not require it for our analytical results. We
do use it in most of our simulations, however. Moreover, Festinger’s hypothesis
informs our understanding of what we consider soft technologies: in the context
of Eq. (1), a soft technology is one with a p in the vicinity of 1/2 and a low α.
To get a feel for how this process works it is useful to consider ﬁrst the two
extreme cases: i.e., when α = 1 and α = 0. The former is simply an independent
trials process with a probability of “heads” of p. This process and its properties
are well-understood. The case of α = 0 (pure social inﬂuence) is the standard
Polya’s urn process [PE23]. Given that we are particularly interested in soft
technologies, which here are represented by low values of α, we will pause for a
moment to recapitulate its features.

3 Pure social inﬂuence (α = 0)

Suppose 100 people have made up their minds, with 70 having chosen A and
30 having chosen B. Then in the current period agent 101 has a 70% chance
of selecting A. Consequently the expected proportion of the population who
101 ) = 1
cleave to A is .7( 71
101 (70.7) = .70; i.e.,
the expected proportion exactly equals the current proportion.
It is easy to
show that this martingale property holds in general: on average the pure social
inﬂuence process stays exactly where it currently is. That is,

101 ) + .3( 70

70) = 1

71 + .3

101 (.7

·

·

E

Ft+k

Ft =

Mt
Mt + Nt (cid:21)
for all k > 0. Hence the pure social inﬂuence process is strongly path dependent:
in expectation it tends to stay wherever it is—i.e., wherever it has arrived via
the particular sample path it has been traveling.

Mt
Mt + Nt

= Ft

(3)

=

(cid:12)
(cid:12)
(cid:12)

(cid:20)

Proposition 1. If m0 = n0 = 1 (and α = 0), then P [Mt = 1] = P [Mt = 2] =

= P [Mt = t + 1] = 1/(t + 1), for all t > 0.

· · ·
Proof. This is a classical result [PE23].

5

 1

 0.8

 0.6

 0.4

 0.2

 0

 0

 200

 400

 600

 800

 1000

Figure 1: A simulation of the pure Polya’s urn process for 1000 rounds. The
initial condition is one A and one B. As can be seen from the ﬁgure, the three
sample paths converge to diﬀerent limits.

Thus every feasible outcome is equally likely at every date: given a fair start,
the pure process of linear social pressure is completely ‘blind’. Therefore the
process is just as likely to wind up generating a heterogeneous diﬀusion, with
half the population championing A and the other half B, as it is to wind up
with a sharply skewed outcome, with nearly everyone backing A.5

It is instructive to look at a typical sample path; see Fig. 1. Note that
initially the relative frequencies of A- versus B-adherents swing wildly: with
only a small number of initial converts, early adopters have a lot of inﬂuence.
But once hundreds of people have taken sides subsequent adopters have little
impact on relative frequencies, and so the process settles down. Hence it may
appear to agents inside the process that the diﬀusion is moving toward some
predetermined equilibrium. Part of this impression is correct: as t
, any
sample path of this process will settle down near some long-run proportion
of A-adherents and B-adherents. But we know from Proposition 1 that this
asymptotic state was not at all predetermined: ex ante, every outcome is just
as (un)likely as every other.

→ ∞

What does the pure Polya process tell us about the complex process, in
which objective evidence does play a role? Recall that by Festinger’s hypothesis,
soft technologies have low α’s. Moreover, an agent’s adoption probability, as
represented by Eq. (1), is continuous in α. Hence for α “close” to zero the
5It is worth mentioning that Proposition 1 depends upon the initial seed being m0 =
n0 = 1.
If it is a fair start but there are more two initial champions then the resulting
distributions are not uniform, though they are symmetric around 1/2. Nevertheless, the
martingale conditional expectations property does continue to hold, for any values of m0 and
n0. So in this sense the strong path dependence property is insensitive to the initial conditions.

6

diﬀusion will approximate a pure social inﬂuence process:
blind, ex ante.

it will be “nearly”

In such circumstances agents are inﬂuenced by a mixture of conformity and
individual judgment about the evidence. Yet they may not have good access
to the ﬁne structure of their own choice processes [WB98]. For one thing, they
may not recognize how much of their choice is inﬂuenced by social cues. And
even if they do, they may rationalize that part of it, along the lines of herding
models: the behavior of peers conveys information, and so it is rational to be
socially inﬂuenced. And of course that may be so. But if α is suﬃciently low
there is a good chance (less than half but still appreciable) that at date t a
majority of the converts will back the weaker option; hence the next adopter
could be led astray.

Further, we suspect that people involved in a diﬀusion of a soft technology
do not have good intuitions for the stochastic properties of the process.
In
particular, we suspect that the fact that with a low α a soft technology could,
given a large population of adopters, wind up at many diﬀerent outcomes with
nearly equal ex ante probabilities is underappreciated. Life unfolds as a sample
path, and the “settling down” feature of the particular sample path one inhabits
(as in Fig. 1) will be much more salient than theoretical ex ante probabilities—if
the latter are recognized at all.

4 Properties of the Complex Process: α

(0, 1)

∈

4.1 The mean of the process

We now directly investigate properties of the complex process. First let us
examine how it behaves over time.

Proposition 2. Assume α > 0. EFt

p monotonously as t

.
→ ∞

In fact, instead of expectations, we can establish a strong convergence result:

Proposition 3. Ft

p a.s. as t

→

Thus the process exhibits a constant drift or bias toward p, the value of
individual judgment. This reason behind this is because the martingale property
is broken. In fact, instead of Eq. (3), it can be shown (see Appendix) that for
the complex process α

(0, 1),

→

.
→ ∞

∈

E[Ft+1

Ft] = Ft +
|

α(p
Ft)
−
t + s + 1

.

(4)

Note that the process could be mostly one of social construction—most of the
m0+n0 <

weight is on imitation—yet improvement will tend to occur anyway, if m0
p. Henceforth we denote m0

m0+n0 by f0.

Next let us consider how Ft is aﬀected by variations in the model’s two basic
parameters, α and p. The latter’s eﬀect is both obvious and unconditional.
Clearly, the average fraction of correct choices, EFt, is increasing in p. But
more can be said.

7

 1

 0.8

 0.6

 0.4

 0.2

 1

 0.8

 0.6

 0.4

 0.2

 0

 0

 200

 400

 600

 800

 1000

α = 0.9

 0

 0

 200

 400

 600

 800

 1000

α = 0.1

Figure 2: Simulations of the complex process after 1000 rounds. In both cases
(α = 0.9 and 0.1) we choose p = 0.7 and initial condition one A and one B. In
each ﬁgure three sample paths are shown. As can be seen, the convergence rate
for small α is much slower than the rate for large α.

8

Proposition 4. A higher value of p yields a distribution of Ft that stochastically
dominates a distribution of Ft produced by a lower value of p, for all t > 0.

This immediately implies that EFt is increasing in p.6
It is worth emphasizing that this strong eﬀect obtains even if the process
is mostly one of social construction (low α’s). Thus the presence of social
construction does not utterly prevent “rational engineering” (e.g., concerning
the technology of evaluation) from having benign eﬀects. (Of course, in a sense
this is built into the model, but hopefully it is built-in in a plausible way.)

Further, Festinger’s hypothesis implies that if p > 1/2, then as the evaluation
technology improves, decision makers will rely more on the evidence and less
on social cues: the rise in p will be followed by an increase in α. This indirect
impact of changes of p might be just as important as its direct eﬀect on EFt.
This naturally raises the question, how do changes in α aﬀect the process?

Proposition 5.

(i) If f0 < p, then EFt is increasing in α, for all t > 0.

(ii) If f0 > p, then EFt is decreasing in α, for all t > 0.

Thus, absent a lucky start (f0 > p), less reliance on social cues improves
matters. Consequently, if Festinger’s hypothesis is correct, improvements in
evaluation technology have two benign eﬀects on diﬀusions that don’t enjoy
lucky starts: the obvious direct one (Proposition 4) and a less obvious indirect
one (Proposition 5), via increases in α.

4.2 The unpredictability of the process

If we compare the two pure processes, it is evident that, given a standard start
(m0 = n0 = 1), the pure social process is less predictable (as measured by
the variance of Ft). When the diﬀusion is purely a matter of social construc-
tion, every feasible outcome is equally likely; this is intuitively very random,
and it translates into one with a high variance. In contrast, even the variant
of the pure individualistic process with maximal variance (p = 1/2), extreme
outcomes—nearly everyone choosing A or B, for example—are less likely than
other outcomes. So the variance must be less than that produced by pure social
imitation.

Since the complex process is, at the level of individual choice, a weighted
average of the two pure processes, it is intuitively reasonable that the variance
of the complex process would be increasing in 1
α, the weight on the higher
variance component, given a fair start. This intuition is correct, but since it
conditions on a particular starting point it is incomplete. The next result shows
that more weight on the social component can reduce the variance of the complex
process, at least for awhile.

−

6However, the converse does not hold: an increase in the mean fraction of correct choices
does not imply that one distribution stochastically dominates the other. So Proposition 4 is
stronger than just a comparison of means.

9

Proposition 6. ∂(var Ft)/∂α < 0 for all t > 0 iﬀ either

(i) f0 < p and p0 = (1

α)f0 + αp > 1/2, or

(ii) f0 > p and p0 = (1

α)f0 + αp < 1/2.

−

−

Thus for parameters in this range, increases in the weight on evidence both
improve community-wide accuracy (on average) and reduce the variance of out-
comes.

While it makes sense that the more socially constructed a diﬀusion is the
more variable are its outcomes, it is important to emphasize that this conclusion
does not always hold, as is indicated by the “only if” part of Proposition 6. Here
is why. Suppose initially A-adherents are few and far between; for simplicity, let
f0 = 0. Then if diﬀusion were based only on imitation (α = 0), everyone would
adopt the wrong option—and the process, although built completely on social
cues, would exhibit no variability whatsoever. In such a case small increases in
α would increase the variance of the outcomes, at least in the early goings. Of
course this increase in variance is thoroughly benign: without it, the diﬀusion
would be stuck in a highly predictable but consistently inferior sample path.

Proposition 7.

(i) ∂(var Ft)/∂p < 0 for all t > 0 if p

1/2 and p0 > 1/2;

≥

(ii) ∂(var Ft)/∂p > 0 for all t > 0 if p

1/2 and p0 < 1/2.

≤
Regarding part (ii), note that increases in p increase the variance in a so-
cially desirable way. However, people who like predictability could resent the
“rationalizing” eﬀect of improvements in program information and evaluation
technology, because in these circumstances increasing p makes things “messier”
and less predictable.

As a matter of interpretation, one might say that a p

1/2 and an p0 < 1/2
involves a “soft” technology with a vengeance: there is some kind of bias against
the better technology, maybe because it is not as trendy, and there is also a bias
in terms of the initial social proclivities (p0 < 1/2).
In this case, improving
evaluation technology also creates a “messier” and more confusing process ex
ante, in that such improvements increase the variance of the outcomes.

≤

Indeed, even if p > 1/2 (i.e., the “standard” case), we know that in period
1 the variance of F1 is increasing in p if p0 < 1/2. (And probably this will hold
for some ﬁnite number of periods after period 1 too.) This is a very natural case
of a soft technology: there is a social bias against the better technology (bad
luck, essentially, or maybe glamour is on the side of the weaker technology), in
that f0 < 1/2, and things are noisy enough so that p, though above 1/2, is still
fairly low. Hence if Festinger’s hypothesis were to kick in, so that α were pretty
low too, then p0 < 1/2, and the variance of F1 would be increasing in p.

4.3 The eﬀects of initial conditions

There are two types of initial conditions: the size of the initial seed (m0 + n0)
and the proportion (f0 = m0
m0+n0 ). Each has eﬀects independently of the other

10

(i.e., holding the other ﬁxed), so we will examine them separately and in a
ceteris paribus manner.

4.3.1 Varying the size of the initial seed
Proposition 8. Suppose F ′
0 = km0 and
n′
0 = kn0, where k is an integer larger than one. In all other respects the two
processes are identical.

t is a bigger process than Ft in that m′

(i) EF ′

(ii) EF ′

t < EFt for all t > 0 iﬀ f0 < p.

t > EFt for all t > 0 iﬀ f0 > p.

Thus a bigger initial seed acts as an inertial anchor, slowing down the move-

ment of E[Ft] to its attractor p.

4.3.2 Varying the initial proportions

It is obvious that, all else equal, increasing the initial bias toward A (i.e., in-
creasing f0) boosts EFt at every date. Suppose, e.g., we start out with m0 + 1
A-converts, instead of with just m0. This increases the social conformity pres-
sure for the agent in period 1 to adopt A. That in turn increases F1, the expected
fraction of the converts who adhere to A at the end of period 1, which in turn
provides more social cues to the decision maker in period 2 to adopt A and so
on.

But a higher f0 has an even stronger eﬀect—stronger even than ordinary
ﬁrst-order stochastic dominance. To see what this sense is, consider the following
deﬁnition.

fl1,t, fl2,t, . . . , flb,t

Deﬁnition 1. Suppose the support of Ft and F ′
t can be divided into three mu-
, a
tually disjoint subsets: a non-empty set of high states
, and a possibly empty set of
non-empty set of low states
intermediate states
. Suppose the three subsets are con-
nected in the sense that any low state is less than any intermediate state, and
any intermediate state is less than any high state. We say that F ′
t is stochas-
tically bigger than Ft in a strong sense if P [F ′
t = fh,t] > P [Ft = fh,t] for any
high state h, P [F ′
t = fm,t] = P [Ft = fm,t] for any intermediate state m, and
P [F ′

t = fl,t] < P [Ft = fl,t] for any low state l.

fm1,t, fm2,t, . . . , fmc,t

fh1,t, fh2,t, . . . , fha,t

{

}

{

}

}

{

Thus a distribution of Ft that is stochastically bigger in a strong sense puts
strictly more weight on high fractions of converts who have chosen correctly, and
strictly less weight on low fractions. (Clearly this implies ﬁrst-order stochastic
dominance, but the converse need not hold, so this is in fact a “strong sense”
of stochastic dominance.)

Proposition 9. All else equal, the distribution of Ft is stochastically increasing,
in a strong sense, in f0, for all t > 0.

11

Naturally, smaller f0’s produce distributions of Ft that are stochastically
smaller, in a strong sense. Suppose, therefore, that A is an innovation that
is superior to B. If B is not an innovation—it is in fact the status quo—and
the community is quite traditional (everyone initially uses B, though people are
willing to consider an innovation), then eﬀectively f0 equals zero. This is the
toughest possible starting point for an objectively superior innovation.

The eﬀect of varying initial bias on the variance of the process is perhaps

less intuitive.

Proposition 10. ∂(var Ft)/∂f0 < 0 for all t > 0 if p0 > 1/2 and p > 1/2.

4.4 The convergence rate

If we wish to use our complex process to explain diﬀusion of innovations in the
real world, only studying the limit behavior is not enough. If the characteristic
time needed to reach the asymptote state is too long to be observed, then the
asymptote state cannot be very meaningful in the practical sense. A rough
estimation of the convergence rate of the complex process can be achieved from
a mean-ﬁeld approximation. Neglecting the noise term, the stochastic process
Ft can be approximated by Eq. (4):

Further approximating Ft by a continuous process F (t), we can write

Ft+1 = Ft +

α(p
Ft)
−
t + s + 1

.

dF (t)
dt

= α

p
F (t)
t + s + 1 ∼

−

p

α

−

F (t)
t

.

Solving for F (t), we ﬁnd

If we deﬁne a characteristic convergence time T to be the time it takes F (t) to
converge to a vicinity within ǫ from p, then we have

(5)

(6)

(7)

(8)

F (t)
|

p

−

| ∼

−α.

t

T

∼

1
α

.

1
ǫ

(cid:18)

(cid:19)

→

0, the characteristic convergence time diverges exponentially in
Thus as α
1/α. Indeed, when α = 0 (Polya’s urn) the process never converges to p. (To
be precise, the Polya process can converge to any p
[0, 1], but the probability
that it converges to any particular p is zero.)

∈

The mean-ﬁeld estimation is in principle only for the mean of Ft, of course.

For a ﬁne estimation of the variance of Ft, we need a central limit theorem.

Proposition 11.

(i) If 1/2 < α

1, then as t

a normal distribution with mean zero and variance p(1
particular, var Ft = O(1/t).

−

−

, √t(Ft

→ ∞

−

p) converges in distribution to
1). In

p)/(2α

≤

(ii) If 0 < α

1/2, then var Ft

0 slower than O(1/t).

≤

→

12

4.5 Implications regarding herding and massive confor-

mity

Assume, as in cascade models with rational agents, that the “initial seed” is
exactly one person who chooses A with probability p and B with probability
1

p, and everyone else follows sequentially.

−

Deﬁnition 2. We say that there is “herding” if after some period T everyone
makes the same choice.7

Fact 1. Herding occurs in our model (with positive probability) iﬀ one of the
following condition holds:

(a) α > 0 and p = 1; then we get herding on option A.

(b) α > 0 and p = 0; then we get herding on option B.

(c) α = 0; then we get herding on option A with probability p and herding on

option B with the complementary probability 1

p.

−

Proof. Suﬃciency. All three parts are trivial, by induction.

Necessity. Suppose none of (a)–(c) hold. Then we know that α > 0 and p
(0, 1). By Prop. 3, Ft
inﬁnitely often with probability one.

∈
p almost surely. Hence both A and B are chosen

→

Fact 2. Under the assumptions of our model, if heterogeneous behavior ever
occurs then herding is impossible (with probability one).

Proof. By Fact 1, if heterogeneous behavior has emerged by some date t > 0
then the extreme conditions (a)–(c) in Fact 1 cannot hold. Hence we know that
α > 0 and p

(0, 1). The rest is the same as the necessity part of Fact 1.

∈

Conformity could be overwhelming—nearly everyone in a community winds
up making the same choice—without being complete. One of the surprising
results of the rational cascade models is that massive-conformity-in-the-making
can be very fragile. As Bikhchandani, Hirshleifer and Welch put it, “A little
bit of public information (or an unusual signal) can overturn a long-standing
informational cascade. That is, even though a million people may have chosen
one action, seemingly little information can induce the next million people to
choose the opposite action. Fragility is an integral component of the informa-
tional cascades theory!” ([BHW96] original emphasis).

But this fragility is intimately linked to the agents’ complete rationality and
deep understanding of informational cascades. As Bikchandani et al. remark, in
standard rational models “everyone knows that there is very little information
in a cascade [BHW96]. That “everyone” pertains, of course, to the model’s
rational agents, not to real decision makers: the evidence is that the latter do
7This is the term some scholars (e.g., [Ban92]) use. Others (e.g., [BHW96]) call this an

informational cascade.

13

 1

 0.8

 0.6

 0.4

 0.2

 0

 0

 200

 400

 600

 800

 1000

Figure 3: A simulation of the complex process with α = 0.5 and initial seed
one A and one B. p is set to 0.2 for the ﬁrst 500 rounds and is updated to 0.3
for another 500 rounds. The vertical line indicates the change point. As can be
seen, the sample path is not signiﬁcantly aﬀected by the new level of p.

not realize that there is very little information in a cascade.8 The agents in
our model are imperfectly rational and lack a deep understanding of cascades.
Hence, diﬀusion processes in our model are not fragile (in the above sense). This
is easily established by re-inspecting Eq. (1): the probability that an agent makes
the correct decision is continuous in p, so a little bit of new public information—
represented as a sudden positive shock to p—will only increase the probability
of choosing correctly by a little bit. (For an illustration of this, see Fig. 3.)

5 Alternative Interpretations

It is worth noting that one can use the model to represent situations in which
there is a status quo option that everyone already uses. Then the diﬀusion is
simply this: in every period one agent has an opportunity to either take up the
innovation (say, A) or keep the status quo (say, B). Further, one could allow for
the innovation to be objectively inferior to the status quo.

Under this interpretation of a novel technology competing with a status quo,
it is reasonable to suppose that f0 equals zero. This is, from the point of view
of an innovation, the toughest possible starting point.

so it is probably the case that αp + (1

If it’s a soft innovation then presumably both p and α are relatively low,
α)f0 is less than one-half. Hence by
−
8This is the pattern that Kubler and Weiszacker found in their experiments on cascades
[KW04]. As they put it, “players do not consider what their predecessors thought about their
respective predecessors. Thus, they do not understand that some of the decisions they observe
have been herding decisions, not based on any private information (pp. 438).

14

Proposition 6, decreasing the reliance on social cues (i.e., a smaller 1
increase the variance of outcomes.

−

α) would

6 Extensions of the Model

6.1 Endogenizing Festinger’s Hypothesis

≤

≤

If Festinger’s hypothesis is correct, then the weight on social cues, should depend
on how diﬃcult the choice is. That is, α should be a function of p. We can
stipulate a priori several properties that this function should have. First, 1
α
should reach its maximum when p = 1/2:
it is in this circumstance that an
agent is maximally uncertain about the relative merits of A versus B and so,
following Festinger, s/he would be maximally reliant on social cues. Second, as
a benchmark the function should be symmetric around one half: f (.5
k) =
f (.5 + k), for .5

1.

−

−

k

−

−

A simple function with both properties is 1

α = 4p(1

p). Then the

−

−

·

probability that the chooser in period t would pick A would equal 4p(1
Ft + 1

4p(1

p)

p.

p)

·

−

An interesting feature of this choice equation is that it creates the possibility
that the probability of a correct choice is decreasing in p. This seems bizarre but
it is explicable: it arises because α is a function of p. Note that 4p(1
p), the
weight on social cues, is increasing when p is less than one half, since in this range
increases in individual-level accuracy make the choice problem more confusing
or troubling. Thus, as we suggested earlier, increases in p have two eﬀects:
a direct eﬀect on individualistic choice (which is always benign, as shown by
Proposition 4) and an indirect one on the weights (which is not always benign).
For certain parametric values the indirect eﬀect is suﬃciently large and negative
so as to swamp the positive direct eﬀect.9

−

Thus endogenizing Festinger’s hypothesis will generate interesting hypothe-

ses.

6.2 Diﬀusion in Communities with Internal Structure

6.2.1 Status Hierarchies

There is considerable empirical support for the hypothesis that the higher the
decision maker’s status, the more impact his/her adoption choice has on the
unconverted (e.g., [SS98, pp. 275]). It would be easy to incorporate this empir-
ical regularity in a stark way in the current model: only high status agents are
imitated; the adoption choices of low status agents are ignored.

9To see this concretely, note that the derivative of 4p(1 − p) · f0 + 1 − 4p(1 − p) · p with
respect to p equals 4(1 − 2p) · f0 + (1 − 8p + 12p2). Then suppose for example that f0 = 0
and p = .25. With these parametric values the derivative equals −.25, so small increases in p
make the agent in period one more likely to err. However, if p is suﬃciently big—speciﬁcally,
if it exceeds max(.5, f0)—then increases in p do decrease the chance of mistakes.
(When
p > .5 then a higher p decreases the decision maker’s confusion, thus raising the weight on
individualistic judgment, which is benign since p > f0.)

15

An intriguing issue concerns the relative competence of high status and low
status agents. In diﬀusions that tap into a relatively strong scientiﬁc or techni-
cal base (pharmaceuticals, computer hardware, etc.), one would expect higher
status agents to be more likely to make the right choice (higher p’s). However,
there may be circumstances in which status is purely a subjective phenomenon,
lacking any objective correlate. (People inside the community may believe that
higher status is correlated with more expertise but this would be an illusion.)

6.2.2 Clustered Interaction

Most diﬀusions occurs in communities that exhibit biased interactions. In gen-
eral, executives in the same industry are more likely to interact with each other
than with executives in a diﬀerent industry. School superintendents in the same
state are more likely to encounter each other than are superintendents in diﬀer-
ent states. (At the limit—if these subcommunities were completely sealed oﬀ
from each other—then our model applies as it is to each subcommunity.)10

6.3 Leakage of Information

Here, p would be a function of time. Typically we would expect that p would in-
crease over time, as information about the technology (by the already-converted
or by third parties) leaks out. As already noted, the baseline diﬀusion process
(stationary p) is robust: small positive shocks to p will on average have small
eﬀects on the fraction of the population that adopts option A.

6.4 Waves of Innovations

Today it seems that the business world never rests. No sooner has one innovation
passed from the scene—or at least from public attention—than another one
appears. Becauase there are good reasons for this—it is not accidental [Abr96]—
one can expect this pattern to continue indeﬁnitely.

Although waves of innovation will obviously produce some new patterns,
we suspect that some of the present paper’s results will continue to hold. In
particular, we conjecture that if the waves are composed of soft technologies,
with p around 1/2 and strong propensities to imitate, then the process will
continue to be Polya-like in two senses. First, objectively uncertainty will be
very great: many adoption patterns will be possible ex ante. Second, if the
waves do not come too often then sample paths of diﬀusion will settle down.
Hence, subjectively it will feel as if the process is moving toward a predetermined
equilibrium—an illusion.

10For a study of the inﬂuence of social structure on opinion formation, see e.g. [WH05, SR05].

16

7 Conclusion

Because they diﬀuse with little objective information about their eﬀects, soft
technologies pose challenges for decision makers. Psychologists have long argued
that when faced with such choice problems, people use a reasonable though im-
perfect imitation heuristic. We have presented a mathematical model of diﬀu-
sion that combines this heuristic with agents’ eﬀorts to make factually-grounded
decisions and we established both analytically and computationally that such
processes exhibit clear stochastic properties. We then showed that the dynam-
ics of the model leads to outcomes that appear to be deterministic in spite of
being governed by a stochastic process.
In other words, when the objective
evidence for the adoption of a soft-technology is weak, any sample path of this
process quickly settles down to a fraction of adopters that is not predetermined
by the initial conditions: ex ante, every outcome is just as (un)likely as every
other. When the objective evidence is strong, the process settles down to a
value that is determined by the joint eﬀect of the quality of the evidence and
the agents’ competence. In neither case does the proportion of adopters settle
into either zero or one: pure herding does not occur except in parametrically
extreme situations.

Further, unlike informational cascades generated by fully rational actors, the
process of the present model is robust: diﬀusions that have for a long time tilted
massively toward one option cannot be suddenly derailed by small infusions of
new public information. The fragility of cascades generated by fully Bayesian
agents is, we believe, an artifact of unrealistic assumptions of hyper-rationality.
Diﬀusions may be initially volatile, as they are in the present model, but we
believe that these processes stabilize once the weight of public opinion has been
brought to bear.11

11Of course, the introduction of a new innovation can, by restarting the process, desta-
bilize it. But that is not what is producing fragility in the full-rationality cascades: these
are not robust against small shocks associated with the pre-existing options. Moreover, as
indicated earlier, we believe that the present model can be extended to accommodate waves
of innovation.

17

References

[Abr96] Eric Abrahamson. Management fashion. Academy of Management

[Ban92] A. V. Banerjee. A simple model of herd behavior. Quarterly J. Econ.,

Review, 21:254–286, 1996.

107:797–818, 1992.

[BHW92] S. Bikhchandani, D. Hirshleifer, and I. Welch. A theory of fads,
fashion, custom, and cultural change as informational cascades. J.
Pol. Econ., 100:992–1026, 1992.

[BHW96] Sushil Bikhchandani, David Hirshleifer, and Ivo Welch. Informational
cascades and rational herding: An annotated bibliography. Working
Paper: UCLA/Anderson and Ohio State University and Yale/SOM.
http://welch.econ.brown.edu/cascades/, 1996.

[Blu54]

J. R. Blum. Approximation methods which converge with probability
one. Ann. Math. Statist., 25:382–386, 1954.

[Cam98] Colin Camerer. Bounded rationality in individual decision making.

Experimental Economics, 1:163–183, 1998.

[Chu54] K. L. Chung. On a stochastic approximation method. Ann. Math.

Statist., 25:463–483, 1954.

[Fes54]

Leon Festinger. A theory of social comparison processes. Human
Relations, 7:117–140, 1954.

[KW04] D. Kubler and G. Weiszacker. Limited depth of reasoning and failure
of cascade formation in the laboratory. Review of Economic Studies,
71:425–441, 2004.

[Las98]

Larry Lashway. Creating a learning organization. Eugene, OR: ERIC
Clearinghouse on Educational Management, ED420897, 1998.

[MC04] Cleborne Maddux and Rhoda Cummings. Fad, fashion, and the weak
role of theory and research in information technology in education.
Journal of Technology and Teacher Education, 12:511–533, 2004.

[MW02] Michael Macy and Robert Willer. From factors to actors: Com-
putational sociology and agent-based modeling. Annual Review Of
Sociology, 28:143–160, 2002.

[PE23]

G. Polya and F. Eggenberger. ¨uber die statistik verketteter vorg¨ange.
Zeitschrift
f¨ur Angewandte Mathematische Mechanik, 3:279–289,
1923.

[Pem01] Robin Pemantle. Random processes with reinforcement. Preprint,

http://www.math.upenn.edu/~pemantle/reinforce/paper/statsci011005.ps,
2001.

18

[RM51] H. Robbins and S. Monro. A stochastic approximation method.

Ann. Math. Stat., 22:400–407, 1951.

[SR05]

[SS98]

V. Sood and S. Redner. Voter model and heterogeneous graphs.
Phys. Rev. Lett., 94:178701, 2005.

D. Strang and S. Soule. Diﬀusion in organizations and social move-
ments: From hybrid corn to poison pills. Annual Review of Sociology,
24:265–290, 1998.

[WB98] D. Wegner and J. Bargh. Control and automaticity in social life. In
D. Gilbert, S. Fiske, and G. Lindzey, editors, The Handbook of Social
Psychology. McGraw-Hill, Boston, 1998.

[Wel92]

I. Welch. Sequential sales, learning, and cascades. J. Finance, 47:695–
732, 1992.

[WH05] Fang Wu
cial
http://http://www.hpl.hp.com/research/idl/papers/opinions/opinions.pdf,
2005.

So-
formation.

Bernardo
and

Huberman.

structure

opinion

and

A.

19

Appendix

Consider the following variation of Polya’s urn. There are two types of alterna-
tives, A and B. At time t = 0 there are s agents who have already made their
choices, of which m0 have chosen A and n0 have chosen B. Denote the initial
fraction of A-adherents to be f0 = m0/s. Deﬁne the dynamics recursively as
follows. Let (Mt, Nt) be the (random) number of agents who have chosen A by
the end of period t. In period t + 1, an agent chooses A with probability

Pt = αp + (1

α)

Mt
Mt + Nt

,

−

where α, p
a standard Polya’s urn process.
α > 0.

∈

[0, 1], and chooses B with probability 1

Pt. If α = 0 this becomes
In the rest of this appendix we will assume

−

We are interested in studying the (random) fraction of agents who have

chosen A up to period t:

Ft =

Mt
Mt + Nt

.

Conditional on the information at time t, with probability Pt,

∆Ft+1 = Ft+1

Ft =

Mt + 1

Mt + Nt + 1 −

Mt
Mt + Nt

1

Ft

=

−
t + s + 1

,

while with probability 1

Pt,

−

−

∆Ft+1 =

Mt

Mt + Nt + 1 −

Mt
Mt + Nt

= −

Ft
t + s + 1

.

Hence

Pt
Ft
−
t + s + 1
Separating out the mean term, we can write

Et[∆Ft+1] =

=

α(p
Ft)
−
t + s + 1

.

∆Ft+1 =

α(p
Ft)
−
t + s + 1

+

Xt+1
t + s + 1

,

where Xt is a martingale diﬀerence with the conditional distribution

1

Pt with probability Pt,

Xt+1 =

−
Pt

(

−

with probability 1

Pt.

−

Eq. (14) falls into the general class of stochastic approximation processes

that have been studied intensively in the statistics literature [RM51, Pem01].
In what follows it is convenient to introduce an auxiliary random variable

(9)

(10)

(11)

(12)

(13)

(14)

(15)

(16)

(17)

so that Eq. (14) can be written as

Gt = Ft

p,

−

∆Gt+1 = −

αGt + Xt+1
t + s + 1

.

20

Proposition 2. EFt

p monotonously as t

→

.
→ ∞

Proof. From Eq. (17) we have

Gt+1 =

1
(cid:18)

−

α
t + s + 1

Gt +

Xt+1
t + s + 1

.

(cid:19)

Taking expectation of both sides, we have

EGt+1 =

1

α
t + s + 1

−

(cid:19)

(cid:18)

EGt =

t

1
k=0 (cid:18)
Y

α
k + s + 1

−

(cid:19)

g0.

(19)

Because

the inﬁnite product in Eq. (19) converges to zero monotonously. Thus EGt
monotonously, or EFt

p monotonously.

0

→

Lemma 1. Assume α > 0. If

→

∞

k=0
X

α
k + s + 1

=

,
∞

yn = xn + α

n−1

k=1
X

xk
k

converges, then xn

0.

→

Proof. Suppose xn does not converge to 0. Then without loss of generality we
can assume that xn > ǫ > 0 inﬁnitely often. It must also be that xn < ǫ/2
ǫ/2 eventually and yn would
inﬁnitely often, otherwise we would have xn
diverge. Because yn is Cauchy, we can ﬁnd N such that
< ǫ/4 for all
yn
ym
|
such that xn′ < ǫ/2. Pick m > n′ such that
m, n
max
xm > ǫ. Let n be the largest integer such that n′
n < m and xn < ǫ/2. It is
clear that m, n chosen this way satisfy the following conditions:

N . Pick n′

N, 2α
}

≥

≤

−

≥

≥

{

|

(18)

(20)

(21)

(22)

Now we have

xm

xn = ym

yn

α

−

−

−

yn +

(xm

xn) <

+

(xm

xn).

(23)

ǫ
4

1
2

−

−

Hence xm
xm > ǫ.

−

xn < ǫ/2. But this contradicts with the fact that xn < ǫ/2 and

≥

m > n
N,
xn < ǫ/2, xm > ǫ,
n < i < m

xi

⇒

≥

ǫ/2 > 0.






ym

yn

α

xn
n

−

m−1

xk
k ≤

k=n
X
< ym

−

−

α
n

21

Proposition 3. Ft

p a.s. as t

→

.
→ ∞

Proof. Replacing t by k and summing up k = 0, . . . , t
martingale:

−

1 in Eq. (17), we ﬁnd a

˜Gt = Gt

g0 +

−

αGk
k + s + 1

=

Xk+1
k + s + 1

.

(24)

t−1

k=0
X

t−1

k=0
X

Furthermore, this martingale is nonnegative. The martingale convergence the-
orem thus ensures that ˜Gt converges to a (random) limit ˜G∞ with probability
1. From Eq. (24) and Lemma 1, the almost sure convergence of ˜Gt implies that
p almost surely.
Gt

0 almost surely, or Ft

→

→

Proposition 4. A higher value of p yields a distribution of Ft that stochastically
dominates a distribution of Ft produced by a lower value of p, for all t > 0.

Proof. Suppose p′ > p.
stochastically dominates Mt, or P [M ′
t > m]
statement is correct for t = 0 because m′
correct for t, we prove for t + 1.
P [M ′

P [Mt = m].

Case 1.

t = m]

It suﬃces to show by induction that for all t, M ′
t
N. The
0 = m0. Suppose the statement is

P [Mt > m] for all m

≥

∈

≥
′
t+1 > m]

P [M

= P [M

′
t > m] + P [M

′
t = m]

′

αp

+ (1

α)

−

−

m
t + s
m
t + s

(cid:21)

(cid:21)

(cid:20)

(cid:20)

P [Mt > m] + P [Mt = m]

αp + (1

α)

≥
= P [Mt > m].

Case 2.

P [M ′

t = m] < P [Mt = m].

P [M

m]

′
t+1 ≤
′
t < m] + P [M

= P [M

P [Mt < m] + P [Mt = m]

α(1

p) + (1

α)

′
t = m]

α(1

′

p

) + (1

α)

1

−

−

−

−

(cid:20)

(cid:20)

m
t + s
m
t + s

(cid:19)(cid:21)

(cid:19)(cid:21)

(cid:18)

1
(cid:18)

−

−

≤
= P [Mt

m].

≤

(25)

(26)

Proposition 5.

(i) If f0 < p, then EFt is increasing in α, for all t > 0.

(ii) If f0 > p, then EFt is decreasing in α, for all t > 0.

Proof. See Eq. (19).

22

Proposition 6. ∂(var Ft)/∂α < 0 for all t > 0 iﬀ either

(i) f0 < p and p0 = (1

α)f0 + αp > 1/2, or

(ii) f0 > p and p0 = (1

α)f0 + αp < 1/2.

−

−

Proof. “If” part.

Taking variance of both sides of Eq. (18), we have

var Gt+1 =

α
t + s + 1

2

(cid:19)

1
(cid:18)

−

var Gt +

(t + s + 1)2 var Xt+1.

(27)

The variance of Xt+1 can be calculated as follows. First note that

Pt = αp + (1

α)Ft = p + (1

α)Gt.

(28)

1

−

Then we can write

var Xt+1 = E[X 2
= EPt(1
= EPt(1

t+1] = E[Et[X 2
EPt)
EPt)

var Pt
(1

−
−

α)2 var Gt.

−

t+1]] = E[Pt(1

Pt)]

−

Plugging this back into Eq. (27), we obtain a recursive relation for var Gt:

var Gt+1 =

(t + s + 2

2α)(t + s)

−
(t + s + 1)2

var Gt +

EPt(1
EPt)
(t + s + 1)2 ,
−

−

−
−

where

It is clear from this recursive relation that the conclusion holds if

EPt = p + (1

α)EGt.

−

∂(EPt(1

EPt))

−
∂α

< 0.

Case (i) By hypothesis g0 < 0. From Eq. (19) we see that EGt (being a
negative sequence) is increasing in both t and α, so is EPt by Eq. (31). Therefore
EPt > p0 > 1/2. Note that the function f (x) = x(1
x) is decreasing in x
when x > 1/2. Thus EPt(1

EPt) is decreasing in α for all t.

−

Case (ii)

−
Similar to (i).

“Only if” part.

Letting t = 0 in Eq. (30), we have

var G1 =

p0(1
p0)
(s + 1)2 .
−

Taking partial derivative with respect to α, we obtain

∂(var G1)
∂α

=

(f0

p)(2p0
−
(s + 1)2

1)

.

−

Thus, in order to have ∂(var F1)/∂α < 0, we must have (f0
i.e., either (i) or (ii).

−

p)(2p0

1) < 0,

−

23

(29)

(30)

(31)

(32)

(33)

(34)

Proposition 7.

(i) ∂(var Ft)/∂p < 0 for all t > 0 if p

1/2 and p0 > 1/2;

(ii) ∂(var Ft)/∂p > 0 for all t > 0 if p

1/2 and p0 < 1/2.

≥

≤

Proof. We see from Eq. (31) and Eq. (19) that

∂(EPt)
∂p

= 1 + (1

α)

−

∂(EGt)
∂p

= 1

(1

α)

−

−

t−1

1
k=0 (cid:18)
Y

−

α
k + s + 1

(cid:19)

> 0.

(35)

Taking partial derivative of p on both sides of Eq. (30) yields

∂(var Gt+1)
∂p

=

(t + s + 2

2α)(t + s)

−
(t + s + 1)2

∂(var Gt)
∂p

+

2EPt
1
(t + s + 1)2

−

∂(EPt)
∂p

.

(36)

The result now follows from the facts that (i) EPt > 1/2 for all t > 0 if p
and p0 > 1/2, and (ii) EPt < 1/2 for all t > 0 if p

1/2 and p0 < 1/2.

≥

1/2

≤

Proposition 8. Suppose F ′
0 = km0 and
n′
0 = kn0, where k is an integer larger than one. In all other respects the two
processes are identical.

t is a bigger process than Ft in that m′

(i) EF ′

(ii) EF ′

t < EFt for all t > 0 iﬀ f0 < p.

t > EFt for all t > 0 iﬀ f0 > p.

Proof. When f0 < p we have g0 < 0. In this case Eq. (19) shows that EGt
is decreasing in s. Hence EF ′
t > EFt
similarly.

t < EFt. When f0 > p we have EF ′

Proposition 9. All else equal, the distribution of Ft is stochastically increasing,
in a strong sense, in f0, for all t > 0.

Proof. We only need to show that Mt is stochastically increasing in f0 in a
strong sense. We prove this by induction. The proposition obviously holds
for t = 1. Suppose t is correct, we prove for t + 1. Let Mt and M ′
t be the
two stochastic processes generated by f0 and f ′
0. By
induction hypothesis, there exist s
t =
t = i] = P [Mt = i] for all integers
i] < P [Mt = i] for all integers i
∈
t = i] > P [Mt = i] for all integers
[b + 1, c
i
[c, d]. Furthermore, [a, d] covers the support of Mt and M ′
t.
i

≤
[a, b], P [M ′
1] (possibly none), and P [M ′

0, assuming that f0 < f ′

t + s such that P [M ′

a < b < c < d

≤

−

∈
∈

24

For all i = c + 1, . . . , d + 1, we have

P [M

′
t+1 = i] = P [M

′
t = i

1]

αp + (1

α)

+ P [M

′
t = i]

p) + (1

−

> P [Mt = i

1]

αp + (1

α)

−

−

(cid:20)
α(1

(cid:20)
α(1

(cid:20)

(cid:20)

−

−

i
1
−
t + s

α)

−
i
1
−
t + s

(cid:21)

1
(cid:18)

(cid:21)

1
(cid:18)

i
t + s

−

(cid:19)(cid:21)

i
t + s

−

(cid:19)(cid:21)

+ P [Mt = i]

p) + (1

α)

−

−

= P [Mt+1 = i].

(37)

Similarly, for all i = a, . . . , b, we have P [M ′

t+1 = i] < P [Mt+1 = i].
To study the relationship between the probability atoms of M ′

at the “boundaries”, distinguish the following two cases:

t+1 and Mt+1

M ′

There are no intermediate “equal” states (b + 1 = c).

Case 1.
Whatever the relationship between P [M ′
t+1 strongly dominates Mt+1.
Case 2.
It can be checked, in a fashion similar to Eq. (37), that (a) P [M ′
P [Mt+1 = c], and (c) P [M ′
P [Mt+1 = b + 1], (b) P [M ′
t+1 = c]
b + 1]
≥
1 (if any). Hence M ′
i] = P [Mt+1 = i] for all i = b + 2, . . . , c
−
dominates Mt+1.

There exist some intermediate “equal” states (b + 1 < c).

≤

t+1 =
t+1 =
t+1 strongly

t+1 = c] and P [Mt+1 = c], we have

Proposition 10. ∂(var Ft)/∂f0 < 0 for all t > 0 if p0 > 1/2 and p > 1/2.

Proof. Using Eq. (31) and Eq. (19), it can be calculated that

∂(EPt(1

EPt))

−
∂f0

= (1

2EPt)(1

α)

−

−

t−1

1
k=0 (cid:18)
Y

−

α
k + s + 1

.

(cid:19)

If p0 > 1/2 and p > 1/2, then because EPt converges to p monotonously, we
have EPt > 1/2 for all t > 0, and therefore

(38)

(39)

∂(EPt(1

EPt))

−
∂f0

< 0

for all t > 0. The result now follows from Eq. (30).

Proposition 11.

(i) If 1/2 < α

1, then as t

a normal distribution with mean zero and variance p(1
particular, var Ft = O(1/t).

−

−

, √t(Ft

→ ∞

−

p) converges in distribution to
1). In

p)/(2α

≤

(ii) If 0 < α

1/2, then var Ft

0 slower than O(1/t).

≤

→

25

Proof. To understand this proposition, deﬁne vt = (t + s) var Gt and rewrite
Eq. (30) as

vt+1

vt =

−

EPt(1

−

(2α

EPt)
t + s + 1

−

1)vt

.

−

When t is large, we have

∆vt+1

p(1

p)

−

(2α
−
t

1)vt

,

−

∼

Hence if 2α

1 > 0, vt is dragged to the limit p(1

p)/(2α

1).

It is also clear from Eq. (40) that when 0 < α < 1/2 we have vt

−

−

−

general, so var Gt converges slower than O(1/t).

in

→ ∞

A rigorous proof for (i), however, is too technical to be presented here. Var-
ious authors have given proofs for general stochastic approximation processes.
For references see [Blu54, Chu54].

(40)

(41)

26

