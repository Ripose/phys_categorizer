UNIVERSIT`E DE PARIS 11 - U.F.R. DES SCIENCES D’ORSAY

Laboratoire de Physique Th´eorique d’Orsay

TH`ESE DE DOCTORAT DE L’UNIVERSIT´E PARIS 11

Sp´ecialit´e: PHYSIQUE TH´EORIQUE

pr´esent´e par

Luca DALL’ASTA

pour obtenir le grade de

Sujet:

DOCTEUR DE L’UNIVERSIT´E PARIS 11

Ph´enom`enes dynamiques sur des r´eseaux
complexes

Jury compos´e de:

M. Alain Barrat
M. Olivier Martin
M. R´emi Monasson
M. Romualdo Pastor-Satorras
M. Cl´ement Sire
M. Alessandro Vespignani

(Directeur de th`ese)

(Rapporteur)

(Rapporteur)

Juin, 2006

6
0
0
2
 
p
e
S
 
4
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
4
2
1
9
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Contents

List of Publications

1 Introduction

1.1 A networked description of Nature and Society . . . . . . . . . . . . . . . . . . . . . .
1.2 Relation between Topology and Dynamics . . . . . . . . . . . . . . . . . . . . . . . . .
1.3 Summary of the thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2 Structure of complex networks: an Overview

2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Statistical Measures of Networks Topology . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.1 Basic notions of Graph Theory . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.2 Degree distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.3 Two and three points degree correlations
. . . . . . . . . . . . . . . . . . . . .
2.2.4
. . . . . . . . . . . . . . . . . . . . . . . . .
Shortest path length and distance
Subgraph structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.5
2.2.6 Further metrics for weighted networks . . . . . . . . . . . . . . . . . . . . . . .
2.3 Examples of real networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.1 The Internet
2.3.2 The World-wide Air-transportation Network . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.3 Other Examples
2.4 Networks modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.1 Homogeneous Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.2 Heterogeneous Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.3 Weighted Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 Exploration of complex networks

3.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.1 Motivations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . .
3.1.2 Networks sampling methods and their biases
3.2 Statistical physics approach to traceroute explorations . . . . . . . . . . . . . . . . . .
3.2.1 The model
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.2 Mean-ﬁeld analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.3 Numerical simulations on computer generated networks . . . . . . . . . . . . .
3.2.4 Accuracy of the mapping process . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.5 Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.6

k-core structure under sampling

i

iv

1
1
3
4

7
7
8
8
9
10
11
14
15
19
19
22
23
26
26
29
31

35
35
35
36
41
41
42
46
49
54
57

3.3 Network Species Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .
Inferring N : Estimators of Networks Size . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.3.1 The Species Problem in Networks
3.3.2
3.3.3 Numerical Results

4 Spreading and Vulnerability

4.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.1.1 Motivations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.1.2 Relation between percolation, vulnerability and spreading . . . . . . . . . . . .
4.2 Vulnerability of Weighted Networks: a case study . . . . . . . . . . . . . . . . . . . . .
4.2.1 Weighted centrality measures . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2.2 Vulnerability of the WAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . .
4.2.3 Comparison with the spatial BBV model
4.2.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .
4.3.1 Generalized Molloy-Reed Criterion in Weighted Random Graphs . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . .
4.3.2 Examples and Numerical Simulations
4.3.3 Discussion and Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.3 Spreading processes on Weighted Random Graphs

5 The Naming Game

5.1
5.2 Naming Game: General features

93
93
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
5.2.1 The Model
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
5.2.2 Mean-ﬁeld case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3 The Role of the Topology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
5.3.1 Coarsening dynamics on low-dimensional lattices . . . . . . . . . . . . . . . . . 102
5.3.2 Crossover to a fast-converging process in small-world networks
. . . . . . . . . 105
5.3.3 Naming Game on complex networks . . . . . . . . . . . . . . . . . . . . . . . . 109
. . . . . . . . . . . . . . . . . . . . . . . 122
5.4.1 Numerical results on agents activity . . . . . . . . . . . . . . . . . . . . . . . . 123
5.4.2 Theoretical interpretation and future work . . . . . . . . . . . . . . . . . . . . 125
5.5 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129

5.4 Agents activity in heterogeneous populations

6 General Conclusions and Outlook

Acknowledgements

A Generating Functions in Percolation Problems

B A General Percolation Theory for Spreading Processes

141
B.1 Markovian Networks with Multi-Type Nodes
. . . . . . . . . . . . . . . . . . . . . . . 141
B.2 Degree-based Multi-type Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
B.3 Local Homogeneity Approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146

C Naming Game solution in d = 1

D Master equation approach to agents internal dynamics

61
61
62
65
68

71
71
71
72
75
75
78
81
82
84
85
88
92

133

135

137

149

153

Bibliography

157

iv

List of Publications

The results exposed in this thesis have been published in a series of papers and preprints that we
report here divided by argument:

Exploration of networks (Chapter 3):

•

•

•

- Dall’Asta, L., Alvarez-Hamelin, J. I., Barrat, A., V´azquez, A., and Vespignani, A.

‘Traceroute-like exploration of unknown networks: A statistical analysis,’
Lect. Notes Comp. Sci. 3405, 140-153 (2005).

- Dall’Asta, L., Alvarez-Hamelin, J. I., Barrat, A., V´azquez, A., and Vespignani, A.,

‘Exploring networks with traceroute-like probes: theory and simulations,
Theor. Comp. Sci. 355, 6-24 (2006).

- Dall’Asta, L., Alvarez-Hamelin, J. I., Barrat, A., V´azquez, A., and Vespignani, A.,

‘Statistical theory of Internet exploration,’
Phys. Rev. E 71 036135 (2005).

- Dall’Asta, L., Alvarez-Hamelin, J. I., Barrat, A., V´azquez, A., and Vespignani, A.,

‘How accurate are traceroute-like Internet mappings?,’
Comference Proc. AlgoTel ’05, INRIA, 31-34 (2005).

- Viger, F., Barrat, A., Dall’Asta, L., Zhang, C.-H., and Kolaczyk, E.,

‘Network Inference from Traceroute Measurements: Internet Topology ‘Species’,’
preprint arxiv:cs/0510007 (2005).

k-core analysis of networks (Chapter 3):

- Alvarez-Hamelin, J. I., Dall’Asta, L., Barrat, A., and Vespignani, A.,

‘k-core decomposition: a tool for the visualization of large scale networks,’
preprint arxiv:cs/0504107 (2005).

- Alvarez-Hamelin, J. I., Dall’Asta, L., Barrat, A., and Vespignani, A.,

‘k-core decomposition: a tool for the analysis of large scale Internet graphs,’
preprint arxiv:cs/0511007 (2005).

- Alvarez-Hamelin, J. I., Dall’Asta, L., Barrat, A., and Vespignani, A.,

‘Large scale networks ﬁngerprinting and visualization using the k-core decomposition,’
in Advances in Neural Information Processing Systems, NIPS ’05 18 (2005).

Functional properties of weighted networks (Chapter 4):

- Dall’Asta, L.,

‘Inhomogeneous percolation models for spreading phenomena in random graphs,’
J. Stat. Mech. P08011 (2005).

v

vi

•

•

- Dall’Asta, L., Barrat, A., Barth´elemy, M., and Vespignani, A.,

‘Vulnerability of weighted networks,’
J. Stat. Mech. in press, preprint arxiv:physics/0603163, (2006).

Naming Game Model (Chapter 5):

- Baronchelli, A., Dall’Asta, L., Barrat, A., and Loreto, V.,

‘Topology Induced Coarsening in Language Games,’
Phys. Rev. E 73, 015102(R) (2006).

- Baronchelli, A., Dall’Asta, L., Barrat, A., and Loreto, V.,
‘Strategies for fast convergence in semiotic dynamics,’
ALIFE X, Bloomington Indiana (2006), (preprint arxiv:physics/0511201).

- Dall’Asta, L., Baronchelli, A., Barrat, A., and Loreto, V.,

‘Agreement dynamics on small-world networks,’
Europhys. Lett. 73(6), 969-975 (2006).

- Dall’Asta, L., Baronchelli, A., Barrat, A., and Loreto, V.,

‘Non-equilibrium dynamics of language games on complex networks,’
submitted to Phys. Rev. E (2006).

Other works published during the PhD:

- B¨orner, K., Dall’Asta, L., Ke, W., and Vespignani, A.,

‘Studying The Emerging Global Brain: Analyzing And Visualizing The Impact Of Co-Authorship
Teams,’
Complexity 10(4), 57-67 (2005).

- L. Dall’Asta,

‘Exact Solution of the One-Dimensional Deterministic Fixed-Energy Sandpile,’
Phys. Rev. Lett. 96, 058003 (2006).

- M. Casartelli, L. Dall’Asta, A. Vezzani, and P. Vivo,

‘Dynamical Invariants in the Deterministic Fixed-Energy Samdpile,’
submitted to Eur. Phys. J. B, preprint arxiv:cond-mat/0502208 (2006).

Chapter 1

Introduction

1.1 A networked description of Nature and Society

The recent interest of a wide interdisciplinary scientiﬁc community for the study of complex networks
is justiﬁed primary by the fact that a network description of complex systems allows to get relevant
information by means of purely statistical coarse-grained analyses, without taking into account the
detailed characterization of the system. Moreover, using an abstract networked representation, it is
possible to compare, in the same framework, systems that are originally very diﬀerent, so that the
identiﬁcation of some universal properties becomes much easier. Simplicity and universality are two
fundamental principles of the physical research, in particular of statistical physics, that is tradition-
ally interested in the study of the emergence of collective phenomena in many interacting particles
systems, even outside its classical ﬁelds of research such as condensed matter theory.
Along the last century, statistical physicists have developed a suite of analytical and numerical tech-
niques by means of which it has been possible to understand the origin of phase transitions and
critical phenomena in many particle systems, and that have been successfully applied also in other
ﬁelds, from informatics (e.g. optimization problems) to biology (e.g. protein folding) and social sci-
ences (e.g. opinion formation models). The presence of disorder, randomness and heterogeneity is the
other important ingredient that justiﬁes the use of statistical physics approaches in so many diﬀerent
ﬁelds and in particular in the study of complex networks, that present non-trivial irregular topological
structures.
From a mathematical point of view, complex networks are sets of many interacting components, the
nodes, whose collective behavior is complex in the sense that it cannot be directly predicted and
characterized in terms of the behavior of the individual components. The links connecting pairs of
components correspond to the interactions that are responsible of the global behavior of the system.
It is clear that a large number of systems can be described in this manner, thus it is not diﬃcult
to ﬁnd disparate examples of networks both in nature and society. The most evident application of
networks theory is the study of the Internet [203], whose detailed characterization is not possible, but
that can be investigated using the statistical analysis of its topological and functional properties. In
general, all infrastructures ﬁt very well the framework of networks theory, so that most of the real
networks studied are communication or transportation networks (such as the Internet, the Web, the
air-transportation network, power-grids, telephone and roads networks, etc) [102]. A second class is
represented by those networks related to social interactions [245], such as sexual-contact networks,
networks of acquaintances or collaboration networks. Finally, another large class concerns biological

1

2

CHAPTER 1.

INTRODUCTION

networks [153, 102] (e.g. protein interaction networks, cellular networks, neural networks, food-webs,
etc.).
The massive use of statistical techniques in the characterization of complex networks is, however,
closely related with the recent improvement of computers, that allow to easily retrieve, collect and
handle large amounts of data. In the last decade, indeed, the analysis of the topological structure
of large real networks such as the Internet and the Web pointed out that many real networks have
unexpected topological properties, characterized by heterogeneous connectivity patterns [120]. These
surprising results were in contrast with the common belief that real networks could be modeled using
either regular networks (e.g. grids or fully connected networks) or random graphs (i.e. networks
in which nodes are randomly connected in such a way that all them have approximately the same
number of connections [77]). These models have been studied for a long time without the necessity
of a relevant statistical analysis, since in such networks all nodes are approximately equivalent, and
the overall behavior of the network is well represented by monitoring that of a single node. On the
contrary, the recent discoveries immediately revealed a completely diﬀerent scenario.
A large number of data about various networks have been gradually collected, ranging from social
sciences to biology, all of them presenting the same type of heterogeneity in the connectivity patterns.
The necessity of a more mathematical analysis of networks excited a large number of physicists, who
recognized the possibility to apply the powerful methods of statistical physics. Without going into
a detailed description of the statistical framework that physicists have built introducing statistical
physics methods into the ideas inherited from graph theory (see Chapter 2 for an introduction), the
main achievement in the characterization of networks topology is the identiﬁcation of few universal
features that are common to many networks and allow to divide them into diﬀerent classes.
A ﬁrst relevant property regards the degree of a node (i.e. the number of connections to other nodes).
In real networks, the probability of ﬁnding a node with a given degree (i.e. the degree distribution)
signiﬁcantly deviates from the peaked distributions expected for random graphs and, in many cases,
exhibits a broadly skewed shape, with power law tails with an exponent between 2 and 3. In this
range of values for the exponent, the distribution presents diverging second moments, meaning that
we can ﬁnd very large ﬂuctuations in the values of nodes connectivity (scale-free property).
Moreover, real networks are characterized by relatively short paths between any two nodes (small-world
property [177, 247]), a very important property in determining networks behavior at both structural
and functional levels. The small world property, while intriguing, was already present in random
graphs models, in which the average intervertex distance scales as the logarithm of the number of
nodes. However, the novelty is due to the fact that real networks present this property together with
a high density of triangles and other small cycles or motifs, that are completely absent in traditional
random graphs, whose local structure is tree-like.
These unexpected results have initiated a revival of network modeling, resulting in the introduction
and study of new classes of modeling paradigms [102, 191, 203, 4]. Many eﬀorts have been spent
to conceive models that are able to reproduce and predict the statistical properties of real networks,
but researchers have soon realized that the characterization of real networks is not exhausted by its
topological properties and that in real networks topology and dynamics are intrinsically related.

1.2. RELATION BETWEEN TOPOLOGY AND DYNAMICS

3

1.2 Relation between Topology and Dynamics: a question of

timescales

The dynamical phenomena related to complex networks can be summarized in three diﬀerent cate-
gories: the dynamical evolution of networks, the dynamics on networks, and the dynamical interplay
between the networks topology and processes evolving on them.
The topology of real networks is indeed far from being ﬁxed, the number of nodes and links changing
together with local and global properties of the system. In particular, evolutionary principles are often
necessary ingredients in order to explain some peculiar topological properties of networks (e.g. the
preferential attachment principle is necessary to understand the emergence of degree heterogeneity in
networks such as the Internet or the Web).
On the other hand, networks are structures on which dynamical processes take place, thus it is inter-
esting to study the behavior of dynamical systems models evolving on networks. Many of them, such
as routing algorithms, oscillators, epidemic spreading, or searching processes, have direct applications
in the study of the dynamical phenomena observed on real networks, others such as random walks,
statistical mechanics models, opinion formation, percolation, and strategic games provide more gen-
eral information that can be used to build a common theoretical framework by means of which the
diﬀerent properties of dynamical processes on networks can be analyzed and explained.
The third situation, characterized by the interplay of the dynamics “of networks” with the dynamics
“on networks” is more complicated and such kind of problems has been only recently considered by the
complex networks community. Moreover, this case has been usually neglected because of the diﬀerent
temporal scales of the two types of dynamics. We can indeed assume that the structural properties of a
network evolve with a time-scale τT , while a particular dynamical process taking place on the network
evolves with time-scale τD, the above mentioned situation corresponding to the case τT ≃
τD. When
τD, we can study the evolution of dynamical processes on networks with quenched topological
τT ≫
τT means that the temporal evolution of processes on the network is
structure; while the case τD ≫
neglected compared to that of the network structure itself. The latter case holds not only when these
dynamical processes are slow compared to the changes in the topology, but also in the situation in
which these processes are fast but they do not inﬂuence the structure of the network.
While the evolution of networks topology has been largely investigated in the past, the present thesis
τD.
is devoted to study some aspects of dynamical processes on networks, i.e. the case in which τT ≫
Actually, the scenario is much more complicated since real networks are usually characterized by a
large number of dynamical processes evolving at the same time, so that in addition to the mentioned
topological and dynamical temporal scales, we have to distinguish the temporal scale governing the
evolution of a single process τ s
D from that governing the evolution of the overall average properties of
that class of processes τ o
D. This is simple to understand if we think at the functioning of the Internet.
Billions of data-packets are continuously transferred between the routers, each one performing a sort
of (random) walk on the network from a source to a destination. But looking at the global average
properties of the traﬃc, we observe suﬃciently stable quantities, so that we can encode the average
traﬃc between two neighboring routers (in terms of transferred bytes) using a single value, a weight,
by means of which we can label the corresponding link.
Therefore, a ﬁrst way to take into account of the dynamics is that of endowing the links with weights,
representing the ﬂow of information or the traﬃc among the constituent units of the system. More
generally, a weighted network representation allows to take into account the functional properties of
networks.

4

CHAPTER 1.

INTRODUCTION

τ o
D).

On the other hand, it is also important to focus on the dynamical behavior of single dynamical pro-
cesses, such as the spreading of information or viruses on social and infrastructure networks, or the
processes of networks exploration from a given source node. One of the striking results of this scales
separation is that it is also possible to study single dynamical processes, such as spreading and perco-
lation, in a weighted network, with quenched structural and functional properties (i.e. τ s
τT and
τ s
D ≪
As a ﬁnal remark, we note that also the general motivation with which we have studied dynamical
phenomena on networks is twofold. On the one hand, we wanted to study the eﬀects of inhomo-
geneous topological and functional properties on the behavior of some classes of dynamical models;
on the other hand, we have exploited some of these dynamical phenomena in order to investigate
unknown topological properties of real networks. This twofold role held by dynamical processes is
maybe the most important idea that statistical physicists should learn from the new interdisciplinary
ﬁeld of complex networks. Physicists have been used for many year to study a variety of interactions
on very well deﬁned topologies, now we have to face a more complex scenario, in which the role of
topology and dynamical rules may be even inverted, i.e. well-deﬁned dynamical phenomena can be
used to uncover topological properties of the system.

D ≪

1.3 Summary of the thesis

The work developed in this thesis concerns the study of various aspects of dynamical processes on
networks: each chapter is devoted to a particular issue, but apparently diﬀerent problems are related
by the general scenario that we have mentioned in the previous paragraph.

Chapter 2 provides an introduction to the science of complex networks:

in the ﬁrst part we
recall the main statistical measures used to analyze networks; then we give some examples of real
complex networks, focusing on the Internet and the World-wide Air-transportation Network; the ﬁnal
section is devoted to review the most important theoretical models of complex networks. This is not
an exhaustive introduction, but it is conceived to give the most relevant notions that are used or
mentioned in the rest of the work.

Chapter 3 concerns the theoretical characterization of the processes of exploration of complex
networks. The relevance of this topic resides in the fact that the topology of real networks is often
only partially known, and the methods used to acquire information on such topological properties
may present biases aﬀecting the reliability of the phenomenological observations. We consider several
diﬀerent types of networks sampling methods, discussing their advantages and limits with respect to
their natural ﬁelds of application. We focus in particular on a tree-like exploration method used in
real mapping processes of the Internet and referred as traceroute exploration. In order to verify the
reliability of the experimental data, and consequently of the main properties, such as the existence
of a broad degree distribution, that have been derived from their analysis, we propose a theoretical
model of traceroute exploration of networks. This model allows an analytical study by means of a
mean-ﬁeld approximation, providing a deeper understanding of the relation between the topological
properties of the original network and those of the sampled network. Moreover, massive numerical
simulations on computer-generated networks with various topologies allows to have also a clearer
quantitative description of the mapping processes. The general picture acquired from this study is
ﬁnally exploited to introduce a statistical technique by means of which some of the biased quantities
can be opportunely corrected.
This topic is also a clear example of the possible use of dynamical processes for the characterization

1.3. SUMMARY OF THE THESIS

5

of unknown topological properties of real networks.

In Chapter 4, we take into account the weighted network representation and its relation with the
functional properties of the network. In the ﬁrst part of the chapter, we investigate the role of weights
in determining the functional robustness of the system, and we compare the results with those based
on purely topological measures. We use the case study of the airports network. The main idea is
that of measuring the vulnerability of the network using global observables based on both topological
and traﬃc centrality measures: we remove the most central nodes according to diﬀerent centrality
measures, monitoring the eﬀects on the structural and functional integrity of the system.
This study gives an example of the diﬀerent roles played by topology and weights, at the same time
pointing out the validity of a static representation of networks functionality (i.e. encoding average
ﬂows and traﬃc into weights on the edges). The second part of the chapter is instead devoted to study
weighted networks from a purely dynamical point of view. Exploiting some remarkable properties of
percolation theory, we build a general theoretical framework in which spreading processes on weighted
networks can be analyzed.
Using an analogy with the scenario proposed in the previous paragraph, passing from the ﬁrst to the
second part of the chapter, we pass from a situation in which we are interested only in the structural
and functional properties determined by the average dynamical behavior of the system, to the study
of the eﬀects of such (structural and functional) properties on the evolution of a particular dynamical
process on the network.

Chapter 5 is completely devoted to the analysis of the recently proposed Naming Game model,
that was conceived as a model for the emergence of a communication system or a shared vocabulary
in a population of agents. The rules governing the pairwise interactions between the individuals are
simple but present several new features such as negotiation, feedback and memory, that are typical
properties of human social dynamics. For this reason the model can be usefully applied also in diﬀerent
contexts, such as problems of opinion formation.
The dynamical evolution of the model is studied considering populations with diﬀerent topologies,
from regular lattices to complex networks, showing that the dynamical phenomena generated by the
model depend strongly on the topological properties of the system. In the last section of the chapter,
the attention is focused on the activity patterns of single agents, that display rather unexpected
properties due to the non-trivial relation between memory and degree heterogeneity.

General conclusions on the work done and possible future developments of the ideas exposed in

the thesis are reported in Chapter 6.

6

CHAPTER 1.

INTRODUCTION

Chapter 2

Structure of complex networks: an
Overview

2.1

Introduction

The ﬁrst step toward a complete characterization of complex networks consists in a reliable description
of their topological properties. As we will see in the following chapters, topological quantities play a
relevant role in determining the functionality of real networks as well as the dynamical patterns of
processes taking place on them. Consequently, we devote Section 2.2 to introduce a set of mathematical
tools, some of them borrowed from Graph Theory, that will be useful in the statistical investigation
of complex networks. In Section 2.3, several examples of real complex networks are reported, together
with the analysis of their most important topological properties. Special care is reserved to the Internet
and the World-wide Air-transportation Network, whose topological and dynamical properties will be
further investigated in Chapters 3-4. Finally, in Section 2.4, we present a brief overview of the main
models of complex networks, that are commonly used in order to reproduce topological and dynamical
properties observed in real networks. The present chapter is not supposed to be an exhaustive review
of all recent developments in the Science of Complex Networks, for which we refer to some very good
books [203, 102], and review articles [103, 4, 191]. Similarly, for a simple introduction to Graph Theory
we refer to Ref. [77], while a more rigorous approach is provided by the book of Bollob´as [48].
Our purpose is more properly that of providing a brief description of the measures used in networks
analysis, focusing only on those concepts that are useful for a better comprehension of the work
developed in the thesis.

7

8

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

2.2 Statistical Measures of Networks Topology

Graph theory is a fundamental ﬁeld of mathematics whose modern formulation can be ascribed to P.
Erd¨os and A. R´enyi, for a series of papers appeared in the early ’60s in which they laid the groundwork
for the study of random graphs [115, 116]. In the following, we go through the basic notions of graph
theory, enriching them with the deﬁnition of other more recently introduced quantities, that are
commoly used for the statistical characterization of networks structure.

2.2.1 Basic notions of Graph Theory

,

E

E

V

V

), in which

is a
An undirected graph G is a mathematical structure deﬁned as the pair G = (
non-empty set of elements, called vertices, and
is the set of edges, i.e. unordered pairs of vertices.
More generally, each system whose elementary units are connected in pairs can be represented as
a graph. In the interdisciplinary context the nomenclature used is not equally clear. Vertices are
usually called nodes by computer scientists, sites by physicists and actors by sociologists. Edges are
also addressed as links, bonds, or ties. We will use indiﬀerently these terms, without any reference
to a particular ﬁeld of research. The cardinality of the sets
are denoted by N and E. The
number of vertices is also referred to as the size of the graph. The simplest generalization of the
deﬁnition of graph is that of directed graph, obtained considering oriented edges (arcs), i.e. ordered
pairs of vertices. A graphical representation of a graph consists in drawing a dot for every vertex, and
a line between two vertices if they are connected by an edge (see Fig. 2.1). If the graph is directed,
the direction is indicated by drawing an arrow.
A convenient mathematical notation to deﬁne a graph is the adjacency matrix A =
matrix such that

aij}

, a N

and

N

×

V

E

{

aij =

1
0

(

(i, j)
if
∈ E
otherwise .

(2.1)

P

The adjacency matrix of undirected graphs is symmetric. Two vertices joined by an edge are called
(i) of all neighbors of the node i. The
adjacent or neighbors; the neighborhood of a node i is the set
j aij of i. In case of directed edges, we have
number of neighbors of a node i is called the degree ki =
to distinguish between incoming and outcoming edges, thus we deﬁne an in-degree (kin
j aji)
and an out-degree (kout
j aij). We do not go deeper into the deﬁnition of properties for directed
graphs, since in this thesis only undirected networks will be explicitly studied.

i =

i =

P

P

V

Moreover, we consider graphs in which vertices do not present self-links (i.e. edges from a vertex
to itself), or multi-links (i.e. more than one edge connecting two vertices). Such objects, whose
If we
properties are rather unusual in real networks, are known in graph theory as multigraphs.
exclude self-links and multiple links, the maximum possible number of edges is N (N
1)/2. Those
graphs, whose number of edges is close to such a value, are called dense graphs, while the graphs in
which the number of edges is bounded by a linear function of N are sparse graphs.
A generalization of the notion of graph, that will be repeatedly taken into account in the following
chapters, is that of weighted graph.
In weighted (directed or undirected) graphs, each edge (i, j)
carries a weight, that is a variable wij assuming real (or integer) values. However, also the nodes
can be diﬀerentiated, introducing classes of nodes with the same set of internal variables. Graphs
with distinct classes of nodes will be denoted as multi-type graphs. Graphs in which there are two or
more distinct sets of nodes with no edges connecting vertices in the same set are commonly referred
as multipartite graphs. Real networks are actually weighted and multi-type, though in many situations
it is more convenient to study their properties by means of single-type, unipartite and/or unweighted

−

2.2. STATISTICAL MEASURES OF NETWORKS TOPOLOGY

9

Figure 2.1: Basic elements of graph theory and their typical graphic representations: (A) vertices and
edges in an undirected graph, (B) directed edges indicated by arrows in a directed graph, (C) the
degree of a node, and (D) weighted edges.

representations.

2.2.2 Degree distribution

A natural way to collect nodes in classes is that of considering nodes with the same degree k. This
is a convenient strategy to analyze large graphs, since the connectivity properties of the nodes are
statistically represented by the histogram P (k) = Nk/N , in which Nk is the number of vertices
), P (k) is called degree distribution, since it
of degree equal to k. In the inﬁnite size limit (N
represents the probability distribution that a node has degree k. The degree distribution P (k) satisﬁes
∞
a normalization condition
k=0 P (k) = 1. The average degree of an undirected graph is deﬁned as
the average value of k over all the vertices in the graph,
P

→ ∞

kP (k)

2E
N

.

≡

=

k
h

i

Xk

(2.2)

k
h

(1).

The condition of sparseness for a graph can be translated into
However, in order to study topological properties of networks, the knowledge of higher moments of the
degree distribution is also important. For instance, the second moment
measures the ﬂuctuations
of the degree distribution, and governs the percolation properties [80]; while higher moments determine
conditions for the mean-ﬁeld behavior of the Ising model on general networks [104].
For a long time, Graph Theory has been interested in random graphs with homogeneous connectivity,
i.e. with a degree distribution that is very peaked around a characteristic average degree and decays
. On the contrary, recent phenomenological ﬁndings have shown that a
exponentially fast for k
i

i ≃ O

k2
h

≫ h

k

i

10

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

large number of real networks present heavy-tailed distributions, some of them close to a power-law
behavior.
In these networks, there is a non-negligible probability of ﬁnding “hubs”, i.e. nodes of
degree k

k

≫ h

.
i

2.2.3 Two and three points degree correlations

The degree distribution does not exhaust the topological characterization of a network, since it has
been shown that many real networks present degree correlations between nodes, i.e. the probability
that a node of degree k is connected to another node of degree k′ depends on k and k′ themselves. More
rigorously, we can introduce a conditional probability P (k′
k) that a vertex of degree k is connected to
|
a vertex of degree k′. This quantity satisﬁes a normalization
k) = 1 and a detailed balance
|
condition [43]

k′ P (k′

kP (k′

k)P (k) = k′P (k
|

P
k′)P (k′) ,
|

corresponding to the absence of dangling bonds. In uncorrelated graphs, P (k′
k) does not depend on
|
k and it can be easily obtained from the normalization condition and Eq. 2.3,

P (k′

k) =
|

k′P (k′)
k
h

i

.

Similarly, it is possible to deﬁne a three-points correlation function P (k′, k′′
that a vertex of degree k is simultaneously connected to vertices of degree k′ and k′′.
In general, the direct measurement of these two conditional probabilities is quite cumbersome and
gives very noisy results on any kind of network. For this reason one usually prefers more practical
estimates by means of indirect quantities, that are averaged over the neighborhood of a node.
In a given network with adjacency matrix
aij }
{
vertex i is provided by the average degree of the nearest neighbors of i

, a good estimation of the degree correlations of a

k), i.e. the probability
|

knn,i =

aijkj .

1
ki

N

j=1
X

knn(k) =

k′P (k′

k) .
|

Deﬁning the network using its degree distribution, the average degree of the nearest neighbors of a
vertex of degree k is

≃

Xk′
If the network is uncorrelated, the degree of the neighbors can assume any possible value, and the
average turns out to be approximately independent of k, i.e. knn(k)
const. On the contrary,
correlated networks can be schematically divided in two large classes. The ﬁrst class is that of those
presenting assortative mixing, i.e. nodes of high (small) degree are more likely to be connected
with nodes of high (small) degree (knn(k) grows with k). This seems to be a general property of
social networks. When vertices of high degree are preferentially linked with vertices of smaller degree
(and viceversa), i.e. knn(k) is a decreasing function of k, the network has disassortative mixing.
Many critical infrastructures such as transportation and communication networks present a clearly
disassortative behavior.
Analogously, for three-points correlations, we can deﬁne a quantity called clustering coeﬃcient that
measures the tendency of a graph to form cliques in the neighborhood of a given node. As depicted in
Fig. 2.2-A, the clustering coeﬃcient of a node i is deﬁned as the ratio of the actual number of edges
ni between the neighbors of i, and the maximum possible number of such edges ki(ki −
2ni
ki(ki −

jh aij ajhahi
ki(ki −

1)/2, i.e.

c(i) =

(2.7)

P

1)

1)

=

.

(2.3)

(2.4)

(2.5)

(2.6)

2.2. STATISTICAL MEASURES OF NETWORKS TOPOLOGY

11

Figure 2.2: (A) The clustering coeﬃcient gives a measure of the local cohesiveness in the neighborhood
of a vertex: the central node in the example has clustering coeﬃcient c = 1 if all pairs of neighbors
of the vertex are connected, c = 0.5 if only half of the possible pairs are connected, and c = 0 if no
triangles are formed. (B) The dashed path represents the shortest path (of length ℓij = 4) between
nodes i and j.

The study of the clustering spectrum c(k),

c(k) =

c(i) ,

1
Nk

Xi/ki=k

provides interesting insights on the local cohesiveness of the network.
In particular, a clustering
coeﬃcient decreasing with the degree k has been put in relation with the existence of hierarchical
structures (e.g. in biological networks [210]).

2.2.4 Shortest path length and distance

Many non-local properties of graphs are related to the reachability of a vertex starting from another.
A walk from a vertex i to a vertex j consists in a sequence of edges and vertices joining i with j. The
length l of the walk coincides with the number of edges in the sequence. A path is a walk in which no
node is visited more than once. A graph is connected if for any pair of vertices i and j, there is a path
from i to j. The number of walks of length l between two nodes i and j can be expressed by the l-th
power of the adjacency matrix

Al

ij =
(cid:1)

(cid:0)

i1,i2,...,il−1
X

aii1 ai1i2 · · ·

ail−1j .

In particular, this deﬁnition is related to the behavior of a random walker on the graph. A closed
walk, in which initial and ﬁnal vertices coincide, is called a cycle; a k-cycle is a cycle of length k.

(2.8)

(2.9)

12

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

The walk of minimum length between two nodes is called shortest path, and its length corresponds to
the hop distance ℓij between the nodes i and j (see Fig. 2.2-B). The diameter ℓmax is the maximum
distance between pairs of nodes in the graph, while the average distance
between nodes is given
by

ℓ
h

i

=

ℓ
h

i

1
N (N

ℓij

1)

−

Xi6=j

(2.10)

i

ℓ
h

ℓ
h

ℓ
h

i ∝

N 1/d.

A complete characterization of the metric properties of a graph corresponds to know the full proba-
bility distribution Pℓ(ℓ) of ﬁnding two vertices separated by a distance ℓ. In fact, many real networks
, that can be safely considered
ℓ
present a symmetric distribution peaked around the average value
i
h
representative of the typical distance between nodes in the network.
From this point of view, complex networks seem to share a striking property, called small-world eﬀect
[247, 246], meaning that the average intervertex distance
is very small compared to the size N
of the network, scaling logarithmically or slower with it. While this property can be found also in
generic random graphs, where
log N , the result is in contrast with the behavior of the distance
on regular d-dimensional lattices, in which
The practical implication of the small-world property is that it is possible to go from a vertex to any
other in the network passing through a very small number of intermediate vertices. In this regard,
the concept of small-world was ﬁrstly popularized by the sociologist S. Milgram in 1967 by means of a
famous experiment [177], in which he showed that a low number of acquaintances, on average only six,
is actually suﬃcient to connect (by letter) any two individuals in the United States. The experiment
was recently reproduced using the world-wide e-mail network and provided results consistent with the
small-world hypothesis [100].
Note that the presence of the small-world property is relevant not only at a topological level, but it
has also strong eﬀects on all dynamical processes taking place on the network.
A plethora of diﬀerent statistical measures is based on the notions of distance and shortest path, some
of them are used in the topological characterization of networks, others in the study of the relation
between functional properties and dynamics (see Chapter 4); we concentrate our attention on central-
ity measures that will be extensively used in the following chapters.

i ∝

The metric properties of a graph are, indeed, very appropriate to deﬁne several diﬀerent measures
of centrality, that are used in social sciences to estimate the importance of nodes and edges. The
most local of these measures is the degree centrality, that is proportional to the degree of a node and
does not account for any metric feature of the graph. All other centrality measures involve non-local
properties in the form of the intervertex distance. For instance, the closeness centrality of a node i is
deﬁned as the inverse of the sum of the distances of all nodes from i.
The most famous measure of centrality is the betweenness centrality, deﬁned in Ref. [123] and recently
adopted in network science as the basic deﬁnition of centrality of nodes and edges. The node between-
ness centrality bi computes the relative number of all shortest paths between pairs of vertices that
pass through the vertex i, i.e.

σst(i)
σst

,

bi =

Xs6=i6=t

(2.11)

where σst = σts is the number of shortest paths between the vertices s and t, and σst(i) = σts(i) is the
number of them going through the node i. Similarly, the edge betweenness centrality bij is deﬁned as
the fraction of all shortest paths from any pair of vertices in the network that pass through the edge

2.2. STATISTICAL MEASURES OF NETWORKS TOPOLOGY

13

Figure 2.3: (A) Star-like network, the node v (in red) has maximum betweenness because all shortest
paths have to pass through the central node. (B) A fully connected clique is characterized by a zero
betweenness value for all nodes. (C) The node v (in red) connects two highly connected groups of
nodes: its betweenness is very high even if its degree is very low.

(i, j),

bi,j =

Xs6=i6=j6=t

σst(i, j)
σst

,

(2.12)

in which σst(i, j) is the number of shortest paths going through the edge (i, j).
It is worthy to
remark that in the literature there are several slightly diﬀerent deﬁnitions of betweenness centrality:
in particular, a prefactor 1/2 can be considered in order not to count twice the paths, while the paths
containing the interested nodes (i.e. i and/or j) as initial or ending points can be accepted or discarded
(the two cases diﬀering just by a constant contribution). The computational cost of determining the
betweenness centrality for all vertices (or edges) in a graph is very high, since one has to discover
all existing shortest paths between pairs of vertices. An optimized algorithm, proposed by Brandes
[53], allows to reduce the computational complexity from
(N E). For sparse graphs the
(N 2) steps, that is still a high complexity when the size of the network is
algorithm performs in
O
(106)), or when the computation has to be repeated many times, as for the
very large (e.g. N
∼ O
measures exposed in Chapter 4.
Figuring out the meaning underlying the notion of betweenness centrality is simple by means of few
examples dealing with extreme topological conditions. Let us consider a star network with a unique
1 leaves at a distance 1 from the center (see Fig. 2.3-A). The node betweenness
central vertex v and N
centrality of v is simple to compute because v belongs to all shortest paths between pairs of leaf nodes,
therefore the sum in Eq. 2.11 becomes a sum of unit contributions and we get bv = (N
2).
The opposite situation is the complete graph, in which all vertices, according to the deﬁnition in
Eq. 2.11, have zero betweenness centrality (Fig. 2.3-B). Another interesting case is that of a node

(N 2E) to

1)(N

O

O

−

−

−

14

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

or an edge joining, as a bridge, two otherwise disconnected portions of a network (Fig. 2.3-C): all
paths connecting pairs of nodes belonging to diﬀerent regions have to pass through that particular
node (edge), that turns out to have very high betweenness even if it may have very low degree. This
property shows that in many networks, as we will see, betweenness centrality is non-trivially correlated
with the other topological properties.

2.2.5 Subgraph structures

′

′

′

,

E

E

E

V

V

V

V

V

V

′,

′,

′)

O

) if

E|V

⊂ E

and

⊂ V

(N ).

, we call G′ = (

′) is a subgraph of the graph G = (

In this paragraph, we discuss a series of topological properties dealing with the structure of subsets of
a graph. Firstly, a graph G′ = (
. A
maximal subgraph with respect to a given property is a subset of the graph that cannot be extended
without loosing that property. Given a subset of nodes
G the
⊆ V
′. A component of a graph G is a maximally connected subgraph of G; it
subgraph of G induced by
is called giant component if its size is
We have already seen that the clustering coeﬃcient is a measure of the cohesiveness of a graph;
however, the maximal cohesiveness corresponds to sets of nodes with all-to-all connections, called
cliques. Formally, a clique is a maximally complete subgraph of three or more nodes. Though there
are several other quantities involving the subgraph’s deﬁnition, such as the n-cliques, or the k-plexes,
for the purposes of this work, we are only interested in two of them: k-cores and k-shells.
The k-core of a graph G is the maximal induced subgraph of G whose vertices have the property of
having degree at least k [47, 221]. (Note that it means that they must have degree at least k inside
the subgraph!). Such a subgraph can be obtained by recursively removing all the vertices of degree
lower than k, using a procedure called k-core decomposition.
Let us call Nk the number of nodes in the graph with degree not larger than k and
belonging to the k-core, the algorithm reads

Ck the set of nodes

⊆

(1) Set k = 0 (

Ck is empty

∀

k > 0,

C0 ≡

G);

(2) k

k + 1;

→

(3) Prune all nodes with degree lower than k (and the corresponding edges);

(4) Update Nl,

0 according to the pruned network;

l
∀

≥

(5) Repeat point (3) until Nl<k = 0;

(6) Put all remaining nodes (and edges) in

Ck and go back to point (2).

A node has shell index k if it belongs to the k-core but not to the k + 1-core; the k-shell is the set of
all vertices of shell index k, i.e. the diﬀerence between two consecutively nested cores. The algorithm
is very clear if we look at simple cases similar to that sketched in Fig. 2.4, in which k-cores and k-shell
are highlighted using diﬀerent colors.

Finally, we usually refer to communities when the graph can be reduced to a certain number of
subgraphs characterized by the property that, for each of them, the number of edges connecting the
subgraph with the rest of the graph is very small compared to the number of edges linking diﬀerent
vertices within the same subgraph.
In such a case each subgraph is a community, as depicted in
Fig. 2.5. The deﬁnition of community is not rigorous, thus the community structure of a network
depends strongly on the practical method used to detect the subgraphs. Several algorithms have
been proposed in order to ﬁnd the community structure of networks. Some of them reduce iteratively

2.2. STATISTICAL MEASURES OF NETWORKS TOPOLOGY

15

Figure 2.4: Illustration of the k-core structure of a simple graph. The blue circle contains the 1-core,
i.e. the giant connected component of the graph. The two smaller contours draw the boundaries of
the 2-core (red) and 3-core (black). Blue nodes belong to the 1-shell, the red and black ones to the
2-shell and 3-shell respectively. The internal sets can be obtained from the larger ones by iterative
pruning of nodes as explained in the text.

the size of the diﬀerent subgraphs, while others are based on the opposite principle of clustering
algorithms, but all them suﬀer of the same incapacity of detecting the correct level at which the
iterative procedure should be stopped. This is probably an intrinsic problem due to the absence of a
rigorous deﬁnition able to ﬁx the correct resolution at which the community structure is more visible.
Some of the algorithms used to detect communities are based on topological properties, such as the
betweenness [128], others exploit the properties of some dynamical systems, e.g. synchronizability of
oscillators [12]. In Chapter 5, we will show that also non-equilibrium models of coarsening dynamics
can be used to put forward alternative methods to detect communities.

2.2.6 Further metrics for weighted networks

In many real networks, edges are not identical, they can have diﬀerent intensities, that are related to
some physical properties and are taken into account assigning them a weight. For instance, in the
Internet the edges represent physical connections, cables, thus weights could be introduced to account
for their bandwidth, or the traﬃc between routers. In the air-transportation network, the weights are
proportional to the traﬃc on the airline connections. Hence, in the technological and infrastructure
networks, weights usually correspond to some physical quantities (energy, information, goods, . . . )
that are transferred between two nodes. On the other hand, in biological networks weights account
for the strength of the interactions between genes or proteins; whereas in social networks they specify
the intensity of interactions between the actors.

16

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

Figure 2.5: An example of network with a very strong community structure. The number of edges
connecting nodes belonging to the same community (black full links) is much larger than the number
of edges between nodes in diﬀerent communities (red dashed links).

Many statistical quantities that have been introduced for unweighted networks can be easily general-
ized to weighted networks. The degree is generalized introducing the node strength; the strength si of
a node i is

si =

wij ,

Xj∈V

where wij is the weight on the edge (i, j) [23, 252] (see Fig. 2.6-A).
If the weights are distributed uniformly at random, the node strength turns out to be linearly correlated
k. In fact, the actual degree-strength correlations observed in many
w
with the degree, i.e. s(k)
real networks suggest rather a super-linear relation s(k)
(see
Chapter 4).

Akβ, with β > 1 and A

w
h

∼ h

∼

=

i

i

A standard measure in the analysis of weighted graphs is the strength distribution Ps(s), that
says which is the probability that a randomly chosen node has strength equal to s. Many weighted
networks with broad degree distribution, such as the World-wide Air-transportation Network, also
present broad weight and strength distributions.
Other quantities are readily extended in order to account for weights, in particular two- and three-
points correlations. For each vertex i one can deﬁne a weighted average nearest neighbors degree,

and a weighted clustering coeﬃcient

kW
nn,i =

1
si

wij kj ,

Xj∈V

cW
i =

1
si(ki −

1)

j,m
X

wij + wim
2

aijajmami .

(2.13)

(2.14)

(2.15)

6
2.2. STATISTICAL MEASURES OF NETWORKS TOPOLOGY

17

Figure 2.6: (A) Strength si of the node i computed as the sum of the weights along the edges
connecting i with its neighbors. (B) The weighted clustering coeﬃcient cW gives a measure of local
cohesiveness in presence of weights. Larger weights are responsible for larger weighted clustering. (C)
The weighted shortest path (red dashed links) can be topologically (number of links) longer than the
unweighted shortest path (grey dashed links). The weighted shortest path depends on the deﬁnition
of edge length, that in this case is ℓij = 1/wij.

nn(k) and cW (k) can be directly compared with the unweighted
The degree dependent functions, kW
measures knn(k) and c(k), providing interesting information on the role of the weights. For the
clustering coeﬃcient, the interpretation is particularly easy (Fig. 2.6-B): when the weighted clustering
coeﬃcient is larger than the topological one, it means that triples are more likely formed by edges
with larger weights. A similar interpretation holds for the relation between kW
With respect to unweighted networks, when edges are weighted the neighborhood of a node is not
homogeneous, namely the edges outgoing from a given vertex can in principle carry very diﬀerent
In order to quantify the homogeneity of the neighborhood of a node i, we consider the
weights.
disparity measure [97, 34],

nn(k) and knn(k).

Yi =

2

.

wij
si (cid:19)

Xj∈V(i) (cid:18)
This quantity depends on the degree, in such a way that, when the weights are comparable, Y (k)
1/k, while when an edge dominates on the others Y (k)
Many other weighted quantities have been deﬁned, but the most important for the topics discussed in
the rest of this thesis are the weighted centrality measures and, in particular, the weighted betweenness
centrality.
Actually, it is suﬃcient to deﬁne the weighted shortest path and all centrality quantities can be directly
constructed from it (Fig. 2.6-C). To each edge (i, j) in the network, we associate a distance that is a

1.

∼

∼

(2.16)

18

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

ij = ℓW (wij ), whose explicit form depends on the nature of the weights.
function of the weight, i.e. ℓW
For instance, in the airports network weights are proportional to the traﬃc capacity, and a larger
traﬃc capacity leads to a better transmission along an edge, that from a “functional” point of view
corresponds to decrease the distances. Hence, we expect that the weighted distance along the edge
(i, j) is inversely proportional to the weight, i.e. ℓW
1/wij.
The deﬁnition of the node weighted betweenness centrality bW
consists in replacing all shortest paths
i
with their weighted versions. For any two nodes h and j, the weighted shortest path between h and
j is the one for which the total sum of the lengths of the edges forming the path from h to j is
minimum, independently from the number of traversed edges. We denote by σW
hj the total number of
weighted shortest paths from h to j and σW
hj (i) the number of them that pass through the vertex i
(with h, j

= i); the weighted betweenness centrality (WBC) of the vertex i is then deﬁned as

ij ∝

σW
hj (i)
σW
hj

,

bW
i =

Xh,j6=i
= h

(2.17)

where the sum is over all the pairs with j
= i. Similarly, we can deﬁne a weighted edge
betweenness. The algorithm proposed by Brandes in Ref. [53] can be easily extended to weighted
graphs, with no further increase in complexity.

6
6
6
2.3. EXAMPLES OF REAL NETWORKS

19

Figure 2.7: Diﬀerent granularity representations of the Internet: routers level (left) and autonomous
systems level (right). Routers are represented by blues nodes grouped in autonomous systems (circles).

2.3 Examples of real networks

In this section, we review of the phenomenological properties of two important real networks: the
Internet (in Section 2.3.1) and the World-wide Air-transportation Network (in Section 2.3.2). At the
same time it is an opportunity to show the practical use of the statistical measures deﬁned in the
previous section. Some of these properties are reliably considered quite universal in complex networks,
such as heavy-tailed degree distributions or the small-world property, others are typical features of
the particular network under study. Though a detailed discussion is reserved only for those networks
that have been objects of direct investigation in this thesis, for the sake of completeness we provide
in Section 2.3.3 a brief overview on the phenomenology of some other real networks.

2.3.1 The Internet

The Internet is a communication network in which the vertices are computers and the edges are the
physical connections among them. The existence of various types of vertices reﬂects the high level
of complexity and heterogeneity of the system: the hosts correspond to single-user’s computers; the
servers are computers or programs providing network services; the routers are computers devoted to
arrange traﬃc and data exchange across the Internet. Similarly, hosts and routers are linked by var-
ious types of connections, that are undirected and have diﬀerent traﬃc capacity depending on their
bandwidth.
The structure of the Internet is the result of a complex interplay between growth and self-organization,
involving processes of cooperation and competition, without central administration or external control.
A good knowledge of the topological structure of the Internet is necessary to improve its functionality,
and prevent the system from faults and traﬃc congestions. This is the main reason for the great
interest of researchers in studying the structure of the Internet.
An exhaustive introduction to the network properties of the Internet is provided by Refs. [203, 16];
we give here only some necessary information on its structure.
The ﬁrst important observation is that it is impossible to keep track of all single hosts, that are hun-
dreds of millions all around the world, organized in complex hierarchically structures, whose smaller
units are Local Area Networks, connected to the main net by means of routers. Monitoring the struc-
ture of single local networks is thus too diﬃcult, and partly useless since these networks are created

20

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

Figure 2.8: Graphs representations of the Internet at the autonomous systems level (left) and the
router level (right). Both graphs are based on data collected by the Internet’s mapping projects at
CAIDA [62].

just to connect hosts inside buildings, university departments, corporate networks, city areas etc, and
their properties depend on very local administrative policies. Hence, the lowest level of granularity
at which we can analyze the Internet topology is the so-called router level (IR), that is a graph with
routers as vertices and the physical connections among them as edges.
At a higher granularity level, the Internet can be partitioned into autonomously administered do-
mains, called Autonomous Systems (AS). Within each autonomous system, whose structure is not
deﬁned on the basis of geographical proximity but more frequently on commercial agreements and
policies, the traﬃc is handled following proper internal control strategies and restrictions, that can
vary considerably from AS to AS. In order to better understand routing problems, it is very convenient
to study the Internet topology at the level of the autonomous systems, considering each AS as a node
and connections between diﬀerent ASs as the links.
The mapping projects of the Internet deal mainly with these two scales of description: the autonomous
systems level (AS), and the router level (IR). Fig. 2.7 reports a scheme of the structure of the Internet
at both levels. For many years, the structure of the Internet has been considered similar to that
of a random graph, with a homogeneous degree distribution peaked around a characteristic degree
value. In the last decade, on the contrary, massive Internet measurements provided evidences against
such kind of modeling and in favor of topologies with heterogeneous degree distributions. Historically,
the ﬁrst experimental evidence of a power-law degree distribution at the AS level is contained in a
famous paper by Faloutsos et al. [120], who analyzed the data collected during the period 1997
1998
by the National Laboratory for Applied Network Research (NLANR) [196]. In the following years
many other studies, both at the AS and the router levels, always conﬁrmed this important discov-
ery [196, 62, 147, 216, 135, 219, 167, 241, 76]. Though the qualitative picture coming from these
two diﬀerent scales is the same, the two graphs show relevant quantitative diﬀerences, that can be
examined in depth using the statistical tools introduced in the previous section. Note that, the size
of the Internet is exponentially growing, but the major statistical measures do not change in time,

−

2.3. EXAMPLES OF REAL NETWORKS

21

AS

IR

0
10

-1

10

)
k
(
P

-2

10

-3

10

0
10

-1

10

-2

10

-3

10

-4

10

-5

10

10

-4
0
10

1
10

2
10
k

3
10

0
10

1
10

2
10

3
10

k

Figure 2.9: Two examples of the degree distributions obtained from Internet mapping projects. P (k)
is clearly power-law at the AS level (left), while it is broad but slightly bended at the IR level (right).
Both graphs are based on data collected by the Internet’s mapping projects at CAIDA [62].

∼

2.1).

suggesting the idea that the Internet, as a physical system, is in a sort of non-equilibrium stationary
state. Two typical pictures of the Internet’s AS and IR levels, obtained from the data of the CAIDA’s
mapping project [62], are displayed in Fig. 2.8.
Apart from the quantitative estimation of the exponent, that can be possibly aﬀected by measurement
biases, the existence of heavy-tails seems to be a solid feature of the Internet (see Chapter 3 for a
complete statistical analysis of the Internet exploration’s technique). In Fig. 2.9, we report the degree
k−γ (with
distributions for the AS (left) and IR (right) levels, that are clearly power-laws P (k)
γ
≃
In both cases, the distribution of the shortest path length is peaked around the average distance
whose very small value is signature of the occurrence of the small-world property.
Diﬀerences in the two levels of descriptions can be found looking at the degree correlations. The de-
gree dependent spectrum of the average degree of nearest neighbors knn(k) is roughly ﬂat or slightly
increasing with k for IR maps, while it shows a very clear disassortative behavior at the AS level. The
reason for disassortative correlations can be found in the strong hierarchical structure of the Internet
at the autonomous system level, that is absent at the router level. This hierarchical organization of the
Internet at the AS level is reﬂected also in other measurements, as for instance its k-core structure,
that is discussed in Refs. [66, 67, 8, 9, 7, 165] (see also Section 3.2.5).
Both levels show similar average clustering coeﬃcient, that is considerably higher than in standard
random graphs, reinforcing the idea that the Internet is far from being locally tree-like. The spectrum
of the clustering coeﬃcient is almost constant at the router level and clearly decreasing at the AS level.
The power-law functional dependence of c(k) on the degree k has been interpreted as a signature of
the presence of modular structures at diﬀerent scales [210].
Finally, the distribution of the node betweenness centrality Pb(b) is clearly power-law for the AS
2.0), while it shows a very broad distribution with a more bended shape
(Pb(b)

ℓ
h

,
i

b−γb, with γb ≃

∼

22

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

name

date

N

AS RV
AS CAIDA
AS Dimes
IR Mercator
IR CAIDA
IP Dimes

2005/04
2005/04
2005/04
2001
2003
2005

18119
8542
20455
228297
192243
328011

k
h
i
3.54771
5.96851
6.03862
2.79635
6.33085
8.2142

kmax

1382
1171
2800
1314
841
1453

k
h

k2
/
h
i
i
2369.82
521.751
1556.24
36838.6
8884.23
10954

ℓ
h
i
3.92
3.18
3.35
11.5
6.1
6.7

c
h
i
0.083
0.222
0.236
0.013
0.08
0.066

) and maximal (kmax) degree, ratio
i

Table 2.1: Main characteristics of the Internet obtained by various mapping projects: number N of
vertices, average (
between
k
, average shortest path
h
i
. For the Autonomous Systems level we consider
c
pairs of vertices, and average clustering coeﬃcient
i
h
maps of the Oregon route-views (RV) project [216], the skitter project at CAIDA [62], and the DIMES
project [98]; at the router level, data about recent maps by CAIDA and DIMES, together with older
results from the Mercator project [135], are reported.

k2
h

k
h

/
i

ℓ
h

i

at the IR level. The correlation between betweenness and degree is almost linear [203] (but large
ﬂuctuations emerge using scatterplots instead of average values).
This picture of the Internet, however, is correct only at a qualitative level, whereas quantitatively,
diﬀerent mapping projects provide slightly diﬀerent results for the average properties of the network,
in relation to the unequal node and edge coverage of the measurements. An idea of such a variety of
results is given by the list reported in Table 2.1.
The validation of Internet’s large scale measurements is of primary interest to understand correctly
topological and functional properties of the real Internet, and will be the subject of the next chapter.
In summary, while the topological structure of the Internet at the router level is still hard to detect
probably because of the unreliability of mapping processes, at higher granularity level, for the ASs,
the Internet structure is much clearer and appears as a mixture of hierarchical modular structures with
degree heterogeneity and small-world property.

2.3.2 The World-wide Air-transportation Network

The World-wide Air-transportation Network (WAN) is the network of airplane connections all around
the world, in which the vertices are the airports and the edges are non-stop direct ﬂight connections
among them. As for the Internet, this is a physical network, in the sense that both the nodes and the
edges are well-deﬁned objects. We can easily as well deﬁne weights on the edges, since diﬀerent ﬂights
are characterized by a diﬀerent number of passengers and by the geographical distance they have to
cover.
For the moment we do not consider geographical properties, that will be taken into account in Chap-
ter 4, and deﬁne the weight wij of the link (i, j) as the total number of available seats per year in
ﬂights between airports i and j.
The analyzed dataset was collected by the International Air Transportation Association (IATA) for
the year 2002. It contains N = 3880 interconnected airports (vertices) and E = 18810 direct ﬂight
connections (edges). This corresponds to an average degree
= 9.7, with maximal value kc = 318.
Degrees are strongly heterogeneously distributed, as conﬁrmed by the shape of the degree distribu-
tion, that can be described by the functional form P (k)
2.0 and f (k/kc)
is an exponential cut-oﬀ which ﬁnds its origin in physical constraints on the maximum number of

k−γf (k/kc), where γ

k
h

∼

≃

i

2.3. EXAMPLES OF REAL NETWORKS

23

Figure 2.10: The strength distribution Ps(s) (left) and the diagram strength vs. degree (right) for the
World-wide Airport Network. The diagram s(k) shows the non-linear correlation between strength
and degree (black circles), whereas the same quantity grows linearly after weights randomization (red
squares). The inset reports the behavior of the degree distribution.

i

≃

∝

ℓ
h

kβ with β

connections that can be handled by a single airport [141, 140].
Moreover, the WAN shows small-world property, since the average distance is
= 4.4. It is worthy
noting that weights from IATA database are symmetrical, that is probably a consequence of the traf-
ﬁc properties and allows to consider the network as a symmetric undirected graph. The analysis of
weighted quantities reveals that both weights and strength are broadly distributed, and that they are
non-trivially correlated with the degree, since the average weight
0.5 and
1.5 [23]. The sets of data in Figure 2.10, representing the strength distribution
s(k)
P (s) and the strength-degree diagram s(k), are borrowed from Ref. [23]. Such super-linear relation
points out that highly connected airports tend to collect more and more traﬃc, that could in principle
yield to a condensation process of the traﬃc on the hubs (i.e. a ﬁnite fraction of traﬃc handled by a
small number of airports).
The non-trivial role of the weights is witnessed also by degree-degree correlations and clustering that
show a slightly diﬀerent behavior if weights are considered [23] (not shown). The topological average
nearest neighbors degree knn(k), indeed, reaches a plateau for high degrees, while the weighted quan-
tity kW
nn(k) still increases, showing that even if the degree of neighboring nodes is various, the hubs are
preferentially connected with high traﬃc nodes. A similar interpretation holds also for the observed
values of the weighted clustering coeﬃcient cW (k) for high degree nodes, that is larger compared to
the topological one.

(kikj)θ with θ

wij i ∼
h

≃

2.3.3 Other Examples

It is possible to distinguish three main types of real complex networks:

artiﬁcial infrastructures and technological networks;

social networks generated by interactions between individuals;

networks existing in nature, such as food webs or biological networks.

•

•

•

The Internet and the WAN are the most popular examples of the ﬁrst class, that contains many other
communication and transportation networks [30, 127, 247, 2, 55, 222]. Not all of them show a broad

24

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

∼ O

degree distribution, but a considerable amount of heterogeneity can be recovered at a traﬃc level, as
recently shown by De Montis et al. [95] in the case of the Sardinian transportation network.
The panorama of biological networks is very wide, and its analysis goes beyond the purposes of this
thesis. For instance, in cellular networks, the nodes are genes or proteins and the links are metabolic
ﬂuxes regulating cellular activity. In a seminal work [152], Kauﬀman showed that chemical processes
can be conveniently represented by chemical reactions networks. The vertices are substrates, connected
by the chemical reactions in which they take part. The orientation of the corresponding edge says
if a substrate is involved in the reaction as product or “educt”. The average size of these networks
(103)), but despite of the small size, the degree distribution is fairly broadly
is quite small (N
shaped. These networks are small-worlds and their structure seems to be rather robust under random
defects, errors and mutations.
Another class of biological networks are protein-protein interaction networks (PIN) (see for instance
Refs. [153, 239, 204, 148]), in which the edges identify the existence of interactions between two
proteins. They present heterogeneous degree distribution and low average distance, but also non-
trivial pair correlations, that are related with the proteins functions. Indeed, by means of modularity
analyses [210, 178], it is possible to uncover the relation between some small topological structures
(like triangles or small cliques) corresponding to some functional modules of proteins.
Other interesting natural networks are food webs [251, 109, 206], i.e. networks of animals in a given
ecosystem, in which directed arrows establish “who eats who” in the food chain. In this case also
self-links must be considered, as consequence of the presence of cannibalism in many animal species.
However, as we will show in another context in Chapter 3, the problem of counting all species of an
ecosystem makes the deﬁnition of these networks quite diﬃcult. Similar diﬃculties are faced in the
(102))
deﬁnition of trophic links between species. In addition, these networks are very small (N
and their degree distributions are not clearly fat-tailed [110]. The clustering coeﬃcient is, instead,
very large showing that they are far from being random graphs, even if they present features that
are typical of small-world models. Another large ﬁeld of application of the network description are
social sciences. Social networks are used to represent social interactions among individuals (called
actors), such as acquaintances, collaborations, sexual relations, etc. The typical structure of social
networks is that of multi-partite networks, with a set of nodes representing actors and other sets
of nodes representing aﬃliations they belong to (Fig. 2.11). Actors are indirectly linked together
by means of common aﬃliations, i.e. the places they frequent, the oﬃce in which they work, etc. A
standard technique to study social networks consists of projecting multi-partite networks on unipartite
representations, in which nodes of a unique type (the actors) are linked by an edge if they have at
least one common aﬃliation. Interesting examples of such networks are co-authorship networks, the
most popular one being the network of collaborations among physicists submitting manuscripts on the
well-known archive called “cond-mat” [187] 1. This database of condensed-matter physics contains
N = 12722 scientists who authored e-prints during the period from 1995 to 1998. According to
the unipartite description, the presence of an edge between two authors means that they have co-
authored at least one paper. Obviously, the link between authors who have co-authored many works
together should be stronger, and we can assign weights to the edges following the deﬁnition proposed
by Newman [192],

∼ O

wij =

j

i δp
δp
1
np −

,

p
X

(2.18)

1It is a public archive of condensed matter preprints and e-prints, see ‘http://www.arxiv.org/archive/cond-mat ’.

2.3. EXAMPLES OF REAL NETWORKS

25

Figure 2.11: (Top) Example of bipartite representation of a social network: blue nodes with numbers
are the aﬃliations, and white nodes with letters are the actors. (Bottom) The ﬁgure represents the
unipartite projection of the network, in which pairs of actors are connected by links if in the original
network they have at least one common aﬃliation.

where δp
is 1 if the author i has contributed to the paper p and 0 otherwise, and np is the number
i
of authors of the paper p. Both the degree distribution and the strength distribution are broad, but
the weights are linearly correlated with the degree, revealing that their distribution is independent of
the topology. The network of “cond-mat” shows, moreover, an interesting community structure, with
many induced subgraphs of diﬀerent sizes, corresponding to diﬀerent research ﬁelds [198, 11].
A further level of information that sometimes is available in many co-authorship networks is the
In such a case the weights are deﬁned ´a la Newman but
number of citations gained by a paper.
including the number of citations [49]. A very interesting issue is the study of the temporal evolution
of co-authorship networks, identifying those topological and weighted structures that reinforced during
the years and those which got lost. This kind of analysis has been carried out in Ref. [49], focusing
on the study of the temporal evolution of the impact of co-authors groups in a particular scientiﬁc
community (the database analyzed was the InfoVis Contest dataset, a network of 614 papers by 1036
authors, published between 1974 and 2004).

26

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

2.4 Networks modeling

In the previous section, we have reviewed some examples of real networks, from which we conclude
that a networked description can be applied to a variety of systems with a large number of interacting
units, independently of their functions and role in nature or society. This makes evident the lack
of a unique underlying theoretical framework in which all networks properties may be analyzed and
interpreted.
In order to build such a theoretical framework starting from phenomenological data, the ﬁrst step
consists of networks modeling. We can roughly divide networks in two classes: static networks and
evolving networks. In the ﬁrst class, the overall statistical properties are ﬁxed and single networks are
generated using static algorithms. A typical example of this class is the static random graphs ensemble
deﬁned by Erd¨os and R´enyi [115, 116]. Classical random graph models are generated drawing edges
uniformly at random between pairs of vertices with a ﬁxed probability. The resulting graphs have
poissonian degree distributions (Erd¨os-R´enyi Model). Recently, this ensemble of graphs has been
extended in order to include graphs with any possible form of the degree distribution (Conﬁguration
Model) [180, 181, 35, 2, 71]. In this section, we introduce these two models together with another
static model, that was proposed by Watts and Strogatz as a toy-model able to reproduce the main
properties of real small-world networks (Watts-Strogatz Model) [247].
Evolving networks, on the contrary, are a very recent topic, that has attracted most attention after
the discovery of broad degree distributions in real growing networks such as the Internet, and the
possibility of producing power-law degree distributions by means of very simple evolution rules. In
this case, the generation algorithm of the network implies a non-equilibrium process in which the
statistical quantities evolve in time. However, all these growing models are built in such a way that
the inﬁnite size (and thus time) limit gives well-deﬁned statistical properties. In the following, we
will describe only two models of growing networks with power-law degree distribution, the famous
Barab´asi-Albert Model [17] and its clustered version proposed by Dorogovtsev, Mendes, and Samukhin
(DMS Model) [106].
Though from the point of view of the application to the description of real networks the division
in static and evolving networks is important, for the purposes of this thesis, i.e.
for the study of
dynamical processes taking place on networks, a better classiﬁcation is that of considering the two
following classes: homogeneous networks, with degree distribution peaked around the average value;
and heterogeneous networks, in which the degree distribution is skewed and may present heavy-tails,
or more generally, large ﬂuctuations around the average value.
Many real networks evolve in time, but, in fact, the temporal scale of their topological rearrangements
is usually much longer than the time-scale of the dynamical processes occurring on the network. This
property allows to study dynamical processes on networks that have been obtained with a growing
mechanism as if they were static models.

2.4.1 Homogeneous Networks

Erd¨os-R´enyi Model (ER) -
As already mentioned the theory of random graphs was founded
GN,p, in
by P. Erd¨os and A. R´enyi [115, 116], who deﬁned two random graphs ensembles
which the ﬁxed quantities are, respectively, the number of nodes and edges in the former case and the
number of nodes and the linking probability in the latter. In
GN,E, the graphs are deﬁned choosing
uniformly at random pairs of nodes and connecting them with an edge, until the number of edges
equals E. The second case is practically more convenient, and is deﬁned as follows. Starting from N

GN,E and

2.4. NETWORKS MODELING

27

0.06

0.05

0.04

)
k
(
P

0.03

0.02

0.01

0
20

<k>

50

k

30

40

60

70

80

Figure 2.12: Typical degree distribution (left) for a homogeneous poissonian random graph (right).

nodes, one connects with probability p each pair of nodes. At the end of the procedure, the average
number of edges is E = pN (N
pN , if N is
suﬃciently large. For a ﬁnite number of nodes, the probability that a node has degree k is given by a
binomial law

1)/2 and the average degree is 2E/N = p(N

1)

−

≃

−

P (k) = Ck

N −1pk(1

p)N −1−k ,

−

p)N −1−k is the probability of having exactly k edges and Ck

where pk(1
number of possible ways these edges can be selected. Taking the limit N
way that pN

= const, the binomial law tends to a Poissonian distribution

→ ∞

−

k

N −1 = (N −1)!
and p

is the
0, in such a

k!(N −1−k)!

→

→ h

i

(2.19)

(2.20)

P (k)

k

k
i
h
k!

≃

e−hki .

i

=

k
h

k
h

k2
h

2 +
i

Poissonian distributions are very peaked around the average value, with bounded ﬂuctuations; indeed,
. An example of such degree distribution is displayed in
the second moment is ﬁnite,
i
Fig. 2.12 (left), while the right panel in the same ﬁgure displays a sketch of its graphical representation.
Since the probability of ﬁnding nodes of degree much larger than
decreases exponentially, these
graphs are prototypes for homogeneous networks.
However, ER random graphs show a giant component only for p > pc with pc = 1/N , that corresponds
to the critical average connectivity
= 1. Erd¨os and R´enyi ([115, 116]) proved the existence of a
transition between a phase, for p < pc, in which with probability 1 the graph has no component of
(log N ), and a phase, for p > pc, in which the graph has a giant component or order
size larger of
(N 2/3). This second order phase

(N ). In the marginal case p = pc, the largest component has size

O
transition belongs to the same universality class of the mean-ﬁeld percolation transitions [48].
The ER random graphs are completely uncorrelated, thus the average degree of the nearest neighbors
is a constant independent of k. The clustering coeﬃcient is simply the probability that any two

k
h

k
h

O

O

i

i

28

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

neighbors of a given vertex are also connected to each others, i.e.

The fact that in random graphs the clustering coeﬃcient vanishes in the limit of large size N justiﬁes
the local tree-like approximation (Bethe Tree) used to obtain many relevant results.
For instance, the tree-like approximation allows to compute how the diameter of the graph scales
neighbors, at distance ℓ in a tree-like topology, the
with N . Indeed, since each node has typically
ℓ. The diameter is reached when the number of visited nodes is
number of visited nodes scales as
equal to N , but the shortest path distribution is very peaked, thus we can approximate the diameter
with the average distance,

k
h

k
h

i

i

ℓ
h

, obtaining
i

k
= p = h
N

c
h

i

.

i
−

1

ℓ
h

i ∼

log N
k
log
h

i

.

(2.21)

(2.22)

Watts-Strogatz Model (WS) -

In Section 2.3, we have shown experimental data from which
it emerges that the average hop distance between two vertices in real complex networks is very small,
and it is possible to reach every vertex in a small number of steps. Nevertheless, random graphs are
not optimal models for the study of real networks, since the most of them are clustered, i.e. they
contain a lot of triangles, whereas random graphs are locally tree-like.
In order to overcome this
problem, Watts and Strogatz proposed a simple model interpolating between a regular lattice with
large average distance but strong clustering and the random graph with small diameter and small
clustering [247].
The initial network is a one dimensional m-banded graph, i.e. a ring of N sites in which each vertex
is connected to its 2m nearest neighbors. The vertices are then visited one after the other: each
link connecting a vertex to one of its m nearest neighbors in the clockwise sense is left in place with
probability 1
p, and with probability p is rewired to a randomly chosen other vertex. The long-
range connections introduced play the role of shortcuts connecting regions that are very distant in the
original network. Figure 2.13 displays a sketch of the rewiring mechanism.
For p = 1, the network is completely randomized but, since it has at least degree 2m, it is not
1, in which a still rather
equivalent to a random graph. The interesting regime is for 1/N
large clustering coeﬃcient coexists with a logarithmically scaling average distance. In the limit p
0,
the small-world property disappears and the metric structure of the lattice is restored. It has been
shown ([29, 32, 195, 194]) that the transition occurs precisely at p = 0, and in the inﬁnite size limit the
average distance diverges as
1/p. This cross-over phenomenon for increasing rewiring probability
plays an important role in determining the behavior of dynamical processes deﬁned on this type of
network (see Chapter 5 for the case of Naming Game on Watts-Strogatz small-world networks). The
degree distribution of this model in the regime 1/N

1 has the form [29]

i ∼

ℓ
h

≪

→

≪

−

p

p

min(k−m,m)

P (k) =

m
i !

(1

−

 

i=0
X

≪

≪
p)ipm−i (pm)k−m−i
i)!
(k
−

m

−

e−pm ,

(2.23)

≥

m, and is equal to zero for k < m.

for k
The clustering coeﬃcient can be easily computed recalling that two neighbors that are linked together
in the original model remain connected with probability (1

p)3,

−

c
h

(p)
i

∼

3(m
2(2m

1)
1)

−
−

p)3 .

(1

−

(2.24)

2.4. NETWORKS MODELING

29

Figure 2.13: Rewiring process in the Watts-Strogatz model of smallworld network. Increasing the
rewiring probability p, the network passes from a regular 2-banded network (left) to a smallworld
network (center) and ﬁnally to a random graph (right).

2.4.2 Heterogeneous Networks

i

k2
h

In the last years, a huge amount of experimental data yielded undoubtful evidences that real networks
present a strong degree heterogeneity, expressed by a broad degree distribution. In order to reproduce
the main features of this new class of heterogeneous networks, a big eﬀort has been devoted to network
modeling, and a large number of models with degree heterogeneity has been put forward. The main
feature of these networks is that the average degree is not representative of the distribution, and the
is very large, possibly diverging in the inﬁnite size limit. A characterization of the
second moment
heterogeneity level of a degree distribution is given by the parameter
, that is strictly related
i
with the expression of the normalized ﬂuctuations and enters in the description of many dynamical
phenomena on networks, such as percolation and epidemic spreading.
When the degree distribution is a power law P (k)
3), the ﬂuctuations diverge with
N (the average remaining ﬁnite), and nodes with very large degree appear in the network. However,
not all heterogeneous networks are power-law, many of them possess bended degree distributions that
cannot be classiﬁed as power-laws. A broad distribution, that is not scale-free, but has been used
to ﬁt a number of data coming from the Internet’s measurements ([57]) is the Weibull (WEI), whose
form is P (k) = (a/c)(k/c)a−1 exp(
(k/c)a), with a, c real positive constants. Weibull distributions
are good candidates as degree distributions also for networks of scientiﬁc collaborations, wordwebs
and biological networks, where the existence of a neat power-law is still under debate.
Now, we introduce the most relevant models of heterogeneous networks, that will be used in the
numerical simulations related to the investigations reported in the next chapters.

k−γ (2 < γ

k2
h

k
h

/
i

−

∼

≤

Conﬁguration Model (CM) -

This is a static model of scale-free graphs that generalizes the
random graph ensemble of Erd¨os and R´enyi to generic degree distributions. It is particularly useful
to study dynamics on network models with a given degree distribution and controlled correlations. A
famous algorithm to generate generalized random graphs was proposed by Molloy and Reed [180, 181].
(i = 1, . . . , N ) is drawn randomly from the desired degree distribution P (k)
A degree sequence
i ki must
and assigned to the N nodes of the network, with the additional constraint that the sum
i ki/2 edges, respecting the assigned degrees
be even. At this point, the vertices are connected by
and avoiding self- and multiple-connections. Figure 2.14 reports a sketch of the generation procedure.
The last condition introduces unexpected correlations, producing a slightly disassortative behavior.
In order to eliminate correlations, Catanzaro et al.
[71] have proposed a variation of the model
characterized by a cut-oﬀ at √N for the possible degree values. In the rest of this work, when talking

ki}

P

P

{

30

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

Figure 2.14: Illustration of the Molloy-Reed algorithm used to generate a generalized random graph
starting from a degree sequence. The stubs (left) are linked in such a way that self-links and multi-links
are avoided.

of conﬁguration model we will always refer to this particular model, that is known as Uncorrelated
Conﬁguration Model (UCM) and presents ﬂat knn(k) and c(k).

Barab´asi-Albert Model (BA) -

The ﬁrst attempt to model real growing networks such as
the Web was provided by Barab´asi and Albert, who proposed the idea of preferential attachment as
the central ingredient in order to get a power-law degree distribution [17]. The preferential attach-
ment is based on the simple idea that, during the network’s evolution, new coming nodes become
preferentially connected with nodes that already have a large number of connections. It was proposed
as a “construction recipe” for the Web, in which new pages acquire more visibility if they link to very
important webpages, but it can be assumed as a valuable principle for a large number of technological
and social networks, in which nodes want to optimize their conditions connecting with very important
and central nodes. During the growth, the “rich gets richer” eﬀect is produced: large degree nodes
more easily increase their degree compared to low degree nodes.
The algorithm starts from a small fully connected core of m0 nodes (their precise properties do
not change the statistical properties of the model in the large size limit). At each time step t =
m0 edges with distinct existing
1, 2, . . . , N
nodes: the probability that an edge is created between j and the node i is

m0, a new node j enters the network and forms m

≤

−

Πj→i =

ki
l kl

.

(2.25)

Every new node has m links and the network size at time t is N (t) = t + m0; since the number of links
is E = mt, in the large time limit the average degree is simply
= 2m. The degree distribution
of the BA model can be obtained by means of diﬀerent methods (mean-ﬁeld approximation [17, 18],
, a power law behavior
rate equation [162], or master equation [105]), and shows, in the limit t

k
h

P

i

→ ∞

2.4. NETWORKS MODELING

31

)
k
(
P

0

10

-1

10

-2

10

-3

10

-4

10

10

-5
0
10

1
10

k

2
10

Figure 2.15: Typical degree distribution (left) for a heterogeneous BA model (right).

∼

k−γ with γ = 3. Figure 2.15 displays the degree distribution and a graphical representation

P (k)
of a BA network.
Apart from the very interesting idea of preferential attachment, the Barab´asi-Albert model is a very
peculiar network, with ﬂat degree correlations and almost vanishing clustering. Many variations of
the model have been proposed, including node aging [157], ﬁtness [40, 117], edge rewiring [3], limited
information [186], etc; in particular, the addition of a constant A representing the initial attractivity
ki + A in the kernel of Eq. 2.25) allows to generate power law networks with desired exponent
(ki →
2
[105]. Note that the linearity (in k) of the attaching kernel in Eq. 2.25 is a necessary
γ
≤
condition to get a power-law distribution. It has been indeed proved ([162, 160]) that using generalized
kernels of the type Πj→i = kβ
the degrees of the emerging network are power-law distributed only
l kβ
for β = 1. When β < 1, the degree distribution is exponentially shaped; when β > 1 the evolution
produces edge-condensation on few vertices.

≤ ∞

P

i

l

Dorogovtsev-Mendes-Samukhin Model (DMS) -

Another interesting variation of BA
model is the growing clustered network proposed by Dorogovtsev, Mendes and Samukhin (DMS)
[106], in which the evolving rule consists in attaching new vertices to the extremities of a randomly
chosen edge. The probability to choose a given vertex is thus proportional to the number of edges of
which it is an extremity, i.e. to its degree. While the DMS model generates a power law distribution
(γ = 3), the growing rule does not explicitely need any a priori knowledge of node’s degrees. The only
real diﬀerence between this model and the BA model is in the clustering coeﬃcient, that in the DMS
0.739 for m = 1). The general behavior of the clustering spectrum c(k)
c
model is very high (
h
and the average value
for the DMS model has been computed using the rate equation formalism
in Ref. [28].

i ≃
c
i
h

2.4.3 Weighted Networks

In this last paragraph, we discuss a model of growing weighted network that is particularly appropriate
for the description of the World-wide Air-transportation Network.

32

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

Figure 2.16: Weights redistribution rule in the BBV model. When a new node j enters the network
attaching to a node i, it carries new traﬃc that is redistributed to the neighbors of i by means of a
contribution to their weights. The edge (j, i) assumes a ﬁxed weight w0.

In real weighted networks, the weights are not ﬁxed but evolve in time together with the topology,
so that the characteristics of the networks depend on the interplay of these two types of dynamics
(topological and weighted) and on the relation between their time-scales. As for the purely topological
models, also for weighted evolving networks there is a variety of slightly diﬀerent models, each one
pinpointing a particular aspect of the evolution. We are interested in the situation in which the
evolutions of links and weights are coupled and have the same temporal scale, that is similar to what
happens in the real network of airports.
In the case of the WAN, in fact, each new airport j that enters the existing network brings new ﬂights,
and new passengers are introduced into the system. A fraction of these passengers will not stop at the
destinations of the direct ﬂights they have taken from j (e.g. a new airport is connected only to New
York but part of the passengers would like to go to other cities, such as Philadelphia or Chicago);
hence, part of the traﬃc is immediately locally redirected on the network. Moreover, new airports try
to connect themselves to the most connected hubs, in order to guarantee many correspondences to the
passengers. Consequently, a good way to naively model the growth of a network like the WAN is that
of considering 1) a preferential attachment procedure based on the strength and 2) a redistribution
rule for the local traﬃc brought by the new node. More precisely, the Barrat-Barth´elemy-Vespignani
(BBV) model [24, 25, 26] starts from an initial clique of m0 nodes with a ﬁxed weight w0. At each
time step, a new vertex j is added to the network with m edges (of weight w0) that are randomly
attached to a previously existing vertex i according to the probability

Πj→i =

si
l sl

.

P

(2.26)

2.4. NETWORKS MODELING

33

(2.27)

Immediately after the creation of the new link (i, j), the weight of links (i, l) connecting i with each
other neighbor l is locally redistributed according to the rule (see Fig. 2.16)

wil →

wil + δ

wil
si

l
∀

∈ V

(i) ,

i.e. the increase of the traﬃc δ is locally distributed among the neighboring connections, each link
receiving a fraction of traﬃc that is proportional to the amount of traﬃc already handled by that
connection.
This network model displays power law distributions of degree, strength and weights. An interesting
feature of the model is the presence of non-linear correlations between degree and strength. However,
it is worthy noting that the model fails in reproducing the large ﬂuctuations that characterize the
quantity s(k) in the case of the WAN (and other growing weighted networks), and that are clearly
visible in the scatter-plot degree vs. strength.
In a recent publication [27], the authors of the model have shown that large ﬂuctuations may be due
to the existence of spatial constraints coming from the embedding of the nodes in a two-dimensional
euclidean space. This modiﬁed model consists in considering the nodes deployed on a two-dimensional
euclidean space: each new node is situated in a randomly chosen point of the lattice, and the prefer-
ential attachment kernel is modiﬁed in order to account for the fact that a node prefers to connect to
nodes that are well-connected but also spatially close to itself,

Πj→i ∝

si exp(

ηdij ) ,

−

(2.28)

where dij is the euclidean distance between nodes i and j, and η is related to a characteristic length
scale. When η is small enough that spatial eﬀects cannot be avoided, the relation between degree
and strength is still non-linear but now presents very large ﬂuctuations (around the average value
expressed by s(k)).
This model will be furtherly investigated in the analysis of the vulnerability of weighted networks
(Chapter 4), in order to explain some results obtained for the real airport network.

34

CHAPTER 2. STRUCTURE OF COMPLEX NETWORKS: AN OVERVIEW

Chapter 3

Exploration of complex networks

3.1

Introduction

The present chapter is devoted to describe and study the exploration techniques of complex networks.
Motivations of this research and a general introduction to the problem, in which we highlight several
diﬀerent sampling methods, are provided in Sections 3.1.1-3.1.2. Then, in Section 3.2, we focus on
a theoretical model for the exploration of the Internet, that is analyzed using a typical mean-ﬁeld
statistical physics approach. A variety of diﬀerent measures are introduced to investigate the main
properties of the exploration process and its biases. Finally, exploiting an interesting application of
non-parametric statistics, we propose an approach to compensate the biases (Section 3.3).

3.1.1 Motivations

Network modeling is undoubtedly the favorite tool used by researchers to understand the origins of
the ubiquity of complex networks in the real world. In particular, the presence, in biological as well as
technological systems, of the same peculiar topological properties, such as a broad degree distribution
and very small average inter-vertex distances, is very intriguing. By means of network models, some
of the phenomenological results have been reproduced, and possible explanations for many observed
properties have been put forward. An aspect, on the contrary, that has been relatively disregarded is
the validation of phenomenological data, and the identiﬁcation of possible errors or biases occurred
during the process of data collection and analysis. The importance of this issue resides in the fact
that “systematic” errors in the statistics, due to sampling biases, could compromise the reliability of
the data and of the observed properties of real networks.
The idea that the sampling of networks may introduce biases is far from being unrealistic, as proved
by several examples reported in the Section 3.1.2 and coming from diﬀerent ﬁelds of complex networks
research.
In social and biological networks, the limited information about the exact mechanisms generating the
original network and the amount of arbitrariness in the deﬁnition of the edges (e.g. relations among
individuals, interactions between proteins, etc), makes sampling processes extremely problematic,
since we do not have a real control on the origins of possible biases.
Completely diﬀerent is the case of the physical Internet, in which nodes and edges are well-deﬁned,
but the dynamical nature of its structure and the lack of any centralized control have favored a self-
organized evolution of the system, without any information on its topological properties. In practice,

35

36

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

•

•

•

•

we do not have a complete knowledge of router’s neighbors, since routing decisions depend on optimized
traﬃc protocols by means of which data packets should be sent along the shortest path available to the
destination. This means that routers only know which are the neighbors belonging to the shortest
paths; i.e., they could ignore the existence of other neighbors. Actually, traﬃc congestions and local
policies can force routers to deliver packets through some preferential neighbors, causing small path
inﬂations with respect to the shortest one.
Internet’s explorations, obtained by means of tree-like probes based on traceroute processes, exploit
the routing protocols in order to trace a path between diﬀerent nodes of the network. In this way,
they suﬀer of important biases due to the loss of lateral connectivity, i.e. of those nodes or links which
do not lay on the shortest path between two nodes (or on its small perturbations). We will see that
traceroute explorations can seriously misrepresent the degree distribution of the original network.
On the other hand, a good knowledge of the Internet topology is fundamental in order to improve
its performances, minimize traﬃc congestions and protect the system against malicious attacks. For
this reason, the study of Internet’s sampling biases is of primary interest, not only for the scientiﬁc
community but also for practitioners and common users.
The investigation has to be carried on at diﬀerent levels; our theoretical formulation of the problem
is aimed at

understanding what is the origin of the exploration biases and at what stage they aﬀect the
observed properties,

identifying which kind of topologies yield the most accurate sampling,

providing some “rules of thumb” for the optimization of mapping strategies,

obtaining alternative approaches able to correct the biases, at least in some simple cases.

In the next section, we introduce the issue of sampling biases in complex networks, highlighting which
dramatic eﬀects of distortion of the shape of the degree distribution can be produced by a bad sampling
of the network.

3.1.2 Networks sampling methods and their biases

There are many possible sources of sampling biases in complex networks, depending on the ﬁeld
of research and the type of sampling method used in the experiments. Here we provide a short
survey of examples, focusing in particular on the mechanisms of homogeneous sampling and tree-like
explorations and on the dramatic eﬀects they can have in misrepresenting the degree distribution of
the underlying network.

Sampling biological and social networks -

In the context of social and biological networks,
practitioners have developed many types of experiments in order to gain information on the topology
of the networks of interest. Apart from the complexity of the experimental set up necessary for such
experiments, a deep conceptual problem emerges: ties between nodes are usually associated with
relations or interactions, thus they can have diﬀerent nature or intensity, that are diﬃcult to evaluate
and take into account correctly. In social networks, this is due to the level of arbitrariness in deﬁning
relations between actors, and in biological networks to the fact that measures are usually indirect
and may be inﬂuenced by the eﬀects of external unknown variables. Nevertheless, many authors
have modeled the collection of data in social as well as in biological experiments by means of node-
or edge-picking sampling algorithms. The two algorithms give similar results, thus let us focus on

3.1.

INTRODUCTION

37

Figure 3.1: Illustration of a node-picking sampling algorithm used to model sampling of biological
and social networks. The original network (top) is sampled picking up nodes at random and retaining
common links (red nodes in the bottom ﬁgure).

In absence of further
the node-picking case. Fig. 3.1 illustrates a node-picking sampling process.
information on the way a node is selected, we can assume a homogeneous sampling, i.e. a node is
included in the sampled subnet with ﬁxed probability p, and left out with probability 1
p; only
edges between sampled nodes are retained. Then, if P (k) and ˜P (k) are respectively the original and
sampled degree distributions, they are related by a “poissonian ﬁlter”,

−

∞

˜P (k) =

P (i)

i
k !

 

pk(1

p)i−k .

−

(3.1)

≃

≪

Xi≥k
Using generating functions formalism [233, 168], it is easy to show that, when p
1, the deviation
from the original distribution is negligible both for homogeneous and heterogeneous degree distribu-
1), homogeneous distributions are conserved, even
tions. When the sampling probability is low (p
if the average connectivity is reduced by a factor p, whereas in the case of power-law distributions the
observed exponent may be diﬀerent from the real one. Subnets have more nodes with relatively few
connections, due to the sampling process, but very large degree nodes are usually well-represented,
so that the original power-law behavior is recovered for k
1. Consequently, the degree distribution
appears slightly concave in the middle (in log-log scale), introducing biases in the measurement of the
exponent (it is systematically reduced). Actually, a good strategy is that of looking at the tail of the
distribution in which the sampling is systematically more accurate.
Unfortunately, sampling by means of real experiments is far from being uniform, since external fac-
tors can be correlated to the properties of some nodes, favoring their sampling. For instance, social
networks are usually bipartite, i.e. actors (individuals) are linked together via multiple interaction
contexts or aﬃliations. Following Refs. [158], together with the random exclusion of actors or aﬃlia-
tions, there are other two principal mechanisms causing data missing: actors unpredictable decision
of non-responding to a particular survey, and of providing ﬁxed or preferential choices in the answer.
A whole ﬁeld of social network analysis is involved in studying how to predict the correlations among

≫

38

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

such data missing events (see Refs. [136, 215] and in particular Ref. [245] and references therein). We
prefer to consider a simpler example coming from biology and reported in Ref. [205], that shows how
hidden variables inﬂuencing the sampling process can have dramatic eﬀects on the results.
Let us consider a protein-protein interaction network (PIN), in which the nodes are proteins and the
edges are the interactions between them. The standard methods to detect interactions are two-hybrid
assays and mass spectrometry [205]. Both of them are sensitive to the physical conditions in which
the experiment is performed (e.g. the temperature, the solubility degree of proteins, etc). The de-
tectability of an interaction can be aﬀected by these external variables, whose eﬀect on the process
is not completely known. Similarly, in neural networks, and cell regulatory networks, some nodes or
edges may be ignored in the experiments only because their functions are temporarily inhibited by
the activation of other functions.
In order to model the sampling, let us consider a network with a homogeneous degree distribution, for
instance an Erd¨os-R´enyi random graph, and for each node i assign a variable xi, taken from a probabil-
ity distribution p(x). Such a hidden variable is also known in literature as “ﬁtness” [63, 130, 40, 117].
Now we prune the graph leaving the edge (i, j) with a probability q(xi, xj ). In a biological framework,
xi is for instance the free energy gain of a protein from being solved during the experiment. The
interaction takes place only if the free energy loss xc in breaking a bond is compensated by the gain
xi + xj of staying together in the solution. On the other hand, it is reasonable to assume an exponen-
tial distribution for the free energy, i.e. p(x)
x). The average degree k(x) of a sampled node
exp(
−
as a function of its free energy is readily computed as

∝

k(x)

pN

∼

ZS

q(x, x′)p(x′)dx′ ,

(3.2)

−

xc). The integral in Eq. 3.2 yields k(x)

where pN comes from the approximation that all nodes have about pN neighbors, and q(x, x′) =
θ(x + x′
N p exp(x), that inserted into the probability
relation P (k)dk = p(x)dx, provides a power-law expression for the degree distribution of the sampled
k−2. This striking result shows that, as a consequence of sampling biases, one may
network, P (k)
observe heterogeneous degree distributions even when the underlying network is homogeneous. In
their work [205], Petermann and De Los Rios show as well that even when the original network has
power-law distributed connectivity, the exponent can be considerably underestimated.

∝

∼

Sampling technological networks -

As already stressed in this section, the case of tech-
nological networks is completely diﬀerent, since we do not have any idea of the topology of the real
graph, but the sampling methods are based on very well-deﬁned probing processes, that can be mod-
eled using tree-like explorations.
The ﬁrst example of this class of networks is the World Wide Web, that is usually eﬃciently explored
using so-called “crawling processes” [200]. The WWW, indeed, possesses the remarkable property that
the links outgoing from a page are directly visible, thus we can apply snowball sampling methods, that
are related to well-known processes like epidemic spreading and percolation (see Chapter 4). A single
node is ﬁrstly chosen together with its outcoming links and the nodes connected to them. Then, new
nodes connected to those picked in the last step are selected. The process continues recursively until
the desired number of nodes are gathered. The main limitation of using this method on the Web is
the huge size of the network itself, that makes diﬃcult to reach all remote regions. In general, in each
layer only a fraction of the nodes is sampled and this may introduce some inaccuracies [236].

Snowball-like samplings do not work on the Internet, since routing protocols redirect probes along
preferential (shortest) paths, thus preventing exploration algorithms from getting a complete knowl-
edge of nodes neighborhood. The common sampling strategy consists in acquiring local views of the

3.1.

INTRODUCTION

39

Figure 3.2: Illustration of the snowball sampling technique. The original graph (left) is sampled using
a snowball algorithm starting from a root vertex (black node on the right part of the ﬁgure). The
ﬁrst layer is composed of a fraction its neighboring nodes (dark grey nodes), that are used as starting
nodes to explore the second layer (bright grey nodes), etc.

network from several vantage points, merging these views in order to get a presumably accurate global
map. Local views are obtained by evaluating a certain number of paths to diﬀerent destinations by
using speciﬁc tools such as traceroute-like commands or by the analysis of BGP tables. At ﬁrst
approximation these processes amount to the collection of shortest paths from a source node to a set of
target nodes, obtaining a partial spanning tree of the network. The merging of several of these views
provides the map of the Internet from which the statistical properties of the network are evaluated.
According to this description, discovering the Internet topology is more than a simple network sam-
pling problem, it consists in a real dynamical exploration process.
The ﬁrst contribution to the problem of sampling biases in the Internet was given by Lakhina et
al. [163], who showed that traceroute-like explorations can seriously aﬀect the estimation of degree
distributions. In particular, when the number of sources and destinations is small, one can observe
power-law like distributions even in the sampling of Erd¨os-R´enyi random graphs, whose original de-
gree distribution is poissonian. Since the ﬁrst data showing heavy-tailed distributions for the Internet
topology have been collected gathering traceroute paths from a very limited number of sources and
destinations [199], they concluded that the Internet maps could be wrong, or at least the node degree
distribution is not a suﬃciently robust metric to characterize Internet’s topology. Nevertheless, the
same exploration performed on a network with a power-law degree distribution behaves very diﬀer-
ently, since a handful number of sources are suﬃcient to yield a sampled graph with degree distribution
that looks very similar to the original one. The authors of Ref. [139] have moreover monitored nu-
merically the observed degree of sampled nodes as a function of their real degree, ﬁnding that it is
systematically underestimated.
The analytical foundation to the numerical work of Lakhina et al. [163] was provided in Refs. [78, 1],
in which the authors modeled traceroute explorations as single-source, all-destinations, shortest-

40

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

k
h

path trees. Using breadth-ﬁrst search spanning trees, they rigorously proved that, for an Erd¨os-R´enyi
random graph with average degree
, the connectivity distribution of the obtained spanning tree
i
displays a power-law behavior k−1, with an exponential cut-oﬀ setting in at a characteristic degree
. We give here a non-rigorous derivation of this result using diﬀerential equations.
k
kc ∼ h
i
A typical breadth-ﬁrst search algorithm is the following. There are three types of nodes: explored,
untouched, and pending. All edges are labeled invisible. The ﬁnal observed network will be composed
only of explored vertices and visible edges. The process starts with the root vertex labeled pending
into a queue, all the others are untouched. Vertices are chosen from the queue in the ﬁrst-in-ﬁrst-out
order, thus at the beginning the root is popped out. All the untouched neighbors of the vertex chosen
from the queue (i.e. explored) are appended to the queue as pending vertices. The edges going from
the explored vertex to these appended neighbors are made visible. Let now be u(t) and s(t) the den-
sities of untouched and pending vertices respectively, the process can be described by the following
system of diﬀerential equations [78],

du(t)
dt

=

k

u(t)
i

−h

ds(t)
dt

=

k
h

u(t)
i

−

1 .

t

−

Using the initial conditions u(0) = 1 and s(0) = 0, we get a solution of the form u(t) = e−hkit and
e−hkit. If a node is chosen at time t, its observed degree is the number of previously
s(t) = 1
untouched neighbors plus one given by the edge we used to reach it. Since a node can be discovered
at any time from t = 0 to t = t0 (the smallest root of s(t) = 0), we get the degree distribution by
means of the following temporal average, i.e.

−

˜P (k + 1)

t0

1
t0 Z

0

∼

k
e−hkiu(t) [
h

u(t)]k
i
k!

dt ,

i

k

∼ h

where a cut-oﬀ sets in.

where we used the fact that the real distribution is poissonian and the untouched nodes at time t are
homogeneously sampled from it with density u(t). After computing the integral and making some
approximations it is easy to show that the observed degree distribution ˜P (k)
1/k up to a degree
k
From such analysis one could conclude that the observation of heavy-tails in Internet’s degree distri-
bution is a fake eﬀect due to the use of tree-like explorations; nonetheless, this result is strictly correct
only in the case of single-source probing, as will be clearer in the following.
All these results stress on the relevance of determining up to which extent the topological properties
observed in sampled graphs are representative of that of the real networks. We have tried to answer
this issue in the case of traceroute-like explorations using methods of statistical physics. The main
results of this study, that led to the publications in Refs. [87, 86, 85, 88], are illustrated in the next
sections.

∝

(3.3)

(3.4)

3.2. STATISTICAL PHYSICS APPROACH TO TRACEROUTE EXPLORATIONS

41

Figure 3.3: Illustration of the traceroute-like procedure. Shortest paths between the set of sources
and the set of destination targets are discovered (red full lines) while other edges are not found (dashed
black lines). Note that not all shortest paths are found since the “Unique Shortest Path” procedure
is used.

3.2 Statistical physics approach to traceroute explorations

This section gives a formal statistical description of traceroute-like processes in terms of a simple
model that provides a qualitative and quantitative understanding of the properties observed in real
experiments.

3.2.1 The model

In a typical exploration, a set of active sources deployed in the network sends traceroute probes
to a set of destination nodes. Each probe collects information on all the nodes and edges traversed
along the path connecting the source to the destination [61]. By merging the information collected on
each path it is then possible to reconstruct a partial map of the network (Fig. 3.3). More precisely,
the set of edges and nodes discovered by each probe depend on the “path selection criterion” (p.s.c)
In the real Internet, many factors, including
used to choose the path between a pair of nodes.
commercial agreement, traﬃc congestion and administrative routing policies, contribute to determine
the actual path, causing it to diﬀer even considerably from the shortest path. Despite these local, often
unpredictable path distortions or inﬂations, a reasonable ﬁrst approximation of the route traversed
by traceroute-like probes is the shortest path between the two nodes. This assumption, however, is
not suﬃcient for a proper deﬁnition of a traceroute model in that equivalent shortest paths between
two nodes may exist. In the presence of a degeneracy of shortest paths we must therefore specify the
path selection criterion by providing a resolution algorithm for the selection of shortest paths.
For the sake of simplicity we can deﬁne three selection mechanisms among equivalent paths that may
account for some of the features encountered in the Internet discovery:

Unique Shortest Path (USP) probe. In this case the shortest path route selected between a node

•

42

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

i and the destination target T is always the same independently of the source S (the path being
initially chosen at random among all the equivalent ones).

Random Shortest Path (RSP) probe. The shortest path between any source-destination pair is
chosen randomly among the set of equivalent shortest paths. This might mimic diﬀerent peering
agreements that make independent the paths among couples of nodes.

All Shortest Paths (ASP) probe. The selection criterion discovers all the equivalent shortest
paths between source-destination pairs. This might happen in the case of probing repeated
in time (long time exploration), so that back-up paths and equivalent paths are discovered in
diﬀerent runs.

•

•

M

-path the path found using one of these “metrics” or path selection criteria.
We will generically call
Actual traceroute probes contain a mixture of the three mechanisms deﬁned above, even if many
eﬀective heuristic strategies are commonly applied to improve the reliability and the performances of
the sampling. An example of such heuristic tricks is the interface resolution algorithm called iﬃnder,
proposed by Broido and Claﬀy [57].
In fact, a router can have more than one interface with the
external world, thus diﬀerent paths passing through diﬀerent interfaces might erroneously consider
two interfaces as two independent routers. Algorithms such as iﬃnder allow to avoid these type of
errors.
As remarked by Guillaume and Latapy [139], the diﬀerent path selection criteria may have inﬂuence
on the general picture emerging from the theoretical model, but the USP procedure clearly represents
the worst scenario among the three diﬀerent methods, yielding the minimum number of discoveries.
For this reason, we will focus only on the USP data. The interest of this analysis resides properly in
the choice of working in the most pessimistic case, being aware that path inﬂations should actually
provide a more pervasive sampling of the real network.
Formally, the traceroute model is the following. Let G = (
with vertices (nodes)
, iNS }

) be a sparse undirected graph
. Then let us deﬁne the sets of vertices
specifying the random placement of NS sources and
, we compute with our
,
T }
∗) is deﬁned as the
∗,
= (
E
V
) induced by considering the union of all
|
-paths connecting the source-target pairs. The sampled graph should thus be analogous to the

, N
· · ·
j1, j2,
S
NT destination targets. For each ensemble of source-target pairs Ω =
p.s.c. the paths connecting each source-target pair. The sampled graph
set of vertices
the
maps obtained from real traceroute sampling of the Internet.
In the next section, we provide a mean-ﬁeld analysis of the discovery process as function of the density
ρT = NT /N and ρS = NS/N of targets and sources. In general, traceroute-driven studies run from
a relatively small number of sources to a much larger set of destinations. For this reason, in many
cases it is appropriate to work with the density of targets ρT while still considering NS instead of the
corresponding density. This combination of the parameters allows us to compare mapping processes
on networks with diﬀerent sizes. An appropriate quantity representing the level of sampling of the
networks is the probing eﬀort ǫ = NSNT
N , that measures the density of probes imposed to the system.
In real situations it represents the density of traceroute probes in the network and therefore a
measure of the load provided to the network by the measuring infrastructure.

and edges (links)
, jNT }

) and edges
|

∗ (with N ∗ =

=
V
and

1, 2,
=

∗ (E∗ =

}
· · ·

{S
G

i1, i2,

{
T

M

· · ·

|V

|E

=

V

V

E

E

E

{

{

∗

∗

,

3.2.2 Mean-ﬁeld analysis

Here, we provide a statistical estimate for the probability of edge and node detection as a function
of NS, NT and the topology of the underlying graph. The method is based on a simple mean-ﬁeld

3.2. STATISTICAL PHYSICS APPROACH TO TRACEROUTE EXPLORATIONS

43

(3.5)

(3.6)

(3.7)

statistical analysis of the simulated traceroute mapping.
For each set Ω =

we deﬁne the quantities

,

{S

T }

NT

t=1
X

NS

s=1
X

δi,jt =

δi,is =

1
0

1
0

(

(

if vertex i is a target;
otherwise,

if vertex i is a source;
otherwise,

i

i,j

where δi,j is the Kronecker symbol. These quantities tell us if any given node i belongs to the set of
NT
NS
sources or targets, and obey the sum rules
t=1 δi,jt = NT and
s=1 δi,is = NS. Analogously,
we deﬁne the quantity σ(l,m)
that takes the value 1 if the edge (i, j) belongs to the selected path
between nodes l and m, and 0 otherwise.
For a given set of sources and targets Ω, the indicator function that a given edge (i, j) will be discovered
and belongs to the sampled graph is simply πi,j = 1 if the edge (i, j) belongs to at least one of the
-paths connecting the source-target pairs, and 0 otherwise. We can obtain an exact expression for
πi,j is 1 if and only if (i, j) does not belong to any of the paths between sources

P

P

P

P

i

M
πi,j by noting that 1
and targets, i.e. if and only if σ(l,m)

−

i,j = 0 for all (l, m)

Ω. This leads to

∈

πi,j = 1

1

−

−

Yl6=m  

s=1
X

t=1
X

NS

NT

δl,is

δm,jt σ(l,m)

i,j

.

!

,

, this function is simply πi,j = 1 if the edge (i, j) belongs to at least one
For a given set Ω =
of the
-paths connecting the source-target pairs, and 0 otherwise. Since we are looking at a purely
statistical level, in order to get more useful expressions, we perform the average over all possible
realizations of the set Ω =

. By deﬁnition we have that

T }

M

{S

,

{S

T }
NT

*

t=1
X

+Ω

NS

*

s=1
X

+Ω

δi,jt

= ρT

and

δi,is

= ρS,

(3.8)

where
h· · · iΩ identiﬁes the average over all possible deployment of sources and targets Ω. These
equalities simply state that each node i has, on average, a probability to be a source or a target
that is proportional to their respective densities. In real processes there are correlations among the
paths, due to the relative position of sources and targets, thus in general the average is a complicate
quantity, that we cannot easily compute analytically. A ﬁrst approximation can be obtained making
an uncorrelation assumption that yields an explicit expression for the discovery probability. The
assumption consists in computing the discovery probability neglecting the correlations among diﬀerent
paths originated by the position of sources and targets. While this assumption does not provide an
exact treatment for the problem it generally conveys a qualitative understanding of the statistical
properties of the system. In this approximation, the average discovery probability of an edge is

πi,j iΩ = 1
h

− *

1

≃

−

NS

NT

δl,is

δm,jt σ(l,m)

i,j

1

−

Yl6=m  
1

Yl6=m (cid:16)

−

s=1
X
ρT ρS

t=1
X
σ(l,m)
i,j

D

,

Ω

E

(cid:17)

!+

Ω

(3.9)

where in the last term we take advantage of neglecting correlations by replacing the average of the
product of variables with the product of the averages and using Eq. 3.8. This expression simply states

44

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

that each possible source-target pair weights in the average with the product of the probability that
the end nodes are a source and a target. The discovery probability is thus obtained by considering the
edge in an average eﬀective media (mean-ﬁeld) of sources and targets homogeneously distributed in the
is very simple in the uncorrelated picture, depending
network. The realization average of

σ(l,m)
i,j

Ω

E

D
σ(l,m)
is just 1 if (i, j)
only of the kind of the probing model. In the case of the ASP probing,
i,j
belongs to one of the shortest paths between l and m, and 0 otherwise.
In the case of the USP
D
and the RSP, on the contrary, only one path among all the equivalent ones is selected. If we denote
by σ(l,m) the number of shortest paths between vertices l and m, and by x(l,m)
the number of these
paths passing through the edge (i, j), the probability that the traceroute model chooses a path going
through the edge (i, j) between l and m is

/σ(l,m).

E

i,j

Ω

= x(l,m)
i,j

The standard situation we consider is the one in which ρT ρS ≪

1 and since

σ(l,m)
i,j

1, we have

σ(l,m)
i,j
D

Ω

E

ρT ρS

1

−

σ(l,m)
i,j
D

Yl6=m (cid:16)

exp

ρT ρS

σ(l,m)
i,j

≃

Ω

E

(cid:17)

Yl6=m

−

(cid:16)

D

Ω ≤

E

D

,

Ω

E

(cid:17)

(3.10)

that inserted in Eq. 3.9 yields

πi,jiΩ ≃
h

1

−

exp

ρT ρS

σ(l,m)
i,j

Yl6=m (cid:16)

−

(cid:16)

D

Ω

E

(cid:17)(cid:17)

= 1

exp (

ρT ρSbij ) ,

−

−

(3.11)

where bij =

l6=m

σ(l,m)
i,j

.

Ω

In the case of the USP and RSP probing, the quantity bij is by

E

P

P

l6=m x(l,m)
D
/σ(l,m) [123, 53]. For the ASP probing, it is a
deﬁnition the edge betweenness centrality
i,j
closely related quantity. Indeed, if the shortest path is used as the metric deﬁning the optimal path
between pairs of vertices, the betweenness gives a measure of the amount of all-to-all traﬃc that goes
through an edge or a vertex. We also recall, that the betweeness can be considered as a non-local
measure of the centrality of an edge or vertex in the graph (see Section 2.2.4).
Since the edge betweenness assumes values between 2 and N (N
1), the discovery probability of
an edge will therefore depend strongly on its betweenness. For instance, for edges with minimum
betweenness bij = 2, we have
2ρT ρS, that recovers the probability that the two end vertices
of the edge are chosen as source and target. This implies that if the densities of sources and targets
are small but ﬁnite in the limit of very large N , all the edges of the underlying graph have a ﬁnite
probability to be discovered. On the other hand, the discovery probability approaches one for edges
with high betweenness, thus predicting a fair sampling of the network.
In most of the current realistic samplings, the situation is diﬀerent. While it is reasonable to consider
(1)) and their density
ρT a small but ﬁnite value, the number of sources is not extensive (NS ∼ O
tends to zero as N −1. In this case it is more convenient to express the edge discovery probability as

πi,j iΩ ≃
h

−

πi,jiΩ ≃

h

1

−

exp

ǫˆbij

,

(cid:17)

−

(cid:16)

(3.12)

where ǫ = ρT NS is the density of probes imposed to the system and the rescaled betweenness ˆbij =
N −1bij is now limited in the interval [2N −1, N
1]. In the limit of large networks (N
), it is clear
(N −1), for any ﬁnite value of ǫ. This readily implies
that edges with low betweenness have
that in real situations the discovery process is generally not complete, a large part of low betweenness
edges not being discovered, and that the network sampling is made progressively more accurate by
increasing the density of probes ǫ.
A similar analysis can be performed for the discovery probability πi of a vertex i. For each source-

−
πi,jiΩ ∼ O
h

→ ∞

3.2. STATISTICAL PHYSICS APPROACH TO TRACEROUTE EXPLORATIONS

45

target set Ω we have that

NS

NT

NS

NT

δl,is

δm,jt σ(l,m)
i

.

(3.13)

πi = 1

1
−  

−

δi,is −

δi,jt

1

−

i

!

s=1
X

t=1
X

= 1 if the vertex i belongs to the

Yl6=m6=i  
where σ(l,m)
-path between nodes l and m, and 0 otherwise. Note
that it has been considered that a vertex belonging to the set of sources and targets is discovered with
probability one. The second term on the right hand side therefore expresses the fact that the vertex
i does not belong to the set of sources and targets and it is not discovered by any
-path between
source-target pairs. By using the same mean-ﬁeld approximation as previously, the average vertex
discovery probability reads as

s=1
X

t=1
X

M

M

!

πiiΩ ≃
h

1

−

(1

ρS −

−

ρT )

ρT ρS

1

−

σ(l,m)
i

Yl6=m6=i (cid:16)

D

.

Ω

E

(cid:17)

(3.14)

As for the case of the edge discovery probability, the average considers all possible source-target pairs
is 1 if i belongs to one
weighted with probability ρT ρS. In the ASP model, the average

of the shortest paths between l and m, and 0 otherwise. For the USP and RSP models,
= x(l,m)
i
ρT ρS ≪

/σ(l,m) where x(l,m)
1, by using the same approximations used for Eq. 3.11 we obtain

Ω
is the number of shortest paths between l and m going through i. If

E

D

i

σ(l,m)
i

σ(l,m)
i
D

Ω

E

1

(1

ρS −
πiiΩ ≃
h
. For the USP and RSP cases, bi =

ρT ) exp (

−

−

−

ρT ρSbi) ,

Ω

E

P

l6=m6=i

σ(l,m)
i
D

/σ(l,m) is the vertex
where bi =
betweenness centrality, that is limited in the interval [0, N (N
1)] [123, 53, 130]. The betweenness
value bi = 0 holds for the leaves of the graph, i.e. vertices with a single edge, for which we recover
ρS + ρT . Indeed, this kind of vertices are dangling ends, that can be discovered only if they
πiiΩ ≃
h
are either sources or targets.
As discussed before, the most usual setup corresponds to a density ρS ∼ O
limit we can conveniently write

(N −1) and in the large N

l6=m6=i x(l,m)

P

−

i

(3.15)

πiiΩ ≃
h

1

−

(1

−

ρT ) exp

ǫˆbi

,

−

(cid:16)

(cid:17)

(3.16)

(N −1) and the rescaled betweenness ˆbi = N −1bi is now
1]. This expression points out that the probability of vertex discovery

where we have neglected terms of order
deﬁned in the interval [0, N
is favored by the deployment of a ﬁnite density of targets that deﬁnes its lower bound.
k∗
i iΩ of the node i
We can also provide a simple approximation for the eﬀective average degree
h
discovered by our sampling process. Each edge departing from the vertex will contribute proportionally
to its discovery probability, yielding

O

−

k∗
i iΩ =
h

1

exp

−

ǫˆbij

−

ǫ

≃

ˆbij.

(3.17)

j (cid:16)
X

(cid:16)
The ﬁnal expression is obtained for edges with ǫˆbij ≪
betweenness is simply related to the vertex betweenness as
2 considers that each vertex path traverses two edges and the term N
paths for which the vertex is an endpoint, this ﬁnally yields

(cid:17)(cid:17)

P

j
X

−

1. Since the sum over all neighbors of the edge
1), where the factor
1 accounts for all the edge

j bij = 2(bi + N

−

k∗
i iΩ ≃

h

2ǫ + 2ǫˆbi.

(3.18)

46

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

ER
N 104
105
E
20
k
h
i
40
kc

ER
104
5.105
100
140

RSF Weibull
104
22000
4.4
3500

104
55000
11
2000

Table 3.1: Main characteristics of the graphs used in the numerical exploration.

The present analysis shows that the measured quantities and statistical properties of the sampled graph
strongly depend on the parameters of the experimental setup and the topology of the underlying graph.
The latter dependence is exploited by the key role played by edge and vertex betweenness in the
expressions characterizing the graph discovery. The betweenness is a nonlocal topological quantity
whose properties change considerably depending on the kind of graph considered. This allows an
intuitive understanding of the fact that graphs with diverse topological properties deliver diﬀerent
answer to sampling experiments.

3.2.3 Numerical simulations on computer generated networks

The previous theoretical results have provided some interesting insights on the topological properties
that are responsible of the eﬃciency and the accuracy of the sampling. In this section, we present the
results of extensive numerical simulations in which the sampling algorithm has been reproduced on
computer generated graphs with diﬀerent topological properties. In particular, we consider the two
separated classes of homogeneous and heterogeneous networks. We use degree dependent quantities to
monitor the eﬃciency of the sampling process as a function of the probing eﬀort. The results are then
exploited to understand the properties of the degree distributions of the sampled networks.
Our data report the various measures for three diﬀerent graphs: the Erd¨os-R´enyi (ER) random graph
as representative of the homogeneous class, and two heterogeneous random graphs, one with power-
k−γ (random scale free - RSF), and the other with Weibull
law distribution of the form P (k)
distribution (WEI) P (k) = (a/c)(k/c)a−1 exp(
(k/c)a). Both forms have been in fact proposed as
representing the topological properties of the Internet [57]. In both cases, we have generated random
graphs using the comﬁguration model (see Section 2.4.2). The parameter choice is a = 0.25 and
c = 0.6 for the Weibull distribution, and γ = 2.3 for the RSF case. Two diﬀerent average degree
= 20, 100 have been used for the ER model. In all cases networks are of N = 104 nodes.
values
The main properties of the various graphs are summarized in Table 3.1.

k
h

−

∼

i

Eﬃciency in the numerical sampling of graphs - The ﬁrst case we consider is that of
homogeneous graphs (ER model). As shown in Ref. [85], vertex and edge betweenness are homogeneous
, respectively,
quantities and their distributions are peaked around their average values
spanning only a small range of variation. These typical values can be inserted into Eqs. 3.12 and 3.16
to estimate the order of magnitude of probes that allows a fair sampling of the graph. Both
πi,jiΩ and
h
. In this limit all edges and vertices will have probability to
πiiΩ tend to 1 if ǫ
h
be discovered very close to one. At lower values of ǫ, obtained by varying ρT and NS, the underlying
i
graph is only partially discovered. Fig. 3.4 shows the behavior of the fraction N ∗
k /Nk of discovered
vertices of degree k, where Nk is the total number of vertices of degree k in the underlying graph,
and the fraction of discovered edges
k /Nk naturally increases with

iΩ /k in vertices of degree k. N ∗

b
h
h

bei
h

bei
h

k∗
h

max

−1,

and

b
h

≫

−1

i

i

3.2. STATISTICAL PHYSICS APPROACH TO TRACEROUTE EXPLORATIONS

47

1
10

2
10

3
10

4
10

1
10

2
10

3
10

4
10

RSF

0
10

-1

10

k

N

 
 
/
 

*
N

-2

k

10

-3

10

0
10
0
10

-1

10

k

N

 
 
/
 
*
N

-2

k

10

WEI

-3

10

0
10

0
10

1
10

2
10

k

N

 
 
/
 
*
N

k

-1

10

-2

10

0

ER

20

k

 

k

 
/
 
Ω
>
*
k
<

 

 

 

k

 
/
 
Ω
>
*
k
<

 

 

 

k

 
/
 
Ω
>
*
k
<

 

 

0
10

-1

10

-2

10

-3

10

0
10
0
10

-1

10

-2

10

-3

10

0
10
0
10

-1

10

-2

10

0

RSF

ε = 0.1
ε = 0.5
ε = 2

ε = 0.1
ε = 0.5
ε = 2

3
10

ε = 0.1
ε = 0.5
ε = 2

40

ε = 0.1 
ε = 0.5
ε = 2

ε = 0.1
ε = 0.5
ε = 2

ε = 0.1
ε = 0.5
ε = 2

WEI

1
10

2
10

3
10

4
10

ER

20

k

40

Figure 3.4: Frequency N ∗
k /Nk of detecting a vertex of degree k (left) and proportion of discovered
iΩ /k (right) as a function of the degree in the RSF, WEI, and ER graph models. The
edges
exploration setup considers NS = 5 and increasing probing level ǫ obtained by progressively higher
density of targets ρT . The axis of ordinates is in log scale.

k∗
h

b
h

the density of targets and sources, and it is slightly increasing with k. The latter behavior can be
easily understood by noticing that vertices with larger degree have on average a larger betweenness.
On the other hand, the range of variation of k in homogeneous graphs is very narrow and only a large
level of probing may guarantee large discovery probabilities. Similarly, the behavior of the eﬀective
discovered degree can be understood by looking at Eq. 3.18. Indeed the initial decrease of
iΩ /k
is ﬁnally compensated by the increase of
(k). The situation is diﬀerent in graphs with heavy-
i
tailed connectivity distributions (RSF and WEI models), for which the betweenness spans various
In
orders of magnitude and the fraction of vertices with very high betweenness is not negligible.
such a situation, even in the case of small ǫ, vertices whose betweenness is large enough (biǫ
1)
ǫ−1/β will be detected with probability one.
have
This is clearly visible in Fig. 3.4 where the discovery probability N ∗
k /Nk of vertices with degree k
saturates to one for large degree values. Consistently, the degree value at which the curve saturates
decreases with increasing ǫ. A similar eﬀect occurs in the measurements concerning
iΩ /k. After
an initial decay (Fig. 3.4) the eﬀective discovered degree increases with the degree of the vertices.
k∗
This qualitative feature is captured by Eq. 3.18 that gives
(k)). At large k
i
h
the term k−1
kβ−1 takes over and the eﬀective discovered degree approaches the real degree
k. Moreover, the broader the distribution of betweenness or connectivity, the better the sampling
obtained.

1. Therefore all vertices with degree k

πiiΩ ≃
h

ǫk−1(1 +

iΩ /k

(k)
i

k∗
h

b
h

b
h

k∗

≫

≫

≃

∼

h

Degree distributions - We now get a clearer picture of the relation between the exploration
process and the underlying graph, and we can tackle the important issue of determining the origin of
sampling biases in the observed degree distributions. Fig. 3.5 shows the cumulative degree distribution

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

48

0

10

-1

10

-2

10

-3

10

)
k
(

P

c

0,1

-4

10

-5

10

0
10

A)

ρ
T = 0.1
ρ
T = 0.25
ρ
T = 0.8

B)

Ns = 2
Ns = 5
Ns = 10

1

10
k

C)

ρ
T = 0.1
ρ
T = 0.25
ρ
T = 0.8

0,04

0,02

0,00

0
10

10

100

1
10

k

D)

Ns = 2
Ns = 5
Ns = 10

10

1
k

2
10

0

10

2

10

10

1
10
k

0

10

i

k
h

= 20, and (C) and (D) to

Figure 3.5: Cumulative degree distribution of the sampled ER graph for USP probes. Figures
(A) and (B) correspond to
= 100. Figures (A) and (C) show
sampled distributions obtained with NS = 2 and varying density target ρT . In the insets we report
the peculiar case NS = 1 that provides an apparent power-law behavior with exponent
1 at all
. The insets are in lin-log scale to show the logarithmic
values of ρT , with a cut-oﬀ depending on
i
behavior of the corresponding cumulative distribution. Figures (B) and (D) correspond to ρT = 0.1
and varying number of sources NS. The solid lines are the degree distributions of the underlying
= 100, the sampled cumulative distributions display plateaus corresponding to peaks
graph. For
in the degree distributions, induced by the sampling process.

k
h

k
h

k
h

−

i

i

i

i

≡

k
h

k
h

k′≥k P (k′) of the sampled graph deﬁned by the ER model for increasing density of targets
Pc(k)
and sources. Sampled distributions look only approximately like the genuine distribution; however,
P
2 they are far from true heavy-tail distributions at any appreciable level of probing. Indeed,
for NS ≥
the distribution runs generally over a small range of degrees, with a cut-oﬀ that sets in at the average
of the underlying graph. In order to stretch the distribution range, homogeneous graphs
degree
with very large average degree
must be considered, that emerges also from the rigorous proof in
Ref. [1] provided for single-source explorations.
However, other distinctive spurious eﬀects appear in this case. In particular, since the best sampling
occurs around the high degree values, the distributions develop peaks appearing as plateaus in the
cumulative distribution (see Fig.3.5). The inset of Fig.3.5 displays the single-source case, in which we
1. It is worth noting that the experimental setup
recover the apparent scale-free behavior with slope
with a single source corresponds to a highly asymmetric probing process, in which the mean-ﬁeld
approach, and consequently our theoretical predictions, are not valid.
The present analysis shows that in order to obtain a sampled graph with apparent scale-free behavior
on a degree range varying over n orders of magnitude we would need the very peculiar sampling of a
10n, that is a rather unrealistic situation
homogeneous underlying graph with an average degree
in the Internet and many other information systems, where the observed cut-oﬀ sets in at least at
2). Indeed, it would mean that on average Internet’s autonomous systems should
k
(102) connections, that is a completely unrealistic huge number. On the contrary, in
have at least
the case of RSP and ASP model, we observe that the obtained distributions are closer to the real one,
almost independently of the probing eﬀort. On graphs with heavy-tailed distributions (see Fig. 3.6),
we observe completely diﬀerent results, due to the fact that the distribution tail is fairly reproduced

(102) (i.e. n

∼ O

k
h

i ≃

O

−

≥

3.2. STATISTICAL PHYSICS APPROACH TO TRACEROUTE EXPLORATIONS

49

0

10

-2

10

)
k
(
 

P

c

-4

10

0

10

-2

10

)
k
(
 

P

c

ρ
ρ
ρ

T = 0.1
T = 0.25
T = 0.8

Ns = 5
Ns = 10
Ns = 20

RSF

WEI

-4

10

RSF

WEI

0

10

1

10

3

10

2
10
k

1

10

2
10
k

3

10

4

10

Figure 3.6: Cumulative degree distributions of the sampled RSF and WEI graphs for USP probes.
The top ﬁgures show sampled distributions obtained with NS = 2 and varying density target ρT . The
ﬁgures on the bottom correspond to ρT = 0.1 and varying number of sources NS. The solid lines are
the degree distributions of the underlying graph.

even at rather small values of ǫ. Despite both underlying graphs (WEI and RSF) have a small average
degree, the degree distribution spans more than two orders of magnitude, and the whole range is
suﬃciently well sampled by the exploration process.
Some distortions occur for low and average degree nodes, that are under-sampled. This undersampling
can either yield an apparent change in the exponent of the degree distribution (as also noticed by
Petterman and De Los Rios in Ref. [205] for single source experiments), or, if NS is small, yield a
power-law like distribution for an underlying Weibull distribution. As shown in Fig. 3.6, a small
increase in the number of sources allows to discriminate between both forms even at small ρT .
The disparity in the quality of the results for homogeneous and heterogenous networks is due to
In heterogeneous graphs, vertices with
the diﬀerent discovery eﬃciency reached by the process.
high degree are eﬃciently sampled with an eﬀective measured degree that is rather close to the
real one. This means that the degree distribution tail is fairly well sampled while deviations should
be expected at lower degree values. In conclusion, graphs with heavy-tailed degree distribution allow a
better qualitative representation of their statistical features in sampling experiments. Indeed, the most
important properties of these graphs are related to the heavy-tail part of the statistical distributions
that are indeed well discriminated by the traceroute-like exploration.

3.2.4 Accuracy of the mapping process

Up to now, we have focused on the eﬃciency of the sampling process, indicating which is the density
of probes we have to deploy throughout the network in order to get reasonably good maps of the

50

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

network. Another important aspect is related to the level of accuracy that the exploration is able
to achieve in the description of the local topology. The most common biases aﬀecting the mapping
process concern 1) the miss of lateral connectivity, and 2) the multiple sampling of central nodes (and
edges), which may aﬀect the eﬃciency of the whole process.
While the ﬁrst problem might be solved by an optimization in the deployment of probes, actually
relying on a criterion of decentralization of sources and targets, multiple sampling can be studied
through some general concepts like redundancy and dissymmetry of the discovery process. A sampling
is redundant when nodes (edges) are discovered many times during the traceroute; it is locally
symmetric when the neighborhood of the nodes is equally sampled, i.e. there are no preferential paths
by which a node is traversed. In the following, we give quantitative measures of the level of redundancy
and dissymmetry of a traceroute mapping process, revealing their relation with the topology of the
sampled graph.

Redundancy -

On the one side, the node discovery process requires a certain level of re-
dundancy, since each new passage might, in principle, contribute to a more detailed exploration of
the neighborhood. When, however, the discovery frequency is too large, it can seriously aﬀect the
eﬃciency of the whole process. Let us deﬁne the edge redundancy re(i, j) of an edge (i, j) in a
traceroute-sampling as the number of probes passing through the edge (i, j). Using the notations of
Section 3.2.2, this quantity is written for a given set of probes and targets as

s=1
X
Averaging over all possible realizations and assuming the uncorrelation hypothesis, we obtain

t=1
X

re(i, j) =

Xl6=m  

NS

NT

δl,is

δm,it σ(l,m)

i,j

.

!

re(i, j)
h

iΩ ≃

ρT ρS

σ(l,m)
i,j

= ρT ρSbij .

Xl6=m

D

Ω

E

This result implies that the average redundancy of an edge is related to the density of sources and
targets, but also to the edge betweenness. For example, an edge of minimum betweenness bij = 2
can be discovered at most twice in the extreme limit of an all-to-all probing. On the contrary, a very
1), would be discovered approximately
central edge of betweenness bij close to the maximum N (N

(N ) times by a traceroute-probing from a single source to all the possible destinations.

O
Similarly, the redundancy rn(i) of a node i, intended as the number of times the probes cross the node
i, can be obtained:

−

rn(i) =

σ(l,m)
i

δl,is

δm,it .

NS

NT

Xl6=m

s=1
X

t=1
X

After separating the cases l = i and m = i in the sum, the averaging over the positions of sources and
targets yields in the mean-ﬁeld approximation:

rn(i)
h

iΩ =

ρSρT h

σ(l,m)
i

iΩ + 2ρSρT N

≃

2ǫ + ρSρT bi .

Xl6=m6=i

In this case, a term related to the number of traceroute probes ǫ appears, showing that unavoidably
a part of the mapping eﬀort goes to generate node redundancy. 1 In Fig. 3.7 we report the behavior of
the average node redundancy as a function of the degree k for both homogeneous and heterogeneous
graphs. For both models, the behaviors are in good agreement with the mean-ﬁeld prediction, showing

1By simple manipulation of formulas 3.20 and 3.22, an equivalent of the identity

j bi,j = 2(bi + N − 1) for

redundancies is

j hre(i, j)iΩ ≃ 2 hrn(i)iΩ − 2ǫ .

P

P

(3.19)

(3.20)

(3.21)

(3.22)

3.2. STATISTICAL PHYSICS APPROACH TO TRACEROUTE EXPLORATIONS

51

5

10
4

10

3

2

10

10

1

10
0

10
-1

10

1

10

0

10

-1

10

-2

10

)
k
(

n

r

)
k
(

n

r

RSF

0

10

1

10

k

2

10

3

10

Ns = 2
Ns = 10
Ns = 20

1

10

0

10

-1

10

-2

10

ER

0

20

k

NS = 2
NS = 10
NS = 20

40

ER

NS = 2
NS = 10
NS = 20

50

150

100
k

Figure 3.7: Average node redundancy as a function of the degree k for RSF (top) and ER (bottom)
model (N = 104). For the ER model, two blocks of data are plotted, for
= 20 (left) and for
= 100 (right) The target density is ﬁxed (ρT = 0.1), and NS = 2 (circles), 10 (squares), 20
k
h
(k) in perfect agreement
b
(triangles). The dashed lines represent the analytical prediction 2ǫ + ρSρT h
i
with the simulations.

k
h

i

i

the tight relation between redundancy and betweenness centrality.
In the case of heavy-tailed underlying networks, the node redundancy typically grows as a power-law
of the degree, while the values for random graphs vary on a smaller scale. This behavior points out
that the intrinsic hierarchical structure of scale-free networks plays a fundamental role even in the
process of path routing, resulting in a huge number of probes iteratively passing through the same
set of few hubs. On the other hand, for homogeneous graphs the total number of node visits is quite
uniformly distributed on the whole range of connectivity, independently of the relative importance of
the nodes. This is a further element in favor of the argument that homogeneous graphs with large
mean connectivity are pretty badly sampled. Indeed, the local topology of well-connected vertices is
analyzed with the same level of accuracy as for low degree nodes, yielding to generally dissatisfying
results.

Dissymmetry: Participation Ratio -

The high rate of redundancy found in the numerical
data does not necessarily imply that the local topology close to a node is well discovered: preferential
paths could indeed carry most of the probing eﬀort. Let us consider the relative number of occurrences
of a given edge (i, j) during the traceroute, with respect to the total occurrence for the edges in the
f (i)
j }j∈V(i) for
neighborhood of i. For each discovered node i, we can thus deﬁne a set of frequencies

{

52

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

0

10

)
*
k
(

Y

2

-1

10

-2

10

-3

10

10

0

10
0

)
*
k
(

Y

2

-1

10

-2

10

0

RSF

Ns = 2
Ns = 10
Ns = 20

Ns = 2
Ns = 10
Ns = 20

1

10

2

10

3

10

ER

40

20
k* 

Figure 3.8: Participation ratio as a function of discovered (k∗) connectivity for RSF (top) and ER
(bottom) models (N = 104). The target density is ﬁxed (ρT = 0.1) and three value of NS are
presented: 2 (circles), 10 (squares), 20 (triangles). The dashed lines correspond to the 1/k∗ bound.

the edges (i, j) of its neighborhood; in terms of redundancy, the edge frequency f (i)

is deﬁned by

j

f (i)
j =

re(i, j)
j∈V(i) re(i, j)

,

0

f (i)
j ≤

1

≤

(i, j)

∀

.

∈ E

Neglecting the correlations, we can write an approximation for the average edge frequency as

P

f (i)
j

D

Ω

E

=

*

re(i, j)

j∈V(i) re(i, j) +Ω
ρSρT bij
2ρSρT (bi + N

≃

P

re(i, j)

iΩ

h
j∈V(i) re(i, j)
E

bij
2(bi + N

Ω

,

1)

−

≃

−

DP
=
1)

j bij = 2(bi + N

1). The calculation reveals that, at a ﬁrst
where we have used the identity
approximation, the edge frequencies are topological quantities, independent of the probing eﬀort, in
agreement with the fact that frequencies are relative quantities. The dissymmetry of the discovery
of the neighborhood of a node may be quantiﬁed through the participation ratio of these frequencies
[97, 34]:

P

−

Y2(i) =

f (i)
j

2

.

Xj∈V(i) (cid:16)
1/k∗
i (only discovered links give a ﬁnite
If all the edge frequencies of i are of the same order
contribution), the participation ratio should decrease as 1/k∗
i with increasing discovered connectivity
k∗
i . Hence, in the limit of an optimally symmetric sampling, it should yield a power law behavior

∼

(cid:17)

(3.23)

(3.24)

(3.25)

3.2. STATISTICAL PHYSICS APPROACH TO TRACEROUTE EXPLORATIONS

53

∼

k∗−1. When only few links are preferred, for instance because more central in the shortest
Y2(k∗)
path routing, the sum is dominated by these terms, leading to a value closer to the upper bound 1.
Numerical data for Y2 as a function of the discovered (k∗) connectivity for diﬀerent probing eﬀorts,
are displayed in Fig. 3.8. For heterogeneous graphs, the values of Y2 tend towards the curve k∗−1 for
increasing ǫ. The average local topology of low degree nodes seems to be sampled more homogeneously
than the larger degree nodes. On the contrary, in the homogeneous case (ER), the ﬁgures show a
general high level of dissymmetry persistent at all degree values, only slightly dependent on the actual
connectivity.

Dissymmetry: Entropy Measure -

The edge frequency is inﬂuenced by the presence of
sources and targets, thus we introduce a more reﬁned frequency, f (i)
kj deﬁned as the number of probes
(i, j) of edges centered on the node i, with respect to the total number
passing through the pair (k, i)
of transits through any of the possible couples of edges in the neighborhood of i. This frequency does
not take into account single edges, but the path traversing each vertex and the dissymmetry of the
ﬂow.
A simple qualitative estimation for the average frequency is obtained using the usual ﬁrst approxima-
tion for the edge redundancy 2

−

f (i)
kj

D

E

Ω ≃

ρSρT bkibij(1
2(bi + N
ci

1

−

−
2

≃

ci)

−
1)

1
ρSρT bi

bkibij
bi(bi + N

.

1)

−

Even in this more complex situation, the approximated expression for the frequencies depends only on
topological properties of the underlying graph (such as the betweenness centrality and the clustering
coeﬃcient ci).
By means of this frequency, we deﬁne an entropy measure providing supplementary evidence of
the tight relation between local accuracy, homogeneous sampling and topological characterization
of graphs. Indeed, a traceroute that discovers nodes crossing a larger variety of their links, and with
diﬀerent paths, is expected to be more accurate (and likely eﬃcient) than the one always selecting the
same path.
In the same spirit of the Shannon entropy [41], which is a good indicator of homogeneity, we deﬁne
the local traceroute entropy of a node i by

hi =

1
log k∗
i

−

Xk6=j∈V(i)

kj log f (i)
f (i)
kj ,

(3.26)

where log k∗
i is simply a normalization factor. As usual, we deﬁne H(k) as the entropy averaged over
the nodes of degree k. The numerical data of H(k) for RSF and ER models and for diﬀerent levels of
probing are reported in Fig. 3.9. The values for ER are slightly increasing both for increasing degree k
and number of sources NS, with no qualitative diﬀerence in the behavior at low or high degree regions.
On the other hand, the case of heterogeneous networks agrees with the previous observations. The
curve for H(k), indeed, shows a saturation phenomenon to values very close to the maximum 1 at

2In this case the redundancy appearing in the fraction deﬁning the frequency f (i)
kj

is the contribution

by the edges-pair (k, i) − (i, j). Considering separately the portion of shortest path
ρS ρT
from l to i through k and from i to m through j, we replace the sum of average products with the approximation

l6=m6=i

Ω

. Up to a factor the last averaged term is the redundancy

bij

2(bi+N−1) of the edge

P

(1 − ci)bki

σ(l,m)
ki

σ(l,m)
ij

D

E
m6=i σ(i,m)

ij

*

P
h∈V(i)

m6=i σ(i,m)

ih +Ω

(i, j). Since the sum of edge-pairs redundancies over the neighborhood gives essentially the redundancy of the central
node i, the ﬁnal expression follows easily.

P

P

54

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

0

10

-1

10

-2

10

)
k
(
H

-3

10

0

10
0

10

)
k
(
H

-1

10

-2

10

1

10

2

10

3

10

4

10

RSF

Ns = 2
Ns = 10
Ns = 20

ER

Ns = 2
Ns = 10
Ns = 20

10

20

30

40

50

k

Figure 3.9: Entropy vs. k: a saturation eﬀect is clear at medium-high degree nodes for scale free
topologies (RSF), instead of a more regular increase for homogeneous graphs (ER). In the ﬁgure there
are diﬀerent curves for NS = 2 (circles), 10 (squares), 20 (triangles) and ρT = 0.1.

large enough degree, indicating a very homogeneous sampling of these nodes.
Summarizing, in the case of heterogeneous networks, the nodes with high degree and betweenness are
in general redundantly sampled, but present a rather symmetrical discovery of their neighborhood.
On the contrary, in homogeneous networks vertices suﬀer a less redundant sampling, showing a higher
dissymmetry of the local exploration process. This result should be taken into account in deciding
source-target deployment strategies, in order to minimize both dissymmetry and redundancy.

3.2.5 Optimization

In the previous sections we have provided a general qualitative understanding of the eﬃciency of
traceroute-like exploration and the induced biases on the statistical properties. The quantitative
analysis of the sampling strategies, however, is a much harder task that calls for a detailed study of the
discovered proportion of the underlying graph and the precise deployment of sources and targets. In
this perspective, Guillaume and Latapy have shown in Ref. [139] that the fraction N ∗/N and E∗/E of
vertices and edges discovered in the sampled graph depend on the probing eﬀort. Unfortunately, the
mean-ﬁeld approximation breaks down when we aim at a quantitative representation of the results,
since the neglected correlations are necessary for a precise estimate of the various quantities of interest.
For this reason we performed an exhaustive set of numerical explorations aimed at a ﬁne determination
of the level of sampling achieved for diﬀerent experimental setups.
In Fig. 3.10 we report the proportion of discovered edges in the numerical exploration of homogeneous

3.2. STATISTICAL PHYSICS APPROACH TO TRACEROUTE EXPLORATIONS

55

RSF

ρ
T = 0.1
Ns = 5

0
10

-1

10

-2

10

0
10

-1

10

-2

10

0
10

-1

10

 

N

 
/
 
*
N

N

 
/
 
*
N

N

 
/
 
*
N

WEI

ER

-2

10

-1

10

E

 
/
 
*
E

E

 
/
 
*
E

E

 
/
 
*
E

0
10

-1

10

-2

10

-3

10

0
10

-1

10

-2

10

-3

10

0
10

-1

10

-2

10

-3

10

RSF

WEI

ER

0
10

ε

-1

10

0
10

ε

Figure 3.10: Behavior of the fraction of discovered edges in explorations with increasing ǫ. For each
underlying graph studied we report two curves corresponding to larger ǫ achieved by increasing the
target density ρT at constant NS = 5 (squares) or the number of sources NS at constant ρT = 0.1
(circles).

(ER model) and heterogeneous (RSF and WEI models) graphs for increasing level of probing eﬀort ǫ.
The level of probing is increased either by raising the number of sources at ﬁxed target density or by
raising the target density at ﬁxed number of sources. As expected, both strategies are progressively
more eﬃcient with increasing levels of probing.

(1)
In heterogeneous graphs, it is also possible to see that when the number of sources is NS ∼ O
the increase of the number of targets achieves better sampling than increasing the deployed sources.
On the other hand, our model of shortest path exploration is symmetric if we exchange sources with
targets; therefore in the numerical experiments we can easily verify that if the number of sources is
(1/N ), then the increase of the number of sources achieves better sampling
very large and ρT ∼ O
than increasing the deployed targets.
This ﬁnding hints toward a behavior that is determined by the number of sources and targets, NS
and NT (or equivalently of NS and ρT ). This point is clearly illustrated in Fig. 3.11, where we report
the behavior of E∗/E and N ∗/N at ﬁxed ǫ and varying NS and ρT . The curves exhibit a non-
trivial behavior and since we work at ﬁxed ǫ = ρT NS, any measured quantity can then be written as
f (ρT , ǫ/ρT ) = gǫ(ρT ). It is worthy noting that the curves show a structure allowing for local minima
and maxima in the discovered portion of the underlying graph.
This feature is a consequence of the symmetry by the exchange of sources and targets of the model,
i.e. an exploration with (NT , NS) = (N1, N2) is equivalent to one with (NT , NS) = (N2, N1). In other
words, at ﬁxed ǫ = N1N2/N , a density of targets ρT = N1/N is equivalent to a density ρ′
T = N2/N .
Since N2 = ǫ/ρT , we get that at constant ǫ, experiments with ρT and ρ′
T = ǫ/(N ρT ) are equivalent,
obtaining by symmetry that any measured quantity obeys the equality

gǫ(ρT ) = gǫ

ǫ
N ρT (cid:19)

.

(cid:18)

(3.27)

56

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

 

N

 
/
 
*
N

 

N

 
/
 
*
N

 

N

 
/
 
*
N

0

10

-1

10

0

10

-1

10

-2

10

0

10

-1

10

-2

10

-3

10

-2

10

-1

10

0

10

-3

10

-1

10

0

10

-3

10

-2

10

-1

10

0

10

-3

10

-2

10

-1

10

0

10

0

10

-1

10

-2

10

0

10

-1

10

-2

10

0

10

-1

10

-2

10

ER

-2

10

WEI

RSF

10

-2
ρ

T

E

 
/
 
*
E

E

 
/
 
*
E

 

E

 
/
 
*
E

-3

10

-1

10

0

10

-3

10

-1

10

0

10

10

-2
ρ

T

Figure 3.11: Behavior as a function of ρT of the fraction of discovered edges and nodes in explorations
with ﬁxed ǫ (here ǫ = 2). Since ǫ = ρT NS, the increase of ρT corresponds to a lowering of the number
of sources NS.

p

This relation implies a symmetry point signaling the presence of a maximum or a minimum at ρT =
ǫ/N .
ǫ/(N ρT ). We therefore expect the occurrence of a symmetry in the graphs of Fig. 3.11 at ρT ≃
Indeed, the symmetry point is clearly visible and in quantitative good agreement with the previous
estimate in the case of heterogeneous graphs. For homogeneous topology the curves have a smooth
behavior that makes diﬃcult the clear identiﬁcation of the symmetry point. Moreover, USP probes
create a certain level of correlations in the exploration that tends to hide the complete symmetry of
the curves. The previous results imply that at ﬁxed levels of probing ǫ diﬀerent proportions of sources
and targets may achieve diﬀerent levels of sampling. This hints to the search for optimal strategies in
the relative deployment of sources and targets. The picture, however, is more complicate if we look at
other quantities in the sampled graph. In Fig. 3.12 we show the behavior at ﬁxed ǫ of the measured
average degree
of the underlying graph as a function
of ρT . The plot shows also in this case a symmetric structure. By comparing Fig. 3.12 with Fig. 3.11
we notice that the symmetry point is of a diﬀerent nature for diﬀerent quantities: the minimum in the
fraction of discovered edges corresponds to the best estimate of the average degree. A similar result
is obtained for the behavior of the ratio
between the clustering coeﬃcient of the sampled and
the underlying graph: as shown in Fig. 3.12, the best level of sampling is achieved at particular values
of ǫ and NS that are conﬂicting with the best sampling of other quantities.
The numerical data obtained with diﬀerent source and target densities hint to a possible optimization
of the sampling strategy. The optimal solution, however, appears as a trade-oﬀ strategy between the
diﬀerent levels of eﬃciency achieved in competing ranges of the experimental setup. In this respect,
a detailed and quantitative investigation of the various quantities of interest in diﬀerent experimental
setups is needed to pinpoint the most eﬃcient deployment of source-target pairs depending on the
underlying graph topology.

∗ normalized by the actual average degree
i

k
h

k
h

c
h

c
h

∗/

i

i

i

3.2. STATISTICAL PHYSICS APPROACH TO TRACEROUTE EXPLORATIONS

57

>
k
<

 
/
 
*
>
k
<

>
k
<

 
/
 
*
>
k
<

>
k
<

 
/
 
*
>
k
<

0

10

-1

10

0

10

-1

10

0

10

-1

10

-3

10

-2

10

-1

10

0

10

-3

10

-2

10

-1

10

0

10

0

10

-1

10

0

10

-1

10

0

10

-1

10

ER

WEI

RSF

10

-2
ρ

T

c
 
/
 
*
c

c
 
/
 
*
c

c
 
/
 
*
c

-3

10

-2

10

-1

10

0

10

-3

10

-2

10

-1

10

0

10

-3

10

-1

10

0

10

-3

10

-1

10

0

10

10

-2
ρ

T

Figure 3.12: Behavior as a function of ρT of the fraction of the normalized average degree
and of the fraction of the normalized average clustering coeﬃcient
(here ǫ = 2).

k
i
h
for a ﬁxed probing level ǫ

k
h

c
h

c
h

∗/

i

i

i

∗/

3.2.6 Non-local measures under sampling: the case of k-core structures

Up to now, all statistical quantities studied on sampled networks are related to local properties and lo-
cal correlations; but real networks may present non-locally correlated structures, whose integrity under
sampling is even more questionable. For this reason, we have investigated the eﬀects of traceroute-
like sampling on the k-core organization of networks.
The k-core analysis of a network is based on a non-trivial decomposition in subgraphs, that has
recently attracted the interest of physicists working in this ﬁeld for its relation with box counting
methods in the study of self-similarity of natural systems [225, 226, 132].
The k-core of a network, deﬁned in Section 2.2.5, is the maximal subset induced by all nodes having
at least k neighbors in it, and the k-shell is the set of nodes belonging to the k-core but not to the
(k + 1)-core.
The k-core decomposition of a network, going from k = 1 (i.e. the whole network without isolated
nodes) up to the maximum available value kmax, provides a hierarchical structure in which most in-
ternal k-shells contain high degree nodes belonging to the very fundamental backbone of the network,
whereas the external ones are formed by low-degree and more peripheral nodes. In Ref. [7, 8, 9] (see
also the web-site of the visualization tool Lanet-VI [165]), we have used the k-core decomposition as
a tool for analyzing networks, discovering hierarchical structures, and studying the main statistical
properties at the diﬀerent scales (i.e. in the diﬀerent k-cores).
Almost all complex networks (real and synthetic) seem to share a common “scale-invariance” prop-
erty with respect to the k-core organization: indeed, after a simple rescaling the curves corresponding
to quantities like the degree distribution P (k), the average nearest neighbor degree knn(k) and the
It is thus
clustering coeﬃcient c(k), computed in the diﬀerent k-cores show a nice data collapse.

58

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

interesting to test the behavior of the k-core decomposition in sampled networks, in order to check
the robustness of these properties with respect to possible sampling biases. 3
Note that a single source traceroute-like probing yields essentially a tree, then the k-core decompo-
sition is by deﬁnition trivial (with maximum core kmax = 1). Yet, a sampling cannot discover paths
or edges that do not exist, so that the maximal shell index of a network, kmax, is not increased by
partial sampling (as the maximal degree observed), and reversely, the actual kmax is at least equal to
the one found by a sampling of the true network.
Internal cores are more connected and are traversed by a larger number of paths, therefore we expect
that a path-based sampling should intuitively discover and sample better the central cores, introducing
stronger biases in the structure of the peripheral shells. Moreover, the shell index of a node is directly
related to its routing capacity, since two nodes belonging to the same shell of index k have exactly
k “distinct” paths between them, where distinct means that no node and no edge are used more
than once. The abundance of paths between nodes corresponds also to a higher level of structural
and functional robustness of the system. Hence, nodes with high shell index are expected to perform
better in routing processes.
We have checked such ideas performing a traceroute-like probing of various networks, and comparing
their k-core decomposition before and after sampling. We have used NS = 50 sources, and various
values of probing eﬀorts from ǫ = 0.1 to ǫ = 5.
Figure 3.13 reports the curves of the k-shell size as a function of the index for various network models
and various sampling eﬀorts. The numerical measures have been performed on four types of networks:
the ER and RSF models, and two network obtained using the generators BRITE [176] and INET
[149], that are based on optimization strategies and are commonly used by computer scientist in order
to reproduce some speciﬁc features of the Internet, such as power-laws and hierarchy. Both yield
broad degree distributions and general properties similar to RSF graphs. For ER networks, shells are
. Such networks,
almost uniformly populated and concentrated in a range of index values around
i
whose k-core structure is very diﬀerent from that observed for AS maps (see Ref. [8]), show a rather
peculiar behavior also after sampling.

k
h

On the contrary, the power-law shapes obtained for RSF or BRITE networks, are comparable to
the one observed in the AS maps and look very robust under sampling; even if the slope is aﬀected.
Indeed, shells of smaller indices are less well sampled.
In particular, the size of the ﬁrst shell is
strongly decreased by the sampling procedure; in some cases in fact, the ﬁrst shell is larger than the
second in the original network, but becomes smaller in the sampled network. We note that in the
available AS maps, the ﬁrst shell is indeed typically smaller than the second, and that the true AS
network thus very probably exhibits a much larger shell of index k = 1. This is consistent with the
idea that the proportion of leaves is extremely underestimated in current Internet mapping data. A
similar argument should hold for the value of the exponent in the power-law behavior of the shell size
vs. its index (see Ref. [8, 9]).
Figure 3.14 reports the behavior of other typical quantities of the network: the average degree of the
nearest neighbors of a node of degree k, and the clustering coeﬃcient of nodes of degree k. These
properties show self-similar features in the k-core decomposition that seem to be preserved by the sam-
pling process. Although the precise form of the degree distribution of the whole network is slightly
altered, the basic correlation properties are conserved in the sampling.

3We will refer to cores and degrees using the same index k, the distinction between the two cases being evident from
the diﬀerent context. When the context is not clear, we will however specify the meaning of k (if it indicates the degree
or the k-core index).

3.2. STATISTICAL PHYSICS APPROACH TO TRACEROUTE EXPLORATIONS

59

5
5
10
10
4
4
10
10

3
3
10
10
2
2
10
10

1
1
10
10

4
4
10
10

3
3
10
10
2
2
10
10

1
1
10
10

|
 
l
l
e
h
s
-
k

 
|

|
 
l
l
e
h
s
-
k

 
|

ER

INET

orig
ε=5
ε=1
ε=0.1

orig
ε=5
ε=1
ε=0.1

orig
ε=5
ε=1

orig
ε=5
ε=1
ε=0.1

RSF, γ=2.3

0
0
10
10

1
1
10
10
k

BRITE

0
0
10
10

1
1
10
10
k

Figure 3.13: Plot of the size of the k-shells vs. k for various models, before and after traceroute-
like sampling, with diﬀerent probing eﬀorts ǫ. We used an Erd¨os-R´enyi (ER) random graph with
= 20, a random scale-free network (RSF) with exponent γ = 2.3, and two networks obtained by
k
h
the generators BRITE and INET, popularly used in the computer scientist community to reproduce
some features of the Internet topology. All networks have size N = 105, except for INET (N = 104).
Note that the k index on the x-axis indicates the k-shell index, not the degree.

i

While on a qualitative level, it seems possible to distinguish between networks with diﬀerent topolog-
ical structures, important quantitative biases appear, that are related with the arguments exposed in
Section 3.2.3 about the eﬃciency of nodes discovery. For a network obtained with BRITE, Fig. 3.15
displays the probability that the original shell index k of a vertex has changed in k′ due to the sam-
pling process. At low sampling eﬀort, many vertices remain completely undiscovered, and in general
shell index properties are strongly aﬀected in a seemingly erratic way (see the plot for ǫ = 0.1). For
larger values of sampling eﬀort a strong correlation appears between the two shell indices, even if a
systematic downwards trend is observed.
A naive explanation for such persistence of the k-core structure under traceroute-like sampling
is given looking at the process of path merging by which we get the maps. Let us consider three
traceroute paths between three diﬀerent pairs of vertices: if these paths meet two-by-two in some
nodes, such three nodes result to be connected by a cycle, that is a 2-core. Increasing the number
of paths, it is possible that strongly connected sets of nodes emerge (in the sense of a large number
of existing paths between them). This picture is likely to be true in scale-free networks, in which
the central nodes are redundantly sampled by traceroute (as seen in Section 3.2.4). Hence, the
presence of a genuine k-core structure in sampled graphs is due to the fact that nodes are sampled
by means of paths. On the contrary, since node-picking algorithms do not guarantee that nodes are
fairly connected, in many biological networks the k-core structure might be strongly biased by sampling
methods.
In summary, the results presented here indicate that the sampling biases do in fact aﬀect only slightly

60

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

0

10

-1

10

0

10

-1

10

>

 

n
n

k
 
<

 
/
 
)
k
(

n
n

k

>

 

n
n

k
 
<

 
/
 
)
k
(

n
n

k

RSF, γ=2.3

5-core
9-core
13-core
17-core

Brite

5-core
9-core
13-core
17-core

Brite

RSF, γ=2.3

0

10

-1

10

>
 
c
 
<

 
/
 
)
k
(
c

0

10

-1

10

>
 
c
 
<

 
/
 
)
k
(
c

8-core
12-core
19-core
25-core

2-core
3-core
4-core
5-core

8-core
12-core
19-core
25-core

2-core
3-core
4-core
5-core

2-core
3-core
4-core
5-core

Weibull

Inet

0

10

1

10
k / < k >

2

10

0

10

1

10
k / < k >

2

10

2-core
3-core
4-core
5-core

Weibull

0

10

1
10
k / < k >

Inet

2
10

0
10

1
10
k / < k >

2
10

Figure 3.14: Nearest neighbors degree distribution (left) and clustering spectrum (right) of some k-
cores, rescaled by the corresponding average values, for some network models after sampling through
a traceroute-like process with NS = 50 sources and target density NT /N = 0.1. Here, the index k
refers to the degree.

the measure of the statistical properties of the k-core organization in heterogeneous graphs, even at
relatively low levels of sampling. This corroborates the idea that the k-core properties observed for
the Internet are genuine. Quantitative analysis is more problematic, due to the incomplete sampling
of the edges. In fact, the routing properties of a network are related with the multiplicity of paths
between nodes, and thus with k-core properties. Hence, we conclude that “measured” routing capacity
of nodes, if limited to the analysis of Internet maps, are certainly rather underestimated compared to
real performances.

3.3. NETWORK SPECIES PROBLEM

61

Figure 3.15: The grayscale code gives the probability of a change in shell index due to the traceroute-
like sampling, from a certain index before sampling (x axis) to another one after sampling (y axis).
The line at y = 0 represents the probability of vertices of shell index x to be absent from the sampled
graph. The initial network is obtained by the BRITE generator. Here NS = 50 sources and a fraction
NT /N = 2.10−3 (left) and NT /N = 2.10−2 (right) of targets are used.

3.3 Network Species Problem: a statistical method to correct

biases

An unexpected application of the traceroute model of Internet explorations is that of providing a
theoretical framework in which it is possible to deﬁne and test statistical estimators for important
unknown properties of the networks and study which is the best estimator for a given underlying
topology. In fact, in Ref. [242], we have shown that the inference from traceroute-like measurements
of many of the most basic topological quantities, including network’s size and degree characteristics, is
a version of the so-called ‘species problem’ in statistics. This observation has important implications,
since the species problem is known to be of a particularly challenging nature.
A basic example of a traceroute-based species problem is the estimate of the number of nodes in
a network (Section 3.3.1). Using statistical subsampling principles we have derived two estimators
for this quantity (Section 3.3.2), the performances of which will be illustrated by means of numerical
simulations on networks with various topological characteristics (Section 3.3.3).
According to the results exposed in the previous section, one can conclude that at a qualitative level
traceroute-like samplings are reliable. On the other hand, at a quantitative level real networks (e.g.
the Internet at diﬀerent levels) can considerably diﬀer from sampled maps. The species approach
seems to be valuable to estimate quantities, such as the size, the number of links, the average degree,
and the precise analytic form of the heavy-tailed degree distribution, that cannot be estimated using
previously exposed techniques.

3.3.1 The Species Problem in Networks

≡

η(G) a generic global quantity characterizing a graph G. In general, the real value
Let us call η
of η is not known, thus it is natural to wish to produce an estimate, say ˆη, based on the network
sampling, i.e. on the traceroute-sampled graph G∗. However, for quantities like the size N , the
number of edges E, the average degree
, the problem of their inference is closely related to the
i
species problem in statistics. In general, the species problem refers to the situation in which, having

k
h

62

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

observed n members of a (ﬁnite or inﬁnite) population, each of whom falls into one of C distinct
classes (or ‘species’), an estimate ˆC of C is desired. This problem arises in numerous contexts, such
as numismatics (e.g., how many of an ancient coin were minted [119]), linguistics (e.g., what was the
size of an author’s apparent vocabulary [174, 113]), and biology (e.g., how many species of animals
inhabit a given region).
The species problem has received a good deal of attention in statistics (see, for instance, Ref. [60]),
but it is, in general, a diﬃcult problem, since we need to estimate the number of species not observed.
In practice, the species expected to be missed are those that are present in relatively low proportions
in the population, and there could be an arbitrarily large number of such species in arbitrarily low
proportions. The methods proposed for its solution diﬀer in the assumptions regarding the nature of
the population, the type of sampling involved, and the statistical machinery used. We have shown
that it can also be associated with the inference of graph characteristics η(G) in traceroute-like
samplings.
For example, the problem of estimating the number of vertices and edges in a network G i.e., N and
E may be mapped on the species problem by considering each separate vertex i (or edge e) as a
‘species’ and declaring a ‘member’ of the species i (or e) to have been observed each time that i (or
e) is encountered on one of the NS ×
Again, the problem of inferring the degree ki of a vertex i from traceroute measurements can also be
mapped on the species problem, by letting all edges incident to i constitute a species and declaring a
member of that species to have been observed every time one of those edges is encountered. Because
ki}i∈V serve as basic components of many of the other standard quantities
the values N , E, and
listed above, obtaining an accurate inference of the former could directly impact our ability to make
accurate inferences on the latter. In the following, we will consider only the inference of the network
size N , but we are now developing a similar formalism in order to extend our analysis to the number
of edges E.

NT traceroute paths.

{

3.3.2 Inferring N: Estimators of Networks Size

Before proceeding to the construction of estimators for N , it is useful to ﬁrst better understand the
relation between this quantity and known characteristics of the Internet topology.
Since the main property aﬀecting the exploration process is the betweenness centrality, one could
argue that N should be estimated using quantities derived from the betweenness. In particular, the
network’s size is related to the betweenness centrality by the following simple expression [131],

in which

is the average distance between pairs of nodes. This may be rewritten in the form

ℓ
h

i

bi = N (N

ℓ
1)(
h

−

i −

1) ,

i
X

N = 1 +

E[b]
ℓ
h

i −

,

1

(3.28)

(3.29)

where the expectation E[
] is with respect to the distribution of betweenness across nodes in the net-
·
work.
can be estimated quite accurately, since traceroute
In general, the average shortest path length
probes lay on the shortest paths and the corresponding distribution is very peaked. Therefore, the
problem of estimating N is essentially equivalent to that of estimating the average betweenness cen-
trality. From the theoretical analysis in previous sections, we know that traceroute experiments
give a good estimate of degree and betweenness distributions tails, thus we can assume that the form

ℓ
h

i

3.3. NETWORK SPECIES PROBLEM

63

∼

b−β for b >> 1 is suﬃciently accurate, but low betweenness nodes are considerably undersam-
P (b)
pled, preventing us from having a correct quantitative knowledge of the full distribution. Hence, the
undersampling of low-betweenness nodes does aﬀect the average value of the betweenness. Addition-
ally, even if we neglect this problem and divide the expectation in two contributions for low and high
betweenness nodes (E[b] = E1[b] + E2[b]), in order to compute the average betweenness, we should
perform an integral of the type

E2[b]

1
K

≃

bmax

bmin

Z

b1−βdb ,

(3.30)

that has to be handled carefully since the experimental values of β are very close to 2 [131, 31], thus
the integral diverges with the upper cut-oﬀ.
These simple arguments give an idea of the diﬃculty of estimating N from traceroute measurements
and suggest the futility of attempting a parametric approach with current measurement tools and
information. There is still the alternative of a nonparametric approach, in which assumed parametric
distributions are eschewed. We have proposed two estimators for N , using subsampling principles: one
is based on the resampling of the network, the other is a reﬁned estimator based on the “leave-one-out”
principle [112, 208, 238].

Resampling Estimator -

Let us call discovery ratio θ = E[N ∗]/N the average fraction of
nodes discovered. From the mean-ﬁeld theory we have learned that the quantity varies smoothly as
a function of the fraction ρT = NT /N of targets sampled, for a given number NS of sources. We use
this fact, paired with the assumption of a type of scaling relation on G, to construct an estimator for
N .
Speciﬁcally, let H be an arbitrary subgraph, of size N (H), of the network graph G. We will as-
sume that, for roughly similar numbers NS(H) and NS(G) of sources used, the discovery ratios for
traceroute sampling on H and G are such that

(i) they vary as smooth functions θ(H; ρT (H)) and θ(G; ρT (G)) of ρT (H) and ρT (G), respectively;

(ii) if ρT (H) = ρT (G), then θ(H; ρT (H)) = θ(G; ρT (G)).

In other words, we expect similar proportions of targets to yield similar proportions of discovered
nodes. Our choice to use NS(H) = NS(G) stems from the fact that typical traceroute-driven
studies run from a relatively small number of sources to a much larger set of destinations. Rewriting
the expression θ(H; ρT (H)) = θ(G; ρT (G)) yields the equation

N (G) = N (H) ρ(G, H) , where ρ(G, H) =

(3.31)

E[N ∗(G)]
E[N ∗(H)]

.

Now if H is a known subgraph, N (H) is known as well, and the problem of inferring N = N (G) can
be reduced to one of inferring ρ(G, H). A natural candidate for such a subgraph is the choice H = G∗
i.e., the graph produced by an initial traceroute sampling on G. In this case, N (H) = N ∗.
It remains then to estimate ρ(G, G∗), which must be deﬁned conditional on G∗. In that case, the
expectation in the numerator is simply E[N ∗(G)
G∗] = N ∗. To estimate the other expectation,
E[N ∗(G∗)
G∗], we use a strategy based on the resampling of paths in G∗. In particular, for a given
sampling rate ρ∗
T N ∗ targets on G∗ and create a resampled graph, say
G∗∗, from the corresponding traceroute paths. Let N ∗∗ = N (G∗∗). We do this some number of
B . Then, we estimate E[N ∗(G∗)
times, say B, forming the collection N ∗∗
G∗] by the average
|
¯N ∗∗
r N ∗∗
r .

T = ρT (G∗), we sample N ∗

1 , . . . , N ∗∗

B = (1/B)

T = ρ∗

|

|

P

64

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

Plugging these quantities into the expression for N in Eq. 3.31 we get

ˆNRS = N ∗

N ∗
¯N ∗∗
B

·

(3.32)

T ≈

N ∗/ ¯N ∗∗

T /NT ≈

Leave-One-Out Estimator -

B for the appropriate N ∗

as a resampling-based estimator for N .
Note, however, that its derivation is based upon the premise that ρ∗
T = ρT , and ρT is unknown (i.e.,
since N is unknown). This issue may be addressed by noting that the equations ρT (H) = ρT (G)
and θ(H; ρT (H)) = θ(G; ρT (G)) together imply the equation NT (G)/NT (H) = E[N ∗(G)]/E[N ∗(H)].
With respect to the calculation of ˆNRS, this fact suggests the strategy of iteratively adjusting N ∗
T =
NT (G∗) until the relation NT /N ∗
B holds (Robbins-Monroe algorithm [213]). The value of
T is then substituted into Eq. 3.32 to produce ˆNRS. In practice, one may
¯N ∗∗
increase B as the algorithm approaches the condition N ∗

¯N ∗∗/N ∗.
Various other subsampling paradigms might be used to con-
struct an estimator. A popular one is the ‘leave-one-out’ strategy, which amounts to subsampling G∗
with N ∗
1. We apply such a principle to the problem of estimating N , in a way that does
not require the subsampling assumptions in Eq. 3.31.
Recall that

∗ is the set of all vertices discovered by a traceroute study, including the NS sources
. Our approach will be to connect N to the
t1, . . . , tNT }
S
frequency with which individual targets tj are included in traces from the sources in S to the other
∗
targets in
i,j be the set of vertices discovered on the path from source si
to target tj, inclusive of si and tj. Then the set of vertices discovered as a result of targets other
to be
than a given tj can be represented as
the indicator of the event that target tj is not ‘discovered’ by traces to any other target. The total
number of such targets is X =
We derive a relation between X and N . Assuming a random sampling model for selection of source
and target nodes from

∗
i,j′ . Next deﬁne δj = I

V
s1, . . . , sNS }

and the NT targets

P
, we have

T = NT −

. Accordingly, let

∪i ∪j′6=j V

∗
(−j) =

T \ {

∗
(−j)

tj}

j δj.

tj /

∈ V

=

=

n

o

V

V

T

{

{

V

Pr

δj = 1

∗
(−j)

=

| V

N

(cid:16)

(cid:17)

N ∗
N
−
NS −

−

(−j)
NT + 1

,

where N ∗

(−j) =
denote this quantity by E

∗
(−j)

V

. Note that, by symmetry, the expectation E
(cid:12)
(cid:12)
(cid:12)

. As a result, we may write

N ∗

(−)

h

(cid:12)
(cid:12)
(cid:12)

N ∗

(−j)

i

is the same for all j: we

which may be rewritten as

h

i

E[X] =

j
X

N

E

N ∗

N

−
h
NS −

−

(−j)
NT + 1

i

=

NT

N

E

N
−
NS −

(cid:16)
−

N ∗

(−)
i(cid:17)
h
NT + 1

,

NT E

N ∗

(−)

N =

h

(NS + NT −
E[X]

−
i
NT −

1)E[X]

.

(3.33)

(3.34)

(3.35)

and E[X], for
To obtain an estimator for N from this expression it is necessary to estimate E
which it is natural to use the unbiased estimators ¯N ∗
(−j) and X itself, measured
i
during the traceroute study. However, while substitution of these quantities in the numerator of
Eq. 3.35 is ﬁne, substitution of X for E[X] in the denominator can be problematic in the event that
X = NT . Indeed, the estimator of N diverges when none of the targets tj are discovered by traces to
other targets, that is possible if ρT = NT /N is small. A better strategy is to estimate the quantity

(−) = (1/NT )

j N ∗

N ∗

P

(−)

h

3.3. NETWORK SPECIES PROBLEM

65

X) directly. We assume that the overlap between diﬀerent sampled set of vertices is very
1/(NT −
X).
high. Using this condition, it is possible to derive an approximately unbiased estimator of 1/(NT −
(Note that empirical data on the Internet collected by the Skitter project at CAIDA [62] show that
the discovery rate is rather uniform, validating our assumption.) The same overlapping argument
implies that N ∗
(−) by N ∗. Putting together all
these quantities in Eq. 3.35, and with a bit of algebra (see Ref. [242] for a detailed derivation) we get

N ∗, for all j, which suggests replacement of ¯N ∗

(−j) ≈

ˆNL1O ≈

(NS + NT ) +

N ∗

(NS + NT )
−
w∗
1

,

−

(3.36)

where w∗ = X/(NT + 1), X being the number of targets not discovered by traces to any other target.
In other words, ˆNL1O can be seen as counting the NS + NT vertices in
separately, and then
taking the remaining N ∗
(NS +NT ) nodes that were ‘discovered’ by traces and adjusting that number
w∗)−1. This form is in fact analogous to that of a classical method in the
upward by a factor of (1
literature on species problems, due to Good [134], in which the observed number of species is adjusted
upwards by a similar factor that attempts to estimate the proportion of the overall population for
which no members of species were observed.

−
−

S ∪ T

3.3.3 Numerical Results

We have tested the performances of the estimators on three diﬀerent types of networks, two computer-
generated networks, with homogeneous (ER model) and heterogeneous (BA model) degree distribu-
tion, and a network based on measurements of the real Internet (Mercator mapping project [135]).
For the synthetic networks, we have considered average degree 6, and sizes ranging from 103 to 106
nodes. The Mercator network (N = 228263 nodes and E = 320149 edges) has been used to see if
more realistic topologies give results in agreement with that from the models.

We plot in Fig. 3.16 the ratio of the estimators to the true size, ˆNRS/N , and ˆNL1O/N , together
with N ∗/N , for the various investigated graphs, number of sources NS = 1, 10, and 100, as a function
of the target density ρT . The improvement with respect to the “trivial” estimation by the size N ∗
of the sampled graph is impressive, the optimal value being 1 for all these curves. Increasing either
the number of sources NS or density of targets ρT yields better results, even for N ∗, but the esti-
mators we have introduced converge much faster than N ∗ towards values close to the true size N .
In fact, a relatively small number of sources and targets is suﬃcient for these estimators to perform
very accurately, in particular, in the case of the “leave-one-out” estimator. Note, however, that the
“leave-one-out” estimator has a larger variability at small values of ρT , while that of the resampling
estimator is fairly constant throughout. This is because in calculating ˆNRS the uncertainty scales in
the same way both in the sampling and in resampling, whereas for ˆNL1O the uncertainty scales with
ρT that changes passing from sampling to resampling.

In terms of topology, the estimation of N appears to be easiest for the ER model. Even N ∗ is
more accurate, i.e. the discovery rate is higher. The estimation for the Mercator graph seems to be
the hardest, possibly because it is the graph with the largest fraction of low degree (and thus low
betweenness) nodes among the three studied. It is worthy noting that the “leave-one-out” estimation
seems to depend only on N ∗/N and NT , thus being quite stable in the three graphs.
Interestingly, the estimators perform better for larger sizes, as shown by Fig. 3.17, in which we investi-
gate, at ﬁxed NS and ρT , the eﬀect of the real size of the graph N . On the contrary, N ∗/N decreases.
This is due to the fact that the sample graph G∗ gets bigger providing more and richer information,
even if the discovery ratio does not grow. The odd nature of the results for the BA graph comes from

66

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

BA

ER

Mercator

2
1.6
1.2
0.8
0.4

1.6
1.2
0.8
0.4

1.6
1.2
0.8
0.4
0
10

-3

-2

10

-1

10

ρ

T

-2

10

-1

10

ρ

T

-2

10

-1

10

ρ

T

Figure 3.16: Comparison of the various estimators for the BA (top), ER (middle) and Mercator
(bottom) networks. The curves show the ratios of the various estimators to the true network size, as
a function of the target density ρT . Full circles: ˆNL1O/N ; Empty squares: ˆNRS/N ; Stars: N ∗/N .
The errorbars go from the 10% to the 90% percentiles. Left ﬁgures: NS = 1 source; Middle: NS = 10
sources; Right: NS = 100 sources

the peak associated with the resampling estimator, see Fig. 3.16. At ﬁxed number of targets however,
ˆNRS/N and ˆNL1O/N decrease as N increases (not shown, see Ref. [242]).
The comparison of the two estimators show that the resampling estimator, although yielding a clear
improvement with respect to N ∗, systematically performs less well. This is probably due to the fact
that the basic hypothesis of scaling (Eq. 3.31) is only approximately satisﬁed, while for ˆNL1O the
underlying hypotheses are well satisﬁed. Nonetheless, the resampling estimator needs less information
on the graph than ˆNL1O, since the “leave-one-out” estimator uses the knowledge that some targets
are not discovered by the paths to other targets.
Of course, in order to apply this inference model to the Internet one should take into account further
issues, as the eﬀects of non-random deployment of sources or the relation with more realistic models
of traceroute exploration. However, the “leave-one-out” estimator should not suﬀer much in perfor-
mance, since its derivation assumes only uniform random choice of targets, not that of sources and
does not make any assumption on the routing strategy.
Finally, we provide a phenomenological validation of our technique. The Internet size can also be
estimated using other techniques, for instance with ping probes in order to test the response of some
suﬃcient number of randomly chosen IP addresses (the total number of possible IP addresses is 232).
Computing the fraction ˆa of ‘alive’ addresses, we get the estimator ˆNping = 232ˆa for the size of the
Internet.
In order to check if the “leave-one-out” estimator gives results in agreement with the latter one, we
106 ping’s probing of the net, obtaining 61246 valid responses and, in parallel,
performed about 3.7
a traceroute study from the same source towards the same number of unique IP addresses. The

·

3.3. NETWORK SPECIES PROBLEM

67

BA

ER

1.5

2

1

0.5

1.5

1

0.5

3
10

4
10

5
10

N

4
10

5
10

N

4
10

5
10

6
10

N

Figure 3.17: Eﬀect of the size N of the graph G for BA and ER graphs at constant number of sources
and density of targets. The curves show the ratios of the various estimators to the true network size,
as a function of the graph size N . Full circles: ˆNL1O/N ; Empty squares: ˆNRS/N ; Stars: N ∗/N .
The errorbars go from the 10% to the 90% percentiles. NS = 10. Left ﬁgures: ρT = 10−3; Middle:
ρT = 10−2; Right: ρT = 10−1.

estimated size was ˆNping = 7, 06
107 using the
“leave-one-out” estimator, conﬁrming a good agreement between the two. Note that the numbers are
not intended to taken too seriously (we used only one source, toward a small number of targets), but
it is important that they give consistent results.

107 using the ping estimator, and ˆNping = 7, 23

·

·

68

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

3.4 Conclusions

In contrast with usual physical disciplines, the science of complex networks is characterized by the
absence of ﬁrst principles from which a theoretical framework can be deduced; for this reason, a very
actual and urgent problem is that of testing the reliability of phenomenological data, on which the
whole theoretical analysis and modeling of networks is based. The ﬁrst step in this direction is that of
assessing the validity of the peculiar topological properties observed in so many real networks, from
biological to social and technological ones. This means that we need an accurate description of the
sampling processes by which data are collected.
In this chapter, we have highlighted the main features of diﬀerent mechanisms of sampling that are
involved in the experimental analysis of networks. In some cases, such as for biological and social
networks, sampling methods may suﬀer of strong biases that are often unpredictable, because of
the incomplete knowledge of all (hidden) processes involved in the experiments. In the case of the
Internet, instead, there exists a well-known and very useful practical method to extract information
from the network, that consists in the dynamical exploration by means of traceroute-like probes.
Unfortunately, also this method suﬀers of biases that could in principle cause a misrepresentation of
the topological properties of the network, in particular of the degree distribution.
By means of a mean-ﬁeld statistical approach, we have provided an insight into the relation between
sampling biases and topological properties of the network, showing that the eﬃciency and accuracy
of the exploration process depend mainly on the betweenness centrality distribution of the underlying
network. The other important parameters are the densities of sources and targets deployed in the
system, or more simply, the probing eﬀort, i.e. the number of probes used in the exploration. In
particular, we have explained how the observed distortions of the degree distribution are actually
possible only when the underlying network is homogeneous and the traceroute process is performed
using very few sources. Moreover, in order to observe power-laws starting from homogeneous networks,
the average degree of the original network must be of the same order as the power-law cut-oﬀ, a rather
unlikely situation for any real technological network (in particular for the Internet at the AS level).
Our results provide a strong evidence that in order to observe a power-law distribution, we need at
the origin a broad distribution, but show as well that networks with other heterogeneous distributions,
diﬀerent from power-laws, can be seen as scale-free networks under sampling. With a low number of
sources and targets, as that involved in outdated Internet mapping projects, we cannot completely
exclude the possibility that the degree distribution of the real network has the shape of a Weibull
distribution rather than of a stretched exponential. According to our analysis, in case of heterogeneous
networks with a non power-law degree distribution, an increase of both source and target densities
should make visible departures from it.
In agreement with our conclusion on the necessity of increasing the number of sources used in the
Internet mapping projects in order to get more accurate data, it has been recently developed a
distributed mapping project called DIMES (Distributed Internet MEasurements & Simulations) [98,
224], with the aim of studying the structure and topology of the Internet using a very large number
of sources. The idea is that of involving in the measurements common Internet users, creating a
volunteer community that sends traceroute-like probes throughout the Net. Preliminary results
from the DIMES project conﬁrm the power-law shape for the degree distribution. The fact that
DIMES is observing power-laws seems to be the ultimate evidence of the genuine nature of scale-free
topologies in the Internet. Nonetheless, it is still very likely that the real exponent is diﬀerent from
(i.e. larger than) the observed one.
In conclusion, the main improvement upon this ﬁeld due to the results obtained in this thesis are

3.4. CONCLUSIONS

69

summarized in the following points:

•

•

•

•

•

We have identiﬁed, at a mean-ﬁeld level, the relations between observed properties of the sampled
networks and the topological properties of the underlying network.

The origin of sampling biases in the Internet measurements has been uncovered. These prop-
erties, together with a minimal set of external parameters (the density of sources and targets)
govern the eﬃciency and accuracy of the sampling process.

Tuning the external parameters we have provided some results that should serve as a guidance
for more realistic optimization strategies.

The eﬀects of traceroute explorations on local and non-local structures have been analyzed.

The traceroute-like explorations can be translated in the framework of statistical species prob-
lems, leading to the formulation of non-parametric statistical approaches for the inference of
Internet’s global properties. As an example of the validity of this method to correct the biases
introduced by the sampling process, we have introduced unbiased estimators of the number of
nodes in the network, that can be applied to the case of the Internet, the real size of which is
still unknown.

70

CHAPTER 3. EXPLORATION OF COMPLEX NETWORKS

Chapter 4

Spreading and Vulnerability in
Complex Networks

4.1

Introduction

A second topic that has been object of investigation in this thesis concerns the role played by some
topological and dynamical properties in determining the functionality of weighted networks. In partic-
ular, we focus on the analysis of vulnerability and spreading properties. The motivations for this type
of analysis, coming from the observation of the functional properties of real infrastructure networks,
are exposed in Section 4.1.1; while in Section 4.1.2, we introduce the main idea of the chapter, con-
sisting in the possibility of linking two apparently diﬀerent subjects as vulnerability and spreading by
means of percolation-like approaches. Then, in Section 4.2, we focus on the vulnerability of weighted
networks, taking into account the case study of the airports network. In Section 4.3, we propose a
theoretical framework for the study of spreading phenomena in weighted networks, using the methods
of percolation theory.

4.1.1 Motivations

From a practical point of view, an accurate knowledge of structural and dynamical properties of net-
works is of primary interest, particularly in the case of technological networks, that form the backbone
of world-wide communication and transportation infrastructures. On the other hand, such networks
are intrinsically weighted networks, so that neglecting weights could lead to wrong conclusions about
these properties. As mentioned in Chapter 1, weights are usually related to dynamics: in some cases
they give just a measure of the traﬃc on the edges, in other cases they pinpoint the diﬀerent attitude
of the edges in exchanging physical quantities (energy, information, goods, etc).
From the point of view of a single dynamical process evolving on a network (e.g. a spreading pro-
cess), the introduction of weights on the edges corresponds, using a pictorial representation, to add
an energy-like variable to the system and look at it as it was in an energy landscape. In this scenario,
some paths with larger weights (or smaller, it depends on weight’s deﬁnition) will be dynamically more
convenient than others, and thus they will be preferentially chosen in the spreading. In addition, as
the trajectory of a particle in a potential is deformed when we change the shape of the potential, ﬂuxes
on weighted networks adjust themselves in order to follow variations of both topology and weights.
In other words, the presence of weights on the edges tunes the functionality of the system towards an

71

72

CHAPTER 4. SPREADING AND VULNERABILITY

optimal point. This picture suggests us the idea of technological networks as critical infrastructures,
whose topological, dynamical and functional properties are intimately related.
The motivations of our research in the ﬁeld of weighted networks can be summarized in the following
issues:

•

•

Which are the levels of structural and functional stability of such critical structures if we perturb
it in diﬀerent ways?

Which are the conditions for a macroscopic spreading? Which is the relation with the functional
properties of the network?

Both our queries are concerned with the prediction of extreme events such as that of a global collapse
triggered by the spreading of a virus, a cascade failure or malicious attacks, and with the necessity
to protect real networks, ensuring their functioning. Nevertheless, the two arguments are developed
separately.
We will ﬁrst study the vulnerability properties of weighted graphs, showing that structural robustness
does not coincide with functional robustness if traﬃc is taken into account. The analysis is carried out
by means of a relevant case study, where practical implications are visible: the airports network. The
weighted representation is, furthermore, general enough to include other contributions, not strictly
due to the traﬃc. For instance, infrastructure networks are embedded in the real space, with euclidean
distances between nodes, and longer connections have higher costs. It is thus possible to verify the
role played by all these quantities in determining the functional integrity of the system.
We will then turn to consider the conditions for observing macroscopic spreading phenomena in the
context of weighted networks, keeping in mind the previous results about the functional properties of
infrastructure networks. We provide a general theory for spreading phenomena in weighted networks.
Some analytical results are presented in the case of (correlated) generalized random graphs, for which
we derive a very general criterion for the percolation threshold, that governs the spreading properties
of many dynamical phenomena (see Appendix B).
In order to have a unitary view of these two topics, we can actually consider the idea of the existence of
diﬀerent scales for the dynamics that we have mentioned as an introductory argument in Chapter 1:
a slower timescale governs the evolution of the average traﬃc (i.e. the weights), and a faster one
characterizes single spreading processes (and thus also the perturbations to the average quantities).
When a cascade failure, a congestion phenomenon, or a disease pops out producing a perturbation of
the normal functioning of the network, the underlying weighted structure appears as a ﬁxed landscape,
whose (weighted) properties can decisively inﬂuence the global eﬀect of such a perturbation (e.g. the
occurrence of a traﬃc collapse, a pandemic state, etc). The advantage of using quenched weighted
networks is related to the possibility of describing dynamical phenomena as well as vulnerability easily
using percolation-like approaches.

4.1.2 Relation between percolation, vulnerability and spreading

Percolation theory has been largely used in statistical mechanics in order to describe topological phase
transitions in lattice systems, such as the emergence of global properties when some physical param-
eter (temperature, concentration, etc) exceeds a critical value [228, 118, 59, 156]. More precisely, a
site percolation process can be sketched as follows. Each site of the lattice is occupied with a uniform
probability q, called occupation probability, and empty with probability 1
q. A cluster is a con-
nected set of occupied sites. When the value q of the occupation probability is larger than a critical

−

4.1.

INTRODUCTION

73

Figure 4.1: Illustration of the relation between percolation, vulnerability and spreading processes. As
a result of percolation (left), the nodes of the original graph are divided into occupied (blue) and
unoccupied (red) nodes. On the right: the correspondence between node removal (top) or spreading
(bottom). On average, the subgraph induced by occupied nodes (black nodes in the top ﬁgure)
coincides with that covered by spreading (blue nodes in the bottom ﬁgure).

value qc, the percolation threshold, a cluster with size of the same order of the system, i.e.
inﬁnite
in the thermodynamic limit, appears. Analogously, the process can be deﬁned on the bonds joining
neighboring sites, with the only diﬀerence that the site occupation probability q is replaced by a bond
occupation probability. The bond percolation corresponds to the site percolation on the conjugate
lattice (obtained exchanging bonds with sites and viceversa), and gives similar results.
Recently, percolation theory has been successfully introduced in the ﬁeld of complex networks, with
some seminal works on undirected uncorrelated random graphs [65, 80, 79]. A number of other works
followed, studying the cases of correlated [189, 190, 240, 64] and directed [108, 220, 46] random graphs.
Percolation is intrinsically related to vulnerability. The process of random removal of a fraction g of
nodes can be seen as a percolation process in which the occupation probability of the nodes is reduced
g. Actually, we can exactly map a random removal of nodes on a site percolation problem, with
to 1
−
q and the same order parameter (i.e. the relative size of the giant component, or topological
g = 1
qc above which the
integrity). Percolation theory predicts the presence of a threshold value gc = 1
giant component
Gc disappears, i.e. the network is fragmented in many disconnected components of
(log N )) with respect to the total number N of vertices in the graph.
very small sizes (Ng ∼ O
The notion of percolation has then found applications in the context of spreading phenomena on
networks, such as epidemic models [182, 183, 188]: for some of them, the connection with the per-
colation is a longtime topic (see for example [124, 138, 244, 217]), while for other models, more
rigorous descriptions, based on the analysis of population equations of epidemiology, are required
[173, 201, 202, 44, 184, 185, 201, 202, 45, 43]. The models of epidemic spreading solved using perco-

−

−

74

CHAPTER 4. SPREADING AND VULNERABILITY

lation theory identify vertices with individuals and edges as pairwise contacts between them [188]. In
this context, the existence of a giant component means that we can reach a large (inﬁnite) number of
other nodes of the same graph starting by one of them and moving along the edges. The spreading
process takes place on the edges, that have a ﬁxed probability to be disease-causing contacts, called
transmissibility. The model’s behavior is easily determined using edge percolation, that establishes
the presence of a giant component as function of the value of transmissibility, and states the possibility
for global epidemic outbreaks. Figure 4.1 illustrates the relation between percolation, vulnerability
and spreading processes. In Ref. [84], we have extended the analogy between spreading processes and
percolation to a very general situation in which node and edge inhomogeneity is considered. Part of
the analysis is reported in Appendices A-B. As a special case of such inhomogeneous percolation, in
Section 4.3, we expose some results that are useful to study spreading processes on weighted networks.

4.2. VULNERABILITY OF WEIGHTED NETWORKS: A CASE STUDY

75

4.2 Vulnerability of Weighted Networks: a case study

Recent studies on phenomenological data of real weighted networks (communication and infrastructure
networks, scientiﬁc collaboration networks, metabolic networks, etc) have given much attention to the
relation between weighted properties and topological quantities [23, 6, 171]. The most striking result
concerns the existence of non-trivial correlation between weights and topology, corroborating the idea
that topological and weighted properties are mutually inﬂuenced, and both take part into the evolution
process of real weighted networks.
Several groups have proposed models of evolving weighted networks [24, 26, 27, 39, 107, 243]; we will
consider only one of them, the spatial BBV model, that has been described in Section 2.4.3.
In the present section, we face the issue of deﬁning and determining the vulnerability of weighted
networks. It is ﬁrstly a problem of deﬁnition, since in many real networks, together with the topological
connectivity there are also weighted properties, that are usually related with the functionality of the
network.
From a topological point of view, the only relevant measure of the vulnerability of a network is the
size Ng of the giant component after the removal of a fraction g of the nodes. If we compare this size
with the original size N0 of the network’s giant component, we have an estimate of the vulnerability
of the network under node (or edge) removal.
Using the already mentioned analogy with percolation, it has been shown that, in contrast with
regular lattices and homogeneous random graphs, heavy-tailed networks can tolerate very high levels
of random failure, without falling into pieces [80, 65]. On the other hand, malicious attacks to the
hubs can easily break the entire network into small components, providing a clear identiﬁcation of the
elements which need the highest level of protection against such attacks [5, 201].
In order to extend the vulnerability analysis to weighted complex networks, we have investigated how
the introduction of traﬃc and spatial properties may alter or conﬁrm the above ﬁndings. In particular,
in Ref. [89], we address three main questions:

(i) on the basis of which measures a weighted network is most eﬃciently protected from damage;

(ii) how traﬃc and spatial constraints inﬂuence the system’s robustness;

(iii) how to measure the damage (diﬀerent integrity measures).

The ﬁrst step in order to face these issues consists in proposing a series of topological and weight-
dependent centrality measures that can be used to identify the most important vertices of a weighted
network. The functional integrity of the whole network depends on the protection of these central
nodes, as we will show applying these considerations to the World-wide Air-transportation Network.
The main result is that under malicious attacks, weighted networks turn out to be more vulnerable
than expected, in that the traﬃc integrity is destroyed when the topological integrity of the network is
still very high.

4.2.1 Weighted centrality measures

We introduce a series of weighted centrality measures, that will be used to deﬁne attack strategies
of node removal on the network. Since we consider the case of technological networks, such as the
airport network, we focus on weighted centrality measures based on traﬃc and spatial properties. The
presence of non-trivial correlations between the diﬀerent centrality measures reveals that all of them
should be considered in order to give an exhaustive description of weighted network’s structural and

76

CHAPTER 4. SPREADING AND VULNERABILITY

functional properties.

Measures deﬁnition -
The centrality of nodes can be quantiﬁed by various measures, the most
intuitive of which is certainly the degree. The natural generalization of the degree to a weighted graph
is given by the strength of vertices si (see Section 2.2.6 for deﬁnitions), that in the case of the air-
transportation network quantiﬁes the traﬃc of passengers handled by the airport i. The corresponding
geographical notion is the distance strength Di, that we deﬁned as

Xj∈V(i)
where dij is the Euclidean distance between i and j, and quantiﬁes how long are the connections
supported by an airport. Another interesting deﬁnition is given by mixing the two ingredients; the
outreach

Di =

dij ,

Oi =

wij dij ,

(4.1)

(4.2)

Xj∈V(i)
measures the total distance traveled by passengers from the airport i and is possibly related to the
total cost of connections.
In general, non-local eﬀects are taken into account introducing the betweenness centrality (see Sec-
tion 2.2.4), that identiﬁes crucial nodes which may have small degree or strength but act as bridges
between diﬀerent parts of the network. In weighted networks, it seems natural to generalize the no-
tion of betweenness centrality through a weighted betweenness centrality in which shortest paths are
replaced with their weighted versions. As already anticipated in Section 2.2.6, a straightforward way
to generalize the hop distance in a weighted graph consists in assigning to each edge (i, j) a length lij
that is a function of the characteristics of the link. In our case, both the weight wij and the Euclidean
distance dij between airports i and j are reasonable quantities. A quite natural assumption is that the
eﬀective distance between two linked nodes should be a decreasing function of the weight of the link.
Indeed, larger ﬂows (traﬃc) correspond to more frequent and faster exchange of physical quantities
(e.g. information, people, goods, energy, etc). Moreover, when spatial embedding is considered, the
edge length must be directly proportional to the geographical distance. In other words, we deﬁne the
length lij of an edge (i, j) as

lij =

dij
wij

.

(4.3)

The deﬁnition of weighted betweenness centrality follows straightforwardly.
According to this deﬁnition, the centrality of a node provides a trade-oﬀ between the idea of the topo-
logical “bridge” connecting diﬀerent parts of a network, and the requirement of carrying a suﬃcient
level of traﬃc.

∼

kβO , with βO ≈

Centrality Measures Correlation -
On the World-wide Air-transportation Network, all the
proposed measures of centrality are broadly distributed, and they are on average non-trivially corre-
1.5 [27], and
lated one with the other, and in particular with the degree (e.g. D(k)
O(k)
Vertices with large degree have also typically large strength and betweenness, but under a detailed
analysis, we observe that deviations are possible. This fact has been already noted in Refs.[141, 27],
where it is stressed that the most connected airports do not necessarily have the largest betweenness
centrality.
Here, we observe a similar eﬀect about the relation between topological and weighted measures. For

kβD with βD ≈

1.8 [89]).

∼

4.2. VULNERABILITY OF WEIGHTED NETWORKS: A CASE STUDY

77

Strength

Atlanta

Rank

Degree

Betweenness

Outreach

W. Betweenness

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

Frankfurt

Frankfurt

London-LHR

London-LHR

Paris-CDG

Paris-CDG

Chicago-ORD

L.Angeles-LAX

L.Angeles-LAX

Munich

Anchorage

London-LHR

Tokyo-HND

Singapore

Amsterdam

Tokyo-HND

Tokyo-HND

Frankfurt

New-York-JFK

Atlanta

Port Moresby

L.Angeles-LAX

Paris-CDG

Miami-MIA

London-LHR

London-LHR

Dallas-DFW

Chicago-ORD

Tokyo-HND

Chicago-ORD L.Angeles-LAX

Paris-CDG

New-York-JFK

Hong-Kong

Duesseldorf

Singapore

Frankfurt

Singapore

Sydney

Vienna

Brussels

Vancouver

Bangkok

Phoenix

Denver

San Francisco

Chicago-ORD

Atlanta

Paris-CDG

Dallas-DFW Johannesburg

Hong Kong

Hong-Kong

Houston-IAH

Toronto-YYZ

Detroit-DTW

Bangkok

Rome-FCO

Amsterdam

Minneapolis-MSP

Amsterdam

Seattle

Atlanta

Dubai

Minneapolis

Seoul-ICN

Dallas-DFW

Frankfurt

Zurich

Hong Kong

New-York-EWR

Brisbane

Madrid

Houston

Table 4.1: Ranking of the ﬁfteen world’s top airports for diﬀerent centrality measures: degree, topo-
logical betweenness, strength, outreach and weighted betweenness. Note that the lists report diﬀerent
single airports, not just the total data relative to the cities; for cities with more than one airport, the
acronym of the corresponding one is indicated.

instance, the scatter plot of the weighted betweenness vs. topological betweenness (not shown) shows
that departures from a perfect correlation are not that rare. Let us consider the list of Top 15 airports
according to diﬀerent measures of centrality (Table 4.1): strikingly, each deﬁnition provides a diﬀerent
ranking. In addition, some airports which are very central according to a given deﬁnition, become
peripheral according to another criteria. For example, Anchorage has a large betweenness centrality
but ranks only 138th and 147th in terms of degree and strength, respectively. Similarly, Phoenix or
Detroit have large strength but low ranks (> 40) in terms of degree and betweenness.
A quantitative analysis of the correlations between two rankings of n objects can be done using rank
correlations such as Kendall’s τ [154, 207]

τ =

nc −
n(n
−

nd
1)/2

(4.4)

where nc is the number of pairs whose order does not change in the two diﬀerent lists and nd is the
1 and 1: τ = 1 corre-
number of pairs whose order is inverted. This quantity is normalized between
sponds to identical ranking while τ = 0 is the average for two uncorrelated rankings and τ =
1 is a
perfect anticorrelation. Table 4.2 gives the values of τ for all possible pairs of centrality rankings. For
10−2 so that even the smallest observed
N = 3, 880, two random rankings yield a typical value of
τ = 0.21 is the sign of a strong correlation (All the values in this table were already attained for a
sublist of only the ﬁrst n most central nodes, with n
500). Remarkably enough, there is a strong
correlation even between local and non-local quantities (degree vs. betweenness), but the weighted
quantities seem to have a lower level of correlation with the topological ones.

≈

−

±

−

Another important aspect concerns the geographical relation between centrality measures. Indeed,

78

CHAPTER 4. SPREADING AND VULNERABILITY

Figure 4.2: Geographical distribution of the world’s 15 most central airports ranked according to
diﬀerent centrality measures.

they are non homogeneously distributed in diﬀerent geographical regions, providing a further precious
hint to understand the functioning of infrastructure networks such as the WAN. Figure 4.2 displays
the geographical distribution of the world’s ﬁfteen most central airports ranked according to diﬀerent
centrality measures. On the one hand, it is clear that topological measures miss the economic dimen-
sion of the WAN, while weighted measures reﬂect traﬃc and economic realities.
European airports are very well connected but the core of the traﬃc is North America, where we
ﬁnd the peaks of strength and outreach. Betweenness based measures on the other hand pinpoint the
most important nodes in each geographical zone. In particular, the weighted betweenness appears as
a balanced measure which combines traﬃc importance with topological centrality, leading to a more
uniform geographical distribution of the most important nodes.

4.2.2 Vulnerability of the WAN

The analysis of complex networks robustness has been largely investigated in the case of unweighted
networks [5, 80, 65, 144], focusing on the topological integrity of the network Ng/N0. When, increasing
(1), the entire network has been destroyed. We say that the attack strategy is
g, we reach Ng ≃ O
“driven” by a property of the network, if the order in which the nodes are one-by-one removed
corresponds to the ranking list according to that property. On heterogeneous networks, a degree-

Degree k
Distance strength D
Strength s
Outreach O
Betweenness BC
Weighted BC

k
1
0.7
0.58
0.584
0.63
0.39

D
0.7
1
0.56
0.68
0.48
0.23

s
0.58
0.56
1
0.83
0.404
0.24

O
0.584
0.68
0.83
1
0.404
0.21

BC W BC
0.39
0.63
0.23
0.48
0.24
0.404
0.21
0.404
0.566
1
1
0.566

Table 4.2: Similarity between the various rankings as measured by Kendall’s τ . For random rankings
of N values, the typical τ is of order 10−2.

4.2. VULNERABILITY OF WEIGHTED NETWORKS: A CASE STUDY

79

0

N

/

N

g

1

0.8

0.6

0.4

0.2

0
0
1

0.8

0.2

0
0

)
g
(

O

I

0.6

0.4

0.04

0.08

0.04

g

0.12

k
s
O
D
BC
WBC

0.08

Figure 4.3: Eﬀect of diﬀerent attack strategies on the size of the connected giant component (top) and
the outreach integrity (bottom). The attack strategies consist in removing nodes in order of: degree
(black circles), strength (red squares), outreach (green diamonds), distance strength (blue triangles),
betweenness (magenta crosses) and weighted betweenness (orange stars).

driven damage strategy (i.e. nodes are removed in order of degree, starting from the maximum one) is
extremely eﬀective, leading to the total fragmentation of the network at very low values of g [80, 65, 5],
but the removal of the nodes with largest betweenness typically leads to an even faster destruction of
the network [144].
In the case of weighted networks, we consider additional quantities related to the functionality of the
network, such as the largest traﬃc or strength still carried by a connected component of the network.
In Ref. [89], we have deﬁned three new measures of network’s damage

,

Is(g) = Sg
S0
D0 =
Sg = maxH
P

IO(g) = Og
O0

,

ID(g) = Dg
D0

,

(4.5)

P

P

P

P

S0 =

O0 =

i Oi and

Dg = maxH

Og = maxH

where
i Si,
i Di are the total strength, outreach and distance strength
i∈H Di
i∈H Oi and
i∈H Si,
in the undamaged network and
correspond to the largest strength, outreach or distance strength carried by any connected component
H in the network, after the removal of a density g of nodes. These quantities measure the integrity
of the network with respect to either strength, outreach or distance strength, since they refer to the
relative traﬃc or ﬂow that is still handled in the largest operating component of the network.
Under random damage, all the integrity measures behave similarly to the simple topological case, i.e.
weighted networks are inherently resilient to random damages. This result is in agreement with the
theoretical prediction of the absence of a percolation threshold in highly heterogeneous graphs [80, 65],
but it is not completely expected in weighted graphs. The scenario corresponding to the damage of
the most central nodes in the network is very diﬀerent and depends on the strategy considered. We
have eliminated nodes (and corresponding links) according to their rank in terms of degree, strength,
outreach, distance strength, topological betweenness, and weighted betweenness. In Fig. 4.3 we report
the behavior of Ng/N0 and of the outreach integrity IO(g) for all cases (the other integrities giving
similar results). As expected, all strategies lead to a rapid breakdown of the network with a very

P

80

CHAPTER 4. SPREADING AND VULNERABILITY

Africa
Asia
Europe
Latin Am
North Am
Oceania

0

N

/

N

g

1

0.8

0.6

0.4

0.2

0.8

)
g
(

O

I

0.6

0.4

0.2

0

0

0.8
0.6
0.4
0.2
0

0

g

0.02

0.02

0.04

0.06

0.08

0.1

0.12

0.14

Figure 4.4: Geographical eﬀect of the removal of nodes with largest strength. The integrity decreases
strongly in regions such as North-America, while a “delay” is observed for the zones with smaller
initial outreach or strength.

small fraction of removed nodes. The structural integrity of a network is principally due to strategic
points such as bridges and bottle-neck structures; as evidenced by the fact that the size of the giant
component decreases faster using non-local measures of centrality (i.e. betweenness) instead of local
ones (i.e. degree, strength). In Ref. [144], it was already shown that the betweenness is the most
eﬀective quantity in order to pinpoint such nodes.
However, the eﬀects are reduced if we take into account weights: some of the important topological
bridges carry a small amount of traﬃc and are therefore part of more shortest paths than weighted
shortest paths. These bridges have therefore a lower rank according to the weighted betweenness.
Note that, among the local quantities, the distance strength is rather eﬀective since it targets nodes
which connect very distant parts of the network.
The picture changes when the attention is shifted to the weighted integrity measures. In this case,
all strategies achieve the same level of damage, and their decrease is even faster than for topological
quantities. In other words, the functionality of the network can be temporarily jeopardized in terms
of traﬃc even if the physical structure is still globally well-connected. This implies that weighted
networks appear more fragile than expected by considering only topological properties. All targeted
strategies are very eﬀective in dramatically damaging the network, reaching the complete destruction
at a very small threshold value of the fraction of removed nodes.
Finally, we consider the role of the spatial constraints. As shown in Fig. 4.2, various geographical
zones contain diﬀerent numbers of central airports. The immediate consequence is that the diﬀerent
strategies for node removal have diﬀerent impacts in diﬀerent geographical areas. Figure 4.4 displays
the case of a removal of nodes according to their strength (other removal strategies lead to similar
data), monitoring topological and outreach integrity. Each geographical zones is more sensitive to
a particular removal strategy, leading to the idea that large weighted networks can be composed by
diﬀerent subgraphs with very diﬀerent traﬃc structure and thus diﬀerent responses to attacks.

4.2. VULNERABILITY OF WEIGHTED NETWORKS: A CASE STUDY

81

1

0.8

0.6

0.2

0

N

 
/
 

N

g

0.4

0.8

0.6

)
g
(

I

s

0.4

0

0

1

0.2

0

0

k
s
BC
WBC

k
s
BC
WBC

1

0.8

0.6

0.2

0

N

 
/
 

N

g

0.4

0.8

0.6

)
g
(

I

s

0.4

0

0

1

0.2

0

0

0.05

0.1

0.15

0.2

0.05

0.1

0.15

0.2

0.25

k
s
BC
WBC

k
s
BC
WBC

0.05

0.1

g

0.05

0.1

0.15

0.2

0.25

g

Figure 4.5: Vulnerability of a network obtained using the growing model with spatial constraints
exposed in Section 2.4.3 for two values of the parameter controlling the spatial constraints η = 0.5
(left) and η = 0.005 (right). The targeted damage is driven removing nodes in order of: degree
(circles), strength (squares), and topological (crosses) and weighted (triangles) betweenness. The
behaviors of the topological (Ng/N0) and functional (Is(g)) integrities are shown.

4.2.3 Comparison with the spatial BBV model

In Section 2.4.3, we have presented a model of growing weighted networks, proposed in Refs. [24, 25]
and based on the preferential attachment. By means of a strength-driven preferential attachment
(i.e. a sort of “busy-get-busier” principle), the model generates networks with properties that are
observed in many real growing weighted networks, such as the small-world property and power-law
distributed degree, strength and weights. We have already observed that the BBV model pinpoints the
basic mechanisms governing the evolution of the airport network, even if it fails in the existing large
ﬂuctuations between topological and weighted quantities (such as degree vs. strength or topological
betweenness vs. weighted betweenness).
A possible reason for the existence of these non-trivial correlations is the presence of spatial constraints,
i.e. the node of the real networks are embedded in a two-dimensional space. The authors of Ref. [24]
have thus put forward a modiﬁed model, in which spatial constraints are taken into account [27]. The
spatial model shows more realistic correlations, but it does not explain all the features observed in
the real airport network.
In this section, we present some preliminary results on the study of the vulnerability properties of
the model, pointing out the relation with the eﬀects observed for the WAN. In particular, we look at
the role played by spatial constraints, ﬁxing the parameter δ = 1 and varying the typical length scale
of the connections governed by the parameter η. The system is embedded in a square of linear size
L = 1, endowed with euclidean metric structure, so that small values of η (η
1) favor the creation of
”regional” structures with hubs of smaller connectivity than the global hubs obtained in the original
BBV model or in the present model when η assumes larger values. We have considered the two cases
η = 0.5 and η = 0.005.
Figure 4.5 displays the behaviors of the topological and functional integrities under diﬀerent damage
strategies. We have focused only on the main attack strategies, i.e. those driven by removing nodes

≪

82

CHAPTER 4. SPREADING AND VULNERABILITY

in order to degree, strength, betweenness and weighted betweenness.
In this ﬁgure the weighted
betweenness has been computed using the weighted distance ℓij = 1/wij instead of ℓij = dij /wij,
but the qualitative diﬀerences in the resulting vulnerability properties are negligible. (Note that this
is true also for the WAN). Comparing the two ﬁgures for η = 0.5 (left) and η = 0.005 (right), it is
clear that, increasing the spatial constraints, the network becomes more vulnerable to betweenness-
driven attacks. This is due to the fact that the system develops a structure composed of many
regional networks connected by a limited number of links. The links or the nodes that play as bridges
connecting diﬀerent regional networks are very important for the global structural properties of the
system. They are the most central nodes in terms of both topological and weighted betweenness, so
that damaging the network removing high-betweenness nodes reveals the fragility of such a regional
structure. This feature is in agreement with the behavior of Ng/N0 in the real airports network.
In the model, the picture does not change if we look at the functional level, monitoring the decrease of
the functional integrity (in this case we have considered Is(g) = Sg/S0, the other functional integrity
measures show similar behaviors). The two non-local damage strategies are indeed more eﬀective
in destroying the network functionality. This feature is diﬀerent from what we observe in the real
airports network, that shows the same rapid decrease for all the strategies. The diﬀerence is possibly
due to the fact that, in the model, the relation between topology and traﬃc is still too strong, while in
the real WAN, other variables play an important role in separating the traﬃc and economic dimension
from the purely topological one.
In summary, the introduction of spatial constraints in a model of growing weighted networks produces
some structural properties that are in agreement with those observed in a real network such as the
WAN; but an improvement is required in order to pinpoint the correct mechanisms that are at the
origins of those functional properties of real weighted networks that are still not completely understood.

4.2.4 Conclusions

In this study (see Ref. [89]), we have identiﬁed a set of centrality measures for technological weighted
networks, in which two further ingredients, traﬃc and spatial constraints, are included. The main
achievements are summarized in the following points:

•

•

•

•

the various deﬁnitions of centrality are correlated, but lead to diﬀerent descriptions of the im-
portance of the nodes;

the level of vulnerability of a network depends on the global property we have decided to monitor;
in general, the attack strategies that are based on the same property (or similar properties to)
that we are monitoring at a global scale are trivially more eﬀective;

spatial heterogeneity has to be considered, weighted regional properties are diﬀerent;

weighted networks are, at a functional level, much more fragile than we would expect looking at
a purely topological level.

It is worth noting that, even if the the vulnerability analysis seems to be completely static, the previ-
ous strategies are based on a recursive re-calculation of the centrality measures on the network after
each damage. As noted by Holme et al. [144], each node removal leads to a change in the properties
of the other nodes. Only the neighboring nodes of the removed one suﬀer a change in the degree and
strength, but the structure and number of shortest paths are modiﬁed for the whole graph and there-
fore the betweennesses of all nodes may potentially be altered. It is therefore quite natural that, after

4.2. VULNERABILITY OF WEIGHTED NETWORKS: A CASE STUDY

83

each node removal, the choice of the next discarded node should be made according to recalculated
degree, strengths and betweennesses, and not according to the original ranking. Such procedure is
somehow akin to a cascade failure mechanism in which each failure triggers a redistribution on the
network and changes the next most vulnerable node.
Actually, we have found [89] that recalculated rankings do not diﬀer considerably from the original
ones, even for non-local quantities like the betweenness. This result has two important consequences.
First, it points out the validity of considering static analysis, such as that of vulnerability (and indi-
rectly percolation), in order to study dynamical property of networks, such as spreading and cascade
failures or congestions. The other observation concerns the protection of large scale infrastructures.
On the one hand, the planning of an eﬀective targeted attack does need only to gather information
on the initial state of the network. On the other hand, the identiﬁcation of crucial nodes to protect is
an easier task, since it is only weakly dependent on the attack sequence.

84

CHAPTER 4. SPREADING AND VULNERABILITY

4.3 Spreading processes on Weighted Random Graphs

This second part of the chapter is devoted to study spreading phenomena on weighted networks.
According to the static analysis made in the previous section, at a functional level, weighted networks
look much more vulnerable. In other words, network’s functionality suﬀers of the disconnection of
some high-traﬃc portions of the system. For the same reasons, we could expect to observe the same
features in the behavior of spreading processes on weighted networks. More precisely, we want to model
a process that exploits the traﬃc to spread throughout the network, the eﬃciency of the spreading
depending on the weights properties.
In Section 4.1.2, we have explained the relation between spreading processes and percolation, stressing
that there is a correspondence between the existence of a giant component in the percolation process
and the possibility of a macroscopic spreading. Of course, the analogy becomes evident if we think
to simple examples, like the outburst of epidemics in a population of individuals, or the diﬀusion of a
virus on the Internet, but also the spreading of information or other physical quantities on a generic
network.
Nevertheless, the standard percolation cannot encode all the features of such spreading processes, in
which the spreading rates depend on the properties of the nodes and the edges, and on the details of
the process. For instance, in the Internet, the connections between computers are real cables, thus the
transmission along them depends on their bandwidth; in the air-transportation network, the edges
are weighted with the number of available seats, that is a measure of the their capacity; in social and
contact networks as well, the importance of links is related to the type of relationships between the
individuals. It is clear that real processes are inﬂuenced by these factors.
According to this remark, we develop a general theory of spreading on networks, in which nodes and
edges are endowed with diﬀerent spreading properties.
In order to express the ability of an edge
(i, j) to transfer some physical quantities (information, energy, diseases, etc), we introduce an edge
transition probability Tij, that depends on the properties of the vertices i, j and of the edge (i, j) itself.
In addition, in real processes the nodes have diﬀerent ability to spread, thus they should be supplied
with a node traversing probability qi. In this manner, the actual size of the giant component can be
aﬀected by the non-optimal or non-homogeneous ﬂow through the nodes and edges, the most general
model performing an inhomogeneous joint site-bond percolation. On the other hand, information about
simpler processes such as site percolation with inhomogeneous bonds (edges) or bond percolation with
inhomogeneous sites (nodes) can be easily obtained assuming, in turn, qi or Tij as uniform. In these
particular cases, we will specify them as node (q) or edge (T ) occupation probability (in agreement
with standard percolation processes).
This formalism ﬁts very well the description of spreading phenomena on weighted networks, since we
can choose the transition probabilities to be functions of the weights (Tij = T (wij)). We can also deﬁne
a weighted giant component as the part of the giant component that is reached in the spreading process
and gives a measure of the functionality of the network. For instance, for the spreading of information,
it corresponds to the maximal subgraph that can bear and handle a large ﬂow of information, ensuring
the global well-functioning of the network. In contrast, if we are dealing with epidemic spreading,
the weighted giant component corresponds to the maximal infected region reachable in the pandemic
regime. In both cases, topological giant component is reduced by introducing weights.
For the sake of simplicity, the rest of this section is devoted to discuss spreading phenomena in weighted
random networks, and the possible applications in the description of real processes. This is done ﬁxing
qi = q and studying a site-percolation problem. On the other hand, the model of generalized spreading
phenomena on networks goes beyond the description in term of weighted networks and can be analyzed

4.3. SPREADING PROCESSES ON WEIGHTED RANDOM GRAPHS

85

Figure 4.6: (A) Graphical representation of the Eq. 4.6. Fat lines indicate the contribution coming
from the unknown probability ρij that an edge (i, j) does not belong to the inﬁnite cluster. The ﬁrst
term on the right-hand side represents the contribution coming from the probability 1
Tij that a
ﬂow does not traverse the edge (i, j); the second term accounts for the probability that the edge (i, j)
is traversed times the unknown contribution ρjh of other edges attached to j. (B) Diagrammatic
representation of the self-consistent Eq. 4.7. Fat lines correspond to the unknown uniform probability
) that an edge does not lead to the giant component. Full lines mean that edges can be crossed,
ρ(
{
with probability T , while the dashed edge corresponds to the contribution 1
T that an edge cannot
be crossed.

−

−

T

}

in a very general and abstract form. The general theory [84], by means of which the most relevant
results have been derived, is reported in the Appendix B, while a brief introduction to generating
functions in graph theory is reported in the Appendix A.

4.3.1 Generalized Molloy-Reed Criterion in Weighted Random Graphs

The idea of a percolation process in which the basic elements (nodes and edges) present inhomogeneous
properties goes back to the physical studies of conduction in resistor network models (see Ref. [156]
and references therein). A typical way to introduce disorder on the edges (or on the nodes) is that of
assigning to each of them a random number between 0 and 1, then removing all edges (nodes) in a
selected interval of values. Percolation properties are studied as functions of the fraction of remaining
edges (nodes) in the strong disorder regime [58, 164].

However, the percolation processes we want to describe is more general than the theory of random
resistor networks. The latter, indeed, corresponds to the case in which the edge transition probability
T0) for a reasonable value T0), so that transmission occurs only
is a step function (the Heaviside θ(Tij −
along a fraction of the edges (with suﬃciently high conductance) and, for those edges, it is optimal.
In other words, it corresponds to a bond percolation, as already noted in Ref. [188]. Here, we are
interested in a site percolation process in which, additionally, there is a quenched variable expressing
the probability of passing through an edge. This quenched probability rate is a function of the weights
along the edges, i.e. Tij = T (wij).
We use an intuitive derivation of the percolation criterion, that generalizes the (Bethe Approximation)
approach introduced by Cohen et al. in Ref. [80] for uncorrelated sparse random graphs. Let us call
ρij the probability that an edge in the network does not lead to a vertex connected via the remaining

86

CHAPTER 4. SPREADING AND VULNERABILITY

edges to the giant component (inﬁnite cluster) and Tij the probability that a ﬂow leaving the node i
passes trough the edge (i, j), reaching the node j. Both ρij and Tij are deﬁned in the interval [0, 1].
In general, ρij depends on the transition probability Tij of the edge (i, j), through a term 1
Tij,
and on the probability that the node j, if reached, does not belong to the inﬁnite cluster. This
contribution can be computed as the joint probability that each one of the remaining edges emerging
from j does not belong to the giant component. Assembling the diﬀerent contributions, we get the
recursive expression (Fig. 4.6-A)

−

ρij = 1

Tij + Tij

−

ρjh ,

(4.6)

(j)

Yh
∈ V
= i
h

}

{

T

V

allows a statistical reformulation of Eq. 4.6.

1 terms ρjh if kj is the degree of the node j and

(j) is its set of
that contains a product of kj −
neighbors. This recursive procedure is not closed, but the introduction of some hypotheses on the set
of transition probabilities
Let us suppose that the transition probabilities are random variables with a given distribution pT , and
the average overall probability ρ that a randomly chosen edge does not belong to the giant component
depends only on some general properties of that distribution such as the mean, the variance, etc (i.e.
ρ = ρ(
{
Note that in this section (as well as in Appendices A-B) we change notation with respect to Chapter 3,
in which the degree distribution is indicated as P (k); here, we use instead pk for the degree distribution.
By picking up an edge at random in a random graph, the probability that it is connected to an edge
of degree k is kpk
hki , where pk is the degree distribution of the graph. We can now write a self-consistent
T
equation for ρ(
{

) (Fig. 4.6-B),

)).

T

}

}

T

ρ(
{

}

) = 1

T + T

−

kpk
k
h

i

Xk

)k−1 ,

T

ρ(
{

}

in which T is a realization of the independent and identically distributed (i.i.d.) random variables
}
in the interval [0, 1]. Averaging both the members of the Eq. 4.7 on pT , we obtain that the probability
T
ρ depends only on the average value

T

{

T
h

, i.e. ρ(
{
i

T
) = ρ(
h

), and the equation becomes
i

T
ρ(
h

) = 1
i

T

+

− h

i

T
h

i

T
ρ(
h

)k−1 = I[ρ(
T
h
i

)] .
i

}
kpk
k
h

i

Xk

Apart from the trivial solution ρ = 1, another solution ρ = ρ∗ < 1 exists if and only if dI
1.
> 0), therefore dI
The curve I[ρ], indeed, is positive in ρ = 0 (I[0] = 1
1
means that it crosses the line f (ρ) = ρ in a point 0 < ρ∗ < 1. The condition on the derivative of the
r.h.s. of Eq. 4.8 corresponds to

dρ |ρ=1 ≥
dρ |ρ=1 ≥

p1/
i

T
h

k
h

− h

+

T

i

i

i − h
k
i
h
A generalization of the Molloy-Reed criterion [180] for the existence of a giant component in presence
of random weights on the edges immediately follows,

≥

(4.9)

T
h

1 .

i

i

k2
h

k

(4.7)

(4.8)

(4.10)

k2
h
k
h

i
i

1 +

≥

,

1
T
h

i

meaning that, when the transition probabilities are i.i.d. random variables, a giant component exists
if and only if the inequality is satisﬁed. The case of uniform transition probabilities is exactly the

6
4.3. SPREADING PROCESSES ON WEIGHTED RANDOM GRAPHS

87

i

i

1/

k
h

i ≥

T
h

T
h

k2
h

same, with uniform value T instead of the average value
. Note that, while in the case of perfect
i
transmission (Tij = 1) the usual formulation of the Molloy-Reed criterion is recovered [180], when
< 1 the r.h.s. of Eq. 4.10 can grow considerably, aﬀecting the possibility of observing percolation:
T
h
needed to
the smaller is the average transition probability, and the larger are degree ﬂuctuations
ensure the presence of a giant component.
k/k!), the criterion in
For a random graph with poissonian degree distribution (i.e. pk = e−hki
k
i
h
. We show in Fig. 4.7-A the results of numerical
Eq. 4.10 corresponds exactly to have
i
simulations for the giant component’s computation on an Erd¨os-R´enyi random graph with N = 104
nodes and with random transition probabilities uniformly distributed in [a, b] with 0
1.
A giant component clearly appears when the mean connectivity
exceeds the inverse of mean
a)/2. Considering diﬀerent distributions (e.g. binomial distributions) for
transmissibility value (b
the i.i.d. random variable T does not aﬀect the results.
For heterogeneous graphs with broad degree distribution, the inequality in Eq. 4.10 is satisﬁed thanks
to the huge ﬂuctuations of the node degrees ensuring the l.h.s.
In
mk−γ (2 < γ < 3, m is the
particular, when the graph has power-law degree distribution pk ∼
minimum degree), the ﬂuctuations diverge in the limit N
. In this case, the giant component
always exists if N is large enough. If γ > 3, the second moment is ﬁnite, and Eq. 4.10 provides the
following bound for the average transition probability necessary to have a giant component (computed
using the continuum approximation for the degree),

to be larger than 1 + 1/

a < b

→ ∞

T
h

k
h

.
i

≤

≤

−

i

γ
3
−
1) + 3

.

2m

−

T
h

i ≥

γ(m

−
1 + 1/

i

≤

≤

≥

O

mhT i

i ≤

3 +

T
h

T
h

T
h

(N ) only when γ

it is satisﬁed when
, while for m < 1 + 1/
i
1−(m−1)hT i . For m = 1, an inﬁnite (uncorrelated) scale-free graph presents a giant component
4. At γ = 3, logarithmic corrections should be taken into

The inequality is always satisﬁed for m
γ
3 +
of order
account [80].
Actually, real networks are large but ﬁnite, and the second moment cannot diverge, thus we expect
that the condition is not always satisﬁed. This is clearly shown in Fig. 4.7-B, where we have reported
the size of the giant component for power-law random graphs as a function of the exponent γ for
. The size of the giant component is
diﬀerent values of the average edge transition probability
i
dramatically aﬀected by low transition probabilities. Now, the argument of Cohen et al.
[80] can
be used to compute the threshold of site percolation with random disorder on the edges. If q is the
(uniform) node occupation probability in an uncorrelated random graph, then a randomly chosen
node, whose natural degree in case of q = 1 is k′, will assume a degree k

k′ with probability

T
h

≤

that means that the corresponding degree distribution pk(q) is related to the degree distribution
pk′ (q = 1) by

∞

pk(q) =

pk′ (q = 1)

k′
k !

qk(1

q)k′−k .

−

 
iq=1, that introduced into the expression
iq=1+q(1
It follows that
Eq. 4.10 for the Molloy-Reed criterion gives the expression of the threshold value for site percolation,

Xk′=k
k2
iq = q
h

iq=1 and

iq = q

k
q)
h

k2
h

k
h

k
h

−

k′
k !

 

qk(1

q)k′−k ,

−

qc =

1
T
h

k
i
h
i − h

k

i

.

k2
h

i

(4.11)

(4.12)

(4.13)

(4.14)

88

CHAPTER 4. SPREADING AND VULNERABILITY

1

0.8

A)

N

 
/
 
|

G

|

c

0.6

0.4

0.2

0

0

1

0.8

N

 
/
 
|

G

|

c

0.6

0.4

<T> = 1
<T> = 0.75
<T> = 0.5
<T> = 0.25

0.2

B)

0

2

<T> = 1
<T> = 0.75
<T> = 0.5
<T> = 0.25

2

4

6

8

10

<k>

2.5

γ

3

3.5

k
h

T
h

Gc vs. average degree

Figure 4.7: (A) Relative size of the giant component
in an Erd¨os-R´enyi
random graph in which the edge transition probabilities are uniformly random distributed with mean
. Simulations are performed on a sample of 100 graphs with N = 104 nodes. The diﬀerent
value
i
curves refer to diﬀerent values of average transition probability:
= 1 (circles), 0.75 (squares), 0.5
Gc vs. the exponent
(up triangles) and 0.25 (down triangles). (B) Relative size of the giant component
γ in an power-law graph in which the edge transition probabilities are uniformly random distributed
. Simulations are performed on a sample of 100 graphs with N = 104 nodes, and
with mean value
i
minimum degree m = 1. The diﬀerent curves refer to diﬀerent values of average transition probability:
T
h

= 1 (circles), 0.75 (squares), 0.5 (up triangles) and 0.25 (down triangles).

T
h

T
h

i

i

i

Eq. 4.14 shows that decreasing the average transmission capacity of the edges (i.e. the edge transition
probability), the value of node occupation probability necessary to ensure percolation increases.
The expression of the percolation threshold in Eq. 4.14 is not very general, since it is correct only
for randomly distributed weights (and thus transition probabilities). On the contrary, in many real
networks (e.g. the WAN) the weights are correlated with the degree, wij = w(ki, kj).
Consequently, a natural generalization is that of considering T = Tkikj . Of course, in this case the
previous derivation breaks down, since two types of correlations have to be considered: correlations be-
tween edge transition probabilities and degree, and degree-degree correlations. The correct approach,
reported in the Appendix B, is that of using the generating functions formalism in the framework of
Markovian correlated random graphs (i.e. with only degree-degree correlations) [43].
We consider here the simpler case in which the transition probability depends only on the degree of the
departure node (i.e. Tij = Tki). The self-consistent equation 4.7 can be straightforwardly generalized
to consider the case T = Tk, obtaining the following expression for the percolation threshold,

k
h
i
k2Tki − h
h
The striking property is that, for particular forms of the transition probability, a ﬁnite value for the
percolation threshold can be restored also in inﬁnite scale-free networks. We will investigate this case
and other possible situations in the following section.

kTki

(4.15)

qc =

.

4.3.2 Examples and Numerical Simulations

The functional dependence of the transition probabilities
is strongly related to the details of
the system and to the type of spreading process. Therefore, in absence of hints from studies of

T

}

{

4.3. SPREADING PROCESSES ON WEIGHTED RANDOM GRAPHS

89

A)

N

 
/
 

N

q

1

0.8

0.6

0.4

0.2

0

0

<T> = 1
<T> = 0.75
<T> = 0.5
<T> = 0.25

B)

N

 
/
 

N

q

0.4

0.8

0.6

0.2

0

0

<T> = 1
<T> = 0.75
<T> = 0.5
<T> = 0.25

0.2

0.4

0.6

0.8

1

0.2

0.4

0.6

0.8

1

q

q

i

= 0.25, 0.5, 0.75, 1 for an Erd¨os-R´enyi random graph (A) with N = 105 vertices and

Gg as function of the fraction q of occupied vertices for
Figure 4.8: Size Nq/N of the giant component
= 10 and
T
h
a power-law random graphs (B) with same size, exponent γ = 2.3. All curves have been averaged over
100 realizations. The predicted values of qc = 0.4, 0.2, 0.133, 0.1 are well veriﬁed in the Erd¨os-R´enyi
(log N ). The power-law graph gives slightly worse results,
graph by the values of q at which Nq ∼ O
but still in agreement with the theoretical values qc = 0.387, 0.20, 0.19, 0.1 (that are indicated by
arrows on the curves).

k
h

i

real data about spreading processes on networks, the present section is devoted to highlight some
simple examples of reasonable functional forms for the transition probability, and to illustrate their
eﬀects on the percolation condition. We perform our analysis on two main classes of random graphs:
homogeneous graphs, in which the connectivity distribution is peaked around a characteristic degree
value, and heterogeneous graphs, whose degree distribution is broad, with very large ﬂuctuations in
the degree values.

Random Transition Probabilities -

Taking randomly distributed transition probabilities
Tij (and weights) can appear unrealistic in technological networks, but it may be interesting to model
spreading processes on some very disordered network. We have checked the validity of Eq. 4.14
performing simulations on an Erd¨os-R´enyi random graph with
= 10 and on a power-law random
graph with exponent γ = 2.3. Both graphs have N = 105 nodes and the transition probabilities
are assigned randomly between 0 and 1. Fig. 4.8-A reports the size of the giant component of the
Erd¨os-R´enyi graph as function of the fraction q of occupied vertices for
= 0.25, 0.5, 0.75, 1; the
predicted values qc = 0.4, 0.2, 0.133, 0.1 are well reproduced by simulations. The same measures for a
power-law graph are shown in Fig. 4.8-B. The curves of the simulations are in good agreement with
= 0.5),
the theoretical values of the percolation threshold qc ≃
0.19 (for

= 0.25), 0.20 (for

= 1.0). 1

0.387 (for

T
h

T
h

T
h

k
h

i

i

i

i

T
h

= 0.75), 0.1 (for

T
h
Single-vertex dependent transition probability -

i

i

The assumption of transition probabil-
ities T = Tk yields diﬀerent results depending on the exact functional dependence on the degree of
the initial vertex. A ﬁrst example is that of a monotonously increasing function of the degree, that

1The estimation of the threshold value, as explicitly shown in Ref. [84], is a very diﬃcult task in power-law graphs,
given that the shape of the curves decreases with constant convexity, converging very smoothly to zero. Indeed, the
probability of nodes with maximum degree is O(1/N ), thus in a ﬁnite graph their frequency depends on the size of the
system. Since the ﬂows are clearly unbalanced in favor of large degree nodes, ﬁnite size eﬀects are more relevant on
these types of processes.

A)

90

c

q

1

0.8

0.6

0.4

0.2

0
2.9

CHAPTER 4. SPREADING AND VULNERABILITY

a = 0.2, γ = 2.4
a = 1, γ = 2.4

0.2

0.4

0.6

0.8

1

a = 0.2, γ = 2.8
a = 1, γ = 2.8  

N

 
/
 

N

q

N

 
/
 

N

q

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0

0

0

0

B)

C)

a = 0.2
a = 1
hom. perc.  

3

3.1

3.3

3.4

3.2
γ

0.2

0.4

0.6

0.8

1

q

1

Figure 4.9: (A) Critical density qc of nodes ensuring the existence of a giant component
Gg as a
function of the exponent γ for a power-law graph in which the transition probability function is
ak
hki ). The ﬁgure reports the theoretical curve.
exp(
single-vertex depending with the form Tk ∼
The parameter a controls the saturation to 1 for highly connected nodes: the cases a = 0.2 (circles)
and a = 1 (squares) are shown. For large values of the parameter a, the curves rapidly converge to
). For a < 1, the curves shift from this
the limit behavior of homogeneous percolation (limit a
limit, but in the range 2 < γ < 3 diverging ﬂuctuations ensure the percolation. (B)-(C) The curves
Nq/N obtained by numerical simulations on power-law random graphs of size N = 105 and exponent
γ = 2.4 and γ = 2.8 for the two values of a = 0.2, 1. The arrows indicate the positions of the threshold
predicted using the theoretical calculation of Ref. [84].

→ ∞

−

−

1

≥

−

−

exp(

ak
saturates to 1 at large k values: we consider Tij = Tki ∼
hki ), that can be applied also to
inﬁnite graphs. The parameter a controls the convergence to 1. For large scale-free networks, however,
the mere presence of a saturation, rather than its rapidity, is suﬃcient for the system to behave as in
the standard percolation, showing that graph’s heterogeneity ensures a zero percolation threshold. In
general, from Eq. 4.15 simple calculations lead to the expression of the threshold for site percolation
(see Ref. [84]). Its behavior is sketched in Fig. 4.9-A as a function of γ and for some values of the
parameter a. It shows that the critical fraction of occupied nodes qc is exactly 0 for 2 < γ < 3. Also
3, the behavior is qualitatively the same as for standard percolation on scale-free networks.
for γ
The reason is essentially that a transition probability converging to 1 for highly connected nodes does
not aﬀect the network’s properties if the network is inﬁnite, because there is always a considerable
fraction of nodes with optimal transmission.
This condition is not trivially satisﬁed by ﬁnite graphs, and the presence of a cut-oﬀ in the degree
can have a strong inﬂuence on the network’s functional robustness. Two kinds of cut-oﬀs on power-
laws have been largely studied in the literature: an abrupt truncation of the degree distribution at a
k−γe−k/κ. Without entering in
maximum value κ
the details of the analytic and numerical investigation, the main result is that the introduction of a
cut-oﬀ actually reduces the eﬀects of degree ﬂuctuations, producing ﬁnite percolation threshold also
in the range 2 < γ < 3.
However, this choice of edge inhomogeneity does not seem to enrich the scenario obtained by standard
percolation, though the case of slow convergence (a < 1) produces non negligible eﬀects on ﬁnite sys-
tems (panels B and C in Fig. 4.9). The structural properties of homogeneous graphs, on the contrary,
are always deeply aﬀected by this type of transition probability, expecially when perfect transmission

γ−1 , or a natural exponential cut-oﬀ, i.e. pk ∼

N

≈

1

4.3. SPREADING PROCESSES ON WEIGHTED RANDOM GRAPHS

91

hom. perc.
α = 0.25
α = 0.5
α = 0.75

c

q

1

0.8

0.6

0.4

0.2

0

2

B)

c

q

1

0.8

0.6

0.4

0.2

0

0

A)

theor. γ = 2.3
theor. γ = 2.6
simul. γ = 2.3
simul. γ = 2.6

2.2

2.4

2.6

3

3.2

3.4

3.6

2.8
γ

0.2

0.4

0.6

α

0.8

1

Figure 4.10: (A) Fraction qc of occupied nodes required to have a giant component as a function of
the exponent γ for a power-law graph in which the transition probability is the single-vertex function
k−α, with exponent 0 < α < 1. The curves report the values of qc computed by Eq. 4.16. All
Tk ∼
curves for α = 0.25 (circles), 0.5 (squares) and 0.75 (triangles) show that the percolation threshold is
increased compared to the homogeneous result (dashed line), also for an inﬁnite graph. In particular, a
ﬁnite threshold larger than 0 appears also in the range 2 < γ < 3. (B) Threshold value qc of occupied
nodes as a function of the parameter α for power-law graphs with cut-oﬀ κ = 102 and exponent
γ = 2.3 (full line and circles) and γ = 2.6 (dashed line and crosses). The symbols (circles and crosses)
are results from simulations on random graphs of size N = 105 (average over 100 realizations); the
lines are the corresponding theoretical predictions.

is reached beyond the peak of the degree distribution (a < 1) [84]. Another wide class of transition
probabilities contains those converging to zero with increasing degree. At a ﬁrst glance, it seems a
very unphysical condition, but the problem can be inverted asking which is the maximal decay in the
degree dependence still ensuring site percolation.
For single-vertex transition probability Tk, Eq. 4.15 implies that, independently of the degree distri-
bution, a graph does not admit percolation if Tk decays as T1/kα with α
1. Indeed, by substitution,
qc =
, and T1 < 1
k
i
h
(assuming
1). This is actually equivalent to the result presented in Ref. [188].
Since α = 0 corresponds to standard percolation, we are interested in the intermediate case 0 < α < 1.
In scale-free networks the percolation threshold is computed by series summation,

)], that is larger than 1 because
i

k2−α
/[T1(
h
i
k
i ≥
h

≥
k2−α
h

k1−α

k1−α

i ≥ h

i − h

k
h

>

i

qc =

ζ(γ + α

ζ(γ
2)

−
−

−

1)
ζ(γ + α

−

,

1)

(4.16)

that has been plotted in Fig. 4.10-A as a function of γ for diﬀerent values of α between 0 and 1. The
curves show that a transition probability moderately decreasing with the degree can induce power-
law graphs with 2 < γ < 3 to present a ﬁnite percolation threshold. However, many real networks
(Internet, WWW, etc) have a power-law degree distribution with exponent lower than 2.5, for which
the giant component persists even for relatively large α (at least in the approximation of inﬁnite
systems). Nevertheless, the giant component is reduced in ﬁnite systems or in presence of a cut-oﬀ
on the degree as shown by the results of simulations reported in Fig. 4.10-B. The ﬁgure displays
the behavior of the threshold value qc as a function of the parameter α for two diﬀerent exponents
γ = 2.3, 2.6. The lines are the theoretical predictions for (inﬁnite) systems with cut-oﬀ κ = 102, the
points are numerical results on ﬁnite systems with N = 105 and same cut-oﬀ. The threshold values qc

92

CHAPTER 4. SPREADING AND VULNERABILITY

for ﬁnite sizes are reasonably smaller compared to the theoretical predictions for inﬁnite graphs with
the same cut-oﬀ on the degree distribution.

4.3.3 Discussion and Conclusions

This collection of examples is far from being complete, it should rather represent a way to better
understand potential applications of calculations and formulae we have presented. Among other
possible expressions for the transition probability, we mention non-monotonous or peaked degree-
dependent transition probabilities, with an optimum of transmissibility for (not necessarily large)
characteristic values of the degree. The actual spreading of a virus on the Internet might have such
a behavior. Highly connected nodes have large exchanges of data with their neighbors, for that they
should be potentially the nodes with highest transmission capability. On the other hand, there is a
common awareness of their importance, thus they are better protected and controlled, so that the
eﬀective transition probability for the spreading of viruses from these nodes is strongly reduced. Very
low-degree nodes are less protected but also less exposed to the transmission (their data exchanges
are limited). Such scenario suggests that also non-monotonous transition probabilities are actually
interesting in the study of dynamical processes on networks.
In conclusion, this section has been devoted to the deﬁnition of a generalized percolation with edge
transition probabilities that can be used to describe spreading processes.
In the case of weighted
networks, the edge transition probabilities should depend on the weights. We have obtained two
important results:

•

•

When weights and degree are not correlated, it is reasonable to assume that also the edge
transition probabilities are randomly distributed (not strictly uniformly random).
It follows
that when the percolation threshold is present in the topological description, it is increased; but
it cannot be restored when it is topologically absent.

Real systems present correlations between weights and degree, thus it is reasonable to include
correlations also in the expression for the edge transition probability. In this case, it is possible
to restore a ﬁnite percolation threshold, even when it is topologically absent.

Chapter 5

Naming Game: a model of social
dynamics on networks

5.1

Introduction

In Chapters 3-4, we have studied the structural and functional properties of complex networks, sup-
porting the phenomenological analysis of real infrastructure networks with a numerical and analytical
investigation of theoretical models. In such a framework, dynamical processes on networks, like ex-
ploration and spreading models, have been principally conceived as tools, by means of which a better
characterization of the underlying networks properties can be achieved.
We turn now our attention to a more direct investigation of dynamical phenomena on complex net-
works, focusing on the ﬁeld of social networks, and in particular on models of social interactions
between individuals.
A theoretical description of social interactions at the individual level is a very complicated task, that
is studied by sociologists and goes beyond the purpose of any statistical physics approach. Though it
is not possible to reproduce or predict human decisions and actions, when looking at a global scale,
social interactions are much simpler to describe. In this case, we do not need to understand all details
of single individual behaviors, but only few collective aspects and their relation with the other global
properties of the population under study. In particular, the large scale observation of social interac-
tions reveals the existence of striking collective phenomena, i.e. the mechanism, based on individual
decision processes, leading to the appearance of an overall homogeneous behavior or some other global
property in a population of agents.
The standard methods of statistical physics are very appropriate to study such collective behaviors,
neglecting details and retaining only few general ingredients observed in real social interactions. For
this reason, physicists have put forward a large number of theoretical models of social dynamics, bor-
rowing a suite of statistical methods from the theory of interacting particles systems [172, 96, 111, 42].
The largest part of these models deals with the study of opinion formation and strategic games. For
instance, the Ising majority rule has found an unexpected ﬁeld of application in problems of opinion
formation [75, 179, 125, 126]. On the same subject, many other models have been proposed, such as
the Voter model [172, 159, 161, 36, 227, 122], the Sznajd-Weron model [235], the Axelrod model for
the dissemination of culture [13], and their variants (e.g. the models proposed by Deﬀuant et al. [94]
and by Krause and Hegselmann [142]). Other types of social dynamics involve diﬀusion or spreading

93

94

CHAPTER 5. THE NAMING GAME

processes (e.g. the diﬀusion of knowledge [81], rumors [83], innovations [214] or ideas [37], etc), and
the wide ﬁeld of strategic games (e.g. the minority game [73], the prisoner’s dilemma [209], etc).
The behavior of these models was usually studied on regular topologies, even though it is clearly inap-
propriate for representing the topology of social interactions. For this reason, for a long time models
of social dynamics have been regarded more as academic exercises than as systems with real potential
applications. The growing interest for networks science has recently led to a better knowledge of the
topological properties of real social groups (Section 2.3), and to the formulation of network models
reproducing such properties (Section 2.4). Consequently, many traditional models of social dynamics
have been reconsidered, in order to be studied in the new, more appropriate, framework of complex
networks.

In this chapter, we report the main results of a series of publications [20, 90, 91, 92, 21], in which we
have studied a recently proposed model of social dynamics, called Naming Game, investigating its dy-
namical behavior on both regular topologies and complex networks. As we will see in the next section,
this model is conceived to grasp the self-organized mechanisms leading to the onset of a communication
system in groups of individuals and, more in general, to describe decision processes involving pairwise
interactions and negotiation, like those underlying the opinion spreading. In addition, with respect
to other models of social dynamics, the evolution rules of the Naming Game present new ingredients,
whose role will be elucidated along the chapter. They can be summarized in the following points:

the introduction of memory in the individual dynamics;

the presence of a feedback interaction with an asymmetric interaction rule;

an a priori unlimited number of states (or words, opinions, etc) that is dynamically determined
during the system’s evolution.

The resulting dynamics is rich of interesting properties, some of them strongly depending on the
underlying topological properties of the system. Hence, the main motivation of the work is that
of studying the impact of diﬀerent topological properties on the local and global dynamical patterns
generated by the Naming Game and on the process leading to the emergence of collective phenomena.
The present chapter is organized as follows. Section 5.2 contains the deﬁnition of the model and
the analysis of the mean-ﬁeld case. A topology in which agents are allowed to interact with all the
others is not realistic; social environments are, on the contrary, more reliably modeled by means of
networked structures, that can better account for the disparity of social relations. Thus, in Section 5.3,
we provide an exhaustive analysis of the Naming Game dynamics on various network models. We
start with low-dimensional lattices and small-world networks, on which some analytical results are
available. Then we turn our attention to general complex networks, looking in particular at the eﬀects
of the node heterogeneity. The last part of the Section 5.3 is devoted to study real complex networks,
whose dynamics is often surprisingly diﬀerent to those observed on computer generated networks.
The internal activity of the agents governing the decision process is described in Section 5.4, while
the conclusions are exposed in Section 5.5. We refer to the Appendices C-D for the analysis of some
more technical issues that are omitted in the main text.

•

•

•

5.2. NAMING GAME: GENERAL FEATURES

95

5.2 Naming Game: General features

Social interactions are based on the existence of a communication system among the agents, who are
able to understand each other by means of common linguistic patterns or, more generally, by means
of a common vocabulary of symbols.
Such a communication system is the result of a self-organized process in which individuals select spe-
ciﬁc symbols (words) and associate them to concepts and ideas (objects). The emergence of a shared
lexicon inside social groups and communities of people is very likely to be driven by simple criteria,
like popularity, imitation, negotiation, and agreement. When a new concept is introduced, people
refer to it using several diﬀerent names or words. These words start spreading among the population,
competing one against the other, until the choice of one of them is taken (with a sudden transition
or with a long process) and everyone uses the same word (or symbol, etc) [166, 56, 145]. This kind of
dynamics has recently become of broad interest after the diﬀusion of a new generation of web-tools
which enable human users to self-organize a system of tags in such a way to ensure a shared classi-
ﬁcation of information about diﬀerent arguments (see, for instance, del.icio.us or www.ﬂickr.com and
Refs. [72, 133]). Another application concerns global coordination problems in artiﬁcial intelligence,
where a group of artiﬁcial embodied agents moving in an unknown environment have to exchange in-
formations about the objects they gradually discover. The emergence of consensus about the objects
names allows to establish a communication system. A practical example of this type of dynamics is
provided by the well-known Talking Heads experiment [230, 231], in which embodied software agents
develop their vocabulary observing objects through digital cameras, assigning them randomly chosen
names and negotiating these names with other agents.
In other words, the process leading to the emergence of a communication system in a population
of agents (e.g. a social network) is an example of social collective phenomenon with polarization of
individual opinions or ideas. On the base of these observations, a new ﬁeld of research called Semiotic
Dynamics has been developed [232], that investigates by means of simple models how (linguistic) con-
ventions originate, spread and evolve over time in a population of agents endowed with simple internal
states and local pairwise negotiation interactions.
The fundamental model of Semiotic Dynamics is the so-called Naming Game [229], in which a popu-
lation of agents, interacting by pairwise negotiation rules, try to assign a common name to an object.
Moreover, this model can be studied as an alternative model of opinion formation, since in place of
names to be assigned to an object we can think to the competition of diﬀerent opinions on a given
topic.
The next section is devoted to the description of the Naming Game model, while the subsequent one
discusses the mean-ﬁeld case.

5.2.1 The Model

A minimal model of Naming Game has been put forward by Baronchelli et al. in Ref. [22] to reproduce
the main features of Semiotic Dynamics and the fundamental results of adaptive coordination observed
in the Talking Heads experiment. The minimal Naming Game model consists of a population of N
agents observing a single object, for which they invent names that they try to communicate to one
another through pairwise interactions, in order to reach a global agreement. The agents are identical
and dispose on an internal inventory, in which they can store an a priori unlimited number of names
(or opinions). All agents start with empty inventories. At each time step, a pair of neighboring agents
is chosen randomly, one playing as “speaker”, the other as “hearer”, and negotiate according to the

96

CHAPTER 5. THE NAMING GAME

Figure 5.1: Agents interaction rules. Each agent is described by its inventory, i.e. the repertoire of
known words. The speaker picks up at random a name in its inventory and transmits it to the hearer.
If the hearer does not know the selected word the interaction is a failure (top), and it adds the new
name to its inventory. Otherwise (bottom), the interaction is a success and both agents delete all
their words but the winning one. Note that if the speaker has an empty inventory (as it happens at
the beginning of the game), it invents a new name and the interaction is a failure.

following rules (see also Fig. 5.1):

•

•

•

the speaker selects randomly one of its words and conveys it to the hearer;

if the hearer’s inventory contains such a word, the two agents update their inventories in order
to keep only the word involved in the interaction (success);

if the hearer does not possess the uttered word, the latter is added to those already stored in
the hearer’s inventory (failure), i.e. it learns the word.

Note that the time unit corresponds to the pairwise interaction, in contrast to usual statistical me-
chanics models in which it corresponds to N interactions. However, in order to compare the results
for the present dynamical rule with well-known results of other models, in many cases, we will use a
rescaled time t/N .
Before entering in the detailed description of the dynamics, it is worthy to specify some visible diﬀer-
ences of the Naming Game with other commonly studied models of social dynamics and, in particular,
of opinion formation [235, 94, 13, 75, 179, 172].

•

Each agent can potentially be in an inﬁnite number of possible discrete states (words, names,
opinions), and the maximum number of states depends on the dynamical evolution itself. This is
in contrast with traditional models (Voter, Potts, etc) in which the number of states is a ﬁxed
external parameter taking ﬁnite (and usually small) values.

•

The two-steps decision process is realistic: an agent can accumulate in its memory diﬀerent
possible names for the object, waiting before reaching a decision. This feature is probably at

5.2. NAMING GAME: GENERAL FEATURES

97

the origin of the surface tension that emerges from the dynamics in low-dimensional lattices (see
sec. 5.3) and of the non-poissonian behavior at the agents level, a property that will be discussed
in Section 5.4.

•

Each dynamical step can be seen as a negotiation between speaker and hearer, with a certain
degree of stochasticity, that is absent in deterministic models such as the Voter model. The
stochastic component is however of a diﬀerent nature compared to that of standard Glauber
dynamics used in majority rule models [129], since here it comes from an internal selection
criterion, and involves only the speaker, without aﬀecting the (deterministic) decision process
of the hearer.

A second important remark concerns the random extraction of the word in the speaker’s inventory.
Most previously proposed models of semiotic dynamics attempted to give a more detailed representa-
tion of the negotiation interaction assigning weights to the words in the inventories. In such models,
the word with largest weight is automatically chosen by the speaker and communicated to the hearer.
Success and failures are translated into updates of the weights: the weight of a word involved in a
successful interaction is increased to the detriment of those of the others (with no deletion of words);
a failure leads to the decrease of the weight of the word not understood by the hearer. An example of
a model including weights dynamics can be found in Ref. [170] (and references therein). For the sake
of simplicity the minimal Naming Game avoids the use of weights, that are apparently more realistic,
but their presence is not essential for the emergence of a global collective behavior of the system.
An important point needs to be stressed: while in the original experiments the embodied agents could
observe a set of diﬀerent objects, in the minimal Naming Game all agents refer to the same single
object. This is actually possible only if we assume that homonymy is excluded, i.e. two distinct objects
cannot have the same name. Consequently, in this model, all objects are independent and the general
problem reduces to a set of independently evolving systems, each one described by the minimal model.
In more realistic situations, however, the occurrence of homonymy cannot be neglected.

5.2.2 Mean-ﬁeld case

In the original work on the minimal Naming Game model [22], Baronchelli et al. have focused on the
mean-ﬁeld case, in which the agents are placed on the vertices of a complete graph, corresponding to
study a population in which all pairwise interactions are allowed. By means of numerical simulations,
they investigated the overall dynamics of the model, monitoring along the evolution three main global
quantities:

the total number Nw(t) of words in the system at the time t (i.e. the total size of the memory);

the number of diﬀerent words Nd(t) in the system at the time t;

the average success rate S(t) as function of the time, i.e. the probability, computed averaging
over many simulation runs, that the chosen agent gets involved in a successful interaction at a
given time t.

•

•

•

Note that all these quantities are zero at the beginning of the evolution, when all inventories are empty,
while they reach a stable value when the system enters the absorbing state corresponding to a global
agreement. In fact, it is possible to show, using a sort of Liapunov functional, that the mean-ﬁeld
model always converges to the absorbing state (consensus) [22]. The consensus state is deﬁned by
observing Nd = 1 and Nw = N (moreover it implies S = 1).

98

CHAPTER 5. THE NAMING GAME

4
1.2×10

)
t
(
 

w
N

3
8.0×10

3
4.0×10

)
t
(
 

N

d

0.0

0

2
5×10
2
4×10
2
3×10
2
2×10
2
1×10
0

1
0.8
0.6
0.4
0.2
0

0

0

)
t
(
S

MF
1D
2D

1300

1200

1100

1000

1
2×10

1
4×10

1
6×10

1
8×10

2
1×10

4

7×10

4

8×10

4

9×10

5

1×10

1
2×10

1
4×10

1
6×10

1
8×10

2
1×10

MF
1D
2D

MF
1D
2D

1
2×10

1
4×10

1
6×10

1
8×10

2
1×10

t/N

Figure 5.2: Evolution of the total number of words Nw (top), of the number of diﬀerent words Nd
(center), and of the average success rate S(t) (bottom), for a mean-ﬁeld system (black circles) and
low-dimensional lattices (1D, red squares and 2D, blue triangles) with N = 1024 agents, averaged
over 103 realizations. The inset in the top graph shows the very slow convergence in low-dimensional
lattices.

The temporal evolution of the three main quantities is depicted in Fig. 5.2 (circles). At the beginning,
many disjoint pairs of agents interact, with empty initial inventories: they invent a large number
of diﬀerent words, that start spreading throughout the system, through failure events. Indeed, the
number of words decreases only by means of successful interactions. In the early stages of the dynamics,
the overlap between the inventories is very low, and successful interactions are limited to those pairs
which have been chosen at least twice. Since the number of possible partners of an agent is of order
N , it rarely interacts twice with the same partner, the probability of such an event growing as t/N 2.
Note that this remark is in good agreement with the initial behavior of the success rate S(t) depicted
in Fig. 5.2. The initial trend of S(t) (black circles) is linear with a slope of order 1/N 2 (whose correct
value has been computed in Ref. [22]).
In this phase of uncorrelated proliferation of words, the number of diﬀerent words Nd invented by
the agents grows, rapidly reaching a maximum that scales as
(N ). Then Nd saturates, displaying
a plateau, during which no new word is invented anymore (since every inventory contains at least
one word). The total number Nw of words stored in the system has a similar behavior, but it keeps
growing after Nd has saturated, since the words continue to propagate throughout the system even if
no new one is introduced.
(N 0.5)
The peak of Nw has been shown to scale as
(N 1.5). In the subsequent
words. This peak occurs after the system has evolved for a time tmax ∼ O
dynamics, strong correlations between words and agents develop, driving the system to a rather fast
convergence to the absorbing state in a time tconv ∼ O
The S-shaped curve of the success rate in Fig. 5.2 summarizes the dynamics: initially, agents hardly
understand each others (S(t) is very low); then the inventories start to present signiﬁcant overlaps, so

(N 1.5) [22], meaning that each agent stores

(N 1.5).

O

O

O

5.2. NAMING GAME: GENERAL FEATURES

99

Figure 5.3: Graphical representation of the four possible terms contributing to the rate equation for
the number of undecided agents and the order of magnitude of the term. Note that, around tmax,
1, and then it decreases to zero; therefore, in principle, all terms play a role
the fraction nu(t)/N
during the evolution.

≃

that S(t) increases until it reaches 1, and the communication system is completely set in. Despite the
apparent simplicity of the dynamics, it is very diﬃcult to study this model analytically, because the
interaction rule is not totally stochastic (the hearer’s moves are deterministic) and the update of the
inventories after a success is highly non-linear. Nevertheless, the authors of Ref. [22] provided several
qualitative theoretical arguments in order to explain the main properties of the population’s global
behavior. We consider here only the argument for the scaling behavior of the maximum number of
words in the system.
From the simulations, we know that the maximum number of words scales as a power of the population
size N , therefore let us assume that, at the maximum, the number of words per agent scales as cN α,
for a certain positive value of the exponent α, and a constant c
1, since the
number of diﬀerent words is at most
In order to determine the value of α, we use the fact that, at the maximum, the ﬁrst temporal
derivative of the total number of words vanishes, i.e. dNw(t)
0. On the other hand, the probability
that a word chosen by the speaker is present in the inventory of the hearer is approximately cN α
N in
absence of correlations. We get the following rate equation [22],

(1). Note that α

dt ≃

(N ).

∼ O

O

≤

dNw(t)

dt ∝

cN α
N

1
(cid:18)

−

−

(cid:19)

cN α
N

2cN α .

(5.1)

The ﬁrst term at the r.h.s. of Eq. 5.1 is the gain term (in case of a failure), while the second term
represents the loss of 2cN α words in case of successful interaction.
At the higher order in powers of N , i.e. neglecting terms decreasing as α
dNw(t)

1, the balance condition
0 is satisﬁed if α = 1/2. This results proves that the maximum number of words in the
system scales as N 3/2. From the same argument we can as well obtain the scaling of the time at which
the peak occurs, tmax ∼
The study of the convergence time is much more diﬃcult, and no theoretical arguments have been
proposed yet (except for some results on the limit of inﬁnite dimensional lattices reported in Sec-

dt ≃

N 3/2.

−

100

CHAPTER 5. THE NAMING GAME

Figure 5.4: A naive representation (left) of the mean-ﬁeld approximation of pairwise interactions:
we focus on the speaker’s behavior, substituting single hearer’s dynamics with a mean-ﬁeld average
quantity. Therefore, only speakers contributions to the rate equation for nu(t) have to be considered,
that is provided by only two possible interactions (right). We can neglect the ﬁrst term, in which the
speaker has only one word, because it does not change the number of undecided nodes. The second
term, that diminishes of one unit nu(t), is the only contribution to Eq. 5.2 in this rough approximation.

tion 5.3.1). It is however possible to write down a very naive argument for the scaling (with the size
(N 3/2). This argument does not want to be rigorous, but
N ) of the convergence time, i.e. tconv ∼ O
its importance is principally that of showing which kind processes lead the system to a consensus
state, justifying the observed behaviors.
Let us consider the number nu(t) of agents with more than one word in the inventory (we denote
them as undecided agents), around the peak in the number of words nu ≃
N , while at the convergence
0. We can now study the way the system approaches the consensus writing a rate equation for
nu ≃
this quantity.
According to the actual pairwise interaction rule of the Naming Game, there are many diﬀerent contri-
butions that should be taken into account (see Fig. 5.3). Moreover, the negotiation process introduces
correlations related to the feedback mechanism in case of success (i.e. both the speaker and the hearer
update the inventory). On the other hand, in a mean-ﬁeld system, the set of words stored in the in-
ventories should be approximately the same for all agents, suggesting to neglect correlations and focus
on the behavior of a single node subjected to the average eﬀect of the rest of the system. Since the
hearer’s interaction rule is strictly deterministic, while the speaker chooses randomly in its inventory,
it seems more reasonable to consider the (mean-ﬁeld) average on the hearer’s term.
We can now write down an equation for the number of undecided speakers nu(t). First, each node is
chosen as speaker or hearer with the same probability, thus along the temporal evolution all nodes will
play as speakers and the equation can be considered to give a rough but correct approximation of the
real dynamics. Then, the four types of interactions depicted in Fig. 5.3 can be grouped in only two
terms (see Fig. 5.4): one in which the speaker is an undecided node, the other in which the speaker
has only one word into the inventory. The latter case do not contribute to the rate equation for nu(t),
because in case of both success and failure the number of undecided speakers does not change. The
only signiﬁcant contribution is the second term in Fig. 5.4, in which nu(t) is decreased by 1 with a
ﬁxed probability.

5.2. NAMING GAME: GENERAL FEATURES

The naive rate equation for the number of undecided agents reads

dnu(t)

dt ∝ −

nu(t)
N

S(t) ,

101

(5.2)

in which nu(t)
N is the probability of choosing an undecided agent as speaker, and S(t) is the success
rate, i.e. the average probability of having a successfull interaction. The functional form of the success
rate is not theoretically known, but we see from Fig. 5.2 that it varies very slowly after the peak until
the convergence process sets in, then it shows a super-exponential saturation to 1, being enhanced by
the decrease of the number of redundant words. Using numerical results for S(t) and nu(t) we have
checked that the relation in Eq. 5.2 is in fact approximately satisﬁed.
According to this picture, Eq. 5.2 sheds light on the type of self-accelerating cascade process leading the
system to the absorbing state. Just before the peak of Nw(t), the success rate increases only linearly
as t/N 2, then it slows down before the sudden acceleration leading to the convergence; therefore after
(1/√N ). This result can be obtained also recalling that the average probability of
the peak S(t)
success (i.e. the success rate) is given by the ratio between the average inventory size and the number
of diﬀerent words present in the system. At the beginning of the convergence process, just after the
peak, Nd(t) is almost constant while the average inventory size is slightly decreasing (starting from
(1/√N ). Then both these quantities start to decrease until they reach 1 (at

(√N )), i.e. S(t)
O
the convergence).
(1/√N ) varies very slowly, we
Solving Eq. 5.2 in the temporal range just after tmax, where S(t)
realize that the system has already entered the convergence process, that is approximately exponential
with characteristic time of order N 3/2 (justifying the observed scaling). However, this exponential
decrease immediately triggers the growth of the success rate, so that the global convergence becomes
a self-enhancing process that results into a super-exponential approach to the absorbing state.

∼ O

∼ O

∼ O

102

CHAPTER 5. THE NAMING GAME

5.3 The Role of the Topology

The mean-ﬁeld case is, from many points of view, rather unrealistic. The agreement process described
by the Naming Game model is, indeed, an example of social dynamics, that is likely to take place on
more realistic topological structures like those characterizing social networks. We expect the topology
to have an eﬀect on the dynamics, in particular on the time required to reach the absorbing state and
on the process of words propagation. It is thus interesting to study the Naming Game on diﬀerent
topologies, expecially on complex networks, whose structure presents properties that are typically
observed in social environments.
Studies of dynamical processes on complex networks showed that the main properties governing the
overall dynamics are the small-world property and the presence of the hubs in heterogenous networks;
it is thus important to understand which is the impact of these properties on the dynamics. For this
reason, we start analyzing, in Section 5.3.1, the behavior of the Naming Game on low-dimensional
lattices, which we prove to be governed by coarsening dynamics; then we show that the presence
of topological shortcuts (i.e. the smallworld property) is responsible for a crossover from a slowly
converging process to a faster one (Section 5.3.2). Finally, in Section 5.3.3, a survey of the behavior
of the Naming Game on complex networks is considered, giving special attention to the role played
by the hubs in heterogeneous topologies.
The behavior of the Naming Game on diﬀerent topologies has recently attracted the attention of
researchers in the ﬁeld of A.I., who are interested in knowing which topology ensures the best trade-oﬀ
between a fast convergence to consensus and an optimization of the required memory per agent. For
this reason our work is expected to be relevant for the application of similar models to the description
and/or modeling of learning processes of robots [155, 151].

5.3.1 Coarsening dynamics on low-dimensional lattices

When the Naming Game is embedded in a regular d-dimensional lattice, the agents interact only with
their 2d neighbors, and the overall dynamical properties turn out to be very diﬀerent compared to the
mean-ﬁeld case. In particular, the time required by the system to reach the global consensus displays
a diﬀerent scaling with the size N , and the eﬀective size of the inventories is considerably diminished.
Actually, the existence of diﬀerent dynamical patterns are clearly visible in Fig. 5.2, where we have
reported the curves for the total number of words Nw(t), the number of diﬀerent words Nd(t) and the
success rate S(t) in the cases of mean-ﬁeld topology (circles), one-dimensional lattice (squares) and
two-dimensional lattice (triangles).
At the early stages of the dynamics, we observe a sharp growth of the success rate, meaning that
agents easily ﬁnd a local agreement with their neighbors; then, the dynamics seem to slow down and
the convergence is reached in a much larger time with respect to the mean-ﬁeld. We know that, in the
initial phase, the success rate is equal to the probability that two agents that have already played are
chosen again, and is proportional to t/E, where E is the number of possible interacting pairs (i.e. the
edges). In the mean-ﬁeld, E
N d, explaining for the
observed slopes of S(t) (Fig. 5.2): this quantity grows N times faster in ﬁnite dimensions. At larger
times, the eventual convergence is much slower in ﬁnite dimensions than in mean-ﬁeld.
The curves for Nw(t) and Nd(t) display in all cases a sharp increase at short times, a maximum for
a given time tmax and then a decay towards the consensus state in which all agents share the same
unique word, reached at tconv. The short time regime corresponds to the creation of many diﬀerent
words by the agents. After a time of order N , each agent has played typically once, and therefore

N 2, while in ﬁnite d-dimensional systems E

∝

∝

5.3. THE ROLE OF THE TOPOLOGY

103

tmax
tconv
tmax
tconv

α
∝ N

1,  α
1
β
∝ N

1,  β
1

≈ 1.0

≈ 3.0

tmax
tconv
tmax
tconv

α
∝ N

2,  α
2
β
∝ N

2,  β
2

≈ 1.0

≈ 2.0

12

10

8

10

4

10

t

10

0
10

0

2
10

4

10

N

0

10

10

2
N

4

10

Figure 5.5: Scaling of the time at which the number of words is maximal, and of the time needed to
obtain convergence, in 1 and 2 dimensions.

1.5).

3 in one dimension and β2 ≃

(N ) diﬀerent words have been invented (typically N/2). In mean-ﬁeld, each agent can interact with
O
all the others, so that it can learn many diﬀerent words; in contrast, in ﬁnite dimensions words can
spread only locally, and each agent has access only to a ﬁnite number of diﬀerent words. The total
memory used scales as N , and the time tmax to reach the maximum number of words in the system
scales as N αd, with α1 = α2 = 1 (Fig. 5.5). No plateau is observed in the total number of distinct
words since coarsening of clusters of agents soon starts to eliminate words. Furthermore, the system
reaches the consensus in a time tconv that grows as N βb with β1 ≃
2 in
two dimensions (while in the mean-ﬁeld case βMF ≃
In Fig. 5.6, we have represented a typical evolution of agents on a one-dimensional lattice, by displaying
one below the others a certain number of (linear) conﬁgurations corresponding to successive equally
separated temporal steps. Each agent with a unique word in memory is presented by a colored point,
while agents with more than one word in memory are shown in black. The ﬁgure clearly shows the
growth of clusters of agents with a unique word by diﬀusion of interfaces made of agents with more
than one word in the inventory. The fact that the interfaces remain small is however not obvious a
priori, and requires a deep analytical investigation that is presented in Appendix C.
The results exposed in Appendix C are conﬁrmed by numerical simulations as illustrated in Fig. 5.7:
(x, t) to ﬁnd an interface in position x at time t is a Gaussian
we have found that the probability
around the initial position, while the mean-square distance reached by the interface at time t follows
the diﬀusion law
= 2Dexpt/N , with experimental diﬀusion coeﬃcient Dexp ≃
The dynamical evolution of clusters in the Naming Game on a one-dimensional lattice can be described
(N ) thin
as follows: at short times, pairwise interactions create
interfaces (see the ﬁrst lines in Fig. 5.6). The interfaces then start diﬀusing. When two interfaces
meet, the cluster situated in between the interfaces disappears, and the two interfaces coalesce. Such
a coarsening leads to the well-known growth of the typical size ξ of the clusters as t1/2. The density
of interfaces, at which unsuccessful interactions can take place, decays as 1/√t, so that 1
S(t) also
decays in the same way. Moreover, starting from an initial conﬁguration in which agents have no
t/N (as
words, a time N is required to reach an average cluster size of order 1, so that ξ grows as
also shown in the Appendix C by the fact that the diﬀusion coeﬃcient is D/N ). This remark explains

(N ) small clusters, divided by

0.224.

x2
h

O

O

−

P

i

p

104

CHAPTER 5. THE NAMING GAME

Figure 5.6: Typical evolution of a one-dimensional system (N = 1000). Black color corresponds to
interfaces (sites with more than one word). The other colors identify diﬀerent single state clusters. The
vertical axis represents the time (from top to bottom, 1000
N sequential steps), the one-dimensional
snapshots are reported on the horizontal axis.

×

(N 3) needed to reach the global agreement, i.e. ξ = N .

the time tconv ∼ O
This framework can be extended to the case of higher dimensions, starting from the case d = 2.
Fig. 5.8 shows four diﬀerent snapshots of the system during the evolution. The interfaces of two-
dimensional clusters, although quite rough, are well deﬁned and their width does not grow in time,
which points to the existence of an eﬀective surface tension. We have substantiated this picture with
two types of measures: following Dornic et al.
[101], one is the measure of the time dependence in
the implosion of a cluster of a given radius; the other is the numerical computation of the equal-time
pair correlation function.
Let us consider the time dependent behavior of the linear size of a droplet, i.e. a cluster with the
form of a bubble in a sea of sites with a diﬀerent word. As predicted by the theory of coarsening
phenomena [54], the radius R(t) of the bubble decreases as
σt, where σ is a coeﬃcient related
to the surface tension (see Fig. 5.9). The equal-time pair correlation function C(r, t) in dimension
f (r/t1/2), where r is the linear
d = 2 (not shown) can be rescaled using the scaling function C(r, t)
(N ) is needed to
length, indicating that the characteristic length scale ξ grows as
initialize the agents to at least one word and therefore to reach a cluster size of order 1). This result
is in agreement with coarsening dynamics for non-conserved ﬁelds [54]. In terms of linear length scale
ξ, the convergence time tconv corresponds to the time necessary to reach ξ = N 1/d, thus we expect
N 1+2/d. This scaling has been veriﬁed by numerical simulations in d = 2 and d = 3 (not
tconv ∼
shown).

∼
t/N (a time

0 −

R2

p

p

O

Note that the obtained scaling law is the same of coarsening dynamics in non-equilibrium Ising
models, but an additional N factor comes from the diﬀerent timescale used (here, it corresponds to a
single interaction instead of N interactions). For the presence of surface tension and the evolution rule
with many possible states, the Naming Game model is similar to Potts-like models, but in the Naming

5.3. THE ROLE OF THE TOPOLOGY

105

3

t = 10

4

t = 10

5

t = 10

-40 -20 0
x

20 40

-40 -20 0
x

20 40

-40 -20 0
x

20 40

simul., N = 200
fit, Dexp = 0.224 

)
t
 
,
x
(
P

0.25

0.2

0.15

0.1

0.05

0

2
3×10
2
2×10
2
2×10
2
2×10
2
1×10

1
5×10

0

0

)
t
(
 
>

 

x
 
<

2

4
2×10

4
4×10

4
6×10

4
8×10

5
1×10

t

Figure 5.7: Evolution of the position x of an interface
(x, t).
distribution
P
x2
sive behavior
h
prediction.

(Top) Evolution of the
(Bottom) Evolution of the mean square displacement, showing a clear diﬀu-
0.224 in agreement with the theoretical

= 2Dexpt/N with a coeﬃcient Dexp ≈

AAABBB

· · ·

· · ·

i

.

Game the number of states (words, opinions, etc) is determined by the dynamics, not ﬁxed a priori.
This feature is determinant in the overall behavior of the system, the convergence time depending
both on the ordering process and the initial words spreading.
(N ),
In low-dimensional lattices, the time of the peak in the number of words scales as tmax ∼ O
thus it is dominated by the second part of the dynamics, that is considerably slower. Increasing the
dimension, the peak height and time increases, approximately as N √d, while the coarsening time
decreases as N 1+2/d. For d = 4, the global consensus is reached in a time that scales as for the mean-
(N 3/2)),
ﬁeld, but the mean-ﬁeld behavior is dominated by the scaling of the time of the peak (
that is smaller (
(N )) in all ﬁnite dimensions. Hence, the general non-equilibrium dynamics of the
Naming Game model in ﬁnite dimensional lattices is the result of the interplay between two diﬀerent
dynamical regimes (i.e. of creation and elimination of words).

O

O

5.3.2 Crossover to a fast-converging process in small-world networks

The precise knowledge of the dynamical behavior of the Naming Game model on low-dimensional
lattices, and in particular on the one-dimensional ring, makes possible to understand, by means of
simple arguments and numerical simulations, the eﬀect of the small-world property, that is a relevant
feature of real complex networks.
In the following, indeed, we investigate the eﬀect of introducing long-range connections which link
In other words, we study the Naming
agents that are far from each other on the regular lattice.
Game on the small-world model proposed by Watts and Strogatz [247]. The detailed description of
the model is reported in Section 2.4.1, however we recall that starting from a quasi-one-dimensional
banded network in which each node has 2m neighbors, the edges are rewired with probability p, i.e.
p represents the density of long-range connections introduced in the network. For p = 0 the network

106

CHAPTER 5. THE NAMING GAME

Figure 5.8: Four snapshots at diﬀerent times (lexicographic order from the top-left corner) for a two-
dimensional system. The form of the clusters (composed of agents with a unique word) clearly show
the presence of an eﬀective surface tension, associated with coarsening dynamics. The width of the
interfaces (in black) is very small as already seen for the one-dimensional model.

p

O

≪

≪

retains an essentially one-dimensional topology, while the random network structure is approached
as p goes to 1. At small but ﬁnite p (1/N
1), a small-world structure with short distances
between nodes, together with a large clustering, is obtained.
When p = 0, the system is one-dimensional and the dynamics proceeds by slow coarsening. At small
p, the typical distance between shortcuts is
(1/p), so that the early dynamics is not aﬀected and pro-
ceeds as in one-dimensional systems. In particular, at very short times many new words are invented
(N ), as in the
since the success rate is small. The maximum number of diﬀerent words scales as
other cases, while the average used memory per agent remains ﬁnite, since the number of neighbors
of each site is bounded (the degree distribution decreases exponentially [29], see Section 2.4.1).
The typical cluster dynamics on a small-world network is graphically represented in Fig. 5.10.1 As
long as the typical cluster size is smaller than 1/p, the clusters are typically one-dimensional, and
the system evolves by means of the usual coarsening dynamics. However, as the average cluster size
1/p, a crossover phenomena toward an accel-
reaches the typical distance between two shortcuts
erated dynamics takes place. Since the cluster size grows as
t/N , this corresponds to a crossover
(N/p2). For times much larger than this crossover, one expects that the dynamics is
time tcross =
dominated by the existence of shortcuts, entering a mean-ﬁeld like behavior. The convergence time is
thus expected to scale as N 3/2 and not as N 3. The condition in order for this picture to be possible is
exactly the small-world condition; indeed, the crossover time N/p2 has to be much larger than 1, and
much smaller than the consensus time for the one-dimensional case N 3, that together imply p
1/N .

p

O

O

∼

≫

1Following the analysis of Section 5.3.1, we call “cluster” a set of neighboring nodes (agents) with the same unique

word.

5.3. THE ROLE OF THE TOPOLOGY

107

2

2
π R
(t) / L
2
fit ∝  R0

 - σ t

0.2

0.15

2

L

 
/
 
)
t
(

2

R
π

0.05

0
0

4
1×10

4
2×10

4
4×10

4
5×10

4
6×10

4
7×10

4
3×10
t/N

Figure 5.9: A measure of the surface tension in the two-dimensional Naming Game. The initial
condition is a conﬁguration (N = L2 = 4002) with only two clusters, an internal droplet (a bubble)
of radius R0 = 100 and a surrounding sea with a diﬀerent word. Initially all agent already possess
one word, thus no new words are created, but the presence of surface tension at the interface between
the two clusters provokes the decrease of the bubble’s size. We have monitored the normalized area
πR2(t)/L2 as a function of the time. According to a coarsening dynamics, the radius R(t) decreases
as √t. Note that the linear trend is very clear even if the data refer to a single realization.

O

In summary, the small-world topology allows to combine advantages from both ﬁnite dimensional lat-
tices and mean-ﬁeld networks: on the one hand, only a ﬁnite memory per node is needed, in opposition
(N 1/2) in mean-ﬁeld; on the other hand the convergence time is expected to be much shorter
to the
than in ﬁnite dimensions. The theoretical predictions have been veriﬁed monitoring the behavior of
the usual global quantities. Figure 5.11 displays the evolution of the average number of words per
agent as a function of time, for a small-world network with average degree
= 8, and various values
of the rewiring probability p. While Nw(t) in all cases decays to N , after an initial peak whose height
is proportional to N , the way in which this convergence is obtained depends on the parameters. At
1/√t is observed due to the one-dimensional
ﬁxed N , for p = 0 a power-law behavior Nw/N
coarsening process. As soon as p
1/N however, we observe deviations getting stronger as p is
increased: the decrease of Nw is ﬁrst slowed down after the peak, but leads in the end to an very fast
convergence. The eﬀect is more evident for larger p. Moreover, increasing the size of the system the
convergence gets slower.

k
h

≫

−

∝

1

i

As previously mentioned, a crossover phenomenon is expected when the one-dimensional clusters
reach sizes of order 1/p, i.e. at a time of order N/p2. Since the agents with more than one word
in memory are localized at the interfaces between clusters, their number is
(N p). The average
excess memory per site (with respect to global consensus) is thus of order p, so that one expects
1)/p for various values
Nw/N
of p and N collapse when tp2/N is of order 1. On the other hand, Fig. 5.12-B indicates that the
convergence towards consensus is reached on a timescale of order N βSW , with βSW ≈
0.1, close
to the mean-ﬁeld case N 3/2 and in strong contrast with the N 3 behavior of purely one-dimensional
systems. Note that the time to converge scales as p−1.4±.1, that is consistent with the fact that for

(tp2/N ). Figure 5.12-A indeed shows that the data of (Nw/N

1 = p

1.4

O

−

±

−

G

108

CHAPTER 5. THE NAMING GAME

Figure 5.10: A naive representation of clusters growth in the small-world model of Watts and Strogatz.
A cluster (in red) starts to expand locally by coarsening dynamics like in dimension one. When the
size of the cluster is of the order of the average distance between shortcuts, long-range interactions
take place. The eﬀect of these long-range interactions is that of boosting up the dynamics.

p of order 1/N one should recover an essentially one-dimensional behavior with convergence times of
order N 3.
In the small-world regime, the system develops a plateau in the total number of words (after the peak
and before the convergence), whose duration increases with the size N . However, during this plateau
the system evolves continuously towards consensus by elimination of redundant words, as evidenced
by the continuous decrease in the number of distinct words displayed in Fig. 5.13-A. It shows that
curves for various system sizes and values of p collapse when correctly rescaled around the crossover
time N/p2.
The combination of the results concerning average used memory and number of distinct words cor-
responds to a picture in which clusters of agents sharing a common unique word compete during the
time lapse between the peak and the ﬁnal consensus. It is thus interesting to measure how the average
cluster size evolves with time and how it depends on the rewiring probability p. Figure 5.13-B allows
evolution for the one-dimensional case and for ﬁnite p. At p = 0, a pure
to compare the cluster size
√t is observed. As p increases, deviations are observed when time reaches the
coarsening law
crossover p2/N , at a cluster size 1/p, as was expected from the intuitive picture previously developed.
As expected, the collapse of the curves of
Another interesting remark concerns the slowing down of the curves after the peak and before the
convergence. This is possibly related to the ﬁrst interactions between clusters and shortcuts. When
a cluster touches a shortcut, the presence of a branching point slows down the interface movement.
Thus, the clusters are locally more stable, due to the presence of an eﬀective ’pinning’ of interfaces
near a shortcut. This eﬀect is reminiscent of what happens for the Ising model on small-world net-
works [52] where, at low temperature, the local ﬁeld transmitted by the shortcuts delays the passage
of interfaces. Unlike Ising’s zero temperature limit, however, the present dynamics only slows down
and is never blocked into disordered conﬁgurations. The idea of interfaces pinning at nodes playing
as branching points is discussed in more detail for tree structures in the next section.

p vs. tp2/N takes place for tp2/N of order 1.
i

i ∝

s
h

s
h

s
h

i

5.3. THE ROLE OF THE TOPOLOGY

109

Increasing p

0

10

-1

10

1
-
 

N

/

 

w
N

-2

10

-3

10

0

10

1

10

2

10

t/N

3

10

4

10

Figure 5.11: Average number of words per agent in the system, Nw/N as a function of the rescaled
= 8 and N = 103 nodes, for various values of p. The
time t/N , for small-world networks with
curve for p = 0 is shown for reference, as well as p = 5.10−3, p = 10−2, p = 2.10−2, p = 4.10−2,
p = 8.10−2, from bottom to top on the left part of the curves.

k
h

i

5.3.3 Naming Game on complex networks

In this section we expose the main results on the dynamics of the minimal Naming Game model on
complex networks. Before entering into the details of the analysis, it is worth noting that the minimal
Naming Game model itself, as described in Section 5.2.1, is not well-deﬁned on general networks. On
regular topologies, the number of neighbors of a node is ﬁxed, thus any possible method used to choose
at random a pair of neighboring agents to interact is completely equivalent. In a general network,
on the contrary, diﬀerent nodes possess a variable number of neighbors, therefore it is important to
take notice of the strategy used to draw the pairs of agents in interaction, since it can produce a
diﬀerent dynamical behavior. When choosing a pair, one should specify which player is chosen ﬁrst,
the speaker or the hearer.
On a generic network with degree distribution P (k), the degree of the ﬁrst chosen node and of its
chosen neighbor are distributed respectively according to P (k) and to kP (k)/
. The second node will
i
therefore have typically a larger degree, and the asymmetry between speaker and hearer can couple to
the asymmetry between a randomly chosen node and its randomly chosen neighbor, leading to diﬀerent
dynamical properties. This aspect of the dynamical processes evolving on irregular topologies and
networks has been ﬁrst noticed by Suchecki et al.
[234] and Castellano et al. [68, 69] in the case of
the Voter model. This is particularly relevant in heterogeneous networks, in which the neighbor of a
randomly chosen node is likely to be a hub.
This remark on the asymmetry of dynamical processes on networks suggests to deﬁne three diﬀerent
pair selection strategies for the Naming Game:

k
h

•

•

A randomly chosen speaker selects randomly a hearer among its neighbors. This is probably the
most natural generalization of the original rule. We call this strategy direct Naming Game. In
this case, larger degree nodes will preferentially act as hearers.

The opposite strategy, called reverse Naming Game, can also be carried out: we choose the
hearer at random and one of its neighbors as speaker. In this case the hubs are preferentially
selected as speakers.

110

80

70

60

50

40

20

10

p
/
)
1
-
N

/
)
t
(

w
N

(

30

CHAPTER 5. THE NAMING GAME

0
10

N1

N2 N3

B)

p=0.01
p=0.02
p=0.04
p=0.08

6

4

p
/
)
1
-
N

/
)
t
(

w
N

(

2

p=0.01
p=0.02
p=0.04
p=0.08

2

t p

/N

1

-1

10

1
-
N

/
)
t
(

w
N

-2

10

10

10

8

10

6

10

10

4
10

2

2

10

10

-3
10

-2

A)

0
10

-4

-2

10

2

t p

/N

0

10

tconv

3

10

4

10

N

5

10

0
10

1.4

t/N

2
10

Figure 5.12: (A) Rescaled curves of the average number of words per agent in the system, in order
to show the collapse around the crossover time N/p2. For each value of p, two values of the system
size (N = 104 and N = 105) are displayed. The curves for diﬀerent sizes are perfectly superimposed
before the convergence. (B) Convergence at large times, shown by the drop of Nw/N
1 to 0: the
time is rescaled by N 1.4. For each p, three diﬀerent sizes (N1 = 103 for the left peak, curves in black,
N2 = 104 for the middle peak, curves in blue, and N3 = 105, right peak, curves in red) are shown. On
the N 1.4 scale, the convergence becomes more and more abrupt as N increases. The inset displays the
convergence time as a function of size for p = 0 (bullets), p = 0.01 (squares), p = 0.02 (diamonds),
p = 0.04 (triangles), p = 0.08 (crosses); the dashed lines are proportional to N 3 and N 1.4.

−

•

A neutral strategy to pick up pairs of nodes is that of considering the extremities of an edge
taken uniformly at random. The roles of speaker and hearer are then assigned randomly with
equal probability among the two nodes.

i

k
h

Figure 5.14 allows to compare the evolution of the direct and the reverse Naming Game for a heteroge-
neous network, a Barab´asi-Albert (BA) network with N = 104 agents and
= 4. In the case of the
reverse rule, a larger memory is used although the number of diﬀerent words created is smaller, and
a faster convergence is obtained. This corresponds to the fact that the hubs, playing principally as
speakers, can spread their words to a larger fraction of the agents, and remain more stable than when
playing as hearers, enhancing the possibility of convergence. Similarly to the case of the Voter model
[68, 69], the scaling laws of the convergence time for direct and reverse strategies seem to be the same
only in some very special cases (power-law degree distribution with exponent γ = 3); however, we do
not dispose of an accurate study of the reverse NG properties. This is due to the fact that from the
point of view of a realistic interaction among individuals or computer-based agents, the direct Naming
Game, in which the speaker chooses a hearer among its neighbors, seems somehow more natural than
the other ones. For this reason we have focused on the direct Naming Game. In future work we will
study more in detail the similarities and diﬀerences of the three strategies.

Global quantities -

As already done for the other topologies, we study the global behavior
of the system looking at the temporal evolution of three main quantities: the total number Nw(t) of
words in the system, the number of diﬀerent words Nd(t), and the rate of success S(t). In Fig. 5.15,
we report the curves of the number of words (Nw(t) and Nd(t)) for homogeneous ER networks (left)
and heterogeneous BA networks (right) with N = 103, 104, 5
= 4.
The corresponding data for the mean-ﬁeld case (with N = 103) are displayed as well for reference.

104 nodes and average degree

k
h

i

·

5.3. THE ROLE OF THE TOPOLOGY

111

2

10

1

10

0

10

-1

10

-2

10

)
p
N

(
/
 

N

d

A)

p=0.01
p=0.02
p=0.04
p=0.08

B)

-1

10

-2

10

-3

10

-4

10

-5

10

N
/
p
>
s
<

10

-6
10

-4

p=0.005
p=0.01
p=0.04
p = 0.08

-4

10

-3

10

-2

10

0

10

1

10

2

10

2
t p

/N

-2

10

2

tp

/N

0
10

Figure 5.13: (A) Number of diﬀerent words in the system as a function of time for
= 8, p =
10−2, 2.10−2, 4.10−2, 8.10−2 and increasing sizes. Data have been rescaled in order to collapse the
curves around the crossover time N/p2. Two values of the system size (N = 104 and N = 105) are
displayed for each p. (B) Evolution of the cluster size for N = 104 and various values of p. The curves
are rescaled around the crossover region.

k
h

i

The curves for the average use of memory Nw(t) show a rapid growth at short times, a peak and then
a plateau whose length increases as the size of the system is increased (even when time is rescaled by
the system size, as in Fig. 5.15). The time and the height of the peak, and the height of the plateau,
are proportional to N . A systematic study of the scaling behavior with the size of the system for these
quantities is reported in Fig. 5.16, which shows that the convergence time tconv scales as N β with
1.4 for both ER and BA. The apparent plateau of Nw does however not correspond to a steady
β
state, as revealed by the continuous decrease of the number of diﬀerent words Nd in the system: in
this re-organization phase, the system keeps evolving by elimination of words, although the total used
memory does not change signiﬁcantly.

≃

±

≃

∼

1.4

k
h

0.1 for various

Note that observed scaling laws for the convergence time is a general robust feature that is not
aﬀected by other topological details (average degree, clustering, etc), and more surprisingly it seems
to be independent of the particular form of the degree distribution. We have indeed checked the value
, clustering, and exponents γ of the degree distribution
of the exponent β
i
k−γ for scale-free networks constructed with the uncorrelated conﬁguration model. These
P (k)
parameters have instead an eﬀect on other quantities such as the time and the value of the maximum
of memory (that will be analyzed later).
The ubiquity of the scaling exponent β

1.4 could be related to the fact that all these networks
present the small-world property. In many equilibrium and non-equilibrium statistical physics models
deﬁned on general networks, the small-world property is suﬃcient to ensure a mean-ﬁeld like behavior
1.5) may
of the system. In the present case, the discrepancy with the mean-ﬁeld exponent (βMF ≃
be due to logarithmic corrections that are unlikely to be captured using numerical scaling techniques.
Comparing Figures 5.15-5.16 with those for the mean-ﬁeld (MF) topology and the regular lattices re-
ported in Sections 5.3.1-5.3.2, some important analogies and diﬀerences emerge. Thanks to the ﬁnite
average connectivity, the memory peak scales only linearly with the system size N , and is reached
(N 1.5) for peak height and time) but similarly to the ﬁnite
after a time
dimensional case. The MF plateau observed in the number of diﬀerent words, is replaced here by
a slow continuous decrease of Nd with an almost constant memory used. With respect to the slow

(N ), in contrast with MF (

O

O

≃

112

CHAPTER 5. THE NAMING GAME

1.6

1.4

N

/
)
t
(

w
N

1.2

1
0
10

N

/
)
t
(

N

d

-1

10

-2

10

10

-3
0
10

reverse NG
direct NG

1

10

2
10

t/N

3
10

Figure 5.14: Total memory Nw (top) and number of diﬀerent words Nd (bottom) vs. rescaled time
for two diﬀerent strategies of pair selection on a BA network of N = 104 agents, with
= 4. The
reverse NG rule (black full line) converges much faster than the direct rule (red dashed line). Note
that the two strategies do not lead to the same scaling laws with the system size for the convergence
time (not shown).

k
h

i

coarsening process observed in ﬁnite dimensional lattices on the other hand, the existence of short
paths among the nodes speeds up the convergence towards the global consensus. Therefore, com-
plex networks exhibiting small-world properties constitute an interesting trade-oﬀ between mean-ﬁeld
”temporal eﬃciency” and regular lattice ”storage optimization”.
The success rate S(t) is displayed in Figure 5.17-A for ER (top) and BA (bottom) networks with
N = 103 (red full line), and 104 (blue dashed line) agents and
= 4. The success rate for the
mean-ﬁeld (N = 103) is also reported (black dotted lines). In both networks the success rate increases
linearly at very short times (see also Fig. 5.17-B) then, after a plateau similar to the one observed for
Nw, it increases on a fast timescale towards 1. At short times most inventories are empty, so that the
success rate is equal to the probability that two agents interact twice, i.e. t/E, where E = N
/2
i
is the number of possible interacting pairs. The curves, for BA networks in Fig. 5.17-B, give slopes
N . Compared to the mean-ﬁeld case, in which
k
in agreement with the theoretical prediction 2/
i
h
E =
(N ), no inventory is empty anymore,
words start spreading through unsuccessful interactions and S(t) displays a bending.

(N 2), the initial success rate grows faster. When t

∼ O

k
h

k
h

O

i

Clusters statistics -

Without entering the detailed analysis of the behavior of clusters of
words, for which we refer to Ref. [91], it is worthy to spend some words on this aspect of the Naming
Game dynamics. We have called ”cluster” any set of neighboring agents sharing a common unique
word. In Section 5.3.1, we have shown that, in low-dimensional lattices, the dynamics of the Naming
Game proceeds by formation of such clusters, that grow through a coarsening phenomenon: the aver-
age cluster size (resp. the number of clusters) increases (resp. decreases) algebraically with time. As
shown instead in Fig. 5.18, for both models (ER and BA) the normalized average cluster size remains
very close to zero (in fact, of order 1/N ) during the re-organization phase that follows the peak in the
number of words, and converges to one with a sudden transition. The same behavior is shown also by
the number of clusters Ncl(t), that decreases to one very sharply.
The emerging picture is not that of a coarsening or growth of clusters, but that of a slow process of

5.3. THE ROLE OF THE TOPOLOGY

113

1
10

N

/
)
t
(

w
N

0
10

0

10
0
10

N

/
)
1
-
)
t
(

N

(

d

-1

10

-2

10

-3

10

10

-4
10

0

1
10

3

4

ER, 10

ER, 10

4

ER, 5.10
3
MF, 10

3

4

BA, 10

BA, 10

4

BA, 5.10
3
MF, 10

1
10

2
10

3

10

1
10

2
10

3
10

0
10
0

0

10

10

-1

10

-2

10

-3

10

3

4

BA, 10

BA, 10

4

BA, 5.10
3
MF, 10

3

4

ER, 10

ER, 10

4

ER, 5.10
3
MF, 10

1
10

2
10

t/N

3

10

10

-4
0
10

1
10

2
10

t/N

3
10

Figure 5.15: ER random graph (left) and BA scale-free network (right) with
= 4 and sizes
N = 103, 104, 5.104. Top: evolution of the average memory per agent Nw/N versus rescaled time t/N .
For increasing sizes a plateau develops in the re-organization phase preceding the convergence. The
height of the peak and of the plateau collapse in this plot, showing that the total memory used scales
1)/N is plotted
with N . Bottom: evolution of the number of diﬀerent words Nd in the system. (Nd −
in order to emphasize the convergence to the consensus with Nd = 1. A steady decrease is observed
even if the memory Nw displays a plateau. The mean-ﬁeld (MF) case is also shown (for N = 103) for
comparison.

k
h

i

correlations between inventories, followed by a multiplicative process of cluster growth triggered by
a sort of symmetry breaking event in the success probability of the words (in favor of the word that
will ultimately survive).

Eﬀect of the degree heterogeneity -

Global properties of dynamical processes are often
aﬀected by the heterogeneous character of the network topology [203, 102]. We have shown however
that the global dynamics of the Naming Game is similar on heterogeneous and homogeneous networks.
Nonetheless, a more detailed analysis reveals that agents with diﬀerent degrees present very diﬀerent
activity patterns, whose characterization is necessary to get additional insights on the Naming Game
dynamics [91, 92].
Let us ﬁrst consider the average success rate Sk(t) of nodes of degree k; at the early stages of the
dynamics it can be computed using simple arguments. The probability of choosing twice the edge
(i, j) is

i.e. the probability of choosing ﬁrst i (1/N ) then j (1/ki) or viceversa. Neglecting the correlations
between ki and kj, one can average over all nodes i of ﬁxed ki = k, obtaining

t
N

1
ki

+

1
kj (cid:19)

,

(cid:18)

Sk(t)

t
N

≃

1
k

+

1
k

.

(5.3)

(5.4)

(cid:18)
Eq. 5.4 show that, at the very beginning, the success rate grows linearly but the eﬀect of the degree
. The same argument
heterogeneity is partially screened by the presence of the constant term
i

1/k
h

(cid:29)(cid:19)

(cid:28)

114

CHAPTER 5. THE NAMING GAME

10

10

8

6

4

10

10

10

2

10

6

4

10

10

2

10

t

 

x
a
wm
N

tmax
tconv
t ∝ N
t ∝ N

α

,  α ≈ 1.0
β
,  β ≈ 1.4

max  ∝ N

γ

Nw

,  γ ≈ 1.0

ER

ER

BA

BA

10

0
10

0

3
10
N

1

10

2

10

4

10

5

10

1

10

2

10

4

10

5

10

6

10

3
10
N

Figure 5.16: (Top) Scaling behavior with the system size N for the time of the memory peak (tmax)
and the convergence time (tconv) for ER random graphs (left) and BA scale-free networks (right) with
= 4. In both cases, the maximal memory is needed after a time proportional to
average degree
the system size, while the time needed for convergence grows as N β with β
1.4. (Bottom) In both
networks the necessary memory capacity (i.e. the maximal value reached by Nw) scales linearly with
the size of the network.

k
h

≃

i

can be used to predict that the success rate should be essentially degree independent for larger times.
S(t) is indeed always given by two terms, of which only that referring to the node playing as speaker
contains an explicit dependence on 1/k.

−

Another interesting point concerns the memory peak. In Fig. 5.19 we have computed the height of
the memory peak reached by diﬀerent classes of nodes, depending on the degree, and we have found
that it is larger for nodes of larger degree. More precisely, the maximal memory used by a node
of degree k is proportional to √k (see bottom panel in Fig. 5.19). This is in agreement with what
1 and the maximal
already observed for the mean-ﬁeld case, in which all agents have degree k = N
value of the total memory Nw scales indeed as N √k = N 3/2. Note however that in the general case,
the estimation of the peak of Nw is not as straightforward. This peak is indeed a convolution of the
peaks of the inventory sizes of single agents, that have distinct activity patterns and may reach their
maximum in memory at diﬀerent temporal steps.
The knowledge of the average maximal memory of a node of degree k is not suﬃcient to understand
which degree classes play a major role in driving the dynamics towards the consensus. More insights
on this issue can be obtained observing the behavior of the total number of diﬀerent words in each
degree class. A detailed analysis is reported in Ref. [91], in which we show that low degree classes
have a larger overall number of diﬀerent words. This is due to the fact that during the initial phase,
in which words are invented, low degree nodes are more often chosen as speakers and invent many
diﬀerent words. The hubs need individually a larger memory, but as classes they retain a smaller
number of diﬀerent words. Then, words are progressively eliminated among low-k nodes while the
hubs, which act as intermediaries and are in contact with many agents, still have typically many words
in their inventories. In this sense, the ”super-spreader” role of the hubs allows a faster diﬀusion of
words throughout the network and their property of connecting agents with originally diﬀerent words
helps the system to converge. The very ﬁnal phase consists in the late adoption of the consensus by
the lowest degree nodes, in a sort of ﬁnal cascade from the large to the small degrees.

5.3. THE ROLE OF THE TOPOLOGY

115

)
t
(
S

)
t
(
S

1

0,8

0,6

0,4

0,2

0

1

0,8

0,6

0,4

0,2

0

m=2
fit S(t) = 0.00053 t
m = 4
fit S(t) = 0.00026 t
m = 8
fit S(t) = 0.00013 t

ER

3
ER, N = 10
4
ER, N = 10

MF, N = 10

3

3
10

BA

3
BA, N = 10
4
BA, N = 10

MF, N = 10

3

3
10

0.2

0.15

)
t
(
S

0.1

0.05

0
0

2
10

2
10

t/N

50

100

200

250

300

150
t

Figure 5.17: (Left) Temporal evolution of the success rate for ER random graphs (red continuous
= 4 and sizes N = 103 and 104. The
line) and BA scale-free networks (blue dashed line) with
dotted black line refers to the mean-ﬁeld case (N = 103). (Right) BA network, N = 103. The short
= 16
k
time behavior of the success rate S(t) is shown for
i
h
N .
k
(triangles). The curves are linear, with a slope that is in agreement to the predicted value 2/
i
h

= 8 (squares), and

= 4 (circles),

k
h

k
h

k
h

i

i

i

Eﬀect of the average degree and clustering -

Social networks are generally sparse graphs,
but their structure is often characterized by high local cohesiveness, that is the result of a very natural
transitive property of social interactions [137]. The simplest way to take into account these features
on the dynamics of Naming Game is that of studying the eﬀects of changing the average degree and
the clustering coeﬃcient of the network. Fig. 5.20 displays the eﬀects of increasing the average degree
on the behavior of the main global quantities. In both ER (left) and BA (right) models, increasing
the average degree provokes an increase in the memory used, while the global convergence time is
decreased. More precisely, the dependence of the height N max
and the time tmax of the memory
w
with ﬁxed population is approximately power-law, with sub-linear behavior
peak as function of
[91]. This remark suggests that the linear scaling for the memory peak properties (N max
N α and
N α with α = 1) are altered by an increase in the average degree (not shown), as expected
tmax ∝
by the fact that increasing
brings the system closer to the mean-ﬁeld behavior where the scaling
of these quantities is non-linear (αMF = 1.5). It is remarkable that the behavior of the convergence
time with N (i.e. a power-law N β with β
1.4) is instead very robust. This is possibly due to the
fact that, in contrast with the power-law dependence of the peak, the convergence time depends only
logarithmically on the average degree.
Note also that the average memory used by a node of ﬁxed degree is larger for larger average degree
(not shown), therefore such a global argument can also be extended to a degree based analysis. The
curves of the success rate (not shown) are consistent with the previous analysis.

w ∝

k
h

k
h

≈

i

i

We are now interested to the eﬀects due to the variation of the clustering coeﬃcient. First, the
clustering is slightly changing when changing the average degree, but its variation is small enough
for the two eﬀects to be studied separately. Here we use some other mechanisms to enhance clus-
tering, summarized in the following two models with tunable clustering: the clustered Erd¨os-R´enyi
(CER) random graphs, and mixed BA-DMS model. These networks have been compared to ER and
BA networks with the same size and average degree. The mixed BA-DMS model is obtained as a
generalization of the preferential attachment procedure, in the spirit of the Holme-Kim model [143]:
starting from m connected nodes (with m even), a new node is added at each time step; with prob-

116

3

4×10

3

3×10

l
c

N

3

2×10

3

1×10

BA

BA

1

0.8

0.6

0.4

0.2

/

N
>
s
<

m = 2
m = 4
m = 8

0
0
10

1

10

CHAPTER 5. THE NAMING GAME

<k> = 4
<k> = 8
<k> = 16

m = 2
m = 4
m = 8

3

4×10

3

3×10

l
c

N

3

2×10

3

1×10

ER

0

1

0.8

0.6

0.4

0.2

/

N
>
s
<

ER

<k> = 4
<k> = 8
<k> = 16

2

10
t/N

3

10

4
10

0
10

4

5

10

6
10
t/N

7

10

8

10

Figure 5.18: Number of clusters Ncl and normalized average cluster size
networks (right) and BA networks (left) with N = 104,
k
h
(crosses).

= 4 (circles),

k
h

i

/N vs.
s
h
i
= 8 (squares),
i

time for ER
= 16
k
h

i

−

−

−

−

−

O

q)(k

1)] +

m)/[k(k

ability q it is connected to m nodes chosen with the preferential attachment rule (BA step), and
with probability 1
q it is connected to the extremities of m/2 edges chosen at random (DMS-like
step). Only the clustering spectrum is diﬀerent with respect to BA and DMS, it can be computed as
c(k) = 2(1
(1/N ) [28]. Changing m and q allows to tune the value of the
clustering coeﬃcient.
Since the ER model also displays a low clustering, we consider moreover a purposely modiﬁed version
of this random graph model (Clustered ER, or CER model) with tunable clustering. Given N nodes,
each pair of nodes is considered with probability p; the two nodes are then linked with probability
Q while, with probability Q, a third node (which is not already linked with either) is chosen
1
and a triangle is formed. The clustering is thus proportional to Q (with p
(1/N ) we can ne-
glect the original clustering of the ER network) while the average degree is approximately given by
(2Q + 1)pN Note that, in order to compare an ER and a CER network
[3Q + (1
k
h
with the same
Figure 5.21 shows the eﬀect of increasing the clustering at ﬁxed average degree and degree distribu-
tions: the number of diﬀerent words is not changed, but the average memory used is smaller and the
convergence takes more time. Moreover, the memory peak at ﬁxed k is smaller for larger clustering
(not shown): it is more probable for a node to speak to 2 neighbors that share common words because
they are themselves connected and have already interacted, so that it is less probable to learn new
words. At ﬁxed average degree, i.e. global number of links, less connections are available to transmit
words from one side of the network to the other since many links are used in “local” triangles. The
local cohesiveness is therefore in the long run an obstacle to the global convergence. This eﬀect is
similar to the observation of an increase in the percolation threshold in clustered networks, due to the
fact that many links are “wasted” in redundant local connections [223].

Q)] pN
−
, we therefore tune p for the construction of the corresponding CER.
k
i
h

∼ O

i ≃

≃

Eﬀect of hierarchical structures -

In the previous sections we have argued that networks
with small-world property have fast (mean-ﬁeld like) convergence after a re-organization phase whose
duration depends on other properties of the system. The small-world property holds when the diam-
eter of the network grows slowly, i.e.
logarithmically or slower, with the size N . However, another
requirement is necessary: the small-world must be generated by shortcuts connecting regions of the

5.3. THE ROLE OF THE TOPOLOGY

117

k=5
k=20
k=50
k=100

1

10

t/N

3

10

4

10

8

6

4

k

N

/
)
t
,
k
(

w
N

2

0
10

0

 
)
k
(

x
a
wm
N

2

10

1

10

0

10

1

10

2

10

k

3

10

i

k
h

= 4), N = 5.104. (Bottom) Maximum memory used
Figure 5.19: BA model with m = 2 (i.e.
√k. (Top) Average memory used by
by a node as a function of its degree. The dashed line is
nodes of degree k, for various values of k. The lines show the total memory Nw(k, t) used by nodes
of degree k at time t, normalized by the number Nk of nodes of degree k. The circles correspond to
k/k0 showing the scaling of the peaks. Note that the values
the bottom curve (k0 = 5) rescaled by
of Nw(k, t)/Nk are averages over many runs that wash out ﬂuctuations and therefore correspond to
smaller values than the extremal values observed for N max

(k).

p

∝

w

network that are otherwise far away one from the other. From this point of view, shortcuts correspond
to the existence of long loops (see Fig. 5.22-A). When shortcuts, and corresponding long loops, are
absent the topological structure of the network possess an intrinsic metric ordering. In such a situa-
tion, regular structures like d-dimensional lattices admit a real geometric distance, whereas disordered
topologies are more generally associated to hierarchical structures.
On a hierarchical network, each node belongs in fact to a given sub-hierarchical unit and for going
from one node to another node in another sub-unit, it is necessary to follow a hierarchical path. In
the Naming Game, each sub-unit can converge towards a local consensus, which makes the global
consensus more diﬃcult to achieve (see Fig. 5.22-B). In other words, the dynamics slows down in the
passage between diﬀerent levels of hierarchy, with a behavior that resembles that observed in models
of glassy dynamics with traps [50] or in “hierarchical islands models” of diﬀusion in turbulent ﬂows
[253]. Note however that, unlike the Naming Game, in these models there are real energy barriers
obstructing the dynamics. The results of numerical simulations on network models with a strong
hierarchical structure are striking: the Naming Game converges very slowly, the number of diﬀerent
1 for several
words decreasing as a power law of the time (in Fig. 5.25 we have reported Nw(t)/N
hierarchical networks). The presence of hierarchy in a network is usually hard to quantify, but in
some cases, such as those of the networks represented in Fig. 5.23, it is implicitly introduced in the
generating procedure:

−

A. Regular or scale-free trees are clearly hierarchical structures (we have checked the behavior
of Cayley trees and BA scale-free trees obtained, as sketched in Fig. 5.23-A, by means of a
preferential attachment rule with m = 1 [17]);

B. For the DMS model with m = 2 [106], one adds at each step a new node which is connected
to the extremities of a randomly chosen edge, thus the causal structure of the tree introduces a
hierarchy (see Fig. 5.23-B);

118

CHAPTER 5. THE NAMING GAME

5

4

3

2

N

/
)
t
(

w
N

1
0
10

-1

10

N

/
)
t
(

N

10

d

-2

-3

10

10

-4
0
10

ER

ER

2,5

3

2

1,5

1
0
10

-1

10

-2

-3

10

10

BA

BA

<k> = 4 
<k> = 8
<k> = 16

1
10

2
10

t/N

<k> = 4
<k> = 8
<k> = 12

10

-4
0
10

3
10

1
10

2
10
t/N

3
10

Figure 5.20: ER networks (left) and BA networks (right) with N = 104 agents and average degree
= 4, 8, 16. The increase of average degree leads to a larger memory used (Nw, top) but a faster
k
h
convergence. The maximum in the number of diﬀerent words is not aﬀected by the change in the
average degree (bottom).

i

C. The deterministic scale-free networks are built starting with two nodes connected to a root. At
each temporal step n, two units (of 3n−1 nodes) identical to the network formed at the previous
step are added, and each of the bottom 2n nodes are connected to the root [19] (Fig. 5.23-C);

D. The Random Apollonian Networks (RAN) [10, 254] are embedded in a two-dimensional plane.
One starts with a triangle; a node is added and connected to the three previous nodes; at each
step a new node is added in one of the existing triangles (chosen at random) and connected to
its three edges, replacing the chosen triangle by three new smaller triangles (Fig. 5.23-D).

In the particular case of tree structures, the power-law decay can be justiﬁed with a more precise qual-
itative argument. In general, from the viewpoint of the Naming Game dynamics, a tree is formed by
two ingredients: linear structures on which the interfaces between clusters diﬀuse as in one-dimensional
systems and branching points at which the motion of interfaces slows down. Following the arguments
used in Section 5.3.1 and in Appendix C, on a linear structure we can model the motion of the inter-
faces between clusters of words as random walks. At branching points, however, the interfaces can in
principle interact with more than one cluster, thus the eﬀective hopping probability is decreased or,
in other terms, the mean waiting time between two successive steps increases. The average waiting
time can be computed as the inverse of the stationary probability for the local conﬁgurations of the
interface (as for a classic escape-over-a-barrier problem [74]). In principle, such probabilities can be
obtained by solving a truncated Markov chain for the transition rates for all possible moves of the
interface at the branching point (as we have done for one-dimensional systems in Appendix C). The
computation is actually very demanding even in simple situations such as that of an interface going
across a node of degree 3 (we have reported in Fig. 5.24 an example containing some of the transitions
one should take into account). However, from simple examples, we expect that increasing the degree
corresponds to a stronger eﬀective pinning of the interfaces and larger waiting times.
The above qualitative argument explains the diﬀusive behavior observed on regular trees, such as the

5.3. THE ROLE OF THE TOPOLOGY

119

BA-DMS

q=1 (BA)
q=0.75
q=0.5
q=0.25

N

/
)
t
(

w
N

2,5

1,5

3

2

1

0
10

N

/
)
t
(

N

d

-1

10

-2

10

1,6

1,4

1,2

1
0
10

-1

10

-2

10

ER-CER

ER-CER

<k> = 6, no clust.
<k> = 6, Q = 0.25
<k> = 10, no clust.
<k> = 10, Q = 0.75

10

-3
0
10

BA-DMS

2
10

10

-3
0
10

1
10

2
10
t/N

3
10

1
10
t/N

Figure 5.21: Eﬀect of clustering on the behavior of the total number of words Nw(t) and of the number
of diﬀerent words Nd(t) on random graphs (left) and scale-free networks (right) with N = 104. The
considered clustered random graphs (CER model, with clustering coeﬃcient proportional to Q) have
been compared to standard ER graphs with equal average degree (
= 6 and 10). Scale-free networks
k
h
have been generated using the mixed BA-DMS model, in which the clustering coeﬃcient is proportional
q. In both networks higher clustering leads to smaller memory capacity required but a larger
to 1
convergence time.

−

i

Cayley tree; on the other hand, on scale-free trees, such as the BA networks with m = 1, the behavior
is even slower, with a clearly subdiﬀusive exponent.
In the theory of random walks, subdiﬀusion can be associated with an anomalously long waiting time
between successive walks [51, 146, 248, 253]. According to our picture, this is exactly what happens
in a scale-free tree, where the degree of the nodes is broadly distributed. The interfaces make random
walks but they may be suddenly pinned at some branching points with waiting times that depend on
the degree of the nodes they try to by-pass. Consequently, the heterogeneity in the degree induces
that of the waiting times and the corresponding subdiﬀusive behavior.
Note that this argument holds only for trees, not for general hierarchical structures, whose local dy-
namics is more complicated preventing us from a detailed analysis.

Community structures -

In contrast with other non-equilibrium models, as those based
on zero-temperature Glauber dynamics or the Voter model [101, 52, 234, 70, 69], we do not ﬁnd
any signature of the occurrence of metastable blocked states in any relevant topology with quenched
disorder. Even when in several cases the total number of words displays a plateau whose length
increases with the system size, the number of diﬀerent words is continuously decreasing, revealing
that the convergence is not triggered by ﬂuctuations due to ﬁnite-size eﬀects, but it is the result of
an evolving self-organizing process. Such behavior makes the Naming Game a robust model of self-
coordinated communication in any structured population of agents.
Finding topological properties ensuring the existence of metastable states or blocked conﬁgurations
seems to be a non-trivial and intriguing task, that we try to investigate starting from the following
main remarks:

120

CHAPTER 5. THE NAMING GAME

Figure 5.22: (A) Sketch of a shortcut connecting two distant regions and reinterpretation as a long
loop. (B) Naive representation of a typical clusters organization in a hierarchical structure.

•

•

•

•

the model displays slow coarsening dynamics whenever there is the possibility of cluster forma-
tion, i.e. when topological constraints are strong enough to prevent words propagation;

highly clustered regions and cliques of nodes rapidly ﬁnd a local consensus;

at the interfaces between clusters, an eﬀective surface tension is generated;

close to bottlenecks the surface tension may increase, causing the ordering process to slow down.

According to this analysis, reasonable candidates for observing metastable states are networks with
strong community structures, i.e. networks composed of a certain number of internally highly con-
nected groups interconnected by few links working as bridges. An example of network with strong
community structure is represented in Fig. 5.26 (left):
fully connected cliques composed of c = 4
agents are interconnected by single edges. Figure 5.26 (right) reports the behavior of the Naming
Game on such a network, for diﬀerent clique’s size c. From simulations it turns out that, not only the
total number of words, but even the number of diﬀerent words has a plateau whose duration increases
with the size of the system. The number of diﬀerent words in the plateau equals the number of com-
munities, while the corresponding total number of words per node is about one, proving the existence
of a real metastable state in which the system reaches a long-lasting multi-vocabulary conﬁguration.
Indeed, each community reaches internal consensus but the weak connections between communities
are not suﬃcient for words to propagate from one community to the other. The chosen network
certainly has an extremely strong community structure, but preliminary studies on real networks of
scientiﬁc collaborations give results that are in qualitative agreement with our results (i.e. plateaus
are observed).
More precisely, when a network contains communities of diﬀerent sizes and the community structure
is not very strong, the corresponding curves Nw(t) and Nd(t) display a series of plateaus, with sharp
transitions in between. Several groups have recently put forward methods to distinguish diﬀerent lev-
els of community structures in real and computer generated networks exploiting dynamical processes
[12]
evolving on them (see the review articles in Refs. [193, 93]). For instance, Diaz-Guilera et al.
have used synchronization properties of non-linear oscillators (deployed on the nodes of a network) in
order to determine community structures at diﬀerent levels of resolution. Communities or groups of
highly interconnected nodes are more likely to synchronize, thus looking at the temporal evolution of
synchronization properties it is possible to identify communities at diﬀerent scales. Similar analyses

5.3. THE ROLE OF THE TOPOLOGY

121

Figure 5.23: Sketch of various generation procedures for models of hierarchical networks: (A) the
Barab´asi-Albert tree (BA model with m = 1); (B) DMS model with m = 2, i.e. only a new triangle
enter the system each time; (C) deterministic hierarchical network proposed in Ref. [19]; (D) random
apollonian network [10, 254].

have been carried out by Bornholdt et al. [211, 212] using Potts dynamics. In this case, the process
leading to the community detection is the same as for the Naming Game, i.e. a coarsening dynamics
of clusters with surface tension at the interfaces. Compared to Potts-based methods, the Naming
Game has the relevant property that we do not have to ﬁx the number of states in advance and the
strength of the eﬀective surface tension depends on the local topological constraints. Future studies
could be addressed to modify the Naming Game model in order to have a more appropriate tool for
community detection.

122

CHAPTER 5. THE NAMING GAME

Figure 5.24: A typical branching point at which clusters interfaces may be pinned down. The in-
creasing number of possible transitions for larger degree causes the eﬀective transition probability to
decrease.

5.4 Agents activity in heterogeneous populations

The aim of this section, based on the material presented in Ref. [92], is that of providing a detailed
statistical description of the internal dynamics of single agents, and its relation with the collective
behavior of the Naming Game model.
The analysis of simulations results points out that the internal dynamics of an agent depends strongly
on its degree, highly connected agents being much more active than low-degree nodes. The existence
of diﬀerent activity patterns is reﬂected in the shape of the distribution of the number of words stored
in the inventory of a node, that turns out to depend on the level of heterogeneity of the network. In
homogeneous networks such distribution is exponential for all agents, while highly-connected agents in
heterogeneous networks present a distribution with a clearly gaussian tail (half-normal distribution).
From the point of view of the evolution rule, this result shows that the role of the memory is diﬀerent
depending on the connectivity properties of single agents. The eﬀect on the dynamics are clearer if
we consider a closely related quantity, the cumulative distribution of the waiting times (or survival
probability) between two consecutive successful interactions, i.e. between two decisions taken by
the same agent.
Indeed, an exponential waiting time distribution is the signature of a poissonian
dynamics, while our results point out that the decision process associated with the internal activity
of the agents is intrinsically non-poissonian, and it turns out to be poissonian only in the special
case of a homogeneous network. This feature is completely new in non-equilibrium models of social
interactions, in which the interaction rules are usually deﬁned in such a way that the agents take
decisions at approximately constant rate.
Apart from the intrinsic interest for non-poissonian individual dynamics, our ﬁndings are interpreted
in order to understand the property of strong convergence towards the absorbing state that the model
exhibits in all small-world structures, independently of the degree heterogeneity.

5.4. AGENTS ACTIVITY IN HETEROGENEOUS POPULATIONS

123

0
10

-1

10

 
1
-
 

N

/
)
t
(

w
N

-2

10

BA tree (m=1)
DMS, m=2
RAN
BRV
BA, m=4

-3

10

1
10

2
10
t/N

3
10

Figure 5.25: Power-law decrease in the total number of words Nw(t) for the Naming Game on several
hierarchical networks: the Barab´asi-Albert scale-free tree (full line), the DMS model with m = 2
(dotted line), the deterministic scale-free network of Barab´asi, Ravasz and Vicsek (dot-dashed line),
the Random Apollonian Network (dot-dot-dashed line). The behavior of hierarchical networks are
compared with the mean-ﬁeld like behavior of a Barab´asi-Albert network with m = 4 (dashed line).
Note that all hierarchical networks show diﬀusive coarsening except for the scale-free tree, whose
behavior is subdiﬀusive.

5.4.1 Numerical results on agents activity

By means of numerical simulations, we characterize the activity patterns of an agent, focusing on
the dynamics of its inventory size, i.e.
the number of words (opinions, states, etc) of an agent.
In particular, our analysis is conceived for those topologies which present mean-ﬁeld like dynamics
(e.g. complete graph, homogeneous and heterogeneous random graphs, high-dimensional lattices, etc),
where we cannot clearly identify a coarsening process leading to the nucleation and growth of clusters
containing quiescent agents. In other topologies, as in low-dimensional lattices, the agents internal
activity is biased by the limited number of words locally available (Section 5.3.1). An example of the
diﬀerent activity patterns in diﬀerent topologies is reported in Fig. 5.27. In homogeneous networks
(e.g. ER random graphs), the nodes have similar topological properties, thus their activity patterns
are very similar as well. For heterogeneous networks, instead, highly connected nodes (hubs) play a
diﬀerent role in the dynamics compared to low degree nodes. The hubs are much more active, and
their activity is determinant to drive the system to a rapid collective agreement.
More precisely, they show opposite behaviors depending on the pairs selection strategy. As already
pointed out in Section 5.3.3, the asymmetry of the NG interaction rules becomes relevant in the case of
heterogeneous networks. In the direct Naming Game, that most naturally describes realistic speaker-
hearer interactions, the speaker is chosen with probability pk (where pk is the degree distribution of
. According to this selection
the network), while the hearer is chosen with probability qk = kpk/
i
criterion, the high-degree nodes are preferentially chosen as hearers. Using the opposite strategy, called
reverse Naming Game, the hubs are preferentially selected as speakers; whereas the neutral strategy
ensures that the roles of speaker and hearer are assigned with equal probability. Figure 5.28 shows that
the reverse strategy produces completely diﬀerent activity patterns compared to the direct one, with a

k
h

124

CHAPTER 5. THE NAMING GAME

1,6

1,4

1,2

N

/
)
t
(

w
N

1

0
10
1

N

/
)
t
(

N

d

0,1

3
, c = 10
N = 10

4
, c = 100
N = 10

1
10

2
10

3
10

4
10

5
10

1
10

2
10

3
10

3
, c = 10
N = 10

4
, c = 100
N = 10

4

3

2

1

0
10
0
10

-1

10

-2

10

0,01

0
10

1
10

3
10

2
10
t/N

4
10

5
10

0
10

1
10

2
10

3
10

t/N

Figure 5.26: (Left) A network with strong community structure. (Right) Metastable states in networks
with strong community structure. Each community is composed of c nodes so that there are N/c
communities.

rather low variability and the absence of high spikes in the number of words. No signiﬁcant diﬀerence
between hubs and low-degree nodes is visible. The reason is that the inventory size increases because
of a failure only if the node is playing as hearer. The speakers never add states to their inventories.
Hence, agents that preferentially play as hearers tend to be more unstable, amplifying the number of
states in the system. Using the direct strategy in heterogeneous networks favors the choice of the hubs
as hearers, the degree of the hubs being orders of magnitude larger than the average degree. This is
the reason of the large number of states stored in the inventory of the hubs for the direct strategy.

k
h

Pn(k

Pn(k

A ﬁrst quantity that clearly points out diﬀerences in the activity of nodes depending both on their
degree and on the topological structure of the network is the probability distribution
t) of the
|
number n of states stored in the inventory of nodes of degree k at time t. This means that the dis-
tribution is averaged over the class of nodes of given degree. Actually, as it is shown in Appendix D,
this quantity depends only parametrically on the time t. Fig. 5.29 (top) reports
t) for the case
|
of highly connected nodes in a heterogeneous network (the Barab´asi-Albert network), whereas the
same data for nodes of typical degree in a homogeneous network (the Erd¨os-R´enyi random graph)
are displayed in the bottom panel. In homogeneous networks the shape of the distribution does not
actually depend on the degree of the node, since all nodes have degree approximately equal to the
average degree
. In heterogeneous networks, instead, a deep diﬀerence exists between the behavior
i
of low and high degree nodes. Low degree nodes have no room to reach high values of n, thus their
distribution has a very rapid decay (data not shown); for high degree nodes, on the contrary, the
distributions extend for more than one decade and their form is much clearer.
Apart from the behavior of low degree nodes, it is clear that the functional form of the distribution
t) is diﬀerent in homogeneous and heterogeneous networks. In homogeneous networks the dis-
Pn(k
|
tribution is exponential, while in heterogeneous networks it decays faster, and is well approximated
by a half-normal distribution.
t) that an agent of degree k gets a
Another interesting quantity is the probability distribution
|
success in an interaction occurring when it has n states into the inventory, i.e. the value at which the
inventory is abruptly reset to 1. This quantity has an exponential shape in homogeneous networks
(Fig. 5.30-bottom) for suﬃciently high average degree, and a Weibull-like shape (Fig. 5.30-top) for
t) and
the case of heterogeneous networks (high-degree nodes). The existing relation between
|

Qn(k

Qn(k

5.4. AGENTS ACTIVITY IN HETEROGENEOUS POPULATIONS

125

BA, k = 414

BA, k = 10

t

n

t

n

60

50

40

30

20

10

60

50

40

30

20

10

0

0

0

0

60

50

40

30

20

10

0

0

6

4

2

0

0

5
2×10

5
4×10

5
6×10

5
8×10

6
1×10

5
2×10

5
4×10

5
6×10

5
8×10

6
1×10

ER,  k =  50

1D, k = 2

5
2×10

5
5
4×10
6×10
t

5
8×10

6
1×10

5
2×10

5
5
4×10
6×10
t

5
8×10

6
1×10

Figure 5.27: Examples of temporal series of the number of states at a given node. (Top) Series from
a BA network with N = 104 nodes and
= 10, for nodes of high degree (e.g. k = 414) and low
k
h
degree (e.g. k = 10). (Bottom) Series for nodes in ER random graph (N = 104,
= 50) and in a
one-dimensional ring (k = 2).

k
h

i

i

t) is straightforward: the probability distribution
|

t) of the level n at which a successful
Pn(k
|
interaction occurs is the product of the probability of having n states and the conditional probability
1
t) that an agent (of degree k) ﬁnds at time t a (temporary) agreement when it has n states;
Wk(n
|
t)=
i.e.
|

→
Qn(k

Wk(n

Qn(k

Pn(k

t).
|

t)
|

→

1

5.4.2 Theoretical interpretation and future work

{

τi}

Qn(k

(τ ). We call survival probability

t) and, consequently, that of
|

In Appendix D, we discuss a master equation approach for the jump process associated to the dynam-
ics of single agents, by means of which it is possible to derive the correct expression for the distribution
t). We recover here the same result using a naive argument,
Pn(k
|
based on the concept of survival probability in renewal processes, that is useful to clarify the role of
non-poissonian dynamics in relation with other types of non-equilibrium statistical models.
A renewal process [82] is a stochastic process characterized by a series of recurrent events that are
. The waiting times are mutually independent random variables with
separated by waiting times
T>(τ ) the probability that the renewal event
a common distribution
T
occurs after a waiting time at least equal to τ .
In physics, stochastic processes are usually coarse-grained models for some natural phenomenon, since
the observed waiting times statistics is the result of some peculiar properties of the underlying phe-
nomena. For instance, we observe power-law waiting time distributions in many natural phenomena
and in the models used to study or reproduce these phenomena (e.g in solar ﬂames [249, 14], ﬁnancial
markets [218, 169], anomalous transport [253], earthquakes [197, 15], etc). Distributions with Weibull
(and gaussian) tails are frequent in more general problems of queuing theory [121] and survival anal-
ysis [114]. On the contrary, models of statistical mechanics traditionally used in opinion dynamics
show exponentially shaped waiting time distributions (signature of a poissonian dynamics).
All these diﬀerent statistics are based on the factorization property of the corresponding stochastic
(renewal) processes. Let us denote h(τ ) the hazard function of the process, i.e. the rate of occurrence

126

CHAPTER 5. THE NAMING GAME

t

n

10

8

6

4

2

0

0

BA, k = 377

BA, k = 10

10

8

6

4

2

5
1×10

5
5
2×10
3×10
t

5
4×10

5
5×10

0

0

5
1×10

5
5
2×10
3×10
t

5
4×10

5
5×10

Figure 5.28: Example of temporal series for nodes activity in a Reverse Naming Game on a BA
network with
= 10. The activity of the hubs (left) is very low (they are preferentially chosen as
speakers) while that of low degree nodes (right) is the same as in the direct NG.

k
h

i

n

P

0.05

0.04

0.03

0.02

0.01

0

0
10

-1

10

n

P

-2

10

-3

10

-4

10

0

BA fit, a*exp(-bx

2
)

ER fit, a*exp(-b x)

20

40

60

80

100

10

20

30

40

50

n

Figure 5.29: Distribution of the number of words for a class of high-degree nodes in a BA network
(top) with
= 50. Both networks
have N = 104 nodes. The distributions have been computed during the re-organizational phase after
the peak in the number of words.

= 10 and for average degree nodes in a ER (bottom) with

k
h

k
h

i

i

of the renewal event at a (waiting) time τ . The survival probability, i.e. the probability that the event
occurs at time at least τ satisﬁes the following recursion equation,

whose general solution is

T>(τ + 1) =

T>(τ ) [1

−

h(τ )] ,

T>(τ ) =

τ
i=1 [1
−
τ
j=1 [1

∞
Q
τ =1

h(i)]

h(j)]

−

.

(5.5)

(5.6)

hQ
In the particular case of the Naming Game, a renewal event is identiﬁed with a successful interaction,
bringing back to 1 the inventory size of the node. The pair selection mechanism is purely poissonian,
thus an agent interacts with a precise constant rate (that is pk or qk depending on whether it plays
as speaker or as hearer). This poissonian external signal can be regarded as a discrete timing for
the internal activity of the nodes. Hence, apart from a time rescaling, the dynamics of the inventory

P

i

5.4. AGENTS ACTIVITY IN HETEROGENEOUS POPULATIONS

127

n
Q

10

n
Q

10

-1

10

10

-2

-3

-4

10

-5
0
0

10

10

-1

10

-2

-3

10

10

-4
0

γ = 1.8
γ = 1.7
BA < k > = 6
BA < k > = 10

γ
fit   y = a x exp[-b (x+1)

]

20

40

60

80

fit   y = a exp(-b x)

< k > = 10
< k > = 50
b = 0.055
b = 0.24

20

40

n

60

80

Figure 5.30: Probability distribution
t) of the number of states n at which an agent gets a
|
success, i.e. the inventory is reset to 1 state. For highly connected nodes in heterogeneous (top) and
nodes of typical degree in homogeneous networks (bottom). Same parameters as in Fig. 5.29.

Qn(k

T

Qn(k

t) and
|

T>(τ ) and
1
→

t), with the waiting time τ instead of the number of words n.
|

size, described in the previous section and in App. D, gives a good approximation of the waiting time
statistics related to the renewal events. The distributions
t) correspond respectively
Pn(k
|
to
(τ ). The hazard function has thus the same functional form of the success probability
Wk(n
In the Appendix D (and in Ref. [92]), we show that the success probability
t) assumes
|
diﬀerent forms depending on the underlying topology. In homogeneous networks, it turns out to be
almost independent of the number n of words stored in the inventory of the node; in heterogeneous
networks it is instead linearly proportional to n (for nodes of suﬃciently high degree k). Inserting in
Eq. 5.6 hazard functions with these functional forms, we can compute the corresponding expression
for
Let us consider a constant hazard function, from Eq. 5.6 the corresponding survival probability dis-
tribution is exponential, and consequently also
t) decreases exponentially with n. On the other
Pn(k
|
hand, when the hazard function grows linearly with the waiting time, with normalization constant
τ 2
2C ). This simple argument provides an explanation of the gaussian de-
C, we get
exp(
T>(τ )
−
t) observed for highly-connected nodes of heterogeneous networks (See
Pn(k
crease of the distribution
|
Appendix D for a more rigorous approach.)

T>(τ ), obtaining an approximate expression also for

Wk(n

Pn(k

t).
|

→

∝

1

A further remark concerns the relation between waiting times and poissonian processes. In general,
the agent-based models studied in statistical physics are spin-like models, in which an individual is
endowed with a variable, assuming a given set of values, each one corresponding to a diﬀerent state.
In such systems, single agent dynamics is intrinsically poissonian. For instance, in systems evolving
by means of Glauber dynamics, spin ﬂips at a site occur independently one of the other, i.e. they are
e−β∆H. The corresponding waiting time distribution
poissonian events with (Boltzmann) rate λ
(and survival probability) is exponential (as λ exp(
λt)). In the present model, on the contrary, the
internal activity of an agent is modeled in order to reproduce a sort of decision process based on infor-
mation storage, and the waiting time between successive decisions turns out to depend strongly on the

∝

−

128

CHAPTER 5. THE NAMING GAME

underlying topology. From the point of view of the global behavior it seems to be important: in the
direct strategy, the hubs drive the system to a fast convergence to the absorbing state, as a result of
the trade-oﬀ between their larger activity and their stronger inclination to reach an agreement (due
to their internal memory patterns).
The ﬁrst step toward a better comprehension of the role of non-poissonian dynamics is that of compar-
ing these results and the scaling properties of the convergence time with those for the reverse Naming
Game, in which the hubs have exponential waiting time distributions.

Finally, waiting time statistics is also used as a measure of the criticality in the behavior of
physical systems, individuals and natural phenomena; in particular, in relation with extreme events
[15]. Waiting time distributions with heavy-tails are signature of the absence of a characteristic scale on
which the events occur. For example, the theory that justiﬁes the observation of power-law distributed
waiting times between aftershocks in earthwakes is based on the Omori law [197], corresponding to a
hazard function inversely proportional to the waiting time. Actually, a success rate decreasing with
the time is necessary to get a broad waiting time distribution.
It should be interesting to modify the interaction rules of the Naming Game model (and thus the
hazard function) in order to change the shape of the waiting time distribution and in particular to
get a power-law one. Such a situation would correspond to a critical decision process, in which agents
might store a very large number of words, with an a priori unlimited memory requirement.

5.5. CONCLUSIONS

5.5 Conclusions

129

In the last part of this thesis, we have investigated a model of social dynamics, the Naming Game,
that can be considered an example of a new interesting class of dynamical processes, conceived to
describe the onset of global agreement in a population of individuals by means of pairwise negotiation
interactions and memory-driven decision processes. With respect to well-known models of social
dynamics that have been borrowed from statistical mechanics (e.g. majority rules models, Voter
model, etc), the Naming Game takes into account more realistic characteristics of social interactions,
conserving a suﬃcient level of simplicity that was a good quality of the former ones.
Thanks to this mixture of ingredients, the Naming Game (and possible variants of the model) seems
to be more appropriate than previous models for the study of heterogeneous populations of agents,
such as social networks, since the dynamics is the result of a strong interplay between topological
features and the internal properties of the agents. We have focused our attention on two aspects:

•

•

•

•

the dynamical features of the Naming Game on diﬀerent topologies;

single agents internal activity and its relation with the global behavior.

In order to understand the behavior of the model on complex networks, we have analyzed the im-
pact of the diﬀerent topological structures, starting from the rather unrealistic cases of the complete
graph (mean-ﬁeld) and the one-dimensional system. However, they turn out to be precious for the
conprehension of more complex topologies. They are, indeed, almost completely analytically solvable,
providing two opposite behaviors:

O

the mean-ﬁeld model is characterized by an initial super-spreading of words throughout the
(N 3/2) and corresponds to a state in
system, whose maximum is reached in a time tmax ∼ O
(√N ) words; then, a very fast convergence (i.e. more than
which each single agent possesses
(N 3/2);
exponential) takes place leading the system to the global consensus in a time tconv ∼ O
in the one-dimensional model, agents ﬁnd immediately a local consensus, many clusters of neigh-
boring agents with a common unique word start to grow, competing in a coarsening process driven
by the diﬀusion-coalescence process of the interfaces. Consequently, the maximum total number
of words, reached very quickly in
(N ) as well, but the global agreement
requires a time tconv ∼ O

(N ) steps, scales as

(N 3).

O

O

The second step towards the comprehension of the Naming Game dynamics has been provided by the
study of the Watts-Strogatz model [247]. The networks generated by this model are characterized by
a tunable parameter (the rewiring probability) that allows to interpolate between a one-dimensional
regular lattice and a homogeneous random graph. For non-zero rewiring probability, the model has
the small-world property, i.e. diﬀerent regions of the network are connected by shortcuts, so that the
average distance between nodes scales logarithmically with the network size. After an initial phase
during which words are created and small local clusters appear, the small-world property ensures their
propagation out of the local scale, boosting up the spreading process (contrarily to what happens in
low dimensional lattices where words spreading is purely diﬀusive).
The same acceleration of the dynamics is then observed in many other networks sharing the small-
world property, suggesting that it is suﬃcient to recover the high temporal eﬃciency observed in the
mean-ﬁeld system. For both the homogeneous and heterogeneous network models, we get a scaling law
N βSW , with exponent
for the convergence time tconv with the size N of the system of the type tconv ∼
1.5) may be due
approximately βSW ≃

1.4. The discrepancy with the mean-ﬁeld exponent (βMF ≃

130

CHAPTER 5. THE NAMING GAME

i

k
h

to logarithmic corrections. Moreover, small-world networks have higher memory eﬃciency than the
mean-ﬁeld model, since the peak in the total number of words scales only linearly with the size N .
This is due to the fact that these networks are sparse (their average degree
is small compared to
N ).
Nonetheless, a detailed analysis allows to point out distinct dynamical patterns on homogeneous and
heterogeneous networks. In homogeneous networks all nodes have a similar neighborhood and therefore
similar dynamical evolution, while in heterogeneous networks classes of nodes with diﬀerent degree
play diﬀerent roles in the evolution of the Game. High degree nodes, indeed, are more likely chosen as
hearers (in the direct Naming Game). At the beginning, low degree nodes are much more involved in
the process of word generation than the hubs; local consensus is easily reached and a large amount of
locally stable diﬀerent words gets in touch with higher degree nodes. The latter start to accumulate
a large number of words in their inventories, playing as “super-spreaders” of names towards less con-
nected agents and ﬁnally driving the convergence. From this viewpoint, the convergence dynamical
pattern of the Naming Game on heterogeneous complex networks presents some similarities with more
studied epidemic spreading phenomena [33].
The shape of the degree distribution and the scaling of the average distance are not the only topolog-
ical properties that determine the Naming Game dynamics; for this reason, we have investigated the
eﬀects of a number of other quantities.
On both homogeneous and heterogeneous networks, an increase in the average degree induces a larger
memory peak and a faster convergence, while the growth of the clustering coeﬃcient has a completely
opposite eﬀect. This is particularly important in social networks that are usually characterized by a
large level of cohesiveness.
A very striking result concerns the convergence of the Naming Game on networks with well-deﬁned
hierarchical organization or community structures. On generic hierarchical networks, and particularly
on trees, the process leading to the ﬁnal agreement is very slow, governed by a diﬀusive or even subd-
iﬀusive coarsening. We have identiﬁed the origin of this behavior in the existence of a non negligible
surface tension between diﬀerent hierarchical levels. A similar behavior is due to the presence of a
community structure: each community ﬁnds quickly an internal agreement, but a cluster cannot easily
expand outside its own community since the interfaces get pinned on the few bridges interconnecting
diﬀerent communities. Therefore, in this case the curve of the number of diﬀerent words Nd(t) is
not characterized by a power-law decay, but by a series of plateaus of diﬀerent size corresponding to
diﬀerent levels of reﬁnement in the community organization of the network. When the duration of a
plateau (in Nd(t)) increases with the size of the network, we say that the system is in a metastable
state.
Even in presence of metastable states, if we wait suﬃciently long, the system will converge to the
absorbing state, meaning that the Naming Game model is a strongly converging dynamical rule. The
origin of this behavior resides in the memory-based decision rule. We have investigated its implications
both at a local and global level.
At a local level we have focused on the internal activity of the agents in diﬀerent topologies, getting
deeper insights in the mechanisms governing the decision processes (see Section 5.4). In particular,
we have found that the single agents dynamics is intrinsically non-poissonian, resulting in a stronger
tendency to take a decision (and then to converge) for the high-degree nodes. This attitude balances
the instability due to the fact that high-degree nodes, being in contact with many diﬀerent words, are
more exposed to perturbations in the dynamics.
The role of the memory in the global behavior of the system is that of generating an eﬀective surface

5.5. CONCLUSIONS

131

tension (see Section 5.3.1), that is responsible for the coarsening of clusters. In fact, the surface ten-
sion associated with the coarsening process of clusters of agents with a unique word is strong enough
to ensure the convergence of the Naming Game in any dimension, but suﬃciently weak to prevent
the system to block in metastable states. From this point of view, the Naming Game is similar to
a low-temperature Potts model, but without the typical bulk noise due to an externally imposed
temperature-like parameter.
Note that this form of surface tension does not have an energetic microscopic nature, as for the Ising
model, but it is due to the introduction of temporal correlations in the decision process (i.e. the in-
troduction of memory) similar to what happens in diﬀusion-limited aggregation when a mechanism of
noise-reduction is taken into account. Some preliminary results on the comparison between clusters
dynamics in models with memory (like the Naming Game) and other lattice spin models seem to
corroborate this picture, that will be developed in a future work.

In summary, as other models of opinion formation, the Naming Game shows a non-equilibrium
dynamical evolution from a disordered state to a state of global agreement. However, with respect
to most opinion models, in which the agents may accept or refuse to conform to the opinion of
someone else, the Naming Game gives more importance to the bilateral negotiation process between
pairs of agents. For this reason, the Naming Game should be regarded as a model for the emergence
of a globally accepted linguistic convention or, in other terms, the establishment of a self-organized
communication system; but it can be also reasonably used to describe opinion formation and other
social polarization phenomena. The main novelty resides certainly in the introduction of pairwise
interactions endowed with memory and feedback, that make the Naming Game phenomenology closer
to that observed in real systems, in particular when we consider the system embedded in a complex
network topology.

132

CHAPTER 5. THE NAMING GAME

Chapter 6

General Conclusions and Outlook

In this thesis, I have studied both numerically and analytically some structural and dynamical as-
pects of complex networks. From the point of view of a theoretical physicist, the problems that
phenomenological observations on complex networks are raising are undoubtedly exciting, because of
the possibility of getting striking results applying rather simple statistical physics approaches. As a
consequence of the small-world property, indeed, the general behavior of complex networks and of the
dynamical processes taking place on them can be fairly described using mean-ﬁeld arguments. On the
other hand, when mean-ﬁeld like methods are not applicable, or the picture we obtain from them is
not satisfactory, in most of the cases the only possible approach is that of numerical simulations.
This picture corresponds in general to the approach of research followed in this thesis. For example,
in the case of the exploration of networks, we have provided a mean-ﬁeld analysis that gives very good
results at a qualitative level, but for any quantitative characterization of networks sampling the use of
numerical simulations cannot be avoided. In the interdisciplinary ﬁeld of complex networks, however,
the quantitative aspect is very important, since the original problems are usually closely related with
applications and theoretical results have to be compared with the abundance of phenomenological
data. Thus, future works will be addressed to improve separately these two approaches. First, from
the numerical side, it is worthy to extend the investigations of this thesis to more realistic models of
Internet mapping, in order to verify the reliability of our results when the condition of shortest path
probes is relaxed. Preliminary results have been obtained following two diﬀerent approaches: one
corresponds to use a model in which local path inﬂations are introduced (i.e. distortions of the short-
est path that should reproduce the eﬀect of traﬃc and policies [99]); the other considers traceroute
probing by means of weighted shortest paths, in which the weights are randomly distributed on the
edges (we have only studied low disorder regimes, but also the strong disorder limit should provide
interesting results [150]). In both cases, the quantitative estimation of the relevant topological quan-
tities seems not to change considerably from the results here exposed.
From an analytical point of view, I am currently interested in understanding the origins of the bi-
ases introduced by tree-like explorations in relations with the causal structure of the spanning trees
generated in the sampling or more generally the framework of hidden variable models. It has been
shown [38, 237] that scale-free topological properties emerge naturally when the networks are endowed
with a causal structure; according to this picture, sampling biases could be the natural result of the
systematic introduction of causality in the network’s topology.
Of course, theoretical improvements of the mean-ﬁeld approach are possible, for instance taking into
account correlations in the expressions for the node and edge discovery probability.

133

134

CHAPTER 6. GENERAL CONCLUSIONS AND OUTLOOK

The most promising possible application of the work exposed in Chapter 3 is however the deﬁnition
of statistical estimators able to correct the biases due to the sampling process. We have successfully
introduced estimators for the number of nodes in the Internet, but the present work is aimed to deﬁne
unbiased estimators also for other quantities (e.g. the number of edges).
A similar twofold approach holds for the subjects discussed in Chapter 4. In order to achieve a more
satisfactory comprehension of which mechanisms are responsible of the non-trivial structural and
functional organization of real complex networks, such as the world-wide airports network, we need
ﬁrst to reﬁne the analysis of the real data, selecting those quantities better pinpointing the functional
and economic dimension of the system; on the other hand, we have to improve the current models of
weighted growing networks to produce more realistic eﬀects.
For the inhomogeneous spreading on complex networks, whose theory is treated in Chapter 4 and
expecially in Appendix B, the situation is the opposite one: we have a good understanding of the
theoretical description of the process, but we do not dispose of phenomenological data (e.g. those
regarding the rates of infection of a real virus on the Internet if the heterogeneity of the nodes as well
as their functional properties are taken into account). It should be interesting to retrieve real data
on the level of functional inhomogeneity in infrastructure networks and verify if the corresponding
spreading properties can be analyzed within the theoretical framework here provided.
The Naming Game is a rather recent topic of research, thus many aspects of the dynamics of the
model are not completely clear. One of the most interesting phenomena displayed by this model is
the presence of an eﬀective surface tension, that is comparable with that of a low temperature Potts
model, even if the pairwise evolution rule looks more similar to that of the Voter model [159], in which
the surface tension is absent. We have reason to think that the surface tension is a consequence of the
presence of memory in local rule, therefore a future work will be addressed to show, using a simpli-
ﬁed model, that the presence of memory in the nodes is suﬃcient to produce a coarsening dynamics
in analogy with some techniques of noise reduction studied in the problems of surface growth [175].
Moreover, my personal opinion is that a further simpliﬁed model of Naming Game, conceived in such
a way to retain all its relevant properties, could allow to study analytically the dynamics on the whole
class of mean-ﬁeld like models, maybe elucidating the relation between the small-world property (and
other topological properties) and the scaling of the convergence time. It should be also interesting
to add some external source of noise to the system, maybe coupled with the internal activity of the
agents, in order to study if a phase transition toward a non-trivial state in which agents do not ﬁnd
a consensus emerges.

In conclusion, the study of dynamical phenomena on complex networks is a fascinating subject
of research that is expected to become more and more popular in the next years, because of the
large amount of data that is still not available on real dynamical processes and for the possibility of
theoretical modeling by means of known statistical physics approach and for the considerable number
of issues in which the analytical and numerical analysis of simple models can be successfully applied.

Remerciements

Cette th`ese s’est d´eroul´ee de novembre 2003 `a juin 2006 au Laboratoire de Physique Th´eorique d’Orsay.
Je remercie les directeurs du labo Dominique Schiﬀ, puis Henk Hilhorst de m’y avoir tr`es bien accueilli
et permis de r´ealiser ce travail de th`ese dans les meilleures conditions.

Je tiens tout d’abord `a remercier Alain Barrat, pour avoir accept´e de diriger ma th`ese. Sa disponi-
bilit´e, sa patience et la conﬁance qu’il a toujours montr´ee `a mon ´egard ont ´et´e tr`es importantes pour
moi. Je tiens ´egalement `a remercier Alessandro Vespignani, avec lequel j’ai eu l’honneur et le plaisir
de travailler durant toute ma th´ese. Je leur suis profond´ement reconnaissant.

Je remercie aussi chaleureusement tous les membres du groupe de Physique Statistique du LPT
avec lesquels j’ai partag´e les joies et les peines, ou plus simplement la vie quotidienne durant ces trois
ann´ees. En particulier, ‘Nacho’ Alvarez-Hamelin, Vivien Lecomte, Aur´elien Gautreau, Fr´ed´eric van
Wijland et ‘les italiens’ de mon bureau, Andrea Puglisi et Paolo Visco, qui m’ont evit´e le mal du pays.
Leur sympathie et leur amiti´e a ´et´e tr`es importantes pour moi.
Je souhaite aussi remercier tout le personnel du labo et le directeur de l’Ecole Doctorale Yves Charon;
leurs comp´etences et leur disponibilit´e m’ont rendu la vie plus facile `a Orsay.

Je remercie Messieurs Olivier Martin, R´emi Monasson, et Alessandro Vespignani d’avoir bien voulu
participer au jury de th`ese et Messieurs Romualdo Pastor-Satorras et Cl´ement Sire d’avoir accept´e la
lourde tˆache d’en ˆetre les rapporteurs.

Je ne pourrai jammais oublier tous ceux qui ont travaill´e avec moi, en particulier Marc Barth´elemy,

Vittorio Loreto et mon grand ami, ‘malheureusement int´eriste’, Andrea Baronchelli.

Finalement, je voudrais t´emoigner ma profonde gratitude `a mes parents et `a ma soeur Chiara,
pour leur soutien et l’aﬀection qu’ils me donnent. Je salue ´egalement du fond du coeur tous mes amis
avec qui j’ai partag´e les meilleurs moments et les diﬃcult´es, et en particulier ma copine Deborah. Je
ne trouve pas suﬃsamment de mots pour te remercier (surtout en francais!); ta presence a ´et´e pour
moi la source de motivation et de s´er´enit´e la plus grande.

135

136

CHAPTER 6. GENERAL CONCLUSIONS AND OUTLOOK

Appendix A

Generating Functions in
Percolation Problems

In this appendix, we provide a brief introduction to the formalism of generating functions in the study
of percolation on random graphs. We consider inﬁnite graphs without isolated vertices, self-edge or
multiple edges. The generating function for the degree distribution pk of a randomly chosen vertex is

G0(x) =

pkxk ,

∞

Xk=1

k kpkxk−1
k kpk

P

= G1(x) =

G′
G′

0(x)
0(1)

.

with G0(1) = 1, and
that a randomly chosen edge leads to a vertex of given degree is

k kpk = G′

k
h

=

i

0(1). Similarly, the generating function for the probability

P

A useful property is that the probability distribution and its moments can be computed by simple
derivative of the corresponding generating function.

P

If we call qk the probability that a vertex of degree k is occupied (or node traversing probability
if regarded as a spreading phenomena), the probability that, choosing randomly a vertex, we pick up
an occupied vertex of degree k is the product of the probabilities of two independent events, i.e. pkqk.
Repeating the same operation with the edges, we need the probability that the randomly chosen edge
is attached to an occupied vertex of degree k. This event happens with probability kpkqk/
. Hence,
i
we deﬁne the generating functions for both these probabilities that are very important in the site
percolation,

k
h

F0(x;

q

) =

{

}

F1(x;

q

) =

{

}

∞

pkqkxk ,

Xk=1
∞
k=1 kpkqkxk−1
k kpk

P

=

F ′
0(x)
k
h

i

.

The function F0(x;
exists and is occupied, while F1(x;
vertex of a given degree starting by a randomly chosen edge and that it is occupied.

) is the generating function of the probability that a vertex of a given degree
) is the generating function for the probability of reaching a

{

}

{

}

q

q

P

The solution of the site percolation problem is the set of values

for which an inﬁnite cluster
(giant component) exists. In order to compute the probability that a randomly chosen vertex belongs

qk}

{

137

(A.1)

(A.2)

(A.3a)

(A.3b)

138

APPENDIX A. GENERATING FUNCTIONS IN PERCOLATION PROBLEMS

to the giant component, we start by computing the probability Ps that a randomly chosen vertex
belongs to a connected cluster of a certain size s. The use of generating functions allows to do it
simultaneously for all the possible sizes. Then, the mean cluster size is obtained as the ﬁrst derivative
of the generating function of Ps. Finally, the condition for the divergence of the mean cluster size
gives the condition for the existence of the giant component as a function of the parameters of the
system, that are the degree distribution and the node occupation probability.

q

Figure A.1: (A) A full dotted bullet with dashed contour line corresponds to the probability that a ver-
tex is unoccupied. This is given by a particular series of diagrams, in which we sum the contributions
of unoccupied vertices of all possible degrees. A striped bullet with full contour line represents the
), whose diagrammatical expansion contains all possible combinations
generating function F0(x;
of occupied vertices reachable by an occupied vertex with a certain degree. The x accounts for the
occupation of a vertex. The contributions of the isolated vertices (p0q0) have been deleted in agree-
ment with our convention of considering only graphs with non isolated vertices. (B) Diagrammatical
representation of the generating function H0(x). The ﬁrst terms of the inﬁnite series correspond to
the summation of the Eqs. A.5 as presented in Eq. A.6. These contributions can be expressed in a
compact form using Eq. A.7, that contains the generating functions F0(x;

) and H1(x).

{

}

q

{

}

Firstly, we consider the probability Ps that a randomly chosen vertex in the network belongs to a
q

connected cluster of a certain size s. We call H0(x;

) its generating function,

{

}

∞

s=0
X

H0(x;

q

) =

{

}

Psxs ,

(A.4)

k qkpk that a
in which we have conventionally grouped in the term for s = 0 the probability 1
vertex is not occupied. Similarly, let ˆPs be the probability that a randomly chosen edge leads to a
) its generating function.
cluster of a given size s, and H1(x;

P

−

q

{

}

Since we choose the starting vertex at random, each possible degree k gives a diﬀerent contribution
to each possible cluster size probability Ps, meaning that each term Psxs is itself given by an inﬁnite

sum of terms labeled by the degree k. For instance, the ﬁrst terms of H0(x;

q

) are:

{

}

P0 = 1

pkqk ,

Xk
plqlx ˆP0

l

,

P1x =

P2x2 =

lplqlx ( ˆP1x) ˆP0

l−1

,

−

∞

Xl=1
∞

Xl=1
∞

Xl=1
∞

Xl=1

P3x3 =

lplqlx ( ˆP2x2) ˆP0

l−1

+

plqlx

( ˆP1x)

2 ˆP0

l−2

,

P4x4 =

lplqlx ( ˆP3x3) ˆP0

l−1

+

plqlx 2

( ˆP2x2) ( ˆP1x) ˆP0

l−2

l
2 !

 

l
2 !

 

Xl≥2

Xl≥2
3 ˆP0

( ˆP1x)

l−3

,

+

plqlx

Xl≥3

l
3 !

 

...

H0(x;

q

) = 1

{

}

pkqk + p1q1x

ˆP0 + ˆP1x + ˆP2x2 + . . .
h

i

−

Xk
+ p2q2x

2

ˆP0
h

2
+ 2 ˆP0 ˆP1x + ( ˆP1x)
2

+2 ˆP1x ˆP2x2 + ( ˆP2x2)

+ . . .

+ . . .

+ 2 ˆP0 ˆP2x2

pkqk + p1q1x

i
ˆP0 + ˆP1x + ˆP2x2 + . . .

h

i

ˆP0 + ˆP1x + ˆP2x2 + . . .

+ . . .

2

i

h

pkqk + xp1q1H1(x;

q

) + xp2q2[H1(x;

{

}

)]2 + . . . .

q

{

}

= 1

−

Xk
+ p2q2x

= 1

−

Xk

Now, summing these terms and grouping similar contributions we get

Note that no term contains p0q0 according with the convention of considering only non isolated nodes.
A compact form for this expression is written using Eq. A.3a,

H0(x;

q

) = 1

F0(1;

q

) + xF0(H1(x;

{

}

−

{

}

q

);

{

}

q

) .

{

}

The structure of Eq. A.7 can be represented diagrammatically as shown in Fig. A.1, associating the
) to each “dressed” vertex, while the function
q
variable x to each “bare” vertex and a variable H(x;
{
F0 weights the contributions over all possible degrees.

}

Moreover, the generating function H1(x;

q

) satisﬁes a similar self-consistent equation,

H1(x;

q

) = 1

{

}

) + xF1(H1(x;

q

);

{

}

q

) ,

{

}

{
F1(1;

}
q

{

}

−

that is obtained following completely similar arguments starting from picking up an edge at random.
Taking the ﬁrst derivative of H0 in Eq. A.7 with respect to x computed in x = 1, we get the
. Then, imposing the divergence of the latter allows to ﬁnd the condition for
mean cluster size
i
the existence of a giant component, that corresponds to the Molloy-Reed criterion as presented in
Ref. [65]. Finally, considering a uniform occupation probability qk = q (or uniform node traversing
probability), the expression for the site percolation threshold qc can be computed.

s
h

139

(A.5a)

(A.5b)

(A.5c)

(A.5d)

(A.5e)

(A.5f)

(A.6)

(A.7)

(A.8)

140

APPENDIX A. GENERATING FUNCTIONS IN PERCOLATION PROBLEMS

Appendix B

A General Percolation Theory for
Spreading Processes

It is possible to develop a general theory for inhomogeneous joint site-bond percolation exploiting the
method of generating functions [65, 103, 250], that is brieﬂy introduced in Appendix B. The theory
holds for Markovian networks, i.e. random graphs with two-point degree correlations [43], therefore
the edge transition probabilities are at least dependent on the degree of the two extremities. Since real
spreading rates may depend on many other features, we account for these properties introducing multi-
type nodes, and assigning to each edge transition probability a pair of additional labels indicating the
types of the nodes at the extremities.

The main result of this appendix is a general version of the Molloy-Reed criterion for the existence
of a giant component in the case of joint site-bond percolation and, consequently, the expressions of
the critical threshold for the two separate cases of site percolation and bond percolation.

B.1 Markovian Networks with Multi-Type Nodes

As already mentioned in Chapter 2, vertex-vertex correlations are usually expressed using the degree
conditional probability p(k′
k), i.e. the probability that a vertex of degree k is connected to a vertex
|
of degree k′. This has led to the deﬁnition of a class of correlated networks, called Markovian random
networks [43] and deﬁned only by their degree distribution pk and by the degree conditional probability
k). The function p(k′
p(k′
k) satisﬁes the normalization constraint and a detailed balance condition
|
|
(see Chapter 2 for details).
In this context, the edge transition probability Tij must depend on the degrees ki and kj of the
extremities. Note that, while the analysis of the standard site (bond) percolation is based on the
relation between the degree distribution pk and the degree-dependent node occupation probability
qk, in the inhomogeneous joint site-bond percolation the relation is between the pair of distributions
pk, p(k′

and the pair of probability functions

qk, Tkk′

.

{

k)
}
|

The multi-type classiﬁcation of the nodes consists in dividing the nodes of a graph into n classes,
each one speciﬁed by a particular quality or “type”. The meaning is generic, it can be a distinctive
feature of the node (e.g. the gender or the age in a population of individuals) or it can be associated
to some quantity that have been measured on the network (e.g. the strength or the betweenness of the
node). Then, we consider the degree distribution p(h)
of nodes of class h = 1, . . . , n, conventionally

{

}

k

141

142

APPENDIX B. A GENERAL PERCOLATION THEORY FOR SPREADING PROCESSES

k p(h)

k = 1. This condition ensures the normalization to 1
normalized on the relative set of nodes, i.e.
for the generating functions. Inside the classes there are no restrictions on the transition probabilities
and they might be very diﬀerent.
Summarizing, our approach considers a Markovian correlated graph with multi-type vertices, in which
each vertex is given an occupation probability depending on its degree and type, and each edge is
endowed with a transition probability depending on the degrees and the types of the extremities.

P

l m(l)

i = mi ≤

The fundamental brick for the construction of generating functions in correlated graphs is the
rooted edge composed of a starting vertex i and the pending edge (i, j) connecting it to a second
vertex j, without explicitly considering this second extremity. For this reason we will always average
on the degree of the second extremity of the edge. Let us consider a vertex i chosen at random,
it will be characterized by a class h and by a degree ki. In principle, the ki edges departing from
that node are connected to ki other nodes belonging to diﬀerent classes. Actually, only mi of them
are really reached by a ﬂow because of the presence of transition probabilities on the edges (we call
, with
such transmitting edges open). Therefore, they identify a partition of
is the number of these neighbouring nodes belonging to the class l

ki, in which m(l)
i
and linked to i by an open edge.
P
Suppose that m(l)
of the ki edges emerging from a node of class h and degree ki are successfully
i
connected to nodes of a same class l and (possibly diﬀerent) degrees kj . The average probability
ki) is
that an edge among them allows the ﬂow to pass is
the degree conditional probability between vertices of states h and l and T (h→l)
is the transition
probability along an edge from a node of degree ki in the class h to a node of degree kj in the
class l. The origin of this term is trivial: the probability to pass along the edge is the product of
two independent events, i.e the edge exists and it is open; then, being interested in rooted edges,
we have to average over all possible degrees kj. The probability that there are m(l)
of these edges
i
m(l)
i

ki), where p(h→l)(kj |

, . . . , m(n)
i }

p(h→l)(kj |

T (h→l)
kikj

, m(2)
i

m(1)
i

kikj

P

kj

{

produces a term [

T (h→l)
kikj

p(h→l)(kj|
mi negative events contribute to a single term

ki)]

kl

P
the ki −
that is the probability that ki −
belong to. Computing the probability of the whole event associated with the partition
mi, m(1)
ki −
i
distribution

,
mi edges do not admit the ﬂow’s passage whichever class they
i =
of the neighbours of the node with degree ki, we get the multinomial

ki)
i
m(0)

, . . . , m(n)
i }

, m(2)
i

p(h→l)(kjl |

P

P

kjl

−

{

1

h

T (h→l)
kikjl

n
l=1

. Positive events give n contributions of this kind, while
ki−mi

P (h)(ki,

m(l)
i }

{

) = ki!

n

1

−

jl=1
X

Xkjl

T (h→l)
kikjl

p(h→l)(kjl |

ki)

m(0)
i

(B.1)

1
m(0)
i

n

! 

1
m(l)
i

×

Yl=1

! 


Xkjl

T (h→l)
kikjl

p(h→l)(kjl |

ki)

m(l)
i





.





A simpler version of this multinomial distribution appears in Ref. [190].
The following step consists in using the expression of the multinomial distribution to obtain the
generating function of the probability that a physical quantity spreading from a vertex of class h
(l = 1, 2, . . . , n).
successfully ﬂows through
m(l)
, we
Summing over all possible values of ki and over all possible partitions of ki in n + 1 values

of its edges that point to vertices in the class

m(l)

}

{

{

}

l

{

}

143

(B.2)

B.1. MARKOVIAN NETWORKS WITH MULTI-TYPE NODES

obtain the generating function

F (h)
0

(x1, x2, . . . , xn;

q, T

) =

{

}

p(h)
ki

q(h)
ki

m(l)

i )P (h)(ki,

m(l)
i }

)

{

∞

Xki=1

n

δ(ki,

X{m(l)
i }

Xl=0

m(l)
x
i
l

,

n

Yl=1

in which q(h)
is the occupation (traversing) probability of a vertex belonging to the class h with degree
ki
ki, δ(
) is a Kronecker’s symbol and the x1, . . . , xn variables represent the average contributions of
,
·
·
the rooted edges of the diﬀerent classes. Introducing Eq. B.1 in Eq. B.2, the sum over the partitions
m(l)
corresponds to the extended form of a multinomial term, providing the following expression
i }
{
for the generating function

F (h)
0

(x1, x2, . . . , xn;

q, T

) = F (h)

0

(x;

q, T

{

)

}

{

}

∞

=

Xki=1

p(h)
ki

q(h)
ki 

1 +

(xl −

1)

T (h→l)
kikjl

p(h→l)(kjl |

ki)



.

n

Xl=1

Xkjl

ki

(B.3)




With a completely similar argument, we compute the generating function F (h)
) of the prob-
ability that a randomly chosen edge leads to a vertex of class h from which the spread toward its
(l = 1, 2, . . . , n).
neighbours successfully ﬂows through
Hence, observing that now the number of emerging edges available to the spreading process reduces
1 and that the probability to reach the starting vertex (from an edge pointing to a generic
to ki −
vertex of class h) is

, the generating function F (h)

edges pointing to nodes of class

) reads

q, T

q, T

ml

(x;

(x;

{

}

{

}

{

}

l

1

kip(h)
ki
k kp(h)

k

1

{

}

F (h)
1

P
(x1, x2, . . . , xn;

q, T

{

}

) = F (h)

1

(x;

q, T

)

}

{
kip(h)
ki
k kp(h)

k

∞

=

Xki=1

P



n

Xl=1

q(h)
ki 

1 +

(xl −

1)

T (h→l)
kikjl

p(h→l)(kjl |

ki)

Xkjl

ki−1

.





(B.4)

As recalled in the Appendix A, the two generating functions are useful in the computation of
a system of self-consistent equations (similar to those in Eqs. A.7-A.8) from which the expression
should be derived. The main diﬀerence concerns the form of the
of the average cluster size
generating functions F (h)
), that are partitioned in classes (of nodes in
{
diﬀerent states) and contain the contributions of the transition probabilities. Firstly, we consider the
probability P (h)
that a randomly chosen edge leads to a vertex of class h belonging to a connected
ˆP (h)
component of a given size s. Its generating function H (h)
s xs satisﬁes the self-
consistent equation

s
h
i
(x;
q, T
{

) and F (h)

) =

q, T

q, T

(x;

(x;

}

}

{

}

1

0

1

s

s

P

H (h)
1

(x;

q, T

) = 1

{

}

−

F (h)
1

(1;

q, T

{

}

) + x F (h)

1

[H (1)

1 (x;

q, T

{

}

), . . . , H (n)

(x;

1

q, T

);

q, T

] ,

(B.5)

{

}

{

}

1

}

{

(x;

q, T

where the presence of H (h)
) for all h = 1, . . . , n on the r.h.s. means that the constraint on
the value of h is required only on the starting node, not on the others reachable from it. Moreover, x
refers to the cluster distribution and does not need any label.
The ﬁrst term in the r.h.s. of Eq. B.5 is due to the probability that the node of class h to which
a chosen edge leads is not occupied, therefore it should not depend on the transmissibility of any
(1;
outgoing edge. As required, the term 1
) computed in x = 1 does not depend on
in the cluster expansion. The second term of Eq. B.5
T
{
refers to the contribution of an occupied vertex. Let us suppose that its degree is ki and consider one

F (h)
1
. This corresponds exactly to the term ˆP (h)

q, T

−

}

{

}

0

144

APPENDIX B. A GENERAL PERCOLATION THEORY FOR SPREADING PROCESSES

of its outgoing edges leading to a vertex in the class l:
1

its contribution is given by the probability
ki) that the ﬂow does not reach the second extremity of the edge, and by

T (h→l)
kikjl

kjl

p(h→l)(kjl |

−

T (h→l)
kikj

kj

P

p(h→l)(kj|

the probability that it passes (
ki)). The latter has to be multiplied by the vertex
function associated to the probability that this second vertex (of class l) belongs to a cluster of a
P
given size. This probability is generated by the function H (l)
) that is the correct vertex term
for this contribution. Then, all these quantities have to be averaged over the set of degrees ki, with
weights p(h)
, easily recovering the second term on the r.h.s.. Since the spirit of the derivation
ki
is completely the same, we refer again to Fig. A.1 for a diagrammatical representation of the Eq. B.5
(details are diﬀerent).
The other equation, for the generating function H (h)
chosen vertex of class h belongs to a cluster of ﬁxed size s, reads

) of the probability that a randomly

and q(h)
ki

1 (x;

q, T

q, T

(x;

{

}

}

{

0

H (h)
0

(x;

q, T

) = 1

F (h)
0

(1;

{

}
Note that, by deﬁnition, both H (h)

−

{

q, T

}

1
Now, taking the derivative of Eq. B.6 with respect to x in x = 1, we obtain the average number of

{

{

}

}

0

(x;

q, T

) and H (h)

(x;

q, T

) are 1 in x = 1 for all h.

vertices reachable starting from a vertex in the class h,

) + x F (h)

0

[H (1)

1 (x;

q, T

{

}

), . . . , H (n)

(x;

1

q, T

);

q, T

] ,

(B.6)

{

}

{

}

=

shi
h

dH (h)
0
dx

x=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)

= F (h)
0

(H1(1) = 1;

q, T

) +

{

}

∂F (h)
0
∂xl

Xl

x=1
(cid:12)
(cid:12)
(cid:12)
(cid:12)

′

H (l)
1

(1;

q, T

) .

{

}

(B.7)

The second term in the r.h.s. contains linear contributions from other classes of vertices, therefore
n product space generated by pairs of classes) as
Eq. B.7 can be written in a matrix form (in the n

i

{

=

s
h

q, T

∇xH0(x;

)
x=1
(cid:12)
(cid:12)
(cid:12)
with s = (s1, s2, . . . , sn). Taking the derivative of Eq. B.5 with respect to x in x = 1, we obtain an
(cid:12)
implicit expression for H (h)

x=1 · ∇xH1(x;
]
(cid:12)
(cid:12)
(cid:12)
(cid:12)

)
x=1
(cid:12)
(cid:12)
(cid:12)
(cid:12)

∇xF0[x;

= F0[1;

(B.8)

q, T

q, T

q, T

q, T

] +

(1;

}

}

{

{

}

}

{

)

,

′

1

{

}

′

H (h)
1

(1;

q, T

{

}

) = F (h)

[1;

1

q, T

] +

{

}

∂
∂xl

F (h)
1

[1;

q, T

{

}

′

]H (l)
1

(1;

q, T

) ,

{

}

(B.9)

and putting together the contributions in a matrix formulation, we get

×

Xl

∇xH1(x;

{

q, T

}

= F1[1;

q, T

] +

{

}

∇xF1[x;

{

q, T

}

x=1

x=1 · ∇xH1(x;
]
(cid:12)
(cid:12)
(cid:12)
(cid:12)

q, T

{

}

.

)
x=1
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(B.10)

= [I

− ∇xF1[x = 1;

{

q, T

}

]]−1

·

F1[1;

q, T

] = [I

{

}

]−1

·

− F

F1[1;

q, T

] , (B.11)

{

}

q, T

]. Introducing the expression in Eq. B.8, we obtain

= F0[1;

q, T

] +

∇xF0[x = 1;

{

q, T

[I

]

}

·

− F

F1[1;

q, T

] .

{

}

·

}

]−1

(B.12)

The condition for a giant component to emerge consists in the divergence of the mean cluster size,
. It corresponds to the following generalized Molloy-Reed
i.e. of at least one of the components of
i

s
h

)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Explicitly, Eq. B.10 becomes

∇xH1(x;

with

=

F

{

}

x=1

q, T

)
(cid:12)
(cid:12)
(cid:12)
∇xF1[x = 1;
(cid:12)
s
h

i

{

}

{

145

(B.13)

B.2. DEGREE-BASED MULTI-TYPE SOLUTION

criterion for inhomogeneous joint site-bond percolation in multi-type Markovian correlated random
graphs:

det [I

]

0 ,

− F

≤

where

=

∇xF1[x = 1;

{

q, T

}

F

] (whose elements are of the type ∂
∂xl

F (h)
1

[1;

q, T

]).

{

}

It is evident that such a general result strongly depends on which kind of node partition we are
considering. Two examples of partitions are particularly relevant: i) a single class collecting all the
nodes and ii) a degree-based classiﬁcation of the nodes.

B.2 Degree-based Multi-type Solution

In this situation the types correspond to the diﬀerent degrees, thus each class gathers all vertices with
a given degree and there is in principle an inﬁnite number n of types (in ﬁnite networks there are as
many types as the number of diﬀerent degrees). Using the relation p(ki)
Eqs. B.3-B.4 become

(ki )
ki
(ki )
k kp
k

= 1, the

= 1 and

kip

ki

P

ki



ki−1





F (ki)
0

(x1, . . . , xn;

q, T

1 +

(xkj −

1)Tkikj p(kj|

ki)



,

(B.14a)

{

{

}

}

) = qki 

) = qki 


Xkj

Xkj

F (ki)
1

(x1, . . . , xn;

q, T

1 +

(xkj −

1)Tkikj p(kj|

ki)

.

(B.14b)

The self-consistent system of equations for the generating functions of clusters size probability looks
like in Eqs. B.5-B.6, and the condition for the existence of a giant component is still the divergence
of the mean cluster size, but now the elements of the matrix

are

Fij = (
The generalized Molloy-Reed criterion becomes

∇xF1[x = 1;

q, T

{

])ij = (ki −

}

F
1)qki Tkikj p(kj|

ki) .

det

(ki −
(cid:2)

1)qki Tkikj p(kj |

ki)

−

δij

0 .

≥

This expression corresponds to the criterion of Ref. [240] for the existence of percolation in correlated
random graphs (apart from a matrix transposition), but with the diﬀerence that in this case we
are dealing with inhomogeneous joint site-bond percolation, then both the degree-dependent node
traversing probability and edge transition probability appear in the expression. The condition that
percolation threshold is related to the largest eigenvalue (see Ref. [240]) is recovered if we assume that
all nodes have equal traversing probability qki = q = const. In other words, we are switching from
a joint site-bond percolation to a simple site percolation with an occupation probability q. If q
= 0
(otherwise the percolation condition cannot be satisﬁed), we can write the condition as

(B.15)

(B.16)

q det

(ki −

1)Tkikj p(kj|

ki)

−

Λδij

0 ,

≥

(B.17)

(cid:2)

with Λ = 1/q. Since in q = 0 the determinant is negative, the smallest positive value of q ensuring
ki).
Eq. B.17 to be satisﬁed corresponds to the largest eigenvalue Λmax of the matrix (ki −
It follows that the critical value of site occupation probability is q = 1/Λmax. In the case Tkikj = 1,
the condition gives exactly the results obtained by V´azquez et al. [240].
However, the complete knowledge of the correlation matrix p(kj|

ki) is very unlikely for real net-
works, and the analytical solution of Eq. B.16 can be problematic also for simple artiﬁcial networks.

1)Tkikj p(kj|

(cid:3)

(cid:3)

6
146

APPENDIX B. A GENERAL PERCOLATION THEORY FOR SPREADING PROCESSES

B.3 Local Homogeneity Approximation

When all nodes belong to a unique class, the single-state network is recovered and the analytical
treatment becomes easier. We recover indeed a sort of local homogeneity approximation for the prob-
ability that an edge emerging from a vertex of degree ki is traversed by the ﬂow. When n = 1, the
terms on the r.h.s. of Eqs. B.3-B.4 reduces to the average over the contributions of all the second
extremities of the edges emerging from a node, obtaining a degree-dependent eﬀective average trans-
1). The advantage of this approximation is
mission coeﬃcient τki =
that of providing analytically solvable equations for the percolation condition. Moreover, even if the
sum on kj introduces an approximation, the eﬀective term τki does not neglect the contributions due
to the edge transition probabilities, weighting them with the correct degree conditional probability as
required for Markovian networks. If these contributions are similar the approximation is very good,
while when the edge transition probabilities or the nodes correlations are highly heterogeneous the
local eﬀective medium approximation breaks down, and we have to use the general approach.

Tkikj p(kj |

τki ≤

ki) (0

P

≤

kj

Derivation of the Molloy-Reed Criterion -

According to this approximation, the gener-
) of the probability that a spreading process emerging from an occupied

ating function F0(x;
node ﬂows through exactly m nodes (whatever their degrees are) is written as

q, T

}

{

F0(x;

q, T

) =

{

}

1 + (x

1)

−

Tkikj p(kj |

ki)

(B.18)

∞

Xki=1

pki qki 


∞

Xkj =1

ki

.





{

}

q, T

) assumed by this function in x = 1 is the average occupation probability

This expression can be alternatively derived using simple arguments (see Ref. [84]). The value
F0(1;
k pkqk,
that is consistent with the fact that summing over the contributions of all the possible amounts of
emerging edges traversed by the ﬂow means that we are simply considering the number of starting
nodes, i.e. the average number of occupied nodes. The ﬁrst derivative with respect to x computed in
x = 1

q
h

P

=

i

∂
∂x

F0(x;

q, T

{

}

)
x=1
(cid:12)
(cid:12)
(cid:12)
(cid:12)

∞

∞

=

kipkiqki

Xki=1

Xkj =1

Tkikj p(kj|

ki) ,

(B.19)

is the average number of open edges emerging from an occupied vertex.
) of the probability that the ﬂow
Using similar arguments, we get the generating function F1(x;
spreading from a vertex, reached as an extremity of an edge picked up at random, passes through a
given number of the remaining edges,

q, T

{

}

F1(x;

q, T

) =

{

}

1 + (x

1)

−

Tkikj p(kj|

ki)

.

(B.20)

∞

kipki
k kpk

qki 


Xki=1

P

∞

Xkj =1

The next step consists in considering the self-consistent equations,

H0(x;

q, T

) = 1

F0(1;

q, T

) + xF0 [H1(x;

q, T

);

q, T

] ,

(B.21a)

{

{

}

}

−

−

{

{

}

}

{

{

}

{

}

{

H1(x;

q, T

) = 1

F1(1;

q, T

) + xF1 [H1(x;

q, T

);

q, T

] .

(B.21b)

Now the two quantity H0(x;
)) is scalar, and represents the generating func-
q, T
tion of the probability that a randomly chosen vertex (and, respectively, vertex reached by a randomly

) (and H1(x;

q, T

}

{

{

}

ki−1





}

}

B.3. LOCAL HOMOGENEITY APPROXIMATION

147

chosen edge) belongs to a cluster of given size. Since using scalar quantities allows to explain some
passages, we derive also the expression for the mean cluster size

s
h

,
i

)
x=1
(cid:12)
(cid:12)
(cid:12)
where x = 1 implies the average over all possible degrees ki. From Eq. B.21a-B.21b, using the relation
(cid:12)
H1(1;

) = 1, we get

(B.22)

H0(x;

0(1;

q, T

q, T

q, T

s
h

) ,

=

{

}

{

}

i

= H ′

d
dx

{

}

s
h
where the expression for H ′
x = 1,

i
1(1;

q, T

{

}

= F0(1;

q, T

) + F ′

0(1;

q, T

)H ′

1(1;

q, T

) ,

}

{
) comes directly from deriving Eq. B.21b with respect to x in

}

{

{

}

(B.23)

}
Inserted into Eq. B.23 it leads to the well-known expression ([65])

−

{

H ′

1(1;

q, T

) =

{

}

1

F1(1;
F ′

{
1(1;

q, T

)
}
q, T

.

)

s
h

i

= F0(1;

q, T

) +

{

}

F ′

0(1;
F ′

{
1(1;

q, T

)
}
q, T

;

)

}

{
)

1

−
1(1;

hence, the giant component exists if and only if F ′
1. Explicitly, it means that, in the
local eﬀective medium approximation, the generalized Molloy-Reed criterion for the inhomogeneous
joint site-bond percolation on Markovian random graphs takes the following form,

q, T

≥

}

{

∞

∞

(ki −

1)qki

Tkikj p(kj|

ki)

1

−



≥

0 .

(B.26)

Xkj =1
The threshold for the site percolation with inhomogeneous edges occurs when the equality holds.
Inserting uniform occupation probability qk ≡

q, its critical value is

Xki=1



pki ki 


(B.24)

(B.25)

(B.27)

qc =

∞

ki=1 ki(ki −

∞

kj =1 Tkikj p(kj |

ki)

.

P

k
h
1)pki

i

P

Transition probability factorization -

Note that, all the expression for the site-percolation
threshold reported in Section 4.3.1 have been derived starting from Eq. B.26. Henceforth, we will
rapidly derive them, making explicit assumptions on the form of the edge transition probabilities.
The most natural assumption consists of their factorization in two single-vertex contributions, i.e.

Tkikj = Θi(ki)Θf (kj ) ,

(B.28)

where subscripts i and f indicate an initial and a ﬁnal term respectively, in order to stress the fact that
ﬁrst and second vertices of an edge can give diﬀerent contributions in the inhomogeneous percolation
process.
Inserting Eq. B.28 in Eq. B.26, the condition for the existence of a giant component becomes

∞

Xki,kj =1

pkiki [(ki −

1)Θi(ki)Θf (kj)qki −

1] p(kj|

ki)

≥

0 .

In the case of uncorrelated graphs, the conditional probability also factorizes in p(k′

and Eq. B.29 gets simpler, leading to an interesting expression for the site percolation threshold,

(B.29)

k) = k′pk′
hki ,
|

(B.30)

qc =

k2Θi(k)
[
h

2
k
h
i
kΘf (k)
]
kΘi(k)
i
h
i
i − h

.

148

APPENDIX B. A GENERAL PERCOLATION THEORY FOR SPREADING PROCESSES

As an alternative, it seems interesting to study situations in which the transition probability is a
function of only one of the two extremities of an edge. When it depends only on ﬁnal nodes means
that Θi(k) = const. = 1 and Tkikj = Θf (kj ) and the site percolation threshold takes the form

qc =

2

k
h
k
i − h

k2
[
h

i
kΘf (k)
]
i
h
i

= qhom
c

k
h
i
kΘf (k)
i
h

,

c

where qhom
is the value of the critical occupation probability for the correspondent standard homo-
geneous site percolation. The opposite situation, Θf (k) = const. = 1 and Θi(k) = Tk, leads to the
following form for the Molloy-Reed criterion

(B.31)

(B.32)

k [(k

1)qkTk −

1] pk ≥

−

0 .

The inhomogeneous site percolation threshold qc follows directly imposing uniform occupation prob-
ability qk = q,

k
h
i
k2Tki − h
h
From Eq. B.32, also the threshold’s value for the inhomogeneous bond percolation is immediately
If we suppose uniform transition probabilities Tk = T , indeed, we can explicit T in
recovered.
Eq. B.32 as a function of the set of

and compute the value of the threshold as

kTki

(B.33)

qc =

.

k
h
i
k2qki − h
h
that represents the case in which percolation on the edges is aﬀected by refractory nodes.

kqki

Tc =

,

(B.34)

The last case we consider is that of uniform transition probabilities Tkikj = T , with 0 < T
1.
In the limit T = 1, the original Molloy-Reed criterion is recovered, otherwise, introducing Tkikj = T
in Eq. B.27, we ﬁnd the same expression for the threshold of site percolation with noisy edges (as in
Eq. 4.14 with

= T )

≤

T
h

i

(B.35)

qc =

1
k
h

i −

k2
(
h

/
i

.

1)T

∞

Xk=1

qk}

{

Appendix C

Solution of the Naming Game on
one-dimensional lattices

In Section 5.3.1, we have discussed the behavior of the Naming Game model on low-dimensional
regular lattices by means of numerical simulations. Local consensus is easy to reach, thus clusters
composed of adjacent agents with the same unique word start to grow, developing a sort of eﬀective
surface tension at the interfaces. This eﬀective surface tension, whose origins are partially investigated
in Section 5.3.1 is responsible for the slow coarsening dynamics leading the system to the consensus
state.
In one-dimensional lattices, it is possible to solve almost exactly the dynamics mapping the Naming
Game on a problem of diﬀusion and coalescence of interfaces. Let us consider a single interface be-
tween two linear clusters of agents: in each cluster, all agents share the same unique word, say A in
the left-hand cluster and B in the other. The interface is a string of length m composed of sites in
which both states A and B are present. We call Cm this state (A + B)m. A C0 corresponds to two
), while Cm means that the interface is composed by
directly neighboring clusters (
m sites in the state C = A + B (
). Note that, in the actual dynamics, two
CBBB
clusters of states A and B can be separated by a more complex interface. For instance a Cm interface
can break down into two (or more) smaller sets of C-states spaced out by A or B clusters, causing
the number of interfaces to grow. Numerical investigation shows that such conﬁgurations are however
eliminated in the early times of the dynamics. A sketch representing the evolution of the interface
between two diﬀerent clusters of words is reported in Fig. C.1.

AAABBB
AAAC

· · ·
· · ·

· · ·

· · ·

· · ·

Since the local dynamics is much faster than the global one, the probability that two neighboring
clusters are separated by an interface of a given width is well approximated by the stationary solution
of a Markov process governing the transitions between interfaces of diﬀerent width. The Markov chain
is easily generated by means of an iterative method.
Let us consider a one-dimensional line composed of N sites, initially divided into two clusters of A and
B, with an interface of zero width. The probability to select for interaction exactly the link associated
with this C0 interface is 1/N . Moreover, the outcome of such an interaction is the appearance of a C1
interface, since one of the two agents (that chosen as hearer) learns the word (A or B) uttered by the
other. Thus, there is a probability p0,1 = 1/N that a C0 interface becomes a C1 interface in a single
time step, otherwise it stays in C0.
We can now compute all possible evolutions, and relative probabilities, for a C1 interface. From C1
the interface can evolve into a C0 or a C2 interface with probabilities p1,0 = 3
2N re-

2N and p1,2 = 1

149

150

APPENDIX C. NAMING GAME SOLUTION IN D = 1

Figure C.1: Sketch of the evolution of an interface in a one-dimensional Naming Game. At the
interface between two clusters (red and blue sites), one or more sites can assume more than one word.

spectively. This procedure is easily extended to higher values of m, even if the number of the possible
cases grows considerably and the enumeration becomes harder. In principle there is no limit to the
growth of the interface’s width; in practice, we can safely truncate this enumeration at m
3, as
suggested by numerical experiments in which we have counted the number of times an interface of a
given width appears during the evolution of one-dimensional models.
In this approximation, the problem corresponds to determine the stationary probabilities of the trun-
cated Markov chain reported in Fig. C.2 and deﬁned by the transition matrix

≤

N −1
N
3
2N
1
N
1
N

1
N
N −2
N
3
2N
1
N

0
1
2N
N −3
N
3
2N

0
0
1
2N

N −4

N + 1

2N



,






(C.1)

and the contribution 1

2N from C3 to C4 has been neglected (see

P0, P1, P2, P3}

is computed by imposing P(t + 1)

P(t) = 0,

−

M

= 




C0, C1, C2, C3}

in which the basis is
Fig. C.2).
The stationary probability vector P =
i.e. (

{
I)P = 0. This condition gives

{

T

M

−

P0 =

133
227 ≈

0.586, P1 =

0.344, P2 =

0.062, P3 =

0.0088 .

(C.2)

78
227 ≈

14
227 ≈

2
227 ≈

· · ·

AAABBB

(of the type reported in
0.581, P1 = 0.344, P2 = 0.063, P3 = 0.01, that are plotted in Fig. C.3 together

Direct numerical simulations of the evolution of a line
Fig. C.1) yields P0 ≃
with the theoretical prediction, conﬁrming that our approximation is correct.
Having shown that the width of the interfaces remains small, we assume that they are punctual
objects localized around their central position x. For instance, in the previously mentioned example
with A and B clusters, we denote by xl the position of the right-most site of cluster A and by xr the
position of the left-most site of cluster B: the position of the interface is x = xl+xr
. An interaction
2
Cm′ , corresponds to a set of possible
involving sites at the interface, i.e. an interface transition Cm →

· · ·

151

(C.3)

(C.4)

(C.5)

(C.6)

(C.7)

Figure C.2: Truncated Markov process associated with interface width dynamics - schematic evolution
of a C0 interface

, cut at the maximal width m = 3.

AAABBB

· · ·

· · ·

movements for the central position x. Our purpose is that of writing down a master equation for the
movement of the interfaces.
The transition rates W (x
δ are
obtained by enumeration of all possible cases. Using the above approximation only three symmetric
3/2. These transition
contributions are present, corresponding to displacements of
probabilities receive contributions from interfaces with diﬀerent width. For instance, the Markov
matrix in Eq. C.1 says that the C1 interface AACBB evolves into the following conﬁgurations

δ) of an interface (its center) from a position x to a position x

1 and

1/2,

→

±

±

±

±

±

x

in which we have put also the corresponding displacement of the center’s position x.
Computing all possible transitions and grouping them according to the displacement δ, we obtain

AACBB =

⇒

AAABB
AABBB
ACCBB
AACCB
AACBB otherwise

3
2N
3
2N
1
2N
1
2N

x
x
x
x

x + 1
2 ,
1
2 ,
x
−
1
2 ,
x
−
x + 1
2 ,
x .

→
→
→
→
x

→






W (x

W (x

W (x

→

±

→

±

x

x

x

→

±

1
2
1) =
3
2

) =

) = 1

2N P0 + 1

N P1 + 1
2N P2 + 1

N P2 + 1
2N P3 ,

1

2N P3 ,

1
2N P3 .

Using the expressions for the stationary probability P0, . . . , P3, we ﬁnally get

W (x

x

→

±

1
2

) =

319
454N

, W (x

x

1) =

, W (x

→

±

8
227N

x

→

±

3
2

) =

1
227N

.

152

APPENDIX C. NAMING GAME SOLUTION IN D = 1

0
10

-2

10

-4

10

-6

10

m

P

0

2

6

8

4
m 

0.6

0.5

0.4

0.3

0.2

0.1

m

P

numerical
analytical

0

0

1

2

3

m (interface’s width)

Figure C.3: Numerical values of the probability of the interface’s width (circles) and corresponding
theoretical predictions (crosses) obtained as solution of the truncated Markov chain. The two sets of
values are in excellent agreement.

The knowledge of these transition probabilities allows us to write the master equation for the
(x, t) to ﬁnd the interface in position x at time t. In the limit of continuous time and

probability
space, expanding the single terms

P

(x + δx, t)

(x, t) + δx

(x, t) +

P

≈ P

∂
P
∂x

(x, t + 1)

(x, t)

δt

(x, t),

P

− P

∂
P
∂t

≈
(δx)2
2

∂2
∂x2 (x, t) ,

P

the master equation reduces to a standard diﬀusion equation

∂

P

(x, t)
∂t

=

D
N

∂2

(x, t)

P
∂x2

,

(C.8)

(C.9)

(C.10)

≃

0.221 is the theoretical value of the diﬀusion coeﬃcient (in the appropriate

where D = 401/1816
dimensional units (δx)2/δt).
These results are conﬁrmed by numerical simulations as illustrated in the Section 5.3.1 by Fig. 5.7,
where the numerical probability
(x, t) is reported. The latter is a Gaussian centered around the
initial position, with diﬀusion coeﬃcient Dexp ≃
The diﬀusion of interfaces and the consequent coarsening dynamics governing clusters growth are the
causes of the slow convergence of one-dimensional Naming Game model, that reaches the consensus
(N 2) if we rescale the time step by N as in statistical
absorbing state in tconv ∼ O
mechanics models).

(N 3) steps (

0.224

D.

O

≈

P

Appendix D

Master equation approach to agents
internal dynamics

In this appendix, we discuss a more rigorous derivation of the probability distribution
t) that
|
an agent of degree k has n words stored in its inventory (at time t) (see also Ref. [92]). Formally, the
master equation associated to the jump process observed in the numerical simulations for the number
of words (opinions, etc.) n in the inventory of a ﬁxed agent of degree k can be written as

Pn(k

Pn(k, t + 1)

− Pn(k, t) =

Wk(n

1
n
Pn−1(k, t)
t)
−
→
|
t)
− Wk(n
Pn(k, t)
1
|
→
Pj(k, t)
t)
j=2 Wk(j
|

Nd(t)

≥
2

− Wk(n

n + 1

Pn(k, t)
t)
|
n > 1

→
Nd(t)

(D.1)

P1(k, t + 1)

− Wk(1
where Nd(t) is the maximum number of diﬀerent words at a time t and
explicitly on the time.

− P1(k, t) =

P

→

1

P1(k, t) ,
t)
|

→
Pn(k, t + 1) depends a priori

In order to get an expression for the transition rates, we call Ct(k) the number of diﬀerent words
that are accessible to a node (of degree k) at time t, i.e. that are present in the neighborhood of the
node. This number is not known, so that we consider it as a parameter to be estimated a posteriori.
Nevertheless, the mean-ﬁeld type of dynamics that characterizes all small-world topologies, ensures
that the quantity Ct(k) depends mildly on k, so that in the following analysis we will often consider
it as function only of the time Ct. In small-world topologies, indeed, there is an initial spreading of
words throughout the network that destroys local correlations. The case of low-dimensional lattices
is diﬀerent since states can spread only locally, causing strong correlations between the inventories.
We deﬁne also the inverse quantity, ρt(k) = 1/Ct(k), that will be used in the following formulae for
notation’s convenience.
The probability of a successful negotiation is nρt(k), where n is the number of words in the inventory
of an hearer of degree k. Considering both the probabilities of the agent playing as hearer and speaker,
the transition rate

1

Wk(n

→

t) reads
|

t)
|
Analogously, using the failure probability 1

Wk(n

→

1

n
ρtih
pkh
≃
nρt(k),

i

+ qkρt(k)n .

(D.2)

where the average terms
boring sites of the node playing as speaker.

n
h

i

Wk(n
ρti
h

→
and

n + 1

≃

t)
|
comes from an uncorrelated mean-ﬁeld hypothesis for the neigh-

) + qk(1
i

ρt(k)n) .

n
ρtih

(D.3)

− h

−

−
pk(1

153

154

APPENDIX D. MASTER EQUATION APPROACH TO AGENTS INTERNAL DYNAMICS

0.08

0.06

n

P

0.04

0.02

0

0

0
10

-2

10

-4

10

-6

10

n

P

Pn(t1)
Pn(t2)
BA fit, a*exp(-bx

2
)

10

20

30

40

50

60

70

Pn(t1)
Pn(t2)
ER fit, a*exp(-b x)

0

20

40

80

100

120

60
nw

Figure D.1: Parametric dependence on time of the distribution of the number of words: the time has
the eﬀect of deforming the shape of the distribution, but does not change the functional form. (Top)
BA graph with N = 104 nodes with
= 10. Only the set of nodes with large k (hubs) is monitored.
k
h
i
105 time steps.
Histograms come from measurements at diﬀerent times t1 and t2 with t2 −
(Bottom) ER graph of N = 104 nodes and
= 10. Measures refer to a set of high-degree nodes
with t2 −

105 time steps.

t1 = 5

t1 = 5

k
h

i

·

·

An important remark concerns the temporal evolution of the master equation. From Eqs. D.2-D.3,
N . On the other hand,
we note that the timescale of the internal dynamics is fast, of order 1/pk ∝
the only time-dependent parameter is ρt(k) (or Ct(k)), that depends on the global behavior of the
system, whose dynamics is slower. Unfortunately, we do not know the exact behavior of this global
quantity, thus the only possible approach consists of considering it as an external modulation to the
internal dynamics. According to this argument, we study the stationary condition of Eq. D.2, and
compute the solution
t), in which we assume a parametric dependence of the distribution on the
|
time, governing its relaxation dynamics. We have veriﬁed this assumption measuring the distribution
at diﬀerent times. As displayed in Fig. D.1, the solution depends on the time, but the dependence has
the only eﬀect of deforming the shape during the evolution, without changing the functional form.
Plugging the expressions of the transition rates into the stationary master equation, we get the fol-
lowing recursion relation,

Pn(k

Pn(k

t) =
|

qk [1

qk [1
ρt(k)(n
nρt(k)] + qkρt(k)n + pkh

1)]

−

−

−

n
ρtih

i

Pn−1(k

t) .
|

Then, introducing qk = kpk/
n

1), Eq. D.4 can be rewritten as

k
h

i

≫

= b(k)pk and replacing ρt(k)(n

1) with ρt(k)n (that is true for

−

(D.4)

(D.5)

Pn(k

t) =
|

ρt(k)n]
b(k)[1
−
n
ρtih
b(k) +
h

i

Pn−1(k

t) .
|

155

-3

10

>
k
<
≈
k

 

 

W

-4

10

-5

10

BA,  W(n → 1)
BA,  W(n → n+1)

1
10
n

10

-6
0
10

2
10

ER, W(n → 1)
ER, W(n → n+1) 

1
10

n

-2

10

-3

10

-4

10

 

>
k
<
>
>
k

 

W

0
10

≃

Figure D.2: Probability of
N = 5000 nodes and k

Wk(n

t) and
→
|
200 (for a BA with

1

n + 1
→
= 10) and k

Wk(n
k
i
h

t) for BA and ER models. Both with
|
≃

70 (for a ER with

= 50).

k
h

i

Since nρt(k)

1, we can write 1

ρt(k)n

e−ρt(k)n, thus solving the recurrence relation,

≪

−

≃

b(k)

Pn(k

t)
|

n−1

e−ρt(k) (n+2)(n−1)

2

P1(k

t) .
|

(D.6)

(cid:20)

≃

b(k) +

n
ρtih
h
The normalization relation gives the constant
n
ρtih
st(k) = b(k)/(b(k) +
h
and a gaussian-like tail.
In the next two paragraphs, we focus on these two cases separately, showing that the two diﬀerent
results derive from diﬀerent forms of the transition rates, that can be also inferred from simulations.

t). The controlling parameter of the curve is
|
), that allows to tune the decay of the distribution between an exponential
i

i (cid:21)
P1(k

The case of homogeneous networks -
Exploiting the remark coming from simulations, in
Ct),
homogeneous networks, we can safely put qk ≃
since the nodes are almost equivalent. The number of states as well is almost the same for every node
that implies n

. The approximated expressions of the success and failure probabilities are
i

(1) and ρt(k)

bpk, with b

(i.e. Ct(k)

ρti

≃ O

≃ h

≃ h

≃

n

Wk(n
→

1

t)
→
|
n + 1

t)
|

≈

≈

n
pkh
pk(1

(1 + b)/Ct ≈
i
n
ρtih
− h

n
2pkh
)(1 + b)
≈
i

/Ct
i
2pk.

Wk(n

(D.7)

(D.8)

Wk(n

t) and
|

We have veriﬁed numerically the validity of these approximated expressions for the quantities
n + 1
almost constant). The data reported in Fig. D.2 (right) show that for an ER model with N = 5
nodes and
The equilibrium condition for the master equation becomes

→
t) (just the term for nodes playing as hearers, since the term for speakers is
|
103

= 50, both quantities are almost constant with respect to n.

Wk(n

k
h

→

1

i

·

0 = 2pkPn−1(k
0 =

t)
2pkPn(k
|
−
2
pkPj(k
n
Ct h
i
We can neglect the dependence on k, since pk is canceled, in agreement with the approximation done
for the homogeneity of the network. The solution by recursion is very simple,

n
pkh
Ct Pn(k
t)
i
|
t) .
2pkP1(k
t)
|
−
|

t)
|
∞
j=2

n > 1

(D.9)

P

−

2

Pn(t)

≈

(1

−

θt)θt

n−1 ,

θt =

1
1 + hni
Ct

.

(D.10)

156

APPENDIX D. MASTER EQUATION APPROACH TO AGENTS INTERNAL DYNAMICS

Using the expansion of logarithm log(1
−
gives the following exponential decay for the distribution of the number of words,

ǫt, with ǫt = 1

n
θt ≃ h

≃ −

ǫt)

−

/Ct, the previous formula
i

The exponential decay is in agreement with the numerical data, providing a value

0.16 for

Pn(t)

≃

n
i
h
Ct

e− hnin

Ct

.

(D.11)

n
h

/Ct.
i

≃

High-degree nodes in heterogeneous networks -

The other important case is that of the
hubs in heterogeneous networks. In a direct NG a hub is preferentially chosen as hearer, by a factor
k/
1, then we can neglect the ﬁrst terms in both success and failure probability. We consider
the following approximated expressions

i ≫

k
h

Wk(n

→

n + 1

qkρt(k)n ,

Wk(n
t)
≃
|

→
qk(1

1

t)
|

−

≃
ρt(k)n)

qk ,

≃

(D.12)

(D.13)

→

Wk(n

in which the last approximation is justiﬁed by the fact that the number of words accessible to a hub is
large, thus ρt(k) is expected to be small. For heterogeneous networks, the numerical data in Fig. D.2
(left) for
t) show a clear linear growth of the quantity with n, in agreement with Eq. D.2,
1
|
t) with n can be ﬁtted with an expression of the
n + 1
while the almost constant behavior of
|
form Eq. D.3 only for very small values of the product ρt(k)n. On the other hand, Fig. D.2 (bottom)
points out that in the case of homogeneous networks both the quantities are almost constant with
respect to n. We prove now that these diﬀerent behaviors of the transition rates are responsible of
t).
the diﬀerent shape of the probability distribution
Pn(k
|
{Pn(k
We can easily compute the quasi-stationary distribution

, from the ﬁrst equation in Eq. D.2

Wk(n

→

0 = qkPn−1(k

t)
|

qkPn(k

t)
|

−

−

(qk + qk

Pn(k
)

t) ,
|

t)
}
|
n
Ct(k)

and we ﬁnd recursively

Pn(k

t) = Ct(k)
|

Ct(k)+n Pn−1(k

(Ct(k)+n)(Ct(k)+n−1) Pn−2(k

t)
|

Ct(k)2

Ct(k)n−1Γ(Ct(k)+2)

t) =
|
Γ(Ct(k)+n+1) P1(k

t) .
|

≈
n=1 Pn(k

∞

Now, from the closure relation
t) becomes
for
|

Pn(k

P
Ct(k)n−1
Γ(Ct(k) + n + 1)

Pn(k

t) =
|

t) = 1 we get the expression of
|

P1(k

t), and the ﬁnal form
|

Ct(k)Ct(k)+1e−Ct(k)

Γ(Ct(k) + 1)
γ(Ct(k) + 1, Ct(k))

,

(cid:21)

(cid:20)

where γ(a, x) is the lower incomplete Gamma function. The functional form of the quasi-stationary
distribution is complicated, but exploiting some approximations for Gamma functions, it is possible
to write it in a simpler form (see Ref. [92] for details),

(D.14)

(D.15)

(D.16)

(D.17)

(D.18)

Pn(k

t)
|

≃ s

2
πCt(k)

e

−(n+1)2
2Ct (k)

.

This expresssion, corresponding to a Half-Normal distribution, is in very good agreement with the
It is remarkable that ﬁtting numerical results in Fig. 5.29 (top) with this
result of simulations.
Indeed, from simulations the constant prefactor is
expression gives a consistent value for Ct(k).
πCt(k) gives the very close value 0.0042.

357, that plugged into

0.0046 and Ct(k)

2

≃

≃

q

Bibliography

[1] Achlioptas, D., Clauset, A., Kempe, D., and Moore, C., ‘On the Bias of Traceroute Sampling;

or, Power-law Degree Distributions in Regular Graphs,’ in STOC’05, 694-703 (2005).

[2] Aiello, W., Chung, F., and Lu, L., ‘A random graph model for power law graphs,’ Experimental

Math. 10, 53-66 (2001).

Phys. Rev. Lett. 85, 5234 (2000).

74, 47-97 (2002).

Nature 406, 378 (2000).

[3] Albert, R., and Barab´asi, A. L., ‘Topology of Evolving Networks: Local Events and Universality,’

[4] Albert R., and Barab´asi, A. L., ‘Statistical mechanics of complex networks,’ Rev. Mod. Phys.

[5] Albert, R. A., Jeong, H., and Barab´asi, A. L., ‘Error and attack tolerance of complex networks,’

[6] Almaas, E., Kov´acs, B., Vicsek, T., Z. N. Oltvai and A. L. Barab´asi, ‘Global organization of

metabolic ﬂuxes in the bacterium Escherichia coli,’ Nature 427, 839 (2004).

[7] Alvarez-Hamelin, J. I., Dall’Asta, L., Barrat, A., and Vespignani, A., ‘k-core decomposition: a

tool for the visualization of large scale networks,’ preprint arxiv:cs/0504107 (2005).

[8] Alvarez-Hamelin, J. I., Dall’Asta, L., Barrat, A., and Vespignani, A., ‘k-core decomposition: a

tool for the analysis of large scale Internet graphs,’ preprint arxiv:cs/0511007 (2005).

[9] Alvarez-Hamelin, J. I., Dall’Asta, L., Barrat, A., and Vespignani, A., ‘Large scale networks ﬁn-
gerprinting and visualization using the k-core decomposition,’ in Advances in Neural Information
Processing Systems, NIPS ’05 18 (2005).

[10] Andrade Jr, J., Herrmann, H. J., Andrade, R. F. S., and da Silva, L. R., ‘Apollonian Networks:
Simultaneously Scale-Free, Small World, Euclidean, Space Filling, and with Matching Graphs,’
Phys. Rev. Lett. 94, 018702 (2005).

[11] Arenas, A., Danon, L., Diaz-Guilera, A., Gleiser, P., and Guimer`a, R., ‘Community analysis in

social networks,’ Eur. Phys. J. B 38(2), 373-380 (2004).

[12] Arenas, A., Diaz-Guilera, A., and Perez-Vicente, C. J., ‘Synchronization reveals topological

scales in complex networks,’ Phys. Rev. Lett. 96, 114102 (2006).

[13] Axelrod, R., ‘The Dissemination of Culture: A Model with Local Convergence and Global

Polarization,’ J. of Conﬂict Resolut. 41, 203, (1997).

157

158

BIBLIOGRAPHY

[14] Baiesi, M., Paczuski, M., and Stella, A. L., ‘Intensity Thresholds and the Statistics of the

Temporal Occurrence of Solar Flares,’ Phys. Rev. Lett. 96, 051103 (2006).

[15] Bak, P., Christensen, K., Danon, L., and Scanlon, T., ‘Uniﬁed Scaling Law for Earthquakes,’

Phys. Rev. Lett. 88, 178501 (2002).

[16] Baldi, P., Frasconi P., and Smyth, P., Modeling the Internet and the Web: Probabilistic methods

and algorithms, Wiley, Chichester, (2003).

[17] Barab´asi, A. L., and Albert, R., ‘Emergence of scaling in random networks,’ Science 286, 509-

512 (1999).

Physica A272, 173 (1999).

559-564 (2001).

[18] Barab´asi, A. L, Albert, R., and Jeong, H., ‘Mean-ﬁeld theory for scale-free random graphs,’

[19] Barab´asi, A. L., Ravasz, E., and Vicsek, T., ‘Deterministic scale-free networks,’ Physica A 299,

[20] Baronchelli, A., Dall’Asta, L., Barrat, A., and Loreto, V., ‘Topology Induced Coarsening in

Language Games,’ Phys. Rev. E 73, 015102(R) (2006).

[21] Baronchelli, A., Dall’Asta, L., Barrat, A., and Loreto, V., ‘Strategies for fast convergence in
semiotic dynamics,’ ALIFE X, Bloomington Indiana (2006), (preprint arxiv:physics/0511201).

[22] Baronchelli, A., Felici, M., Caglioti, E., Loreto, V., and Steels, L., ‘Sharp Transition towards

Shared Vocabularies in Multi-Agent Systems,’ preprint arxiv:physics/0509075 (2005).

[23] Barrat, A., Barth´elemy, M., Pastor-Satorras, R., and Vespignani, A., ‘The architecture of com-

plex weighted networks,’ Proc. Natl. Acad. Sci. 101, 3747-3752 (2004).

[24] Barrat, A., Barth´elemy, M., and Vespignani, A., ‘Weighted evolving networks: coupling topology

and weights dynamics,’ Phys. Rev. Lett. 92, 228701 (2004).

[25] Barrat, A., Barth´elemy, M., and Vespignani, A., ‘Modeling the evolution of weighted networks,’

Phys. Rev. E 70, 066149 (2004).

[26] Barrat, A., Barth´elemy, M., and Vespignani, A., ‘Traﬃc-driven model of the World Wide Web

graph,’ Lect. Notes Comp. Science 56, 3243 (2004).

[27] Barrat, A., Barth´elemy, M., and Vespignani, A., ‘The eﬀects of spatial constraints on the evo-

lution of weighted complex networks,’ J. Stat. Mech. P05003 (2005).

[28] Barrat, A., and Pastor-Satorras, R., ‘Rate equation approach for correlations in growing network

models,’ Phys. Rev. E 71, 036127 (2005).

[29] Barrat, A., and Weigt, M., ‘On the properties of small-world network models,’ Eur. Phys. J. B

13, 547 (2000).

163-168 (2004).

[30] Barrett, C. L., Eubank, S., Kumar, V. S. A., and Marathe, M. V., ‘Understanding Large-Scale
Social and Infrastructure Networks: A Simulation-Based Approach,’ SIAM News 37(4), (2004).

[31] Barth´elemy, M., ‘Betweenness Centrality in Large Complex Networks,’ Eur. Phys. J. B 38,

BIBLIOGRAPHY

159

[32] Barth´elemy, M., and Amaral, L. A. N., ‘Small-world networks: evidence for a crossover picture,’

Phys. Rev. Lett. 82, 3180 (1999).

[33] Barth´elemy, M., Barrat, A., Pastor-Satorras, R., and Vespignani, A., ‘Dynamical patterns of
epidemic outbreaks in complex heterogeneous networks,’ Jour. Theor. Biol. 235, 275-288 (2005).

[34] Barth´elemy, M., Gondran, B., and Guichard, E., ‘Spatial Structure of the Internet Traﬃc,’

Physica A 319, 633-642 (2003).

[35] Bender, E. A., and Canﬁeld, E. R., ‘The asymptotic number of labeled graphs with given degree

distribution,’ Journal of Combinatorial Theory A, 24, 296-307 (1978).

[36] Ben Naim, E., Frachebourg, L., and Krapivsky, P. L., ‘Coarsening and Persistence in the Voter

Model,’ Phys. Rev. E 53, 30783087 (1996).

[37] Bettencourt, L. M. A., Cintr`on-Arias, A., Kaiser, D. I., and Castillo-Ch`avez, C., ‘The power of
a good idea: quantitative modeling of the spread of ideas from epidemiological models,’ preprint
arxiv:physics/0502067 (2005).

[38] Bialas, P., Burda, Z., Jurkiewicz, J., and Krzywicki, A., ‘Tree networks with causal structure,’

[39] Bianconi, G., ‘Power-law strength-connectivity dependence in weighted scale-free networks,’

[40] Bianconi, G., and Barab´asi, A. L., ‘Competition and multiscaling in evolving networks,’ Euro-

[41] Billingsley, P., Ergodic Theory and Information, Wiley (1965).

[42] Blume, L., The statistical Mechanics of Social Interaction, Mimeo, Cornell University, Ithaca,

Phys. Rev. E 67, 066106 (2003)

Europhys. Lett. 71, 1029 (2005).

phys. Lett. 54 436-442 (2001).

N.Y. (1991).

Phys. Rev. E 66, 047104 (2002).

[43] Bogu˜n´a, M., and Pastor-Satorras, R., ‘Epidemic spreading in correlated complex networks,’

[44] Bogu˜n´a, M., Pastor-Satorras, R., and Vespignani, A., ‘Absence of epidemic threshold in scale-

free networks with degree correlations,’ Phys. Rev. Lett 90, 08701 (2003).

[45] Bogu˜n´a, M., Pastor-Satorras, R., and Vespignani. A., ‘Epidemic spreading in complex networks

with degree correlations,’ Lecture Notes in Physics 625, 127-147 (2003).

[46] Bogu˜n´a, M., and Serrano, M. ´A., ‘Generalized percolation in random directed networks,’ Phys.

Rev. E 72, 016106 (2005).

Press, 35-57 (1984).

[47] Bollob´as, B., in Graph Theory and Combinatorics, conference in honor of Paul Erd¨os, Academic

[48] Bollob´as, B., Random Graphs, Academic Press, New York (1985).

[49] B¨orner, K., Dall’Asta, L., Ke, W., and Vespignani, A., ‘Studying The Emerging Global Brain:
Analyzing And Visualizing The Impact Of Co-Authorship Teams,’ Complexity 10(4), 57-67
(2005).

160

BIBLIOGRAPHY

[50] Bouchaud, J.-P., ‘Weak ergodicity breaking and aging in disordered systems,’ J. Phys. I France

2, 1705-1713 (1992).

[51] Bouchaud, J.-P., and Georges, A., ‘Anomalous diﬀusion in disordered media: Statistical mech-

anisms, models and physical applications,’ Phys. Rep. 195, 127 (1990).

[52] Boyer, D., and Miramontes, O., ‘Interface motion and pinning in small-world networks,’ Phys.

Rev. E 67, 035102 (2003).

(2001).

[53] Brandes, U., ‘A Faster Algorithm for Betweenness Centrality,’ J. Math. Soc. bf 25(2), 163–177,

[54] Bray, A., ‘Theory of phase-ordering kinetics,’ Adv. in Phys. 51, 481 (2002).

[55] Brimberg, J., Hansen, P., Lih, K.-W., Mladenovic, N., and Breton, M., ‘An oil pipeline design

problem,’ Operations Research 51, 228-239 (2003).

[56] Briscoe, T., Linguistic evolution through language acquisition: formal and computational models,

Cambridge University Press, Cambridge (1999).

[57] Broido, A., and Claﬀy, K. C., ‘Internet topology: connectivity of IP graphs,’ San Diego Pro-
ceedings of SPIE International symposium on Convergence of IT and Communication, Denver,
(2001).

[58] Bruggeman, D. A. G., ‘The calculation of various physical constants of heterogeneous substances.
I. The dielectric constants and conductivities of mixtures composed of isotropic substances,’ Ann.
Phys. (Liepz.) 24, 636 (1935).

[59] Bunde, A., and Havlin, S., ‘Percolation I’ and ‘Percolation II,’ in Fractals and Disordered Systems

, Springer, second edition , (1996).

[60] Bunge, J., and Fitzpatrick, M., ‘Estimating the Number of Species: A Review,’ Journal of the

American Statistical Association 88, 364-373 (1993).

[61] Burch, H., and Cheswick, B., ‘Mapping the internet,’ IEEE computer, 32(4), 97–98 (1999).

[62] CAIDA - Cooperative Association for Internet Data Analysis, located at the San Diego Super-

computer Center (see “http://www.caida.org/home/”).

[63] Caldarelli, G., Capocci, A., De Los Rios, P., and Mu˜noz, M. A., ‘Scale-Free Networks from

Varying Vertex Intrinsic Fitness,’ Phys. Rev. Lett. 89, 258702 (2002).

[64] Callaway, D. S., Hopcroft, J. E., Kleinberg, J. M., Newman, M. E. J., and Strogatz, S. H., ‘Are

randomly grown graphs really random?,’ Phys. Rev. E 64, 041219 (2001).

[65] Callaway, D. S., Newman, M. E. J., Strogatz, S. H., and Watts, D. J., ‘Network robustness and

fragility: percolation on random graphs,’ Phys. Rev. Lett. 85, 5468-5471 (2000).

[66] Carmi,

S.,

Havlin,

S.,

Kirkpatrick,

S.,

Shavitt,

Y.,

and

Shir,

E.,

“http://www.cs.huji.ac.il/~kirk/Jellyfish_Dimes.ppt” (2005).

[67] Carmi, S., Havlin, S., Kirkpatrick, S., Shavitt, Y., and Shir, E., “MEDUSA - New Model of
Internet Topology Using k-shell Decomposition,’ preprint arxiv:cond-mat/0601240 (2006).

BIBLIOGRAPHY

161

[68] Castellano C., ‘Eﬀect of network topology on the ordering dynamics of voter models,’ AIP Conf.

Proc. 779, 114 (2005).

[69] Castellano, C., Loreto, V., Barrat, A., Cecconi, D., and Parisi, D., ‘Comparison of voter and

Glauber ordering dynamics on networks,’ Phys. Rev. E 71, 066107 (2005).

[70] Castellano, C., Vilone, D., and Vespignani, A., ‘Incomplete ordering of the voter model on

small-world networks,’ Europhys. Lett. 63 (1), 153-158 (2003).

[71] Catanzaro, M., Bogu˜n´a, M., and Pastor-Satorras, R., Phys. Rev. E 71, 027103 (2005).

[72] Cattuto, C., Loreto, V., and Pietronero, L., ‘Semiotic dynamics and collaborative tagging,’

preprint (2006).

[73] Challet, D., Marsili, M., Zhang, Y.-C., Minority Games : Interacting Agents in Financial Mar-

kets, Oxford Finance Series (2005).

[74] Chandrasekhar, S., ‘Stochastic problems in physics and astronomy,’ Rev. Mod. Phys. 15, 1-89

(1943).

(2005).

[75] Chen, P., and Redner, S., ‘Majority rule dynamics in ﬁnite dimensions,’ Phys. Rev. E 71, 036101

[76] Chen, Q., Chang, H., Govindan, R., Jamin, S., Shenker, S. J., and Willinger, W., ‘The Origin
of Power Laws in Internet Topologies Revisited,’ Proceedings of IEEE Infocom ’02, New York,
USA (2002).

[77] Clark, J., and Holton, D. A., A ﬁrst look at graph theory, World Scientiﬁc (1991).

[78] Clauset, A., and Moore, C., ‘Accuracy and Scaling Phenomena in Internet Mapping,’ Phys. Rev.

Lett. 94, 018701 (2005).

[79] Cohen, R., ben-Avraham, D., and Havlin, S., ‘Percolation critical exponents in scale-free net-

works,’ Phys. Rev. E 66, 036113 (2002).

[80] Cohen, R., Erez, K., ben-Avraham, D., and Havlin, S., ‘Resilience of the Internet to random

breakdown,’ Phys. Rev. Lett. 85, 4626-4628 (2000).

[81] Cowan, R., and Jonard, N., ‘Network structure and the diﬀusion of knowledge,’ Journal of

Economic Dynamics and Control, 28(8), 1557-1575 (2004).

[82] Cox, D. R., Renewal Theory, Methuen and Co. Ltd., London (1962).

[83] Daley, D. J.,and Kendall, D. G., ‘Epidemics and rumors,’ Nature 204, 1118 (1964).

[84] Dall’Asta, L., ‘Inhomogeneous percolation models for spreading phenomena in random graphs,’

J. Stat. Mech. P08011 (2005).

[85] Dall’Asta, L., Alvarez-Hamelin, J. I., Barrat, A., V´azquez, A., and Vespignani, A. ‘Traceroute-
like exploration of unknown networks: A statistical analysis,’ Lect. Notes Comp. Sci. 3405,
140-153 (2005).

[86] Dall’Asta, L., Alvarez-Hamelin, J. I., Barrat, A., V´azquez, A., and Vespignani, A., ‘Exploring
networks with traceroute-like probes: theory and simulations, Theor. Comp. Sci. 355, 6-24
(2006).

162

BIBLIOGRAPHY

[87] Dall’Asta, L., Alvarez-Hamelin, J. I., Barrat, A., V´azquez, A., and Vespignani, A., ‘Statistical

theory of Internet exploration,’ Phys. Rev. E 71 036135 (2005).

[88] Dall’Asta, L., Alvarez-Hamelin, J. I., Barrat, A., V´azquez, A., and Vespignani, A., ‘How accurate
are traceroute-like Internet mappings?,’ Comference Proc. AlgoTel ’05, INRIA, 31-34 (2005).

[89] Dall’Asta, L., Barrat, A., Barth´elemy, M., and Vespignani, A., ‘Vulnerability of weighted net-

works,’ J. Stat. Mech. in press, preprint arxiv:physics/0603163, (2006).

[90] Dall’Asta, L., Baronchelli, A., Barrat, A., and Loreto, V., ‘Agreement dynamics on small-world

networks,’ Europhys. Lett. 73(6), 969-975 (2006).

[91] Dall’Asta, L., Baronchelli, A., Barrat, A., and Loreto, V., ‘Non-equilibrium dynamics of lan-

guage games on complex networks,’ submitted to Phys. Rev. E (2006).

[92] Dall’Asta L., and Baronchelli, A., ‘Agents activity in Language Games on Complex Networks,’

in preparation.

[93] Danon, L., Dutch, J., Arenas, A., and Diaz-Guilera, A., ‘Comparing community structure iden-

tiﬁcation,’ J. Stat. Mech., P09008 (2005).

[94] Deﬀuant, G., Neau, D., Amblard, F., and Weisbuch, G., ‘Mixing beliefs among interacting

agents,’ Adv. Compl. Syst. 3, 87 (2001).

[95] De Montis, A., Barthelemy, M., Chessa, A., and Vespignani, A., ‘The structure of Inter-Urban

traﬃc: A weighted network analysis,’ preprint arxiv:physics/0507106, (2005).

[96] de Oliveira, S. M., de Oliveira, P. M. C., and Stauﬀer, D., Evolution, Money, War and Computers
- Non-Traditional Applications of Computational Statistical Physics, Teubner, Stuttgart (1999).

[97] Derrida, B., and Flyvbjerg, H., ‘Distribution of local magnetisations in random networks of

automata,’ J. Phys. A 20 5273-5288 (1987).

[98] DIMES,

Distributed

Internet

MEasurements

and

Simulations

(see

“http://www.netdimes.org”).

[99] Donnet, B., Raoult, P., Friedman, T., Crovella, M., ‘Eﬃcient Algorithms for Large-Scale Topol-

ogy Discovery,’ in Proc. ACM Sigmetrics 2005 (2005).

[100] Doods, P. S., Muhamad, R., and Watts, D. J., ‘An Experimental Study of Search in Global

Social Networks,’ Science 301, 827-829 (2003).

[101] Dornic, I., Chat´e, H., Chave, J., and Hinrichsen, H., ‘Critical Coarsening without Surface Ten-

sion: The Universality Class of the Voter Model,’ Phys. Rev. Lett. 87, 045701 (2001).

[102] Dorogovtsev, S. N., and Mendes, J. F. F., Evolution of Networks: from biological nets to the

Internet and WWW, Oxford University Press, Oxford, (2003).

[103] Dorogovtsev, S. N., and Mendes, J. F. F., ‘Evolution of networks,’ Adv. Phys. 51, 1079-1187

(2002).

[104] Dorogovtsev, S. N., Goltsev, A. V., and Mendes, J. F. F., ‘Ising model on networks with an

arbitrary distribution of connections,’ Phys. Rev. E 66, 016104 (2002).

BIBLIOGRAPHY

163

[105] Dorogovtsev, S. N., Mendes, J. F. F., and Samukhin, A. N., ‘Structure of Growing Networks

with Preferential Linking,’ Phys. Rev. Lett. 85, 4633 (2000).

[106] Dorogovtsev, S. N., Mendes, J. F. F., and Samukhin, A. N., ‘Size-dependent degree distribution

of a scale-free growing network,’ Phys. Rev. E 63, 062101 (2001).

[107] Dorogovtsev, S. N., and Mendes, J. F. F., ‘Minimal models of weighted scale-free networks,’

cond-mat/0408343.

[108] Dorogovtsev, S. N., Mendes, J. F. F., and Samukhin, A. N., ‘Giant strongly connected compo-

nent of directed networks,’ Phys. Rev. E 64, 025101(R) (2001).

[109] Drossel, B., and McKane, A. J., ‘Modelling food webs,’ in Handbook of Graphs and Networks:
From the Genome to the Internet, S. Bornholdt and H. G. Schuster eds., Wiley-VCH, Weinheim,
218-247 (2003).

[110] Dunne, J. A., Williams, R. J., and Martinez, N. D., ‘Small networks but not small worlds:
Unique aspects of food web structure,’ Proc. Natl. Acad. Sci. USA 99, 12917-12922 (2002).

[111] Durlauf, S. N., ‘Statistical Mechanics Approaches to Socioeconomic Behavior,’ in The Economy
as a Complex Evolving System II, W.B. Arthur, S.N. Durlauf and D. Lane eds., Redwood City,
Addison-Wesley (1997).

[112] Efron, B., ‘The jackknife, the bootstrap, and other resampling plans,’ Society of Industrial and

Applied Mathematics CBMS-NSF Monographs 38 (1982).

[113] Efron, B., and Thisted, R., ‘Estimating the Number of Unseen Species: How Many Words Did

Shakespeare Know?,’ Biometrika 63, 435-447 (1976).

[114] Elandt-Johnson, R., and Johnson, N., Survival Models and Data Analysis, Wiley, New York

[115] Erd¨os, A., and R´enyi, A., ‘On random graphs,’ Publicationes Mathematicae 6, 290-297 (1959).

[116] Erd¨os, P., and R´enyi, A., ‘On the evolution of random graphs’, Publications of the Mathematical

Institute of the Hungarian Academy of Sciences 5, 17-61 (1960).

[117] Erg¨un, G., and Rodgers, G. J., ‘Growing random networks with ﬁtness,’ Physica A 303, 261-272

(1999).

(2002).

[118] Essam, J. W., ‘Percolation Theory,’ Rep. Prog. Phys. 43, 833-912 (1980).

[119] Esty, W. W., ‘Estimation of the Size of a Coinage: A Survey and Comparison of Methods,’

Numismatic Chronicle 146, 185-215 (1986).

[120] Faloutsos, M., Faloutsos, P., and Faloutsos, C., ‘On Power-law Relationships of the Internet

Topology,’ ACM SIGCOMM ’99, Comput. Commun. Rev. 29, 251-262 (1999).

[121] Feller, W., An Introduction to Probability Theory and its Application, Wiley (1950).

[122] Frachebourg, L., and Krapivsky, P. L., ‘Exact results for kinetics of catalytic reactions,’ Phys.

Rev. E 53, R3009R3012 (1996).

164

BIBLIOGRAPHY

[123] Freeman, L., ‘A Set of Measures of Centrality Based on Betweenness,’ Sociometry 40, 35-41

[124] Frisch, H. L., and Hammersley, J. M., ‘Percolation processes and related topics,’ J. SIAM 11,

(1977).

894-918 (1963).

61, 943-951 (1990).

238, 66-80 (1997).

mat/0407680 (2004).

[125] Galam, S., ‘Social paradoxes of majority rule voting and renormalization group,’ J. Stat. Phys.,

[126] Galam, S., ‘Rational group decision making: A random ﬁeld ising model at T = 0,’ Physica A

[127] Gastner, M. T., and Newman, M. E. J., ‘The spatial structure of networks,’ preprint arxiv:cond-

[128] Girvan, M., and Newman, M. E. J., ‘Community structure in social and biological networks,’

Proc. Natl. Acad. Sci. USA 99, 8271-8276 (2002).

[129] Glauber, R. J., ‘Time-dependent statistics of the Ising model,’ J. Math. Phys. 4 294 (1963).

[130] Goh, K.-I., Kahng, B., and Kim, D., ‘Universal Behavior of Load Distribution in Scale-Free

Networks,’ Phys. Rev. Lett. 87, 278701 (2001).

[131] Goh, K.-I., Kahng, B., and Kim, D., ‘Packet transport and load distribution in scale-free network

models,’ Physica A 318, 72 (2003).

[132] Goh, K.-I., Salvi, G., Kahng, B., and Kim, D., ‘Skeleton and Fractal Scaling in Complex Net-

works,’ Phys. Rev. Lett. 96, 018701 (2006).

[133] Golder, S. A., and Huberman, B. A., ‘The structure of collaborative tagging systems,’ preprint

arxiv:cs.DL/0508082 (2005).

[134] Good, I. J., ‘On the population frequencies of species and the estimation of population param-

eters,’ Biometrika 40, 237264 (1953).

[135] Govindan, R., and Tangmunarunkit, H., ‘Heuristics for Internet Map Discovery,’ Proc. of IEEE

Infocom 2000, 3, IEEE Computer Society Press, 1371–1380 (2000).

[136] Granovetter, M. S., ‘Network Sampling: Some ﬁrst steps,’ American Journal of Sociology 81,

1287-1303 (1976).

Theory 1, 203-233 (1983).

[137] Granovetter, M. S., ‘The Strength of Weak Ties: A Network Theory Revisited,’ Sociological

[138] Grassberger, P., ‘On the critical behaviour of the general epidemic process and dynamical per-

colation,’ Math. Biosci. 63, 157-172 (1983).

[139] Guillaume, J.-L., and Latapy, M., ‘Relevance of Massively Distributed Explorations of the In-

ternet Topology: Simulation Results,’ IEEE 24th Infocom’05, Miami, USA (2005).

[140] Guimer`a, R., and Amaral, L. A. N., ‘Modeling the world-wide airport network,’ Eur. Phys. J.

B 38, 381-385 (2004).

BIBLIOGRAPHY

165

[141] Guimer`a, R., Mossa, S., Turtschi, A., and Amaral, L. A. N., ‘The worldwide air transportation
network: Anomalous centrality, community structure, and cities’ global roles,’ Proc. Natl. Acad.
Sci. USA 102, 7794-7799 (2005).

[142] Hegselmann, R., and Krause, U., ‘Opinion dynamics and bounded conﬁdence models,. analysis,

and simulation,’ J. Art. Soc. Soc. Sim. 5(3), paper 2 (2002).

[143] Holme, P. and Kim, B. J., ‘Growing scale-free networks with tunable clustering,’ Phys. Rev. E

65, 026107 (2002).

Phys. Rev. E 65, 056109 (2002).

[144] Holme, P., Kim, B. J., Yoon, C. N., Han, S. K., ‘Attack vulnerability of complex networks,’

[145] Hurford, J., Knight, C., and Studdert-Kennedy, M., (eds.), Approaches to the Evolution of

Human Language, Cambridge University Press (Cambraidge), 1999.

[146] Isichenko, M. B., ‘Percolation, statistical topography, and transport in random media,’ Rev.

Mod. Phys. 64, 961 (1992).

[147] ITP - Internet Topology Project, Electric Engineering and Computer Science Department, Uni-

versity of Michigan (see “http://topology.eecs.umich.edu/”).

[148] Jeong, H., Mason, S. P., Barab´asi, A. L., and Oltvai, Z. W., ‘Lethality and centrality in protein

networks,’ Nature 411, 41 (2001).

[149] Jin, C., Chen, Q., and Jamin, S., ‘INET: Internet topology generators,’ Tech. Rep. CSE-TR-

433-00, EECS Dept., University of Michigan, 2000.

[150] Kalisky, T., Braunstein, L. A., Buldyrev, S. V., Havlin, S., and Stanley, H. E., ‘Scaling of

optimal-path-lengths distribution in complex networks,’ Phys. Rev. E 72, 025102(R) (2005).

[151] Kaplan, F., Les machines apprivois´ees, Vuibert (2005).

[152] Kauﬀman, S. A., ‘Metabolic stability and epigenesis in randomly constructed genetic nets,’ J.

Theor. Biol. 22, 437 (1969).

[153] Kauﬀman, S. A., The Origins of Order: Self-organization and Selection in Evolution, Oxford

University Press, New York, Oxford (1993).

[154] Kendall, M., Rank Correlation Methods, Charles Griﬃn & Company Limited (1948).

[155] Kirby, S., ‘Natural Language from Artiﬁcial Life,’ Artiﬁcial Life 8, 185-215 (2002).

[156] Kirkpatrick, S., ‘Percolation and conduction,’ Rev. Mod. Phys. 45, 574-588 (1973).

[157] Klemm, K., and Egu´iluz, V. M., ‘Highly clustered scale-free networks,’ Phys. Rev. E 65, 036123

(2002).

(2003).

1067 (1992).

[158] Kossinets, G., ‘Eﬀects of missing data in social networks,’ preprint arxiv:cond-mat/0306335

[159] Krapivsky, P. L., ‘Kinetics of monomer-monomer surface catalytic reactions,’ Phys. Rev. A 45,

166

BIBLIOGRAPHY

[160] Krapivsky, P. L., and Redner, S., ‘Organization of growing random networks,’ Phys. Rev. E 63,

66123 (2001).

[161] Krapivsky, P. L., and Redner, S., ‘Dynamics of Majority Rule in Two-State Interacting Spin

Systems,’ Phys. Rev. Lett. 90, 238701 (2003).

[162] Krapivsky, P. L., Redner, S., and Leyvraz, F., ‘Connectivity of Growing Random Networks,’

Phys. Rev. Lett. 85, 4629 (2000).

[163] Lakhina, A., Byers, J. W., Crovella, M., and Xie, P., ‘Sampling Biases in IP Topology Mea-
surements,’ Technical Report BUCS-TR-2002-021, Department of Computer Sciences, Boston
University (2002).

[164] Landauer, R., ‘The electrical resitance of binary metallic mixtures,’ J. Appl. Phys. 24, 779

[165] LANET-VI, LArge NETwork VIsualization tool (see “http://xavier.informatics.indiana.edu/lanet-vi/”).

[166] Lass, R., Historical Linguistics and Language Change, Cambridge University Press (Cambridge),

(1952).

1997.

[167] LBL

-

Internet

mapping

project

at

Lucent

Bell

Labs

(see

“http://www.cs.bell-labs.com/who/ches/map/”).

[168] Lee, S. H., Kim, P. J., and Jeong, H., ‘Statistical properties of sampled networks’, Phys. Rev. E

73, 016102 (2006).

[169] Lee, J. W., Lee, K. E., Rikvold, P. A., ‘Waiting-time distribution for a stock-market index,’

Journal of Korean Physical Society 48, 123-126 (2006).

[170] Lenaerts, T., Jansen, B., Tuyls, K., and de Vylder, B., ‘The evolutionary language game: An

orthogonal approach,’ Journal of Theoretical Biology, 235, 566-582 (2005).

[171] Li, W., and Cai, X., ‘Statistical Analysis of Airport Network of China,’ Phys. Rev. E 69, 046106

[172] Ligget, T., Interacting particle systems, New York, Springer-Verlag (1985).

[173] May, R. M., and Lloyd, A. L., ‘Infection dynamics on scale-free networks,’ Phys. Rev. E 64,

[174] McNeil, D., ‘Estimating an Author’s Vocabulary,’ Journal of the American Statistical Associa-

[175] Meakin, P., Fractals, scaling and growth far from equilibrium, Cambridge University Press,

(2004).

066112 (2001).

tion 68, 92-96 (1973).

Cambridge (1998).

[176] Medina, A., and Matta, I., ‘BRITE: a ﬂexible generator of Internet topologies,’ Tech. Rep.

BU-CS-TR-2000-005, Boston University, 2000.

[177] Milgram, S., ‘The small world problem,’ Psychology Today 2, 60-67 (1967).

[178] Milo, R., Shen-Orr, S., Itzkovitz, S., Kashtan, N., Chklovskii, D., and Alon, U., ‘Network Motifs:

Simple Building Blocks of Complex Networks,’ Science 298, 824-827 (2002).

BIBLIOGRAPHY

167

[179] Mobilia, M., and Redner, S., ‘Majority versus minority dynamics: Phase transition in an inter-

acting two-state spin system,’ Phys. Rev. E 68, 046106 (2003).

[180] Molloy, M., and Reed, B., ‘A critical point for random graphs with a given degree sequence,’

Random Structures and Algorithms 6. 161-180 (1995).

[181] Molloy, M., and Reed, B., ‘The size of the giant component of a random graph with a given

degree sequence,’ Combinatorics, Probability and Computing 7, 295-305 (1998).

[182] Moore, C., and Newman, M. E. J., ‘Epidemics and percolation in small-world networks,’ Phys.

Rev. E 61 (2000) 5678-5682.

[183] Moore, C., and Newman, M. E. J., ‘Exact solution of site and bond percolation on small-world

networks,’ Phys. Rev. E 62 (2000) 7059-7064.

[184] Moreno, Y., Pastor-Satorras, R., and Vespignani, A., ‘Epidemic outbreaks in complex heteroge-

neous networks,’ Eur. Phys. J. B 26, 521-529 (2002).

[185] Moreno Y., and V´azquez, A., ‘Disease spreading in structured scale-free networks,’ Eur. Phys.

J. B 31, 265-271 (2003).

[186] Mossa, S., Bart´elemy, M., Stanley, H. E., and Amaral, L. A. N., ‘Truncation of power law
behavior in scale-free network models due to information ﬁltering,’ Phys. Rev. Lett. 88, 137701
(2001).

[187] Newman, M. E. J., ‘Scientiﬁc collaboration networks:I. Network construction and fundamental

results,’ Phys. Rev. E 64 016131 (2001).

[188] Newman, M. E. J., ‘Spread of epidemic diseases on networks,’ Phys. Rev. E 64, 016128 (2002).

[189] Newman, M. E. J., ‘Assortative mixing in networks,’ Phys. Rev. Lett. 89, 208701 (2002).

[190] Newman, M. E. J., ‘Mixing patterns in networks,’ Phys. Rev. E 67, 026126 (2003).

[191] Newman, M. E. J., ‘The structure and function of complex networks,’ SIAM Review 45, 167-256

[192] Newman, M. E. J., ‘Coauthorship networks and patterns of scientiﬁc collaboration,’ Proc. Natl.

Acad. Sci. USA 101, 5200-5205 (2004).

[193] Newman, M. E. J., ‘Detecting community structure in networks,’ Eur. Phys. J. B 38 321-330

(2003).

(2004).

[194] Newman, M. E. J., Moore, C., and Watts, D. J., ‘Mean-ﬁeld solution of the small-world network

model,’ Phys. Rev. Lett. 84, 3201 (2000).

[195] Newman, M. E. J., and Watts, D. J., ‘Renormalization group analysis of the small-world network

model,’ Phys. Lett. A 263, 341 (1999).

[196] NLANR, The National Laboratory for Applied Network Research, sponsored by the National

Science Foundation (see “http://moat.nlanr.net/”).

[197] Omori, F., ‘On Aftershocks of Earthquakes,’ J. Coll. Sci. Imp. Univ. Tokyo 7, 11-200 (1894).

168

BIBLIOGRAPHY

[198] Palla, G., Der´enyi, I., Farkas, I., and Vicsek, T., ‘Uncovering the overlapping community struc-

ture of complex networks in nature and society,’ Nature 435, 814-818 (2005).

[199] Pansiot, J.-J., and Grad, D., ‘On routes and multicast trees in the Internet,’ ACM Comp. Comm.

Rev. 28, 41 (1998).

[200] Pant, G., Srinivasan, P., and Menczer, F., ‘Crawling the Web,’ Web Dynamics, 153-178 (2004).

[201] Pastor-Satorras, R., and Vespignani, A., ‘Epidemic spreading in scale-free networks,’ Phys. Rev.

Lett. 86, 3200-3203 (2001).

[202] Pastor-Satorras, R., and Vespignani, A., ‘Epidemic dynamics and endemic states in complex

networks,’ Phys. Rev. E 63, 066117 (2001).

[203] Pastor-Satorras, R., and Vespignani, A., Evolution and structure of the Internet: a statistical

physics approach, Cambridge University Press, (2004).

[204] Pellegrini, M., Haynor, D., and Johnson, J. M., ‘Protein Interaction Networks,’ Expert Rev.

Proteomics 1(2), 89-99 (2004).

[205] Petermann, T., and De Los Rios, P., ‘Exploration of Scale-Free Networks: Do we measure the

real exponents?,’ Eur. Phys. J. B 38, 201-204 (2004).

[206] Pimm, S. L., Food Webs, Chapman and Hall, London (1982).

[207] Press, W. H., Flannery, B. P., Teukolsky, S. A., and Vetterling, W. T., Numerical recipes in

Fortran, Cambridge University Press, 2nd Edition (1992).

[208] G. Quenouille, ‘Notes on bias in estimation,’ Biometrika 43, 353-360 (1956).

[209] Rapoport, A., and Chammah, A. M., Prisoner’s dilemma, University of Michigan Press, Ann

Arbor, (1965).

[210] Ravasz, E., Somera, A. L., Mongru, D. A., Oltvai, Z. N., and Barab´asi, A. L., ‘Hierarchical

Organization of Modularity in Metabolic Networks,’ Science 297, 1551-1555 (2002).

[211] Reichardt, J., and Bornholdt, S., ‘Detecting fuzzy communities in complex networks with a

Potts model,’ Phys. Rev. Lett. 93, 218701 (2004).

[212] Reichardt, J., and Bornholdt, S., ‘Statistical Mechanics of community detection,’ preprint arxiv:

[213] Robbins, H., and Zhang, C.-H., ‘Eﬃciency of the u, v method of estimation,’ Proc. Natl. Acad.

cond-mat/0603718 (2006).

Sci. USA 97, 12976-12979 (2000).

[214] Rogers, E., The diﬀusion of innovations, Free Press, New York (1995).

[215] Rothenberg, R. B., ‘Commentary: Sampling in Social Networks,’ Connections 18 104-110 (1995).

[216] ROUTEVIEWS,

University

of

Oregon

Route

Views

Project

(see

“http://www.routeviews.org/”).

[217] Sander, L. M., Warren, C. P., Sokolov, I. M., Simon, C., and Koopman, J., ‘Percolation on

disordered networks as a model for epidemics,’ Math. Biosci. 180, 293-305 (2002).

(2005).

392-395 (2005).

(2005).

London (1994).

BIBLIOGRAPHY

169

[218] Scalas, E., Gorenﬂo, R., Luckock, H., Mainardi, F., Mantelli, M., and Raberto, M., ‘Anomalous
waiting times in high-frequency ﬁnancial data,’ Quantitative Finance 4, 695-702 (2004).

[219] SCAN project at the Information Sciences Institute (see “http://www.isi.edu/div7/scan/”).

[220] Schwartz, N., Cohen, R., ben-Avraham, D., Barab´asi, A. L., and Havlin, S., ‘Percolation in

directed scale-free networks,’ Phys. Rev. E 66, (2002).

[221] Seidman, S. B., ‘Network structure and minimum degree’, Social Networks 5, 269-287 (1983).

[222] Sen, P., Dasgupta, S., Chatterjee, A., Sreeram, P. A., Mukherjee, G., and Manna, S. S., ‘Small-

world properties of the Indian railway network,’ Phys. Rev. E 67, 036106 (2003).

[223] Serrano, M. ´A., Boguna, M.,

‘Percolation and epidemic thresholds in clustered networks,’

preprint arxiv:cond-mat/0603353 (2006).

[224] Shavitt, Y., and Shir, E., ‘DIMES: Let the Internet Measure Itself,’ preprint arxiv:cs.NI/0506099

[225] Song, C., Havlin, S., and Makse, H. A., ‘Self-similarity of complex networks,’ Nature 433,

[226] Song, C., Havlin, S., and Makse, H. A., ‘Origins of fractality in the growth of complex networks,’

Nature Physics 2(4), 275-281 (2006).

[227] Sood, V., and Redner, S., ‘Voter Model on Heterogeneous Graphs,’ Phys. Rev. Lett. 94, 178701

[228] Stauﬀer, D., and Aharony, A., Introduction to Percolation Theory, 2nd Edition, Taylor & Francis,

[229] Steels, L., ‘A Self-Organizing Spatial Vocabulary,’ Artiﬁcial Life 2(3), 319-332 (1995).

[230] Steels, L., ‘The Origins of Ontologies and Communication Conventions in Multi-Agent Systems’,

Autonomous Agents and Multi-Agent Systems 1, 169-194 (1998).

[231] Steels, L., The Talking Heads Experiment. Volume 1. Words and Meanings, Laboratorium,

Antwerpen (Belgium), 1999.

[232] Steels, L., ‘Language as a complex adaptive system,’ Proceedings of PPSM VI in Lecture Notes

in Computer Science, Springer-Verlag, Berlin (Germany), 2000.

[233] Stumpf, M. P. H., Wiuf, C., and May, R. M., ‘Subsets of scale-free networks are not scale-free:

Sampling properties of networks,’ Proc. Natl. Acad. Sci. 102 4221-4224 (2005).

[234] Suchecki, K., Egu´iluz, V. M., and San Miguel, M., ‘Voter model dynamics in complex networks:
Role of dimensionality, disorder, and degree distribution ,’ Phys. Rev. E 72, 036132 (2005).

[235] Sznajd-Weron, K., and Sznajd, J., ‘Opinion evolution in closed community,’ Int. J. Mod. Phys.

[236] Thomson, S. K., Sampling, Wiley and Sons, New York (2002).

[237] Toroczkai, Z., and Bassler, K. E., ‘Jamming is limited in scale-free systems,’ Nature 428, 716

C 11, 1157 (2000).

(2004).

170

BIBLIOGRAPHY

[238] Tukey, J. W., ‘Bias and conﬁdence in not quite large samples,’ Annals of Mathematical Statistics

29, 614 (1958).

[239] Uetz, P. L., Giot, L., Cagney, G., Mansﬁeld, T. A., Judson, R. S., Knight, J. R., Lockshon, D.,
Narayan, V., Srinivasan, M., Pochart, P., Qureshi-Emili, A., Li, Y., Godwin, B., Conover, D.,
Kalbﬂeisch, T., Vijayadamodar, G., Yang, M., Johnston, M., Fields, S., and Rothberg, J. M.,
‘A comprehensive analysis of proteinprotein interactions in Saccharomyces cerevisiae,’ Nature
403, 623 (2000).

[240] V´azquez, A., and Moreno, Y., ‘Resilience to damage of graphs with degree correlations,’ Phys.

Rev. E 67, 015101 (2003).

[241] V´azquez, A., Pastor-Satorras, R., and Vespignani, A., ‘Large-scale topological and dynamical

properties of the Internet,’ Phys. Rev. E 65, 066130 (2002).

[242] Viger, F., Barrat, A., Dall’Asta, L., Zhang, C.-H., and Kolaczyk, E., ‘Network Inference from
Traceroute Measurements: Internet Topology ‘Species’,’ preprint arxiv:cs/0510007 (2005).

[243] Wang, W. X., Wang, B. H., Hu, B., Yan, G., and Ou, Q., ‘General Dynamics of Topology and

Traﬃc on Weighted Technological Networks,’ Phys. Rev. Lett. 94, 188702 (2005).

[244] Warren, C. P., Sander, L. M., and Sokolov, I. M., ‘Firewalls, disorder, and percolation in

epidemics,’ Physica A 325, 1-8 (2003).

[245] Wasserman, S., and Faust, K., Social Network Analysis: Methods and Applications, Cambridge

University Press, Cambridge and New York (1994).

[246] Watts, D. J., Six Degrees: The Science of a Connected Age, W.W. Norton & Company, New

[247] Watts, D. J., and Strogatz, S. H., ‘Collective dynamics of small-world networks,’ Nature 393,

[248] West, B. I., and Deering, B., ‘Fractal physiology for physicists: L´evy statistics,’ Phys. Rep. 246,

[249] Wheatland, M. S., ‘The Origin of the Solar Flare Waiting-Time Distribution,’ Astrophys J.

536(2), L109-L112 (2000).

[250] Wilf, H. S., Generatingfunctionology, 2nd Edition, Academic Press, London (1994).

[251] Williams, R. J., and Martinez, N. D., ‘Simple rules yield complex food webs,’ Nature 404,

[252] Yook, S. H., Jeong, H., Barabasi, A. L., and Tu, Y., ‘Weighted Evolving Networks,’ Phys. Rev.

York (2003).

440–442 (1998).

1 (1994).

[253] Zaslavsky, G. M., ‘Chaos, fractional kinetics, and anomalous transport,’ Phys. Rep. 371, 461-580

[254] Zhou, T., Yan, G., and Wang, B. H., ‘Maximal planar networks with large clustering coeﬃcient

and power-law degree distribution,’ Phys. Rev. E 71, 046141 (2005).

180-183 (2000).

Lett. 86, 5835-5838 (2001).

(2002).

