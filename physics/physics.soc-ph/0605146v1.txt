6
0
0
2
 
y
a
M
 
7
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
6
4
1
5
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

FNT/T 2006/04

A Non-Gaussian Approach to Risk Measures

Giacomo Bormetti a,b Enrica Cisana a,b Guido Montagna a,b
and Oreste Nicrosini b,a

aDipartimento di Fisica Nucleare e Teorica, Universit`a di Pavia
Via A. Bassi 6, 27100, Pavia, Italy
bIstituto Nazionale di Fisica Nucleare, sezione di Pavia
Via A. Bassi 6, 27100, Pavia, Italy

Abstract

Reliable calculations of ﬁnancial risk require that the fat-tailed nature of prices
changes is included in risk measures. To this end, a non-Gaussian approach to
ﬁnancial risk management is presented, modeling the power-law tails of the returns
distribution in terms of a Student-t distribution. Non-Gaussian closed-form solutions
for Value-at-Risk and Expected Shortfall are obtained and standard formulae known
in the literature under the normality assumption are recovered as a special case.
The implications of the approach for risk management are demonstrated through
an empirical analysis of ﬁnancial time series from the Italian stock market and in
comparison with the results of the most widely used procedures of quantitative
ﬁnance. Particular attention is paid to quantify the size of the errors aﬀecting the
market risk measures obtained according to diﬀerent methodologies, by employing
a bootstrap technique.

Key words: Econophysics; Financial risk; Risk measures; Fat-tailed distributions;
Bootstrap
pacs: 05.10.Ln - 05.45.Tp - 89.65.Gh

Preprint submitted to Elsevier Science

21 September 2013

1 Introduction

A topic of increasing importance in modern economy and society is the devel-
opment of reliable methods of measuring and controlling ﬁnancial risks. Ac-
cording to the new capital adequacy framework, commonly known as Basel II
accord [1], any ﬁnancial institution has to meet stringent capital requirements
in order to cover the various sources of risk that they incur as a result of
their normal operation. Basically, three diﬀerent categories of risk are of in-
terest: credit risk, operational risk and market risk. In particular, market risk
concerns the hazard of losing money due to the ﬂuctuations of the prices of
those instruments entering a ﬁnancial portfolio and is, therefore, particularly
important for ﬁnancial risk management.

In the ﬁnancial industry today, the most widely used measure to manage
market risk is Value-at-Risk (VaR) [2,3]. In short, VaR refers to the maximum
potential loss over a given period at a certain conﬁdence level and can be
used to measure the risk of individual assets and portfolios of assets as well.
Because of its conceptual simplicity, VaR has become a standard component
in the methodology of academics and ﬁnancial practitioners. Moreover, VaR
generally provides a reasonably accurate estimate of risk at a reasonable com-
putational time. Still, as discussed in the literature [3,4], VaR suﬀers from
some inconsistencies: ﬁrst, it can violate the sub-additivity rule for portfolio
risk, which is a required property for any consistent measure of risk, and, sec-
ondly, it doesn’t quantify the typical loss incurred when the risk threshold is
exceeded. To overcome the drawbacks of VaR, the Expected Shortfall (or Con-
ditional VaR) is introduced, and sometimes used in ﬁnancial risk management,
as a more coherent measure of risk.

Three main approaches are known in the literature and used in practice for
calculating VaR and Expected Shortfall. The ﬁrst method consists in assum-
ing some probability distribution function for price changes and calculating
the risk measures as closed-form solutions. This approach is called parametric
or analytical and is easy to implement since analytical expressions can often
be obtained. The parametric approach usually relies on the (log)normality as-
sumption for the returns distribution, although some analytical results using
non-Gaussian functional forms are available in the literature [5,6]. Actually, it
is well known that empirical price returns, especially in the limit of high fre-
quency, do not follow the Gaussian paradigm and are characterized by heavier
tails and a higher peak than a normal distribution. In order to capture the lep-
tokurtic (fat-tailed) nature of price returns, the historical simulation approach
is often used as an alternative to the parametric method. It employs recent
historical data and risk measures are derived from the percentiles of the dis-
tribution of real data. This method is potentially the most accurate because
it accounts for the real statistics of price changes but it is computationally

2

quite demanding (especially when applied to large portfolios) and absolutely
depending on the past history of empirical data. A third approach consists
in Monte Carlo simulations of the stochastic dynamics of a given model for
stock price returns and in calculating risk measures according to Monte Carlo
statistics. This method, however, requires very intensive simulations to achieve
risk measures predictions with acceptable numerical errors.

As a result of the present situation, reliable and possibly fast methods to calcu-
late ﬁnancial risk are strongly demanded. Inspired by this motivation, the aim
of this paper is to present a non-Gaussian approach to market risk manage-
ment and to describe its potentials, as well as limitations, in comparison with
standard procedures used in ﬁnancial analysis. To capture the excess of kurto-
sis of empirical data with respect to the normal distribution, the statistics of
price changes is modeled in terms of a Student-t distribution, which is known
to approximate with good accuracy the distribution derived from market data
at a given time horizon [3,7] and is widely used in the ﬁnancial literature. In
the econophysics literature, the Student-t distribution is also known as Tsal-
lis distribution, emerging within the framework of statistical physics [8]. It
has been shown in various studies [8,9] that the distribution of returns can
be modeled quite well by a Tsallis distribution, which, for this reason, has
been already used in a number of ﬁnancial applications, ranging from option
pricing [10] to risk analysis [11]. However, with respect to the investigation of
Ref. [11], we include in our analysis the study of the Expected Shortfall and
we present, in the spirit of a parametric approach, analytical expressions for
the risk measures in order to provide accessible results for a simple practical
implementation. At a variance of the recent calculation in Ref. [6], where ana-
lytical results for risk measures using Student-t distributions are presented, we
critically investigate the implications of our non-Gaussian analytical solutions
on the basis of an empirical analysis of ﬁnancial data and we perform detailed
comparisons with the results of widely used procedures.

The paper is organized as follows. In Section 2 non-Gaussian closed-form ex-
pressions for VaR and Expected Shortfall are derived as generalizations of the
analytical formulae known in the literature under the normality assumption.
It is also shown how the standard Gaussian formulae of the parametric ap-
proach are recovered, in the appropriate limit, as a special case. In Section 3
an empirical analysis of daily returns series from the Italian stock market is
performed, in order to constrain the Student-t parameters entering the for-
mulae of Section 2 and to describe the ingredients needed for the forecoming
risk analysis. The latter is carried out in Section 4. The implications of the
parametric non-Gaussian approach for VaR and Expected Shortfall are shown
in Section 4 and compared with the results of the parametric normal method,
of its improved version known as RiskMetrics methodology and of the histor-
ical simulation. Particular attention is paid to quantify the size of the errors
aﬀecting the various risk measures, by employing a bootstrap technique. Con-

3

clusions and possible perspectives are drawn in Section 5.

2 Non-Gaussian closed-form expressions for risk measures

Value-at-Risk is referred to the probability of extreme losses in a portfolio
value due to adverse market movements. In particular, for a given signiﬁcance
⋆ (typically 1% or 5%), VaR, usually denoted as Λ⋆, is deﬁned as the
level
maximum potential loss over a ﬁxed time horizon ∆t. In terms of price changes
.
= ∆S/S, VaR can be computed as follows
∆S, or, equivalenty, of returns R

P

⋆ .
=

P

Λ⋆

−

Z

−∞

Λ⋆/S

−

Z

−∞

d∆S ˜P∆t(∆S) = S

dR P∆t(R),

(1)

where ˜P∆t(∆S) and P∆t(R) are the probability density functions (pdfs) for
price changes and for returns over a time horizon ∆t, respectively. For ﬁnancial
analysts, VaR has become the standard measure used to quantify market risk
because it has the great advantage to aggregate several risk component into
a single number. In spite of its conceptual simplicity, VaR shows two main
drawbacks: it is not necessarly subadditive and it does not quantify the size
of the potential loss when the threshold Λ⋆ is exceeded.

A quantity that does not suﬀer of these disadvantages is the so called Expected
Shortfall (ES) or Conditional VaR (CVaR), E⋆. It is deﬁned as

E⋆ .
=

Λ⋆

−

Z

−∞

1
⋆

P

d∆S (

∆S) ˜P∆t(∆S) =

−

dR (

R) P∆t(R),

(2)

−

Λ⋆/S

−

Z

−∞

S
⋆

P

with

⋆ and Λ⋆ as in Eq. (1).

P

The standard approach in the ﬁnancial literature [2,12] is to assume the returns
(m, σ2). In
as normally distributed, with mean m and variance σ2, i.e. R
that case, VaR and ES analytical expressions reduce to the following closed-
form formulae

∼ N

Λ⋆ =

mS0 + σS0√2 erfc−

1(2

⋆)

−

P

(3)

and

E⋆ =

mS0 +

−

σS0
⋆

P

exp

1
√2π
P
1 is the inverse of the complementary error

[erfc−

⋆)]2

1(2

{−

(4)

}

,

where S0 is the spot price and erfc−
function [13].

However, it is well known from several studies, especially in the econophysics
literature [3,7,14], that the normality hypothesis is often inadeguate for daily
returns and, more generally, for high-frequency stock price variations. A better

4

Fig. 1. Convergence of the VaR (left) and ES (right) Student-t formulae toward
Gaussian results when approaching the limit ν
 10

∞

→

+

 10

.

1%

5%

1%

5%

Normal
ν = 2.75
ν = 3.50
ν = 4.50
ν = 100

⋆
Λ

 9

 8

 7

 6

 5

 4

 3

 2

 1

 0
 0.001

⋆
E

 9

 8

 7

 6

 5

 4

 3

 2

 1
 0.001

 0.01

 0.02

 0.03

 0.04

 0.05

 0.06

 0.07

 0.08

 0.09

 0.1

 0.01

 0.02

 0.03

 0.04

 0.05

 0.06

 0.07

 0.08

 0.09

 0.1

⋆

P

⋆

P

agreement with data is obtained using leptokurtic distributions, such as trun-
cated L´evy distributions or Student-t ones. In spite of this interesting feature,
the former family has the main disadvantage that it is deﬁned only throught
its characteristic function and we have no analytic expression for the pdfs [15].
Moreover, in order to compute the cumulative density function (cdf), which
is a necessary ingredient of our analysis, we have to resort to numerical ap-
proximations. For the reasons above, to model the returns, we make use of a
Student-t distribution deﬁned as

ν
m,a(R) =

S

1
B(ν/2, 1/2)

[a2 + (R

m)2]

,

ν+1
2

aν

−

∈

(1, +

where ν
easy to verify that, for ν > 2, the variance is given by σ2 = a2/(ν
for ν > 4, the excess kurtosis reduces to k = 6/(ν
we obtain closed-form generalized expression for VaR and ES given by

) is the tail index and B(ν/2, 1/2) is the beta function. It is
2), while,
4). Under this assumption,

∞

−

−

Λ⋆ =

mS0 + σS0√ν

−

1

λ⋆

2

−

s

−
λ⋆

and

mS0 +

E⋆ =

−
[ν/2,1/2](2

σS0
⋆B(ν/2, 1/2)
[ν/2,1/2] is the inverse of the incomplete beta

2
−
1
−

ν−1
2 ,

√ν
ν

[λ⋆]

(7)

1

P

where λ⋆ .
P
function, according to the deﬁnition of Ref. [13].

⋆) and I −

= I −

1

+

→

As shown in Fig. 1, we have checked numerically the convergence of formu-
lae (6) and (7) to the Gaussian results (3) and (4), in the appropriate limit
ν
. We chose ν = 2.75, 3.5, 4.5, 100 and m = 0, σS0 = 1, but we
checked that the value of these last parameters does not aﬀect the conver-
gence, as expected. As can be seen, the points corresponding to ν = 100 are
almost coincident with the Gaussian predictions, demonstrating that our re-
sults correctly recover the Gaussian formulae as a special case. It is also worth

∞

(5)

(6)

5

P

P

P

⋆. Analogously, for a ﬁxed

noting that each line, corresponding to a ﬁxed ν, crosses over the Gaussian
⋆, there exists a νcross value
one for a certain
whose line crosses the Gaussian result at that signiﬁcance level. In the light of
this observation, we report in Table 1 the values of νcross corresponding to a
⋆ for both VaR and ES. As can be observed, the growth of νcross with
given
⋆ is very rapid for VaR, while for ES and for usually adopted signiﬁcance
P
values, νcross keeps in the interval [2.09, 2.51]. From this point of view, VaR
and ES are quite diﬀerent measures of risk, since the crossover values for the
latter are much more stable than those associated to the ﬁrst one. This result
can be interpreted as a consequence of ES as a more coherent risk measure
than VaR.

Table 1
Values of ν crossover for VaR and ES corresponding to diﬀerent signiﬁcance levels
⋆.

P

⋆

P
νcross(VaR)

1% 2% 3%

4%

5%

2.44

3.21

5.28

32.38

νcross(ES)

2.09

2.18

2.28

2.38

100

≫
2.51

3 Empirical analysis of ﬁnancial data

The data sets used in our analysis consist of four ﬁnancial time series, com-
posed of N = 1000 daily returns, from the Italian stock market. Two series
are collections of data from the Italian assets Autostrade SpA and Telecom
Italia (from May 15th 2001 to May 5th 2005), while the other two correspond
to the ﬁnancial indexes Mib30 and Mibtel (from March 27th 2002 to March
13th 2006). The data have been freely downloaded from Yahoo Finance [16].

Figure 2 shows a comparison between the historical complementary cumula-
tive density function P> of the negative daily returns and two theoretical ﬁts
obtained using Gaussian and Student-t distributions. The parameters values
of the ﬁtted curves, as obtained according to the likelihood procedure de-
scribed below, are displayed in Table 2. In principle, we could perform the ﬁt
according to diﬀerent methods, but we have to balance between accuracy and
computational time. Therefore, we estimate mean and variance as empirical
moments, i.e.

and

.
=

m

1
N

N

1

−

Xi=0

Rt

i

−

σ2 .
=

1

N

−

1
(Rt

N

1

−

Xi=0

m)2,

i −

−

6

(8)

(9)

−

= (Rt, . . . , Rt

where R .
N +1) is the N-dimensional vector of returns. Using
the above m and σ values, we derive a standardized vector (with zero mean
and unit variance) r .
m)/σ for i =
1. In order to ﬁnd the best value for the tail parameter ν, we look
0, . . . , N
for the argument that minimizes the negative log-likelihood, according to the
formula

N +1), where rt

= (rt, . . . , rt

.
= (Rt

i −

−

−

−

−

i

ν = argmin ν>2

N

1

−

Xi=0

"−

log

ν
0,√ν

S

2(rt
−

i)

,

#

−

(10)

where the constraint ν > 2 prevents the variance to be divergent and
2 is
as in Eq. (5), with m = 0 and a = √ν
2. This apparently simple optimization
−
problem can not be solved analytically. In fact, the normalization factor in the
Eq. (5) does depend on the tail index ν in a non trivial way. Actually, the beta
function B(ν/2, 1/2) only admits an integral representation and therefore we
implemented a numerical algorithm to search for the minimum.

S

−

ν
0,√ν

As shown in Section 2, the excess kurtosis k depends only on ν and this pro-
vides an alternative and more eﬃcient way to estimate the tail parameter [11].
However, this approach forces ν to be bigger than 4, while from Table 2 it can
be seen that all the exponents obtained in the likelihood-based approach are
smaller than 3.5. For this reason, the implementation of the excess kurtosis
method is inadequate for the time series under study here. In order to test the
robustness of our results, we also performed a more general three-dimensional
minimization procedure over the free parameters (m, σ, ν). The multidimen-
sional optimization problem was solved by using the MINUIT program from
CERN library [17]. The obtained numerical results are in full agreement with
the previous ones, but the process is more computationally burden and more
cumbersone, since it requires particular care in avoiding troubles related to
the appearing of local minima in the minimization strategy.

In Fig. 2 we show the cumulative distribution P> obtained using the empirical
parameters of Table 2. As expected, we measure daily volatilities of the order
0.01%). The tail parameters fall in the
of 1% and quite negligible means (
range (2.9, 3.5), thus conﬁrming the strong leptokurtic nature of the returns
distributions, both for single assets and market indexes. The quality of our ﬁt
clearly emerges from Fig. 2, where one can see a very good agreement between
Student-t and historical complementary cdfs, while the Gaussian distribution
fails to reproduce the data.

∼

Before addressing a risk analysis in the next Section, it is worth mentioning, for
completeness, that other approaches to model with accuracy the tail exponent
of the returns cdfs are discussed in the literature. They are based on Extreme
Value Theory [18] and Hill’s estimator [19,20]. However, since they mainly
focus on the tails, they require very long time series to accumulate suﬃcient
statistics and are not considered in the present study.

7

Fig. 2. From top left clockwise: Autostrade SpA, Telecom Italia (from May 15th
2001 to May 5th 2005), Mibtel and Mib30 (from March 27th 2002 to March 13th
2005) P> of negative daily returns. Points represent historical complementary cdf,
while dashed and solid lines correspond to Gaussian and Student ﬁts, respectively.
The parameters values of the ﬁtted curves are detailed in Table 2.

Data
Normal
Student

 0.001

 0.001

 0.01

 0.1

 0.001

 0.001

 0.01

 0.1

 1

 0.1

 0.01

 1

 0.1

 0.01

>
P

>
P

 1

 0.1

 0.01

 1

 0.1

 0.01

 0.001

 0.001

 0.1

 0.001

 0.001

 0.1

 0.01

R

−

 0.01

R

−

Table 2
Mean m, volatility σ, and tail exponent ν, for Autostrade SpA, Telecom Italia,
Mibtel and Mib30 time series. m and σ are estimated from empirical moments,
while ν is obtained through a negative log-likelihood minimization as in Eq. (10).

m

σ

ν

Autostrade

0.12% 1.38% 2.9061

Telecom

Mibtel

Mib30

0.02% 2.23% 3.1423

−
0.02% 1.03% 3.3469

0.02% 1.16% 3.2195

4 Risk analysis

In this Section we present a comparison of the results obtained estimating the
market risk throught VaR and ES according to diﬀerent methodologies. The
standard approach is based on the normality assumption for the distribution
of the returns. For this case we are provided of closed-form solutions, Eqs. (3)
and (4), that depend on the two parameters m and σ. For the time series

8

under consideration, the eﬀect of the mean, as shown before, is negligible, and
the surviving parameter is the volatility σ. Several techniques are discussed
in the literature to model and forecast volatility, based on stochastic volatilty
approaches [21], GARCH-like [22] and multifractal models [23]. They usually
require very long time series (tipically 300 high frequency returns per day over
5 - 10 years) and are quite demanding from a computational point of view.
∼
As discussed in Section 3, we limit our analysis to 1000 daily data and we
estimate the volatility using the empirical second moment. In order to avoid
the problem of a uniform weight for the returns, RiskMetrics introduces the
use of an exponential weighted moving average of squared returns according
to the formula [12]

.
=

σ2
t+1
|

t

λ
−
λN +1

1

−

1

N

1

−

Xi=0

λi(Rt
−

i −

m)2,

(11)

∈

t (coupled with Rt = σtǫt with ǫt ∼

where λ
(0, 1] is a decay factor. The choice of λ depends on the time hori-
zon and, for ∆t = 1 day, λ = 0.94 is the usually adopted value [12]. σt+1
t
|
represents volatility estimate at time t conditional on the realized R. If one
considers Eq. (11) as the deﬁning equation for an autoregressive process fol-
lowed by σt+1
i.i.d.(0, 1)), Refs. [24,25]
|
provide reasons for the claimed good success of the RiskMetrics methodology.
In order to relax standard assumption about the return pdf without loosing
the advantages coming from a closed-form expression, we presented in Sec-
tion 2 generalized formulae for VaR and ES based on a Student-t modeling
of price returns. In this framework, the tail index ν emerges as a third rel-
evant parameter, which is possible to constrain using a maximum likelihood
technique, as previously described. As a benchmark of all our results, we also
quote VaR and ES estimates following a historical approach, which is a pro-
cedure widely used in the practice. According to this approach, after ordering
the N data in increasing order, we consider the [N
⋆]) as
⋆] returns as an
an estimate for VaR and the empirical mean over ﬁrst [N
estimate for ES 1 .

⋆]th return R([N

P

P

P

At a variance with respect to previous investigations [11,24], we also provide
68% conﬁdence level (CL) intervals associated to the parameters. In this way
we can estimate VaR and ES dispersion. To this extent, we implement a boot-
strap technique [26]. Given the N measured returns, we generate M = 1000
sinthetic copies of R,
, with j = 1, . . . , M, by random sampling with
replacement according to the probability p = (1/N, . . . , 1/N). For each R∗j we
estimate the quantities of interest and we obtain bootstrap central values and

R∗j }

{

1 The symbol [ ] stands for integer part, while R(j) is the standard notation for the
jth term of the order statistic of R. Since N
1 we neglect the fact that the pth
entry is a biased estimator of the p/N -quantile, i.e. E[R(p)] = p/(N + 1).

≫

9

Table 3
Parameters values and bootstrap estimates for the 68% CL intervals for the time
series as in Table 2.

Autostrade

Telecom

Mibtel

Mib30

m

−

0.12+0.04
0.05% 1.38+0.08
−
0.02+0.06
0.07% 2.23+0.11
−
−
0.04% 1.03+0.03
0.02+0.02
−
0.04% 1.16+0.03
0.02+0.03
−

−

−

−

σ

t

−

ν

σt+1
|
0.33% 2.9061+0.0005
0.10% 1.83+0.31
0.47% 3.1423+0.0002
0.11% 1.54+0.42
0.20% 3.3469+0.0002
0.04% 0.69+0.19
0.22% 3.2195+0.0004
0.05% 0.72+0.22

−

−

−

−

−

0.0004 −

0.0005 −

0.0003 −

0.0005 −

−

−

R(10)

0.15%

3.51+0.31
−
6.14+0.87
−
2.96+0.25
−
3.33+0.30
−

1.35%

0.24%

0.25%

conﬁdence levels. For example, we use for the mean the relations

.
=

m∗b

1
M

M

Xj=1

m∗j with m∗j =

(12)

1
N

N

1

−

Xi=0

(R∗j )t
−

i

2α CL interval as [m∗α, m∗1
−

and we deﬁne the 1
−
≤
m∗a) = a and a = α, 1
α. For 68% CL, α = 16%. In Fig. 3 and Tables 3, 4, 5
m∗b). In this way, we
(m∗b −
we quote results according to m
use the bootstrap approach in order to estimate the dispersion of the mean
around the measured value, m. Analogously for all the other parameters.

α], with m∗a such that P (m∗

m∗α) + (m∗1
−

α −

−

−

Table 3 shows central values and estimated 68% CL intervals for the daily
returns series under study. These numerical results come from a straightfor-
ward application of the resampling technique. It is worth mentioning that it is
possible, and sometimes necessary, to use improved versions of the bootstrap.
As a rule of thumb, we consider the boostrap approach accurate when, given a
generic parameter, the diﬀerence between its empirical value and the boostrap
central value estimate is close to zero and 68% CL interval is symmetric to a
good approximation. In our numerical simulation, we measured a systematic
non zero bias for σt+1
t and from Table 3 it is quite evident the asymmetry of
|
R([N
⋆]) intervals for both Autostrade and Telecom data. We can, therefore,
consider the corresponding CL intervals as a ﬁrst approximation of the right
ones, since bias and skewness corrections would require soﬁsticated and ad-hoc
techniques [26], which are beyond the scope of the present work.

P

In Fig. 3 we show VaR and ES central values and 68% CL bars for Autostrade
SpA and Mib30, corresponding to 1% and 5% signiﬁcance level and according
to the four methodologies previously described. In Tables 4 and 5 we de-
tail all the numerical results, including also Telecom Italia and Mibtel data.
As already noted in Ref. [24], at 5% signiﬁcance level Student-t and Normal
approaches are substantially equivalent, but here such a statement sounds
more statistically robust, thanks to the bootstrap 68% conﬁdence levels and
to the comparison with the historical simulation. At this signiﬁcance level,
we register for VaR a diﬀerent behaviour between single assets and indexes.
While assets show the best agreement between the Student-t and historical

10

Fig. 3. VaR Λ⋆ (upper panel) and ES E⋆ (lower panel) central values with 68%
CL intervals for Autostrade SpA (left) and for Mib30 (right), according to the four
⋆ is ﬁxed to
diﬀerent methodologies discussed in the text. The signiﬁcance level
1% (circles, solid lines) and 5% (triangles, dashed lines).

P

P ⋆1%
P ⋆5%

Student−t Normal Historical RiskMetrics

Student−t Normal Historical RiskMetrics

 6

 5

 4

 2

 1

 0

 7

 6

 5

 4

 2

 1

 0

 3

⋆
Λ

⋆
E

 3

 6

 5

 4

 3

 2

 1

 0

 7

 6

 5

 4

 3

 2

 1

 0

Student−t Normal Historical RiskMetrics

Student−t Normal Historical RiskMetrics

Autostrade

Mib30

approaches (see also Table 4), for Mib30 and Mibtel data we observe the best
agreement between the Normal and historical methodology. In order to en-
force this empirical evidence, it would be necessary to analyze additional time
series to see to what extent this diﬀerence between assets and indexes holds.
From Fig. 3, Table 4 and Table 5 it can also be seen that Λ⋆ and E⋆ central
values calculated according to RiskMetrics methodology are quite ﬂuctuating
⋆ translates into
and characterized by the largest CL bars. The decreasing of
a major diﬀerentiation of the diﬀerent approaches. In general, we obtain the
best agreement between the Student-t approach and the historical simulation,
both for Λ⋆ and E⋆, whereas, as before, the RiskMetrics methodology overesti-
mates or underestimates the results of the historical evaluation and is aﬀected
by rather large uncertainties.

P

To conclude, we would like to note that we expect, from the results shown in
Fig. 1 and Table 1, that, for a ﬁxed signiﬁcance level, there exists a crossover
value, νcross, below which the generalized Student-t VaR and ES formulae un-
derestimate the Gaussian predictions. This eﬀect was already mentioned in
Ref. [11], but the analytical formulae here derived allow us to better charac-
terize it. Under the hypothesis of a Student-t distribution, the crossover value
does not depend on the ﬁrst and second moments and, therefore, the knowl-
edge, for a given time series, of the tail exponent only is suﬃcient to conclude,

11

Table 4
Estimated VaR values (mean and 68% CL interval) for 1% and 5% signiﬁcance
levels from Autostrade SpA, Telecom Italia, Mib30 and Mibtel. For each time se-
ries, the results of Student-t and Normal ﬁt, historical simulation and RiskMetrics
methodology are shown.

Student-t

Normal

Historical

RiskMetrics

−

−

Telecom

Autostrade VaR 1% 3.472+0.223
0.226
VaR 5% 1.717+0.113
0.116
VaR 1% 5.900+0.308
0.308
VaR 5% 3.121+0.185
0.178
VaR 1% 3.047+0.111
0.108
VaR 5% 1.612+0.064
0.066
VaR 1% 2.718+0.100
0.094
VaR 5% 1.454+0.060
0.058

Mibtel

Mib30

−

−

−

−

−

−

3.091+0.197
0.204
−
2.150+0.139
0.145
−
5.200+0.275
0.277
−
3.682+0.214
0.202
−
2.675+0.097
0.096
−
1.885+0.073
0.072
−
2.378+0.088
0.084
−
1.674+0.065
0.065
−

3.516+0.149
0.306
−
1.810+0.175
0.156
−
6.137+1.348
0.866
−
3.398+0.110
0.127
−
3.331+0.255
0.304
−
2.010+0.090
0.157
−
2.967+0.240
0.255
−
1.811+0.150
0.173
−

4.138+0.733
0.764
−
2.890+0.520
0.540
−
3.595+0.990
1.085
−
2.548+0.694
0.777
−
1.662+0.524
0.516
−
1.169+0.375
0.358
−
1.581+0.453
0.449
−
1.110+0.324
0.316
−

Table 5
Estimated ES values (mean and 68% CL interval) for 1% and 5% signiﬁcance levels.
Time series and methodologies as in Table 4.

Student-t

Normal

Historical

RiskMetrics

−

−

Telecom

Autostrade ES 1% 5.503+0.353
0.360
ES 5% 2.946+0.189
0.195
ES 1% 8.912+0.450
0.454
ES 5% 5.035+0.267
0.270
ES 1% 4.572+0.161
0.159
ES 5% 2.596+0.095
0.094
ES 1% 4.021+0.142
0.141
ES 5% 2.314+0.085
0.083

Mibtel

Mib30

−

−

−

−

−

−

3.559+0.229
0.231
−
2.727+0.175
0.182
−
5.954+0.311
0.310
−
4.613+0.248
0.246
−
3.068+0.111
0.109
−
2.369+0.088
0.086
−
2.728+0.099
0.094
−
2.106+0.078
0.077
−

5.076+0.607
0.634
−
3.006+0.248
0.235
−
9.685+1.456
1.475
−
5.320+0.478
0.466
−
3.918+0.223
0.234
−
2.804+0.145
0.155
−
3.501+0.215
0.224
−
2.524+0.128
0.136
−

4.759+0.837
0.876
−
3.655+0.653
0.677
−
4.116+1.133
1.250
−
3.190+0.879
0.969
−
1.908+0.599
0.590
−
1.471+0.467
0.458
−
1.815+0.524
0.516
−
1.399+0.399
0.400
−

a priori, whether the fat-tailed results for VaR and ES will underestimate or
not the corresponding Gaussian estimates.

5 Conclusions

In this paper we have presented a careful analysis of ﬁnancial market risk
measures in terms of a non-Gaussian (Student) model for price ﬂuctuations.
We have derived closed-form parametric formulae for Value at Risk and Ex-

12

pected Shortfall that generalize standard expressions known in the literature
under the normality assumption and can be used to obtain reliable estimates
for the risk associated to a single asset or a portfolio of assets. The obtained
non-Gaussian parametric formulae have been shown to be able to capture ac-
curately the fat-tailed nature of ﬁnancial data and, when speciﬁed in terms of
the model parameters optimized by means of an empirical analysis of real daily
returns series, have been found to be in good agreement with a full historical
evaluation. Moreover, the risk measures obtained through our model show non
negligible diﬀerences with respect to the widely used Normal and RiskMetrics
methodologies, indicating that the approach may have helpful implications for
practical applications in the ﬁeld of ﬁnancial risk management. We also pro-
posed a bootstrap-based technique to estimate the size of the errors aﬀecting
the risk measures derived through the diﬀerent procedures, in order to give a
sound statistical meaning to our comparative analysis.

As far as possible perspectives are concerned, it would be interesting to in-
vestigate to what extent our conclusions, drawn from an analysis of a sample
of Italian ﬁnancial data, apply also to other ﬁnancial markets. In particular,
one could check whether, at a given signiﬁcance level, statistically relevant
diﬀerences are present between the results valid for a single asset and those
relative to a portfolio of assets, as our analysis seems to indicate, at least for
5% VaR. Another interesting development concerns the comparison between
the predicitions for VaR and ES of our model with the corresponding ones
derived by means of other statistical procedures to measure tail exponents
known in the literature [18,19,20], as well as with the results from simulations
of advanced models of the ﬁnancial market dynamics, such as GARCH-like
and multifractal models [22,23].

Acknowledgments
We are grateful to Enrico Melchioni of FMR Consulting for continuous inter-
est in our work and very useful discussion about ﬁnancial risk. We wish to
thank Paolo Pedroni and Alberto Rotondi for informative discussions about
the bootstrap, as well as for suggestions about the relative bibliography. We
acknowledge precious collaboration with Andrea Fontana concerning software
issues and, in particular, the CERN tool quoted in Ref. [17].

References

[1] Basel Committee on Banking Supervision,

International Convergence of
Capital Measurement and Capital Standards: a Revised Framework, 2004
[http://www.bis.org/publ/bcbs107.htm].

[2] P. Jorion, Value at Risk: the New Benchmark for Managing Financial Risk,

13

McGraw Hill, 2001.

[3] J.P. Bouchaud and M. Potters, Theory of Financial Risk and Derivative Pricing:
from Statistical Physics to Risk Management, Cambridge University Press,
Cambridge, 2003.

[4] See, for example, C. Acerbi, C. Nordio and C. Sirtori, Expected Shortfall as a
tool for ﬁnancial risk management, cond-mat/0102304 and references therein.

[5] V.P. Heikkinen and A. Kanto, Journal of Risk 4 (2002) 77.

[6] J.S. Kamdem, Int. J. Theoretical and Applied Finance 8 (2005) 537.

[7] R.N. Mantegna and H.E. Stanley, An Introduction to Econophysics:
Correlations and Complexity in Finance, Cambridge University Press,
Cambridge, 2000.

[8] M. Gell-Mann and C. Tsallis, Nonextensive Entropy -
Applications, Oxford University Press, New York, 2004.

Interdisciplinary

[9] C. Tsallis, C. Anteneodo, L. Borland and R. Osorio, Physica A 324 (2003) 89.

[10] L. Borland, Quantitative Finance 2 (2002) 415; Phys. Rev. Lett. 89 (2002)

098701.

(2004) 554.

[11] A.P. Mattedi, F.M. Ramos, R.R. Rosa and R.N. Mantegna, Physica A 344

[12] J. Mina and J.Y. Xiao, Return to RiskMetrics. The Evolution of a Standard,

RiskMetrics Group, New York, 2001.

[13] W.H. Press, B.P. Flannery, S.A. Teukolsky and W.T. Vetterling, Numerical
Recipes - The Art of Scientiﬁc Computing, Cambridge University Press, New
York, 1989.

[14] B. Mandelbrot, Fractals and Scaling in Finance, Springer-Verlag, New York,

1997.

[15] R.N. Mantegna and H.E. Stanley, Phys. Rev. Lett. 73 (1994) 2946.

[16] http://finance.yahoo.com

[17] F. James, Minuit Reference Manual, CERN Program Library, 1998.

[18] A.J. McNeil and R. Frey, Journal of Empirical Finance 7 (2000) 271.

[19] M.L. Goldstein, S.A. Morris and G.G. Yen, Eur. Phys. J. B 41 (2004) 255.

[20] F. Clementi, T. Di Matteo, M. Gallegati, The power-law tail exponent of income

distributions, physics/0603061.

[21] S.L. Heston, Rev. Financ. Stud. 6 (1993) 327.

[22] L. Borland and J. P. Bouchaud, On a multi-timescale statistical feedback model

for volatility ﬂuctuations, physics/0507073

14

[23] E. Bacry, J. Delour and J. F. Muzy, Phys. Rev. E 64 (2001) 026103.

[24] S. Pafka and I. Kondor, Physica A 299 (2001) 305.

[25] D.B. Nelson, Journal of Econometrics 52 (1992) 61.

[26] B. Efron and R. Tibshirani, An Introduction to the Bootstrap, Chapman &

Hall, 1993.

15

