5
0
0
2
 
t
c
O
 
0
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
5
7
0
0
1
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Incorporating Inertia Into Multi-Agent Systems

W. C. Man and H. F. Chau∗
Department of Physics, University of Hong Kong, Pokfulam Road, Hong Kong and
Center of Theoretical and Computational Physics,
University of Hong Kong, Pokfulam Road, Hong Kong
(Dated: February 21, 2014)

We consider a model that demonstrates the crucial role of inertia and stickiness in multi-agent
systems, based on the Minority Game (MG). The inertia of an agent is introduced into the game
model by allowing agents to apply hypothesis testing when choosing their best strategies, thereby
reducing their reactivity towards changes in the environment. From massive numerical simulations,
a remarkable improvement of global cooperation is observed throughout the whole phase space, and
the maladaptation behaviour due to over-reaction of agents is removed. Also, these agents are found
to be advantageous over the standard ones, which are sometimes too sensitive to attain a fair success
rate. Analytical calculation on determining the minimum amount of inertia needed to achieve the
above improvement is also provided, which is consistent with the numerical data.

PACS numbers: 89.65.Gh, 02.50.-r, 05.40.-a, 89.75.-k

I.

INTRODUCTION

There is a growing interest in studying artiﬁcial agents-
interacting models which are able to generate global be-
haviours found in social, biological and economical sys-
tems [1]. Examples such as matching games [2] and ideal
gas models of trading markets [3] show that this approach
commonly used by physicists can be nicely applied to
problems lay outside the discipline. One exciting fact
is that these artiﬁcial models, although contain simple
governing rules, can still generate non-trivial global co-
operative behaviours [4, 5]. In these self-organized com-
plex systems, agents can reach equilibrium states through
adaptation, a dynamical learning process initiated by the
feedback mechanism present in these systems.

People possesses inertia when making decisions and
switching strategies in economical systems. Conceptu-
ally, this inertia is similar to what Newton’s laws describe
about body motions in the physical world. It refers to
how much people are reluctant to leave their own eco-
nomical plan in order to move around diﬀerent invest-
ment tools, just like objects are reluctant to change their
motion states. The origin of this inertia may come from
the following three reasons: (1) cost needed for changing
strategies, (2) low sensitivity towards the change of en-
vironment and (3) the loss-aversion [6] human carries —
people loves to ﬁght back from loss [7]. Like bodies may
have diﬀerent mass in classical physical systems, people
may carry diﬀerent inertia in economical markets. In this
paper, we discuss a simple model to study the idea of in-
ertia. This model gives striking improvement of coopera-
tive behaviour, such as removal of maladaptation [8] and
dynamically increase of diversity among agents, without
any necessity to alter initial conditions and payoﬀ mech-
anism.

∗Corresponding author: hfchau@hkusua.hku.hk

Our model is a modiﬁcation of a famous econophysical
model known as MG, proposed by Challet and Zhang in
1997 [5, 9]. MG is a simple game model that captures
the minority seeking behaviour found in stock markets
and resources competitions. In MG, N agents struggle
to choose between two options repetitively, either buy
(0) or sell (1) in each turn. Those who have chosen the
minority sides are winners at that turn and are awarded 1
dollar, otherwise they lose 1 dollar. The only information
they received is the history of the game, which is a binary
bit string composed by previously M turns minorities. A
strategy is a map from the set of all possible histories to
the set of two options. If a strategy predicts the minority
correctly, it is added 1 virtual score, otherwise it loses 1
virtual score. Each agent is assigned S strategies once
and for all at the beginning of the game in order to aid
his/her decision. In standard MG, the best strategy in
an agent’s hand is the strategy with the highest virtual
score, which he/she would rely on in that particular turn.
M
Clearly, there are 2M possible histories and hence 22
available strategies. However, out of the whole strategy
space, only 2M+1 of them are signiﬁcantly diﬀerent. The
diversity of the population is measured by α, which is
equal to 2M+1/N S. The smaller the α, the more similar
are the strategies hold by agents. Up to ﬁrst order ap-
proximation, the dynamics of MG is determined by this
control parameter α. [10, 17, 18]

The most sparkling macroscopic observable in MG is
perhaps the variance of option attendance per agents
σ2/N . It represents the wastage of the system and ﬂuctu-
ation of resources allocation; the smaller σ2/N , the more
the whole population beneﬁts. Researchers found that
σ2/N falls below the value that all agents make their
choices randomly in a certain range of α, indicating that
agents are cooperating although they are independent
and selﬁsh. More speciﬁcally, there is a phase transition
at the critical point αc which divides the σ2/N against
α curve into the so-called symmetric phase (α < αc) and
asymmetric phase (α > αc).

[11]

written as

where

Ωk,0(τk)

Ωk,1(τk)

H0 :

−
δk

> xk,

(1)

N

/

2
σ

I = 0.53
I = 0.6
I = 0.9

2

every agent needs a longer time to make up his/her mind
and the equilibration time in HMG is lengthened. We
take the value of σ2 every 1,000 time steps and regard
the system is equilibrated if the percentage diﬀerence of
successive measurement is smaller than ǫ = e−6. Then
we shall take our measurement for 25,000 number of time
steps and make an average over 150 independent runs
unless speciﬁed.

In a population where each agent try to cling on the
minority side as long as possible, every agent may have
diﬀerent inertia Ik, or even they have no inertia at all
(standard MG agents). We ﬁrst study the eﬀect of whole
population having the same Ik, i.e. Ik = I for all agents
k, then we shall move on to mixed population in later
sections. The next problem is the determination of δk,
a perception of agents on the ﬂuctuation of virtual score
diﬀerence between two strategies. A naive guess would be
assuming Ωk,j(τk) performs random walk for all strate-
gies j throughout the game, then δk equals √2τk.

0.001

0.01

0.1

1
α

10

100

FIG. 1: The variance of attendance per agent σ2/N against
the system complexity α for I equals (a) 0.53, (b) 0.6 and (c)
0.9, setting δk equals √2τk. Here, N = 501 and S = 2. The
dashed line represents the σ2/N curve in standard MG.

II. OUR MODEL

To incorporate inertia into MG, we introduce a
new modiﬁcation – Hypothesis Testing Minority Game
(HMG). Hypothesis testing standard statistical tool to
test whether an eﬀect emerged from an independent vari-
able appears by chance or luck. In the standard version
of MG, the best strategy is deﬁned as the strategy with
the highest virtual score.
In HMG, however, an agent
k determines his/her own best strategies by testing the
following null hypothesis H0: The current strategy
Sk,0
performs better than the other strategy
Sk,1 available to
agent k. Note that we have restricted ourselves to the
simplest case S = 2, but the model can be easily ex-
tended to S > 2 cases under the same formalism. This
1/2 on his/her cur-
agent possesses an sustain level Ik ≥
rent strategy
Sk,0, which is the same as the conﬁdence
level on the validity of the null hypothesis we commonly
use in hypothesis testing (that is, the acceptance area of
a standard normal). This Ik deﬁnes how much he/she
could sustain the under-performance of
Sk,0 and thereby
represents his/her inertia.
The H0 of a particular agent k can be quantitatively

+∞

1
√2π

xk

Z

2

−x

e

/2dx = Ik.

(2)

Here, Ωk,j (τk) is the virtual score of a particular strategy
Sk,j at τk, where τk is the number of time steps counted
from his/her adoption of
Sk,0 for that individual agent.
The dominator δk represents the ﬂuctuation of strate-
gies’ performance the agent perceived. An agent k would
Sk,0 until
continue to stick on his/her current strategy
Ωk,j(τk) descends outside his/her sustain level. Then
he/she has to admit that H0 is not likely to be true,
rejects it and shift to the other strategy. After a change
of strategy, the virtual scores of both strategies are reset
to zero and τk is set back to 1. The higher the value of
Ik, the milder his/her response and the more reluctant
for him/her in shifting strategies. In this way, Ik plays
the role of inertia of an agent in this game. Agents with
Ik = 1/2 would be most similar to standard MG agent,
they employ strategy with highest virtual score. How-
ever, there are still two diﬀerences: these HMG agents
would still stick on current strategy in case of a tie in
virtual scores, and the virtual scores will be reseted after
shifts in strategies.

III. PURE POPULATION WITH RANDOM
WALK APPROXIMATION

1

0.1

0.01

1

0.1

N

/

2
σ

0.01

0.4

0.5

0.6

0.8

0.9

1

0.7
I

FIG. 2: The variance of attendance per agent σ2/N against
the I at α = 0.06, setting δk equals √2τk. Here, N = 501, S
= 2 and M = 5.

We have performed extensive numerical simulation on
our model. With the presence of inertia among agents,

Fig. 1 shows a plot of the variance of attendance for
a particular option σ2/N against the control parameter

α for diﬀerent inertia I, with δk set to √2τk. There is
a huge drop of σ2/N when I is suﬃciently large, espe-
cially in symmetric phase when α is small (see Fig. 2).
Not just the maladaptation in symmetric phase is greatly
reduced, but the cooperation between agents is also im-
proved in the asymmetric phase for certain values of I.
Note that one can reduce the volatility in the symmetric
phase by artiﬁcially distributing a variety of initial virtual
scores to agents, but this act does not aﬀect the σ2/N
in the asymmetric phase [8]. The above improvement of
cooperation for whole phase space can also be found in
Thermal Minority Game (TMG) proposed by Cavagna
et al., but such an improvement from a diﬀerent origin.
While TMG improves global cooperation by adding in
individual stochasticity among agents [12], HMG attains
this uplift by reinforcing stickiness and determination.

The reduction of system wastage in the asymmetric
phase (α > αc) is believed to be resulted by increasing
stickiness of agents on current strategies and elongating
their observing time. This leads to an increase of frozen
agents (see Fig. 3) and an more eﬀective crowd-anticrowd
cancellation, succeeding in better cooperation.
[11, 13,
14]

I = 0.53
I = 0.6
I = 0.9

0.8

0.6

0.2

φ

0.4

0
0.01

0.1

1
α

10

100

FIG. 3: The frozen probability φ against α for diﬀerent I by
setting δk equals √2τk. The dashed line represents the frozen
probability of the standard agents in MG. Here, N = 501, S
= 2 and M = 5.

However, things become more complicated when α <
αc. From now on, this article will focus on the striking
improvement of cooperation in the symmetric phase. The
removal of maladaptation in this region is directly related
to the disappearance of periodic dynamics that normally
present in the standard MG. The periodic dynamics is
a result of oversampling of strategy space and common
zero initial conditions among agents when α < αc, ac-
counting for the high volatility in the symmetric phase.
It is reﬂected in a prominent period 2M+1 peak in the au-
tocorrelation of the attendance time series of a particular
option [8, 15, 16, 17, 18]. Fig. 4 shows an evidence of this
postulate; as shown from the autocorrelation functions,
periodic dynamics appears in the case I = 0.53 which has
high σ2/N in Fig. 1 and 2, while the low σ2/N cases I
= 0.6 and I = 0.9 show no trace of this signal.

3

100

300

400

100

300

400

(a)

200
∆

(c)

0.8

0.6

0.2

0

C

0.4

0

0

0.8

0.6

0.2

0

C

0.4

0

0

(b)

200
∆

(d)

0.8

0.6

0.2

0

C

0.4

0

0

0.8

0.6

0.2

0

C

0.4

0

0

100

200
∆

300

400

100

200
∆

300

400

FIG. 4: The autocorrelation of attendance C0 against various
interval ∆ on cases (a) standard MG, (b) I = 0.53, (c) I =
0.6 and (d) I = 0.9 averaged over 50 independent runs. Here,
N = 501, M = 5 and S = 2.

What is the critical limit of I in order to remove the
maladaptation? To answer this, we have to look closely
into the periodic dynamics that governs the maladapta-
tion in the symmetric phase. Earlier study stated that
virtual scores of strategies are likely to reset to zero ev-
ery 2M+1 number of steps through the periodic dynamics
in the symmetric phase. Initially all strategies have zero
score, whenever a strategy β wins a bet in a particular µ,
most agents would rush to β which is 2 scores ahead its
anti-correlated partner ¯β in the next appearance of µ. It
is likely that they would lose due to this overcrowding. In
this manner, the virtual scores of all strategies are reset
at this stage. This loop repeats with interval 2M+1 and
leads to the large ﬂuctuation of option attendance in the
symmetric phase. [19]

Therefore, the question becomes when this reset and
oscillate mechanism will be broken oﬀ. Actually, the pe-
riodic dynamics is destroyed when agents are no longer so
sensitive that they will not immediately shift to a strat-
egy standing out after it wins a bet. Here, the criteria
for this situation to occur as follow:

2
−
2M+1

√2

·

< xk,

(3)

where xk satisﬁes Eq. (2).
If the value of I satisﬁes
the inequality (3), agents would no longer tightened by
the periodic dynamics every 2M+1 steps. Then, a re-
recognizing process will draw in. In the standard MG, all
identical strategies have same virtual scores throughout
the game. However, in HMG agents would clear all vir-
tual scores after changing strategies. This move is done in
multifarious time steps for diﬀerent agents, depending on
the combination of strategies in their hands. Hence, the
scores of identical strategies eventually diverges if they
are hold by diﬀerent agents, and these strategies may
be employed again in multifarious time in the future.
The net eﬀect of this re-recognizing process is diversi-
fying strategies in the population intrinsically.
In this
way, both the oversampling and overcrowding found in

1

0.1

0.01

N

/

2
σ

1

0.1

N

/

2
σ

0.01

·

I

≃

−

25+1 =

0.177, i.e.

the symmetric phase are relaxed, lowering the volatility.
For instance, when M = 5, the limit xc equals
2/√2
0.57. This criteria
−
is conﬁrmed again in Figs. 2 and 4, all cases showing
no periodic dynamics satisﬁes Eq. (3) and have low vari-
ances. Note that for the cases where I does not exceed
this limit, their correlation signals is much stronger than
that of the standard MG (see Fig. 4b).
It is because
in HMG agents are more deterministic, they continue to
stick on current strategy when facing a tie in strategy vir-
tual scores, which happens during a reset. That means
their actions repeat during this reset and the system path
is more likely to repeat, resulting in stronger correlation.
This is like removing the random dice in standard MG
when facing a tie in virtual scores, a periodic signal as
strong as this case is also obtained.

IV. PURE POPULATION WITH RUNTIME δk

Actually, the movement of the virtual score diﬀerence
between two strategies is not likely to perform random
walk. Another possible way in perceiving δk is to put it
as the actual standard deviation of this diﬀerence in run-
time, which represents a more realistic market scenario.
That is,

−

−

δk =

Ωk,0(τk)

iτk − h

Ωk,1(τk))2

(Ωk,0(τk)
h
q

2
Ωk,1(τk)
τk .
i
(4)
The results are very similar to the previous case, which
are shown in Figs. 5–7. However, the critical value of I
for the system to escape from the grip of periodic dynam-
ics appears to be higher. Remind that the virtual score
diﬀerence of two strategies performs random walk with
following step sizes and probabilities p:

Ωk,0 −

Ωk,1 =

+2 with p = 1/4,
2 with p = 1/4,
with p = 1/2.

−
0




(5)



Meanwhile, the presence of periodic dynamics ensure a
reset every 2M+1 number of time steps. We can approx-
imately calculate the average variance by considering all
possible traveling paths, which equals 2M+1/12 (detail
mathematics is shown in the Appendix). For instance,
when M = 5, the critical value for the periodic dynam-
2/
ics to disappear is xc <
0.866, i.e.
I
0.81, which is consistent with the data presented in
Figs. 6 and 7. Again, we believe that after the breaking of
periodic dynamics, the re-recognizing process mentioned
in the previous section comes in and diversiﬁes the strat-
egy space, resulting in a drop of ﬂuctuation.

25+1/12 =

p

≃

−

−

V. MIXED POPULATION WITH STANDARD
MG AGENTS

It is already clear that a pure population of agents hav-
ing inertia reduces system wastage. Now it is instructive

4

I = 0.55
I = 0.6
I = 0.9

0.001

0.01

0.1

1
α

10

100

FIG. 5: The variance of attendance per agent σ2/N against
the system complexity α for I equals (a) 0.55, (b) 0.6 and (c)
0.9, with δk given by Eq. (4). Here, N = 501 and S = 2. The
dashed line represents the σ2/N curve in standard MG.

0.4

0.5

0.6

0.8

0.9

1

0.7
I

FIG. 6: The variance of attendance per agent σ2/N against
I at α = 0.06, setting δk satisfying Eq. (4). Here, N = 501,
S = 2 and M = 5.

to study whether these agents (sticky agents) is advan-
tageous over standard MG agents (sensitive agents) in a
mixed population.

Fig. 8 gives the success rates of both races against γ
in the mixed population with I = 0.9, where γ is the
fraction of sticky agents in the population. Clearly, these
sticky agents take advantages of the sensitive agents for
whole range of γ, they successes in maintaining their suc-
cess rates close to 0.5. The sensitive agents are believed
to be tightened by the periodic dynamics, making them
keep on losing. On the other hand, sticky agents are
likely to win more turns as they are resistant to follow
the oscillation. Note that the whole population also ben-
eﬁts from adding in more sticky agents (see the triangles
in ﬁg. 8). When γ is increased up to about 0.6, Ws starts
to raise.
It is because the crowd of sensitive agents is
no longer large enough to override the net actions made
by sticky agents, and therefore there is no more peri-
odic dynamics existing. Fig. 9 conﬁrms our suspicion,
the periodic dynamics disappear around γ = 0.6. We
have also performed simulations on mixed population of
sensitive agents and sticky agents with other values of I.

0.8

0.6

0.2

0

C

0.4

0

0

0.8

0.6

0.2

0

C

0.4

0

0

e
t
a
r
 
s
s
e
c
c
u
s

0.51

0.5

0.49

0.48

0.47

0.46

0.45

0

5

100

300

400

100

300

400

(a)

200
∆

(c)

(b)

200
∆

(d)

0.8

0.6

0.2

0

C

0.4

0

0

0.8

0.6

0.2

0

C

0.4

0

0

100

200
∆

300

400

100

200
∆

300

400

0

0.04
0
-0.04

C

0

0.04
0
-0.04

C

0

0.04
0
-0.04

C

0

0.04
0
-0.04

C

0

0.3

0.6

0.9

0

0.04
0
-0.04

C

0

0.04
0
-0.04

C

0

0.04
0
-0.04

C

0

0.04
0
-0.04

C

0.1

0.4

0.7

1.0

0.2

0.5

0.8

0

0.04
0
-0.04

C

0

0.04
0
-0.04

C

0

0.04
0
-0.04

C

FIG. 7: The autocorrelation of attendance C0 against various
interval i on cases (a) standard MG, (b) I = 0.55, (c) I = 0.6
and (d) I = 0.9 averaged over 50 independent runs. Here, N
= 501, M = 5 and S = 2 and δk given by Eq. (4).

FIG. 9: The autocorrelation of attendance C0 for diﬀerent γ
averaged over 50 independent runs. Here, N = 501, M = 5,
S = 2 and I = 0.9.

they will suﬀer from a overcrowd loss easily. Meanwhile,
agents carrying stickiness seems to perform much better
than sensitive agents. Our ﬁndings suggest that inertia,
or stickiness is crucial and beneﬁcial to a society. It is
hoped that the role of inertia will be investigated in more
detail based on our model HMG, such as the eﬀect of giv-
ing a diversifying range of inertia to a population. It is
also instructive to apply our method of modeling inertia
to study inertia eﬀect in other multi-agent systems.

Ws
Wh
W

0.2

0.4

γ

0.6

0.8

Acknowledgments

FIG. 8: A plot of success rate of sticky agents Wh, sensitive
agents Ws and the whole population W against the fraction of
sticky agents γ in the mixed race. There are total 501 agents,
with M = 5, S = 2 and I = 0.9.

As expected, sticky agents are only advantageous with I
exceeds the critical value that allow them to escape from
periodic dynamics mentioned in the last section. Other-
wise, all agents in the whole population would still suﬀers
from overcrowding and no one will be beneﬁted.

VI. CONCLUSIONS

We have successfully introduced the concept of iner-
tia into the Minority Game, which shows a remarkable
improvement of cooperation among agents in most range
of α, especially in the symmetric phase α < αc. We
also calculated the critical values of inertia needed to up-
lift the cooperation behaviours, which depends on how
agents perceive the ﬂuctuation of virtual score diﬀer-
ence between strategies. This tune down of sensitivity
among agents is found to be useful in removing maladap-
tation due to over-reaction. In contrast, if every action is
smooth and all agents response to information in no time,

We thank the Computer Center of HKU for their help-
ful support in providing the use of the HPCPOWER Sys-
tem for simulations reported in this article. K. M. Lee,
F. K. Chow, K. H. Ho and C. C. Leung are gratefully
acknowledged for their fruitful discussions.

APPENDIX

In this appendix, we consider a simple random walk
of a cumulative sum xt after time t. At each step, xt
increases (decreases) one if moves upward (downward)
with probability 1/2. We also impose a boundary con-
dition that the sum is equal to zero at both t = 0 and
t = T . A schematic diagram is shown in Fig. 10. Under
such constraint, we ﬁnd that the variance of xt averages
r = t(T −t)
over all possible paths σ2
. Using this formula,
we can evaluate the average standard deviation of virtual
score diﬀerence of an agent’s strategies within a period
2M+1, that is the δk mentioned in Eq. (4).

4T

First, we need to know the probability of xt within k

and k + dk, which is given by [20]

P (k

xt ≤

≤

k + dk)

2
πt

e

2

−2k

/tdk.

≈ r

(6)

6

(10)

(12)

By the boundary condition, 0

dl, then we have

xT ≤

≤

k

l

dk

dl

t

t

T

P (k

≤

xt ≤
2T

k + dk

−2T k

2

≤

xT ≤
0
|
/t(T −t)dk.

dl)

=

πt(T

s

e

t)

−

FIG. 10: A schematic sketch showing a typical random walk
of particle travels for T time step.

Therefore, the variance σ2
paths:

r averaged over all possible

Hence, the probability of the cumulative sum xt to be
within k and k + dk at time t and xT to be within l and
l + dl at time T can be expressed by

P (k
= P (k

xt ≤
xt ≤

≤
≤

k + dk and l
P (l
k + dk)

·

xT ≤
k
≤

l + dl)
l
xT −t ≤

≤
−

−

k + dl)
(7)

where t
T . The equality follows from the fact that
the discrete steps size is equal to one. Using the Eqs. (6)
and (7), the conditional probability

≤

P (k
P (k

xt ≤
xt ≤

≤
≤

=

2

πt e−2k

2

/t

= q

P (l

≤

l
k + dk
xT ≤
|
k + dk and l
≤
xT ≤
l + dl)
≤
π(T −t) e−2(l−k)
πT e−2l2/T dl

q

2

2

·

l + dl)
xT ≤

l + dl)

(8)

2

/(T −t)dkdl

q

σ2
r =

+∞

k2P (k

−∞
Z
t(T

t)

.

−
4T

=

xt ≤

≤

k + dk

0
|

xT ≤

≤

dl) (11)

In order to calculate δ2

k, we should rescale σ2

r because
the virtual score diﬀerence of an agent’s strategies can
2) or
move two steps upward (+2), two steps downward(
keep stationary(0). Hence, by approximating the travel
time T consists inﬁnity number of time steps:

−

δ2
k = 2

1
T

·

0
Z

T

t(T

t)

−
4T

dt =

T
12

.

(13)

. (9)

where δk is the perceived ﬂuctuation mentioned in
Eq. (4).

[1] S. A. Levin, Ecosystems 1, 431 (1998).
[2] P. Laureti and Y. C. Zhang, Physica A 324, 49 (2003).
[3] A. Chatterjee, B. L. Chakrabarti and S. S. Manna, Phys-

ica A 335 155 (2004).

[4] W. B. Arthur, Amer. Econ. Rev. 84, 406 (1994).
[5] D. Challet and Y. C. Zhang, Physica A 246, 407 (1997).
[6] D. Kaheman and A. Tversky, Economertica 47, 2 (1979).
[7] A. Tversky and D Kaheman, Journal of Risk and Uncer-

[13] M. Hart, P. Jeﬀeries, N. F. Johnson and P. M. Hui, Phys-

[14] M. Hart, P. Jeﬀeries, N. F. Johnson and P. M. Hui, Eur.

ica A, 298, 537 (2001).

Phys. J. B, 20, 547 (2001).

[15] D. Challet and M. Marsili, Phys. Rev. E. 62, 2 (2000).
[16] C. Y. Lee, Phys. Rev. E 64, 015102(R) (2001).
[17] R. Manuca, Y. Li, R. Riolo and R. Savit, Physica A 282,

559 (2000).

tainty 5, 297 (1992).

[18] R. Savit, R. Manuca and R. Riolo, Phys. Rev. Lett. 82,

[8] K. Y. Michael Wong, S. W. Lim and Zhuo Gao, Phys.

10 (1999).

Rev. E 70, 025103(R) (2004).

[19] K. H. Ho, W. C. Man, F. K. Chow and H. F. Chau, Phys.

[9] Y. C. Zhang, Europhys. News 29, 51 (1998).
[10] D. Challet and Y. C. Zhang, Physica A 256, 514 (1998).
[11] D. Challet and M. Marsili, Phys. Rev. E 60, 6 (1999).
[12] A. Cavagna, J. P. Garrahan, I. Giardina and D. Sher-

rington, Phys. Rev. Lett. 83, 21 (1999).

Rev. E 71, 066120 (2005).

[20] A. N. Shiryaev, Probability, p. 49 (Springer, Berlin, 2nd

ed., 1989).

