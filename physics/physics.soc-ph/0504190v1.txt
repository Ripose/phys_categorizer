5
0
0
2
 
r
p
A
 
6
2
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
0
9
1
4
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Prisoner’s dilemma on dynamic networks
under perfect rationality

Christoly Biely a,b, Klaus Dragosits a, Stefan Thurner a,b,∗
a Complex Systems Research Group
HNO, Medical University of Vienna
W¨ahringer G¨urtel 18-20, A-1090 Vienna, Austria
b Atominstitut der ¨Osterreichischen Universit¨aten
Stadionallee 2, A-1020 Vienna, Austria

Abstract

We consider the prisoner’s dilemma being played repeatedly on a dynamic network,
where agents may choose their actions as well as their co-players. In the course
of the evolution of the system, agents act fully rationally and base their decisions
only on local information. Individual decisions are made such that links to defecting
agents are resolved and that cooperating agents build up links, as new interrelations
are established via a process of recommendation. The dynamics introduced thereby
leads to periods of growing cooperation and growing total linkage, as well as to
periods of increasing defection and decreasing total linkage, quickly following each
other if the players are perfectly synchronized. The cyclical behavior is lost and the
system is stabilized when agents react ’slower’ to new information. Our results show,
that within a fully rational setting in a licentious society, the prisoner’s dilemma
leads to overall cooperation and thus loses much of its fatality when a larger range
of dynamics of social interaction is taken into account. We also comment on the
emergent network structures.

Key words: Cooperation, Evolutionary Games, Networks

JEL: C72, C73, D70

∗ Correspondence to:
Stefan Thurner
Complex Systems Research Group, HNO, Medical University of Vienna
W¨ahringer G¨urtel 18-20, A-1090 Vienna, Austria
T +43 1 40400 2099; F +43 1 40400 3332
thurner@univie.ac.at

Preprint submitted to Elsevier Science

21 February 2014

1 Introduction

One of the most impressing ways of illustrating situations where mutual trust

is beneﬁcial, but egoism leads to a breach of promise is the classical prisoner’s

dilemma (PD) game, discussed in detail by Axelrod (1984). The game is played

by two persons, further denoted by i and j. Representing the game by positive

valued payoﬀs for the two individuals, it can be described by a matrix of the

form given in Table 1.

If there is only one round of the game, i, who chooses between cooperation

and defection, will select to defect, independent of j’s behaviour. Similarly, j,

who has the same choices, will decide to defect. The result of these individual

decisions is mutual defection and the ’solution’ lies in the cell marked I (the

cell with a payoﬀ of 0, respectively). However, as the payoﬀs indicate, both

players would ﬁnd the mutual optimum if they both chose to cooperate.

Broaden the game to a large scale it is often argued (e.g. Buchanan (1975)),

that unless there is some convention that dictates altruistic behaviour in the

game, rational and utility-maximizing individuals end up in a scheme of over-

all defection. These arguments refer to problems of constitutional economy,

like the respect of property between individuals or cooperative behaviour in

bargaining and have been discussed by Buchanan, Brennan and Buchanan

(1985) and Tullock (2005). To circumvent the dilemma, the need for a rule

is suggested, a binding norm to acquire an acceptable state which overcomes

2

Player j

C D

Player i

C R S

D T I

Pij = 


3 −1

4 0





Table 1
Table of payoﬀ matrix for two players in the prisoner’s dilemma game. The abbrevia-
tions stand for Reward (R), Sucker’s payoﬀ (S), Temptation (T) and Ineﬃciency (I).
For the prisoner’s dilemma the entries have to obey the restrictions S < I < R < T
and (T + S)/2 < R. On the right hand side, the payoﬀ matrix we used as a typical
starting point of our simulations is given.

the social dilemma. Breaking the rule is penalized via external sanctions, ef-

fectively leading to a variation of the payoﬀ-matrix and thus resolving the

dilemma.

(2002).

Apart from constitutional economics, applications of the PD range from bi-

ological networks, as discussed by Oborny et al. (2000), and the analysis of

internet congestion (Huberman and Lukose (1997)) to economic communica-

tion, introced via an analysis of a single-shot Prisoner’s dilemma by Miller et al.

Axelrod (1984) explored an extension to the classical PD, where the game is

repeated and participants have to choose their mutual strategies again and

again - the iterated prisoner’s dilemma (IPD). If the number of iterations

of the game is a known ﬁnite number, a simple argument proves that the

only equilibrium is mutual defection in every round. However, if the game

is played an inﬁnite or a ﬁnite - but unknown - number of times and one

considers the players to act according to strategies, the folk theorem implies

3

that cooperation may emerge, if the payoﬀs are suﬃciently little discounted.

Recent research has concentrated on aspects of the iterated prisoner’s dilemma

based on a spatial version of the game, introduced in the pioneering work of

Nowak and May (1992). In their survey, cooperation is made possible by the

assumption, that every agent imitates his neighbours in such a way, that he

chooses the action of the neighbour who got the highest payoﬀ in the last

turn. The imitation rule leads to complex spatio-temporal dynamics and the

emergence of cooperation for strategy spaces conﬁned to cooperation and de-

fection. The spatio-temporal dynamics have been studied under the aspect

of diﬀerent topologies of the underlying interaction networks by diﬀerent au-

thors: Abramson and Kuperman (2001) have studied the case of a small world

network, later Kim et al. (2002) have introduced and discussed the role of an

’inﬂuential node’. Holme et al. (2003) have investigated Nowak and May’s spa-

tial prisoner’s dilemma driven by mutations on empirical social networks. On

the other hand, also the role of a larger strategy space has been examined ex-

tensively in various articles. The well-known computer tournaments of Axelrod

showed that the simple tit-for-tat strategy did outstandingly well. Alternative

behavioral mechanisms such as ’win-stay’ ’lose-shift’ have been discussed by

Nowak and Sigmund (1993). An overview of the developments which have

taken place is given by Weibull (1996). More recently, Ebel and Bornholdt

(2002) have discussed co-evolutionary dynamics of diﬀerent strategies on net-

works. Less work concerning the prisoner’s dilemma has been done on dynamic

4

networks, where also the links between the agents are dynamical variables in

the total system. In this regard, Zimmermann et al. (2004) have recently pre-

sented results where the evolution of the system is based on imitation within a

dynamic network. Literature has also concentrated on learning schemes paired

with mechanisms of partner choice and refusal (Ashlock et al. (1996); Hauk

(2001)). In this context, Sato et al. (2002) have recently shown that learning

may lead to chaos even in the simple two-person rock-paper-scissors game.

To our best knowledge, in the variety of research conducted about the PD,

there is no model resembling what we regard as the necessary properties when

discussing the iterated prisoner’s dilemma game based on a strict interpre-

tation of homo oeconomicus: Pure rationality, local information-horizons, as

well as access to the full range of social interactions - including both, network

dynamics and freedom of choice of actions. Our present model aims at clos-

ing this gap to show that neither external rules nor imitative behavior, nor

the introduction of strategies are necessary to obtain cooperative behaviour,

even within a population of selﬁsh agents maximizing their payoﬀs expected

for the very next turn. The model is based on a society without regulations

and without an institution acquiring and providing global information - cir-

cumstances which have been long considered as to leading to a ’solitary, poor,

nasty, brutish, and short’ life, as Hobbes (1943) formulated more than three

centuries ago.

If there are no rules in society, there are also no norms and laws demanding and

5

controlling the liability to continue the interrelations one maintains. In other

words, the players are not compelled to keep their links and may cancel them

whenever they like. Conversely, they may build up new links whenever they

want. Then, the variation of the links between the individuals has to be taken

into account and implicit rewards as well as internal sanctions originating

from the variability of the network start to inﬂuence individual decisions.

This paper explores the implications of this idea and is structured as follows:

A general outline and a detailed description of the model embodying the

above mentioned thoughts is given in Section 2. In Section 3, results based

on computer-simulations of the model are presented: On the one hand, the

characteristics of the global time-series and the inﬂuence of the relevant model

parameters are discussed (Sections 3.1-3.3). On the other hand, the structure

of the networks obtained in the simulations is examined more closely in Section

3.4. Finally, a conclusion is reached and a short discussion of the main results

is given in Section 4.

2 The Model

2.1 Basic assumptions

We impose full rationality of each of the N players i and allow them to obtain

only local information. Furthermore, they have no memory (’zero-intelligence’)

and base their decisions on a strictly egotistic evaluation of the expected pay-

6

oﬀs in the next timestep.

next round, given by

¯Pi(t + 1) = X

jǫ ˜Ni(t+1)

At each update at time t, each agent i maximizes her expected payoﬀ in the

¯ai(t + 1)Pij¯aj(t + 1)

.

(1)

Here, Pij denotes the (given) payoﬀ-matrix (see Table 1). The actions of the

agents at timestep t are given by a two-dimensional unit-vector,

ac
i (t) =

or

ad
i (t) =

,

(2)

























1

0













0

1













if agent i is cooperating or defecting at timestep t, respectively.

Each agent tries to maximize her payoﬀ by adjusting her future action ai(t +

1) and direct neighbourhood ˜Ni(t + 1), which is deﬁned as the set of next

neighbours to i (a next neighbour is a node connected with i by one link).

As he has no knowledge about future actions of her neighbours, agent i takes

their preceding actions as a reasonable expectation value:

¯aj(t + 1) = aj(t)

.

(3)

Furthermore, agent i has full knowledge about the payoﬀ Pj(t) of each of her

neighbours j. He needs this information to conduct an evaluation of the payoﬀ

expected from establishing new links to other players (see below).

7

For the update of the neighbourhood ˜Ni(t) → ˜Ni(t + 1) we conceive that

agents cancel a link if the payoﬀ with this co-player is smaller than, or equal

to zero. The maximum number of links agents may cancel in one period is

limited by a model-parameter α and the neighbourhood after cancellation of

α′ links is depicted by ˜N α′

i (t).

We conceive that new links may only be established to players next to nearest

neighbours by a process of being made acquainted to them by one’s nearest

neighbours. The reason for this assumption lies in the rationality of the players,

which makes them aim at a minimization of potential losses by accepting

only ’recommended’ co-players. Therefore, only agents who have chosen to

cooperate have the possibility to establish new links in our model. To model

friction within the system we limit the maximum number of links which may

be established in an update. The maximum number of new links is given by

the model-parameter β; the neighbourhood after establishment of β′ links is

depicted by ˜N β′

i (t). Parameters α and β can be seen as ’agility’, as willingness

to change partners upon new information.

Now, to determine their action in the next timestep, agents have to estimate

the additional expected payoﬀ ¯P add

i

(t+1), which they could acquire due to new

links. This can in principle be achieved in two ways: On the one hand, agents

can be informed by their nearest neighbours about cooperating next-to-nearest

neighbours, which would sacriﬁce the locality of our model. On the other

hand, a detailed evaluation of the neighbourhood only using information about

8

Illustration for the notation of variables characterizing the neighbourhood
Fig. 1.
of players i and j. The players have two neighbours in common - where the corre-
sponding set is denoted ˜N(i,j) - and a number of Nu = 5 unequal neighbours. The
payoﬀ player i obtains from the set of neighbours ˜N(i,j) is denoted P ˜N(i,j)

.

nearest neighbours may be performed, as will be described in detail below. As

we have conﬁned ourselves to strictly local information, we have implemented

the second alternative. This always leads to a lower expected payoﬀ than

the ﬁrst alternative because the actions of next-to-nearest neighbours have to

be estimated . With this choice we therefore model the ’rational worst case

scenario’ within the presented framework.

2.2 The ’rational worst case scenario’

Figure 1 illustrates how the expected payoﬀ is estimated within a framework

of strictly local information: Agent i can ﬁrst evaluate her payoﬀ obtained

from the set of neighbours he and j have in common, denoted by ˜N(i,j):

P ˜N(i,j)

(t) = X
kǫ ˜N(i,j)

ai(t)Pikak(t)

(4)

Then, he can subtract this payoﬀ from j’s total payoﬀ Pj(t) to obtain an

approximation of the proﬁt j gained from the number of neighbours they

9

do not have in common, denoted by Nu. Weighting this estimate with the

fraction β/Nu, agent i obtains the expected additional payoﬀ he may receive

when establishing β random links to next-to-nearest neighbours:

¯P add
i

(t + 1) = (cid:16)Pj(t) − P ˜N(i,j)

(t)(cid:17)

β
Nu

(5)

Equation (5) gives the highest possible value only if all second next near-

est neighbours cooperate. If all of them defect, a negative payoﬀ is obtained.

Generally speaking, the procedure always gives a lower estimated payoﬀ then

would be obtained when exactly knowing the number and identity of cooper-

ating agents in the vicinity.

The dynamics of our model may be summarized as follows: At timestep t, agent

i performs an update of his action and local neighbourhood with probability

pu. This parameter is introduced to capture the synchronisation of the agents’

individual decisions (i.e. the ’coupling’ of the agents). For pu = 1, the decisions

of the agents are fully synchronized and are made simultaneously. Clearly,

the more independently the agents conduct their evaluation (the lower the

update-probability pu), the better becomes the estimate given in equation (3).

Once chosen for update, each agent calculates the expected payoﬀ in case of

cooperation, given by

¯P c
i (t + 1) = X
jǫ ˜N c
i (t)

i (t)Pij¯aj(t + 1) + ¯P add
ac

i

(t)

(6)

10

Here, ˜N c

i (t) and ˜N d

i (t) denote the ’preliminary’ neighbourhoods for the two

and the expected payoﬀ in case of defection,

¯P d
i (t + 1) = X
jǫ ˜N d
i (t)

ad
i (t)Pij¯aj(t + 1)

cases, which can be written as

˜N c

i (t) = (cid:16)

˜Ni(t) \ ˜N α′

i (t)(cid:17) ∪ ˜N β′

i (t)

and

˜N d

i (t) = ˜Ni(t) \ ˜N α′

i (t)

(7)

(8)

(9)

In equations (8) and (9) A∪B denotes the union of sets A and B, A\B stands

for excluding set B from set A. Based on the estimations given in equation (6)

and (7), agent i chooses the action, which gives him the higher expected payoﬀ

in the next turn and performs the corresponding update of his neighbourhood.

If the expected payoﬀs are equal, the action is chosen at random. This is done

simultaneously by all agents who have been selected for update at timestep t

(N sel ≈ puNtot).

The decisions are evaluated at the end of each turn and the whole procedure

is repeated in the next timestep.

11

3 Results

Within the network-dynamics implied above defectors are eﬀectively sanc-

tionized in two ways: By implicitly being eﬀected by link-cancellations and

by explicitly not being able to establish new links. The inﬂuence of these two

aspects is controlled by the two parameters α and β. The third parameter of

the model - the update probability pu - also aﬀects the nature of the resulting

time-series. In the following, the inﬂuence of these parameters is discussed in

some detail, beginning with an overview of the basic properties at given values

of α and β for diﬀerent values of pu. The discussion is based on simulations

with a C++ implementation of the model.

As a starting point, we generated random networks of a size of N = 103

agents. The random networks have been implemented in a way widely used in

literature, initially introduced by Erd¨os and Renyi (1960). A detailed discus-

sion has recently been given by Barabasi (2002). We have chosen a probability

of pl = 0.01 for the establishment of each link in the initial network. As

far as the role of diﬀerent starting conﬁgurations of the random networks is

concerned, our simulations have clearly shown that the development of the

network is independent of these conﬁgurations and converges relatively fast

towards its attractors (repulsors). If not stated otherwise, simulations have

been performed for 105 timesteps, providing very accurate statistics.

12

Fig. 2. Time-series of the fraction of cooperating agents fC for diﬀerent values of
the update-probability pu (pu = 1.0, pu = 0.5, pu = 0.1). The curves clearly indicate
that the regularity in the time-series decreases by lowering pu.

3.1 Basic properties of time-series

Figure 2 depicts the time series of the number of cooperating agents (denoted

by Nc) for the last 1000 steps of a particular simulation. The diﬀerent lines

correspond to diﬀerent values of pu with the other two parameters held ﬁxed

(α = β = 6). The payoﬀ-matrix used is the one given in Table 1. For pu = 1.0,

where each agent can change up to α + β link conﬁgurations in each turn,

oscillations with a comparably high range are observed: Quantitatively, the

number of cooperating agents undergoes rapid changes of about 50% of the

overall system size within only 3 timesteps. As shown in Figure 3, the average

number of links per agent (denoted by hli(t)i = ltot(t)/N) shows the same

behavior, oscillating between a minimum of about 4 and a maximum of about

13 links per agent.

13

Fig. 3. Time-series of average number of links hlii per agent for diﬀerent values
of the update-probability pu (pu = 1.0, pu = 0.5, pu = 0.1). Again, the values
become more erratic when loweringpu. Clearly, the time average hlii for pu = 0.1
and pu = 0.5 is considerably above the case for pu = 1.0, indicating the stabilisation
of the corresponding network.

The reason for this cyclical behavior of the system can be easily understood:

In the states corresponding to low Nc, linkage has been reduced to an extent

motivating the agents to build up links again, where a considerable amount

(in our simulations for pu = 1.0, β = 6 and α = 6 a maximum of 10% of

the overall population) of the agents lost all of their links and is relinked to a

single agent chosen at random. In conﬁgurations with high Nc, the majority

of agents has collectively acquired a state of maximum linkage, where there is

no more motivation to cooperate in our rational setting and where the clas-

sical situation of the PD is reached. This can be understood by the following

argument: If all li(t) neighbours of agent i cooperate, he starts to defect as

soon as

βRef f + li(t)R < li(t)T

(10)

14

Fig. 4. Time-series of the fraction of number of cooperating agents (solid line),
average number of links per agent (dotted line) and total payoﬀ (broken line) in the
system for pu = 0.1 and α = β = 6. The individual time-series have been shifted
for better comparison.

is realized. Here, Ref f is the averaged ’eﬀective’ reward imanent in the system,

arising from equation (5) via

Ref f =

1
N X
i

¯P add
i

(t + 1)
β

.

(11)

Of course, βRef f always gives an estimated payoﬀ lower then βR. The observed

rapidity of the oscillations becomes clear, when one considers that the agents

may build up β = 6 links per move and therefore reach hlmax

i comparatively

i

fast. By lowering α and β the amplitudes reduce (not shown).

3.2 Dependence on update-probability pu

In reality, agents are not inﬁnitely fast in assessing new information in their

surrounding. Further, they need time to adopt and employ decisions based on

15

Fig. 5. Average number of cooperating agents hNci as a function of up-
date-probability pu for α = β = 6 and α = β = 4. When pu gets larger, correlations
between the individual values grow. Taking averages of highly correlated timeseries
is to a certain extent problematic, which is why the line is drawn broken in the cor-
responding regime. To guide the eye, actual values (circles) have been interpolated
by a cubic spline.

new information. We model these time-delays by the update probability pu.

By lowering pu, the oscillations of the overall population are increasinlgy

damped. The time-series corresponding to pu = 0.5 in Figure 2 allows one to

examine this issue roughly. In contrast to the rapid update mode at pu = 1.0,

the range of the number of cooperating agents exhibits a reduced span of

about 12% of the overall population and the average number of links varies

between 5.4 and 6.5. Only 1% of the agents have lost all their links in a certain

timestep, indicating that the network is in this sense stabilized in comparison

to the pu = 1.0 case.

For values of pu < 0.5, the time-series continues to reduce in regularity, but

the range of the trajectories does not decrease accordingly. In either case, the

time-series of total payoﬀ, average number of links and number of cooperating

16

agents are strongly coupled, as shown in Figure 4 for pu = 0.1. Periods of

growing cooperation and growing average linkage hlii are found, followed by

periods of decreasing cooperation and average linkage.

Moreover, decreasing pu allows to approximate Nc based on equation (10): As

soon as the number of cooperating agents does not oscillate too strongly, the

eﬀective reward can be estimated via Ref f ≈ RNc/Ntot. Rewriting equation

(10) as

hlmax
i

i ≈ β

Ref f
T − R

(12)

allows one for the approximation hlmax

i

i ≈ 13 for pu = 0.1. The average of

hlii ≈ 12 observed in the simulations implies that the agents have arranged

quite eﬃciently as the average linkage per agent is just one link below the ’ra-

tional maximum’. Below (Section 3.4) we show that the eﬃcient arrangement

can be characterized by hierarchical structures in the network. The eﬃciency

of the system is also conﬁrmed by noting that the average number of links is

considerably increasing for lower values of pu, as can be seen in Figure 3.

As far as the overall dependence of Nc on pu is concerned, Figure 5 shows Nc

for diﬀerent values of pu. For α = β = 6, the curve exhibits a maximum at

pu ≈ 0.6, which can be understood when considering that decreasing values of

pu result in higher randomness and therefore destroy cooperative structures

in the network. On the other hand, increasing values of pu lead to a growing

amplitude of oscillations which destabilizes cooperative behavior in the system.

17

Fig. 6.
to the
Correlation length λ determined by an exponential ﬁt
auto-correlation-function of ∆NC(t), given in equation (14). For small pu the expo-
nential ﬁt becomes problematic because the process becomes practically uncorre-
lated, i.e. the correlation function turns into a Dira-delta function. This is why the
correlation length is not shown for pu < 0.3 .

Fig. 7. Visualization of ’attractors’ in the space {NC (t), NC (t + 1)} for diﬀerent
values of pu (pu = 0.1, pu = 0.7, pu = 0.8) and α = β = 6.

These oscillations also lead to growing correlations, which is why the spline-

interpolation connecting the points is drawn as broken line in Figure 5. The

gray line corresponding to α = β = 4 has its maximum at pu ≈ 0.7. Obviously,

for decreasing α and β, the system is stabilized at a higer value of pu as the

link-dynamics is reduced.

To allow a closer investigation of the qualitative change in the systems-dynamics

between pu = 1.0 and pu = 0.1, we have plotted NC(t + 1) against NC(t) in

18

Figure 7. This allows to point out that the respective attractor of the system

has a quite regular limit-cycle for pu = 0.8. Decreasing pu to 0.7 leads to a

smaller gap in the attractor and at pu = 0.6 the gap has vanished (not shown).

Further decrease in pu narrows the space ﬁlled by the trajectory of the system

(see Figure 7, pu = 0.1). Furthermore, we have taken a closer look at the

correlations in the system by the means of the autocorrelation function of the

ﬁrst diﬀerences of NC(t)

∆NC(t) = NC(t) − NC(t − 1)

.

(13)

The envelope of the autocorrelation function is ﬁtted by an exponential func-

tion with correlation length λ, i.e.

h∆NC(t + τ )∆NC(t)i ∼ e−λτ

(14)

for τ > 0. Values of λ for diﬀerent update-probabilities are summarized in

Figure 6. As expected, between pu = 1.0 and pu = 0.8 the time-series cor-

relations in the system are very strong. Lowering pu below 0.8 leads to an

decrease in the correlation, where the exponential ﬁt becomes more and more

problematic. For pu < 0.3, the correlation function resembles the shape of a

dirac-delta-function and an exponential ﬁt loses sensibility.

19

Fig. 8. Inﬂuence of the parameters α and β on the number of cooperating agents in
a population of 103 players. The two parameters have been kept equal. Simulations
were done for pu = 0.5.

3.3 Impact of ’agility’ α and β and the inﬂuence of the payoﬀ-matrix ele-

ments

To quantitatively describe the inﬂuence of the parameters α and β on Nc,

we kept both parameters equal and performed simulations for values ranging

from 1 to 7. Results are summarized in Figure 8, for pu = 0.5 and for the

payoﬀ-matrix given in Table 1. Only for a parametrization of α = β = 1, the

majority of agents is defecting, which leads to very unstable networks of very

low average connectivity (approximately 1.3 links per agent). For higher values

of α = β, the system gets initially stabilized and the increase of Nc ﬂattens as

α increases. This can be understood as the parameter α has reached a value,

where cooperating agents are able to cancel virtually all the links they have

with defecting agents. In other words, further increase of α does not improve

the ability of the players to protect themselves from defecting agents - the

internal sanction-potential of the system has reached a maximum.

20

Fig. 9.
Inﬂuence of the parameters α and β on the number of cooperating agents
in a population of 103 players. Here, the two parameters have been kept equal and
simulations have been performed for an update-probability pu = 0.5

Clearly, not only the parameters α, β and pu, but also the entries in the

payoﬀ-matrix Pij heavily inﬂuence the dynamics obtained within the presented

model. In this context, the entry for the ’ineﬃcient’ constellation I (Table

1) is of fundamental importance: When chosen larger than zero, defecting

agents keep the links between one and another, which results in a decrease of

the network’s stability and the number of cooperating agents: Once defecting

players ’organize’ themselves and cooperation collapses almost entirely. On the

other hand, increasing the values for temptation T and reward R, while holding

their diﬀerence T − R constant, allows one to examine the corresponding

increase in the average number of cooperating agents. This interrelation is

quantitatively captured in Figure 9 for two values of pu (pu = 0.5 and pu =

0.1), α = β = 6 and T = 1 + R. Apparently, for ’low’ values of R, the

update-probability has comparatively larger inﬂuence on hNci, whereas in the

ﬂattening regime, the increase caused by switching between pu = 0.1 and

pu = 0.6 is decreasing more and more.

21

Fig. 10. Degree distributions averaged over time series with T = 105, N = 103,
α = 6 and β = 6 for two diﬀerent values of update probability pu (0.1 and 0.6).

3.4 Emerging Network structure

So far, we have discussed properties of time-series generated by means of

simulation. However, also the networks obtained in these simulations show

interesting properties resembling some features of real-world networks. We

conﬁne ourselves to the discussion of the two most widely used quantities in

the analysis of networks: The degree distribution and the cluster-coeﬃcient.

For a detailed discussion of these concepts see e.g. the recent discussions of

Barabasi (2002) and Dorogovtsev and Mendes (2003).

Figure 10 shows the degree-distribution P (k) in a double-logarithmic plot for

two values of pu. To improve the accuracy of the plot, degree distributions of

networks at diﬀerent times have been averaged, where the correlation in the

time-series has been regarded by using appropriate time-diﬀerences between

the individual network conﬁgurations. Also, we have monitored the results via

comparison of degree-distributions for larger networks with the same param-

eters. Although the results were the same, to remain consequent, Figure 10

22

depicts the degree-distribution for the N = 103 case, for pu = 0.1 and pu = 0.6.

For pu = 0.1, the linear ﬁt shown is apparently inadequate - the network is

certainly not scale-free, but somewhere between a power-law and an exponen-

tial regime. However, for pu = 0.6, the distribution is more narrow and the

linear approximation in the double-logarithmic plot indicates that the tail of

the distribution can be given by a scaling law P (k) ≈ k−γ. This shows that

the network is clearly not random, but possesses self-similar structure. Fur-

ther, by increasing the irregularity introduced into the system by lowering pu,

the network obviously loses structure and becomes more random. For pu > 0.6

correlations sharply increase, as does the variation in the total number of links

of the individual networks at diﬀerent timesteps. This hinders averaging the

degree-distributions. At pu = 1.0, no ’global’ degree-distribution exists, but

diﬀerent P (k)’s for each of the possible states (high Nc and low Nc) of the

system have to be considered.

The cluster coeﬃcient C, deﬁned as the average of all individual cluster coef-

ﬁcients Ci, provides a quantitative measure for cliques (i.e. circles of acquain-

tances in the network in which every member knows every other member) in

the network. The individual cluster coeﬃcient of a node i is deﬁned as

Ci =

2Ei
ki(ki − 1)

(15)

where Ei are the number of existing edges between i’s neighbours and ki(ki −

1)/2 gives the highest possible value of edges between the neighbours. The

23

Fig. 11. Time averages hCi of the cluster coeﬃcient for diﬀerent values of pu and
α = β = 6. The insert shows the cluster coeﬃcients of equivalent random graphs,
denoted by hCrandi. hCrandi is decreasing strongly for pu > 0.7 because the average
number of links in the system is dropping considerably in this regime.

clustering coeﬃcient of a random graph is given by Crand = p = hki/N (see e.g.

Barabasi (2002)). As the expected total number of edges in a random graph can

be obtained via ¯ltot = p(N(N − 1))/2, one can compare the cluster coeﬃcient

obtained from given networks to those of equivalent random networks. Figure

11 shows the average cluster coeﬃcients from simulations at diﬀerent values

of pu and the other parameters ﬁxed (α = β = 6). For comparison, also the

cluster coeﬃcients of equivalent random graphs are shown. Again, a data point

represents a time-average over cluster-coeﬃcients of diﬀerent networks, where

the above annotations apply in the same manner.

Obviously, the observed networks exhibit large clustering-coeﬃcients when

compared to those of equivalent random graphs. This is not a big surprise, as

our mechanism of linkage between the agents is characterized by links being

made to next-to-nearest neighbours and thus directly favours the formation

24

of cliques. When taking a look at the dependence of the cluster-coeﬃcient on

pu, a minimum at pu = 0.6 can be identiﬁed. Interestingly, this corresponds

to the maximum of the number of cooperating agents in Figure 5 and to the

value of pu where we examined an apparent scaling-law behavior of the degree

distribution. This is not a contradiction, but rather indicates, that - when

compared to the other cases - there is still a potential for further clustering

in the system. In almost the same manner, the high clustering-coeﬃcient for

pu = 1.0 is the outcome of averaging over maximum clustering and states

where cliques are still comparatively pronounced.

Plotting the cluster-coeﬃcients Ci of individual agents against their degree

ki allows for a more sophisticated analysis of network structure. The corre-

sponding plot is shown in Figure 12, where each point corresponds to a pair

{ki, Ci}. The points have been sampled from 100 diﬀerent networks. Based

on this data, we have calculated the mean cluster-coeﬃcient in dependence of

the degree of the nodes, denoted by hCii(k). The tail of this distribution is

shown in double logarithmic scale in the insert of Figure 12. Clearly, there is a

non-random relationship between cluster-coeﬃcient and degree of the nodes.

Speciﬁcally, Figure 12 shows that the underlying networks exhibit hierarchy:

For small degrees the mean clustering is much higher than for large degrees.

Equivalently, nodes with many links are - on average - less connected between

each other than nodes with less links, which is exactly what one would expect

from a hierarchic network. Examination of {ki, Ci} for pu = 1.0 (not shown)

25

Individual cluster coeﬃcients Ci plotted against individual degree ki for
Fig. 12.
pu = 0.6 and α = β = 6. The insert shows the tail of the corresponding distribution
in a double-logarithmic plot, where the individual Ci’s have been averaged. The
slope of the interpolating line is γ ≈ − 0.4.

conﬁrms that the network is disintegrating for high values of pu. The hierarchy

is lost, as for degrees up to 35 the downward slope of the curve is destructed.

Finally, Figure 13 shows the average distribution of individual payoﬀs in the

system, for pu = 0.1 and pu = 0.6 respectively. Although, the maximum of

the distribution is at a higher payoﬀ for pu = 0.1, the average payoﬀ is higher

for pu = 0.6 as the tail of the distribution is ’fatter’ in this case. Further, the

insert shows the tails of the distribution in a semi-logarithmic plot, indicating

that the tails are almost exponential.

4 Conclusion and Discussion

In this article, we have considered the prisoner’s dilemma being played on

dynamic networks under full rationality and local information horizons of the

26

Fig. 13. Average distribution of the individual payoﬀs for pu = 0.1 (broken line)
and pu = 0.6 (solid line) (α = β = 6). The insert shows the tails of the distribution
in a semi-logarithmic plot.

agents. Within this framework, reasonable assumptions about individual de-

cisions lead to a model of network dynamics where defecting agents become

isolated over time. Our results show, that the simulation of these dynamics

leads to cooperative behavior, even within a preconstitutional setting and a

framework of complete rationality. In contrast to previous work neither imi-

tation nor memory longer than one single timestep is required. The degree of

cooperation arising depends on the three introduced model parameters and

on the speciﬁc choice of the payoﬀ-matrix.

Most important, a high update-probability pu leads to high synchronisation of

the agents’ decisions and signiﬁcant oscillations of global parameters like the

number of cooperating agents and the average linkage in the system. Much re-

sources are wasted in collective movements. This oscillatory dynamics might

provide an understanding for many cyclical synchronization patterns found

in actual economic settings. In contrast, low synchronisation of the agents

27

introduces considerable randomness in the system and seems to hinder the

emergence of cooperative structures. For regimes in between high and low

synchronization, we showed that the system reaches an optimum, where net-

work characteristics resemble those of complex networks, exhibiting clearly

non-random properties. The cooperative structures can be characterized by a

scaling-law-behavior of the degree-distribution and a hierarchical organization

of the network. In this context, a discussion of substructures and hierarchical

organization in the interbank market is given by Boss et al. (2005).

In the spirit of constitutional economics and under the aspect of the ob-

served facts, we may point to Buchanan (1975) and his conception of the

social dilemma faced within a licentious society. In his work, Buchanan points

out that - when generalized to social scales - ’the prisoner’s dilemma will

take on highly complex structural characteristics’. Eventually, we have mod-

elled these characteristics within our model and demonstrated that the afore

mentioned ’characteristics’ exhibit a nature strongly reducing the fatality of

the prisoner’s dilemma, as its properties resemble those of complex networks.

What goes beyond the presented work, but would merit closer investigation is

a quantitative discussion of the resources spent by the agents to assert their

decisions, combined with a comparison to the resources spent by a state-like

institution leading to the same degree of cooperation.

28

The authors acknowledge funding through the Austrian Science Fund (FWF),

Project P17621-G05, and the Austrian Council. S.T. would like to thank the

SFI and in particular J.D. Farmer for the great hospitality in the summer of

5 Acknowledgements

2004.

References

Review E 63, 030901.

99–125.

Modern Physics 74, 47.

tative Finance.

Abramson, G., Kuperman, M., 2001. Social games in a social network. Physical

Ashlock, D., Smucker, S., Stanley, A., Tesfatsion, L., 1996. Preferential partner

selection in an evolutionary study of the prisoner’s dilemma. BioSystems 37,

Axelrod, R., 1984. The Evolution of Cooperation. Basic Books, New York.

Barabasi, A., 2002. Statistical mechanics of complex networks. Reviews of

Boss, M., Elsinger, H., Summer, M., Thurner, S., 2005. The network topology

of the interbank market. Santa Fe Institute preprint, to appear in Quanti-

Brennan, G., Buchanan, J., 1985. The Reason of Rules: Constitutional Polit-

ical Economy. Cambridge University Press, Cambridge.

Buchanan, J., 1975. The Limits of Liberty: Between Anarchy and Leviathan.

29

University of Chicago Press, Chicago.

Dorogovtsev, S., Mendes, J., 2003. Evolution of Networks: From Biological

Nets to the Internet and WWW. Oxford University Press, Oxford.

Ebel, H., Bornholdt, S., 2002. Coevolutionary games on networks. Physical

Erd¨os, P., Renyi, A., 1960. On the evolution of random graphs. Publ. Math.

Review E 66, 056118.

Inst. Hungar. Acad. Sci. 5, 17–61.

Hauk, E., 2001. Leaving the prison: Permitting partner choice and refusal in

prisoner’s dilemma games. Computational Economics 18, 65–87.

Hobbes, T., 1943. Leviathan. Everyman Edition, New York.

Holme, P., Trusina, A., Kim, B., Minnhagen, P., 2003. Prisoners’ dilemma

in real-world acquaintance networks: Spikes and quasi-equilibria induced

by the interplay between structure and dynamics. Physical Review E 68,

Huberman, B., Lukose, R., 1997. Social dilemmas and internet congestion.

030901(R).

Science 277, 535.

Kim, B., Trusina, A., Holme, P., Minnhagen, P., Chung, J., Choi, M., 2002.

Dynamic instabilities induced by asymmetric inﬂuence: Prisoners’ dilemma

game in small-world networks. Physical Review E 66, 021907.

Miller, J., Butts, C., Rode, D., 2002. Communication and cooperation. Journal

of Economic Behavior and Organization 47, 179.

Nowak, M., May, R., 1992. Evolutionary games and spatial chaos. Nature 359,

826–829.

30

Nowak, M., Sigmund, K., 1993. A strategy of win-stay, lose-shift that outper-

forms tot-for-tat in the prisoner’s dilemma game. Nature 364, 56–58.

Oborny, B., Kun, A., Czaran, T., Bokros, S., 2000. The eﬀect of clonal integra-

tion on plant competition for mosaic habitat space. Ecology 81, 3291–3304.

Sato, Y., Akiyama, E., Farmer, J., 2002. Chaos in learning a simple two-person

game. Proceedings of the National Academy of Sciences 99, 4748–4751.

Tullock, G., 2005. Social Dilemma Of Autocracy, Revolution, Coup D’etat.

Liberty Fund, Indianapolis.

Weibull, J., 1996. Evolutionary Game Theory. MIT Press, Cambridge.

Zimmermann, M., Eguiluz, V., Miguel, M., 2004. Coevolution of dynami-

cal states and interactions in dynamic networks. Physical Review E 69,

065102(R).

31

