6
0
0
2
 
g
u
A
 
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
6
0
0
8
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A Rational Indicator of Scientiﬁc Creativity

Jos´e M. Soler∗
Departamento de F´ısica de la Materia Condensada, C-III,
Universidad Aut´onoma de Madrid, E-28049 Madrid, Spain
(Dated: February 2, 2008)

A model is proposed for the creation and transmission of scientiﬁc knowledge, based on the network
of citations among research articles. The model allows to assign to each article a nonnegative value
for its creativity, i. e. its creation of new knowledge. If the entire publication network is truncated to
the ﬁrst neighbors of an article (the n references that it makes and the m citations that it receives),
its creativity value becomes a simple function of n and m. After splitting the creativity of each
article among its authors, the cumulative creativity of an author is then proposed as an indicator
of her or his merit of research. In contrast with other merit indicators, this creativity index yields
similar values for the top scientists in two very diﬀerent areas (life sciences and physics), thus oﬀering
good promise for interdisciplinary analyses.

Introduction

Creativity Model

Evaluating the scientiﬁc merit and potential, of tenure
and professorship candidates, is perhaps the most critical
single activity in the academic profession. In countries
and institutions with a long scientiﬁc tradition, selection
committees are generally well trained and trusted to bal-
ance wisely the vast variety of factors that may inﬂuence
the decision, in the sense of optimizing the long-term
scientiﬁc output. In less established environments, deci-
sions are frequently perceived as arbitrary, and the use
of objective indicators and procedures may be necessary
to obtain a wide consensus.1

The most traditional indicator of research output, the
number of published papers, has been progressively sub-
stituted by the number of citations received by those
papers, when this impact indicator has become widely
available and easy to obtain.2,3 Diﬀerent combinations of
both magnitudes have been proposed,4 like those in the
SPIRES database.5 The ﬁeld has been recently revital-
ized by the proposal by Hirsch6 of yet another combina-
tion, the so-called h index, which has gained a rapid pop-
ularity, partly because the Thomson-ISI Web of Knowl-
edge database3 provides a handy tool to sort articles by
their number of citations (while it oﬀers no tools to ob-
tain other indicators, like the total citation count). Apart
from that comparative handiness, there is little objective
evidence for the relative advantages of diﬀerent indexes,
which are generally motivated in terms of “impact” or
“inﬂuence”. However, it must not be forgotten that the
task of a scientist is to create useful knowledge (in its
It
broadest sense), not merely to produce an impact.
is therefore desirable to derive some rational measure of
the magnitude and quality of research output, rooted in
a plausible model of the creation and transmission of sci-
entiﬁc knowledge.7

∗E-mail: jose.soler@uam.es.

Basic scientiﬁc knowledge, as opposed to technological
or industrial knowledge, is created by the minds of scien-
tists and expressed almost exclusively as research articles.
The knowledge is transmitted to other scientists, who
read previous articles and acknowledge this transmission
in the form of references (in what follows, I will call ref-
erences of an article those made to previous papers, and
citations those received from posterior papers). Thus,
the output knowledge of an article comes partly from
previous work, which is simply transmitted, and partly
from the creation of new knowledge by the authors. How-
ever, there are many possible reasons why references are
made.2,8,9,10 Furthermore, some of the references of an
article may be more important than others. Thus, it
is rather uncertain to what extent a given reference re-
ﬂects the use of previous knowledge. Therefore, in the
present model I will simply assume that each reference
reﬂects the transmission of a diﬀerent nonnegative value
xij of knowledge, with probability P (xij ), from the cited
article i to the citing article j. The maximum entropy
principle11 dictates that, in the absence of any a priori
information, other than the average value hxi = 1/α, the
probability is given by P (x) = αe−αx.

Consider the network formed by all published papers
connected by their citations. The growth, connectivity,
and statistical properties of this and similar networks
have been the subject of much recent work.12,13 To model
the ﬂow of knowledge on this supporting network,7 we
may assign random ﬂow numbers xij to all citations, with
probability P (xij ). Flow conservation implies that the
articles’ knowledge-creation values ci (that I will simply
call creativities) obey

ci =

xij −

xki

Xj

Xk

(1)

I will discard negative knowledge as meaningless.14 Thus,
I will require that ci ≥ 0 ∀i, and reject the sets {xij }
that violate this condition.15,16,17 The ﬁnal values ci will
then be averages over all valid sets {xij}, with a relative

weight P ({xij}) ∝ exp(−α

ij xij ).

Some attention must be paid to the deﬁnition of knowl-
P
edge that is being used. It might seem that all the knowl-
edge created by an article must be present already when
it is published. However, this would make it diﬃcult
to judge the relative importance of the knowledge cre-
ated by diﬀerent papers. Therefore, I rather consider
the amount of “used knowledge” (and therefore useful).
The situation is very similar in software development:
the economic value of a computer library does not ma-
terialize when it is written, but when licenses of it are
sold, presumably to create new software (for free software
we might substitute licenses sold by copies downloaded).
Similarly, I am counting every “copy” of the knowledge,
used in every new paper that cites it (alternatively, one
might consider the knowledge created by a paper as the
sum of that added to all the brains that have read it).

Some of the general qualitative features of the model,
as an indicator of research merit, may be expected a pri-
ori: articles with less citations than references will have
a positive but small creativity value; articles with a large
output (very cited) and a small input (not many refer-
ences) will have the largest creativities; in contrast, the
merit of review articles will be much more moderate than
that shown by their raw impact factor (citation count);
the diﬀerences between the creativities of authors in very
large and active ﬁelds (with large publication and cita-
tion rates), and those in smaller and less active ﬁelds, will
be largely attenuated, as compared to other merit indi-
cators, since the basic measure is the diﬀerence between
citations and references, which should be roughly zero in
all ﬁelds; self-citations will be largely discounted, since
they will count both as a negative contribution (to the
citing paper) and a positive one (to the cited paper); ci-
tations received from a successful article (i. e. a very cited
one itself) will be more valuable than those made by a
poorly cited one.18,19 In particular, citations by uncited
papers will add no value at all, since no knowledge can
ﬂow through them; more generally, articles that generate
a divergent citation tree (e. g. the DNA paper of Watson
and Crick) will have a large creativity, while those lead-
ing ultimately to a dead end (e. g. the cold fusion paper
of Fleischmann and Pons) will have a small one, even if
they had the same number of direct citations.

Simpliﬁed Model

2

and m citations, and to impose the conservation of ﬂow,
Eq. (1), only in the central node i. The average value hxi
can be used as a convenient unit of knowledge, so that
α = 1 and P (x) = e−x. The probability that an article,
with n references and m citations, has a creativity c is
then, for n, m > 0:

P (c|n, m) = N

−1

dx1...dxndy1...dym δ(c+x−y) e

−x−y

∞

...

Z
0

Z

n
i=1 xi and y =

(2)
m
j=1 yj, where xi are the in-
with x =
P
put ﬂows (references) and yj are the outputs (citations).
δ(x) is Dirac’s delta function, and N is a normalization
factor given by

P

∞

N =

...

Z

Z

0

dx1...dxndy1...dym θ(y − x) e

−x−y

(3)

where θ(x) is the step function. Using a convenient
change of variables, the integrals can be evaluated as
dx dy xn−1ym−1
(n − 1)!(m − 1)!

θ(y − x) e

N =

−x−y

(4)

∞

Z Z
0

P (c|n, m) = N

−1

∞

dx dy xn−1ym−1
(n − 1)!(m − 1)!

Z Z
0

δ(c+x−y) e

−x−y

The result is

P (c|n, m) =

ne−c
n + m − 1

1F1(1 − m, 2 − n − m; 2c)
2F1(1, 1 − m; 1 + n; −1)

where 1F1 and 2F1 are hypergeometric functions, which
can be expanded as a ﬁnite series.20 Figure 1 shows some
typical probability distributions.

(5)

(6)

0.2

0.15

)

m
,
n
c
(
P

|

0.1

0.05

m=10

n=30

m=20

m=50

m=80

The quantitative analysis of the model presented above
is an interesting challenge that will be addressed in the
future. In this work, I am rather interested in simplify-
ing the model to allow the easy generation of a practi-
cal indicator of merit of research. The simpliﬁed model
will keep many of the general features discussed above,
though not all (in particular, it will loose the last two
properties mentioned above). Thus, I propose to trun-
cate the citation network beyond the ﬁrst neighbors of
any given paper, i. e. to consider only its n references

0

0

20

40
c

60

80

FIG. 1: Probability that an article, that has made n = 30
references and has received m citations, has created a value c
of scientiﬁc knowledge. It was obtained from Eq. (6).

The average value of c,

c(n, m) =

dc c P (c|n, m),

(7)

∞

Z
0

is, for n, m > 0:

c(n, m) = P

m−1
k=0

(n+m−2−k)!
(m−1−k)! (k + 1)2k
(n−1)!(n+m−1)!
(n+k)!(m−1−k)!

m−1
k=0

.

P

(8)

It is represented in ﬁgure 2 for some typical values of
n and m. As expected, c(n, m) increases with m and

n=10

n=30

n=50

)

,

m
n
(
c

50

40

30

20

10

0

0

20

40

60

80

100

m

FIG. 2: Circles: mean creation of knowledge (creativity)
of an article with n references and m citations, calculated
from Eq. (7) (in units of the mean transmission of knowledge
reﬂected by one reference). Solid lines: ﬁts given by Eq. (9).
Dashed lines: m − n.

it decreases with n. It obeys c(0, m) = m, c(n, 0) = 0,
c(n, 1) = 1, and c(n, m) ≥ max(1, m − n) ∀m > 0.
For the present purposes, a reasonably accurate ﬁt is, for
m > 0:

c(n, m) ≃ m − n +

(9)

n
A eaz + B ebz

where z = (m − 1)/(n + 5), A = 0.986, B = 0.014, a =
1.08, and b = 6.3. The accumulated creativity of an
author with Np published papers is then deﬁned as

Ca =

Np

Xi=1

c(ni, mi)
ai

(10)

where ai is the number of authors of paper i. Notice that,
being positive and cumulative, Ca can only increase with
time and with the number of published papers.

In order to ﬁnd in practice the creativity of an au-
thor (among many other merit indicators), one can fol-
low these steps: 1) Download the programs ﬁlter and
merit from this author’s web page,21 and compile them
if necessary. 2) Perform a “General search” in the Thom-
son ISI Web of Science database3 for the author’s name,
using the appropriate ﬁlters.
3) Select the required
records. Usually the easiest way is to check “Records
from 1 to last one” and click on “ADD TO MARKED
LIST” (if you ﬁnd too many articles, you may have
to mark and save them by parts, say (1-500)→ﬁle1,

3

(501-last one)→ﬁle2); 4) Click on “MARKED LIST”. 5)
Check the boxes “Author(s)”, “Title”, “Source”, “key-
words”, “addresses”, “cited reference count”, “times
cited”, “source abbrev.”, “page count”, and “subject cat-
egory”. Do not check “Abstract” nor “cited references”,
since this would slow down considerably the next step.
6) Click on “SAVE TO FILE” and save it in your com-
puter. 7) Click on “BACK”, then on “DELETE THIS
LIST” and “RETURN”, and go to step 2 to make an-
other search, if desired. 8) If you suspect that there are
two or more authors with the same name, use the ﬁlter
program to help in selecting the papers of the desired
author. 9) Run the merit program to ﬁnd the merit in-
dicators. Mind for hidden ﬁle extensions, possibly added
by your navigator, when giving ﬁle names in this and
previous step.

Results and Discussion

Table I shows several indexes of merit of top scien-
tists in life sciences and physics, taken from Hirsch’s
selection.6 It may be seen that the h index of all biol-
ogists is larger than that of all physicists, and their aver-
age number of publications and citations is 1.5–2.5 times
larger. In contrast, the two creativity distributions are
remarkably similar, with averages that diﬀer only ∼ 15%,
well below the standard deviation of both distributions.
This oﬀers the promise of direct interdisciplinary compar-
isons, without any ﬁeld normalization, a highly desirable
characteristic of any index of merit.

Although it is a natural consequence of the idea of
knowledge ﬂow, the fact that the references of an article
will result in lowering the merit assigned to it, is admit-
tedly striking. It is thus appropriate to recognize that
this is partly due to a deliberate intent of measuring cre-
ativity rather than productivity (or, in economic terms,
added value rather than sales). To illustrate the point,
imagine that two scientists, Alice and Bob, address in-
dependently an important and diﬃcult problem in their
ﬁeld. Bob takes an interdisciplinary approach and dis-
covers that a method developed in a diﬀerent ﬁeld just
ﬁts their need. Simultaneously, Alice faces the problem
directly and re-invents the same method by herself (thus
making less references in her publication).22 All other
factors being equal, both papers will receive roughly the
same number of citations, since they transmit the same
knowledge to their ﬁeld. But it may be argued that Al-
ice’s work was more creative in some sense, and that her
skills might possibly (but not necessarily) be more valu-
able in a given selection process. Eventually, the use-
fulness of diﬀerent merit indicators will depend on how
well they correlate with real human-made selections4,23.
Thus, Table I shows also a “productivity index” Pa (not a
probability), given by the author’s share of the citations
received by her/his papers. Notice that, in the model
proposed, Nc is the total output ﬂow of knowledge from
the author’s papers, while Pa is her/his share of it. It

Np Nc(103) h Pa(103) Ca(103)
Name
447
B. Vogelstein
1144
S. H. Snyder
693
S. Moncada
987
P. Chambon
1247
R. C. Gallo
657
D. Baltimore
428
R. M. Evans
T. Kishimoto
1621
C. A. Dinarello 992
615
A. Ullrich
883
Average
Standard dev.
364
P. W. Anderson 342
999
A. J. Heeger
254
E. Witten
444
S. Weinberg
625
M. L. Cohen
M. Cardona
1096
A. C. Gossard 918
P. G. deGennes 358
446
469
595
286

144.4
154
34.1
138.3
194
48.2
106.2
145
32.5
98.1
153
23.0
95.9
154
17.9
95.3
162
33.0
78.8
130
21.2
77.5
134
14.6
74.3
138
26.3
13.6
122
73.0
98.2 149 26.4
10.1
19
24.1
39.1
96
56.7
14.2
109
53.5
39.9
111
53.1
32.7
88
38.8
14.3
94
37.4
12.8
88
37.0
7.4
92
34.3
26.7
80
32.6
19.0
88
29.8
12.2
75
24.9
21.8
92
39.8
11.3
11
10.4

32.0
38.9
27.8
17.7
13.8
28.2
18.3
10.2
19.2
10.9
21.7
9.1
36.9
10.3
35.9
29.3
10.6
7.8
5.8
23.9
14.3
9.9
18.5
11.3

M. E. Fisher
G. Parisi
Average
Standard dev.

TABLE I: Several merit indicators of the ten most cited scien-
tists in life sciences and physics.6 Np: number of papers pub-
lished. Nc: number of citations received by those papers. h:
number of papers with h or more citations (Hirsch index).6 Pa:
Np
author’s knowledge-productivity index, Pa =
i=1 mi/ai,
where ai and mi are the number of authors and of citations
received by paper i. Ca: author’s creativity index, Eq. (10).
The data were obtained in April 2006.

P

may be seen that Pa also allows reliable interdisciplinary
comparisons. It may be concluded that the main diﬀer-
ence between the two communities is the larger average
number of authors per article in the life sciences, which
is taken into account in both Pa and Ca, but not in the
other indexes.

Knowledge-productivity and creativity indicators can
be used also for groups, institutions, or journals. Thus,
Table II shows them for some leading journals. As ex-
pected, most review journals have considerably smaller
creativities than productivities (dramatically smaller in
some cases). Still, Reviews of Modern Physics has the
largest creativity index of all the journals studied, show-
ing that collecting, processing, and presenting knowledge
in a coherent way can by itself create much new useful
knowledge.

Finally, in a world of strong competition for positions
and founds, a negative merit assignment to references
might result in a tendency to reduce them below what

4

Journal
Nature
Science
Rev. Mod. Phys.
Adv. Phys.
Surf. Sci. Rep.
Rep. Prog. Phys.
Phys. Rep.

Np Nr/Np Nc/Np C/Np
3676
2449
20
8
5
29
81

IF
59
28.8
24.4
63
160 13.4
12.7
18
10.3
3
6.2
32
5.6
22
6.0
44
3.9
11
3.3
24
3.3
26
3.1
16
2.8
18

67
74
327
149
61
90
90
59
23
42
34
37
35

10
14
284
391
159
198
166
18
27
37
13
37
27

Phys. Rev. Lett. 1904
Phys. Rev. D 1049
620
Nucl. Phys. B
Appl. Phys. Lett. 1819
J. Chem. Phys. 2040
Phys. Rev. B 3488

TABLE II: Several indicators of some of the main multidisci-
plinary, review and non-review Physics journals. Np: number
of “papers” (documents) published in year 1990, in all the
sections included in the Science Citation Index database. Nr:
number of references made by those papers. Nc: number of
citations received by those papers until May 2006. C: Sum of
Np
the creativities, Eq. (7), of those papers, C =
i=1 c(ni, mi).
IF: Impact factor in 1998 (center of the period 1990-2006), as
deﬁned by the Journal of Citation Reports.3 For the non-
review physics journals (last group), the indicators (other
than Np and IF) have been obtained from a random sample
of their Np papers, rather than from the whole set.

P

would be scientiﬁcally desirable and professionally fair.
A possible solution is to use, in Eq. (7), a ﬁxed value of
n (equal to the journal reference intensity, i. e. the aver-
age number of references per article in that journal), to
calculate the creativities for competitive-evaluation pur-
poses. This would spoil a few desirable properties of the
model (like the discount of self-citations), but most of its
eﬀects would probably be rather mild, since the number
of references per paper has a much smaller variance than
the number of citations. Thus, the root mean squared
diﬀerence between the creativities of Table I, calculated
using the average references of the journals, rather than
the actual references of each article, is only ∼ 4%.

Conclusion

In conclusion, I have proposed an index of research
merit based on creativity, deﬁned as the creation of new
scientiﬁc knowledge, in a plausible model of knowledge
generation and transmission. It is calculated easily from
the citations and references of the author’s articles, and
it is well suited for interdisciplinary comparisons. An
advantage of such an index is that its meaning may be
more easily perceived, by policy makers and the general
public, as a measure of a scientist’s social and economic
service to the community.

Acknowledgments

Herrero, L. Seijo, and F. Yndurain. This work has been
founded by Spain’s Ministery of Science through grant
BFM2003-03372.

I would like to acknowledge very useful discussions
with J. V. Alvarez, J. R. Castillo, R. Garc´ıa, J. G´omez-

5

1 H. F. Moed, Citation Analysis in Research Evaluation

taken α = const = 1.

(Springer, Dordrecht, 2005).

2 E. Garﬁeld, Science 144, 649 (1964).
3 http://isiknowledge.com.
4 E. J. Rinia, T. N. van Leeuwen, H. G. van Vuren, and

A. F. J. van Raan, Research Policy 27, 95 (1998).

5 http://www.slac.stanford.edu/spires/hep/.
6 J. E. Hirsch, Proc. Nat. Acad. Sci. 102, 16569 (2005).
7 E. J. Rinia, T. N. van Leeuwen, E. E. W. Bruins, H. G.
van Vuren, and A. F. J. van Raan, Scientometrics 54, 347
(2002).

8 R. K. Merton, Science 159, 56 (1968).
9 G. N. Gilbert, Social Studies of Science 7, 113 (1977).
10 S. E. Cozzens, Scientometrics 15, 437 (1989).
11 M. Tribus, Rational Descriptions, Decisions, and Designs

(Pergamon Press, New York, 1969).
12 S. Redner, Physics Today 58, 49 (2005).
13 R. Albert and A. L. Barabasi, Rev. Modern Phys. 74, 47

(2002).

14 An ironic observer might object to this assumption, argu-
ing that many articles contribute only to confusion, and
that some citations are in fact critical. I ﬁnd this question-
able, since most readers will ﬁlter eﬃciently this “negative”
knowledge, simply ignoring it. Also, even wrong ideas can
stimulate new valid ones. In any case, critical references
cannot be easily distinguished from positive ones, but their
average eﬀect might be taken into account by renormaliz-
ing the mean ﬂow value hxi.

15 Since new, nonnegative knowledge is created in every arti-
cle and transmitted to the future, the total ﬂow of knowl-
edge must increase with time. Such an increase may be
absorbed in three ways: by an increase in the number of
articles published per year; by an increase in the number
of references per article; and by an increase in the average
ﬂow per citation hxi. The increase of the rate of publica-
tions is indeed a large eﬀect, while that of citations per
paper is much weaker, if positive at all. In any case, it is
not clear whether those two eﬀects combined can fully ac-
count for the transmission of the new knowledge predicted
by the model. Thus, it may be necessary to adjust self-
consistently a function α(t), of time t. In this work I have

16 Some of the basic scientiﬁc knowledge “leaks” out of the
academic research literature in various forms: as knowl-
edge absorbed by scientists who read the articles but do
not cite them; as established knowledge transmitted to
textbooks and no longer cited in research articles (oblivion
by incorporation); as technological knowledge translated
to patents, that may cite the literature but that are not
included in databases of basic research;24 and as industrial
knowledge translated to unpublished manufacture meth-
ods and products. It seems reasonable to assume that this
“hidden” ﬂow of knowledge is proportional on average to
the “visible” ﬂow shown by citations. Therefore, in order
to account for the hidden ﬂow, we may multiply the visi-
ble output ﬂow of each article (ﬁrst term of Eq. (1)) by a
factor (1+γ), where γ is a phenomenological adjustable pa-
rameter. In the simpliﬁed model of this work I have taken
γ = 0.

17 The boundary problem posed by recent papers, that have
had no time to transmit their knowledge, may be addressed
by not imposing ﬂow conservation on them, or by assign-
ing to them an average number of additional expected ci-
tations, that will be a decreasing function of their age. In
any case, it is clear that any ﬁgure of merit based on ci-
tations will not be as reliable for very recent papers as for
old ones.

18 G. Pinski and F. Narin, Information Processing and Man-

agement 12, 297 (1976).

19 P. Chen, H. Xie, S. Maslov, and S. Redner (2006),

arXiv:physics/0604130.

20 I. S. Gradshteyn and I. M. Rydhik, Table of Integrals, Se-
ries, and Products (Academic Press, Orlando, 1980).

21 http://www.uam.es/jose.soler/tools.
22 This is somewhat hypothetical since good citation practice
(generally enforced by the referees) requires that previous
relevant work is cited, independently of whether it was
actually used.

23 J. Cole and S. Cole, American Sociologist 6, 23 (1971).
24 F. Narin, K. S. Hamilton, and D. Olivastro, Research Pol-

icy 26, 317 (1997).

