5
0
0
2
 
r
p
A
 
4
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
6
2
0
4
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Let Your CyberAlter Ego Share Information and Manage Spam

Joseph S. Kong,∗ Behnam A. Rezaei,† Nima Sarshar,‡ and Vwani P. Roychowdhury§
Electrical Engineering Department
University of California, Los Angeles.

P. Oscar Boykin¶
Electrical and Computer Engineering Department
University of Florida.
(Dated: September 8, 2013)

Almost all of us have multiple cyberspace identities, and these cyberalter egos are networked
together to form a vast cyberspace social network. This network is distinct from the world-wide-
web (WWW), which is being queried and mined to the tune of billions of dollars everyday, and until
recently, has gone largely unexplored. Empirically, the cyberspace social networks have been found
to possess many of the same complex features that characterize its real counterparts, including scale-
free degree distributions, low diameter, and extensive connectivity. We show that these topological
features make the latent networks particularly suitable for explorations and management via local-
only messaging protocols. Cyberalter egos can communicate via their direct links (i.e., using only
their own address books) and set up a highly decentralized and scalable message passing network
that can allow large-scale sharing of information and data. As one particular example of such
collaborative systems, we provide a design of a spam ﬁltering system, and our large-scale simulations
show that the system achieves a spam detection rate close to 100%, while the false positive rate
is kept around zero. This system of letting cyberalter egos network among themselves has several
advantages over other recent proposals for collaborative spam ﬁltering: (i) It uses an already existing
network, created by the same social dynamics that govern our daily lives, and no dedicated peer-
to-peer (P2P) systems or centralized server-based systems need be constructed; (ii) It utilizes a
percolation search algorithm (which can be viewed as mimicking how rumor is spread in a social
network) that makes the query-generated traﬃc scalable; (iii) The network has a built in trust
system (just as in social networks) that can be used to thwart malicious attacks; and (iv) It can be
implemented right now as a plugin to popular email programs, such as MS Outlook, Eudora, and
Sendmail.

I.

INTRODUCTION

A. CyberAlter Ego and the Pervasive Cyberspace
Social Networks

Our socioeconomic activities are getting intricately en-
twined with our identity in the cyberspace, and perhaps
we are witnessing the emergence of an alter ego in the
cyberspace. For example, every email user can construct
a list of email addresses from which he has received
emails or sent emails to; this constitutes one’s cyber-
neighborhood. This list is stored in the address books or
contact lists managed by one’s email client software or
by the ISPs that one uses. It can be also automatically
constructed by just sifting through one’s mail box. Indi-
viduals on such lists have their own address books and
contact links and soon there is a cyberspace network, in
which our identities or cyberalter egos are ﬁrmly embed-
ded and occupy various positions of power, centrality,

∗Electronic address: jskong@ee.ucla.edu
†Electronic address: behnam@ee.ucla.edu
‡Electronic address: nima@ee.ucla.edu
§Electronic address: vwani@ee.ucla.edu
¶Electronic address: boykin@ece.ufl.edu

or proximity to cyber-communities of potential interest.
Thus, an undirected social email network can be deﬁned
as follows: the nodes in the network correspond to email
addresses; a pair of nodes is connected by an edge if a
message is exchanged between the two nodes. Similarly,
a directed social email network can be deﬁned as follows:
nodes also correspond to email addresses; a directed edge
points from A to B if node A has sent an email to node
B and vice versa[21]. One can modify this network to in-
corporate other parameters of interest; for example, each
edge can be assigned a weight based on the number of
email messages exchanged, or time-stamps can be added
to messages along each edge so that one can prune the
network to reﬂect the recent status of interactions among
the cyberalter egos.

A major obstacle to studying such email networks has
been that contact addresses and lists of a large enough
group of cyberalter egos are not available in the public
domain. Even though large ISPs, such as Hotmail, Ya-
hoo, and AOL, have this information for all their users,
they are not for public consumption. Drawn by the com-
mercial potential of these latent networks, a number of
companies [6] have started providing services where par-
ticipants can upload their address books, allowing the
corporation to create a central server where the social
email network is stored and updated; the goal is to pro-
vide services to the participating clients by mining the

network. These networks, however, are also proprietary,
because of both privacy and commercial secrecy reasons.
Fortunately for us (i) the system that we have designed
do not make use of the knowledge of the complete net-
work; to carry out the protocols described here, the cy-
beralter egos have only to exchange messages with those
on their own contact lists and do not have to know about
its cyber-neighbor lists, and (ii) A few examples of social
email networks have been thoroughly studied in the liter-
ature, allowing us to observe that they share many of the
same complex features as real world social networks. In
particular, we will use the network analyzed by Ebel et.
al.
in a recent work[11], which shows that the network
has a scale-free structure, short diameter, and a giant
connected component (gcc) that contains more than 95%
of the nodes.

Since our cyberalter egos are becoming more en-
trenched as a signiﬁcant part of our overall social and
commercial selves, can one start managing and utilizing
their network the same way that we manage our real-life
social networks? Any such eﬀort should abide by rules,
such as the need to protect the privacy of the users and
also the need to allow participants to dynamically decide
whether they want to participate or not. The primary
contribution of this paper is to provide a decentralized,
eﬃcient, and scalable system for querying and sharing
information on the global social networks. One major
application of this overlay information management sys-
tem is to ﬁlter spam, as reviewed in the following.

B.

Spam and Content-based Spam Filtering

Spam, or Unsolicited Bulk Email, is plaguing internet
users around the world. It has been estimated that ap-
proximately 68% of the worldwide email traﬃc today is
spam and up to 87% of the emails directed to US users
is spam[3].

For the past few years, numerous spam ﬁlters have
been proposed and deployed, and of all the existing
anti-spam solutions, two classes of spam ﬁlters have
emerged as the most eﬀective and widely-deployed:
Bayesian/rule-based spam ﬁlters and collaborative spam
ﬁlters. A Bayesian ﬁlter uses the entire context of an
e-mail in looking for words or phrases that will iden-
tify the e-mail as spam based on the experiences gained
from the user’s sets of legitimate emails and spams[12].
One example of a widely deployed Bayesian spam ﬁlter
is SpamAssassin[4]. Although the Bayesian anti-spam
solutions oﬀer very impressive performances, they suﬀer
from several serious drawbacks: ﬁrst, Bayesian ﬁlters re-
quire an initial training period and exhibit a downgrade
in performance for responding to messages composed of
previously unknown words; second, Bayesian ﬁlters are
unable to block messages that do not look like a typi-
cal spam such as messages that is consist of only a URL
or messages that are padded with random words. Most
recently a number of multifaceted approaches have been

2

proposed[7, 17]. They consider combining various forms
of ﬁltering with infrastructure changes, ﬁnancial changes,
legal recourse, and more, to address shortcomings of reg-
ular statistical ﬁlters.

C. Collaborative Spam Filtering: Prior Work and
Challenges

The increasing realization that the dynamic of spam
fostered
constitutes a complex phenomenon brewed,
and propagated in the interconnected realm of the cy-
berspace, has prompted the use of collaborative spam
ﬁlters, where the basic idea is to use the collective mem-
ory of, and feedback from, the users to reliably iden-
tify spams. That is, for every new spam that is sent
out, some user must be the ﬁrst one to identify it upon
receiving this spam (e.g., by using a Bayesian ﬁlter or
locally generated white and black lists); now, any sub-
sequent user that receives an email that is a suspect,
can query the community of email users to ﬁnd out if
it has been already tagged as spam or not.
In con-
trast to Bayesian type ﬁlters, collaborative spam ﬁlters
do not suﬀer from the drawbacks just mentioned above,
and it has been shown that they are also capable of su-
perior spam detection performance[22]. The existing
collaborative ﬁltering schemes mostly ignore the
already present and pervasive social communities
in the cyberspace and try to create new communi-
ties of their own to facilitate the sharing of information.
This unenviable task of creating new social communities
is beset with several diﬃculties that have limited the de-
ployment and eﬀective use of most collaborative ﬁltering
schemes proposed so far. The challenges include:
(i) How to ﬁnd users to participate?:
In order for a
collaborative spam ﬁlter to be highly eﬀective, a large
number of users (on the order of hundreds of thousands
or millions) must be participating in using the system.
However, eﬀectively ﬁnding and interconnecting a large
number of willing participants is non-trivial.
In other
words making any artiﬁcially established community ac-
ceptable and popular is an unpredictable and diﬃcult
task at best, and impossible at worst.
(ii) How to make the search scalable? : The power of a
collaborative spam ﬁlter lies in the fact that spam data
resources from a large number of users are pooled to-
gether and utilized to ﬁght spam. In order to avoid high
server cost, the spam databases are typically stored lo-
cally on users’ computer. Finding a way to do eﬃcient
searches on a network of distributed databases is very
challenging.
(iii) Who to trust : Inevitably, there would be malicious
users who try to subvert the collaborative anti-spam
system by providing false information regarding spam.
Therefore, a trust scheme must be devised to place more
weights on the opinions of some provably trustworthy
users than on some unknown users who can be poten-
tially malicious.

The diﬀerent proposed schemes for collaborative ﬁlter-
ing attempt to address the above challenges to diﬀerent
degrees of eﬀectiveness. For example, SpamNet[5] em-
ploys the following mechanisms to address the challenges
stated above: It uses a central server model to connect
all the willing participants of this collaborative spam ﬁl-
ter. The central server solution is not scalable as the
system scales and the server becomes a single point of
attack or failure. In addition, SpamNet employs a com-
plicated algorithm to compute the trust score for each
of its user. SpamWatch[20] is a totally distributed spam
ﬁlter based on the Distributed Hash Table (DHT) sys-
tem Tapestry[19]. SpamWatch addresses the three chal-
lenges of a collaborative spam ﬁlter in the following ways:
First, SpamWatch uses a DHT-based P2P system to con-
nect all the participants. The primary drawback in using
a DHT for collaborative spam ﬁltering purpose is that
DHT’s do not provide a natural platform to network
existing databases, such as every email user’s personal
database of spams. Merging and mining existing sets
of databases is very diﬃcult if not impossible. Second,
SpamWatch uses a hash-based mechanism called Approx-
imate Text Addressing (ATA) to perform general query
searches for spams. However, as seen in the description
of the ATA algorithm, supporting general query search
in a DHT is very complex and involves expensive oper-
ations. DHT’s typically excel at exact-match lookups
but does not perform well for application that needs to
support general search queries such as in a collaborative
spam ﬁlter. Lastly, SpamWatch does not oﬀer any mech-
anism to address the trust issue. Most recently Gray et.
al. have proposed CASSANDRA, a collaborative spam
ﬁlter where the network is formed as clusters of trusted
and similar peers. Finally a new reputation analysis have
been proposed by Golbeck et. al. [13] where reputation
relationships are inferred from the structure and are used
as a method to score emails.

D. Harnessing The Global Social Email Network

Recently, Boykin and Roychowdhury investigated the
notion of utilizing social network to do spam ﬁltering[8].
In their work, it was shown that just by looking at the
clustering coeﬃcient of an email user’s personal contact
networks, their algorithm is able to achieve a spam de-
tection rate of 53% with zero false positives. Although
this algorithm is very attractive, it ignores the larger so-
cial email network and focuses only on a projection of
it, as witnessed by an individual user, and it begs the
questions whether the larger social email networks can
be harnessed.

In this paper, we show that a high-performance, scal-
able and secure information management and query sys-
tem can be overlaid on the social email networks, and
provide a case study for collaborative spam ﬁltering. The
basic idea is the same as that of other proposed collab-
orative spam ﬁlters; however, instead of using special-

3

ized network, we use the latent social email network over
which the queries and messages are exchanged. We show
how the three challenges outlined in the preceding discus-
sions can be eﬀectively addressed using the topological
properties of the underlying social email networks and
recent advances in complex networks theory. First, no
especially designed network has to be created for collab-
orative ﬁltering. In fact, one of the main features of this
system is that all queries and communications are ex-
changed via email through personal contacts, and that
no server or a traditional P2P system with TCP/IP con-
nections is needed. Second, we observe that social email
networks correspond to Power-Law (PL) graphs[23] [11],
with a PL coeﬃcient around 2. Hence, the underlying
network naturally possesses a scale-free structure that is
a key hall-mark of many unstructured P2P systems that
have organically grown for ﬁle-sharing on the Internet.
One can then utilize a scalable global search system,
namely the percolation search algorithm, recently pro-
posed by Sarshar et. al. [18], on this naturally scale-free
graph of social contacts to enable peers to exchange their
spam signature data. Third, one can harvest and utilize
the trust that is embedded in the web of email contacts.
By regarding contact links as local measures of trust and
using a distributed Singular-Value-Decomposition (SVD)
algorithm, we can obtain a trust score called mailtrust.
In fact, the famous Google PageRank[9] is computed in
a similar fashion. Finally, the proposed system can be
implemented right now as plugin to popular email pro-
grams, such as the MS Outlook.

We show via extensive simulations that the system is
also capable of delivering high performances while incur-
ring minimal costs. Under the assumption that there
would be a large number of users (on the order of hun-
dreds of thousands or millions), the system can oﬀer a
spam detection rate around 99%; in fact, the detection
rate can reach close to 100% when the number of users
approach the internet scale. At the same time, the num-
ber of false positives in our system can be tightly con-
trolled to a level very close to zero. Meanwhile, as the
number of users of the system scales, the communication
cost of the system would be kept at a sublinear scale and
the memory storage cost would grow only at a logarithmic
scale. In addition, due to the fact that no TCP/IP con-
nection is required and all communications in the system
is done via background email exchanges, less computa-
tional and networking burden would be placed on local
computers. Lastly, the system is designed to be secure
and rigorously protective of users’ privacy and conﬁden-
tiality.

The rest of the paper is organized as follows. In sec-
tion II, we present the background theory and the impor-
tant concepts vital to this paper, such as email network
theory and the percolation search algorithm. In section
III, we describe the protocol of our social network based
collaborative anti-spam system in detail. In section IV,
we use a real world email network to perform large-scale
simulations of the system. In section V, we construct a

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

n
o

i
t
c
a
r
F

e
t
a
R

 
t
i

H

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0
0

threat model and show by simulation that a social net-
work based trust scheme is eﬀective in minimizing dam-
ages caused by malicious users. Finally, in section VI, we
address several important topics such as the protection of
privacy and the system’s resilience against random user
failure.

II. BACKGROUND CONCEPTS

Our system is motivated by a number of recent ad-
vances in complex networks theory and systems, Eigen-
methods based computation of trust and relevance, and
the proven eﬃcacy of the spam digest system as signa-
tures of emails. We brieﬂy review this background ma-
terial in this section.

A. Topology of Social Email Networks

A particular email network comprising 56,969 nodes
(i.e., email addresses) has been studied by Ebel et. al.[11]
Based on the statistics reported in Ebel’s work, we iden-
tify three desirable properties that would make social
email networks an attractive platform for building a col-
laborative spam ﬁlter:
(i) An email network has been found to possess a scale-
free topology. More precisely, for the email network ex-
amined in [11], the node degree distribution follows a
power law (PL): P (k) ∝ k−1.81, where k is the node de-
gree, and P (k) denotes the probability that a randomly
chosen node has degree equal to k. One of the conse-
quences of this property is that of very low percolation
threhold[18]; in other words, the network is extremely re-
silient to random deletions of nodes. One can also show
that even if high-degree nodes are deleted preferentially,
one has to remove almost all the high-degree nodes, be-
fore the network gets fragmented.
(ii) A large fraction of the nodes (˜95.2%) in a social email
network is connected to the giant connected component
(GCC). This means that any node can reach almost any
other arbitrary node by simply following email links.
(iii) The email network has a low diameter (i.e. there ex-
ist short paths between almost any pair of two nodes in
the network). In fact, for the email network investigated
by Ebel et. al.[11], the mean shortest path length in the
giant connected component was found to be l = 4.95 for
a component size of 56, 969 nodes. This short-diameter
property allows any email user to eﬃciently communicate
with any other email user in the network by crossing only
a few email contact links.

The above properties of the social email network
should not come as a surprise, since it reﬂects the same
social dynamics that we practice in our everyday life.

0
0 0.010.020.030.040.050.060.070.080.09 0.1 0.110.120.130.140.15
Percolation Probability

4

Hit Rate
Fraction of Links
Fraction of Nodes

1 Trial
3 Trials
5 Trials

(a)

(b)

0.01

0.02

0.03

0.04
Fraction of Links Traversed

0.05

0.06

0.07

0.08

FIG. 1: Percolation Search On Social Email Networks:
(a)The hit rate, fraction of links and fraction of nodes tra-
versed as a function of the percolation probability. Notice
that there is a sudden jump in the hit rate above the percola-
tion threshold, while the fraction of links and nodes processing
the search query increases only linearly, after the threshold.
The network used in this percolation search simulation is a
real-world email contact network. The number of nodes is
56,969, τ ≈ 1.81, the TTL is 50 for both query and content
implants and only one unique content exists in the network.
(b) Hit rate for percolation search on email contact network
with TTL of 50. Repeating the percolation trial multiple times
pushes the hit rate exponentially closed to 1.

B. Percolation Search and Scalability

We can utilize the percolation search algorithm pro-
posed by Sarshar et. al.[18] that exploits the presence of
a tightly connected core comprising mostly high-degree
nodes. In particular, it is shown in [18] that unstructured

searches in PL networks can be made highly scalable using
the percolation search algorithm. The algorithm involves
message passing on direct links only, and in some sense it
resembles how rumors propagate in social networks. The
key steps of the algorithm are as follows:
(i) Caching or Content Implantation: Each node per-
forms a short random walk in the network and caches its
content list on each of the visited nodes. The length of
this short random walk is speciﬁed later and is referred
to as the Time To Live (TTL).
(ii) Query Implantation: When a node intends to make
a query, it ﬁrst executes a short random walk of the same
length as step 1 and implants its query requests on the
nodes visited. The length of this random walk is usually
taken to be the same as the TTL used in the content
implantation process.
(iii) Bond Percolation: All the implanted query requests
are propagated through the network in a probabilistic
manner; upon receiving the query, a node would relay
to each of its neighboring nodes with percolation proba-
bility p, which is a constant multiple of the percolation
threshold, pc, of the underlying network.

It is shown in [18] that the percolation threshold of
any random network is given as pc = hki/hk2i. For a PL
network with exponent τ and maximum degree kmax, we
have hk2i = O(k3−τ
max) and hki = O(k2−τ
max), and hence, we
get a percolation threshold of pc = O(k−1
max), which is
vanishingly small if kmax increases with the size of the
network, which is usually the case. Thus, if we perco-
late at a multiple γ of pc, then the total traﬃc generated
would be, Cτ = γpchkiN = O( hki
max N (cid:1). In
real world networks, kmax typically scales sublinearly as
a function of the network size. For kmax = O(N 1/τ ), we
1
have: Cτ = O (cid:0)k−τ +1
τ ). For a detailed anal-
ysis of the hit rate and how it behaves as one performs
multiple searches see [18].

hk2i ) = O (cid:0)k−τ +1

max N (cid:1) = O(N

N

2

Since the social email networks have a PL degree dis-
tribution, it is ideally suited for reaping the beneﬁts of
a percolation search, and the simulation plots obtained
from performing percolation search on the real email
dataset [1, 11] are provided in Fig. 1.

C. The MailTrust Algorithm

Just as in the case of WWW, where the PageRank cap-
tures the relevance of a particular web page, the topolog-
ical structure of the social email networks can be used to
assign trust or reputation to individual users. First, we
model each email contact as placing a unit of trust on
the recipient. Thus, for a node that contacts kout other
nodes, we can compute the fraction of trust that this
node places on each of his out-neighbors as followed: the
trust for neighbor i, ti, is equal to the number of emails
sent to neighbor i divided by the total number of emails
sent. Note that the collection of ti’s forms a probability
−→
vector, called the personal trust vector
t . Thus, if we
model the entire email network as a discrete time Markov

5

−→
chain, the local trust vector,
t , becomes the transition
probability function for each node. We then compute
the steady state probability vector using Power Iteration
method which is the the same algorithm adopted to com-
pute pagerank score of documents on web [9, 14]. As dis-
cussed in the literature, one needs to make sure that this
Markov chain is ergodic and this can be achieved by hav-
ing nodes with zero out-degree assign uniform trust to a
set of pre-trusted nodes who have been carefully picked.
An alternate way to compute the MailTrust score in a
distributed fashion can be found in [14], along with a
scheme on how the trust scores can be kept securely in
the system even with the presence of malicious users.

9 emails (1.0)

8 emails (0.8)

Trust = .351

B

D

Trust = .263

5 emails (0.25)

7 emails (1.0)

Trust = .298
A

5 emails (0.25)

2 emails (0.2)

10 emails (0.5)

C
Trust = .088

FIG. 2: MailTrust: A simple illustration of the MailTrust
algorithm. The numbers in parentheses represent the local
trust values that each node places on his/her neighbors. The
MailTrust scores for each node is then obtained by computing
steady state probability vector of the Markov chain.

We will refer to this trust score as MailTrust in the rest
of this paper. A plot of the MailTrust scores obtained
from [1, 11] is shown in Fig. 3.

D. Digest-based Spam Indexing

In a collaborative spam ﬁltering system, it is important
to have an eﬀective mechanism to index known spams so
that subsequent arrivals of the same spam can be cor-
rectly identiﬁed. The collaborative design of the system
does not depend on any speciﬁc algorithm, but for ini-
tial experimental results we have adopted the well known
digest-based indexing mechanism [10] to share spam in-
formation between users. Damiani et. al. have rigorously
demonstrated that the digest algorithm described in [10]
is highly resilient against the possible forms of automatic
modiﬁcations of spam emails. The digest algorithm is
further shown to satisfy both the privacy preserving and
that it produces almost close to zero false positives (i.e.,
the digest of one email matches the digest of an unrelated
email).

0
10

−1

10

−2

10

−3

10

−4

10

)

%

(
 
y
c
n
e
u
q
e
r
F

−5

10

−6

10

−5

10

−4

10
MailTrust Scores

10

−3

−2

10

−1

10

FIG. 3: MailTrust Distribution: The probability density
function of MailTrust scores using 104 bins. These scores are
obtained by applying the MailTrust algorithm on the email
network data set from [11]. Notice that this probability den-
sity function is heavy-tailed, indicating that a few nodes are
much more trustworthy than most nodes.

III.

IMPLEMENTATION AND SYSTEM

PROTOCOL

In order to use our proposed collaborative spam ﬁlter-
ing system, an interested individual must ﬁrst obtain a
simple client program that works as a plug-in to an email
program such as MS Outlook, Eudora, Sendmail, etc[24].
This simple client will only need to provide the follow-
ing features: ﬁrst, the client must come with a digest-
generating function as speciﬁed in section II D; second,
the client is responsible for keeping a personal blacklist
of spams for the end-user as well as caching blacklists of
spams for other nodes as described in the section on the
percolation search algorithm, (see section II B); third, the
client would have access to the list of social email con-
tacts (both inbound and outbound) of the end-user. The
pseudo code of the distributed client is given in Algo-
rithm 1.

the

end-user,

Message Arrivals and Digest Indexing: When
an email message arrives at
the
method checks whether it is deﬁnitely spam or not
spam(DeﬁnitelySpam/DeﬁnitelyNotSpam). Any tradi-
tional spam ﬁltering method like white-list, blacklist,
Bayesian ﬁlter, etc. can be integrated to create a hybrid
multi tier architecture. DeﬁnitelyNotSpam for example
can be a white list of addresses in the contact list and
DeﬁnitelySpam can be output of a Bayesian ﬁlter when
the ﬁlter indicates email as spam with very high prob-
ability.
If an email is then suspected to be spam, the
client program would call the digest function to generate
a digest, De, for the message.

Making a Query in the System: Now, we would
query the system to ﬁnd out whether any other user in
the network already has the digest, De, on its spam list.

6

Algorithm 1 PROCESS-MAIL(Email E)

1: if DeﬁnitelySpam(E) then
2: Mark E as Spam
3: else if DeﬁnitelyNotSpam(E) then
4: Mark E as not Spam
5: else
6: De = Digest(E);{Gray SPAM};
7:

Implant percolation of De on a random walk of length
l

if He < threshold then
Mark E as not Spam

8: Wait(T);
9: He = HitScore();
10:
11:
12:
13:
14:
15: end if

end if

else

Mark E as spam

Algorithm 2 Publish-Spam(Email E)

1: De = Digest(E);
2: Implant De on a random walk of length l

Each query message for this digest is then implanted on
a random walk of length l. Nodes with an implanted
query request will then percolate the query message con-
taining the digest, De, through their email contact net-
work using a probabilistic broadcast scheme as speciﬁed
in the bond percolation step of the percolation search al-
gorithm. Each node visited by the query would declare a
hit if the digest, De, matches with any of the digest that
is cached on that node[25]. All the hits would be routed
back to the node that originated the query through the
same path that the query message arrives at the hit node.
If the nodes have trust scores, then returned hits include
the their trust score as well.

Processing the Hits and Making the Decision:
After all the hits are routed back, HitScore is then cal-
culated as (or as the weighted sum if using trust scheme;
see Section II C) sum of all the positive hits. If it exceeds
a constant threshold value, the message in question is
declared as spam; otherwise, the email message is deter-
mined to be non-spam.

Publishing Digest: If an email is declared as spam,
and placed in the user’s ”spam” folder then the Publish-
Spam function would be called that generates the digest
of the spam message, De and caches the digest on a short
random walk, as speciﬁed in the caching or content im-
plantation step of the percolation search algorithm.

System Maintenance: If the EigenTrust algorithm

Algorithm 3 HitScore(Hits)

HitScore = Σh∈Hitsmailtrust(h)

1: if Using MailTrust then
2:
3: else
4:
5: end if
6: Return HitScore;

HitScore = |Hits|

7

FIG. 4: An illustration of the protocol of the system.

from section II C is implemented, we would need to up-
date the trust scores of the nodes on a periodic basis.
Since most people’s amount of email contacts change
not faster than a daily basis, The distributed EigenTrust
computation should be performed at most once a day to
obtain up to date trust scores for all nodes. Connectiv-
ity of the network is maintained by simple background
message declaring join/leave sent to each of the user’s
contacts.

IV. SIMULATION AND SYSTEM
PERFORMANCE

Network Model: In this section, all simulations are
performed on a real-world email network investigated in
Ebel et.al.’s work[11]. (The email network data can be
obtained via this url [1].) In the following simulations,
only the giant connected component is used, which con-
tains 95.2% of all nodes in the original dataset. Please
see table I for the speciﬁc values of this email network’s
parameters.

Spam Arrival Model: We model the spam detection
performance of a collaborative spam ﬁlter as a function
of the number of copies of the similar spam messages
that arrive to the system. In the extreme case that every
spam arrived to the system is unique, one can easily see
that a collaborative ﬁlter would be totally futile, since no
user can beneﬁt from the prior identiﬁcations of others.

Assuming that similar spam messages are sent to ap-
proximately 5 million internet users on average[26] and
estimating internet users to be 600 million worldwide[2];
thus, assuming that spammers select spam targets uni-
formly randomly from the set of all internet users, the
probability that any individual would receive a copy of a
given spam is approximately 0.8%. Since there are 56,969
nodes/users in our email network, the approximate num-
ber of identical spams arrived to this network is about
500. We further assume that each spam message arrives
at nodes of the network uniformly randomly.[27]

Speciﬁcation of Percolation Probabilities: Re-
call that in the percolation search algorithm, each edge
gets a message with probability p which is chosen to be
a constant multiple of the percolation threshold of the
network. In general, the percolation threshold might not
be known, and so one needs to come up with a scheme
to adaptively perform the search using an increasing se-
quence of percolation probabilities. In order to ensure a
high hit rate for queries and a low communication cost for
the system, we propose the following scheme to perform
query searches: we start the ﬁrst query with very low
percolation probability; if not enough hits are returned,
we send out a second query with a percolation probabil-
ity that is twice of the ﬁrst one; if still not enough hits
are routed back, we repeat the searches by increasing the
percolation probability in this two-fold fashion until the
probability value reaches a maximum value, pmax; once
this maximum is reached, we repeat the query with the

8

)

%

(
 
e
t
a
R
 
n
o
i
t
c
e
t
e
D
m
a
p
S

 

100

99

98

97

96

95

94

93

92

91

90

0

)

%

(
 

d
e
s
s
o
r
C
 
s
k
n
L

i

 
f

o

 

t

e
g
a
n
e
c
r
e
P

0.1

0.05

maximum percolation probability for a constant number
of trials and stop. The query search is terminated as
soon as the total number of distinct hits routed back
reaches the threshold after any given trial. If no hits are
returned after nrep attempts at the maximum probability
pmax, then the search is terminated and the queried item
is considered as absent.

For the simulation experiment in this section, we set
the starting percolation probability to be .00625 and
pmax to be .05, and nrep = 3. All other relevant param-
eters of the experiment are speciﬁed in Table I. In addi-
tion, we assume in this simulation experiment that upon
the receipt of a new spam message, all nodes immediately
cache this new content on a random walk as speciﬁed in
the percolation search algorithm. This is done regardless
of the fact that the spam has been automatically ﬁltered
by the system or it leaked through the ﬁlter and must be
identiﬁed by human inspection or by some other means.
Simulation Execution: The simulation is repeated for
30 runs. In each run, 500 copies of the same spam arrive
sequentially at diﬀerent nodes in the network. The nodes
are selected uniformly randomly for each spam message
arrival. The ﬁrst node receiving it performs a search, but
of course gets 0 hits; similarly, the second node will also
get at most one hit and it will be below the threshold
of 2 to be identiﬁed as a spam. For the ﬁrst two nodes,
after the searches return no hits, the messages are manu-
ally tagged as spams. Since these two initial searches will
be considered as misses, the maximum detection rate is
498/500 = 99.6%, where the detection rate is simply the
number of successful spam detections divided by the to-
tal number of spam arrivals. We record the the detection
rate for each run, compute the overall average and stan-
dard deviation, and plot the results in error-bar plots.
In addition to the detection rate, we also record the per-
centage of edges crossed per query, which is the primary
metric for network traﬃc cost. We repeat the simulation
by varying one parameter: nreps, which is the number of
query trials repeated with percolation probability set at
pmax before declaring failure.

Simulation Results Analysis: Fig. 5 plots the sim-
ulated spam detection rate (in percentage) as a function
of nreps, averaged over 30 runs. Note that for nreps ≥ 3,
the spam detection rate is extremely close to the maxi-
mum detection rate of 99.6% for this experiment

Fig. 6, plots the percentage of edges crossed for per
query as a function of nreps, averaged over 30 runs. (A
query is deﬁned as a series of percolation search trials as
deﬁned in the subsection above.) Note that the network
traﬃc cost is extremely low: on average, only approx-
imately 0.1% of the 84,190 email links in the network
needs to be crossed in order to get enough query hits to
identify a suspected message as spam. Combining results
from Fig. 5 and Fig. 6, one can argue that nreps = 3 is a
good operation point, since it gives near optimal spam de-
tection performance while incurring minimal traﬃc cost.
Fig. 7 shows the network traﬃc as the average number

of messages processed by nodes with degree k.

1

2

3

4

5

6

Number of search trials at p=.05=p

 before declaring failure

max

FIG. 5: Spam Detection Performance: This ﬁgure plots
the simulated spam detection rate (in percentage) as a func-
tion of the number of query trials repeated with percolation
probability set at pmax before declaring failure. Note that all
the average detection rates are well above 99%. The results
are averaged over 30 runs and the error bar plots one standard
deviation above and below the mean.

0
0

1

2

3

4

5

6

Number of search trials at p=.05=p

 before declaring failure

max

FIG. 6: Overall Traﬃc Per Query: This ﬁgure plots the
percentage of edges crossed per query as a function of nreps,
average over 30 runs. Note that traﬃc cost is extremely low
(only around 0.1% of network links need to be crossed per
query). The error bar plots one standard deviation plus and
minus the mean.

Fig. 8 shows the average number of participating nodes
in a query as function of node degree. As expected that
high-degree nodes are more likely to be visited for any
given query since they are connected to a large number
of nodes.

Bandwidth Cost Estimates: Fig. 6 shows that the
required traﬃc for each query is about 0.1% of edges,
which corresponds to about 84 emails. Moreover, ev-
ery short email containing the digest of a message is
about 1 KByte in size, and every email incurs band-

9

Network

# of nodes
# of edges
Node degree distribution
PL exponent
mean node degree < k >
node degree 2nd moment < k2 >
approximate percolation threshold (qc) ≈ <k>
time-to-live (ttl)

<k2> .0169

56,969
84,190
Power-Law (PL)
≈ 1.8
2.96
174.937

Simulation Param. # of arrivals of the same spam

threshold (# of hits needed to identify spam)
percolation probability trials
# of runs
# of time steps
# of malicious nodes inserted per time step
total # of mailing lists
Zipf coeﬃcient
# of non-spams queried per time step (x)
m, number of items on a blacklist
% of user’s non-spam to be queried

TABLE I: Simulation Settings

50
500
2
[.00625 .0125 .025 .05 .05 . . .]
30
25
10
50,000
0.8
1,000
10
5%

Threat Model

Data
Linear Fit

Data
Linear Fit

k
 
e
e
r
g
e
D
 
h
t
i

w
 
e
d
o
N

 
r
e
P
 
y
r
e
u
Q

 
r
e
P
 
d
e
s
s
e
c
o
r
P
 
s
e
g
a
s
s
e
M

 
f
o
 
r
e
b
m
u
N

2.5

1.5

3

2

1

0.5

0

0

0.25

0.2

0.15

0.1

0.05

 
y
r
e
u
Q

 
r
e
P
d
e

 

i

t
i
s
V
 
k
 

e
e
r
g
e
D
h

 

t
i

w
 
s
e
d
o
N

 
f

o

 

n
o

i
t
c
a
r
F

0
0

100

200

300

600

700

800

900

400

500

Node Degree, k

100

200

300

400

500

600

700

800

900

Node Degree, k

FIG. 7: Traﬃc vs. Degree: The data points show the av-
erage number of messages processed per percolation query for
a node with degree k (i.e. it is the total number of messages
processed per query for all nodes in the network with degree
k divided by the number of nodes with degree k.) This plot
is obtained by using an nreps value of 3 for every percola-
tion query. The slope of the linear ﬁt is 0.0019 query/degree.
since each node forwards a query to a link with a ﬁxed perco-
lation probability, we naturally expect that high-degree nodes
handle more messages.

width cost on both the sender and receiver. Thus,
the bandwidth cost per query is approximately (84+50)
email exchanges (where the number 50 corresponds to the
random-walk query implantation with TTL=50), which
at 1 KByte/email results in a total of 268 KByte per
query. This total traﬃc per query is distributed among
all the nodes, and in particular more among the high-
degree nodes, as shown in Fig. 7.

Let us consider the worst case scenario ﬁrst.

In the

FIG. 8: The data points show the fraction of nodes with
degree k visited per percolation query (i.e.
it is the number
of nodes with degree k visited per query divided by the total
number of nodes in the network with degree k.) This plot is
obtained by using an nreps value of 3 for every percolation
query. The slope of the linear ﬁt is 1.573x10−4

/degree.

network used for this simulation, a very high-degree node
typically processes around 1.5 messages per query in the
network, as seen from Fig. 7; only one set of nodes uses
more than this value. Assuming that every user gets
1 spam per hour, we conclude that a very high-degree
node would need to process about 85,500 messages per
hour since there are around 57,000 nodes in the network.
Since the query message size is 1 KByte, the bandwidth
cost on high degree nodes would be around 85 MByte per
hour[28], which is equivalent to around 0.18 Mb/second.
For a typical fast internet connection of 100 Mb/second,
this represents about .2% of bandwidth cost.

For nodes with lower degree, the cost is substantially
lower. For example, even a node with degree 100 would
process on the average 0.19 messages per query, and
hence, using the same estimate of 1 spam per node
per hour, the bandwidth costs would be only around
23K/second.

V. THREAT MODEL AND EFFECTIVENESS
OF TRUST SCHEME

In this section, we will construct a model of malicious
users in the network trying their best to subvert the sys-
tem. Through a large-scale simulation, we will demon-
strate that implementing the EigenTrust algorithm pre-
sented in section II C can eﬀectively reduce the damage
inﬂicted by the malicious users.

With the system introduced so far, a malicious node
can subvert the system by introducing blacklists of well-
known valid messages into the network.[29] As a result,
messages from mailing lists become easy targets of an
attacker. Note that this form of attack will only raise
the false positive rate of the system and it has no impact
on the spam detection rate. Every malicious node will
pick a ﬁxed set of mailing lists and periodically update
the blacklist with new messages from the mailing lists.
In addition, it is assumed that the popularity of mailing
lists follows a Zipf distribution and the probability that
a mailing list is being queried follows the same Zipf law.
We further assume that the spammer wants to inﬂict
maximum damage and thus will select a given mailing
list to blacklist following the same Zipf distribution for
popularity since users of the system are more likely to be
subscribed to popular mailing lists.

A. Simulation Setup and Trust Scheme

The simulation setup and parameters in this section
will be identical to the simulation performed in section
IV, except for the following: ﬁrst, a small fraction of
nodes in the network (250 nodes) will be labelled as ma-
licious nodes and these malicious nodes will blacklist non-
spams from popular mailing lists; second, for simulation
purpose, we assume that the probability that a node in
the email network is malicious is inversely proportional
to its in-degree, since low in-degree nodes are trusted by a
few peer email users and thus more likely to be malicious;
third, the malicious nodes will follow all speciﬁcations of
the protocol such as forwarding and routing queries, stor-
ing the cache implants for other nodes, etc.[30]; fourth,
we relax the uniform spam arrival assumption in section
IV. In this simulation, the probability that a node re-
ceives a spam is directly proportional to its in-degree.
The justiﬁcation for this assumption is that a high in-
degree node signiﬁes very active and long-time usage of
the email account and thus more likely to receive spams.
All relevant parameters are speciﬁed in Table I.

10

We then perform a Monte Carlo simulation on email
network as follows: at every time step, ten malicious
nodes would insert their malicious content, which consist
of blacklists of non-spams; also, 500 copies of the same
spam message arrive as in section IV; In addition to the
spam arrivals, a constant number of non-spams would
arrive and queried by users; based on the hits that are
routed back, nodes would classify the messages queried
to be spam or non-spam.

We will use two methods for spam classiﬁcation: the
non-trust scheme and the MailTrust scheme (for spec-
iﬁcation of the MailTrust algorithm, see section II C).
Under the non-trust scheme, a suspected message is clas-
siﬁed as spam if the number of distinct hits routed back
is greater than or equal to a threshold (the threshold is
set at 2 to give comparable performance as in section IV).
For the MailTrust scheme, the queried message is iden-
tiﬁed to be spam if the sum of the MailTrust scores of
the distinct hits routed back is above a threshold. This
threshold is set to generate comparable spam detection
rate as the non-trust scheme. The results are plotted in
Fig. 9 for spam detection rate and false positive rate as
a function of the number of malicious nodes inserted. As
shown in the plot, the malicious nodes have no impact
on the spam detection rate, since their blacklists of non-
spams do not aﬀect the ability of other normal users to
blacklist and identify spams. From the spam detection
rate plot, one can see that both schemes generate compa-
rable spam detection rates. However, by examining the
false positive rate plot, one can immediately see that the
MailTrust scheme results in about 50% improvement in
lowering the false positive rate.

The reason for this improvement is mainly due to the
fact that high in-degree nodes tend to have high trust
scores and receive more spams. Thus, for the MailTrust
scheme, we can set the threshold value a little high and
still have a very good spam detection rate, because a
large fraction of query hits for spams will be provided
by the high in-degree nodes who have high trust scores.
In addition, most malicious nodes have low trust scores
since they tend to have low in-degrees (this assumption
is made in the subsection above).

VI. MISCELLANEOUS

A. Protection of Privacy

Since our proposed anti-spam system is social network
based, it is very important to protect users’ privacy by
preventing anybody from using the network to map out
social links. Furthermore, if a malicious individual is
able to map out the social email network, a database
of social contacts can be constructed to send out more
spams from spoofed personal contacts. To address this
problem, all messages exchanged in the system must be
forwarded anonymously. The basic idea is that when a
node forwards a message, any information pertaining to

100

)

%

(
 
e
t
a
R
 
n
o
i
t
c
e
t
e
D
m
a
p
S

 

)

%

(
 
e
t
a
R
 
s
s
e
n
e
v
i
t
c
e
f
f

E
 
k
c
a
t
t

A

90

80

70

60

50
0

15

10

5

0
0

non−trust scheme
MailTrust scheme

50

100

150

200

250

Number of Malicious Nodes

non−trust scheme
MailTrust scheme

50

100

150

200

250

Number of Malicious Nodes

FIG. 9: MailTrust Performance: The top and bottom ﬁg-
ures plot the spam detection rate and the attack eﬀectiveness
rate as a function of the number of malicious nodes that have
joined the system. While both schemes yield approximately
the same detection rate, the MailTrust scheme results in a
signiﬁcantly lower attack eﬀectiveness rate. Note that we are
assuming it is easy for malicious nodes to know of messages
(e.g., sent to mailing lists) that a large number of nodes will
receive. Clearly, incorporating a white-list based scheme for
processing messages from mailing lists at the level of a cy-
beralter ego, would be the best way of handling such attacks.

which nodes that the message has visited must be deleted
before forwarding. This keeps all system communications
to an acquaintance-acquaintance level, Fig. 10.

From: B
To: C(cid:10)
Query

From: B
To: D(cid:10)
Query

B

D

C

HIT!!

From: C
To: B
Hit

From: B
To: A(cid:10)
Hit

From: A
To: B(cid:10)
Query

A

Initiates Query

FIG. 10: Protecting Privacy: A simple diagram illustrating
the secure version of message forwarding in the system. For
example, note that both node C and node D do not know
that the query comes from node A; similarly, node A does
not know that the hit comes from node C.

11

B. System Resilience against User Unreliability

The users of the system are dynamic. Namely, users
will logon and logoﬀ as they wish. Since our system heav-
ily relies on the underlying social email network, the nat-
ural question will be: how many users in the system can
be oﬄine before the network is severely segmented into
many small components?

Alternately, we can re-phrase the above problem as fol-
lowed: how many nodes in a network can randomly fail
before the network becomes fragmented? It turns out
that this problem has been extensively studied analyti-
cally and numerically [15, 16]. Using site percolation the-
ory, Cohen et.al. [16] shows that scale-free PL networks
are extremely robust to random failures: for a PL net-
work with PL exponent less than 3, the critical fraction
of nodes, pc, that needs to be removed for the network
to fragment goes to 1 as the network size approaches in-
ﬁnity. Furthermore, for a ﬁnite-size network with a large
number of nodes on the order of tens of thousands, the
critical fraction pc is well over 0.99. Since the social email
network is a PL network with exponent close to 2, these
results from site percolation theory is directly applicable.
Therefore, the network will not be fragmented even if
a massive number of system users suddenly leave. Alter-
nately, one only needs a very small fraction of the users
to be using the system before they can start successfully
exchanging information.

C. Simple Measures for Performance Improvement

Spam Traps. When our proposed system is deployed
in the real world, the initial number of users will be small.
In fact, all collaborative spam ﬁlters must overcome this
”initial hurdle” in order to become widely-used.

Our proposed solution to this ”initial hurdle” problem
is to install spam traps. By deﬁnition, a spam trap is an
email account created for the sole purpose of attracting
spams. These spam trap addresses can be easily pro-
moted throughout the internet to attract a large number
of spams. It has been noted by a commercial anti-spam
company that only a few hundred well-spread spam traps
are needed to catch almost all new spams [31]. These
spam traps are not diﬃcult to initiate and they do not
cost much in bandwidth and memory storage to main-
tain. With spam traps properly installed, the system is
ready to be deployed and oﬀer superior spam detection
performance.

Hybrid and Multi Tier Design. As discussed in
section V, legitimate emails from popular mailing lists
can easily become blacklist targets of the malicious users
of the system. In addition to the trust scheme we pro-
posed in section II C, any traditional spam ﬁltering tech-
nique can be utilized as DeﬁnitelySpam and Deﬁnitely-
NotSpam function in Algorithm 1 to achieve enhanced
performance, and plug security holes in the collaborative
system.

12

VII. CONCLUDING REMARKS

Our fairly comprehensive simulation results show that
global social email networks possess several properties
that can be exploited using recent advances in complex
networks theory (e.g., the percolation search algorithm)
to provide an eﬃcient collaborative spam ﬁlter. Clearly,
the proof-of-concept system discussed here can be vastly
improved and augmented with schemes that have proven
successful at various levels. Moreover, there is nothing
special about searching for and caching spam digests,
and one can use our pervasive message passing system
for managing a general distributed information system.
The primary requirement is to be able to provide enough
beneﬁts to the users so that they are motivated to co-
operate, which is relatively easily accomplished when it
If users get used to the
comes to spam management.

spam ﬁltering system, then we envision that queries for
other information will follow.

The study brings out several aspects of the burgeon-
ing cyberspace networks, and the increasingly powerful
Cyberalter ego: (i) They have some of the same charac-
teristics as their real-life counterparts, and hence, can be
managed and explored using well-studied schemes; (ii)
In many P2P applications, we do not need to explicitly
deﬁne new links and form the network from scratch, but
existing cyberspace and social contacts can be exploited
as an eﬃcient P2P infrastructure. Such existing networks
combined with eﬃcient tools, borrowed from the ﬁeld of
complex networks, can achieve almost optimum perfor-
mance. This work and similar recent concepts [8] con-
stitute some of the ﬁrst steps toward the management
and design of eﬃcient and naturally grown collaborative
systems in the cyberspace.

[1] Email network data.

http://www.theo-physik.uni-

kiel.de/∼ebel/email-net/email net.html.

[2] Nua internet surveys. http://www.nua.ie/surveys

/howmanyonline/world.html.

[3] Spam statistics. http://www.theregister.co.uk.
[4] Spamassassin. http://spamassassin.apache.org/.
[5] Spamnet. http://www.cloudmark.com.
[6] Spoke. http://www.spoke.org/.
[7] N. B. Barry Leiba. A multifaceted approach to spam
In Proc. of First Conference on Email and

reduction.
Anti-Spam (CEAS), 2004.

[8] P. Boykin and V. Roychowdhury.

networks:
http://xxx.lanl.gov/abs/cond-mat/0402143.

An eﬀective anti-spam tool.

Personal email
2004.

[9] S. Brin and L. Page. The anatomy of a large-scale hy-
pertextual Web search engine. Computer Networks and
ISDN Systems, 30(1–7):107–117, 1998.

[10] E. Damiani, S. De Capitani di Vimercati, S. Paraboschi,
and P. Samarati. An open digest-based technique for
spam detection. In Proceedings of the 4th IEEE interna-
tional conference on peer-to-peer computing, 2004.
[11] H. Ebel, L.-I. Mielsch, and S. Bornholdt. Scale-free topol-
ogy of e-mail networks. Phys. Rev. E, 66(035103), 2002.
http://xxx.lanl.gov/abs/cond-mat/0201476.

Chung-kwei:

[12] T. H. Isidore Rigoutsos.

a pattern-
discovery-based system for the automatic identiﬁcation
of unsolicited e-mail messages (spam). In Proc. of First
Conference on Email and Anti-Spam (CEAS), 2004.
[13] J. H. Jennifer Golbeck. Reputation network analysis for
In Proc. of First Conference on Email

email ﬁltering.
and Anti-Spam (CEAS), 2004.

[14] S. D. Kamvar, M. T. Schlosser, and H. Garcia-Molina.
The eigentrust algorithm for reputation management in
p2p networks. In Proceedings of the twelfth international
conference on World Wide Web, pages 640–651. ACM
Press, 2003.

[15] H. J. R. Albert and A.-L. Barab´asi. Attack and error tol-
erance of complex networks. Nature, 378-382(406), 2000.
[16] D. b. R. Cohen, K. Erez and S. Havlin. Resilience of
the Internet to random breakdowns. Phys. Rev. Lett.,
85:4626–4628, 2000.

[17] J. K. B. L. Richard Segal, Jason Crawford. Spamguru:
An enterprise anti-spam ﬁltering system. In Proc. of First
Conference on Email and Anti-Spam (CEAS), 2004.
[18] N. Sarshar, P. Boykin, and V. Roychowdhury. Percola-
tion search in power law networks: Making unstructured
peer-to-peer networks scalable. In Proceedings of the 4th
IEEE international conference on peer-to-peer comput-
ing, 2004.

[19] B. Y. Zhao, L. Huang, S. C. Rhea, J. Stribling, A. D.
Joseph, and J. D. Kubiatowicz. Tapestry: A global-
scale overlay for rapid service deployment. IEEE J-SAC,
22(1):41–53, January 2004.

[20] F. Zhou, L. Zhuang, B. Y. Zhao, L. Huang, A. D. Joseph,
and J. D. Kubiatowicz. Approximate object location and
spam ﬁltering on peer-to-peer systems. In Proc. of Mid-
dleware, pages 1–20, Rio de Janeiro, Brazil, June 2003.
ACM.

[21] In this paper, we use the term social email network in the
sense of an undirected network, except when we discuss
the computation of trust.

[22] SpamNet[5], a fairly popular commercial collaborative
anti-spam system, claims that a detection rate closed to
100 % and a false positive rate closed to 0 % are achieved.
[23] For a power-law (PL) degree distribution, the probability
of a randomly chosen node to have degree k scales as
P (k) ∝ k−γ for large k; γ is referred to as the exponent
of the distribution.

[24] However, implementing the client program as an email
program plug-in is not the only option;
large email
providers can also implement this system on the email
server ends.

[25] Please refer to Damiani et. al.’s work [10] on the deﬁnition

of matching digests.

[26] No statistics on this has been found but several online
sources suggest that spammers usually send out on the
order of millions of copies per unique message.

[27] We will see that in section V, this uniform assumption is
relaxed. In fact, when no trust scheme is implemented,
the selection of spam target node has no impact on spam
detection performance since all contents are almost surely
to be found with probability exponentially closed to one.

[28] In this calculation, the bandwidth cost due to content
caching and the routing back of messages is ignored.
[29] There are other possible forms of attack such as a Denial-
of-Service attack on the high-degree nodes by artiﬁcially
ﬂooding the network with queries. These forms of attacks
are outside the scope of this paper.

[30] Malicious nodes can undermine the performance of the
system by failing to follow the protocol. However, this is
outside the scope of the paper.
[31] http://www.esafe.com/pdf/esafe/
esafe antispam whitepaper.pdf

13

