5
0
0
2
 
p
e
S
 
2
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
8
7
0
9
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Minority Games with heterogeneous timescales

Giancarlo Mosetti1, Damien Challet2, Yi-Cheng Zhang1
1D´epartement de Physique, Universit´e de Fribourg,
Chemin du Mus´ee 3, 1700 Fribourg, Switzerland
2Nomura Centre for Quantitative Finance, Mathematical Institute,
Oxford University, 24–29 St Giles’, Oxford OX1 3LB, United Kingdom∗
(Dated: December 9, 2013)

Minority games where groups of agents remember, react or incorporate information with diﬀerent

timescales are investigated. We support our ﬁndings by analytical arguments whenever possible.

PACS numbers: 88

INTRODUCTION

Heterogeneity is gradually being recognized as one of the most important ingredients for the modeling of ﬁnancial
markets. Among the many types of heterogeneities, timescales are diﬃcult to understand analytically, because they
increase usually much the complexity of the equations to solve. However, as argued very early [1], ﬁnancial market
participants have very discernably diﬀerent timescales, which deserve therefore a detailled study. Among recent works
on the topic, two models of stochastic volatility have explicitely included an inﬁnite number of timescales [2, 3].

Here we investigate several types of timescale heterogeneities in the Minority Game model (MG) framework: strategy
change frequency, strategy-strategy correlation, reaction rates and score memory. We are able to provide analytical
support for our ﬁnding in the last three cases. Previous work addressed the eﬀects of trading frequency [4, 5]
analytically.

CANONICAL MG

The minority game is easily deﬁned: at each time step, all the players have to choose between two alternatives;
those who happen to be in the minority win. This is variant of Arthur’s El Farol bar [6] problem where the resource
level is set to satisfy half of the people. The Minority Game is exactly solvable which makes it an ideal model to
study and understand various aspects of the dynamics of competition.

· · ·

, N takes action ai(t)

Mathematically, agent i = 1,

ai(t)A(t)
N
i=1 ai(t). The agents base their decisions on public information which
where A(t) is the aggregated outcome A(t) =
is encoded in an integer number µ(t) drawn uniformly from 1,
, P . In order to process this information they are
endowed with S strategies, which are ﬁxed maps, or look-up tables, from the current public information µ(t) to an
action. At time t, agent i decides to trust his best strategy si(t) = arg maxs=1,
,S yi,s(t), where yi,s(t) is the score of
strategy s of agent i, which evolves according to

at each time step and receives a payoﬀ

1, +1

∈ {−

· · ·

P

−

···

}

yi,s(t + 1) = yi,s(t)

aµ(t)
i,s A(t)

−

Strategy change frequency

(1)

The above deﬁnition of the MG assumes implicitely that all the agents may change the strategy that they use
(si(t)) at each time step. Variants of the game where all the agents update synchronously their si(t) every T time
steps have been studied in the literature [7, 8, 9, 10], and are exactly solvable in the limit T
, in which case
they are called batch games. This part of the paper separates the populations into two groups. Fast agents behave as
usual, whereas slow agents update their strategies synchronously every T time steps. This introduces a heterogeneity
of time scales. I n essence, it is similar to giving a longer history memory in games where the state µ(t) is the binary
encoding of the last M winning choice, also known as games with real histories. Giving a larger M to a set of agents
is already found in the very ﬁrst paper on the MG, and was analyzed further in [11, 12]. Such agents do surprisingly
worse than their colleagues as long as the system is not deep into the symmetric phase, which is characterized by
alternating winning sides; Metzler [13] showed that agents with a larger M need a large alternating probability in
order to be able to proﬁt from it. The case we study here is much simpler as it does not require real histories and is a
priori more suitable to mathematical understanding. Unfortunately, since the exact analytical solution does not exist

→ ∞

2

(2)

(3)

T=1
T=50
T=500

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0
0.1

2

Ν

/

σ

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

Ν
Η

/

FIG. 1: Variance σ2/N (top) and predictability H/N (bottom) as a function of α for φ=0.7 and several values of T . Simulations
with P = 64, averages over 200 samples

1
α

10

for games where all the agents update synchronously their strategies every T time steps, we cannot solve the mixed
case either and must resort to numerical simulations.

The relative composition of the population is tuned by a parameter φ: if N is the total number of agents, φN of
φ)N update their strategy choice variable si(t) every

them are ordinary Minority Game agents, i.e., fast, whereas (1
T time steps, that is, their scores evolve following

−

i (t + 1) = ys
ys

i (t)

ys
i (t + 1) = ys

−

Xt′=t

T +1
i (t) otherwise.

−

t

′

)

aµ(t
i,s A(t′) if t MOD T = 0

As usual, we shall focus on the predictability

H =

1
P

P

2
i

ν
A
|
h
ν=1
X

i

ν
A
h
|
A2
h

where
is the temporal average of A conditional to µ(t) = ν. If H > 0, knowing µ makes it possible to predict
statistically the next outcome. H measures the amount of information left by the agents in the game. The ﬂuctuations
σ2 =
play a special role as they quantify the quality of resource sharing achieved by the population, which is
usually benchmarked against the ﬂuctuations produced by random choice σ2/N = 1. It is easy to see indeed that the
σ2 is nothing else than the average total loss per time step of the population. Of particular interest in the case of
competing populations are their respective average gains per time step.

i

Figure 1 reports the behaviour of H and σ2 as a function of α = P/N , for a ﬁxed φ and diﬀerent values of T . In
the predictable, asymmetric phase (H > 0), the slow agents do not change the unique stationary state; as a result,
H does not depend on T , but σ2 is slightly lowered as T increases, because strategy switching occurs less often. On
the other hand, in the unpredictable, symmetric phase (H = 0), multiple stationary states exist as a result of broken
ergodicity [7, 14], and any modiﬁcation to the system will accordingly change the ﬁnal values of σ. This is the case
here: the introduction of a small amount of slow agents reduces the total amount of ﬂuctuations because they damp
the overreaction of the fast players without contributing too much to the global outcome A.

What is more surprising is the behaviour of σ2 in the symmetric phase when one varies φ, as shown in Fig. 2:
at ﬁxed α = 0.2, slow agents (φ = 0) produce larger ﬂuctuations than fast ones (φ = 1); increasing the fraction of
fast agents φ decreases the ﬂuctuations which reaches a minimum below 1, the random choice benchmark, and then
increase again to reach the standard MG value, slightly above 1. This means that the two groups live in symbiosis,

3

T=500
T=50

Ν

/

σ

2

1

2

1.8

1.6

1.4

1.2

0.8

0.6

0.4

0.2

0

0

0.2

0.4

0.6

0.8

1

 φ

FIG. 2: Volatility σ2/N as a function of φ for α = 0.2 ﬁxed (P = 32, N = 160).

and that there is a non-trivial optimal composition of the population. Other known examples of symbiosis in MGs
include speculators and producers [11].

In such cases, it is natural to characterize the information ecology of the model (see [11, 15]), that is, who exploits
who. To this end, Fig. (3) reports the average gain per time step of fast agents γf , which decreases monotonically as
their concentration φ increases, but stays roughly constant as long as φ < 0.4. In this region, the slow agents provide
information that the fast agents exploit. The losses of the latter are greatly reduced compared to φ = 1, but they
seem not to be able to achieve positive gain on average. Similarly, when the slow agents are few (φ > 0.8), they proﬁt
from overreacting fast agents.

T=1
T=200
T=500

T=1
T=200
T=500

f

γ

s

γ

0

-0.5

-1

-1.5

0

-0.5

-1

-1.5

0.2

0.4

0.8

1

0

0.2

0.6

0.8

0.6

φ

0.4

φ

FIG. 3: Average gain of fast (left) and slow (right) agents as a function of φ for several T . Simulations with N = 300, P = 64,
averages over 200 samples

Strategy correlation

In the standard MG, all the aµ

i,s are random variables, drawn completely independently from each other. Take an
agent with two strategies; they will stipulate the same action a fraction c = 1/2 of the µs on average. In other words,
the standard-MG agents behave in the same way irrespectively on their strategy choice for half of the market states

1/(1

µ.[25] MG with tunable c where introduced in Ref. [11] and also studied later in Refs [8, 16]. The parameter c induces
a reaction time scale
c): the smaller c, the more adaptive an agent is; on the other end, people with c = 1
are not adaptive: they inject predictability and are ideal candidates for exploitation. The latter were introduced as
producers, that is, people who do not care much about timing in market, but use the market as a tool for exchanging
goods [15]; producers (c = 1) and speculators (c < 1) live in symbiosis [11], that is, the gain of a given group increases
then the other group is also present.

∼

−

Here, we consider the case where the two groups s and f have 0

cg < 1, g = s, f . The apparent similarity of this

setup with the case previously studied [11] is deceptive, as we shall see. The strategies are drawn according to

≤

Pf (aµ
Ps(aµ

i,1 = aµ
i,1 = aµ

i,2) = cf ;
i,2) = cs.

When cf < cs, group f is the fast one, and group s is the slow one. The asymmetric phase of the model for an
with replica trick [11, 14, 17]. The solution gives
arbitrary number of groups is exactly solvable in the limit N

H
N

=

φcf + (1

φ)cs + φ(1

−

−

(1 + φχf + (1

−
φ)χs)2

−

φ)(1

cs)Qs

−

→ ∞
cf )Qf + (1

i
∈N

2 (g = f, s); χf and χs are the integrated response functions [7]. These four quantities all
si(t)
where Qg =
i
depend on two variables ζf and and ζs which are the solutions of two coupled non-linear equations (see appendix).
Eq. (7) shows that in this case the stationary state of the asymmetric phase depends on the composition of the
population, which is also true of the location of the critical point.

P

g h

The respective gains of the two groups can also be computed exactly. Starting from the total losses

=

+ φ(1

cf )(1

Qf ) + (1

φ)(1

cs)(1

Qs)

−

−

−

−

−

and observing that if σ2

λ =

(Afast + λAslow)2

/P , the gains of the agents are nothing else than
µ
i
|

σ2
N

H
N

P
µ=1h

P

From the replica calculus, we ﬁnd

γs =

AslowA

=

−h

i

−

1
2

∂σ2
λ
∂λ

γf =

σ2

−

−

γs.

λ=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)

γs
Ns

=

H
N

χs −

cs + (1
−
1 + φχf + (1

cs)Qs

(1

cs)(1

Qs);

φ)χs −

−

−

−

γf
Nf

=

1
φ

σ2
N −

−

1

φ

−
φ

γs
Ns

.

4

(4)

(5)
(6)

(7)

(8)

(9)

(10)

(11)

(12)

The behaviour of the game is non trivial, which is already clear in Fig 4, where the ﬂuctuations, or average losses
of the players per time-step, are plotted agains cs, showing a maximum. In this kind of plot, one should be careful
to stay in the asymmetric phase, because the critical point αc depends on cs, cf , and φ. Taking α > 1 solves this
1. The minimum of σ2/N is surprising at ﬁrst. Figure 5 gives a deeper understanding of this
problem since αc ≤
peculiar phenomenon by plotting the gains of the two groups. The minimum of the losses can be attributed entirely
the slow agents only, who proﬁt quite remarkably from the fast agents (cf = 0) unless they are very slow. This shows
an competition between two eﬀects: being slower means that one overreact less, in particular with respect to local
ﬂuctuations; inversely, being too slow makes it too diﬃcult to react to being exploited. Interestingly, increasing cs
increases monotonically the gains of group f .

The relative fraction of each type of agent is a crucial parameter, as illustrated by Fig 5, in particular when one
group of agents has a large strategy correlation. In order to shed more light on the matter, we produced plots of the
regions where one group has an advantage over the other. When φ = 0.5, Figure 6 contains four regions of interest.
0.61, group g on average wins more than the other group g′ as long as cg > c′g, which means that
When cg < c∗
as long as both groups have suﬃciently low cs, the slower the better. On the other hand, when cg > c(m)
0.98,

≃

≃

5

φ=0.5, α=2, cf=0

Ν

/

σ

2

0.8

1

0.9

0.7

0.6

-0.4

-0.6

-0.8

-1

0

f < γ
γ

s

-0.4

-0.6

-0.8

-1

0

0.2

0.4

0.6

0.8

cs

FIG. 4: Fluctuations σ2/N versus the strategy correlation parameter cs of the slow agents (φ = 0.5, cf = 0). Simulations with
P = 64, α = 2, averages over 200 samples.

φ=0.1

φ=0.5

φ=0.9

gf
gs

gf
gs

gf
gs

-0.4

-0.6

-0.8

-1

0

cs

1

0.8

0.6

0.4

0.2

0

0

0.2

0.4

0.6

0.8

1

0.2

0.4

0.6

0.8

1

0.2

0.4

0.6

0.8

1

cs

FIG. 5: The average gains gf /Nf , gs/Ns for fast and slow agents respectively (φ = 0.5, cf = 0). Lines are theoretical predictions
from Eq (10). Simulations with N = 32, P = 64, averages over 200 samples

.

cs

1

0.8

0.6

0.4

0.2

f > γ
γ

s

f > γ
γ

s

f

c

f

c

f < γ
γ

s

0 > γ

f > γ

s

0 > γ

f > γ

s

f < γ
γ

s

f < γ
γ

s

0.2

0.4

0.6

0.8

1

0
0.4

cs

0.6

0.8

cs

γ
f > 0
1

FIG. 6: Regions of relative advantage for φ = φf = 0.5 (left graph) and φ = 0.01 (right graph); the region ﬁlled corresponds to
the symmetric phase, in which the replica calculus is not valid.

group g′ always exploits group g. For intermediate values of cg, the outcome depends on the precise value of both cg
and c′g. While changing φ leaves unaﬀected the diagonal boundary, it has two remarkable eﬀects: ﬁrst it changes the
non-linear boundary between the γf < γs and γs < γs regions by roughly rotating it clockwise. A new region also
appears for α and φ small enough where the gain of group in relative sparseness is positive; it is however very small,
and only appears when the largest group has a very large c. In this case, one needs to be few and react fast in order
to be able to exploit very slow agents so much that one’s gain is positive.

GAMES WITH NO PUBLIC INFORMATION

The case where P = 1, that is, when there is no public information available corresponds to the limit α = 0 of the
previous section, and is particularly simple to understand analytically [18, 19]; as a result explicit formulae for the
ﬂuctuations and gains can be obtained. Given A(t), each agent i receives a payoﬀ
ai(t)A(t), which is stored in the
score

−

and

to

∆i(t + 1) = ∆i(t)

A(t)
N

−

P [ai(t + 1) = 1] =

1 + tanh(Γi∆i(t))
2

.

p(t + 1) = p(t) +

A
N

.

∆i(t) =

p(t) + ∆i(0).

−

P

Γi is a reaction rate: it speciﬁes the diﬀerence of behaviour to a change of ∆i. Because of Eq (13) it is also timescale.
Linking the above model with ﬁnancial markets is straighforward if one assumes that the log-price evolves according

This allows us to propose a new interpretation of this case: rewriting ∆i(t) =
is the initial condition of agent i, one sees immediately that

−

t
t′=0 A(t)/N + ∆i(0) where ∆i(0)

∆i(0) is nothing else than the asset reference price, or value, of agent i. Hence, this equation describes a model of N
investors having each a value in mind for the price, and acting accordingly.[26] The agents are therefore fundamentalists
[19] who compare the current price with a reference price φi, and Γi tunes the price excursion from its supposed
fundamental value ∆i(0) tolerated by agent i.

If ∆i(0) = 0, all the ∆is are the same and can be replaced by ∆. Eq (13) becomes

∆(t + 1) = ∆(t)

tanh(Γ∆(t)) + n(t)

−

where n(t) is a noise term with zero average
therefore in the N
and unstable otherwise; in the latter case, a period 2 dynamics emerges, with the stable points determined by [18]

n(t)n(t′)
h
limit. It is easy to ﬁnd that the ﬁxed point ∆(0) = 0 is stable if Γ < Γ∗ = 2 and

tanh(Γ∆(t))2]/N ; it vanishes
N ,

= δt,t′[1

= 0 and

n(t)
h

A2
h

→ ∞

i ∝

−

i

i

∆(1) = tanh(Γ∆(1))/2.

i ∝

N 2. A Taylor expansion of Eq (18) gives ∆1 ≃ ±

A2
and
h
Γ) for large Γ. A way to check numerically the value of Γ∗ is to observe the onset of the change of
exp(
−
1) to O(1) as a function of Γ. Heterogeneous initial conditions ∆i(0)
O(N −
raising Γ∗ [19].

∆1 ∝
from
= 0 help to stabilize the ﬁxed point by

for Γ close to 2; on the other hand, A

2 −
∆2
i
h

−
Γ3

q

3(Γ

2)

We shall be particularly interested in the gains of the agents. The knowledge of P (∆) allows us to compute the

average gain

=

γ
h

i

−h

A2

/N , i.e. the ﬂuctuations themselves
i
A2
h
N

A2
d∆P (∆)
h

∆
i
|

1
N

1
N

=

=

i

Z

Z

= 1 + (N

1)

d∆P (∆) tanh(Γ∆)2

−

Z

(δA)2
d∆P (∆)[
h

∆
i
|

+

∆
A
|
h

2]
i

6

(13)

(14)

(15)

(16)

(17)

(18)

(19)

(20)

6
1
-
N

/

2
σ

 

100

10

1

0.1

0.01

FIG. 7: Fluctuations versus Γ from numerical simulations (thick line; N = 100, 106 iterations per point), from the Fokker-Plank
equation (thin line, Γ < 2), the Gaussian approximation (dashed red line), and Eq (25) (dash-dotted line, Γ > 2)

0.1

1

Γ

10

If Γ > Γ∗ and N

, we can simply write

→ ∞

A2
h
i
N 2 →

4∆2
1

which is about 12(Γ
−
Γ3
equation for ∆ can be rewritten as a Fokker-Planck equation, which reads

2)

for Γ close to 2. For Γ < 2, one must ﬁrst keep N ﬁnite and derive P (∆). The dynamical

∂P (∆)
∂t

=

∂2
2∂∆2

1

(N

−

−

1) tanh(Γ∆)2
N

P (∆)

+

[tanh(Γ∆)P (∆)]

∂
∂∆

(cid:21)

Solving this equation in the stationary states gives

(cid:20)

1
Z

P (∆) =

[2 + N (cosh(2Γ∆)

1))]

−(1+Γ)
Γ

cosh(Γ∆)2

−

where Z is the normalisation factor. When Γ is small, P can be approximated by a Gaussian with zero average and
∆2
h

= 1/[2Γ[(N (Γ + 1)

Γ]. Therefore

−

i

A2
i
h
N ≃

1 + (N

1)

−

2[N (Γ + 1)

Γ] →

2(Γ + 1) ≃

Γ

1 +

1 +

Γ
2

N

→ ∞

, Γ

1

≪

Γ

−

Figure 7 shows that the Fokker-Planck equation provides a good description of the stationary state for Γ
1, whereas
for larger Γ the hypothesis of small jumps in ∆ is clearly wrong; this is due to the fact that with Γ > 1, the drift
term makes ∆ change sign on average at each time step. The Gaussian approximation bends in the wrong way as Γ
increases and should not be used for Γ > 0.01. For Γ > 2, P (∆) separates into two symmetric peaks, centered roughly
at

∆1; it can therefore be approximated by

≤

±

P (∆)

[2 + N (cosh(2Γ(∆

∆1)

1))]

−

−

[2 + N (cosh(2Γ(∆ + ∆1))

1))]

−

1
2Z
1
2Z

≃

+

−(1+Γ)
Γ

−(1+Γ)
Γ

cosh(Γ(∆

∆1))2

−
cosh(Γ(∆ + ∆1))2

Heterogeneous learning rates

Let us consider G groups of respectively φgN agents, g = 1,

, G; all the agents belonging to group g have Γg.
g φgf (xg) for any function f of variables xg, the dynamical equation for ∆ reads now

· · ·

Using the notation f (xg) =

P

∆(t + 1) = ∆(t)

tanh[Γg∆(t)] + η(t)

−

7

(21)

(22)

(23)

(24)

(25)

(26)

>
n
i
a
g
<

-3

0

-1

-2

-4

-5

-6

0

0.5

1

2

2.5

3

1.5
Γ
F

FIG. 8: Average gain versus Γf from numerical simulations (circles: fast agents with Γf , slow agents with Γs = 0.001) and Eq
(31) (dashed lines); average over 100000 time steps, after 10/Γs time steps, average over 20 samples.

where ηg(t) are Gaussian noises with zero average and variance
that ∆(0) is a stable ﬁxed point as long as

η(t)η(t′)
h

i

(1

tanh(Γg ∆)2

= δt,t′

−

N

. Linear stability shows

When this point is unstable, it replaced by a period-two dynamics with stable point

Γg < 2.

∆(1) =

tanh(Γg∆(1))
2

Going through the same procedure as before, one ﬁnds that P (∆) is determined by

2N tanh(Γg∆)[1 + Γg(1

dP
P

= −

tanh(Γg∆)2]
2
N tanh(Γg∆)

+ 1

−

−
tanh(Γg∆)2

2Γg tanh(Γg∆)[1

tanh(Γg∆)2]

−

This cannot be integrated any more. The Gaussian approximation consists in keeping only the terms linear in ∆ in
this equation, and results in ∆ being of average 0 and variance

for small Γ.

=

1

−

∆2
h

i

2[N Γg(1+Γg )

Γ2
g ]

−

The average gain per player of group g at ﬁxed ∆ is equal to

∆
γg|
i
h
Ng

=

−

A2
g|
h

∆

+

i

=g h

∆
AgA′g|
i

g′
Ng

P

=

1

−

−

(Ng −

1) tanh(Γg∆)2

tanh(Γg∆)

N ′g tanh(Γ′g∆)

(30)

−

Xg′

Assuming that the Gaussian approximation is valid, i.e. if all the Γg are small,

for inﬁnite N . The gain of an agent of group g can be compared to the average gain, which yieds

γgi
h
Ng ≃ −

1

∆2

Γgh

−

Γg + N Γg

1

→ −

−

Γg
2[1 + Γg]

i

−

(cid:2)

(cid:3)

γgi − h
h

γgi →

Γg
Γg −
2(1 + Γg)

.

In other words, the smaller Γg, the smaller the losses of that group. This is intuitive: at a given time, i.e. at a given
∆, the fraction of players whose action is opposite to the sign of ∆ is larger for smaller Γ.

Figure 8 compares

from numerical simulations and from Eq (31). As before, the approximations made are valid

for small Γ. This ﬁgure also indicates that the transition at Γ∗ is smooth.

γ
h

i

8

(27)

(28)

(29)

(31)

(32)

6
1
-
N

/

2
σ

1

0.8

0.6

0.4

0.2

0

0

FIG. 9: Fluctuations σ2/N − 1 versus λ for Γ = 0.1, 0.5, 0.7 and 0.9 (bottom to top) obtained by numerical simulations.
N = 100, 106 iterations per point;

0.2

0.4

0.6

0.8

1

λ

Another way of having heterogeneous time scales is to diﬀer in one’s score memory. Before studying groups, let us
again characterise ﬁrst the homogeneous case. For the sake of simplicity, we consider exponential moving averages.
There are two ways of implementing them:

Heterogenous score memory λ

∆(t + 1) = ∆(t)(1

λ)

A(t)
N

−

−

∆′(t + 1) = ∆′(t)(1

λ)

λ

A′(t)
N

−

−

Γ + λ < 2

λ(Γ′ + 1) < 2

and

and

The length of score memory is 1/
∆′ = ∆λ and Γ′ = Γ/λ. The same stability analysis as above gives for a homogeneous population

1/λ for small λ. One can transform Eq (33) into (34) by setting

ln(1

| ∝

λ)

−

|

Increasing λ at ﬁxed Γ and Γ′ has therefore opposite eﬀects for the two kinds of dynamics: a small λ stabilises Eq
(33) and destabilises Eq (34). Since there is a one-to-one correspondance between all the results of Eqs (33) and (34),
we shall focus on Eq (33). The period-two ﬁxed point for Γ + λ > 2 is now determined by ∆(1) = 1
λ tanh(Γ∆(1)).
2
−
Assuming that ∆(0) = 0 is stable, the same procedure as before yields

dP
P

=

2N

−

[λ∆ + tanh(Γ∆)](1 + λ + Γ[1

tanh(Γ∆)]) + Γ tanh(Γ∆)[1

−
N (λ∆ + tanh(Γ∆))2 + 1

tanh(Γ∆)2

−

tanh(Γ∆)2]

−

In the Gaussian approximation, one ﬁnds

∆2
h

i

=

2[(Γ + λ)(1 + λ + Γ)N

1

.

Γ2]

−

As consequence, for small Γ, λ > 0 decreases the ﬂuctuations. The Fokker-Planck equation holds if λ + Γ < 1;
otherwise, the change of sign of ∆ at each time step (neglecting the noise) causes more ﬂuctuations. Therefore, σ2/N
has a minimum at λ + Γ = 1 when λ increases, as illustrated by Fig 9. The Gaussian approximation is very good for
small Γ and λ.

9

(33)

(34)

(35)

(36)

(37)

(38)

Generalising these results to groups of agents is more complicated than for heterogeneous Γ because of the role of

λ in Eq. (33): each group g with a given λg has its own ∆g

∆g(t + 1) = ∆g(t)(1

λg)

tanh(Γ∆g′ ) + η(t) = fg(
{

−

−

∆g′

) + η(t)

}

tanh(Γ∆g′ )2)/N . For inﬁnite N , the linear stability conditions of the ﬁxed point ∆g = 0
< 1, that is,

where
for all g are

η(t)η(t′)
i
h
g′

= δt,t′ (1
−
∂fg/∂∆g′
|
|

P

1
|

λg −

φgΓg|

−

+

φg′ tanh(Γg′ ∆g′ ) < 1

=g

Xg′
for all g. When λg + φgΓg < 1, i.e. both λg and Γ are small, the stability condition is Γg′ < λg + 2φgΓg; for instance
if Γg = Γ for all g, and φg = 1/G, then the condition is Γ(1
1/φg
and gives λg + Γg′ < 2, which is the same as before. Interestingly, some unstable ∆(0)
can coexist with stable ones,
g
1, φ = 1/G and λg = 2ǫg/G, where the dynamics of ∆g is stable for
for instance when Γg = Γ = 2
g < G/2 and unstable otherwise. This is clearly a source of losses for fast-forgetting players. Going back to the
average gain per player per time step, ones indeed that the gain of group g is intimately related to the variance of
∆g. The multivariate Fokker-Planck equation reads

2/G) < λg. The other case is obtained when Γg ∼

ǫ, 0 < ǫ

≪

−

−

with

∂P (∆, t)
∂t

=

∂
∂∆g 

(cid:16)



g
X

1

tanh(Γg′′ ∆g′′ )2

Dg,g′ =

−

N

[λg∆g + tanh(Γ∆g′ )]P

+

(Dg,g′ P )

(41)

1
2

∂
∂∆g′

(cid:17)

Xg,g′





+ (λg∆g + tanh(Γg′′ ∆g′′ ))(λg′ ∆g′ + tanh(Γg′′ ∆g′′ ))

(42)

Solving a linearised version of Eq (41) is done following standard procedure [20] and gives a multivariate Gaussian
solution. For G = 2, we have the resulting equations.

P (∆f , ∆s) =

2πσf σs

1

ρ2

−

1

p

exp

"−

2(1

ρ2)  

1

−

∆2
f
σ2
f −

2ρ∆f ∆s
σf σs

+

∆2
s
σ2

s !#

The expressions for σf , σs and ρ are too long to be reported here [27]. Reusing Eq (30) the respective average gain is

∆2
Γ2
f i
h
f σ2
Γ2
f (Nf −
(cid:0)
Figure 10 plots the gains of the two groups and clearly shows that all other things beeing equal, having a shorter
memory is an advantage. Indeed, when Γf = Γs = Γ and φf = φs = 1/2, as in Fig. (10), Eq (44) leads to

∆f ∆si
1) + Nsh
(Nf −
Γf ΓsNsρσf σs]
1)
(cid:1)
−

γf i ≃ −
h
=
−

(44)

−

−

1

1

γf i − h
h

γsi ≃

8Γ2(λf −

λs)(1 + Γ + λf + λs)[λf (1 + λf + Γ

2 ) + λs(1 + λs + Γ

2 ) + λf λs]

[2λf λs + Γ(λf + λs)][4Γ2 + 2(2 + 2λf + λs)(2 + λf + 2λs) + 3Γ(4 + 3λf + 3λs)]

×

2Γ2 + Γ(2 + 3λf + 3λs) + 2(λf + λ2

f + λs + λ2

s + λf λs)

1

which is of course positive when λf > λs. The above sections suggest that such advantage is menaced by increasing
Γf . Interestingly, increasing φf increases the gains of both groups, as the fast agents suﬀer less from the ﬂuctuations
caused by their slow colleagues. In the unstable region, the eﬀect is the opposite, that is, fast forgetting agents fail
to smooth out suﬃciently slowly large ﬂuctuations, and suﬀer from larger losses than slower agents. We performed
similar numerical simulations for P > 1 and Γ =
(standard MG), and found out similar results: faster agents end
up earning less in both phases (we could not ﬁnd an opposite result), which can be interpreted by their tendency to
switch more often between their strategies.

∞

10

(39)

(40)

(43)

(45)

6
11

Short memory
Long memory

1
 
+
>

 

 

X

γ
 
<

-0.00005

-0.00010

-0.00015

-0.00020

-0.00025

-0.00030

0.001

FIG. 10: Average gain per time step versus λf for fast players (circles) and slow players (squares). Continuous lines are from
the Gaussian approximation of Eq (44). Γf = Γs = 0.001, 107 iterations per point.

0.01

0.1

1

λ
F

CONCLUSIONS AND REMARKS

The four types of timescale heterogeneities investigated point to compatible and broad conclusions. First, agents
with a smaller strategy change frequency are similar to agents with larger strategy-strategy correlation, except that
their presence does not change the onset of the critical point, nor H. Accordingly, the gain of fast/slow agents in both
cases show similar behaviour. Although Ref. [4] did not compute the average gain as a function of playing frequency
it did show however that agents that trade less often tend to stick more to one strategy in the asymmetric phase;
since frozen agents have a higher average payoﬀ, this suggests agent who play less often win more. We conﬁrme this
intuition by extensive numerical simulations, and checked that this conclusion does not depend on the concentration
of slower agents. However, the results is the opposite in the symmetric phase where slower agents are exploited, while
all the agents have an equal gain at the critical point. Overreacting, that is, having a larger reaction rate than the
average population is detrimental. Reference [5] did not study the gain of agents with heterogeneous reaction rates,
therefore we refrain to generalize this conclusion to P > 1. Finally, for P = 1, agents with a smaller ﬁnite score
memory do generally better than average, unless they have a too large reaction rate.

D.C thanks B. Hambly for technical help, and Wadham College for support.

∗

Electronic address: challet@maths.ox.ac.uk

[1] R. Olsen et al., Tech. Rep. RBO.1992-09-07, Olsen & Associates (1992).
[2] L. Borland and J.-P. Bouchaud (2005), preprint physics/0507073.
[3] G. Z. and, Quant. Fin. 3, 320 (2003).
[4] M. Marsili and M. Piai, Physica A 310, 234 (2002), cond-mat/0202479.
[5] A. D. Martino, Eur. Phys. J. 35, 143 (2003).
[6] B. W. Arthur, Am. Econ. Rev. 84, 406 (1994).
[7] J. A. F. Heimel and A. A. C. Coolen, Phys. Rev. E 63, 056121 (2001), cond-mat/0012045.
[8] D. S. andTobias Galla, Physica A 324, 25 (2003).
[9] J. P. Garrahan, E. Moro, and D. Sherrington, Phys. Rev. E 62, R9 (2000), cond-mat/0004277.
[10] D. Challet, A. D. Martino, M. Marsili, and I. Per´ez-Castillo (2004), cond-mat/0407595.
[11] D. Challet, M. Marsili, and Y.-C. Zhang, Physica A 276, 284 (2000), cond-mat/9909265.
[12] N. J. P. Hui, D. Zheng, and M. Hart, J. Phys. A: Math. Gen. 32, L427 (1999).
[13] R. Metzler, J. Phys. A: Math. Gen. 35, 721 (2002).
[14] D. Challet, M. Marsili, and R. Zecchina, Phys. Rev. Lett. 84, 1824 (2000), cond-mat/9904392.
[15] Y.-C. Zhang, Physica A 269, 30 (1999).
[16] D. Sherrington, E. Moro, and J. P. Garrahan, Physica A 311, 527 (2002), cond-mat/0010455.
[17] M. M´ezard, G. Parisi, and M. A. Virasoro, Spin glass theory and beyond (World Scientiﬁc, 1987).
[18] M. Marsili and D. Challet, Phys. Rev. E 64, 056138 (2001), cond-mat/0102257.
[19] M. Marsili, Physica A 299, 93 (2001).
[20] N. G. van Kampen, Stochastic processes in Physics and Chemistry (North-Holland, 1992), chap. 8, p. 211.
[21] D. Challet and M. Marsili, Phys Rev. E 60, R6271 (1999), cond-mat/9904392.
[22] R. Savit, R. Manuca, and R. Riolo, Phys. Rev. Lett. 82, 2203 (1999).
[23] J. V. Andersen and D. Sornette, Eur. Phys. J. B 31, 141 (2003), cond-mat/0205423.
[24] I. Giardina and J.-P. Bouchaud (2002).

[25] This is the origin of predictability in the MG [21].
[26] Ref [22] proceeded the other way around by making value investors with heterogeneous expectations on the fair value
playing a delayed majority game [23, 24] and noticing that the ﬂuctuations look like those produced by minority players;
this was shown analytically in [19]

[27] We provide however a Mathematica ﬁle at www.maths.ox.ac.uk/ challet

REPLICA CALCULUS

The calculus parallels mostly the established procedure [11, 14]: the dynamics minimizes H [18] that is akin to
an energy. The stationary state of the system corresponds therefore to the ground state of H. After some algebraic
manipulations it is possible to ﬁnd relations that link the quantities that we have introduced The predictability is
given by

Hλ
N

=

φcf + λ2(1

φ)cs + φ(1

−

−

cf )Qf + λ2(1
φ)χs)2

−

(1 + φχf + λ2(1

φ)(1

cs)Qs

−

−

where the integrated response functions χs and χf are deﬁned as

α

(1

φ) erf

−

−
erf

ζs
√2

(cid:16)

(cid:17)

−

ζf
√2

(cid:16)

(cid:17)

χf =





1

−

φ





,

χs
χf

=

erf

erf

ζs
√2

ζf
√2

(cid:16)

(cid:16)

;

(cid:17)

(cid:17)

The self-overlap Qg is equal to

(cid:18)
All these quantities depend on ζs and ζf , determined through

Qg = 1

2
π

− r

ζ2
g /2

e−

ζg −

1

−

1
ζ2
g (cid:19)

erf

ζg
√2 (cid:19)

(cid:18)

ζ f =

φcf + (1

s

φ) cs + φ (1

−
e−

ζ2
f /2

ζf

2
π

 r

α (1

cf )
−
cf ) Qf + (1

−

−

1
ζ2
f !

erf

ζf
√2

φ) (1

cs) Qs

−
α (1

cf )

+

−
ζ2
f

+

ζs
√2

(cid:19)!

erf

(cid:18)
1
ζ2
s (cid:19)

(cid:18)

(cid:19)!

= 1.

+

1

−

 
ζ2
s /2

e−

2
π

ζs

 r

+

1
(cid:18)

−

φ (1

cf )

−

−

+ (1

φ) (1

cs)

,

ζf
ζs

=

cf
cs

;

1
1

−
−

r

Finally, the average gain of slow agents is

γs
Ns

=

−

1

φ

1
2

∂
∂λ

σ2
λ
N |λ=1 =

−

1

1

−

φ

lim
β
→∞

∂Hλ(β)
∂λ

(1

cs)(1

Qs)

−

−

λ=1 −
(cid:12)
(cid:12)
(cid:12)
(cid:12)

that leads to the expressions (11).

−

1

−

More than two groups

The results above are readily generalised to G groups denoted by g = 1, . . . , G: group g comprises Ng = φgN agents

equipped with two strategies with correlation cg:

H
N
σ2
N
γg
Ng

= h

c + (1

(1 +

=

=

H
N
H
N

+ h

χg −

−
χ
h
(1

i

c) Q
)2
i
c)(1
−
N
cg + (1
1 +

Q)
i

−

cg) Qg
−
χ
h

i

(1

−

−

cg) (1

Qg)

−

12

(46)

(47)

(48)

(49)

(50)

(51)

(52)

(53)

(54)

where the average

is over the groups.

.
i
h

Qg = 1

2
π

− r

ζ2
g /2

e−

ζg −

1 =

(1
h

−

c)

e−

2
π

ζ

 r

1
(cid:18)
ζ2/2

−

+

1
ζ2
g (cid:19)

erf

ζg
√2 (cid:19)

(cid:18)
1
ζ2

1
(cid:18)

−

erf

(cid:19)

(cid:18)

ζ
√2

+

(cid:19)!i

α(1

cg)

−
ζ2
g

ζg
ζg′

=

cg
cg′

.

1
1

−
−

s

13

(55)

(56)

(57)

