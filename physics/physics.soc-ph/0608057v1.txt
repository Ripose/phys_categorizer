6
0
0
2
 
g
u
A
 
4
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
7
5
0
8
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Self-organizing information networks that can be searched in constant time

Gourab Ghoshal1, 2 and M. E. J. Newman1, 3
1Department of Physics, University of Michigan, Ann Arbor, MI 48109
2Michigan Center for Theoretical Physics, University of Michigan, Ann Arbor, MI, 48109
3Center for the Study of Complex Systems, University of Michigan, Ann Arbor, MI 48109

We consider information networks in which data items of interest to the networks’ users are stored
at network nodes. Examples of such networks include peer-to-peer ﬁle sharing networks and other
kinds of distributed databases. A known problem with information networks of this kind is the
diﬃculty of searching them. Excluding cases where a centralized index of the network exists or can
be created, searches are typically obliged to make use of local message-passing algorithms that scale
poorly with system size. Methods have been proposed in the past for improving the performance
of these algorithms by exploiting the structure of the network, which in some cases is observed to
be scale-free. Here we take an alternative approach and ask how the structure of the network can
best be designed to optimize search performance. We show that it is possible to create a network
in which searches take constant time in the limit of large system size, even when only one copy of
the item for which we are searching exists in the network. We also give a distributed algorithm
based on biased random walks that allows the network to self-organize into this structure without
the need for outside supervision. We conﬁrm our results with computer simulations of the proposed
networks and of searches taking place on them.

I.

INTRODUCTION

Complex networks, such as the Internet, the worldwide
web, and social and biological networks, have attracted a
remarkable amount of attention from the physics com-
munity in recent years [1, 2, 3, 4]. One topic of in-
terest is the design of eﬃcient search strategies to ﬁnd
In-
items or data stored on the vertices of a network.
terest in this problem has been inspired partly by the
emergence of network-based distributed databases, par-
ticularly peer-to-peer ﬁle sharing networks. In such net-
works the structure of the network and the distribution
of the items stored on it typically change rapidly and fre-
quently, which means that searches must be performed
in real time, unlike web crawls, for example, which can
be performed oﬀ-line to create a centralized searchable
database of network contents. In peer-to-peer networks
searches typically consist of queries that are forwarded
from one vertex to another until the target item is found.
While in many cases it is precisely the decentralized na-
ture of these networks that makes them attractive, real-
time searches place heavy demands on computer power
and bandwidth, and there is interest in ﬁnding eﬃcient
search strategies to decrease these costs.

Direct measurements of real peer-to-peer networks [5]
have found that in some networks the degree distribu-
tion follows a power law, which has led some authors
to propose search strategies that exploit this power-
law form to improve eﬃciency, resulting in algorithms
capable of ﬁnding speciﬁc items in time that scales
(poly)logarithmically or at least sub-linearly with net-
work size [6, 7].
In this paper we propose an alterna-
tive approach to the problem in which, instead of tailor-
ing our algorithm to the observed network, we tailor the
structure of the network to optimize the performance of
the algorithm. We also describe explicit mechanisms by
which the resulting optimal structure can be achieved in

practice. We ﬁnd that even in the case where the de-
sired target item occurs at only one or a ﬁxed number of
vertices in the network (rather than at a ﬁxed fraction
of vertices) it is possible to design a network so that the
mean time to ﬁnd the target is a constant, independent
of network size.

II. DEFINITION OF THE PROBLEM

Consider a distributed database consisting of a set of
computers each of which holds some data items. Copies
of the same item can exist on more than one computer,
which would make searching easier, but we will not as-
sume this to be the case in the present work. Computers
are connected together in a “virtual network,” meaning
that each computer is designated as a “neighbor” of some
number of other computers. These connections between
computers are purely notional: every computer can com-
municate with every other directly over the Internet or
other physical network. The virtual network is used only
for the purposes of search and to limit the amount of in-
formation that computers have to keep about their peers.
Each computer maintains a directory of the data items
held by its network neighbors, but not by any other com-
puters in the network. Searches are performed by passing
a request for a particular item from computer to com-
puter until it reaches one in whose directory that item
appears, meaning that one of that computer’s neighbors
holds the item. The identity of the computer holding
the item is then transmitted back to the origin of the
search and the origin and target computers communicate
directly thereafter to negotiate the transfer of the item.
This basic model is essentially the same as that used by
other authors [6] as well as by many actual peer-to-peer
networks in the real world. Note that it achieves eﬃ-
ciency by the use of relatively large directories at each

vertex of the network, which inevitably use up mem-
ory resources on the computers. However, with standard
hash-coding techniques and for databases of the typical
sizes encountered in practical situations (thousands or
millions of items) the amounts of memory involved are
quite modest by modern standards.

A. Search time and bandwidth

The two deﬁnitive metrics of search performance that
we consider in this paper are search time and bandwidth,
both of which should be low in a good algorithm. We
deﬁne the search time to be the number of steps taken
by a propagating search query before the desired target
item is found. We deﬁne the bandwidth for a vertex as
the average number of queries that pass through that ver-
tex per unit time. Bandwidth is a measure of the actual
communications bandwidth that vertices must spend to
keep the network as a whole running smoothly, but it
is also a rough measure of the CPU time that they ex-
pend on searches. Since these are limited resources it
is crucial that we not allow the bandwidth to grow too
quickly as vertices are added to the network; if this were
to happen then the size of the network would be con-
strained, a severe disadvantage for networks that can in
some cases swell to encompass a signiﬁcant fraction of all
the computers on the planet. (In some early peer-to-peer
networks, issues such as this did indeed place impractical
limits on network size [8, 9].)

Assuming that the average behavior of a user of the
database remains essentially the same as the network
gets larger, the number of queries launched per unit time
should increase linearly with the size of the network,
which in turn suggests that the bandwidth per vertex
might also increase with network size, which would be
a bad thing. As we will show, however, it is possible
to avoid this by designing the topology of the network
appropriately.

B. Search strategies and search time

In order to treat the search problem quantitatively, we
need to deﬁne a search strategy or algorithm. In this pa-
per we consider a very simple—even brainless—strategy,
that of random walk search, which, although certainly
not the most eﬃcient strategy possible, has two signiﬁ-
cant advantages. First, it is simple enough to allow us to
carry out analytic calculations of its performance. Sec-
ond, as we will show, even this basic strategy can be
made to work very well. Our results constitute an exis-
tence proof that good performance is achievable: searches
are necessarily possible that are at least as good as those
analyzed here, and possibly better (although we will not
demonstrate the latter in this paper).

The deﬁnition of random walk search is simple: the
vertex i originating a search sends a query for the item it

2

(1)

(3)

wishes to ﬁnd to one of its neighbors j, chosen at random.
If that item exists in the neighbor’s directory the identity
of the computer holding the item is transmitted to the
originating vertex and the search ends.
If not, then j
passes the query to one of its neighbors chosen at random,
and so forth. (One obvious improvement to the algorithm
already suggests itself: that j not pass the query back to
i again. As we have said, however, our goal is simplicity
and we will allow such “backtracking” in the interests of
simplifying the analysis.)

Let pi be the probability that our random walker is at
vertex i at a particular time. Then the probability p′
i of
its being at i one step later, assuming the target item has
not been found, is

′
i =

p

Aij
kj

pj,

j
X
where kj is the degree of vertex j and Aij is an element
of the adjacency matrix:

Aij =

(

1
0

if there is an edge joining vertices i, j,
otherwise.

(2)

After reaching equilibrium the probability distribution
over vertices thus tends to the ﬁxed point of Eq. (1),
which is given by

pi =

ki
2m

,

where m is the total number of edges in the network.
That is, the random walk visits vertices with probability
proportional to their degrees. (An alternative statement
of the same result is that the random walk visits edges
uniformly.)

We will assume here that the random walk mixes well,
i.e., that it comes to equilibrium quickly, meaning that
the slowest decaying eigenmode of Eq. (1) other than the
ground state decays quickly on the timescales we care
about for performing our search. While some networks
will certainly have this property, others will not: a net-
work with more than one large component would be an
extreme example of the latter. We must exercise care
when we come to design our network to avoid pitfalls of
this nature.

When our random walker arrives at a previously un-
visited vertex of degree ki, it “learns” from that vertex’s
directory about the items held by all immediate neigh-
1 excluding the
bors of the vertex, of which there ki −
vertex we arrived from (whose items by deﬁnition we al-
ready know about). Thus at every step the walker gath-
ers more information about the network. The average
number of vertices it learns about upon making a single
1), with pi given by (3), and hence the
step is
total number it learns about after τ steps is

i pi(ki −

P

τ
2m

i
X

ki(ki −

1) = τ

k2
h
k
h

i
i

(cid:20)

−

1

,
(cid:21)

(4)

k2
h

i

i

i

k
h

k
h

and

where
represent the mean and mean-square
degrees in the network and we have made use of 2m =
with n the total number of vertices in the network.
n
(There is in theory a correction to this result because
the random walker is allowed to backtrack and visit ver-
tices visited previously. For a well-mixed walk, however,
, which, as we will see, is
this correction is of order 1/
i
negligible for the networks we will be considering.)

k
h

How long will it take our walker to ﬁnd the desired
target item? That depends on how many instances of the
target exist in the network. In many cases of practical
interest, copies of items exist on a ﬁxed fraction of the
vertices in the network, which makes for quite an easy
search. We will not however assume this to be the case
here, at least initially. Instead we will consider the much
harder problem in which copies of the target item exist
on only a ﬁxed number of vertices, where that number
could potentially be just 1. In this case, the walker will
need to learn about the contents of O(n) vertices in order
to ﬁnd the target and hence the average time to ﬁnd the
target is given by

k2
h
k
h

i
i

τ

(cid:20)

1

= An,

−

(cid:21)

for some constant A, or equivalently,

.

1

(6)

i −

k2
h

τ = A

n
k
/
h
i
Consider, for instance, the much studied case of a net-
work with a power-law degree distribution of the form,
pk = Ck−γ, where γ is a positive exponent and C is
∞
k=0 pk = 1.
a normalizing constant chosen such that
Real-world networks usually exhibit power-law behavior
only over a certain range of degree. Taking the minimum
of this range to be k = 1 and denoting the maximum by
kmax, we have

P

Typical values of the exponent γ fall in the range 2 <
γ < 3, so that k2−γ
max is small for large kmax and can be
ignored. On the other hand, k3−γ
max becomes large in the
same limit and hence

k3−γ
max and

k2
h
k
h

i
i

k3−γ
max −
k2−γ
max
−

1
1

.

∼ −

k2
h
τ

/
i

k
i ∼
h
nkγ−3
max.

∼

The scaling of the search time with system size n thus
depends, in this case, on the scaling of the maximum
degree kmax.

As an example, Aiello et al. [10] studied power-law
degree distributions with a cut-oﬀ of the form kmax ∼
n1/γ, which gives

n2−3/γ,

τ

∼

which is essentially the same result obtained previously
by Adamic et al. [6] using diﬀerent methods.

(5)

(7)

(8)

(9)

3

C. Bandwidth

Bandwidth is the mean number of queries reaching a
given vertex per unit time. Equation (3) tells us that
the probability that a particular current query reaches
vertex i at a particular time is ki/2m, and assuming as
discussed above that the number of queries initiated per
unit time is proportional to the total number of vertices,
the bandwidth for vertex i is

Bn

= B

ki
2m

,

ki
k
h

i

(10)

where B is another constant.

This implies that high-degree vertices will be over-
loaded by comparison with low-degree ones so that net-
works with power-law or other highly right-skewed de-
gree distributions may be undesirable, with bottlenecks
around the vertices of highest degree that could in prin-
ciple harm the performance of the entire network. If we
wish to distribute load evenly among the computers in
our network, then a network with a tightly peaked degree
distribution is desirable. The optimal situation would be
a regular graph, i.e., a network in which every vertex has
the same degree.

III. DESIGNING THE NETWORK

We wish to choose a structure for our network that
gives low search times and modest bandwidth demands.
Crucially, however, the structure must also be realizable
in practice. We will assume that vertices are entering
and leaving the network at all times, as is common in
real peer-to-peer networks, and part of our task is to
design a practical mechanism for new vertices to attach to
others in such a way that the resulting network functions
eﬃciently. Indeed, it is the creation of this mechanism
that is the challenging part of the problem. The design
of the network itself, as we now show, is very simple.

As we have said, the most desirable network from a
bandwidth point of view, is a regular graph. For the
purposes of argument, let us begin by assuming such a
network, although we will later be forced to relax this
assumption somewhat.

Suppose then that all vertices have the same degree c
= c2. Then the average
k2
h

= c and

k
h

i

i

and hence that
search time is

τ = A

n

−

c

.

1

(11)

α

≤

≤

1. Then τ

And suppose that we allow the degree c to grow as some
nα with
power of the size of the entire network, c
n1−α. For smaller values of α,
0
searches will take longer, but vertices’ degrees are lower
meaning that each vertex will have to devote less mem-
ory resources to maintaining its directory. Conversely,
for larger α, searches will be completed more quickly at
In the limiting
the expense of greater memory usage.

∼

∼

case α = 1, searches are completed in constant time, in-
dependent of the network size, despite the simple-minded
nature of the random walk search algorithm. Previ-
ously proposed search methods, by contrast, have at best
achieved polylogarithmic scaling of the search time with
system size.

The price we pay for good performance is that the
network becomes dense, having a number of edges scal-
ing as n2. It is important to bear in mind, however, that
this is a virtual network, in which the edges are a purely
notional construct whose creation and maintenance car-
ries essentially zero cost. There is a cost associated with
the directories maintained by vertices, which for α = 1
will contain information on the items held by a ﬁxed frac-
tion of all the vertices in the network. For instance, each
vertex might be required to maintain a directory of 1% of
all items in the network. Because of the nature of mod-
ern computer technology, however, we don’t expect this
to create a signiﬁcant problem. User time (for perform-
ing searches) and CPU time and bandwidth are scarce
resources that must be carefully conserved, but mem-
ory space on hard disks is cheap, and the tens or even
hundreds of megabytes needed to maintain a directory is
considered in most cases to be a small investment. By
making the choice α = 1 we can trade cheap memory re-
sources for essentially optimal behavior in terms of search
time and this is normally a very good deal for the user.
We notice also that the search process is naturally par-
allelizable: there is nothing to stop the vertex originating
a search from sending out several independent random
walkers and the expected time to complete the search
will be reduced by a factor of the number of walkers. Al-
ternatively, we could reduce the degrees of all vertices in
the network by a constant factor and increase the num-
ber of walkers by the same factor, which would keep the
average search time constant while reducing the sizes of
the directories substantially, at the cost of increasing the
average bandwidth load on each vertex.

A.

Item frequency distribution

4

items is not uniformly distributed: more popular items,
that is those with higher s, are likely to be searched for
more often than less popular ones. For the purposes of
illustration, let us make the simple assumption that the
frequency of searches for a particular item is proportional
to the item’s popularity. Then the average time taken by
a search is

(13)

=

τ
h

i

∞
s=1 spsτs
∞
s=1 sps

P
P

(c

= A

n
s
1)
h
s ps = 1 and

−

,

i

P

s
h

s sps =

where we have made use of

.
i
A commonly occurring case (perhaps the most com-
P
mon in practical situations) is of items with a power-law
s−δ. This case describes, for
frequency distribution ps ∼
example, essentially every form of mass art or culture in-
cluding copies of books, recordings, emails and other mes-
sages circulating on the Internet, and many others [11].
The mean time to perform a search in the network then
depends on the value of the exponent δ. In many cases
is ﬁnite and well-
we have δ > 2, which means that
behaved as the database becomes large, and hence
,
i
Eq. (13), diﬀers from Eq. (11) by only a constant factor.
(That factor may be quite large, making a signiﬁcant
practical diﬀerence to the waiting time for searches to
complete, but the scaling with system size is unchanged.)
becomes ill-deﬁned, having a
If δ < 2, however, then
formally divergent value, so that
0 as system size
becomes large. Physically, this represents the case in
which most searches are for the most commonly occur-
ring items, and those items occur so commonly that most
searches terminate very quickly.

i →

s
h

s
h

τ
h

τ
h

i

i

While this extra speed is a desirable feature of the
search process, it’s worth noting that average search time
may not be the most important metric of performance
for users of the network. In many situations, worst-case
search time is a better measure of the ability of the search
algorithm to meet users’ demands. Assuming that the
most infrequently occurring items in the network occur
only once, or only a ﬁxed number of times, the worst-case
performance will still be given by Eq. (11).

In most cases, the search problem we have posed above
is not a realistic representation of typical search problems
encountered in peer-to-peer networks. In real networks,
copies of items often occur in many places in the network.
Let s be the number of times a particular item occurs in
the network and let ps be the probability distribution of
s over the network, i.e., ps is the fraction of items that
exist in s copies.

If the item we are searching for exists in s copies, then

Eq. (11) becomes

τs = A

,

(c

1)s

n

−

(12)

since the chance of ﬁnding a copy of the desired item is
multiplied by s on each step of the random walk. On the
other hand, it is likely that the frequency of searches for

IV. GENERATING THE NETWORK

While the results of the previous section are satisfy-
ing, there is a catch. As discussed above, we need not
only to ﬁnd a network structure that gives good perfor-
mance but also to ﬁnd a mechanism by which we can
create the desired structure.
In most cases users con-
nect to peer-to-peer networks for only limited periods
of time while they are actually performing searches and
then disconnect again. What we would like to do is spec-
ify a mechanism or algorithm by which vertices join and
leave the network so that the desired network structure
is maintained at all times.

As discussed in Section II B, our random walk must
mix well in order for the calculations here to be valid.
The only regular network structure we are aware of that

guarantees good (meaning O(1)) mixing is the random
regular graph. It would be ideal if we could ﬁnd a growth
mechanism that generates such a graph, but this turns
out to be diﬃcult. We can however generate networks
that make a good approximation to the random regular
graph, in a way that gives performance about as good.
Speciﬁcally, we can generate random graphs with tightly
peaked degree distributions, using analytic results ob-
tained recently by Moore et al. [12].

Consider then a network that evolves by the constant
addition and deletion of vertices. We will assume that
the network is roughly constant in size, which simpliﬁes
the calculations.
(The calculations can be generalized
to growing and shrinking networks, at the expense of
considerable eﬀort, but the results are not signiﬁcantly
diﬀerent from the constant size case.) Let us set our time-
scale so that in each unit of time one vertex is added to
the network and one vertex is deleted.

Since we wish to make the degrees of vertices as nar-
rowly peaked as possible, we will give all vertices the
same initial degree c when they are added to the net-
work.
In the absence of other information about how
vertices leave the network we will assume that they leave
purely at random. When we remove a vertex, we also
remove all edges incident on that vertex, which decreases
by one the degrees of the vertices at the other ends of
those edges.

Let pk be the fraction of vertices in the network having

degree k, normalized such that

pk = 1.

(14)

Following Moore et al. [12] we also deﬁne an attachment
kernel πk which is n times the probability that an edge
of a newly added vertex attaches to a pre-existing vertex
with degree k. The total probability that a given edge
attaches to a vertex with degree k is then simply πkpk.
Since every edge must attach to a vertex of some degree,
the normalization condition for the attachment kernel is

∞

Xk=0

∞

Xk=0

5

(18)

(19)

1, as they lose edges
with degree k + 1 and k to k and k
with the removal of neighboring vertices. The term
pk
represents the probability of removal of a vertex of degree
k and the term δk,c represents the addition of a vertex
with degree c to the network.

−

−

Assuming pk has an asymptotic form in the limit of

large time, that form is given by setting p′

k = pk thus:

cπkpk
kpk −
Let us deﬁne two generating functions

δk,c + cπk−1pk−1 −
+ (k + 1)pk+1 −

pk = 0.

(17)

f (z) =

πkpkzk,

∞

Xk=0
∞

g(z) =

pkzk.

Xk=0
Multiplying both sides of (17) by zk and summing over k,
we derive a diﬀerential equation for g(z) of the following
form:

(1

z)

−

dg
dz −

g(z)

c(1

−

−

z)f (z) + zc = 0.

(20)

This growth process gives us considerable control over
the degree distribution of the network via the choice of
the attachment kernel. Here we make the particularly
simple choice of uniform attachment: we assume that
vertices attach to others uniformly at random without
regard for vertex degree. This implies that the attach-
ment kernel πk is independent of k. Combining (14)
and (15) we then see that πk = 1 for all k and hence
that g(z) = f (z). Substituting into (20) this gives

1

c +

1

g(z)

z

(cid:21)

dg
dz

−

zc

=

1

.

z

(cid:20)

Noting that (1

−
z)e−cz is an integrating factor for
the left-hand side and applying the boundary condition
g(1) = 1 (see Eq. (14)), the solution of (21) is

−

−

(21)

1

tce

−ct dt

ecz
1
−
ecz
1

−

z

z

z
Z
−(c+1)
c

(cid:2)

=

Γ(c + 1, cz)

Γ(c + 1, c)

, (22)

−

(cid:3)

Γ(c + 1, x) =

(23)

∞

tce

−t dt

x
Z

πkpk = 1.

(15)

g(z) =

The evolution of our network can now be described
by a rate equation as follows. The number of vertices
with degree k at a particular time is npk. One unit of
time later we have added one vertex and taken away one
vertex, so that the number with degree k becomes

where

′

np

k = npk + δk,c + cπk−1pk−1 −
pk.
+ (k + 1)pk+1 −

kpk −

cπkpk

(16)

is the incomplete Γ-function. The degree distribution pk
can be extracted from (22) through a sequence of manip-
ulations [12], giving

cπkpk represent the ﬂow of
The terms cπk−1pk−1 and
vertices with degree k
1 to k and k to k + 1, as they
gain extra edges with the addition of new vertices. The
kpk represent the ﬂow of vertices
terms (k + 1)pk+1 and

−

−

−

pk =

Γ(c + 1)

Γ(c + 1, c)

−

ec
cc+1

(cid:2)

Γ(k + 1, c)
Γ(k + 1)
for k < c,

,

(cid:3)

(24)

6

and

pk =

ec
1
cc+1 Γ(c + 1, c)
(cid:20)

Γ(k + 1, c)
Γ(k + 1)

−

,

(cid:21)

for k

c. (25)

≥

This distribution has a maximum at c and is sharply
peaked. To see this, we note that the average de-
= g′(1) = c and the variance is
gree is given by
k
h
σ2 = g′′(1) + g′(1)
c2 = 2
3 c. This gives a ratio of the
mean to the standard deviation varying in typical Pois-
son fashion as 1/√c, which goes as 1/√n for the choice
n made here, and hence the distribution becomes
k
h
arbitrarily narrow as the network becomes large.

i
−

i ∼

We can also calculate

3 c + c2, and
i
substituting into (6) we then ﬁnd that the average search
time for this network is

2 = 2
i

= σ2 +

k2
h

k
h

simply drawing vertices from such a walk will not sam-
ple them uniformly as we would like. Instead, therefore,
we make use of a biased random walk in which steps are
deliberately taken in inverse proportion to degree. In par-
ticular, we consider a walk in which a walker at vertex j
chooses uniformly at random one of the kj neighbors of
that vertex. Let us call this neighbor i. Then the walk
takes a step to vertex i with probability

Pij =

(

kj/ki
1

if ki > kj ,
otherwise.

(27)

If the step is rejected (which happens with probability
1
Pij ) then the walker stays where it is for the current
time-step and tries again on the next step.

−

With this choice of transition probability, the equiva-

τ = A

n
1/3

.

c

−

(26)

lent of Eq. (1) is

→

Again setting c equal to Bn for some constant B, we ﬁnd
that the search time tends to a constant τ
A/B as
n

.
→ ∞
Moreover, the functional form (25) of the degree distri-
bution for large degree has a tail that decays sharply—
faster than any exponential [12]—so there will be no
“hubs” in the network, vertices with degree substantially
higher than the average. This implies that there will also
be no vertices with bandwidth loads substantially higher
than the average, ensuring that the network will operate
smoothly and without bottlenecks.

We have here demonstrated only that we can gener-
ate a desirable degree distribution and not that the net-
work is otherwise random, a property which, as discussed
above, we require for rapid mixing of our random walk
search algorithm. However, since vertices choose neigh-
bors at random, it is trivially the case that in the equi-
librium state there can be no correlations in the network
and hence the network will be a true random graph for
the given degree distribution.

A. A practical algorithm

We still have a problem however. In practical peer-to-
peer networks, no computer knows the identity (e.g., IP
address) of all others in the network, and certainly not a
computer that has only just joined the network. This
makes the direct application of the process described
above impossible because there is no way for a newly
joined vertex to choose at random those that it will at-
tach to.

To solve this problem, we propose again to make use
of random walks. Starting a walk from any vertex in the
network, we can sample vertices by allowing the walk to
take some ﬁxed number of steps and then choosing the
vertex that it lands upon on its ﬁnal step. As we have ob-
served, a normal random walk visits vertices with prob-
ability proportional to their degree, which means that

′

p

i = pi −

AjiPji
ki

pi +

AijPij
kj

pj,

j
X

j
X

(28)

where the ﬁrst two terms represent the probability that
the walker is already at vertex i and does not move, and
the last term is the appropriate generalization of (1).
Combining Eqs. (27) and (28) and observing that Aji =
Aij , we then ﬁnd that

′
i = pi +

p

= pi +

AjiPji
ki

pj

ki
kj

Pij
Pji −

pi

(cid:21)

j
X

P

j AjiPji

(cid:20)
pj −
j Aji
(cid:0)

pi

(cid:1)

(29)

P
which necessarily converges to the point at which all pi
are equal to the values pj on the neighboring vertices,
i.e., the point where the pi are uniform, provided only
that the network is connected, so that each vertex is
reachable from every other.

Thus, if we start a biased random walker of this type
from any point in a connected network then the vertex
at which the walker ﬁnds itself after taking a number
of steps large enough to ensure full mixing is uniformly
selected from the entire network.

Our proposed method for creating a network is thus
as follows. Each newly joining vertex i ﬁrst locates any
It might do this
single other vertex j in the network.
for instance using a list of known previous members of
the network or a standardized list of permanent network
members. This ﬁrst vertex is probably not selected uni-
formly from the network, so it is not chosen as a neighbor
of i. Instead, we use it as the starting point for a set of c
biased random walkers of the type described above. Each
walker consists of a message, which starts at j and prop-
agates through the network by being passed from com-
puter to neighboring computer. The message contains
(at a minimum) the address of the computer at vertex i
as well as a counter that is updated by each computer
to record the number of steps the walker has taken. The

7

k

p
 
y
t
i
l
i

b
a
b
o
r
P

100

10-1

10-2

10-3

10-4

10-5

10-6

 1

τ
 

e
m
T

i

 

 170

 160

 150

 140

 130

 120

 110

 100

 90

 0

 10

Degree k

 5000

 10000

 15000

 20000

Network size n

FIG. 1: The degree distribution for a network of ﬁxed size
n = 50 000 generated using the biased random walk growth
mechanism described in the text, with c = 10. The points
represent the results of our simulations and the solid line is
the analytic solution of Eqs. (24) and (25).

computer that the walker reaches on its rth step, where
r is a ﬁxed but generous constant chosen to allow enough
time for mixing of the walk, establishes a new network
edge between itself and vertex i and the walker is then
deleted. When all c walkers have terminated in this way,
vertex i has c new neighbors in the network, all chosen
uniformly at random.

As a test of this method, we have performed simu-
lations of the growth of the network. Starting from a
random graph of the desired size n, we randomly add
and remove vertices according to the prescription given
here. Figure 1 shows the resulting degree distribution for
the case c = 10, along with the exact analytic solution of
Eqs. (24) and (25). As the ﬁgure shows, the agreement
between the two is excellent.

We have also performed simulations of our search pro-
cedure on networks generated in this way. Figure 2 shows
as a function of network size the average time τ taken by
a random walker to ﬁnd an item placed at a single ran-
domly chosen vertex in the network. As we can see, the
value of τ does indeed tend to a constant (about 100 steps
in this case) as network size becomes large. The value of
c in this case was chosen to be n/100.

B. Estimating network size

One further detail remains to be considered. We want
to make the degree c of vertices added to the network
proportional to the size n of the entire network, which
means we need to know n, which presents a challenge
since, as we have said, we do not expect to know all or
even most of the vertices in the network. This particular
problem however is easily solved. The size of the network
can be measured using a breadth-ﬁrst search which can
be implemented by message passing across the network.

FIG. 2: The time τ for the random walk search to ﬁnd an item
deposited at a random vertex, as a function of the number of
vertices n.

One vertex i chosen at random (or more realistically ev-
ery vertex, at random but stochastically constant inter-
vals proportional to system size) sends messages to some
number d of randomly chosen neighbors. The message
contains the address of vertex i, a unique identiﬁer string,
and a counter whose initial value is zero. Each receiving
vertex increases the counter by 1, passes the message on
to one of its neighbors, and also sends messages with the
1
same address, identiﬁer, and with counter zero to d
other neighbors. Any vertex receiving a message with
an identiﬁer it has seen previously sends the value of the
counter contained in that message back to vertex i, but
does not forward the message to any further vertices. If
vertex i adds together all of the counter values it receives,
the total will equal the number of vertices (other than it-
self) in the entire network. This number can then be
broadcast to every other vertex in the network using a
similar breadth-ﬁrst search (or perhaps as a part of the
next such search instigated by vertex i.)

−

The advantage of this process is that it has a total
bandwidth cost (total number of messages sent) equal
to dn. For constant d therefore, the cost per vertex is
a constant and hence the process will scale to arbitrar-
ily large networks without consuming bandwidth. The
(worst-case) time taken by the process depends on the
longest geodesic path between any two vertices in the
network, which is O(log n). Although not as good as
O(1), this still allows the network to scale to exponen-
tially large sizes before the time needed to measure net-
work size becomes an issue, and it seems likely that di-
rectory size (which scales linearly with n) will become a
limiting factor long before this happens.

V. DISCUSSION

In this paper, we have proposed a design for distributed
databases such as peer-to-peer networks that allows us

to perform decentralized searches in constant time, with
constant bandwidth demands per vertex, even in the
limit where the database becomes arbitrarily large. We
have also given a decentralized algorithm that allows a
network to self-organize into the proposed structure as
vertices join and leave, without the need for global plan-
ning or supervision. Indeed no part of the design requires
any centralized knowledge of the network, making the
network a true peer-to-peer network, in the sense of hav-
ing client nodes only and no servers. Another attractive
feature of the design is its simplicity: both the network
growth and search mechanisms are implemented using
random walkers, which can themselves be implemented
by message-passing on the network.

One important issue that we have neglected in our dis-
cussion is that of “supernodes” in the network. Because
the speed of previous search strategies has been recog-
nized as a serious problem for present peer-to-peer net-
works, designers of some networks have chosen to des-
ignate a subset of network vertices (typically those with
above-average bandwidth and CPU resources) as super-
nodes. These supernodes are themselves connected to-
gether into a network over which all search activity takes
place. Other client vertices then query this network when
they want a search performed. Since the size of the su-

8

pernode network is considerably less than the size of the
network as a whole, this tactic increases the speed of
searches, albeit only by a constant factor, at the ex-
pense of heavier load on the supernode machines. Such
a model is not necessary in our approach, since search
speed is already good and bandwidth demands are mod-
est, but it would nonetheless be elementary to general-
ize our approach to incorporate supernodes, were such a
thing desirable for some other reason. One would simply
give each supernode a directory of the data items stored
by the client vertices of its supernode neighbors. Then
searches would take place exactly as before, but on the
supernode network alone, and client vertices would query
the supernode network to perform searches. In all other
respects the mechanisms would remain the same.

Acknowledgments

The authors thank Lada Adamic for useful discussions.
This work was funded in part by the National Science
Foundation under grant number DMS–0405348 and by
the James S. McDonnell Foundation.

[1] M. E. J. Newman, SIAM Review 45, 167 (2003).
[2] S. Boccaletti, V. Latora, Y. Moreno, M. Chavez, and D.-

U. Hwang, Physics Reports 424, 175 (2006).

[3] S. N. Dorogovtsev and J. F. F. Mendes, Evolution of Net-
works: From Biological Nets to the Internet and WWW
(Oxford University Press, Oxford, 2003).

[4] M. E. J. Newman, A.-L. Barab´asi, and D. J. Watts, The
Structure and Dynamics of Networks (Princeton Univer-
sity Press, Princeton, 2006).

[5] T. Hong, in Peer-to-Peer: Harnessing the Beneﬁts of a
Disruptive Technology, edited by A. Oram (O’Reilly and
Associates, Sebastopol, CA, 2001), pp. 203–241.

[6] L. A. Adamic, R. M. Lukose, A. R. Puniyani, and B. A.

[8] J.

to-Peer Computing (IEEE Computer Society, New York,
2004), pp. 2–9.
P.

can’t
scale.
URL
http://www.darkridge.com/~jpr5/doc/gnutella.html.
[9] M. Ripeanu, I. Foster, and A. Iamnitchi, IEEE Internet

Gnutella

(2000),

Ritter,

really

Why

No,

Computing 6, 50 (2002).

[10] W. Aiello, F. Chung, and L. Lu, in Proceedings of the
32nd Annual ACM Symposium on Theory of Computing
(Association of Computing Machinery, New York, 2000),
pp. 171–180.

[11] M. E. J. Newman, Contemporary Physics 46, 323 (2005).
[12] C. Moore, G. Ghoshal, and M. E. J. Newman, Preprint

Huberman, Phys. Rev. E 64, 046135 (2001).

cond-mat/0604069 (2006).

[7] N. Sarshar, P. O. Boykin, and V. P. Rowchowdhury, in
Proceedings of the 4th International Conference on Peer-

