5
0
0
2
 
c
e
D
 
0
2
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
7
8
1
2
1
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Prisoner’s Dilemma cellular automata
revisited: evolution of cooperation under
environmental pressure

J. Alonso a , A. Fern´andez a and H. Fort b

a Instituto de F´isica, Facultad de Ingenier´ia, Universidad de la Rep´ublica, Julio
Herrera y Reissig 565, 11300 Montevideo, Uruguay.
bInstituto de F´isica, Facultad de Ciencias, Universidad de la Rep´ublica, Igu´a 4225,
11400 Montevideo, Uruguay.

Abstract

We propose an extension of the evolutionary Prisoner’s Dilemma cellular automata
introduced by Nowak and May [13], in which the pressure of the environment is
taken into account. This is implemented by requiring that an individual needs to
collect a score U above a threshold Umin, representing vital resources (nutrients,
energy, etc.). Thus agents, instead of evolving just by adopting the strategy of the
most successful neighbour (who got U msn), also take into account if U msn is above
or below Umin. Three diﬀerent model variants are considered: (1) If U msn < Umin an
organism has a probability of adopting the strategy that is the opposite of the one
used by its most successful neighbour; (2) similar to (1) but a cell can die leaving a
vacancy (that in the subsequent step may be occupied by another organism); (3) the
ordinary evolutionary recipe of copying the most successful neighbour supplemented
with a Pavlovian ”win-stay, lose-shift” criterion. In all the cases the modiﬁcations
allow the evolution of cooperation in payoﬀ regions where defection was the rule for
simple unconditional strategy players, as it happens when the diﬀerence between
the punishment for mutual defection and the sucker’s payoﬀ is large. The cluster
structure is analysed and, for one version of the model in a restricted region of the
parameter space, we found power-law scaling for the cluster size distributions and
perimeter vs. area curves.

Key words:
Complex adaptive systems, Agent-based models, Evolutionary Game Theory
PACS:

Preprint submitted to Elsevier Science

21 February 2014

1 Introduction

Cooperation among animals, either within or between species, is widespread
throughout nature [1]-[6]. This presents a puzzle for Darwinists since, accord-
ing to Darwin’s theory, the rule among animals should be competition, not
cooperation.

Attempting to understand the evolution of cooperation, Maynard Smith and
Price [7] applied game theory to interactions between competing individuals
of the same species that use diﬀerent strategies for survival. They found that
in situations like combat, in which each individual must decide whether or not
to escalate the ﬁght without knowing his opponent’s decision, the interests of
both combatants are best served if both decide not to escalate the ﬁght.

2 × 2 games (2 players making a choice between 2 alternatives), which showed
their usefulness in Economics and Social Sciences, consitute a basic tool to
model the conﬂict/cooperation situations in Biology [8].

In particular one of such games is the Prisoner’s Dilemma (PD), now well
established as a useful tool for studying cooperative interactions among self-
interested agents. The PD game comes from an experimental setup designed
by the researchers at the RAND Corporation M. Dresher and M. Flood. The
game refers to an imaginary situation in which two suspects are arrested near
the scene of a crime. The police don’t have enough evidence to convict the
pair on the principal charge. The two prisoners are held in separate cells and
oﬀered a deal: If one testiﬁes implicating the other in the principal crime
will go free, while the other, if remains silent, will receive 10 years in prison.
If they both testify against each other, each will receive 5 years. Finally, if
they both remain silent, they will both be convicted by a minor crime and
serve one year. What’s the rational choice for each prisoner? To remain silent
(cooperate with your partner) or to confess (not to cooperate)? The ”dilemma”
faced by the prisoners is that, whatever the other does, each is better oﬀ
confessing than remaining silent. But the outcome obtained when both confess
is worse for each than the outcome they would have obtained if both had
remained silent. This puzzle illustrates well a conﬂict between individual and
group rationality. A group whose members pursue rational self-interest may
all end up worse oﬀ than a group whose members act contrary to rational
self-interest. Formulated in its general form the PD game involves two players
each confronting two choices: cooperate (C) or defect (D) and each makes his
choice without knowing what the other will do. The possible outcomes for the
interaction of both agents are: 1) they can both cooperate: (C,C) and get the
”reward” for mutual cooperation R, 2) they can both defect: (D,D) and get the
”punishment” for mutual defection or 3) one of them cooperates and the other
defects: (C,D); in that case the one who played C gets the ”sucker’s payoﬀ”

2

S while agent who played D gets the ”temptation to defect” T . The following
payoﬀ matrix summarizes the payoﬀs for row actions when confronting with
column actions:

M =

(R, R)
(T, S)

(cid:18)

(S, T )
(P, P ) (cid:19)

,

with the four payoﬀs obeying the inequalities:

T > R > P > S
and
2R > S + T.

(1)

(2)

Clearly it pays more to defect: if your opponent defects, and you cooperate you
will end up with the worst payoﬀ. On the other hand, even if your opponent
cooperates, you should defect because in that case your payoﬀ is T which
is higher than R. In other words, independently of what the other player
does, defection D yields a higher payoﬀ than cooperation and is the dominant
strategy for rational agents. Nevertheless, reasoning that way both agents get
P which is worst than R.

A possible way out for this dilemma is to play the game repeatedly. In this
iterated Prisoner’s Dilemma (IPD), there are several strategies that outper-
form the dominant one-shot strategy [D,D] and lead to some non-null degree
of cooperation. The tournaments organized by Axelrod [9] [10] in the 80s were
very illuminating. He invited researchers from diﬀerent ﬁelds to contribute a
strategy, in the form of a computer program, to play the Prisoner’s Dilemma
against each other and themselves repeatedly. Each strategy speciﬁed whether
to cooperate or defect based on the previous moves of both the strategy and
its opponent. The programs were then ranked according to the total payoﬀ
accumulated. The winning program, was also the simplest: ’TIT FOR TAT’
(TFT), which plays C on the ﬁrst move, and on all subsequent moves copy
the choice of its opponent on the previous move. In an ecological approach
[11], the scores from round two were used to calculate the relative frequencies
of the strategies in a hypothetical population. The strategies were then sub-
mitted to each subsequent round in proportion to their cumulative payoﬀ in
the previous round. In the long run, TFT outcompeted its rivals and went to
ﬁxation. Axelrod and Hamilton [10] used these ecological competition between
strategies as a basis for their analysis of the evolution of reciprocal altruism.
This model is applicable in two opposite situations: On the one hand, in the
case of higher animals, which can distinguish between their various opponents
in order to reciprocate [12]. Otherwise an individual which met defection from

3

one opponent would defect against others, and the result would soon be gen-
eral defection. On the other hand, in the case of very simple organisms who
have only one opponent in its lifetime.

Nowak and May [13] found another way to escape from the dilemma: the in-
corporation of territoriality in evolutionary game theory favours cooperation.
The authors proposed simple cellular automata (CA) for general ecological
systems involving undiscriminating organisms who play against several oppo-
nents (their neighbours). They neglected all strategical complexities or mem-
ories of past encounters considering a cellular automaton in which each cell
is either in a C or D state and plays repeatedly with its neighbours. In the
next generation, an individual cell adopts the state of the most successful cell
of the neighbourhood (the one that collected the highest payoﬀ among the
cell itself and its neighbours). Coexistence of both states or behaviours were
found for a simpliﬁed version of the PD in which the punishment P is equal
to (or slightly greater than) the sucker’s payoﬀ S 1 , implying then a ”weak
dilemma” (maximum punishment). Taking R = 1 and P = S = 0 allows to
parameterise the payoﬀ matrix in terms of just one parameter T . Szab´o and
T¨oke [14] slightly modiﬁed this model with the addition of randomness: play-
ers are chosen to update their states randomly by copying the state of one
of its neighbours with a probability depending on the payoﬀ diﬀerence. They
measured the fraction of cooperators c for diﬀerent values of the temptation
to defect T and found a continuous transition from c = 1 to c = 0 as T in-
creases. A problem with these simple spatial games is that if P is augmented
until it becomes comparable to the reward R (say P = 0.5 ) then cooperation
disappears and all the individuals end playing D. Spatial evolutionary games
involving more sophisticated players, with m-steps memory and strategies in-
volving conditional probabilities, were studied by Lindgren and Nordahl [15].
They considered payoﬀ matrices parameterised in terms of two parameters,
T /R and P/R (S = 0), and found the evolution of cooperation for payoﬀ
matrices not restricted to ”weak” dilemmas.

In the present work we analyse how the evolution of cooperation can be pre-
served even though when the punishment P is relatively soft (P >> S) for
the simplest unconditional cellular automata i.e. agents using unconditional
strategies 2 , without the ability to distinguish opponents, without long term
memory, etc. The basic idea is that individuals need to collect, when play-
ing with their z neighbours, a payoﬀ above certain threshold Umin in order

1 Indeed this is the frontier between the PD game an another interesting game,
called chicken by game theorists and Hawk-Dove (H-D) game by evolutionary bi-
ologists, in which the punishment for mutual defection is the worst payoﬀ i.e.
T > R > S > P .
2 As opposed to the conditional ones like TFT, the simpleton [16] or PAVLOV [17]
”win-stay, lose-shift”, etc.

4

to survive. In an ecosystem Umin represents the minimal resources (nutrients,
energy, etc.) without which organisms die. Thus, even though for the diﬀer-
ence between P and S suﬃciently large the most successful individuals are the
ones who play D, when Umin > z(P − S) they cannot survive surrounded by
an entire neighbourhood of D’s and some of them are replaced by C players.
We use a normalized payoﬀ matrix with R = 1 and S = 0. Besides the 3
parameters: Umin, T and P we include a probability p for players of copying
the behaviour of the most successful neighbour (depending if their utilities
are above or below Umin). We explore a subspace of the space of parameters
{T, P, Umin, p} measuring the fraction of cooperators and quantities charac-
terizing the cluster structure. We also discuss the diﬀerent model variants and
compare their results.

2 The model and its variants

The players, which are represented by cells of a two dimensional automaton,
can follow only two unconditional strategies when playing with their neigh-
bours: cooperate (C) or defect (D). In this work we restrict ourselves to a) the
von Neumann neighbourhood (z = 4 neighbour cells: the cell above and below,
right and left from a given cell) and b) the Moore neighbourhood (z = 8 neigh-
bour cells surrounding a given cell). Typical grid sizes range from 50 × 50 to
500 × 500. Periodic boundary conditions are used. The total payoﬀ of a given
player is the sum of all the payoﬀs he gets against each neighbour. Tables 1 and
2 summarize the diﬀerent payoﬀs for a player depending on the number of C’s
and D’s in its neighbourhood (except for the case of the second model variant
where the number of D agents is not the complement of the number of C’s).
The dynamic is synchronous: all the agents update their states simultaneously
at the end of each lattice sweep.

4C, 0D 3C, 1D 2C, 2D 1C, 3D 0C, 4D

C

D

4

4T

3

2

1

3T + P 2T + 2P T + 3P

0

4P

Table 1
payoﬀ of a player depending on its state C(row 1) or D (row 2) and the number of
C and D agents in its neighbourhood for the z = 4 case.

In the CA of ref. [13] natural selection is implemented very simply: each player
adopts the strategy of the most successful neighbour (who got U msn).

Here, we consider three diﬀerent possible variants:

(1) Basic version: Conditional copying the most successful neighbour.

5

8C, 0D 7C, 1D 6C, 2D

5C, 3D

4C, 4D

3C, 5D

2C, 6D 1C, 7D 0C, 8D

C

D

8

8T

7

6

5

4

3

2

1

7T + P 6T + 2P 5T + 3P 4T + 4P 3T + 5P 2T + 6P T + 7P

0

8P

Table 2
The same as Table 1 but for z = 8 neighbours.

If U msn > Umin,then the player adopts the strategy of the most success-
ful neighbour in the next generation. Otherwise, the player has a small
probability p of adopting the opposite strategy. The rationale for this
is that copying the most successful neighbour, when its payoﬀ doesn’t
reach a critical threshold, may not be the most eﬃcient strategy from an
evolutionary point of view.

(2) Version 1 + death of organisms

This variant includes the possibility of some cells remaining unoccu-
pied. The rules are the same as above except that in the case when
U msn < Umin, instead of adopting the strategy of the most successful
neighbour, the player dies with probability 1−p leaving an empty cell. An
empty cell updates its state copying the one of its most successful neigh-
bour with probability 1 − p and the opposite strategy with probability p.
Finally, an empty cell surrounded by empty cells remains unoccupied in
the next round.

(3) Hybrid version: natural selection complemented with a Pavlovian crite-

rion

A relevant input to produce an eﬃcient behaviour update rule is the
comparison of the individual payoﬀ with Umin. If it is above Umin then
the agent’s behaviour may be worth keeping even if it is not the most
successful in the neighbourhood. Then we implement this variant as fol-
lows: If U msn > Umin there are two alternatives, depending whether the
individual payoﬀ U is above or below Umin. In the former case the cell
copies the state of its most successful neighbour with probability p (equiv-
alently it remains in its state with probability 1 − p). In the latter case
the cell does the opposite: it copies the state of the most successful neigh-
bour with probability 1 − p (remains in its state with probability p). On
the other hand, if U msn < Umin the cell copies the opposite state of its
most successful neighbour with probability 1 − p (otherwise remains in
its state).

Therefore, this variant interpolates between the ordinary evolutionary
recipe of copying the most successful neighbour adopted in [13] and the
”win-stay, lose-shift” criterion of the game considered by Herz [18].

6

3 Results

It turns out that, for the diﬀerent variants of the model, the system reaches a
steady state with a deﬁnite value c for the fraction of agents playing C after
a transient. The duration of the transient depends on the lattice size and the
neighbourhood. For instance for a 50 × 50 lattice and z = 8 it last typically
between 100 and 200 rounds.

To avoid dependence on the initial conditions, the measures correspond to
averages over an ensemble of 100 systems with arbitrary initial conditions.

Here, we present results for a subspace of the parameter space {T, P, Umin, p}.
We choose deﬁnite values for the punishment P and the probability parameter
p, speciﬁcally: P = 0.5 3 and p = 0.1. The temptation parameter T is varied
between 1 and 2. Umin < zP has no eﬀects; on the other hand Umin > zT
doesn’t make sense since no one can reach this threshold. Thus, the parameter
space reduces to the square plane T − Umin delimited by 1 ≤ T ≤ 2 and
zP ≤ Umin ≤ zT .

3.1 Frequency of cooperators

The asymptotic (after a transient) fraction of cooperator agents c was com-
puted for a grid of points in the T -Umin plane using lattices of relatively modest
size: 50 × 50. Similar results hold for 100 × 100 lattices or bigger.

Figures 1.a and 1.b corresponding to the ﬁrst model variant show a similar
dependence on frequency of cooperators with T and Umin. Note that, when
Umin > zP , the fraction of cooperators raises from zero to a non negligible
value regardless of the value of T 4 . The explanation of this is simple: a D
agent surrounded by D’s get a payoﬀ zP that is below the surviving threshold,
and thus has a probability p of becoming C in the next round. Basically three
regions can be distinguished in the plots:

• A stepladder region emerges from the right border Umin = zP .
• For not too large values of T and Umin there is a high peak of cooperation,

delimited at the left by Umin = zR = z (when all the cells play C).

• Finally, beyond Umin = zR = z c reaches a plateau delimited by the straight
line Umin(T ) = zT (Umin greater than zT is an unreachable score in the game
we are considering).

3 This value of the punishment implies a non weak dilemma and, both for z = 4 or
z = 8, leads to c = 0 when simulating the model of ref. [13].
4 At least in the considered T interval: 1 < T < 2.

7

(a)

(b)

c

1
0.8
0.6
0.4
0.2
0
8

1
0.8
0.6
0.4
0.2
0
16

c
1

1.5

6

4

Umin

2

2

0

T

12

8

Umin

4

2

0

1

1.5

T

Fig. 1. Asymptotic frequency of cooperators for the simplest model, for p = 0.1, (a)
z=4 neighbours and (b) z=8 neighbours.

To understand the 3 diﬀerent regions it is useful to consider a small deviation
from the minimum T : T = 1 + ǫ. Therefore, for z = 8 and P = 0.5 the Table
2 becomes the Table 3.

8C, 0D 7C, 1D 6C, 2D 5C, 3D 4C, 4D 3C, 5D 2C, 6D 1C, 7D 0C, 8D

C

8

7

6

5

4

3

2

1

D 8.0 + 8ǫ

7.5 + 7ǫ

7.0 + 6ǫ

6.5 + 5ǫ

6.0 + 4ǫ

5.5 + 3ǫ

5 + 2ǫ

4.5 + ǫ

0

4

Table 3
Same as Table 2 for T = 1 + ǫ, P = 0.5

Let’s start with the peak. For Umin greater than 6, only D’s surrounded by at
least 4 C’s can achieve the minimum Umin, so cooperation grows dramatically.
This corresponds to ǫ <∼ 0.16, (i.e. T <∼ 1.16). When Umin = 8 c drops abruptly
since even C agents surrounded entirely by other C’s cannot survive anymore.

The stepladder structure can be easily explained considering the payoﬀ values
for D agents shown in Tables 1 and 2. As long as Umin increases each D agent
needs more C agents in its surroundings in order to achieve the threshold.
So cooperation grows with Umin by steps at the values mentioned before:
Umin = T + 7P , Umin = 2T + 6P and so on, which correspond to straight
lines with diﬀerent slopes in the (T, Umin) plane . Finally, when Umin > 8T
the minimum required is above any agent’s possible score, then the fraction
of agents C one time step further will be given by

c(t + 1) = pfD + (1 − p)fC,

(3)

8

where fD stands for the fraction of agents (C and D) whose most successful
neighbour is a D and fC is the fraction of agents (C and D) whose most suc-
cessful neighbour is a C. As none of the agents achieves the threshold, the
state of all of them is updated with probability p to the opposite state to that
of each one’s most successful neighbour. For small values of p, fC ≈ 0 (since a
C agent needs to be surrounded by a minimum number of C agents to be the
most successful), fD ≈ 1 and ﬁnally c ≈ p. This explain why the height of the
plateau coincides with the probability p 5 .

The landscape that emerges from the second model variant (see Fig. 2.a and
Fig. 2.b) is very similar to the one produced by the ﬁrst variant.

(a)

(b)

c

1
0.8
0.6
0.4
0.2
0
8

1
0.8
0.6
0.4
0.2
0
16

c

1

1.5

1

1.5

6

4

Umin

2

2

0

T

12

8

Umin

4

2

0

T

Fig. 2. Asymptotic frequency of cooperators for the empty cells variant, for p = 0.1,
(a) z=4 neighbours and (b) z=8 neighbours; frequency is normalized by the total
number of cells (including empty the empty ones)

On the other hand, the hybrid model variant gives rise to dramatic modiﬁca-
tions in the landscape shown in Fig. 3.

Firstly, we observe a strong increase in c for all the parameter space surround-
ing the peak zone. In particular, note the height of the plateau and the steep
formation. Secondly, most part of the plateau is replaced by steeply ”cliﬀs”.

For this version, when Umin > 8T the equation 3 is replaced by

c(t + 1) = (1 − p)fD + pc(t).

(4)

5 Besides p = 0.1, we checked this also for p = 0.2 and p = 0.3

9

(a)

(b)

c

1
0.8
0.6
0.4
0.2
0
8

1
0.8
0.6
0.4
0.2
0
16

c
1

1.5

1

1.5

6

4

Umin

2

2

0

T

12

8

Umin

4

2

0

T

Fig. 3. Asymptotic frequency of cooperators for the hybrid variant, for p = 0.1, (a)
z=4 neighbours and (b) z=8 neighbours.

Hence, in the steady state we have the solution c = fD.

3.2 Cluster structure

In this subsection we analyse the cluster structure and spatial patterns in the
three diﬀerent regions of the plane T − Umin identiﬁed in the previous sub-
section. We restrict to the hybrid model for the z = 8 Moore neighbourhood,
since this variant is the one that exhibits more clear cut results. In addition,
this variant is the one that shows a greater richness in the c landscape (see Fig.
3). Hence we present the results from measures at four representative points in
the T −Umin plane: (a) [T =1.5,Umin=11.9] belonging to the plateau (c ≃0.75),
(b) [T =1.06,Umin=6.9] belonging to the peak (c ≃0.91), (c) [T =1.2,Umin=5.5]
at the side of the peak (c ≃0.5) and (d) [T =1.6,Umin=7.5] belonging to the
stepladder region (c ≃0.4).

For [T =1.5,Umin=11.9], although fraction of cooperators is stable the spatial
patterns change constantly as a consequence of the transition rules. One of
these patterns is showed in ﬁgure 4.a For [T =1.06,Umin=6.9], giant stable
clusters dominate the lattice as expected from the high level of cooperation in
that region as shown in ﬁgure 4.b At the side of the cooperation peak there
are spatial stable structures of clusters with a characteristic size as the ones of
ﬁgure 4.c. When we move away from the peak into the region bounded between
2T + 6P and 3T + 5P scale invariance emerges: clusters of all size occur as
can be seen from ﬁgure (4.d) for T = 1.6 and Umin = 7.5. In this case we are

10

Fig. 4. Cooperation maps after transient for the hybrid variant with z = 8 for
(a)T = 1.5, Umin = 11.9 (b)T = 1.06, Umin = 6.9 (c)T = 1.2, Umin = 5.5
(d)T = 1.6, Umin = 7.5 and p = 0.1, black cells correspond to C and white cells to
D. The mean frequency of cooperators corresponding to this maps are (a)c = 0.75
(b)c = 0.91 (c)c = 0.50 (d)c = 0.40.

in presence of constantly changing spatial patterns again. Histograms of the
size distribution of clusters for the four above points in the T − Umin plane
are shown in ﬁgure 5. Note that 5.d clearly shows a power law distribution
with exponent −1.6357 ± 0.0001. Power laws are the signature of organisation
into a critical state. It indicates that the system exhibits the highest pattern
of diversity: there are few large structures and many smaller clusters. This
power-law scaling emerges only for a very reduced region in the plane plane
T − Umin in the vicinity of the point [T = 1.6, Umin = 7.5] 6 . In that sense
this scale-free behaviour seems more to ordinary critical phenomena, where
a ﬁne-tuning of the control parameters is required, than to the much more
robust self-organized criticality (SOC).

Besides the size distribution of clusters, the relationship between the perimeter
and the area of the clusters provides useful information on their geometry. The
area A of a cluster is the number of all connected cells with a given strategy
(C or D) and its perimeter ℓ is deﬁned as the number of cells that form its
boundary (those cells of the cluster with at least one neighbour not belonging

6 For the other two variants no power-laws were found.

11

(b)

−2

10

−4

10

−6

10

)
 
y
c
n
e
u
q
e
r
f
 
(
g
o

l

−8

10

0
10

0
10

)
 
y
c
n
e
u
q
e
r
f
 
(
g
o

l

−5

10

−10

10

0
10

(a)

−5

10

)
 
y
c
n
e
u
q
e
r
f
 
(
g
o

l

−6

10

−7

10

−8

10

0
10

10

10

(c)

0
10

)
 
y
c
n
e
u
q
e
r
f
 
(
g
o

l

−5

10

5
10
log( cluster size )

5
10
log( cluster size )

10

10

(d)

log( cluster size )

log( cluster size )

5
10

−10

10

0
10

4
10

Fig. 5. Dependence of the number of C clusters with size for the hybrid variant with
z = 8 for (a)T = 1.5, Umin = 11.9 (b)T = 1.06, Umin = 6.9 (c)T = 1.2, Umin = 5.5
(d)T = 1.6, Umin = 7.5 and p = 0.1. Measures were performed on a 500× 500 lattice
and clusters sampled over 100 generations after transient.

to it). We compute the mean perimeter ℓ(A) for a given area A averaging over
all the perimeters of clusters with given area A. Plots of ℓ vs. A for the four
T, Umin points treated before are shown in ﬁgure 6.

For the case depicted in ﬁgure 6.d (which corresponds to a power law in size
distribution as shown in ﬁgure 5.d) the mean perimeter scales linearly with the
area. So again we have for this region of the T − Umin plane another power-law
scaling. From this linearity it follows that the ratio of perimeter to interior
becomes independent of the cluster size. The coeﬃcient of the line ℓ(A) is
0.8369 ± 0.0001. which is much greater than the 0.5 expected for clusters with
a regular geometry. This is an indicator of the ramiﬁed structure of clusters
(see ﬁgure 4.d).

4 Discussion

We have shown how cooperation among self-interested individuals can emerge
from evolution in PD games, involving quite arbitrary payoﬀ matrices, us-
ing the simplest possible agents: unconditional strategists, without long term

12

4
x 10

(a)

4
x 10

(b)

1
area

2
5
x 10

(c)

0

1

2

area

4
x 10

3
5
x 10

(d)

8

6

4

2

0

6

4

2

r
e
t
e
m

i
r
e
p

r
e
t
e
m

i
r
e
p

15

10

5

r
e
t
e
m

i
r
e
p

2000

1500

1000

500

r
e
t
e
m

i
r
e
p

0

0

0

0

2000
area

4000

0

0

2

area

4

6
4
x 10

Fig. 6. The perimeter ℓ plotted as a function of cluster area A for the hybrid variant
with z = 8 for (a)T = 1.5, Umin = 11.9 (b)T = 1.06, Umin = 6.9 (c)T = 1.2,
Umin = 5.5 (d)T = 1.6, Umin = 7.5 and p = 0.1. Measures were performed on a
500 × 500 lattice and clusters sampled over 100 generations after transient.

memory and without distinguishing ”tags”. This allows the applicability of
the model to a wide variety of contexts from natural to social sciences.

The main idea was to include the inﬂuence of the environment exerting pres-
sure on individuals to cooperate even when the punishment for defecting is
relatively soft. This is done by requiring a minimum score Umin necessary
for agents to carry on vital functions. This recipe works for arbitrary pay-
oﬀ matrices provided the threshold Umin is grater than zP . An indication
of the robustness of the model is that the three explored variants produce,
qualitatively, the same main results. In particular, for moderate values of the
temptation to defect T , there is an intermediate range of values of Umin that
maximises cooperation among self-interested agents producing a high peak of
cooperators.

It is worth remaking that the supplementation of the ordinary evolutionary
recipe of copying the most successful neighbour with a Pavlovian ”win-stay,
lose-shift” criterion has two relevant eﬀects. The ﬁrst is global optimisation
i.e. it gives rise to a much higher cooperation level. The second is the emer-
gence of power-laws in the size distribution and perimeter-size relationship for
clusters of C agents. Power-laws were also found in a diﬀerent study of cellu-

13

lar automata playing the PD game with Pavlovian strategies [19]. However, in
that case, this scaling behaviour is a much more robust result than the one we
found here which holds only for quite reduced region in the T − Umin plane.

To conclude, we envisage some future extensions of this model. For instance to
explore the eﬀect of heterogeneities, in the environment (a landscape depen-
dent Umin function) or in the agents (diﬀerent payoﬀ matrices, diﬀerent types
of individuals, etc.). In addition, the spatial networks observed in nature are in
general not uniform square lattices like the ones considered here. So, another
interesting direction that seems worth studying is to consider more realistic
network topologies, for example scale free [20] or small worlds networks [21].

References

[1] Augros, R. and Stanciu G. The New Biology. Boston, London: New Science

Library, (1987).

[2] L. A. Dugatkin, Cooperation in Mammals I : Nonprimates In Cooperation
Among Animals, An Evolutionary Perspective (Oxford University Press 1997),
pp. 111-113.

[3] L. Dugatkin, Cheating Monkeys and Citizen Bees: The Nature of Cooperation

in Animals and Humans (New York: Free Press 1999).

[4] J. Stewart, EVOLUTION’S ARROW: The direction of evolution and the future

of humanity, (The Chapman Press, Canberra, Australia 2000).

[5] J. Maynard-Smith, and E. Szathmary, The Major Transitions in Evolution

(Oxford University Press 1997).

[6] J. Maynard-Smith, and E. Szathmary, The Origins of Life From the Birth of

Life to the Origin of Language (Oxford University Press 1999).

[7] J. Maynard-Smith and G. Price, The Logic of Animal Conﬂict, Nature (London)

146 (1973) 15.

1982).

(1981) 1390-1396

1396

[8] J. Maynard-Smith, Evolution and the Theory of Games, (Cambridge Univ. Press

[9] R. Axelrod, in The Evolution of Cooperation, (Basic Books, New York, 1984);

[10] R. Axelrod and W. D. Hamilton, The evolution of cooperation. Science 211:

[11] R. Axelrod, J. of Conﬂict Resolution 24 (1980) 379. Science 211: (1981) 1390-

[12] K. Sigmund, On Prisoners and Cells, Nature 359 (1992) 774.

14

[13] M.A. Nowak and R. May, Nature 359 (1992) 826.

[14] G. Szab´o and C. T¨oke, Phys. Rev. E58 (1998) 69.

[15] K. Lindgren and M. G. Nordahl, Evolutionary dynamics of spatial games,

Physica D 75 (1994) 292-309.

[16] A. Rapoport and A. M. Chammah, Prisoner’s Dilemma (The University of

Michigan Press 1965) pp. 73-74.

[17] D. Kraines and V. Kraines, Pavlov nd the Prisoner’s Dilemma, Theory Decision

26 (1988) 47-79.

[18] A. V. M. Herz, Collective Phenomena in Spatially Extended Evolutionary

Games, J. Theor. Biol. 169 (1994) 65-87.

[19] H. Fort and S. Viola, Spatial patterns and scale freedom in Prisoner’s Dilemma
cellular automata with Pavlovian strategies, J. Stat. Mech. (2005) P01010.

[20] A. Barab´asi and R. Albert Emergence of Scaling in Random Networks, Science,

286 (1999) 509-512.

Nature 393 (1998) 440-442.

[21] D. Watts and S.H. Strogatz, Collective dynamics of smallworld networks,

15

