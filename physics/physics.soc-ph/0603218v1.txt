Self-Assembly of Information in Networks

M. Rosvall1,2∗ and K. Sneppen2
1)Department of Theoretical Physics, Umeå University, 901 87 Umeå, Sweden
2)Niels Bohr Institute, Blegdamsvej 17, Dk 2100, Copenhagen, Denmark†
(Dated: February 2, 2008)

We model self-assembly of information in networks to investigate necessary conditions for building a global
perception of a system by local communication. Our approach is to let agents chat in a model system to self-
organize distant communication-pathways. We demonstrate that simple local rules allow agents to build a
perception of the system, that is robust to dynamical changes and mistakes. We ﬁnd that messages are most
effectively forwarded in the presence of hubs, while transmission in hub-free networks is more robust against
misinformation and failures.

6
0
0
2
 
r
a

M
 
6
2
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
8
1
2
3
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

PACS numbers: 89.75.-k,89.70.+c,89.75.Hc

Communication is essential in systems ranging from hu-
man society to mobile telephone- and computer networks. It
enables parts of a system to build a global perception, and
thereby makes it possible for these parts to overcome the
information horizon[1, 2, 3] set by their immediate neigh-
bors. We mimic real-world situations to investigate what lim-
its the local generation of this global perception of the net-
work from multiple communication events. Our approach is
to let agents chat in a model system to self-organize distant
communication-pathways, and thereby make use of the typ-
ical small-world properties of networks[4]. We investigate
the necessary conditions for building a global perception, and
demonstrate that simple local rules allow agents to build a per-
ception of the system that is robust to dynamical changes and
mistakes. In this minimalistic model, we ﬁnd that messages
are most effectively forwarded in the presence of hubs with
funnelling[5], like in scale-free networks, while transmission
in hub-free networks is more robust against misinformation
and failures.

To visualize our basic approach we illustrate in Fig. 1 the
rules of communication in a network composed of individual
agents, each of them connected to a number of acquaintances.
Each individual communicates with its immediate neighbors
in order to exchange information about agents in other parts of
the system. In this way every individual gradually builds up a
global perception by knowing people through people[7]. This
can be modeled in terms of agents having information about
the position of other agents in the system. In our minimalistic
model, we allow each agent to have information about which
of its neighbors that connects most efﬁciently to each of the
other agents in the system. Thus, a perfectly informed agent
will know which direction to send a message to any other
If all agents were perfectly informed,
agent in the system.
any message would be reliably forwarded from sender to re-
cipient, using the information of the subsequent agents along
its paths. Through these communications, agents create a sim-
plistic routing protocol, related to the pro-active protocols for
mobile networks[8]. This is a routing procedure that, in its
simplest form, only requires agents to know to whom to trans-
fer information[5, 9]. Our approach opens up for schematic
modeling of self-assembly of information in a variety of sys-

FIG. 1: (Color online) Self-assembly of information as modeled in
this paper. Agents at nodes communicate with their acquaintances
about any third target agent in the network, and estimate the quality
of the information by its age. Here, agent A learns that B has newer
information about H, disregards its old information, and change its
pointer associated to H from C to B. The three memory bubbles from
left to right, the information about H of A before and after the com-
munication event, and the information about H of B represent: The
target agent (top), the age of the information (middle), and the ac-
quaintance that provided the information (bottom). Every agent has
a corresponding perception for all other agents in the network.

tems, including social systems.

The key question is how different communication rules of
the agents inﬂuence their possibility to obtain a reliable per-
ception of the network. Obviously, if the two acquaintances A
and B in Fig. 1 just exchange information about the possible
directions to a target, say agent H, they may agree or disagree,
but cannot decide which information is best. As a result, the
correct information is not transmitted, and no coherent per-
ception can emerge. The agents need some index of quality
that let them judge who has the best knowledge. One option
is that each agent both have a pointer (the acquaintance that
provided the information) and an estimate of the number of

y
t
i
l
a
u
q
n
o
i
t
a
m
r
o
f
n
I

1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0

(a)

0

(b)

0

Directionality

Reliability

10

20

10

Time

20

FIG. 2: (Color online) The quality of the self-assembled informa-
tion. The reliability (ﬁlled curve), is the fraction of messages that
reach their targets guided by the agents’ pointers . The directionality
(black line), is the fraction of pointers that points to an acquaintance
that is closer to the target agent than the agent itself The time unit is
N communication events per agent. The network perception devel-
ops from complete absence of information at time 0. The quality of
the self-assembled information is in (a) estimated by distance and in
(b) by time. At time 10 and time 20, all links are completely reshuf-
ﬂed. The agents thereby get wrong perception, but the reliability is
recovered within a few time units in the time-based update in (b), but
not in the distance-based update in (a). The simulation is performed
on a connected Erd˝os-Rényi network [16], with N = 1000 nodes
and L = 2000 links.

intermediates there are on the information path to the target
agent H [10]. In social systems this can be motivated by the
observation that knowledge of a person is related to the short-
est path[1]. For example, if two acquaintances communicate
about a third agent, the agent with the longer distance esti-
mate simply adopts the view of its acquaintance. The agent
change the information about the target agent, sets its pointer
to the acquaintance and its distance estimate to the acquain-
tance’s estimate plus 1. With this method all agents obtain
perfect knowledge of both directions and distance in any type
of statically connected network, see Fig. 2(a).

The use of distances as quality of information about direc-
tions has some important costs. In particular, we found that if
someone somewhere gives wrong information and provides a
distance that is smaller than the real one, this misinformation
will overrule the correct information and lead to permanent
damages. The method is exact to the price of not being robust
to any structural changes (or other sources of wrong informa-
tion), see Fig. 2(a).

We therefore introduce another way of validating informa-
tion to mimic systems that should be robust to dynamical
changes: The age of the information about a target agent, say
agent H in Fig. 1. When an acquaintance of H obtains infor-

2

mation about H, it sets its pointer to H, and the information
starts aging. With successive communication events, the in-
formation spreads from agent to agent and gets older and older
(we increase the age of all information when all links on av-
erage have participated in one communication event). When
two agents compare the validity of their pointers to a target
agent, like A and B to H in Fig. 1, they validate the newest
information as the most correct one.

Figure 2(b) shows the quality of the self-assembled infor-
mation. The result was obtained by putting 1000 agents with-
out any prior information on a connected Erd˝os-Rényi net-
work [16], followed by successive communication events: A
randomly chosen link connects two agents that communicate
about a third randomly chosen target agent. The communica-
tion rules make the agents point in the direction of the fastest
communication path from a target, and we only use the short-
est path as a benchmark. The directionality is the fraction of
all pointers for all agents that points to an acquaintance that
is closer to the target agent than the agent itself. The direc-
tionality never reaches 100%, because some paths between
two agents are updated faster than the shortest path. The mes-
sage paths depend on the communication activity and ﬂuctu-
ate with time, but anyway stay fairly close to the shortest paths
(see Fig. 4(b) and Java-simulation [11]). To investigate the re-
liability of such forwarded messages, we selected all possible
combinations of pairs of agents as sources and targets, and
released messages at the sources. The reliability in Fig. 2(b)
shows that 100% of the messages reached their targets guided
by the agents’ pointers along the paths (when the information
was recovered). The main feature of this time-based update is
that the agents forget old mistakes, and that their network per-
ception recovers completely after reshufﬂing of the links (see
Fig. 2(b)). We ﬁnd that the reliability is insensitive to network
topology or details in the model, but that the recovery and the
communication paths depend on communication habits.

In implementing the communication model we also spec-
ify how often different nodes are selected for communication.
Above we did so by simply assuming that persons with many
connections were more active in communication (by choosing
a random link). This will be referred to as link limited com-
munication, LL, in contrast to the case where each node is
equally active, denoted node limited communication, NL. In
Fig. 3, we illustrate how individual nodes use communication
to build up a perception of the surrounding network (this is
visualized by letting the agents transfer the full path to the tar-
get node at each communication event, see also simulation at
[11]). This can also represent the spread of information about
individual nodes in initially non-informed networks. We use
a scale-free (SF) network as an extreme, yet realistic [12, 13],
example of networks with hubs, and an Erd˝os-Rényi (ER) net-
work as an example of networks without hubs[16]. The upper
two sequences in Fig. 3 illustrate the information spreading
around, respectively, a hub node, and a single-linked node.
We see that hubs most rapidly gain information about a large
part of the network [7]. The third sequence illustrates infor-
mation spreading in a network without hubs. The dynamic

0.5

Time

1

2

∞

(a)

(b)

d
e
t
i

i

m
L
k
n
i
L

d
e
t
i

i

m
L
e
d
o
N

e
e
r
f

e
l
a
c
S

i
y
n
é
R

-
s
˝o
d
r
E

e
e
r
f

e
l
a
c
S

i
y
n
é
R

-
s
˝o
d
r
E

FIG. 3: (Color online) Initial spread of information. The black parts
of the network show paths which are known by the red-marked agent.
As time progresses the red agent builds its perception until com-
plete coverage of all nodes (not all links) in the network. The up-
per panel investigates a setup where each agent communicates with
a frequency proportional to its connectivity (LL), whereas the lower
panel shows the more restricted case where each agent communicate
equally much (NL). To explore the effects of well connected agents,
we compare scale-free with Erd˝os-Rényi networks (N = 100 nodes
and L = 160 links), and hub nodes with peripheral nodes. An inter-
active Java simulation is available online [11].

advantage of scale-free networks, with faster self-assembly of
information, is closely associated to the higher communica-
tion activity of hubs (funneling, see [5]). In the node limited
version, where each agent communicates equally much, the
advantages of hubs are severely reduced.

We now turn to how messages are transmitted in the model
networks with varying degree of false information (Fig. 4).
We parametrize noise in terms of dynamically changing net-
works, where pairs of links are swapped [15] at different
“boiling” rates. A directed message might get trapped in a
closed loop, because the pointers are not always updated. Fig-
ure 4(a) shows the reliability of forwarded messages in net-
works with hubs (SF) and without hubs (ER) for communica-
tion limited to, respectively, links (LL) and nodes (NL). We
see that the communication habits do not affect the perfor-
mance on the hub-free Erd˝os-Rényi network. With, and only
with the large communication ability of hubs (LL), scale-free

3

)
l

(D
h
t
g
n
e
l
h
t
a
p

s
s
e
c
x
E

103

102

101

100

1

0.8

y
t
i
l
i
b
a
i
l
e
R

0.6

0.4

0.2

SF

ER

LL

NL

0
10−4

10−2
10−4
Noise (link swaps/communication event)

10−2

100

100

FIG. 4: (Color online) The ability to self assemble information in a
noisy environment. The unit of noise is one link swap[15] per com-
munication event. As in Fig. 2 we in (a) show the reliability of for-
warded messages, here for a scale-free (SF) and an Erd˝os-Rényi (ER)
network with communication limited to, respectively, links (LL) and
nodes (NL). The network size is N = 1000 nodes and L = 2000
links and the scale-free network is generated with the degree distribu-
tion P (k) ∝ k−2.4 with the method suggested in[14]. ∆l/N in (b)
is the average excess path length of forwarded messages compared
to the shortest path length between agents.

networks provide the most reliable communication.

In Fig. 4(b), we go one step further and investigate the
excess path length ∆l of messages, by comparing with the
shortest-path length between agents. Again we choose all pos-
sible combinations of source and target agents. To avoid being
trapped in closed loops, we here let the messages step to a ran-
dom acquaintance when it reaches an agent the second time
between a source and a target agent. Obviously ∆l increases
with increasing noise level. However, and more importantly,
at a wide range of boiling rates, ∆l for scale-free networks is
substantially larger than ∆l for networks without hubs. Scale-
free networks are less robust signal transmitters than networks
without hubs. Hubs are sometimes efﬁcient, but they tend to
accumulate mistakes, and are not necessary to provide short
paths [20]. Contrary, networks without hubs provide many
alternative short paths.

The social implications of our model may be illustrated
through an analogy to Milgram’s famous experiment where
letters were transmitted by sequences of person-person con-
tacts across USA[5, 17]. The surprising result was that the
letters, that actually arrived, only used a few intermediate con-
tacts. Since the dimension in social networks is high[18], the
non-trivial result was not that short paths existed, but that
they were found in the experiment. The accepted explana-
tion is, again that world is small[4, 18], and that people use
geographic closeness of the acquaintance to the target (ﬁrst
steps) and similarity of occupation (later steps) to forward
messages[9, 20, 21, 22]. This is in overall accordance with our
scenario where messages that arrive typically use short paths,
and where any serious deviation leads to much longer paths

and in practice to lost messages. Obviously, one could add a
number of layers to our minimalistic model [11], including in
particular: Geographic closeness, social identity, and interest
spheres[9, 20, 21, 22], strength of links [23], and information
decay [24] or dropouts at the passage of messages[17, 25]. In
any case, we found that our simple interaction rules give a per-
ception that is enough to overcome the information horizon[1]
set by immediate acquaintances. It is a framework for further
exploration and a possible bridge between network theoretical
approaches [4, 19] and experiments [17, 20, 25].

Social as well as many modern information networks are
highly complex.
In addition to the dynamical characteris-
tics of both the local properties and the global organization,
they also have a complex interplay. Nevertheless, the systems
should have the ability to self-organize their locally available
information such that messages can be guided between distant
parts of the network. To study such self organization, we have
presented a generic framework that also is open for a direct ex-
tension to networks where the capacity of links or nodes vary
with time. When some pathways are temporarily occluded by
congestion[26] or malfunction[27], the local chatting allows
the system to adapt dynamically to the new situation and sub-
sequently transmit messages along other fast pathways.

∗ Electronic address: rosvall@tp.umu.se
† URL: http://cmol.nbi.dk

[1] N. E. Friedkin, Horizons of Observability and Limits of Infor-
mational Control in Organizations. (The UNC Press 1983).
[2] S. Valverde and R. V. Solé, Eur. Phys. J. B 38, 245–252 (2004).
[3] A. Trusina, M. Rosvall, and K. Sneppen, Phys. Rev. Lett. 94,

238701 (2005).

[4] D. Watts and S. Strogatz, Nature 393, 440–442 (1998).

4

[5] T. Jeffrey and S. Milgram, Sociometry 32, 425–443 (1969).
[6] J R. Bergmann, DiscreetIndiscretions: TheSocialOrganization

ofGossip, Aldine De Gruyter, New York, (1993).
[7] N. E. Friedkin, Social Networks 3, 273–285 (1982).
[8] C. E. Perkins and P. Bhagwat, In Proc. ACM SIGCOMM 94,

[9] D. J. Watts, P. S. Dodds, and M. E. J. Newman, Science 296,

234–244 (1994).

1302–1305 (2002).

[10] M. Rosvall and K. Sneppen, Phys. Rev. Lett. 91, 178701 (2003).
[11] Javasimulation available at

http://cmol.nbi.dk/models/infoﬂow/infoﬂow.html

[12] M. Faloutsos, P. Faloutsos, and C. Faloutsos, Comput. Com-

mun. Rev. 29, 251 (1999).

[13] A.-L Barabási and R. Albert, Science 286 (1999).
[14] A. Trusina, S. Maslov, P. Minnhagen, and K. Sneppen, Phys.

Rev. Lett. 92, 178702, (2004).

[15] S. Maslov and K. Sneppen, Science 296, 910–913 (2002).
[16] P. Erd˝os and A. Rényi, Publ. Math. Debrecen 6, 290–297

(1959).

(2003).

(1965).

(1997).

(2000).

[17] S. Milgram, Psychol. Today 2, 60–67 (1967).
[18] M. Kochen, (Ed.) The Small World (Ablex, Norwood, 1989).
[19] J. M. Kleinberg, Nature 406, 845–845 (2000).
[20] P. S. Dodds, R. Muhamad and D. J. Watts Science 301, 827

[21] J. M. Kleinberg, In Proceedings of the 2001 Neural Information
Processing Systems Conference (MIT Press, Cambridge, MA,
2002).

[22] P. Killworth, and H. Bernard, Social Networks 1, 159 (1978).
[23] M. Granovetter, Am J Sociol 78, 1360–1380 (1973).
[24] N. C. Waugh and D. A. Norman, Psychol Rev 72, 89–104

[25] J. Hunter and R. Shotland, Social Forces 52, 321 (1974).
[26] B. A. Huberman and R. M. Lukose, Science 277, 535–537

[27] R. Albert, H. Jeong and A. Barabasi, Nature 406, 378–382

[28] We acknowledge the support of the Danish National Research

Council: “Models of Life” at NBI.

