6
0
0
2
 
c
e
D
 
3
1
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
4
3
1
2
1
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Eﬀective networks for real-time distributed processing

Gonzalo Travieso∗ and Luciano da Fontoura Costa†
Instituto de F´ısica de S˜ao Carlos, Universidade de S˜ao Paulo,
Av. do Trabalhador S˜ao-Carlense 400, 13566-590, S˜ao Carlos, SP, Brazil

The problem real-time processing is one of the most challenging current issues in computer sci-
ences. Because of the large amount of data to be treated in a maximum period of time, parallel
and distributed systems are required, whose performance depends on a series of factors including
the interconnectivity of the processing elements, the application model and communication proto-
col. Given their ﬂexibility for representing and modeling natural and human-made systems (such
as the Internet and WWW), complex networks have become a primary choice in many research
areas. The current work presents how the concepts and methods of complex networks can be used
to develop realistic models and simulations of distributed real-time system taking into account two
representative interconnection models: uniformly random and scale free (Barab´asi-Albert), includ-
ing the presence of background traﬃc of messages. The interesting obtained results include the
identiﬁcation of the uniformly random interconnectivity scheme as being largely more eﬃcient than
the scale-free counterpart.

PACS numbers: 89.75.-k, 89.20-Ff

I.

INTRODUCTION

We live in a world governed by action. From the am-
ple motion of our planet to the intricacies of Brownian
agitation, the universe is pervaded by an endless ﬂow of
changes to which our lives are no exception. While lit-
tle can follow out of stillness, movement imposes a con-
tinuing challenge to our senses. An immediate and im-
portant implication of movement is causality, one of the
most essential elements in animal survival and also the
key element in scientiﬁc investigation. In order to cope
with such demands, animals evolved an intricate neu-
ronal ‘hardware’ capable of analyzing moving images at
a high resolution and rate appropriate to enable an imme-
diate response, i.e. enough so as to favor their survival
and reproduction. Such a type of reaction by dynami-
cal systems is technically known as real-time (e.g. [1]).
Despite the several advances in computing technology
achieved along the last decades, we still lag well behind
biological system as far as real-time processing and recog-
nition is concerned. One of the possible ways to learn
how to develop automated systems for eﬀective, real-time
processing is to look at the organization of biological sys-
tems for inspiration. Another possibility is to model and
simulate such systems in order to try to identify partic-
ularly eﬀective architectures and algorithms. One of the
fundamental organizational principles of biological pro-
cessing of information regards inherent concurrency and
parallelism characterizing those systems. Because neu-
rons are relatively slow in processing and transmitting
information (e.g. [2]), high speed can only be achieved
by carefully interconnecting neurons so as to form groups
or modules working in parallel. Indeed, the brain is cur-

∗Electronic address: gonzalo@ifsc.usp.br
†Electronic address: luciano@ifsc.usp.br

rently known to be organized according to interconnected
modules [3] resembling a distributed computer system.
In addition to the inherent features of the modules and
involved neuronal cells, one particular feature of such
modular processing systems concerns the speciﬁc way in
which the several components are interconnected.

The interconnections between processing elements in a
distributed system can be natural and eﬀectively repre-
sented in terms of complex networks (e.g. [4, 5, 6]), where
each processor is associated to a node while the inter-
connections between these nodes are expressed as edges.
Through such a simple analogy, it is possible to bridge
the gap between research in real-time distributed systems
and the exciting concepts, tools and results from the area
of complex networks. Although the origin of the latter
area can be traced back to random graphs (e.g. [7]), and
despite their immediate relationship with graph theory,
the term complex network has been used to express the
emphasis placed on graphs which exhibit complex struc-
tured connectivity.[19]

Thanks to technological advances in neuroanatomy
and physiology, a more comprehensive vision of neu-
ronal interconnections underlying the nervous systems of
several animals is progressively emerging. At the mi-
croscopic — cellular — level, recent investigations have
suggested that neurons are interconnected through small
world and even scale free networks [8]. The macroscopic
organization of cortical areas [3] also seems to be orga-
nized according to this principle [9].

This article presents the application of complex net-
works as the means for investigating the eﬀect of al-
ternative connectivity schemes, namely uniformly ran-
dom (i.e. Erd˝os and R´enyi — ER) and scale free (i.e.
Barab´asi-Albert — BA) network models, on the overall
performance of a real-time distributed processing system.
While the ER model represents the natural reference sys-
tem for connectivity, being almost universally considered
as the null hypothesis in complex network studies, the

BA model is particularly representative of natural — in-
cluding neuronal information processing systems [8] —
and human-made systems such as the Internet and the
WWW [4]. ER networks exhibit a characteristic node de-
gree (i.e. the number of connections of each node of the
network), in the sense that their overall connectivity can
be well characterized in terms of the mean node degree.
Contrariwise, BA networks exhibit a power law distribu-
tion of node degrees, which favors a heterogeneous con-
nectivity, as well as the appearance of hubs (e.g. [4, 5]).
In addition to their particular importance in modeling
natural and human-made systems, BA networks provide
an interesting model for the Internet and, consequently,
grid computing systems — an important current trend
in distributed computing [10] which provides a good deal
of the motivation for the present work. In addition, the
consideration of the BA model allows us to investigate
the eﬀect of the presence of hubs in parallel and grid
systems — as implied by the Internet connectivity [11]
— on the overall performance, as a counterpart to the
otherwise almost regular connectivity ensured by the ER
model making it similar to uniform parallel systems such
as those involving mesh or hypercube interconnectivity.
However, unlike those architectures, ER (and BA) net-
works are small-world.

The application model simulated while considering
these two interconnecting models involves a master node
which distributes tasks, namely a stream of frames to
be processed, among processing elements in other nodes
acting as clients according to their availability. This as-
sumes that both the source and destination of the frames
are at the same site. The processing protocol consid-
ers a communication model involving routers connect-
ing the clients to the master, as typically found in prac-
tice. Therefore, the overall modeling and simulation ap-
proaches adopted in this work include many realistic el-
ements common to a real distributed processing system.

A previous work [12] studied the eﬀect of intercon-
nection topology in the performance of a grid comput-
ing application. The application considered involved the
processing of a number of not interacting tasks, with no
real-time requirements. The lack of real-time constraints
reduces the importance of traﬃc ﬂuctuations enabling
the use of average communication times for performance
evaluation. Correspondingly, [12] does not include traﬃc
eﬀects. Under the real-time constraints of the applica-
tion studied in the present work, varying delays induced
by traﬃc play a major role, and application-independent
traﬃc is thus included in the simulations. Another rea-
son for inclusion of traﬃc is that the network topology
strongly inﬂuences packet transit times under traﬃc, as
reported in many works (e.g. [13, 14, 15, 16]).

The article starts by presenting the adopted network,
application and communication models, followed by the
presentation and discussion of the obtained results and
conclusions.

2

II. MODELS

The model used for the simulations is composed of
three ingredients: a network model, a model for the com-
munication between the collaborating computers, and an
application model. These models are described below.

A. Network Models

When studying complex networks, the interest can be
focused on their topologies, i.e. their structural proper-
ties, or on some dynamical processes taking place in the
network. In this work, we use complex networks to de-
scribe the interconnection topology of a collection of com-
puters participating in a collaborative real-time compu-
tation. As such, our main focus is on the dynamical
processes of data communication and computations in
the computers interconnected through the network. In
this work, two widely used network models are consid-
ered: the Erd˝os-R´enyi (ER) random network model with
ﬁxed number of edges [17] and the Barab´asi-Albert (BA)
scale-free model [18].

ER networks are constructed by starting with N iso-
lated nodes (i.e. the network starts with no edges) and
adding edges one by one between uniformly chosen pairs
of nodes (avoiding duplicate connections of nodes and
self connections); the addition of edges is repeated a pre-
speciﬁed number L of times. N and L are the parameters
of the ER model and the average degree is given by:

hki =

2L
N

.

(1)

BA networks are constructed starting with m0 nodes
and adding new nodes one by one. When a new node
is inserted, m ≤ m0 edges are added from this node to
one of the previously existing nodes. The nodes to be
linked are chosen following the preferential attachment
rule [18]. The process is repeated until de desired num-
ber of nodes N is reached. In the simulations presented
below, the initial network was ﬁxed with m0 = 2m + 1
fully connected nodes. The parameters of the model are
thus N and m. Considering that for each new node m
new edges are added and that the initial network already
has m edges for each node, the total number of edges is
L = mN , and therefore

hki = 2m.

(2)

B. Application Model

This work analyzes the inﬂuence of network topology
on a real-time collaborative computation. The compu-
tation considered here is deﬁned as follows: A special
node in the network, called the master, is responsible for
reading a stream of input data and writing a stream of

output data. The data arrives at the master in pack-
ets, here called frames in an analogy to real-time video
processing, at regular intervals and the result of their
processing must be output at the same interval.

For each input frame, an output frame is produced af-
ter the realization of a certain amount of computation
In this work,
(the computational load of each frame).
the load is considered equal for all frames. The compu-
tation is not done by the master. Instead, a collection
of clients register their willingness to participate in the
computation; when a new input frame arrives, the mas-
ter chooses one available client and sends the frame to
it for processing. After receiving and processing the in-
put frame, the client sends the output frame back to the
master; when the output frame arrives at the master,
the client that processed the frame is again registered as
ready to receive a new frame.

After arrival (or generation) at the master, each frame
must be sent to a client, processed and sent back to the
master. As communication delays in the network are un-
predictable, the order of arrival of the resulting frames
at the master is not guaranteed to be the order in which
they were delivered. To avoid output of the frames out-
of-order and also enable waiting for the transmission and
processing of the frames, a frame buﬀer must be main-
tained by the master, where arriving frames are stored
in the correct order. The production of the output must
then be delayed for some time, i.e. the output of frames
must start some time after the arrival of the ﬁrst frame.
When a frame must be output, if it has not yet arrived it
must be dropped with resulting quality loss. It is there-
fore important to allow suﬃcient time for the frames to
arrive, but additional time given to frame processing re-
sults in increased latency in the production of the output.
The time between the arrival of the ﬁrst frame and the
start of the output (which is also the time each frame will
have available to be processed and returned to the mas-
ter) is here quantiﬁed in terms of the number of frame
intervals.

C. Communication Model

After a network is generated according to a given
model and set of parameters, its nodes are considered the
routers of a computer network. The computers partici-
pating in the collaborative work are hosts connected to
one of the routers. The master is connected to a router
randomly selected with uniform probability. Not all of
the network participates in the computation. The num-
ber of participating clients is a parameter of the sim-
ulation. Each client is associated with a router selected
with uniform probability, but a limitation is imposed that
each host (master or client) is associated with a diﬀerent
router. Only routers from the largest connected compo-
nent of the network are selected.

As the network is not dedicated to the computation,
traﬃc external to the computation is simulated on the

3

network by the generation of packets between random
pairs of routers.

After insertion in the network, the packets are routed
from node to node. The routers follow a “shortest path”
routing strategy: each router sends a packet to a neigh-
boring router that strictly decreases the number of steps
if more than one
remaining to reach the destination;
neighbor satisﬁes this condition, one of them is chosen at
random. While a router is routing and sending a packet
to a neighbor, it cannot handle other packets. Packets
arriving during this operation are queued in arrival order
to be processed later; the routers are assumed to have
unbounded queuing capacity.

The time for processing and communication at each
step on the network is considered independent of the
packet and router, although the delivery time for dif-
ferent packets might diﬀer due to queuing. If the traﬃc
in the network is low, the queues are empty or short, and
the time taken for a packet to reach the destination is
proportional to the topological distance between source
and destination. As traﬃc increases, congestion ensues
[13, 15, 16], and the delivery time grows to many times
that of the uncongested network.

D. Parameters

Here the model parameters and their values for the

simulation results described below are presented.

Both network models are characterized by two param-
eters: the number of nodes N and the number of edges
(for the ER model) or number of edges added for each
new node (for the BA model). Henceforth the latter pa-
rameters are represented by the average node degree hki,
that can be computed from the model parameters by us-
ing equations (1) and (2).

The computation dynamics is described by the compu-
tational load for the processing of each frame, the interval
between frames and the number of frames to wait before
starting the output. Considering that all clients are taken
as identical (no diﬀerence in processing power), the com-
putational load can be given as the computational time T
of the processing task. The time interval between frames
will be represented by τ and the number of frames to
buﬀer by B. The output latency is therefore Bτ.

The time taken for a packet to traverse a step in the
network from a node to one of its neighbors, h, is the
same for each packet and router. As only the relation
between the times are of importance, the time scale is
chosen such that h = 1, the values of T and τ being
expressed in these units. The random traﬃc generation
in the network is assumed to be a Poisson process with
inter-arrival times given by an exponential distribution
with average 1/(N λ); the factor N is introduced to make
the amount of traﬃc proportional to the size of the net-
work; λ is the per-node packet generation frequency (in
units compatible with h = 1).

The remaining parameter is simply the number of

TABLE I: Model parameters and their values. Time and fre-
quency parameter “normalized” units (see text); output start
interval in number of frame intervals.

Parameter

Meaning

N
hki
T
τ
B
λ
C

Number of nodes
Average node degree
Frame computation time
Frame interval
Output start interval

Packet generation frequency 0.001–0.02

Number of clients

100

Values

1000
2, 6, 10
100
5
10–50

clients C ≤ N − 1. The parameters are listed in Table I,
together with their range of values used in the simula-
tions discussed below.

III. RESULTS AND DISCUSSION

A computation is successful if all output frames are
returned from the clients and arrive at the master before
they need to be output. If a frame arrives too late for
output, the frame is dropped, and the quality of the out-
put consequently reduced. Frames that arrive in time are
here called completed. The number of completed frames
is chosen as quality measure of the computation. In the
simulations, a total of 1000 frames needs to be computed.
Figure 1 shows the number of completed frames as a
function of network traﬃc and the output latency, for ER
and BA networks of 1000 nodes, with hki = 2, 6, 10. The
other simulation parameters used are: 100 clients, frame
interval of 5, frame processing time of 100. The results
shown are averages of 100 simulations, each with a dif-
ferent network generated according to the corresponding
model and diﬀerent traﬃc patterns.

Consider ﬁrst the case of the Erd˝os-R´enyi network with
hki = 10 (Fig. 1(e)). This plot shows a sharp transi-
tion on the number of completed frames for a latency
of about 20 frame intervals. This transition is expected:
with T = 100 and τ = 5, at least T /τ = 20 frame in-
tervals must elapse before results start to arrive at the
master. The fact that the transition is sharp, close to
this lower limit, and independent of traﬃc in the studied
region shows that an Erd˝os-R´enyi topology with hki = 10
is eﬃcient for this application, that is, it introduces small
delays. For hki = 6 (Fig. 1(c)), the results are similar,
but the transition is not so sharp and a larger latency
is needed to reach the plateau of all frames completed.
In the case of hki = 2 (Fig. 1(a)), another eﬀect ap-
pears: a reduction on the number of completed frames
occurs when the traﬃc is increased. The larger value
of B needed and the drop in the number of completed

4

frames with increased traﬃc for reduced values of hki are
due to the reduction in the connectivity of the network:
Few edges connecting the nodes result in increased aver-
age distances from the master to the clients; this aﬀects
the time taken to deliver the frames and complete their
calculations, resulting in the need for an increase in the
frame buﬀer and therefore the latency. Also, the pres-
ence of fewer edges means that fewer alternative paths
are available between the nodes, rising the sensitivity of
the network to increased traﬃc.

For the Barab´asi-Albert networks, Figs. 1(b), (d), (f),
the results show a much stronger inﬂuence of traﬃc. For
hki = 6 and hki = 10 a continuous drop of the number
of completed frames is noticed as the amount of traﬃc
grows. For high traﬃc values, even large buﬀers are not
able to guarantee the completion of a suﬃcient amount
of frames. For hki = 2 the number of completed frames
is small even for small amounts of traﬃc.

In order to better understand these results, Figure 2
plots the average packet transmission delay for the same
situations as presented in Figure 1. The delay is com-
puted as the time taken from the delivery of a packet at
the source to the arrival at the destination. As shortest
path routing is used and the time taken at each step (hop)
is unitary, the average delay should equal the average dis-
tance between nodes under reduced traﬃc. This can be
seen for the ER networks with hki = 6 and hki = 10
(Figs. 2(c),(e)), where the graphs are ﬂat with a delay
value about the value of the average distances. A dif-
ferent behavior is seen for ER networks with hki = 2
(Fig. 2(a)). At a packet generation frequency of about
λ = 0.01 the delay starts to grow linearly with the
amount of traﬃc. This is due to the onset of conges-
tion in the network: some nodes start to receive packets
far more frequently than they can handle, leading to in-
creased queuing times of the packets in the nodes. After
congestion the average delays grow fast to many orders
of magnitude of the average distance. Figure 2(f) shows
that congestion occurs for the BA network with hki = 10
for a similar value of λ = 0.01, but note that the in-
crease in delay is steeper after that point. For hki = 6,
BA networks display congestion at lower traﬃcs (about
λ = 0.005) and even steeper increases of delay. The prob-
lem is accentuated for hki = 2 (Fig. 2(b)), where conges-
tion occurs even for small amounts of traﬃc.

The reason for this greater sensibility of the Barab´asi-
Albert networks to traﬃc in comparison with the Erd˝os-
R´enyi networks is easy to understand. In fact, the pref-
erential attachment rule of BA networks induces the cre-
ation of nodes with a high degree (hubs). Due to their
high connectivity, these hubs appear in many of the
shortest paths of the network. Although hubs are cre-
ated, the number of hubs is always small, and most of
the nodes have small connectivity and take part in just
a few shortest paths. Therefore, a few nodes of the net-
work are responsible for routing almost all of the traﬃc,
resulting in large packet queues and congestion in these
nodes. The lower the total connectivity of the network,

Erd˝os-R´enyi , hki = 2

Barab´asi-Albert , hki = 2

5

20

30

Buﬀer Size (frames)

40

(a)

50

Traﬃc

0.01

0.015

0.02 10

20

30

40

Buﬀer Size (frames)

50

Erd˝os-R´enyi , hki = 6

Barab´asi-Albert , hki = 6

20

30

Buﬀer Size (frames)

40

(c)

50

Traﬃc

0.01

0.015

0.02 10

20

30

40

Buﬀer Size (frames)

50

Erd˝os-R´enyi , hki = 10

Barab´asi-Albert , hki = 10

Completed Frames
Completed Frames

1000
750
500
250
0

0
0.005

Completed Frames
Completed Frames

1000
750
500
250
0

0
0.005

Completed Frames
Completed Frames

1000
750
500
250
0

0
0.005

Completed Frames
Completed Frames

1000
750
500
250
0
0
0.005

Traﬃc

0.01

0.015

0.02

10

Completed Frames
Completed Frames

1000
750
500
250
0
0
0.005

Traﬃc

0.01

0.015

0.02

10

Completed Frames
Completed Frames

1000
750
500
250
0
0
0.005

Traﬃc

0.01

0.015

0.02

10

(b)

(d)

(f)

20

30

Buﬀer Size (frames)

40

(e)

50

Traﬃc

0.01

0.015

0.02 10

20

30

40

Buﬀer Size (frames)

50

FIG. 1: Number of completed frames from a total of 1000 frames as a function of network traﬃc and number of buﬀered
frames, for ER networks (left column) and BA networks (right column). Model parameters are N = 1000, T = 100, τ = 5, and
C = 100.

the more pronounced is this problem, as fewer links im-
ply fewer alternative shortest paths. ER networks, on the
other hand, distribute the connectivity homogeneously
between all nodes, thus generating a better distribution
of shortest paths among the nodes of the network.

To assess the inﬂuence of the computational load as-
sociated with each frame (parameter T ), Figure 3 shows
the number of completed frames as a function of traf-
ﬁc and frame processing time. For ER networks with
hki = 6 and hki = 10, where no congestion occurs, two
plateaux, one with all frames completed and the other

with no frames completed, with a sharp transition be-
tween T = 140 and T = 150, are clearly seen. For the
other cases, where traﬃc is important, a gradual decay
of the number of completed frames is seen for increased
traﬃc, as already seen in Figure 1, but there is also a
gradual decrease of the number of completed frames as
the frame computation time increases (before the transi-
tion to the no completion plateau). The higher the traﬃc,
the steeper is the decrease of the number of completed
frames with frame completion time.

The above results can be understood by the following

Erd˝os-R´enyi , hki = 2

Barab´asi-Albert , hki = 2

6

0

0.005

0.015

0.02

0.005

0.015

0.02

0.01

Traﬃc

(a)

0.01

Traﬃc

(b)

Erd˝os-R´enyi , hki = 6

Barab´asi-Albert , hki = 6

0

0.005

0.015

0.02

0.005

0.015

0.02

0.01

Traﬃc

(c)

0.01

Traﬃc

(d)

Erd˝os-R´enyi , hki = 10

Barab´asi-Albert , hki = 10

y
a
l
e
D
t
e
k
c
a
P

y
a
l
e
D
t
e
k
c
a
P

y
a
l
e
D
t
e
k
c
a
P

50000

45000

40000

35000

30000

25000

20000

15000

10000

5000

0

0

3500

3000

2500

2000

1500

1000

500

0

0

900

800

700

600

500

400

300

200

100

0

0

y
a
l
e
D
t
e
k
c
a
P

y
a
l
e
D
t
e
k
c
a
P

y
a
l
e
D
t
e
k
c
a
P

160

140

120

100

80

60

40

20

0

4.5

3.5

2.5

1.5

4

3

2

1

0

0.5

3.5

2.5

1.5

3

2

1

0

0.5

0

0.005

0.015

0.02

0.005

0.015

0.02

0.01

Traﬃc

(e)

0.01

Traﬃc

(f)

FIG. 2: Average delay for the delivery of packets in the network (time taken by the packets from source to destination) as a
function of network traﬃc. All packets in the network are included in the average (not only packets that transport frames).
Model parameters are N = 1000, T = 100, B = 3, τ = 5, and C = 100.

reasoning. After the generation of a frame f , it must
be delivered to a client, processed, and sent back to the
master. Total processing time for f , P (f ) is given by

P (f ) = w(f ) + tmc(f ) + tcm(f ′) + T

(3)

tcm(f ′) are generally diﬀerent (although the topological
distance is the same in both directions) due to possibly
diﬀerent traﬃc conditions at the two transit periods. The
condition for the completion in time of f is that P (f ) is
less then the accepted latency Bτ , giving

where w(f ) if the time f waits for a ready client, tmc(f )
is the travel time of f from master to client, and tcm(f ′)
is the travel time from client to master of the frame gen-
erated by the processing of f . Travel times tmc(f ) and

w(f ) + tmc(f ) + tcm(f ′) + T ≤ Bτ.

(4)

This condition must be satisﬁed by most frames. Under
low traﬃc conditions, tmc(f ) ≈ tcm(f ′) is close to the

Erd˝os-R´enyi , hki = 2

Barab´asi-Albert , hki = 2

Completed Frames
Completed Frames

7

50

100

150

Frame processing time

(a)

0
0.005

Traﬃc

0.01

200

0.015

0.02

50

100

Frame processing time

200

Erd˝os-R´enyi , hki = 6

Barab´asi-Albert , hki = 6

Completed Frames
Completed Frames

50

100

150

Frame processing time

(c)

0
0.005

Traﬃc

0.01

200

0.015

0.02

50

100

Frame processing time

200

Erd˝os-R´enyi , hki = 10

Barab´asi-Albert , hki = 10

Completed Frames
Completed Frames

1000
750
500
250
0

1000
750
500
250
0

1000
750
500
250
0

150

(b)

150

(d)

150

(f)

Completed Frames
Completed Frames

1000
750
500
250
0
0
0.005

Traﬃc

0.01

0.015

0.02

Completed Frames
Completed Frames

1000
750
500
250
0
0
0.005

Traﬃc

0.01

0.015

0.02

Completed Frames
Completed Frames

1000
750
500
250
0
0
0.005

Traﬃc

0.01

0.015

0.02

50

100

150

Frame processing time

(e)

0
0.005

Traﬃc

0.01

200

0.015

0.02

50

100

Frame processing time

200

FIG. 3: Number of completed frames from a total of 1000 frames as a function of network traﬃc and frame computation time,
for ER networks (left column) and BA networks (right column). Model parameters are N = 1000, B = 30, τ = 5, and C = 100.

topological distance between master and client and small
due to the small world property of the network models
used, and the buﬀer used can be small, implying small
latencies. Under heavy traﬃc, transit times can be very
large (see Fig. 2), resulting in the need of high values of
B and therefore large latencies; also, even with large B,
the ﬂuctuations in traﬃc are high, and many frames will
be lost. This renders the distributed system useless for
the application.

IV. CONCLUDING REMARKS

Combined with the availability of ever increasing
amounts of data, the continuing advances scientiﬁc simu-
lations have imposed serious demands for real-time pro-
cessing. A natural means to cope with such a pressure is
to develop and apply distributed systems, including the
possibility of learning from biological systems and the
application of Internet-based grid computing. Because of
the high cost in implementing such solutions, it becomes
essential to have access to realistic and eﬀective model-
ing and simulation methodologies. The current work has

described how concepts and methods from the modern
area of complex networks research can be applied in order
to model and simulate with a good level of realism dis-
tributed systems for real-time processing, with emphasis
focused on grid computing structures with connectivity
underlined by the Internet. At the same time, because
the BA model reﬂects some important connectivity fea-
tures found in neuronal processing systems, the develop-
ment and evaluation of such complex network models for
real-time processing bear potential implications also for
understanding natural processing.

Given its compatibility with some Internet topological
features, and also because of its potential compatibility
with neuronal processing systems, the Barab´asi-Albert
complex network model has been selected in order to de-
ﬁne the overall connectivity of the distributed real-time
processing system. The Erd˝os-R´enyi complex network
model was also considered as a null hypothesis charac-
terized by a high uniformity of node degree. Realistic
models were assumed for the application and communi-
cation dynamics, including the eﬀect of background mes-
sage traﬃc, while the overall performance was quantiﬁed
in terms of the total number of processed frames with

8

respect to varying traﬃc intensity, buﬀer size and frame
processing time. The obtained results included the iden-
tiﬁcation of critical parameter conﬁgurations which are
closely related to the model parameters and overall con-
nectivity. Of special interest is the clear superiority of
ER networks over BA networks. This is a result of the
better handling of traﬃc by ER networks, due to a better
distribution of connectivity between the nodes.

Possible future works include the consideration of other
complex network models and applications, as well as
inclusion of variability in the computing power of the
clients, in the processing requirements of diﬀerent frames
and in the communication times between nodes.
It is
also of interest to study the eﬀect of diﬀerent routing
algorithms and packet queuing strategies at the routers.

Acknowledgments

Luciano da F. Costa thanks FAPESP (05/00587-5) and

CNPq (308231/03-1) for sponsorship.

[1] J. W. S. Liu, Real-Time Systems (Prentice-Hall, 2000).
[2] E. R. Kandel, J. H. Schwartz, and T. M. Jessell, Princi-

tions, technologies, architectures, and protocols for com-
puter communication (1999), pp. 251–262.

ples of Neural Science (McGraw-Hill, 2000).

[3] S. Zeki, Inner Vision: An Exploration of Art and the

Brain (Oxford University Press, 2000).

[4] R. Albert and A. L. Barab´asi, Rev. Mod. Phys. 74, 47

[12] L. da F. Costa, G. Travieso, and C. A. Ruggiero,
European Physical Journal B 44, 119 (2005), cond-
mat/0312603.

[13] P. Holme, Advances in Complex Systems 6, 163 (2003).
[14] B. Tadi´c, S. Thurner, and G. J. Rodgers, Physical Review

[5] M. E. J. Newman, SIAM Review 45, 167 (2003), cond-

E 69, 036102 (2004).

[6] S. Boccaletti, V. Latora, Y. Moreno, M. Chavez, and D.-

E 71, 026125 (2005).

U. Hwang, Physics Reports (2006), accepted.

[16] B. Tadi´c, G. J. Rodgers, and S. Thurner (2006),

[7] B. Bollob´as, Random Graphs (Cambridge University

physics/0606166.

[15] L. Zhao, Y.-C. Lai, K. Park, and N. Ye, Physical Review

[8] O. Sporns, G. Tononi, and G. M. Edelman, Cerebral Cor-

290 (1959).

(2002).

mat/0303516.

Press, 2001).

tex 10, 127 (2000).

[17] P. Erd˝os and A. R´enyi, Publicationes Mathematicae 6,

[18] A.-L. Barab´asi and R. Albert, Science 286, 509 (1997).
[19] Although authors tend not to consider uniformly random
graphs (constant probability of connection between any
pair of nodes) as complex networks, even such simpler
structures do exhibit complex connections as a conse-
quence of statistical ﬂuctuations.

[9] O. Sporns, D. Chialvo, M. Kaiser, and C. C. Hilgetag,

Trends in Cognitive Sciences 8, 418 (2004).

[10] I. Foster, C. Kesselman, and S. Tuecke, International
Journal of High Performance Computing Applications
15, 200 (2001).

[11] M. Faloutsos, P. Faloutsos, and C. Faloutsos, in SIG-
COMM ’99: Proceedings of the conference on applica-

