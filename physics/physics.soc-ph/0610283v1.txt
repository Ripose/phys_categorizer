6
0
0
2
 
t
c
O
 
1
3
 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 
1
v
3
8
2
0
1
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Exploring an opinion network for taste
prediction: an empirical study

Marcel Blattner, Yi-Cheng Zhang

Department of Physics, University of Fribourg, Chemin du Muse 3, CH - 1700
Fribourg, Switzerland

Department of Physics, Brookhaven National Laboratory, Upton, New York 11973

Sergei Maslov

Abstract

We develop a simple statistical method to ﬁnd aﬃnity relations in a large opinion
network which is represented by a very sparse matrix. These relations allow us to
predict missing matrix elements. We test our method on the Eachmovie data of
thousands of movies and viewers. We found that signiﬁcant prediction precision can
be achieved and it is rather stable. There is an intrinsic limit to further improve the
prediction precision by collecting more data, implying perfect prediction can never
obtain via statistical means.

Key words: Opinion network, recommender systems, taste prediction.

1 Introduction

With the advent of the World Wide Web (WWW) we witness the onset of
what is often called ’Information Revolution’. With so many sources and users
linked together instantly we face both challenges and opportunities, specially
for scientists. The most prominent challenge is information overload: no one
can possibly check out all the information potentially relevant for him. The
most promising opportunity is that the WWW oﬀers possibility to infer or
deduce other users experience to indirectly boost a single user’s information
capability. Both computer scientists and internet entrepreneurs extensively
use various collaborative-ﬁltering tools to tap into this opportunity.

1 Supported by the Swiss National Science Foundation

Preprint submitted to Elsevier Science

2 February 2008

The so-called web2.0 represents a new wave in web applications: many newer
web sites allow users’ feedback, enable their clustering and communication.
Much of users’ feedback can be interpreted as votes or evaluation on the infor-
mation sources. Such voting is much more widespread: our choice of movies,
books, consumer products and services could be considered as our votes repre-
senting our tastes. With a view to develop a prediction-model suitable for web
application, we need to ﬁrst test a model is a limited setting. For a more con-
crete example consider opinions of movie-viewers on movies they have seen. We
use in this work the EachMovie dataset, generously provided by the Compaq
company. The Eachmovie dataset comprises ratings on 1628 movies by 72916
users. The dataset has a density of approximately 3%, meaning that 97% of
possible ratings are absent. This dataset can represented by an information
matrix: each user has only seen a tiny fraction of all the movies; each movie
has been seen by a large number of users but they are only a tiny fraction of
all users. This (sparse) information matrix has 97% elements missing; our task
is to ﬁnd whether we can predict them leveraging aﬃnity relations hidden in
the dataset.

2 Prediction Algorithm and Results

There is a particular way how such information on movies could be used
to recommend other users movies they have not yet seen but which would
likely suit their tastes. Such recommendations can be made by a centralized
agent (matchmaker) who collects a large number of votes. The idea behind
such services (called “recommender system” or “collaborative ﬁltering” by
computer scientists [1][2][3][4] ) is that users’ votes are ﬁrst used to measure
the aﬃnity of users’ tastes. Then opinions of users with tastes suﬃciently
similar to the user in question are summed up to predict the opinion on movies
she/he has not seen yet. The data of the “matchmaker” are stored in the voting
matrix V with entries viα, this is the vote of user i to movie α. For simplicity we
only take into account from the original data users who have seen at least 200
movies. As a further approximation we shall compress the original votes (1to5)
to viα
1 (dislike), 4 and 5 to 1 (like),
3 is interpreted as 0, as if the user has not seen the movie. Elsewhere we show
that such simplifying approximations do not induce statistically signiﬁcant
reduction in prediction power. The dimension of the rectangular matrix V is
1648), i.e. there are N = 1223 users and M = 1648 movies. In this
(1223
matrix there are

105 non-zero elements (votes).

, i.e, 1 and 2 are converted to

∈ {−

1, 1

×

−

}

2

viα

Pi,α |

| ∼

·

Duality picture. The voting matrix V can be viewed in two ways. In user-
centric view we measure the pairwise aﬃnity of users. The aﬃnity distribution
indicates how much information redundancy is buried in the data to predict
users’ opinion about a movie. This is similar to Newman’s ’Ego-centered net-

2

works’ [5]. In the movie-centric view we look at the distribution of movie
aﬃnity. This shows how controversial movies were voted by the population.
This “duality picture” is not symmetric Fig.(1).

Let us start with the user-centric view. We deﬁne the overlap between users i
and j as

M
α=1 viαvjα
Ωij = P
M
vjα
viα
α=1 |
This measures the aﬃnity between users i and j. Ωij close to 1 means similar
tastes, whereas Ωij close to
gives
||
−
|
the number of commonly seen movies by both users i and j.
denotes the
absolute.

1 means opposite tastes.

M
α=1 |
| · |

, Ωij

1, 1).

vjα

viα

(1)

−

P

P

∈

||

(

|

In the movie-centric view the aﬃnity between two movies is deﬁned in an
analogous way as follows:

N
i=1 viαviβ
Ωαβ = P
N
viβ
viα
i=1 |

, Ωαβ

(

1, 1).

∈

−

(2)

||

P

|
Ωαβ close to 1 means that movie α and movie β are judged as similar by each
1 indicates that the two movies are judged to be
user, whereas Ωαβ close to
N
gives the number of people who have seen both movies
opposite.
i=1 |
α and β. A more intuitive concept is given by the distance dij = (1
Ωij)/2
for users and dαβ = (1
0 represents
∼
similar tastes for user i and user j whereas dij
1 opposite opinions. Likewise
interpretations for the movie-centric view.

Ωαβ)/2 for movies respectively. dij

viα

viβ

−

−

−

∼

P

||

|

Pu(d) in Fig.(1)indicates a rather homogenous distribution of tastes among
0.2 implies a rich information source
users. Furthermore the peak around d
∼
which allows taste prediction. If users would vote in a random manner the
peak would be around 0.5. On the other hand in the movie-centric view the
distribution Pm(d) in Fig.(1) appears more polarized. One explanation for this
is the following: the overlaps of the users are typically averaged over a lot of bits
(from every user there are at least 200 opinions known), while many movies
are only few times voted. Hence it is much easier to get a “perfect” +1 or
1
−
overlap. Apart from this we observed two eﬀects which also give hints about
the asymmetry between the two views. One example: for a Star wars movie
the set of ’antipodes’- movie with d
1 includes A) some movies oriented for
the audience of young women (e.g. Mr. Wrong); B) Less successful sequels of
the Star Wars trilogy hated by some of their fans. It is not surprising that for
movies of type B there exists a considerable number of people who saw both
of them. What is more surprising is that for some of the movies of type A the
number of users liking Star Wars could also be quite large. We tentatively
attribute it to the ‘girl-friend eﬀect’ in which Star Wars fans were dragged
by their girlfriends to see a movie like Mr. Wrong. Most of them disliked it

∼

3

)
d
(

P

m

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

0

)
d
(

P

u

0.3

0.25

0.2

0.15

0.1

0.05

0

0

0.2

0.4

0.6

0.8

1

d

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
d

1) of distance between users
Fig. 1. Distribution Pu(d) =
Pi Pj6=i δ(dij , d)/N (N
1) of distance between
and the distribution Pm(d) =
movies. δ(dx, d) is the Kronecker symbol, N is the total number of people in the
population and M is the total number of movies.

Pα Pβ6=α δ(dαβ , d)/M (M

−

−

(hence the distance between these movies is close to 1 in spite of a relatively
large common audience).

One can use the information of distances between movies to make a proposition
to users: if user i likes movie α (viα = 1) and this movie is within a distance
d

0 with movie β it is very likely that user i also will like movie β.

∼

However to predict a vote viα we will use the information of aﬃnity between
users. Here, user i is the ’center’ of the universe and all others have certain
distances to him. Users close to him are more trustful because they share simi-
lar tastes. Hence they should have more weight in the prediction. Furthermore
we have to penalize users who have not seen that much movies in common. In
this way we take care of the statistical signiﬁcance.

We introduce our method to predict votes: the dataset of votes (matrix V ) is
divided into a ’training’ set Vtrain and a ’test’ set Vtest. The votes of the two
sets are generated randomly out of the voting matrix V . The votes in Vtrain
are treated as observed whereas the votes in Vtest are hidden for the algorithm.
That is we use votes in Vtrain to predict votes in Vtest.

4

only Overlap

combined Overlap and Mean

)
ρ
(
π

0.75

1

0.95

0.9

0.85

0.8

0.7

0.65

0.6

0.55

0.5

0

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
ρ

Fig. 2. The prediction power Π(ρ) as a function of ρ. ρ is the fraction of present
votes in Vtrain to the total number of votes in the voting matrix V .

For prediction we use the following form

iα = Pj6=i Ωij√ωij
v′
Pj6=i |

Ωij

|

√ωij ·

vjα
vjα

.

|

|

(3)

(4)

iα is the predicted vote which has to be compared to viα

Vtest.
Vtrain are the votes which are supposed as known . Statistical signiﬁcance
vjα
, which is the number of shared

Where v′
vjα
is taken into account by ωij =
Pα |
movies between user i and user j. Our measure of accuracy is given by

viα

∈

∈

||

|

siα =





(0.5, 1.0),

Vtest

|

|

Where Π
viα

Vtest.

∈

∈

1 if sign(v′

iα) = viα

0 otherwise

, Π =

(

Pi Pα siα)
Vtest

|

|

is the number of votes we want to predict and

0.5 means no predictive power. In this case prediction is random whereas

Π
Π = 1 gives an accuracy of 100% (every vote was predicted correctly).

∼

It is a common belief that prediction accuracy in ’recommender systems’ is
an increasing function of the available amount of data. The more votes the
better. However, our result shows a saturation of the prediction power after
a critical mass of data Fig.(2). We can clearly distinguish two phases. In
the region ρ
0.2 no reasonable prediction can be done, because there are
not enough overlaps present. In this region the prediction is by chance. By

≤

5

increasing the number of votes in Vtrain - the prediction accuracy increases
too. However, after a critical value of ρ
0.6 the predictability saturates,
without any further improvement with additional data input. When we use
somewhat diﬀerent method with the mean tendance as an aide, that is

∼

iα = ¯vα + Pj6=i Ωij√ωij
v′
Pj6=i |

Ωij

|

√ωij ·

vjα
vjα

.

|

|

(5)

the onset of the plateau is much earlier, in a sense this represents a big im-
Pi viα/Nα denotes the average vote of a movie α and Nα
provement. ¯vα =
is the number of people who voted for movie α. However the plateau value
remains the same. This hints some fundamental limit at work, for this we need
examine the origins of noise intrinsically buried in the data. First of all, the
massive collection of thousands web surfers is far from being a precise pro-
cess, an average user often votes carelessly, and with biases and whim, typical
of any human experiment. However if a rater sometimes votes random, and
random data won’t show any meaningful correlation, as pointed out by [6], on
the aggregate one must expect that there is some coherence left in the data,
its less-than-perfect collection quality ﬁnally shows up in our calculation. It is
remarkable that this degree of imperfection can be calculated at all. Though
we should never expect perfection in human endeavors, but signiﬁcant room
left for improvement. Prediction quality can never attain 1, no matter how
good is the method and data [7].

j

{

dl

≤

, 0.9

dl =

}
· · ·

= i
|

≤
∈ {

dl + 0.1
0.0, 0.1

We investigate in more detail what are crucial parameters for prediction accu-
racy. Fig.(3) shows a non cumulative and a cumulative plot of the prediction
power. In the non cumulative case we only take into account users within a
certain range of distance. Predicting viα (the vote from user i to movie α)
we build a subset of users A(i)
dij
and use only
members of this set to predict votes in question. dl
is the
lower distance threshold. The upper distance threshold is given by dl + 0.1.
Prediction power is given again by Eq.(4). For the cumulative case dl remains
always 0 and we vary only the upper distance threshold. We build a subset of
users B(i)
, 1.0
}
denotes the upper distance threshold. We observe in the non cumulative case
that my ‘antipodes’ Fig.(3) still could be used for prediction (albeit poorly).
However users who are very similar to ’me’ are best in predicting my tastes.
The number of users within a small distance d to a given user is low but their
predictions are good, while the number of users at intermediate distances
d
0.3 is large but their predictive power is poor. One needs to strike a bal-
ance. As one can see in the cumulative case Fig.(3) prediction power saturates
around d = 0.2 (indicated by the dotted line). So there is no harm in including
the votes from all users (provided that we weight them as we do).

to predict vote viα. du

0.1, 0.2,

= i
|

du =

∈ {

0.0

· · ·

dij

du

≤

≤

∼

}

{

}

j

Next we investigate what determines the mean predictability of a user or a

6

6
6
non cumulative

cumulative

)

u

d
(
Π

1

0.9

0.8

0.7

0.6

0.5

0

0.2

0.4

0.6

0.8

1

d
u

l

)
d
(
Π

0.75

1

0.95

0.9

0.85

0.8

0.7

0.65

0.6

0.55

0.5

0

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
d
l

Fig. 3. The prediction power Π(dl) as a function of the lower distance threshold for
the non cumulative case and Π(du) as a function of the upper threshold (small box)
for the cumulative case. Note that the calculated accuracy for the non cumulative
case is plotted always between the lower and the upper distance threshold.

movie Fig.(4). People who have a small average distance ¯di =
1)
to the rest of the population are better predictable then people who have
somewhat special tastes. If somebody follows the mainstream he or she will
have more users with similar tastes which are best for predictions. Note that
the predictability seems to extrapolate to 1 for small d.

Pj6=i dij/(N

−

The major determinant of predictability of a movie is how many votes it has.
This is quantiﬁed in Fig.(4). It could be interpreted like this: the prediction of
an opinion of a given user on a popular movie could be based on large ensemble
of other users who also saw this movie. Chances are that this ensemble would
contain decent number of users with tastes similar to the user we are currently
trying to predict. Thus the prediction would turn out to be more precise.

7

)

N
Π

(

0.9

0.8

0.7

0.6

0.5

0

200

400

600

800

N

)
d
(
Π

0.75

1

0.95

0.9

0.85

0.8

0.7

0.65

0.6

0.55

0.5

0

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
d

Fig. 4. The prediction power Π(d) as a function of the mean distance d and the
predictability Π(N ) for movies as a function of the number of votes N it has (small
box). The two plots are non cumulative. An example: Π(0.2) gives the average
predictability of users who have an average distance ¯di =
d = 0.2
to the rest of the population, Π(0.3) gives the average predictability of users who
d = 0.3 and so on. The
have an average distance d = 0.2
plot for the movie predictability (small box) is also non cumulative and indicates
an increasing prediction accuracy for an increasing number of votes.

Pj6=i dij/(N
1)

Pj6=i dij/(N

¯di =

1)

≤

−

≤

≤

−

3 Conclusion

To conclude we note that our relatively straightforward method can yield
signiﬁcant prediction precision. However there seems to have an intrinsic limit
in the precision that should be attributed to the original noisy source. Our
results reveal that people’s tastes tend to be homogenous whereas movies are
polarized. The implications of our study go much beyond merely predicting
user’s tastes. One can image that consumers’ relation with myriad of products
and services as a much larger information matrix. It would have signiﬁcant
impact on the economy if a consumer’s potential tastes to the vast majority of
products and services that she has not yet tested can, to a reasonable precision,
be predicted. With the rapid evolution of the Information Technology, where
the feedbacks from consumers can be eﬀectively tracked and analyzed, it is not
to far-fetched to see our economy completed transformed by a new paradigm.

8

References

[1] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, J. Riedl, Grouplens: an open
architecture for collaborative ﬁltering of netnews, in: Proceedings of the 1994
ACM conference on Computer supported cooperative work, 1994.

[2] J. Breese, D. Heckerman, C. Cadie, Empirical analysis of predictive algorithms
for collaborative ﬁltering, in: Proceedings of the 14th Annual Conference on
Uncertainty in Artiﬁcial Intelligence (UAI-98), 1998.

[3] D. Billsus, M. Pazzani, Learning collaborativ information ﬁlters, in: Proceedings

of the 14 Conference on Uncertainty in Reasoning, 1998, pp. 43–52.

[4] B. Sarwar, G. Karypis, J. Konstan, J. Reidl,

Item-based collaborative
ﬁltering recommendation algorithms, in: WWW ’01: Proceedings of the tenth
international conference on World Wide Web, 2001.

[5] M. Newman, Ego-centered networks and the ripple eﬀect, Social Networks 25

(2001) 83–95.

[6] S. Maslov, Y.-C. Zhang, Extracting hidden information from knowledge

networks, Phys. Rev. 87 (2001) 248701.

[7] W. Hill, L. Stead, M. Rosenstein, G. Furnas, Recommending and evaluating
choices in a virtual community of use, in: Proceedings of the SIGCHI conference
on Human factors in computing systems, 1995.

9

