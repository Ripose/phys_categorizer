2
0
0
2
 
t
c
O
 
6
1
 
 
]
s
c
i
t
p
o
.
s
c
i
s
y
h
p
[
 
 
1
v
2
6
0
0
1
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Schr¨odinger equation with a spatially and temporally random potential: Eﬀects of
cross-phase modulation in optical communication.

A. G. Green1, P. B. Littlewood2, P. P. Mitra3 and L. G. L. Wegener2
1Theoretical Physics, Oxford University, U.K.
2T.C.M., Cavendish Laboratory,
Cambridge University, UK.
3Lucent Technologies,
Bell Laboratories Innovations, Murray Hill, NJ.
(Dated: December 16, 2013)

We model the eﬀects of cross-phase modulation in frequency (or wavelength) division multiplexed
optical communications systems, using a Schr¨odinger equation with a spatially and temporally ran-
dom potential. Green’s functions for the propagation of light in this system are calculated using
Feynman path-integral and diagrammatic techniques. This propagation leads to a non-Gaussian
joint distribution of the input and output optical ﬁelds. We use these results to determine the
amplitude and timing jitter of a signal pulse and to estimate the system capacity in analog commu-
nication.

I.

INTRODUCTION

A. General

The ability to transmit information is ultimately lim-
ited by signal distortion. Information theory1,2 quantiﬁes
the extent to which such distortions inhibit communica-
tion; it was originally developed for the study of radio
communication or electrical communication along cop-
per wires. In these cases the signal propagation is linear-
the received signal is a linear function of the transmitted
signal. Distortion arises due to the addition of extrane-
ous signal ﬂuctuations, which propagate linearly along-
side the original signal. These ﬂuctuations may come
from noisy ampliﬁers or other circuit elements, or from
cross-talk with other messages. Such linear systems with
additive noise are very well characterized from an infor-
mation theoretical perspective.

In modern communication systems, the situation is
rather more complicated. The very high transmission
rates- particularly in optical communication- require that
the transmission medium be operated in regimes where
the signal propagation is substantially non-linear3. These
nonlinearities can lead to a variety of new mechanisms
of signal distortion4,5,6,7,8,9 and are often very diﬃcult
to characterize analytically. This has limited the under-
standing of non-linear channels, particularly from an in-
formation theoretical perspective.

Faced with these diﬃculties, there are two ways in
which progress may be made. One approach is to perform
detailed numerical simulations of the underlying partial
diﬀerential equation. This has been the approach of much
of the work in the literature. However, it is very dif-
ﬁcult to use the results of such analyses to understand
the information theoretical aspects of communication in
non-linear media. An alternative approach is to harness
physical understanding of the signal propagation to moti-
vate simple phenomenological models that capture some
aspects of the non-linear propagation, but which are nev-
ertheless analytically tractable. This approach has been

used to understand a number of aspects of non-linear
propagation in optical ﬁbers4,5,6,7,8,9. Only recently have
such approaches been applied to study the information
theoretical aspects of the problem10,11,12.

When one is interested in optimizing the design of a
communications system, it is often useful to characterize
the various mechanisms of signal distortion according to
their physical origin in the system. This is not always
the best way of classifying signal distortion from an in-
formation theoretical point of view. A more convenient
classiﬁcation is to divide signal distortions into additive
and multiplicative noise. The signal distortions in opti-
cal ﬁbers may be classiﬁed in this manner12.
It is the
multiplicative noise that presents the main diﬃculty in
understanding non-linear channels. It lies behind some
of the classic unsolved problems in information theory2.
It is to this aspect of the problem that path-integral and
diagrammatic techniques are particularly suited. In the
system studied in this paper, multiplicative noise appears
as a random potential in a Schr¨odinger equation.

The tension between additive and multiplicative noise
is similar to the tension between disorder and interac-
tions in many-body physics. In the latter case, the con-
sequence of this tension is that a full analytical charac-
terization is not possible.
Instead, one must resort to
approximation schemes that are appropriate under dif-
ferent regimes of system parameters. It is likely that for
the same reasons one will be forced to use similar ap-
proximate schemes to study the propagation of signals
in non-linear media. Physicists have worked hard to de-
velop such schemes and some of them are directly appli-
cable to the study of non-linear signal propagation; for
example, Falkovich et al13 have used the theory of opti-
mal ﬂuctuation to understand the ﬂuctuations in soliton
amplitude and timing that occur in optical communica-
tion. In this paper, we use Feynman path-integral14 and
diagrammatic techniques15 in order to understand some
of the eﬀects of non-linearity upon optical communica-
tion. Most of this paper will concentrate upon charac-
terizing the propagation of light in the ﬁber. Towards the

end of the paper, we will harness this characterization to
understand some information theoretical aspects of the
problem.

B. The wavelength division multiplexed (WDM)
optical ﬁber.

In this paper, we will consider some of the eﬀects of
non-linearity upon communication using frequency divi-
sion multiplexed optical ﬁbers3. Optical ﬁbers have an
enormous transparent bandwidth. It is far beyond cur-
rent electronics to modulate at these frequencies. In or-
der to utilize as much of the bandwidth as possible, it
is divided into a number of non-overlapping frequency
bands, or sub-bands, each of which is modulated indepen-
dently. This is called frequency division multiplexing or
alternatively wavelength division multiplexing(WDM).

Light propagating in a WDM optical ﬁber experiences
several sources of signal distortion and non-linearity. The
ﬁrst of these is due to dispersion; the diﬀerent frequency
components of a signal travel at diﬀerent velocities along
the ﬁber, leading to a spreading of a signal pulse. This
spreading is a linear operation, however, and does not
reduce the capacity to communicate information. The
eﬀects of dispersion could be taken into account by a suit-
able linear transformation of the received signal during
processing. Usually, however, dispersion is accounted for
by introducing dispersion compensating elements into the
transmission link; Spans of standard, dispersive ﬁber are
interleaved with spans of dispersion compensating ﬁber
in which the sign of dispersion has been reversed, so that
more slowly moving frequency components catch up with
the faster moving components.

As light propagates in an optical ﬁber, some of it is
scattered out of the ﬁber by Raman scattering leading to
a loss of signal power. This is compensated for by the
periodic insertion of short spans of lasing ﬁber. As the
light passes through the lasing ﬁber, it is ampliﬁed by
stimulated emission. It is impossible to avoid a certain
amount of spontaneous emission in this process. This
is ampliﬁed alongside the signal and provides a source
of additive noise called ampliﬁed spontaneous emission
(ASE) noise.

Although we take full account of the eﬀects of disper-
sion, dispersion compensation and ASE noise in our anal-
ysis, these are not the main focus this of work. A system
with only these eﬀects is a linear system with additive
noise. This is precisely the type of system understood
by Shannon many years ago1. The additional aspects of
optical communication are the non-linearities present in
the propagation of light in an optical ﬁber. The most im-
portant of these non-linearities is the optical Kerr non-
linearity, by which the refractive index of the ﬁber de-
pends upon the intensity of light in the ﬁber3.

The Kerr non-linearity causes scattering between dif-
ferent frequency components of light in the ﬁber. Two
incoming frequency components scatter into two outgo-

2

ing frequency components. In WDM systems the eﬀects
of the Kerr non-linearity are grouped according to the ori-
gin of the frequency components which scatter oﬀ one an-
other. When the incoming and outgoing frequency com-
ponents all lie in the same sub-band, the eﬀect is known
as self-phase modulation (SPM). It is this non-linearity
that is responsible for the possibility of soliton propaga-
tion within a sub-band. The combination of SPM and
ASE noise leads to several mechanisms of signal distor-
tion: ﬂuctuations in the amplitude and arrival times of
soliton pulses, known as Gordon-Haus jitter4; non-linear
ampliﬁcation of the phase noise5; and, depending upon
the sign of dispersion, a non-linear instability of ampli-
tude ﬂuctuations about a constant signal called the mod-
ulation instability9. When the incoming frequency com-
ponents are in diﬀerent sub-bands and scatter back into
their original sub-bands, the eﬀect is called cross-phase
modulation (XPM). This is the eﬀect that we will concen-
trate upon here. We will show explicitly that this leads
to multiplicative noise- to a spatially and temporally ran-
dom potential due to the signal in the other sub-bands.
We will ﬁnd a super-diﬀusive spreading of the pulse shape
and a super-diﬀusive spreading of arrival times. Finally,
the eﬀect of the Kerr non-linearity when all of the incom-
ing and scattered frequency components lie in diﬀerent
sub-bands is known as four wave mixing (FWM). From
the point of view of the signal in any particular sub-band,
it has an identical eﬀect to additive ampliﬁer noise16.

A complete WDM optical communications system con-
sists of a series of spans of standard, dispersive ﬁber in-
terleaved with dispersion compensating ﬁbers and loss
compensating ampliﬁers. The precise ordering of these
elements is known as the dispersion map. The perfor-
mance of the system can depend quite sensitively upon
this dispersion map. However, for concreteness, we will
restrict ourselves to one particular map, shown in Fig1.
Our approach will be to calculate Feynman path inte-
grals describing the propagation of light in a single sub-
band, taking account of scattering from signals in the
other sub-bands through XPM. The Green’s functions for
this propagation must be averaged over realizations of the
signal in the other sub-bands. The Green’s functions for
propagation in the optical ﬁber turn out to be the Green’s
functions of a Schr¨odinger equation with spatially and
temporally random potential. The main calculations in
this paper are the evaluation of the single and two parti-
cle Green’s functions of this Schr¨odinger equation. This
calculation is similar to calculations carried out in two
other contexts: Turbulent ﬂow or the growth of interfaces
may both be described by the KPZ equation17,18,19. This
may be mapped to a diﬀusion equation with spatially and
temporally random potential. Calculating the quadratic
statistics for these processes and averaging over the tur-
bulent ﬂow or noise in the growth process is very similar
to calculating the two particle Green’s function in our
problem. In particular, short-range temporal correlations
allow the calculation to be reduced to an eﬀective single
body problem for which the Feynman path integral may

be readily calculated. We will ﬁnd the same structure in
our solution to the present problem. The second prob-
lem to which our work bears similarity is the calculation
of Green’s function in the presence of a quenched ran-
dom potential15. In this context, it is usual to truncate
the diagrammatic series for the single and two particle
Green’s functions to the Born and Ladder series, respec-
tively. Here we will ﬁnd that this truncation is justiﬁed
by the short range temporal correlations of the random
potential.

Our approach contrasts with other methods of includ-
ing the eﬀects of XPM in WDM systems6, in which indi-
vidual scattering events between soliton pulses in diﬀer-
ent sub-bands are considered. Our results are very sim-
ilar to those obtained for Gordon-Haus jitter4, although
of a diﬀerent physical origin.

Before going on to a detailed calculation, let us ﬁrst
state our results and the physics underlying them. As
a signal pulse propagates along a particular sub-band it
passes through regions of higher and lower intensity of the
total signal in the other sub-bands. This causes the pulse
to speed up and slow down due to the Kerr non-linearity.
Since the signals in the other sub-bands are unknown to
the users of any particular sub-band, this speeding up
and slowing down of the pulse has a statistical uncer-
tainty. The result is a diﬀusive spreading of the phase
velocity and a corresponding super-diﬀusive spreading of
the distribution of pulse arrival time; hδT 2i ∝ L3(to see
this requires integrating the diﬀusively spreading phase
velocity over the length of propagation). This is the main
result of our calculation. The functional form is very sim-
ilar to that obtained previously for Gordon-Haus jitter4,
although its physical origin is slightly diﬀerent; it is due
to XPM rather than a combination of SPM and ASE
noise. In addition to the uncertainty in the pulse arrival
time, the pulse shape itself is distorted due to the eﬀect
of XPM; since they travel at diﬀerent speeds, the dif-
ferent frequency components of the pulse sample slightly
diﬀerent portions of the signal in the other channels and
arrive at slightly diﬀerent times. Therefore, the pulse
width itself will show a super-diﬀusive spreading due to
the eﬀects of XPM. The eﬀect of XPM upon the pulse
power is much weaker than its eﬀect upon pulse timing.
The processes leading to ﬂuctuations in pulse power are
of higher order in the (weak) non-linearity. The timing
errors induced by XPM cause the pulse power to spread
over a larger interval leading to the possibility of over-
lap between adjacent pulses. This intersymbol interfer-
ence allows timing errors to be converted into amplitude
errors. Numerical simulation, however, shows that the
dominant contribution to amplitude errors comes from
SPM16, the eﬀects of which are not studied here.

II. THE MODEL

The propagation of light in an optical ﬁber is described
by Maxwell’s equations with a dielectric constant depen-

3

Standard Fibre

DCfibre

Amp

x10

80km

16km

FIG. 1: Schematic Diagram of Optical Fiber System

dent upon the energy density of the electromagnetic ﬁeld.
The optical ﬁbers used in communications systems sup-
port only one transverse mode. Expanding the Maxwell’s
equation for the low frequency envelope of the electric
ﬁeld and taking the long wavelength limit, one obtains a
non-linear Schr¨odinger equation with the roles of space
and time interchanged3:

i∂zE(z, t) =

β∂2

t − iα

E(z, t)− γ |E(z, t)|2 E(z, t). (1)

(cid:0)

(cid:1)

The term proportional to α on the right-hand side of
this equation describes the loss of optical power from
the channel and the term proportional to γ encodes the
eﬀects of the Kerr non-linearity. Dividing the electric
ﬁeld into its components in each sub-band of the WDM
system, the low frequency envelope of the electric ﬁeld in
the ith sub-band, Ei(z, t), is given by

i∂zEi(z, t) =

β∂2

t − iα

Ei(z, t) + V (z, t)Ei(z, t),

V (z, t) = −2γ

(cid:0)

|Ej(z, t)|2.

(cid:1)

(2)

Xj6=i

P

j,k6=i E∗

In writing down this expression we have neglected self-
phase modulation, γ |Ei(z, t)|2 Ei(z, t), and four-wave
mixing, γ
j (z, t)Ek(z, t)Ei(z, t). This neglect
of self-phase modulation and four-wave mixing may be
justiﬁed on two grounds. Firstly, there are regimes
where numerical simulation conﬁrms this to be a good
approximation16. Studying the system in the absence of
the eﬀects of self-phase modulation and four-wave mix-
ing allows us to deduce the eﬀects of XPM. Our aim is to
determine what constraints are imposed upon communi-
cation by these eﬀects. In a real system, other sources of
signal distortion will impose additional constraints, but
these are not of direct concern in this paper. Equation(2)
corresponds to a non-linear Schr¨odinger equation with a
spatially and temporally random potential due to non-
linear interaction with the signals in the other sub-bands.
The eﬀects of loss in this system may be accounted for by
using rescaled electrical ﬁelds that maintain their ampli-
tude during propagation; Eef f,i(z, t) = eαzEi(z, t). The
propagation of these rescaled ﬁelds is described by Eq.(2)
with an exponential rescaling of the strength of non-
linearity, γef f = γ(1−e−αL)/αL, where L is the length of
a single span of ﬁber, and without the loss term propor-
tional to α. Henceforth, we will assume the use of these
rescaled ﬁelds and drop the subscript ef f for brevity.

We follow Ref.10 and model the stochastic potential by
a Gaussian distribution with short-ranged correlations in

(cid:2)

(γP )2/(2β∆δW )

dzhδV (z, t)δV (0, t)i =

space and time; the signals in the separate sub-bands are
statistically independent and have short-ranged temporal
correlations on timescales of order 1/bandwidth. Rel-
ative dispersion of signals in diﬀerent sub-bands leads
to short-ranged spatial correlations, which may be ap-
proximated by a delta-function if the dispersion is suf-
ﬁciently large. The strength of the potential, η =
ln [nc/2], is
obtained by summing the contributions from nc channels
R
with separation δW , bandwidth ∆ and signal power, P .
The logarithmic dependence upon the number of chan-
nels is due to the suppression of the eﬀects of widely sep-
arated channels by dispersion10. In the following section,
we will often write hδV (z, t)δV (0, 0)i = 2πη/∆δ(t)δ(z),
with an explicit delta-function in time. This simpliﬁes
our calculations and elucidates which contributions are
most important for propagation in a potential with short
temporal correlations. It is important to realize, however,
that the potential and signal are both band-limited, so
that the correlations are not strictly delta-functional. We
account for this by regularizing the delta-function of zero
argument to δ(t = 0) = ∆/2π.

(cid:3)

The system considered here consists of 10× [80km
standard ﬁber followed by 16km dispersion compensat-
ing (d.c.) ﬁber and a loss compensating ampliﬁer]. The
input signal has power, bandwidth and channel sepa-
ration P = 5mW, ∆ = 10GHz and δW = 15GHz,
respectively. The standard/dc ﬁber loss, non-linearity
and dispersion parameters are α = 0.048/0.115km−1,
γ = 1.2/5.1W−1km−1 and β = 11.0/ − 66.9ps2km−1.
Comparing γP/α for the standard and d.c. ﬁbers gives a
measure of their relative strengths of non-linearity. The
power entering the d.c ﬁber is a factor of ∼ 50 lower
than that entering the standard ﬁber. This, combined
with the greater loss in the d.c. ﬁber, leads to an eﬀec-
tive strength of non-linearity ∼ 150 times greater in the
standard ﬁber. We ignore non-linearity in the d.c ﬁber
in our analytical work. It may be included in precisely
the same way as in the standard ﬁber and does not lead
to any qualitative change in our results. Three impor-
tant lengthscales may be determined from these system
parameters; the total ﬁber length, Ltot = 10 × 80km,
the non-linear length, η−1 = 223km, and the dispersion
length, LD = (β∆2)−1 = 747km. The response of the
system is completely determined by the ratios of these
three lengthscales.

III.

INPUT OUTPUT STATISTICS

The output electric ﬁeld, Eout(t), after propagating
along a single span of standard ﬁber, may be expressed
in terms of the input electric ﬁeld Ein(t) as

Eout(t) =

dt′G(t, t′)Ein(t′) + n(t),

(3)

Z

where n(t) is additive Gaussian white noise, with vari-
ance N , representing ASE noise. G(t, t′) is the Green’s

4

function of Eq.(2) for propagation from z = 0 at time t
to z = L at time t′, with a ﬁxed realization of V (z, t).
More generally, we will use the notation G(z1, z2; t1, t2)
to indicate the Green’s function for propagation from
t = t1, z = z1 to t = t2, z = z2. Using this notation,
G(t1, t2) ≡ G(0, L; t1, t2). Suppression of one of the spa-
tial indices implies propagation from z = 0; G(z; t1, t2) ≡
G(0, z; t1, t2). Similarly, G(z, t) ≡ G(0, z; 0, t). It is par-
ticularly important to note that G(t1, t2) 6= G(t1 − t2) as
would be the case for a static potential.

Dispersion compensation is included by replacing
G(t, t′) in Eq.(3) with a dispersion compensated Green’s
function, Gd(t, t′). This is obtained by convolving the
Green’s function for the standard ﬁber, G(t, t′), with
the Green’s function for the dispersion compensating
dt′′Gcomp(t, t′′)G(t′′, t′).
ﬁber, Gcomp(t, t′); Gd(t, t′) =
Gcomp(t, t′), has the opposite sign of β to G(t, t′) and de-
scribes propagation with no potential, V .

R

Propagation along a series of interleaved standard and
d.c spans is modeled by convolving a string of disper-
sion compensated Green’s functions. This convolution
is independent of the ordering of the Green’s functions
and the eﬀects of XPM are, therefore, independent of
the dispersion map. Real systems are sensitively depen-
dent upon the choice of map due to the eﬀects of SPM,
which is ignored here. Finally, due to the unitarity of
Gd(t, t′), adding ASE noise at each ampliﬁer is equiva-
lent to adding Gaussian white noise at the receiver. An-
alytical calculations may, therefore, be performed using
a simpliﬁed dispersion map consisting of Ns standard
spans followed by Ns dispersion compensating spans and
adding Gaussian white noise at the receiver.

We now use this simple model of the system to calcu-
late the eﬀects of XPM upon the input/output statistics.
The quadratic statistics are given by

hE∗
hE∗
hE∗

in(t)Ein(t′)i = P δ(t − t′),
in(t)Eout(t′)i = P hGd(t, t′)i,
out(t)Eout(t′)i = (P + N )δ(t − t′),

(4)

and the quartic statistics are given by

hδ|Ein(t)|2δ|Ein(t′)|2i = ∆P 2δ(t − t′)/2π,
hδ|Ein(t)|2δ|Eout(t′)|2i = P 2GII
hδ|Eout(t)|2δ|Eout(t′)|2i = ∆(P + N )2δ(t − t′)/2π.(5)

d (t − t′),

The angular brackets indicate averages over the signal
in the sub-band of interest, the signals in the other sub-
bands and the ampliﬁer noise. hGd(t, t′)i is the average of
the dispersion compensated, single particle Green’s func-
tion over the potential (or realizations of the signal in
d (t − t′) = h|Gd(t, t′)|2i is
the other sub-bands) and GII
the average of the two-particle Green’s function over the
random potential. The input signal is assumed to have
a Gaussian distribution with power P and the ampli-
ﬁer noise to have a Gaussian distribution with power N .
We have used the unitarity of the single point Green’s
function for a particular realization of the potential in

deriving Eqs.(4) and (5); G(t, t) = 1. The delta-function,
δ(t−t′ = 0), has been regularized as discussed in Sec.II, to
allow for the fact that the sub-band has a bandwidth ∆;
δ(t − t′ = 0) = ∆/2π. The averaged Green’s functions,
hGd(t, t′)i and GII
d (t − t′) are invariant under temporal
translations and are, therefore, functions of t − t′.

The statistics embodied by Eqs.(4) and (5) are non-
d (t − t′) 6= |h|Gd(t, t′)i|2 in general.
Gaussian, since GII
The corrections to Gaussian statistics are given by the
vertex corrections to the two-particle Green’s function.
Alternatively, one may say that linear propagation in the
presence of a random potential leads to non-linear prop-
agation on average. Calculation of the quadratic and
quartic statistics in terms of Green’s functions allows a
simple characterization of this non-linearity. In the fol-
lowing section, we will give an explicit calculation of the
averaged Green’s functions and follow this in the subse-
quent sections by a discussion of their consequences for
optical communication. The quadratic statistics will be
useful for our discussion of coherent communication and
the quartic statistics will be useful for our discussion of
incoherent communication.

IV. CALCULATIONS

The average Green’s functions hGi and GII may
be
calculated from their Feynman path integral
representations14. If we assume that the stochastic po-
tential is delta-function correlated in time, these path
integrals may be evaluated in closed form. These results
correspond to re-summing the Born and ladder series15
in the diagrammatic expansions of hGi and GII , respec-
tively. These series may be used to approximate the ef-
fects of a non-delta-function correlated potential. The
diagrams that are neglected in this approximation are
small for a potential with short ranged temporal correla-
tions; the use of a delta-function correlated potential is
a calculational tool that emphasizes the range of validity
of this approximation. In the following , we will calcu-
late equations of motion for hGi and GII from their path
integrals, under the assumption that V is delta-function
correlated in time. We will show how the solutions of
these equations correspond to the re-summed perturba-
tive, ladder and Born series. Finally, the average Green’s
functions hGi and GII will be calculated allowing for the
band limit of the sub-band and potential due to the other
sub-bands.

A. Single particle Green’s function

Recalling that the roles of space and time have been in-
terchanged here compared with their more familiar roles
in quantum mechanics, the single particle Green’s func-

5

tion is written in the form

hG(L, t)i = h

Dt(z) exp

−

L

dz

i
2β

(∂zt(z))2

−i

dzV (z, t(z))

t(L)=t

t(0)=0

Z

L

0
Z
t(L)=t

t(0)=0

Z

−

1
2

L

L

0 Z
0
Z

"

0
Z

i
#

"

0
Z

=

Dt(z) exp

−

L

dz

i
2β

(∂zt(z))2

dzdz′hV (z, t(z))V (z′, t(z′))i
,(6)
#

where the angular brackets denote averages over realiza-
tions of V . We have carried out the average over V in
order to obtain the second line, assuming that V is a
Gaussian random variable.

Taking the derivative of Eq.(6) with respect to L14, we

obtain the following equation of motion for hGi:

β
2

(cid:18)

−i

∂2
t − ∂L

hG(L, t)i

(cid:19)

L

∞

= δ(L)δ(t) +

dt′dzhV (L, t)V (z, t′)i

0 Z
Z
×hG(L − z, t − t′)ihG(z, t′)i.

−∞

(7)

(cid:1)

local

in time

t /2 − ∂L

equation is
that

for a stochastic
This
potential
is delta-function correlated in time;
hV (z, t)V (0, 0)i = (2πη/∆)δ(t)δ(z). The solution of this
local equation of motion is hG(L, t)i = e−ηL/2G0(L, t),
where G0(L, t) is the Green’s function of the operator
, i.e. the Green’s function for propaga-
−iβ∂2
tion in the absence of V . This result was ﬁrst obtained in
(cid:0)
Ref.10. Equation(7) may also be obtained diagrammati-
cally by re-summing the Born series; it is nothing but the
Dyson’s equation for hG(L, t)i obtained by re-summing
this series15. The temporal delta-function correlation of
V implies that the propagators of V must not cross, thus
restricting the contributing diagrams to the Born series.
Figure 2. shows a symbolic representation of Eq.(7) after
multiplying on the left by G0. The dashed line indicates
propagators of V , the solid line indicates G0 and the thick
solid line indicates hGi. This diagram is to be interpreted
in real space or momentum space in the usual way. The
momentum/frequency space solution is

hG(p, ω)i = i

p − βω2 + iη/2

−1

,

(8)

(cid:0)

where p is the wavevector conjugate to z and ω is the
angular frequency conjugate to t. For later calculations,
it is useful to have hGi in a mixed, position/frequency
notation, where it is given by

(cid:1)

hG(z, ω)i = exp

−

η/2 − iβω2

z

.

(9)

Dispersion compensation is achieved by temporally con-
volving G(L, t) for the standard ﬁber with that of the

(cid:2)

(cid:0)

(cid:1)

(cid:3)

6

we perform the average over V and deduce an equation
of motion for GII by diﬀerentiating with respect to L.
This diﬀerential equation is local in time when the cor-
relation function of V is a temporal delta-function. The
equation of motion is most easily solved in the frequency
domain, where it is recognizable as the re-summed lad-
der series. As before, the set of contributing diagrams is
restricted due to the requirement that the propagators of
V may not cross. We will ﬁrst of all derive an expression
for GII (ω, q) in the absence of dispersion compensation
from its path integral representation. We will verify that
this result is identical to that obtained by summing the
ladder series of diagrams. In fact, closed expressions for
GII (L, t) are most readily obtained by re-summing this
series directly in the length/frequency domain. We ex-
plicitly carry out this re-summation to obtain expressions
for GII (L, ω) and its dispersion compensated counterpart
GII
d (L, ω).
We will ﬁrst derive a path integral and equation
of motion for the Green’s function, GII (L; τ1, τ2) =
hG(L, τ1)G∗(L, τ2)i. In the end we will be interested in
GII (L, t) = GII (L; τ1 = t, τ2 = t). The path integral
representation of GII is

=

+

FIG. 2: Born series for hGi.

compensating ﬁber (or alternatively multiplying together
Ig-
the position/frequency space Green’s functions).
noring non-linearity in the compensating ﬁber, we ﬁnd
Gcomp(L, t) = G∗
0 (L, t). The dispersion compensated
Green’s function is then given by

hGdi(L, t) = e−ηL/2δ(t).

(10)

On average, therefore, the eﬀects of XPM non-linearity
separate from those of dispersion. Moreover, the eﬀect
of XPM is to dephase the propagating electric ﬁeld.

B. Calculation of G

II

The calculation of GII from its path integral proceeds
in a very similar manner to the calculation of hGi. Af-
ter writing down the path integral representation of GII ,

GII (L; τ1, τ2) = hG(L, τ1)G∗(L, τ2)i
τ1(L)=τ1,τ2(L)=τ2

dz

i
(cid:18)

(cid:20)Z

(∂zτ1)2
2β

− i

(∂zτ2)2
2β

(cid:19)(cid:21)

− i

(∂zτ2)2
2β

(cid:19)(cid:21)

= h

Dτ1(z)Dτ2(z) exp

Z

× exp

τ1(0)=0,τ2(0)=0
1
2
τ1(L)=τ1,τ2(L)=τ2

−

Z

(cid:20)

i

dz

dz (−iV (z, τ1(z)) + iV (z, τ2(z)))
(cid:21)
(∂zτ1)2
2β

Dτ1(z)Dτ2(z) exp

i
(cid:18)
dzdz′hV (z, τ1(z)) V (z′, τ1(z′))i
(cid:21)
dzdz′hV (z, τ2(z)) V (z′, τ2(z′))i
(cid:21)

(cid:20)Z

Z
dzdz′hV (z, τ1(z)) V (z′, τ2(z′))i
(cid:21)

=

τ1(0)=0,τ2(0)=0

Z

× exp

−

1
2
1
2

Z

× exp

−

× exp

(cid:20)

(cid:20)

(cid:20)Z

(11)

The average over V has been carried out in passing from
the penultimate to ﬁnal line of Eq.(11). The equation of
motion for GII is derived by diﬀerentiating both sides of
this equation with respect to L. The resulting diﬀeren-
tial equation is local in time when V has delta-function
correlations in time. It is slightly easier to make the as-
sumption of temporally delta-function correlations for V
in Eq.(11) before diﬀerentiating. The path integral then
reduces to

GII (L; τ1, τ2) =

Dτ1(z)Dτ2(z)

τ1(L)=τ1,τ2(L)=τ2

τ1(0)=0,τ2(0)=0

Z

dz

(∂zτ1)2
2β

i
(cid:20)Z
(cid:18)
δ (τ1(z) − τ2(z))

× exp

−η

2π
∆

− i

(∂zτ2)2
2β

+ η

.

(cid:19)(cid:21)

(12)

This result is very similar to that obtained in the analysis
of the diﬀusion equation with a spatially and temporally
random potential17. In that case, the path integral for
the square of the wavefunction reduced to that of two
interacting random walks. Here the path integral for GII
reduces to that of two interacting Schr¨odinger particles,
or waves, propagating in opposite directions. Diﬀerenti-

(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)

(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)

=

(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)

+

(cid:1)
(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:1)
(cid:0)
(cid:1)
(cid:0)
(cid:0)
(cid:1)
(cid:0)
(cid:1)
(cid:0)
(cid:1)
(cid:1)
(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:1)
(cid:0)

(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)

FIG. 3: Ladder series for G

II

.

ating Eq.(12) with respect to L, we obtain the following
local equation of motion for GII .

∂L − i

(∂2

τ1 − ∂2

τ2) + η

GII (L; τ1, τ2)

β
2

(cid:18)

= δ(L)δ(τ1)δ(τ2) + η

δ(τ1 − τ2)GII (L; τ1, τ2).(13)

(cid:19)

2π
∆

This equation is most easily solved by ﬁrst changing co-
ordinates to the mean time, t = (τ1 + τ2)/2, and time
diﬀerence, T = (τ1 − τ2)/2. After Fourier transforming
in space and time we ﬁnd

− i

q −

ωΩ + iηδ(0)

GII (q; ω, Ω)

β
2

(cid:18)

= 1 +

2πη
∆

(cid:19)
dΩ
2π

GII (q; ω, Ω),

(14)

Z
where ω and Ω are the angular frequencies conjugate to t
and T , respectively and q is the wave-vector conjugate
to L. Equation(14) is equivalent to the ladder series
In order to make this correspondence
shown in Fig.2.
clear, the eﬀects of non-linearity have been divided into
two parts; the term proportional to η on the left hand
side of Eq.(14) takes account of self-energy correction to
the single particle Green’s function and the term propor-
tional to η on the right hand side takes account of vertex
corrections. Following the usual convention, we denote
the solution of Eq.(14) in the absence of vertex correc-
tions by Π(q; ω, Ω) = −i (q − βωΩ/2 + iη)−1. One may
check by direct substitution of hG(q, ω)i from Eq.(8) that
dp/2πhG(q + p, ω + Ω)ihG∗(p, Ω)i. Finally,
Π(q; ω, Ω) =
using the notation Π(q, ω) =
dΩ/2πΠ(q; ω, Ω), the so-
R
lution of Eq.(14) is

GII (q, ω) =

R

Π(q, ω)
∆ Π(q, ω)

1 − 2πη

= Π(q, ω)

1 +

Π(q, ω)

2πη
∆

2

(cid:18)
2πη
∆

(cid:18)

(cid:19)

+

Π(q, ω)2 + ...

,

(15)

!

The modiﬁcation to these results due to dispersion
compensation is not quite as simple as the modiﬁcation
to hGi. Although it is possible to derive a path integral
expression for GII
d akin to Eq.(13), it is easiest to derive
the dispersion compensated GII using diagrammatic per-
turbation theory in the length/frequency domain. The

7

(16)

(17)

appropriate diagrammatic series is shown in Fig.4. The
result of summing this series is

GII
d (L, ω)
= Πd(L, ω)
2πη
∆

+

L

0
Z
2πη
∆

+

(cid:18)
+...

Π(z, ω) is given by

dxΠ(x, ω)Πd(L − x, ω)

2

L

x

(cid:19)

0
Z

0
Z

dx

dyΠ(x, ω)Π(y, ω)Πd(L − y, ω)

Π(z, ω) =

hG(z, ω′ + ω/2)ihG∗(z, ω′ − ω/2)i

Z
= e−ηz

dω′
2π

Z

dω′
2π

′

ωz

eiβω

and Πd(z, ω) is the dispersion compensated analogue of
Π(z, ω), given by

Πd(z, ω) =

hG(z, ω′ + ω/2)iG∗

dω′
0 (L, ω′ + ω/2)
2π
×hG∗(z, ω′ − ω/2)iG0(L, ω′ − ω/2)

Z

= e−ηz

′

eiβω

ω(z−L).

(18)

dω′
2π

Z

The calculation of GII proceeds by substituting Πd(z, ω)
and Π(z, ω) into Eq.(16), carrying out the frequency inte-
grals in each term, followed by the integrals over length,
and ﬁnally summing the contributions from each term.
In carrying out this procedure, one must take careful
account of the support for the various frequency inte-
grals. The band limitation of the sub-band implies that
the angular frequency carried by each internal Green’s
function must lie between −π∆ and +π∆. Carrying
out the frequency integrals with this restriction leads to
very complicated expressions. An alternative approach,
which yields much more manageable expressions, is to
take into account the fact that the stochastic potential
is not strictly delta-function correlated in time, but is
band-limited to lie between −π∆ and +π∆. We use the
fact that V has short range correlations in time to justify
neglecting terms other than those of the Born and ladder
series in our diagrammatic calculation, but allow for the
band limitation of V in calculations of internal frequency
integrals.

Let us illustrate this by explicitly calculating the sec-

ond order term in Eq.(16). This is given by

L

x

0
Z

L

0
Z

x

=

dx

dy

dω1
2π

dω2
2π

dω3
2π

0
Z

0
Z
× exp [iβω(ω3 − ω2)x + iβω(ω2 − ω1)y]
πβω∆L

Z

X

3

=

∆
2π

(cid:18)

(cid:19)

e−ηL

0

Z

dX

dY

0
Z

sin X
X

sin Y
Y

which corresponds to the ladder diagram shown in Fig.3.

dx

dyΠ(x, ω)Π(y, ω)Πd(L − y, ω)

standard fiber

d.c. fiber

at short times. We will discuss the consequences of these
results for communication in the following sections.

8

0

0

2πη
∆

2πη
∆

2

0

x

x

y

L

L

L

+

+

+

Π(ω,   )x

Π(ω,       )
y−x

Π  (ω,        )
L−y

d

2L

2L

2L

 

FIG. 4: Position-space diagrammatic series for G

II
d (L, ω).

=

∆
2π

3

Le−ηL 1
2

(cid:18)

(cid:19)

Si[X]
X

(cid:18)

,

(19)

X=πβω∆L

(cid:19)(cid:12)
(cid:12)
(cid:12)
(cid:12)

X
0 du sin u/u. We have carried out
where Si[X] =
the frequency integrals in passing between the second,
R
third and fourth lines. The integration variables have
been changed from ω1, ω2 and ω3 to ω1, ω3 − ω2 and
ω2 − ω1. Integrations have been carried out over the do-
mains −∆/2 ≤ ω1, ω3 − ω2, ω2 − ω1 ≤ ∆/2, the ﬁrst
corresponding to the band-limitation of the signal in the
sub-band and the second and third to band-limitation of
the stochastic potential leading to a restriction on the
transfer of frequency at each vertex.

Calculating each term in the series in this way and

re-summing, we obtain our ﬁnal result

GII
d (L, ω) =

exp

−ηL

1 −

∆
2π

Si[X]
X

,

X=πβω∆L

(cid:20)

(cid:18)

(20)
for dispersion compensated propagation. The Green’s
function for uncompensated propagation is calculated
similarly replacing Πd with Π in Eq.(16). The result is

(cid:19)(cid:21)(cid:12)
(cid:12)
(cid:12)
(cid:12)

GII (L, ω) = GII

d (L, ω)

sin X
X

.

(21)

X=πβω∆L
(cid:12)
(cid:12)
(cid:12)
(cid:12)

The prefactor of sin X/X describes the dispersive spread-
ing of a pulse propagating in the absence of non-linearity.
The distortion of the pulse due to XPM is described by
GII
d (L, ω). There are two important limits of Eq.(20).
At small frequencies, Si[X]/X → 1 − X 2/18. As a
consequence, GII
d (L, ω) tends to a Gaussian of width
D/ηL3
tot. The interpre-
tation of this width as an eﬀective bandwidth will be
p
discussed below. At large frequencies, GII
d (L, ω) tends to
a constant. These limits imply that GII
d (L, t) has Gaus-
sian tails at large times and approaches a delta-function

hω2i = 2π∆ef f = (3∆/π)

L2

p

V. AMPLITUDE AND TIMING JITTER

The results of sections III and IV give the input/output
statistics of the WDM optical ﬁber in terms of its single
and two-particle Green’s functions. In this and the fol-
lowing section, we shall use these results to discuss the
eﬀectct of XPM upon communication.

Firstly, we discus two operational measures of the ef-
ﬁciency of an optical communications system. Our dis-
cussion will be quite brief, since these considerations are
not central to the main message of this paper. Neverthe-
less, it is important to demonstrate that analytical results
such as Eqs. (20) and (21) can be used to enhance under-
standing from this operational perspective. A common
way of characterizing signal distortion in optical com-
munications is by amplitude and timing jitter. These
measures of system performance are speciﬁc to digital
communication. A digital message is made up of a string
of pulses or marks representing 1s, and spaces represent-
ing zeros. As a pulse propagates along a noisy channel,
it speeds up and slows down in a random way leading to
a distribution of arrival times(deﬁned as the centroid in
time of the power distribution at the output) at the re-
ceiver known as timing jitter. Similarly, the total power
of the pulse ﬂuctuates leading to a distribution of am-
plitudes of the received pulse known as amplitude jitter.
The distributions of amplitude and timing ﬂuctuations
need not be independent13. In fact, the terms amplitude
and timing jitter are often reserved for the variance in
amplitude and arrival times of a pulse. This is the sense
in which we shall uses these terms from now on. In ad-
dition to jitter, the shape of the individual pulses may
be distorted during propagation. We do not discus these
distortions here.

The eﬀects of SPM and ASE upon the amplitude and
timing jitter of soliton, or soliton-like, pulses has been
considered in a number of works, starting with Ref.4. All
of these works expand in small ﬂuctuations- induced by
the additive ASE noise- about a soliton solution. Such
analyses lead to the conclusion that amplitude jitter is
not very signiﬁcant and that timing jitter leads to an L3
dependence of the variance of arrival times. This latter
result is known as Gordon-Haus jitter after its discovery
in Ref.4. A recent work of Falkovich et al 13 has used a
saddle point approximation within a Martin-Siggia-Rose
ﬁeld theory for this propagation to obtain a full joint
distribution of amplitude and timing errors. This work
shows in a particularly transparent way, the connection
between the method of optimal ﬂuctuations in ﬁeld the-
ory and large deviations in statistics. Here we use Green’s
function techniques to consider the contribution of XPM
to jitter. Despite its diﬀerent physical origin, the result-
ing jitter has a broadly similar dependence upon system
parameters to Gordon-Haus jitter.

In principle, the output for an arbitrary input pulse
shape may be calculated, accounting for the eﬀects of
XPM, in terms of Green’s functions for propagation along
the ﬁber. The amplitude and timing jitter may then be
obtained by taking appropriate averages. This calcula-
tion may in practice prove rather cumbersome. How-
ever, the functional dependence of the jitter upon sys-
tem parameters is expected to be broadly independent
of the input pulse shape (the magnitude of the jitter will
show a weak dependence upon the pulse shape). For
simplicity, therefore, we present approximate expressions
for amplitude and timing jitter due to XPM, by con-
sidering the output for constant and delta-function in-
puts, respectively. The simple expressions obtained in
this way demonstrate the functional dependence of the
jitter upon the system parameters. In particular, we ﬁnd
that the variance of arrival times is proportional to L3,
whereas amplitude jitter is largely independent of XPM
. These functional dependences are the same as those
due to Gordon-Haus jitter although the physical origin is
somewhat diﬀerent4.

Timing jitter may be found by considering the re-
sponse to an input delta-function in time. A real sig-
nal pulse is band-limited, but it may be thought of as
being made up of many delta functions. The use of
a delta-function input allows us to calculate the func-
tional form of the timing jitter in an analytically tractable
way. The dependence of the resulting jitter upon sys-
tem parameters is expected to be broadly similar for
arbitrary input pulse shapes. Without XPM, the out-
put electric ﬁeld resulting from a delta function input is
Eout(t) = Gd(t) ∝ δ(t) and the modulus of the electric
ﬁeld is given by |Eout(t)|2 = |Gd(t)|2 ∝ δ(t). Introduc-
ing XPM broadens this response. Diﬀerent frequencies
making up the pulse see a slightly diﬀerent stochastic
potential and arrive at slightly diﬀerent times. Since the
signals in the neighboring sub-bands are unknown, this
broadening leads to uncertainty in the arrival time. Av-
eraging the response to a delta function input over real-
izations of the signals in the other sub-bands, therefore,
d (t) = h|Gd(t)|2i gives a measure of the
we ﬁnd that GII
distribution of arrival times. Using this interpretation
and the results of the preceding section on the calcula-
d , we ﬁnd ht2i = (2π∆ef f )−2 ∝ L3
tion of GII
totη; XPM
causes a super-diﬀusive spreading of arrival times. This
functional dependence of the timing jitter upon the ﬁber
length is identical to that found by Gordon and Haus for
the combined eﬀects of ASE noise and SPM4. Notice that
this contribution to timing jitter arises entirely from ver-
tex corrections to the 2-particle Green’s function, GII
d (t);
if we ignore vertex corrections by making the approxima-
d (t) = |hGd(t)i|2 and substituting Eq. (9), we ﬁnd
tion GII
no contribution to timing jitter.

Using Eq.(3) to calculate the statistics of the output
for inputs held constant at Ein(t) = 0 and Ein(t) = A
gives an estimate of the amplitude statistics of a 1 and 0
in the output bit stream7. For a zero input, the output
has the same Gaussian distribution as the noise. For an

9

input of constant amplitude A,

hEout(t)i1 = AhGd(ω = 0)i,
h|Eout(t)|2i1 = (A2 + N )δ(0),

hδ|Eout|2(t)δ|Eout|2(t)i1 = A4

h|Gd(ω = 0)|4i − δ(0)2

+N (2A2 + N )δ(0)2
≈ N (2A2 + N )δ(0)2,

(cid:2)

(cid:3)
(22)

where the delta-function of zero argument is to be un-
derstood as ∆/2π = δ(0) for our band-limited sub-band.
The evaluation of these results is outlined in the Ap-
pendix. The output for a 1 input is not Gaussian: a
Gaussian ﬁt to hEout(t)i1 and h|Eout(t)|2i1 does not re-
produce hδ|Eout|2(t)δ|Eout|2(t)i1. These results also pre-
dict that the contribution of XPM to amplitude jitter
is small. Equation (22) depends upon the evaluation of
h|G(ω = 0)|4i, which we have not carried out here. A
full evaluation of this 4-particle Green’s function would
be required to give a full expression for amplitude jitter.
If, however, we approximate h|G(ω = 0)|4i ≈ h|G(ω =
0)|2i2 = δ(0)2 then amplitude jitter shows no dependence
upon XPM. Corrections to this result arise from higher
order vertex corrections to the 4-particle Green’s func-
tion and are small for weak non-linearity. In particular,
these vertex corrections are of higher order than those
that give rise to timing jitter. The predominant eﬀect of
XPM, therefore, is to induce timing errors. This conclu-
sion is in accord with other works which have attempted
to model the eﬀects of XPM as a modiﬁcation to the
Gordon-Haus results for soliton jitter6. In these works,
individual scattering events between soliton-like pulses in
diﬀerent sub-bands of the WDM system are considered
and the amplitude jitter due to scattering ignored.

VI.

INFORMATION THEORY

In this section, we will discuss how the input/output
statistics calculated in sections III and IV may be used
to construct general arguments about the maximum rate
of communication via a WDM system. This is still an
open problem. The only systems for which exact answers
about information capacity may be obtained are those
with Gaussian input/output statistics. We will use the
results for Gaussian systems to obtain lower bounds upon
and approximations to the capacity of the present, non-
Gaussian system.

The ideas of information theory propounded by Shan-
non are very much akin to the ideas of statistical me-
chanics. For a signal made up of a sequence of let-
ters (or ﬁeld values), chosen from some alphabet (or
range of values) one may deﬁne a probability distribu-
tion, p(x), for the probability that a particular letter
takes the value x. The amount of information per let-
ter in such a sequence is given by the entropy of this
x p(x) log p(x). If
distribution; H(X) ≡ H[p(x)] = −
the logarithm is taken in base 2, this gives the amount
of information per letter in bits. One way to understand

P

this is to think of compressing a signal. Compression
involves removing redundancy in the signal (or alterna-
tively correlations between letters) and so increasing the
amount of information per letter. In this way, a signal
with higher entropy will carry a higher density of infor-
mation.

When one attempts to communicate via a channel,
each letter, x, of the input signal will be received as
some letter, y, at the output. Allowing for the uncer-
tainty in the transmission process, the output for an in-
put, x, will be given by some conditional distribution
p(y|x). For an information theorist, this deﬁnes the chan-
nel of communication. For each input letter, the out-
put may take a range of values. The entropy of this
additional spreading at the output is given by the con-
x p(x)H(Y |X = x) =
ditional entropy; H(Y |X) =
−

y p(y|x) log p(y|x)].

x p(x)[

P

When a sequence of letters is transmitted, the amount
P
of information in common between the input and output,
otherwise know as their mutual information is given by
the total entropy of the output signal minus the addi-
tional entropy due to signal distortion;

P

I(X; Y ) = H(Y ) − H(Y |X).

(23)

When using a particular channel, the conditional distri-
bution p(y|X) is ﬁxed and the remaining freedom is in
the choice of input distribution, p(x). The idea is that
if certain letters are more distorted than others, it pays
one to use them less frequently, even though this means
a reduction in the amount of information that the input
signal can carry. The maximum transmitted information
density that can be achieved is given by functionally op-
timizing the mutual information over the choice of input
signal distribution;

C = max
p(x)

I(X; Y ).

(24)

Shannon formulated these ideas rigorously and showed
that this is not only an upper bound upon the rate of
transmission of information, but that it is also an achiev-
able bound. A summary of these basics of information
theory may be found in Ref.2. The functional optimiza-
tion in Eq.(24) is carried out under the various system
In fact,
constraints, such as the average signal power.
the only case for which there exists an explicit analyti-
cal solution is when the joint distributions of input and
output signal are Gaussian. In this case, the capacity is
given by

C = log 

(25)

hx∗xihy∗yi
hx∗xi hx∗yi
hy∗xi hy∗yi



.





(cid:12)
(cid:12)
(cid:12)
(cid:12)





(cid:12)
(cid:12)
(cid:12)
(cid:12)

When the signal is band-limited, the corresponding ex-
pressions for the capacity per unit bandwidth, or the

10

spectral eﬃciency, is given by integrating over frequency;

c =

1
2π∆

Z

dω log 

hx∗
ωx−ωihy∗
ωx−ωi hx∗
hx∗
ωx−ωi hy∗
hy∗

ωy−ωi
ωy−ωi
ωy−ωi



.

(26)





(cid:12)
(cid:12)
(cid:12)
(cid:12)





(cid:12)
(cid:12)
(cid:12)
(cid:12)

The factor of 1/2π arises because ω is the angular fre-
quency conjugate to t.

We are now in a position to use these results from
information theory, together with our knowledge of the
quadratic and quartic statistics of the WDM system to
obtain a lower bounds and estimates of the capacity of
the WDM optical communications system. A rigorous
lower bound on the capacity of a channel deﬁned by a
conditional distribution, p(y|x), may be found as follows:
The quadratic input/output statistics are calculated for
a Gaussian input distribution. A channel whose statistics
are Gaussian and whose quadratic statistics correspond
to those of the actual channel, will have capacity given by
Eq.(26). This gives a lower bound on the capacity of the
actual channel. A proof of this is given in Ref.10. The ba-
sic idea behind it is that deviations from Gaussian statis-
tics correspond to extra correlations in the noise that the
channel adds to the signal. These extra correlations al-
low one to make progress in determining which part of
the received signal is noise and which part is signal. Ig-
noring these correlations- as one does in the Gaussian
approximation- leads one to underestimate the extent to
which noise may be removed from the signal and so to an
underestimate of the system capacity. Notice that since a
Gaussian distribution maximizes the entropy for a ﬁxed
variance, any deviation from Gaussianity will increase
correlations.

We are interested in two ways of using the WDM op-
tical ﬁber system. In the ﬁrst case, both the amplitude
and phase of the electrical signal are used to communi-
cate. We call this coherent communication. In the sec-
ond situation, only the amplitude of the electrical ﬁeld is
used to communicate. This latter case is more represen-
tative of current optical communication systems. Coher-
ent communication was considered by Mitra and Stark
in Ref.10. The quadratic statistics given by Eq.(4) are
combined with Eq.(26) to give the following expression
for the spectral eﬃciency in terms of the single particle
Green’s function of the channel:

dω
2π∆

c ≥

Z

log [1 + Pef f (ω)/Nef f (ω)]

(27)

with the eﬀective signal and noise powers given by

Pef f (ω) = P |hGd(ω)i|2
Nef f (ω) = P

1 − |hGd(ω)i|2

+ N,

(28)

(cid:0)

respectively. This result is a modiﬁcation of the famous
Shannon1 result for the capacity of a linear channel with
additive white noise, allowing for the conversion of sig-
nal power to noise power by scattering from signals in

(cid:1)

the other sub-bands. The single-particle Green’s function
calculated in section 4, hGd(L, ω) ∝ exp[−const. × P 2L]
is substituted into Eq.(28) to obtain the functional de-
pendence of the capacity upon system parameters. The
result is sketched in Fig.5. There are two main features
worthy of comment. The ﬁrst is the peak in capacity
for a particular power; increasing the signal power rela-
tive to the noise power is productive up to a point, but
when the signal power is very large, non-linear interac-
tions between signals in the diﬀerent sub-bands become
the dominant mechanism of signal distortion. The ap-
pearance of an optimal power is a common feature of the
eﬀects of non-linearity. It occurs in the Gordon-Haus jit-
ter of solitons4 and in the non-linear/Gordon-Mollenauer
phase noise5(see for example Ref.12). The second feature
worthy of comment is the dependence of capacity upon
length at large distances. This is important, since it is for
very long distance communication that propagation non-
linearities have the most important eﬀect. The Gaussian
approximation to coherent communication gives a lower
bound on capacity that decays exponentially with length
at large distances. We do not expect this exponential
decay to correctly reproduce the dependence of the sys-
tem capacity, since it is in this limit that non-Gaussian
corrections to the input/output statistics are likely to be
most important. We will see below how taking account
of these non-Gaussian corrections is likely to change the
dependence of capacity at large distances.

Unfortunately, there exist no rigorous bounds on the
capacity for incoherent communication in which the
phase of the electric ﬁeld is ignored. Nevertheless, ex-
pressionssimilar to Eq.(28) can provide useful estimates
of the incoherent capacity. One such estimate is obtained
by ﬁtting an approximate Gaussian distribution of in-
tensity about its mean values (given by Eq.(4)) to the
quadratic statistics of intensity given by Eq.(5). The ca-
pacity of the channel with this Gaussian distribution is
an approximation to the capacity of the actual channel.
It is given by

c ≈

1
2

Z

dω
2π∆

× log

1 +

 

P 2

1 − 2π|GII

d (ω)|2/∆

+ 2P N + N 2 !

(29)
.

P 22π|GII

d (ω)|2/∆

(cid:0)

(cid:1)

(cid:2)

π/2∆ef f Li3/2

P 2/(P + N )2

The pre-factor of 1/2 arises because the intensity is
a real ﬁeld.
In the limit of strong non-linearity and
large signal to noise ratio, Eq.(29) reduces to C ≈
. This has an appealing
interpretation. The eﬀects of non-linearity are contained
p
entirely within a prefactor and provide an eﬀective band-
tot. Our analysis of jitter
width ∆ef f = 6∆
showed that XPM mainly introduces timing errors and
not amplitude error. The eﬀective bandwidth enters be-
cause signal pulses must be separated by more than the
timing error in order to be distinguishable. The infor-
mation carried by each pulse is determined by the ad-
ditive noise power. Notice that in the limit of strong

D/ηL3

L2

p

(cid:3)

11

8

6

4

2

)
z
H
/
s
/
s
t
i
b
(
 
y
c
n
e
c
i
f
f
e
 
l
a
r
t
c
e
p
S

i

0
10−3

10−2

10−1
Power density (mW/GHz)

100

101

FIG. 5: Spectral Eﬃciency vs Input Power: Plots of i.
Eq.(26)-solid black line; ii.Shannon formula, c = log[1 + P/N ]
-short-dashed, red line; iii.Eq.(29)- long-dashed, green line.

non-linearity, the coherent capacity has an exponential
decay with length, whereas Eq.(29) has a power-law de-
cay. The actual coherent capacity is greater than the
incoherent capacity, since a greater number of degrees of
freedom are used in coherent communication. The be-
havior of Eqs. (28) and (29) at large powers point to lim-
itations of the Gaussian approximation. A comparison of
the coherent and incoherent capacity is shown in Fig.5.
The incoherent capacity shows a peak at some optimal
power. This peak is at slightly higher power than that for
the coherent capacity, because phase/timing ﬂuctuations
are more sensitive to XPM than amplitude ﬂuctuations.
It seems plausible that it should be possible to express
the capacity of a channel purely in terms of its multiple
order Green’s functions. Unfortunately, we do not have
such an expression.
Indeed, only for a channel that is
entirely determined by its two-point (or single particle)
Green’s function is it possible to write down such an ex-
pression. In this case the channel is Gaussian and the re-
sult is Eq.(28) as obtained by Shannon1. Obtaining such
expressions would be a signiﬁcant contribution to the un-
derstanding of communication in non-linear media. The
bound on coherent communication and the estimate of
capacity for incoherent communication given above give
an indication of the importance of including higher or-
der Green’s functions. Vertex corrections to higher or-
der Green’s functions determine the extent to which the
channel has non-Gaussian statistics. Including these cor-
rections can dramatically modify the functional depen-
dence of ones estimates of system performance upon sys-
tem parameters.

VII. CONCLUSIONS

In conclusion, we have considered the impediments to
communication caused by non-linear interaction between
the sub-bands of a WDM optical ﬁber system. These
interactions between sub-bands lead to non-Gaussian in-
put/output statistics. We have provided a simple char-

acterization of these non-Gaussian statistics in terms of
vertex corrections to higher order Green’s functions of
the channel. Propagation of light in the WDM system
under the action of XPM is described by a Schr¨odinger
equation with a spatially and temporally random poten-
tial. This potential encodes the eﬀects of XPM. We have
calculated the Green’s function for propagation in this
channel using Feynman path-integral and diagrammatic
techniques. In the case where the signal correlations are
approximated by delta-functions in time, these Green’s
functions may be obtained in closed form. The result
shows a super-diﬀusive spreading of a signal pulse and
of its arrival time. We have interpreted these results
in terms of the amplitude and timing jitter of received
pulses; both of which are standard measures of optical
system performance. We ﬁnd that the received signal
pulse shows a super-diﬀusive spreading of its distribu-
tion of arrival times; ht2i ∝ L3. Finally, we have used
the results to obtain lower bounds and estimates of the
capacity of the WDM system. These are based upon the
Shannon result for the capacity of a Gaussian channel.
In the case of coherent communication, they lead to a
strict lower bound upon the capacity. In the case of inco-
herent communication, where only the signal amplitude
and not its phase is used for communication, we obtain
an estimate of the system capacity. The diﬀerent de-
pendences of our estimates of capacity for coherent and
incoherent communication at large distances, exponen-
tial and power-law, respectively, show the importance of
accounting for the non-Gaussian nature of the channel.

APPENDIX A: CALCULATION OF AMPLITUDE
FLUCTUATIONS

The results contained in Eqs.(22) may be derived using

rules for the composition,

dt′G(x1, x′; t1, t′)G(x′, x2; t′, t2) = G(x1, x2; t1, t2),

Z

unitarity,

G(x = 0; t1, t2) = δ(t1 − t2)

12

and time-reversal,

G∗(x1, x2; t1, t2) = G(x2, x1; t2, t1)

(A3)

of the Green’s function for a particular realization of the
potential, V (x, t). These properties of the Green’s func-
tion may be conﬁrmed by considering the path integral
formulation, Eq.(6).

Using these relations, the ﬁrst of Eqs.(22) may be de-

duced by the following series of manipulations:

hEout(t)i = hA

dt′G(t, t′) + n(t)i

= Ah

dt′G(t, t′)i

Z

Z

= AhG(ω = 0)i
This is nothing more than the average of Eq.(3). The
second of Eqs.(22) requires a few more manipulations;

h|Eout(t)|2i = A2h
Z
+Ahn(t)

dt1dt2G(t, t1)G∗(t, t2)i + h|n(t)|2i

dt1G∗(t, t1)i + Ahn(t)∗

dt1G(t, t1)i

Z

Z

= A2

dtdt1dt2G(t, t1)G∗(t, t2)/δ(0) + N δ(0)

= A2

= A2

Z

Z

Z

= (A2 + N )δ(0)

dtdt1dt2G(0, 0; t2, t1)/δ(0) + N δ(0)

dtdt1dt2δ(t1 − t2)/δ(0) + N δ(0)

We have used Eq.(A3) in moving from the ﬁrst to second
line, followed by Eqs.(A1) and (A2) moving between lines
two and three and three and four, respectively. We have
also used the fact that the averages over the noise and
over the potential are temporally invariant. Eq.(22c) may
be deduced as follows:

(A1)

(A2)

hδ|Eout(t)|2δ|Eout(t)|2i = h|Eout(t)|2|Eout(t)|2i − h|Eout(t)|2i2

= A4

dt1dt2dt3dt4hG∗(L; t, t1)G∗(L; t, t2)G(L; t, t3)G(L; t, t4)i

Z
+4N A2

Z

≈ A4

Z

(cid:20)Z

dt1dt2hG ∗ (L; t, t1)G(L; t, t2)i +

2N 2 − (A2 + N )2

δ(0)2

≈ A4

dt1dt2dt3dt4hG∗(L; t, t1)G(L; t, t3)ihG∗(L; t, t2)G(L; t, t4)i +

N (2A2 + N ) − A4

δ(0)2

(cid:3)

dtdt1dt2hG∗(L; t, t1)G(L; t, t3)i/δ(0)
(cid:21)

(cid:2)
N (2A2 + N ) − A4

+

δ(0)2

(cid:3)

(cid:2)

(cid:3)

(cid:2)

2

≈ N (2A2 + N )δ(0)2

13

The third line is simply a rearrangement of the various
terms arising after substitution of Eq.(3). A complete
calculation of the ﬁrst term in this expression requires
evaluation of the 4-particle Green’s function. We do not
carry out this calculation here.
Instead we make the
approximation discussed in the text and ignore vertex

corrections. This approximation is embodied in the step
between the third and fourth lines.
In moving to the
ﬁfth line, we have used the fact that the average over the
noise and random potential leads to temporally invariant
expressions. We may then use Eqs.(A1,A2) and (A3) in
the same way as before in order to derive our ﬁnal result.

1 C. E. Shannon, Bell Syst. Tech. J. 27, 379 (1948);27, 623

11 Evgenii E. Narimanov and Partha Mitra, J. Lightwave

(1948)

Technol. 20, 530 (2002).

2 T. M. Cover and J. A. Thomas, “Elements of Information

12 Partha P. Mitra, Jason B. Stark and Andrew G. Green,

Theory” (Wiley, New York, 1991).

Optics and Photonics News, 13, S22 (2002).

3 G. P. Agrawal, “Nonlinear Fiber Optics” ( Academic Press,

13 G. E. Falkovich, I. Kolokolov, V. Lebedev and S. K. Tur-

San Diego, 1995).

4 J. P. Gordon and H. A. Haus, Opt. Lett. 11, 665 (1986).
5 J. P. Gordon and L. F. Mollenauer, Optics Lett. 15, 1351

(1990).

6 Linn F. Mollenauer, Stephen G. Evangelides and James P.

Gordon, J. Lightwave Technol. 9, 362 (1991).

7 Dietrich Marcuse, J. Lightwave Technol. 8, 1816 (1990).
8 Pierre A. Humblet and Murat Azizoglu, J. Lightwave Tech-

nol. 9,1576 (1991).

9 Rongqing Hui, Maurice O’Sullivan, Alan Robinson and

Mike Taylor, J. Lightwave Technol. 15, 1071 (1997).
10 Partha. P. Mitra and Jason. B. Stark, Nature 411, 1027

isyn, Phys. Rev. E63, 025601(R) (2001).

14 R. P. Feynman and A. R. Hibbs, “Path integrals in quan-

tum mechanics” (McGraw Hill, New York, 1965).

15 K. Efetov, “Supersymmety in disorder and chaos” (CUP

1999).

16 L. G. L. Wegenger, M. Povinelli, A. G. Green, P.B. Little-

wood and P. P. Mitra, unpublished.

17 Mehran Kardar, Phys. Rev. Lett. 55, 2235 (1985).
18 Mehran Kardar, Giorgio Parisi, Yi-Cheng Zhang, Phys.

Rev. Lett. 56, 889 (1986).

19 Mehran Kardar, Yi-Cheng Zhang, Phys. Rev. Lett. 58,

2087 (1987).

(2001).

