0
0
0
2

 
l
u
J
 

2
1

 
 
]
s
c
i
t
p
o

.
s
c
i
s
y
h
p
[
 
 

1
v
3
3
0
7
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

The Channel Capacity of a Fiber Optics

Communication System: perturbation theory

Evgenii Narimanov and Partha Mitra

1

Abstract— We consider the communication channel given
by a ﬁber optical transmission line. We develop a method to
perturbatively calculate the information capacity of a non-
linear channel, given the corresponding evolution equation.
Using this technique, we compute the decrease of the chan-
nel capacity to the leading order in the perturbative param-
eter for ﬁber optics communication systems.

I. Introduction

TH e performance of any communication system is ul-

timately limited by the signal to noise ratio of the re-
ceived signal and available bandwidth. This limitation can
be stated more formally by using the concept of channel
capacity introduced withing the framework of information
theory[1]. The channel capacity is deﬁned as the maximum
possible bit rate for error-free transmission in the presence
of noise. For a linear communication channel with additive
white Gaussian noise, and a total signal power constraint at
the input, the capacity is given by the celebrated Shannon
formula[1]

(1)

C = W log(cid:18)1 +

P0

PN(cid:19)

where W is the channel bandwidth, P0 is the average signal
power, and PN is the average noise power.

Current optical ﬁber systems operate substantially below
the fundamental limitation, imposed by the Eq. (1). How-
ever, a considerable improvement in the coding schemes
for lightwave communications, expected in the near future,
may result in the development of systems, whose eﬃciency
may approach this fundamental limit.

However, the representation of the channel capacity in
the standard form (1) is unsuitable for applications to the
actual ﬁber optics systems.
It was obtained based on
the assumption of linearity of the communication chan-
nel, while the modern ﬁber optics systems operate in a
substantially nonlinear regime. Since the optical transmis-
sion lines must satisfy very strict requirements for bit-error-
rate (10−12 to 10−15), the pulse amplitude should be large
enough so that is can be eﬀectively detectable. The in-
crease of the number of wavelength-division multiplexing
(WDM) channels[2] in the modern ﬁber optics communi-
cation systems also leads to a substantial increase of the
electric ﬁeld intensity in the ﬁber. As a consequence, the
Kerr nonlinearity of the ﬁber refractive index n = n0 + γI
(where I is the pulse intensity) becomes substantial and
should be taken into account.

In the present paper we consider corrections to the chan-
nel capacity of the optical ﬁber communication system,

the relevant mutual information and subsequent optimiza-
tion. To our knowledge, this method appears to be sub-
stantially new.

II. Fiber Optics Communication System as an

Information Channel

We consider a typical ﬁber optics communication sys-
tem, which consists of a sequence of N ﬁbers each followed
by an ampliﬁer (see Fig. 1). The ampliﬁers have to be in-
troduced in order to compensate for the power loss in the
ﬁber. An inevitable consequence of such design, however, is
the generation of the noise in the system, coming from the
spontaneous emission in the optical ampliﬁers. For sim-
plicity, we will assume that all the ﬁbers and the ampliﬁers
of the link are identical.

The information is encoded in the electric ﬁeld at the
“imput” of the system, typically using the light pulses sent
at diﬀerent frequencies. The available bandwidth of the
ampliﬁers as well as the increase of the ﬁber absorption
away from the “transparency window” near the wavelength
λ = 1.55µm, limits the bandwidth of the ﬁber optic com-
munication system.

The maximum amount of the information, that can be
transmitted through the communication system per unit
time, is called the channel capacity C. According to the
Shannon’s basic result[1], this quantity is given by the max-
imum value of the mutual information per second over all
possible input distributions:

C = maxpx {H [y] − hH [y | x]ipx }

The mutual information

R = H [y (ω)] − hH [y (ω)|x (ω)]ipx

(2)

(3)

is a functional of the “input distribution” px [x (ω)], which
represents the encoding of the information using the elec-
tric ﬁeld components at diﬀerent frequences

Ein (t) = ZW

dω x (ω) exp (iωt)

(4)

The entropy H [y (ω)] is the measure of the information re-
ceived at the output of the communication channel. How-
ever, if the channel is noisy, for any output signal there
is some uncertainty of what was originally sent. The con-
ditional entropy H [y (ω)|x (ω)] at the output for a given
x (ω) represents this uncertainty.

The entropies H [y (ω)] and H [y (ω)|x (ω)] are deﬁned in
terms of the corresponding distributions p (y) and p (y|x)
via the standard relation

2

Fig. 1

The schematical representation of a fiber optics

communication channel

where p ≡ py(y) for the entropy H [y (ω)], and p ≡ p (y | x)
for the entropy H [y (ω)|x (ω)], and the functional integral
is deﬁned in the standard way

Z Dξ (ω) ≡ lim

M→∞

cM(cid:20)ΠM

m=1Z dξ (ωm)(cid:21)

(6)

where is a normalization constant.

For any communication link, the signal power is limited
by the system hardware. Therefore, the maximum of the
mutual information in (1) should be found under the con-
straint of the ﬁxed total power P0 at the input:

P0 = Z Dx (ω) |x (ω)|2 px [x (ω)]

(7)

If the propagation in the communication channel is de-
scribed by a linear equation, then the input-output relation
for the system is given by

y (ω) = K (ω) x (ω) + n (ω)

(8)

where n (ω) is the noise in the channel. In this approxima-
tion, the problem of ﬁnding the maximum of the mutual
information can be solved exactly, with the corresponding
input distribution px being Gaussian[1]. If the ampliﬁers
compensate exactly for the power losses in the ﬁbers, the
Channel Capacity is given by the Shannon formula (1).

As follows from (1), the better bit rates can be obtained
for the higher signal-to-noise ratio P0/PN . With this in
mind, the optics ﬁber communication systems are designed
to operate with the pulses of high power. As a result, the
optics ﬁber links operate in the regime, in which due to the
Kerr nonlinearity the refraction index of the ﬁber strongly
depends on the local electric ﬁeld intensity. Therefore, a
modern ﬁber optics communication system is, in fact, an
essentially nonlinear communication channel, and cannot
be adequately described within the framework of the Shan-
non’s linear theory.

III. The Model

The ﬁrst step in the calculation of the channel capacity is
to ﬁnd the “input-output” relation for the communication
channel. The time evolution of the electric ﬁeld in the
ﬁber E(z, t), where z is the distance along the ﬁber, can be
accuarately described in the “envelope approximation”[2],
when

E (z, t) = A (z, t) exp (i (β0z − ω0t)) + c.c.

(9)

in the ﬁber. The evolution of A (z, t) is described by the
equation

∂A
∂z

+ β1

∂A
∂t

+

i
2

β2

∂2A
∂t2 +

α
2

A = iγ |A|2 A

(10)

Here the coeﬃcients β describe the frequency dependence
of the wavenumber

β (ω) = β0 + β1ω +

β2
2

ω2 + O(cid:2)ω3(cid:3)

(11)

where ω is measured from the center of the band ω0.

The equation (10) neglects the eﬀects such as the stimu-
lated Raman scattering and the stimulated Brillouin scat-
tering[2], compared to the Kerr nonlinearity of the refrac-
tion index of the ﬁber, represented by the term γ |A|2 A.

The optical ampliﬁers incorporated into the communi-
cation system (see Fig.
1) compensate for the power
losses in the ﬁber, but due to spontaneous emission
inevitably introduce noise n(t) =
each of them will

exp (iω0t)R dω nω exp (iωt) into the channel. Generally,

even in a single optical ampliﬁer, the noise distribution at
any given frequency ω0 + ω within the channel bandwidth
n (ω) is close to a Gaussian:

pn [n (ω)] ∼ exp"−

|n (ω)|2

N #

P ω

(12)

This is even more so in a system with many independent
ampliﬁers, due to the Central Limit Theorem. For simplic-
ity, the noise spectrum P ω

N can be assumed to be ﬂat.

If the envelope function just before the ampliﬁer is
ω exp (iωt), then immediately after the ampliﬁer

A (t) ≡ A0

Aω = exp(cid:16) α

2

d(cid:17) A0

ω + nω

where d is the span of a single ﬁber.

(13)

The equations (10), (13) deﬁne the evolution of the elec-
tric ﬁeld envelope over one “ﬁber-apliﬁer” link of the com-
munication system. The total “input-output” relation will
then involve solving the corresponding equations for all N
iterations of the single ﬁber-ampliﬁer unit.

IV. The Perturbative Framework

If one is able to calculate the “output” signal y(ω) in
terms of the “input” x(ω) and the noise contributions of
each of the ampliﬁers n{α}

ω , α = 1, . . . , N ,

y(ω) = Φ(cid:16)x(ω); nω

{1}, . . . , nω

{N }(cid:17)

(14)

then the the conditional distribution p (y|x) can be simply
calculated as follows:

p (y|x) = (cid:26)ΠN −1

α=1 Z Dnω

{α} pnhnω
× pnhy(ω) − Φ(cid:16)x(ω); nω

{α}i(cid:27)

{1}, . . . , nω

{N }(cid:17)i(15)

then be directly related to the input distribution px (x) via
the standard relation

• calculating the entropies H [y (ω)] and H [x (ω)|y (ω)],

and the mutual information R

3

Following these steps, the calculation of the channel ca-
pacity becomes a straightforward procedure. In Appendix
B we describe it in detail, using a simple nonlinear channel
y (ω) = x (ω) exp (−φ [x (ω)]) + n (ω) as an example.

V. The Fiber Link Channel Capacity

After a tedious, but straigthforward calculation, we ob-

tain:

and

H [y (ω)] = H0 [y (ω)] − ∆C1 − ∆Hy + O(cid:0)γ4(cid:1) (20)
H [y (ω)|x (ω)] = H0 [y (ω)|x (ω)] + ∆C2 + O(cid:0)γ4(cid:1)(21)

where H0 [y] and H0 [x|y] are given by the standard expres-
sions for a linear channel[1]. In the limit of large signal-to-
noise ratio P0 ≫ PN we obtain:

α (cid:19)2
∆C1 = N 2W(cid:18) γP0

Q1(cid:18)αd,
α (cid:19)2
3(cid:0)N 2 − 1(cid:1) W(cid:18) γP0

4

∆C2 =

2 W 4
β2

α2 (cid:19)
Q2(cid:18)αd,

(22)

2 W 4
β2

α2 (cid:19)(23)

and the functions Q1 and Q2 are deﬁned as follows:

py (y) =Z Dx(ω) p [y(ω)|x(ω)] px [x(ω)]

(16)

Using Eqns. (15),(16), one is able to express the mutual
information in terms of a single distribution px. The calcu-
lation of the channel capacity then reduces to a standard
problem of ﬁnding the maximum of a (nontrivial) func-
tional.

The equation (10) is, in fact, the well studied [3] non-
linear Shroedinger equation, with the time and distance
variables interchanged. Only some partial solutions of this
equation are known, corresponding to solitons[3], [4]. How-
ever, in order to calculate the channel capacity, one needs to
ﬁnd the general input-output relation for the communica-
tion system. This implies solving a set of N essentially non-
linear equations (10) for arbitrary initial conditions. Even
knowing some partial solutions, doing such calculation ex-
actly for an essentially nonlinear system is not possible in
a closed form.

In order to make progress, we note the presence of a nat-
ural perturbation parameter in the problem, namely γ.In
fact, the ﬁber equation (10) is already an approximation,
derived in the limit, when the change in the eﬀective re-
fraction index due to pulse propagation, described by the
nonlinear term iγ |A|2 A, is small compared to the “un-
perturbed” value of the index of refraction n0. We have
developed a perturbative technique, when the solution of
the nonlinear evolution equation, is represented as a power
series in γ. Solving (10) separately for each power of γ,
and using (13), for the input-output relation of a single
ﬁber-ampliﬁer unit Φ(n)

ω , deﬁned as

A(n)

ω

= Φ(n)

ω (cid:16)A(n−1)

ω

(cid:17) ,

(n−1)(cid:17) = "A(n−1)

ω

+

∞

Xℓ=1

× exp (−iκωd) + nω

γℓF (ℓ)

ω (cid:16)A(n−1)

ω

(17)

(cid:17)#

(18)

we obtain:

Φ(n)

ω (cid:16)Aω

Q1 (u, z) = Z 1/2
Q2 (u, z) = Z 1/2

dx1Z 1/2
dx1Z 1/2

−1/2

−1/2
× f (u, z; x1, x2, x)

−1/2

−1/2
× f (u, z; x1, x2, x)

dx

1/2

dx2Z ¯x
dx2Z 1/2

−1/2

where ¯x ≡ max [1/2, 1/2 + x1 + x2], and

f (u, z; x1, x2, x) ≡ (cid:12)(cid:12)1 − exp(cid:0)−u − iv2(cid:1)(cid:12)(cid:12)

1 + v2

2

where

dx

(24)

(25)

(26)

(27)

where d is the length of a single ﬁber,

κω = β1ω −

1
2

β2ω2

(19)

The correction

v ≡ z (x − x1) (x − x2)

The procedure for the calculation of the functions F (ℓ)
ω , de-
scribed in detail Appendix A, can be carried to an arbitrary
order ℓ.

The further calculation then involves the following steps:
• Iterating Eq.
(18) N times, to obtain the “input-
output” relation for the whole communication system

Φωhx (ω) ; n(1)

ω , . . . , n(N )

ω i

• substituting the result into Eqns. (15), (16) to obtain
the conditional distribution p(x|y) and the output dis-

∆Hy = γ2W Z Dy (ω)p(0)

y

[y (ω)](cid:16)p(1)

y

[y (ω)](cid:17)2

(28)

is caused by the deviations of the otput distribution

py = p(0)

y +Xℓ

γℓp(ℓ)
y

(29)

from the Gaussian form

  |y (ω)|2 !

4

where Pω (such that P0 = R dωPω) is the input power at

frequency ω:

p(0)

x [x (ω)] ∼ exp −

|x (ω)|2

ω !

P 0

(31)

Note, that the correction ∆Hy ≥ 0 and equals to zero only
when the distribution p(1)
y = 0. Therefore, as follows from
Eqns. (20),(28), in the second order in nonlinearity γ the
mutual information R has the maximum, when p(1)
y = 0,
or, equivalently, when the output distribution is Gaussian
up to the ﬁrst order in nonlinearity.

For a general nonlinear channel, that would correspond
to the input distribution, being non-Gassian already in the
ﬁrst order in γ. The corresponding correction can be ob-
tained from Eq. (16), taken only up to the ﬁrst orded in
nonlinearity:

∂

= 0(32)

∂γ (cid:20)Z Dx(ω) p [y(ω)|x(ω)] px [x(ω)](cid:21)(cid:12)(cid:12)(cid:12)(cid:12)γ=0
x (x)(cid:16)1 + γp(0)

such an integral would yield px (x) =
Generally,
p(0)
6=
0. However, it is straightforward to show, that for the ﬁber
optics channel described by Eq. (10), a Gaussian input dis-
tribution leads to non-Gaussian corrections in the output
distribution starting only from the second order. There-
fore, the requrement p(1)
y = 0 is satisﬁed, when the input
distribution is such that p(1)

x (x)(cid:17), where p(0)

is Gaussian, and p(1)
x

x = 0.

x

Fig. 2

The corrections to the channel capacity, ∆C1 and ∆C2, in
units of W N 2γ 2P 2
0 α−2, shown as functions of |β2|W 2/α in

the limit αd ≫ 1, N ≫ 1. The correction ∆C2 is represented
by the solid line, while ∆C1 corresponds to the dashed line.

Note, that ∆C1, which describes the effect of the power

leakage from the bandwidth, is more strongly affected by

the dispersion

Such scattering processes are suppressed, when the scat-
tering leads to a subsantial change of the total momen-
tum δκ [ω1, ω2 → ω3, ω], so that the corresponding scatter-
ing rate

For the channel capacity, deﬁned as the maximum value

of the mutual information, we obtain:

S [ω1, ω2 → ω3, ω] ∼

δ (ω1 + ω2 − ω3 − ω)

1 + (δκ/κ0)2

(35)

C = W log(cid:18)1 +

P0

PN(cid:19) − ∆C1 − ∆C2 + O(cid:0)γ4(cid:1) (33)

The equation (33) yields the result for the ﬁber optics chan-
nel capacity in the second order in the nonlinearity γ. In
the next section we will discuss the physical origins of the
corrections ∆C1 and ∆C2.

VI. The Discussion and the Conclusions

In the spirit of the Shannon formula, the decrease of the
capacity of a communication channel with a ﬁxed band-
width can be attributed to (i) the eﬀective suppression of
the signal power, and (ii) the enhancement of the noise.
The corrections to the channel capacity, derived in the pre-
vious section, can be interpreted as resulting precisely from
these two eﬀects.

The four-wave scattering[2], induced by the ﬁber non-
linearity, inevitably leads to the processes, which gener-
ate photons with the frequencies outside the channel band-
width. Such photons, are not recorded by the “receiver”,
and are lost for the purpose of the information transmis-
sion. This corresponds to an eﬀective bandwidth power
dissipation, and should therefore lead to a decrease of the
channel capacity. Since for small nonlinearity this power
loss ∆P ∼ γ2, the dimension analysis implies

2

2 (cid:18)

2(cid:19)

In the spirit of the uncertainty realtion, κ0 ∼ 1/Leﬀ, where
Leﬀ corresponds to the length of the concentration of the
power of the signal in the ﬁber. For a small absorption
coeﬃcient α ≪ 1/d the distance Leﬀ is of the order of
the ﬁber length d, while in the opposite limit α ≫ 1 the
eﬀective length Leﬀ ≈ 1/α.

Using Eqn. (19), and the energy conservation ω3 = ω1 +
ω2 − ω, the momentum change δκ [ω1, ω2 → ω3, ω] can be
expressed as

δκ = β2 (ω − ω1) (ω − ω1)

(36)

Substituting (36) into (35), for the channel capacity loss
due to the bandwidth power “leakage”, in the limit P0 ≫
PN , and αd ≫ 1, we obtain

∆CP ∼ W

∆P
P

∼ W

γ2P 2
0

α2 Z W

dω1 ZW

dω2 ZW

dω3

dω S [ω1, ω2 → ω3, ω]

× Zω /∈W

= W

γ2P 2
0

α2 ZW

dω1 ZW

1

dω2Zω /∈W

dω

1 + (β2/α)2 (ω − ω1)2 (ω − ω2)2

×

(37)

In Fig. 2 we plot the dependence of ∆C1 on the dimen-
sionless parameter β2W 2/α. Since momentum change δκ
is proportional to β2, the increase of the dispersion leads to
a strong suppression of the power leakage from the band-
width window, and of the corresponding correction to the
channel capacity.

In a communication system with many “ﬁber-ampliﬁer”
units, the ﬁber nonlinearity leads not only to the mixing
of the signals at diﬀerent frequencies, but also to the mix-
ing of the signal with the noise. Qualitatively, this would
correspond to an eﬀective enhancement of the noise power
in the system, and therefore to a loss of the channel capac-
ity. This eﬀect is not present, when the system has only
one “ﬁber-ampliﬁer” link, which explains the appearance
of the (N − 1) factor in ∆C2 and ∆C3.

The eﬀective noise enhancement is caused by the scat-
tering processes, which involve a “signal photon” and a
photon, produced due to spontaneous emission in one of
the ampliﬁers. The total power of this extra noise can be
expressed as

∆PN
P0

∼ γ2 P0PN

α2 ZW

dω1 ZW

× S [ω1, ω2 → ω3, ω]

dω2 ZW

dω3ZW

dω

(38)

The corresponding correction to the capacity

∆CN ∼ W

∆PN
PN

∼ W

γ2P 2
0

α2 ZW

1

dω1 ZW

dω2ZW

dω

×

1 + (β2/α)2 (ω − ω1)2 (ω − ω2)2

(39)

where we assumed αd ≫ 1. In this limit (39) is up to a
constant factor identical to ∆C2.

The dependence of ∆C2 on β2W 2/α is also shown in Fig.
2. Note, that ∆C2 also decreases with the increase of the
dispersion, but more slowly than ∆C1. Since the scattering
processes, which contribute to ∆C1, need to “move” one of
the frequencies out of the bandwidth window, they gener-
ally involve a substantial change of the total momentum,
and are therefore more strongly aﬀected by the dispersion.
The two physical eﬀects, described above, determine the
fundamental limit to the bit rate for a ﬁber optics commu-
nication system. As follows from our analysis (see Fig. 2),
the relative contributions of ∆C1 and ∆C2, often referred
to as the “four-wave mixing”, can be suppressed by choos-
ing a ﬁber with a large dispersion, or when using a larger
bandwidth.

As a result,

In our analysis, we treated the whole available band-
width as a single channel.
the cross-
phase modulation[2], which severely limits the performance
of advanced wavelength-division multiplexing systems[6]
(WDM), does not aﬀect the channel capacity. The rea-
son for this seemingly contradictory behaviour, is that in a
WDM system, the “receiver”, tuned to a particular WDM
channel, has no information on the signals at the other
channels. Therefore, even in the absense of the “geniune”

5

be an eﬀective noise source, thus limiting the communica-
tion rate. This limit however is not fundamental, and can
be overcome by using the whole bandwidth all together.

In conclusion, we developed a perturbative method for
the calculation of the channel capacity for ﬁber optics com-
munication systems. We obtained analytical expressions
for the corrections to the Shannon formula due to ﬁber
nonlinearity. We have shown that, compared to the Shan-
non limit, the actual channel capacity is substantially sup-
pressed by the photon scattering processes, caused by the
ﬁber nonlinearity.

Appendix

I. Perturbative Solution of the Propagation

Equation

In this Appendix we describe the perturbative solutuion
of the nonlinear equation (10) with the boundary condition

A (0, t) = Z dω x (ω) exp (iωt)

(40)

We represent A (z, t) as a power series

A (z, t) = Z dω exp(cid:16)iωt −h α

2

× Fℓ (z, ω)

+ iκωi z(cid:17)

γℓ

∞

Xn=0

(41)

where κω is deﬁned is (19). Substituting (41) into Eqns.
(10),(40), we obtain:
(i) for ℓ = 0

∂F0 (z, ω)

∂z

= 0

F0 (0, ω) = x (ω)

(42)

(43)

(ii) for ℓ 6= 0

∂Fℓ (z, ω)

∂z

= i

ℓ−1

Xℓ1,ℓ2,ℓ3=1

δℓ−1,ℓ1+ℓ2+ℓ3Z dω1Z dω2

× Fℓ1 (z, ω1) Fℓ2 (z, ω2) F ∗
ℓ3 (z, ω1 + ω1 − ω)
× exp [i (κω1 + κω1 − κω1+ω2−ω − κω)] (44)
(45)

Fℓ (0, ω) = 0

where δ in the Kronekker’s delta-function.

For any ℓ, these equations reduce to linear ﬁrst order
diﬀerential equation, and can be solved straightforwardly.
For example, the solutions for the ﬁrst three terms in the
anzats (41) are given by:

F0 (z, ω) = x (ω)

ω1ω2x (ω1) x (ω2)

F1 (z, ω) = Z dω1Z dω2 F ω
F2 (z, ω) = Z dω1Z dω2Z dω3Z d¯ω(cid:2)Gω

× x∗ (ω1 + ω2 − ω)

ω1ω2ω3 ¯m

× x∗ (ω1) x∗ (ω2) x (ω1 + ω2 − ¯ω) x (ω3)
× x (ω + ¯ω − ω ) + H ω

x (ω ) x (ω ) x (ω )

(46)

(47)

6

Here the functions F , G and H are given by

where p0

y(y) is the “unperturbed”, Gaussian distribution

F ω

ω1ω2 = i

ω1ω2d(cid:1)

1 − exp(cid:0)−αd − iφω
ω1ω2(cid:1)∗

α + iφω
(F ω3

ω ¯ω)∗

ω1ω2

× (1 − exp (−αd + iφω3

ω ¯ωd))

Gm

ω1ω2ω3 ¯ω = −(cid:0)F ¯ω

H ω

∗

ω ¯ω

ω1 ω2

F ¯ω

1
F ¯ω

ω1ω2
+ 1
F ω3



ω1ω2(cid:1)(cid:0)F m
¯ωω3(cid:1)

− 

× (cid:0)1 − exp(cid:0)−2αd +(cid:0)φ¯ω
ω1ω2ω3 ¯ω = 2(cid:0)F ¯ω
× (cid:0)1 − exp(cid:0)−αd − iφω
− 2



× (cid:0)1 − exp(cid:0)−2αd − i(cid:0)φ¯ω

ω1ω2
+ 1
F ω

1
F ¯ω

F ¯ω

ω1 ω2

¯ωω3

¯ωω3d(cid:1)(cid:1)

∗

where

ω1ω2 + φω3

ω ¯ω(cid:1) d(cid:1)(cid:1)

¯ω1ω2 + φω

¯ωω3(cid:1) d(cid:1)(cid:1)

φω
ω1ω2 = (κω1 + κω2 − κω1+ω2−ω − κω)

II. The Perturbative Calculation of the

Channel Capacity

In this Appendix, we describe the perturbative calcula-

tion of the capacity of the simple nonlinear channel

y (ω) = x (ω) exp (iγφ [x (ω)]) + n (ω)

(49)

Here φ [x] is an arbitrary real function, and the noise n (ω)
is a Gaussian random variable:

p0
y (y) =

1

π (P0 + PN )

exp −

|y|2

P0 + PN! (54)

corresponding to the linear channel y = x+n. Substituting
(53) into the deﬁnition of the entropy Hy, Eq.
(5), we
obtain:

Hy = log [2πe (P0 + PN )] −

+

1

P0 + PN (cid:20)Z dy |y|2 py (y)

− Z dy |y|2 p0

y (y)(cid:21)

1

2Z p(1)

y

(y)2 p0

y (y)

(55)

The second term in Eq. (55), (1/2)R p(1)

y (y), repre-
sents the diﬀerence of the output distribution from Gaus-
sian, and corresponds to the contribution ∆Hy in Eq. (20).
Note, that in the second order in nonlinearity the devia-
tions of the output distribution from Gaussian lead to a
decrease of capacity.

(y)2 p0

y

The

third

term,

y (y)i, is propor-
(1/(P0 +PN ))hR dy |y|2 py (y) −R dy |y|2 p0
tional to the change of the output power, R dy |y|2 py (y),

due to nonlinearity, and corresponds to ∆C1 in Eq. (20).
Generally, the nonlinearity leads to energy exchange be-
tween diﬀerent degrees of freedom in the channel (e.g. be-
tween diﬀerent frequencies), and to the power leakage out
of the bandwidth window. However, for the speciﬁc (nad
non-generic) example, chosen in the present Appendix, this
exchange is absent, since the output power

pn [n (ω)] ∼ exp"−

|n (ω)|2

PN #

(50)

h|y|2i = h|x|2i + h|n|2i = P0 + PN

(56)

The fact, that the noise in this model is additive, implies
that the conditional distribution p (y|x) is ﬁxed, and de-
ﬁned by the noise distribution pn:

p (y | x) = pn [y − x exp (iγφ (x))]

(51)

It is therefore straightforward to show, that the entropy
H [y|x] does not depend on γ:

does not depend on the nonlinearity.

Substituting (56) in Eq. (55), and using Eq. (52), for

the mutual information R we obtain:

R = log(cid:20)1 +

P0

PN(cid:21) −

1

2Z p(1)

y

(y)2 p0

y (y)

(57)

As immediately follows from Eq. (57), the channel capac-
ity, equal to the maximum of the mutual information, is
given by the Shannon formula (1), and is achieved when

H [y|x] = −Z dypn(cid:16)y − xeiγφ(x)(cid:17)
× loghpn(cid:16)y − xeiγφ(x)(cid:17)i
= −Z dzpn (z) log [pn (z)]

= log [2πePN ]

p(1)
y

(y) = 0

The next step is to calculate the input distribution

(52)

px (x) = p0

x (x)"1 +

p(n)

x (x)#

∞

Xn=1

(58)

(59)

In order to calculate the entropy H [y], we represent the
output distribution as a power series in γ:

corresponding to (58). The general relation between the
input and the output distributions is deﬁned by the condi-
tional distribution p(y|x):

∞

"

#

and, considered as an equation for p(x), is a Fredholm in-
tergal equation of the ﬁrst kind. Note however, that since
Eq. (58) represents not the whole output distribution, but
only it’s ﬁrst order term p(1)
y (y), we can expand Eq. (60)
and keep only the terms up to the ﬁrst order in γ. We
obtain:

Substituting here the conditional distribution from Eq.
(51), we obtain:

x (x) p(1)

x (x)

p0
x (x) = 0,

(61)

+ Z dx

∂
∂γ

Z dx p (y|x)|γ=0 p0
p (y|x)(cid:12)(cid:12)(cid:12)(cid:12)γ=0
Z dx pn (y − x) p0

x (x) p1 (x) =

i
PN

x (x) φ (x) (x∗y − y∗x) ,

×Z dx pn (y − x) p0

7

This result has a simple physical meaning. When the in-
put distribution is organized in such a way, that the quan-
tity z = x exp (iγφ (x)) has the Gaussian distribution, then,
considering z as input, the communication channel be-
comes linear: y = z + n, and the channel capacity is there-
fore given by the Shannon formula (1),(68). The corre-
sponding input distribution is then deﬁned by the Jacobian
of the transformation from x ≡ xR + ixI to z ≡ zR + izI,
∂ (zR, zI) /∂ (xR, xI ) (note, that xR, xI , zR, zI are deﬁned
as real variables):

px (x) =

1

πP0

∂ (zR, zI )
∂ (xR, xI )

exp"−(cid:12)(cid:12)x2

R + x2

P0

2

# (69)

I(cid:12)(cid:12)

which reduces to the distribution (67), since

∂ (zR, zI)
∂ (xR, xI )

(62)

∂φ (xR, xI )

∂φ (xR, xI )

− γxI

= 1 + γxR
≡ 1 + iγx∗ ∂φ (x, x∗)

∂xI

∂x∗

∂xR
∂φ (x, x∗)

∂x

− iγx

(70)

This result should be contrasted to the so called “Gaus-
In the latter
sian estimate” of the channel capacity[7].
appoach, the information channel is described by the joint
Gaussian distribution

P (xω, yω) ∼ exp(cid:18)− [x∗

ω y∗

ω] A(cid:20) xω

yω (cid:21)(cid:19)

A = (cid:20) hx∗

hy∗

ωxωi
ωxωi

hx∗
hy∗

ωyωi

ωyωi (cid:21)−1

(71)

(72)

The channel capacity is then estimated as the mutual in-
formation, corresponding to the distribution (71):

hx∗

hx∗
ωxωihy∗
ωyωi − hx∗
ωxωihy∗

CG =Z dω log(cid:20)
Under the constraint of the ﬁxed input power R dωh|xω|2i,

the estimate (73) was shown[7] to give the low bound to
the channel capacity.

ωyωi
ωyωihy∗

ωxωi(cid:21)

(73)

For the model channel considered in the present Ap-
pendix, the “Gaussian estimate” yields an expression, dif-
ferent from the Shannon result. For example, when φ (x) =
|x|2, we obtain

CG = −W log"1 −
= W log(cid:20)1 +

P0

(P0 + PN ) (1 + γ2P 2

P0

PN(cid:21) − 2W γ2P 2

0

P0
PN

0 )2#
+ O(cid:0)γ4(cid:1) (74)

which, as expected, is smaller that the actual channel ca-
pacity (68). Note, that the diﬀerence between the exact
channel capacity and the Gaussian estimate

δC ≡ C − CG = W log"1 +

P0

PN  1 −

1

0 )2!#

(1 + γ2P 2

Using the identity

ypn (y − x) = (cid:18)x + PN

∂

∂x∗(cid:19) pn (y − x) ,

(63)

and integrating by parts, we can represent the right hand
side of (62) as follows:

iZ dx pn (y − x) p0
iZ dx pn (y − x) p0

x (x)

i
PN

φ (x) (x∗y − y∗x) =

where

x (x)(cid:18)x∗ ∂φ (x)

∂x∗ − x

∂φ (x)

∂x (cid:19)

(64)

Therefore, as follows from Eqns. (62) and (64), the input
distribution

p(1)

x (x) = i(cid:18)x∗ ∂φ (x)

∂x∗ − x

∂φ (x)

∂x (cid:19)

(65)

This procedure can be followed up for all orders in γ. By
a direct calculation, it is straightforward to show, that the
channel capacity is represented by the Shannon result (1),
which is achieved when for any n > 1

( p(n)

x (x) = 0
p(n)
(y) = 0
y

(66)

Subsitituting (66) and (65) into Eq.
distibution we ﬁnally obtain:

(59), for the input

px (x) =

1

πP0 (cid:20)1 + iγ(cid:18)x∗ ∂φ (x)

∂x∗ − x

× exp"−

|x|2

P0 #

∂φ (x)

∂x (cid:19)(cid:21)

(67)

with the corresponding channel capacity

(cid:20)

(cid:21)

8

is not merely a constant scale factor, but a nontrivial func-
tion of the signal to noise ratio, and the nonlinerity.

Even when the input distribution is Gaussian, like e.g.
when the phase φ depends on x via the “power” |x|2, the
Gaussian Estimate does not yield the exact result. The
reason for this behaviour is that the joint Gaussian distri-
bution does not correctly reproduce the conditional distri-
bution p (y | x).

For an essentially noinlinear system (e.g. a ﬁber op-
tics communication channel), there is generally very little
apriori knowledge about the parametric dependence of the
Channel Capacity on the signal to noise ratio and other
system parameters.
In this case, the Gaussian Estimate
for the channel capacity can be (should be?) viewed as a
very unreliable method, as there is no way to separate it’s
artefacts from the actual behaviour of the channel capacity.

References

[1] C. E. Shannon, A Mathematical Theory of Communication. The
Bell System Technical Journal vol 27, pp. 379 - 423, 623-656.
1948.

[2] G.P.Agrawal, Nonlinear Fiber Optics, Academic Press, San

Diego, 1995.

[3] R.K.Dodd, J.C.Eilbeck, J.D.Gibbon, and H.C.Morris, Solitons
and Nonlinear Wave Equations, Academic Press, New York,
1984.

[4] G. L. Lamb, Jr., Elements of Soliton Theory, Wiley, New York,

1980.

[5] J. P. Gordon and L. F. Mollenauer, Phase noise in photonic com-
munication systems using linear ampliﬁers. Optics Letters, vol.
23, pp. 1351-1353. Dec. 1990.

[6] G. P. Agrawal, Fiber-Optic Communication Systems, John Wiley

and Sons, New York, 1997.

[7] I. Teletar, unpublished.

