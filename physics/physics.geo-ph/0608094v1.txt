6
0
0
2
 
g
u
A
 
8
 
 
]
h
p
-
o
e
g
.
s
c
i
s
y
h
p
[
 
 
1
v
4
9
0
8
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Tomographic inversion using ℓ1-norm regularization of wavelet
coeﬃcients

Ignace Loris1,2, Guust Nolet3, Ingrid Daubechies1, F. A. Dahlen3
1Program in Applied and Computational Mathematics,
Princeton University, Princeton, New Jersey, USA
2Dienst Theoretische Natuurkunde, Vrije Universiteit Brussel,
Brussels, Belgium, E-mail: igloris@vub.ac.be
3Department of Geosciences, Princeton University, Princeton, New Jersey, USA

February 2, 2008

Abstract

We propose the use of ℓ1 regularization in a wavelet basis for the solution of linearized seismic
tomography problems Am = d, allowing for the possibility of sharp discontinuities superimposed
on a smoothly varying background. An iterative method is used to ﬁnd a sparse solution m that
contains no more ﬁne-scale structure than is necessary to ﬁt the data d to within its assigned errors.

keywords: inverse problem, one-norm, sparsity, tomography, wavelets

2m) norm of a dense local parametrization [Nolet(1987), Constable et al.(1987),

1

Introduction

Like most geophysical inverse problems, the linearized problem Am = d in seismic tomography is un-
derdetermined, or at best oﬀers a mix of overdetermined and underdetermined parameters. It has there-
fore long been recognized that it is important to suppress artifacts that could be falsely interpreted
as ‘structure’ in the earth’s interior. Not surprisingly, strategies that yield the smoothest solution m
have been dominant in most global or regional tomographic applications; these strategies include seek-
ing global models represented as a low-degree spherical harmonic expansion [Dziewonski et al.(1975),
Dziewonski & Woodhouse(1987), Masters et al.(1996)] as well as regularization via minimization of the
gradient (
Spakman & Nolet(1988), VanDecar & Snieder(1994), Trampert & Snieder(1996)].

m) or second derivative (

∇

∇

Smooth solutions, however, while not introducing small-scale artifacts, produce a distorted image
of the earth through the strong averaging over large areas, thereby making small-scale detail diﬃ-
cult to see, or even hiding it. Sharp discontinuities are blurred into gradual transitions. For ex-
ample, the inability of global, spherical-harmonic, tomographic models to yield as clear an image of
upper-mantle subduction zones as produced by more localized studies has long been held against them.
[Deal et al.(1999)] and [Deal & Nolet(1999)] optimize images of upper-mantle slabs to ﬁt physical models
of heat diﬀusion, in an eﬀort to suppress small-scale imaging artifacts while retaining sharp boundaries.
[Portniaguine & Zhdanov(1999)] use a conjugate-gradient method to seek the smallest possible anoma-
lous domain by minimizing a norm based on a renormalized gradient
2 , where γ is
a small constant. Like all methods that deviate from a least-squares type of solution, both these methods
are nonlinear and pose their own problems of practical implementation.

m + γ2)

m/(

The notion that we should seek the ‘simplest’ model m that ﬁts a measured set of data d to within
the assigned errors is intuitively equivalent to the notion that the model should be describable with a

· ∇

m

∇

∇

1

1

small number of parameters. But, clearly, restricting the model to a few low-degree spherical-harmonic or
Fourier coeﬃcients, or a few large-scale blocks or tetrahedra, does not necessarily lead to a geophysically
plausible solution. In this paper we investigate whether a multiscale representation based upon wavelets
[Daubechies(1992)] has enough ﬂexibility to represent the class of models we seek. We propose an ℓ1-
norm regularization method which yields a model m that has a strong tendency to be sparse in a wavelet
basis, meaning that it can be faithfully represented by a relatively small number of nonzero wavelet
coeﬃcients. This allows for models that vary smoothly in regions of limited coverage without sacriﬁcing
any sharp or small-scale features in well-covered regions that are required to ﬁt the data. Our approach is
diﬀerent from an approach brieﬂy suggested by [de Hoop & van der Hilst(2005)], in which the mapping
between data and model is decomposed in curvelets: here we are concerned with applying the principle
of parsimony to the solution of the inverse problem, without any special preference for singling out linear
features, for which curvelets are probably better adapted than wavelets.

In Section 2 we give a short description of the mathematical method, and in Section 3 we con-
sider a geophysically motivated, toy 2D application, in which the synthetic data are a small set of
regional, fundamental-mode, Rayleigh-wave dispersion measurements expressed as wavenumber pertur-
bations δk(ν) at various frequencies ν. To enable us to concentrate on the mathematical rather than the
geophysical aspects of the inverse problem, we assume that the fractional shear-velocity perturbations
δ lnβ = δβ/β within the region are depth-independent. Finite-frequency interpretation of the surface-
wave dispersion data [Zhou et al.(2004)] then yields a 2D linearized inverse problem of the form Am = d.
We compare wavelet-basis models m obtained using our proposed ℓ1-norm regularization with models
obtained using more conventional ℓ2 regularization, both with and without wavelets, and show that the
former are sparser and have fewer small-scale artifacts.

2 Mathematical principles

In any realistic tomographic problem, the linear system Am = d is not invertible: even when the
number of data exceeds the number of unknowns, the least-squares matrix AT A is (numerically) singular.
Additional conditions always have to be imposed. The proposed regularization method is based on the
fundamental assumption that the model m is sparse in a wavelet basis [Daubechies(1992)]. We believe
that this is an appropriate inversion philosophy for ﬁnding a smoothly varying model while still allowing
for whatever sharp or small-scale features are required to ﬁt the data d. An important feature of the
method is that the location of the small-scale features does not have to be speciﬁed beforehand.

A wavelet decomposition is a special kind of basis transformation that can be computed eﬃciently
(the number of operations is proportional to the number of components in the input). At each step
the algorithm strips oﬀ detail belonging to the ﬁnest scale present —this detail is encoded in wavelet
coeﬃcients, broadly corresponding to local diﬀerences— and calculates a coarse version —encoded in
scaling coeﬃcients, broadly corresponding to local averages— that is only half the size of the original in
1D and only one quarter the size in 2D. This procedure is repeated on the successive coarse versions. The
resulting wavelet coeﬃcients (at the diﬀerent scales) and scaling coeﬃcients (at the ﬁnal coarsest scale
only) are called the wavelet decomposition of the input. By this construction each wavelet coeﬃcient
carries information belonging to a certain scale (by virtue of the decimation) and a certain position (use
of local diﬀerences). The ﬁnal few scaling coeﬃcients represent a (very) coarse average.

The mathematical relation between the wavelet-basis expansion coeﬃcients w and the model m
is the wavelet transform W (a linear operator): m = WT w. By choosing the local diﬀerences and
averages carefully (corresponding to a choice among many diﬀerent so-called wavelet families), the inverse
transformation from w back to m can be made equally eﬃcient. In our application we will use a special
kind of 2D wavelet basis that is overcomplete: it contains six diﬀerent wavelets corresponding to diﬀerent
directions. Because of this overcompleteness, the wavelet transform W has a left inverse (namely WT ):
= I. Appendix B contains a short overview of this particular
WT W = I, but no right inverse, WWT

2

6
w2

w with d = AWT w and smallest ℓ1-norm

w with d = AWT w and smallest ℓ2-norm

d = AWT w

w1

ℓ2-ball: w

2
1 + w

2
2 = constant

ℓ1-ball: |w1| + |w2| = constant

2

w

|w|

w

Figure 1: Sparsity, ℓ1 minimization and ℓ2 minimization: Left: Because the ℓ1-ball has no bulge, the solu-
penalization
tion with smallest ℓ1-norm is sparser than the solution with smallest ℓ2-norm. Right: A
eﬀects small coeﬃcients more and large coeﬃcients less than the (traditional) w2 penalization.

w
|

|

construction. In short our wavelet and scaling coeﬃcients w contain information on scale, position and
direction.

For the tomographic reconstruction, we will require a sparse set of wavelet-basis coeﬃcients: the vast
majority of these represent diﬀerences and will only be present around non-smooth features. In this way
we regularize the inversion by adapting ourselves to the model rather than to the operator. As a measure
of sparsity we will use the ℓ1-norm of the wavelet representation w of the model m, i.e. we will look for a
solution of the linear equations Am = d that has a small
w
2 for small wi
2 for large wi, this type of penalization will favor a small number of large coeﬃcients over
and
a large number of small coeﬃcients in the reconstruction (whereas a traditional ℓ2 penalization might
do the opposite). We are not claiming that the sparsest solution always coincides with the minimum
ℓ1-norm solution, but one can show that it often does [Donoho(2004), Candes et al.(2006)]. A schematic
justiﬁcation for this is given in Fig. 1.

wi|
i |

k1 =

. Since

wi|
|

wi|
|

wi|
|

wi|
|

P

>

<

k

In particular, our strategy will consist of searching for the minimizer of the functional

d

AWT w

2
2 + 2τ

w

I1(w) =

d

Am

k

k

k

−

k1 =
where τ is an adjustable parameter at our disposal. Here, the ﬁrst (quadratic) term corresponds to the
(Am)i]2, and the second (ℓ1-norm)
conventional statistical measure of misﬁt to the data, χ2 =
k1 is introduced to regularize the inversion. In writing χ2 in this form, we have made the
term 2τ
simplifying assumption that the noisy data d are uncorrelated with unit variance. More generally, the
Am)T Σ−1(d
misﬁt portion of the functional (1) is χ2 = (d
Am), where Σ is the data covariance
matrix. In the 2D toy problem considered in Section 3, we invert synthetic data d having a constant (but
non-unit) variance, Σ = σ2I.

i[di −

k1,

(1)

P

w

−

−

−

k

k

k

k

2
2 + 2τ

w

The minimizer of the functional (1) can be found by iteration [Daubechies et al.(2004)]: starting with

the present approximation w(n) one constructs an nth-iterate surrogate functional

I (n)
1

(w) = I1(w)

AWT (w

w(n))
k

2
2 +

k

w

−

−

w(n)

2
2

k

− k

(2)

that has the same value and the same derivative at the point w = w(n) as the original functional (see

3

Fig. 2). This surrogate functional can be rewritten as

I (n)
1

(w) =

w

WAT d + (I

WAT AWT )w(n)

−

+ 2τ

w

k1 + c(n),

k

− (cid:16)

(cid:13)
(cid:13)
(cid:13)

2

2

(cid:17)(cid:13)
(cid:13)
(cid:13)

where c(n) is independent of w. This functional has a much simpler form than the original I1(w) because
there is no operator AWT mixing diﬀerent components of w. The next approximation w(n+1) is deﬁned
by the minimizer of this new functional. By calculating the derivative of expression (3) with respect
to a speciﬁc wavelet or scaling coeﬃcient wi, one ﬁnds the following set of component-by-component
equations:

wi − (cid:16)

WAT d + (I

WAT AWT )w(n)

+ τ sign(wi) = 0,

valid whenever wi 6
solution —corresponding to the minimizer of the surrogate functional I (n)
is then found to equal

(cid:17)i
= 0. These equations are solved by distinguishing the two cases wi > 0 and wi < 0; the
(w), and denoted by w(n+1)—

1

−

−
where Sτ is the so-called soft-thresholding operation, i.e.

w(n+1) =

Sτ

WAT d + (I
h

WAT AWT )w(n)

,

i

τ

−

w
0
w + τ

Sτ (w) = 




w
w
|
w

≥
| ≤

τ
τ
τ,

≤ −

performed on each wavelet or scaling coeﬃcient wi individually. The starting point of the iteration
procedure is arbitrary, e.g. w(0) = 0. Because of the component-wise character of the tresholding, it
is straightforward to use diﬀerent thresholds τi for diﬀerent components wi if desired, and in fact we
shall use diﬀerent thresholds τw and τs for the wavelet and scaling coeﬃcients in our application. A
schematic representation of the idea behind the iteration (5) is given in Fig. 2. We realize that this
iteration converges slowly for ill-conditioned matrices, but we use it here because it is proven to converge
to the solution [Daubechies et al.(2004)].

An improvement in convergence can be gained by rescaling the operator A (and rescaling the data
d at the same time) in such a way that the largest eigenvalue of α2AT A is close to (but smaller than)
unity. The iteration corresponding to the minimization of this new, rescaled functional is

w(n+1) =

Sτ α2

α2WAT d + (I
h

−

α2WAT AWT )w(n)

.

i

We will also make use of the following two-step procedure: from the outcome m = WT w of the iteration
(7), we deﬁne new, linearly shifted data d′ = 2d
Am and restart the same iteration with this new data:

w(n+1) =

Sτ α2

α2WAT d′
h

+ (I

−

−
α2WAT AWT )w(n)

,

i

w(0) = w.

(8)

The outcome m = WT w of this second iteration is then the ﬁnal, regularized reconstruction of the
model. For the same value of the regularization parameter τ , the second step improves the data ﬁt
2; hence a given level of ﬁnal data ﬁt χ2 will, in the two-step
2
considerably,
procedure, correspond to a higher value of τ . Because τ speciﬁes the threshold level, a higher value will
lead to more aggressive thresholding and thus faster convergence to a sparse solution.

Am
k

2
2 <

Am

−

−

d

d

k

k

k

The above method will be demonstrated in the next section and compared to a conventional ℓ2-

regularization method, in which the functional

(3)

(4)

(5)

(6)

(7)

(9)

I2(m) =

d

Am

2
2 + τ

m

2
2

k

k

k

k

−

4

I (n)
1

(w)

I1(w) =

d
k

−

Am

2
2 + 2τ
k

w
k

k1

Sτ (w)

τ
−

τ

w

w(n+1)

w(n)

Figure 2: Left: The functional I1(w) is approximated in the vicinity of w(n) by a surrogate functional
I (n)
(w), constructed in such a way that its minimum is easy to ﬁnd (eq. (5)). This deﬁnes the next step
1
Sτ (w).
in the iteration. Right: Soft thresholding function

is minimized (the crucial diﬀerence with I1(w) being the second term). This gives rise to the familiar
system of damped normal equations

(AT A + τ I)m = AT d,
(10)
whose solution m = (AT A + τ I)−1AT d can be found using a linear solver of choice, since AT A + τ I
is a regular matrix. To emphasize the similarities and diﬀerences with the ℓ1 method, we adopt the
classical Landweber iteration [Landweber(1951)] that can be (but in modern applications seldom is) used
for solving the linear equations (10):

(11)

(12)

m(n+1) = AT d +

I

(AT A + τ I)
(cid:3)

−

(cid:2)

m(n),

m(0) = 0.

No thresholding is employed here. Rescaling of the operator and the data again improves the rate of
convergence:

m(n+1) = α2AT d +

I

(α2AT A + τ α2I)
(cid:3)

−

(cid:2)

m(n),

m(0) = 0.

Of course it is also possible to solve the linear system (10) using a conjugate-gradient or similar algorithm
in much less time.

A third option is to use an ℓ2 penalization on the wavelet coeﬃcients. This allows us to penalize
the scaling coeﬃcients diﬀerently than the wavelet coeﬃcients (with the help of diﬀerent penalization
parameters τs and τw). We can use the following iteration, similar to formula (12), but now in the wavelet
domain:

w(n+1) = α2WAT d +

I
h

−

(α2WAT AWT + α2˜I)
w(n),
i

w(0) = 0,

(13)

where ˜I acts as the τw ×
identity on scaling coeﬃcients.
If we were to use an orthonormal wavelet basis (WT W = WWT = I) for our expansions, and if we
penalized every coeﬃcient the same, τw = τs = τ , then this method would be identical to the previous ℓ2
method.

identity on wavelet coeﬃcients and as the τs ×

In the following we consider both one-step and two-step ℓ1 wavelet penalization as well as conventional
ℓ2 penalization, both without and with wavelets, using the rescaled iterative schemes (7), (8), (12) and (13)
for the purposes of comparison.

5

3

Implementation

To test the above ideas, we devised a dramatically simpliﬁed, two-dimensional, synthetic surface-wave in-
version problem very loosely modeled after an actual Passcal deployment in Tanzania [Owens et al.(1995)].
Fig. 4 (left) shows the hypothetical experimental setup: the highly schematized input model consists of a
sharp, bent, East African rift structure with low shear-wave velocity, δ lnβ(x, y) < 0, superimposed upon
a smooth, circular cratonic positive anomaly, δ lnβ(x, y) > 0. Eleven earthquake events (circles) were
taken from the NEIC catalogue to mimic realistic regional seismicity for the duration of a typical tempo-
rary deployment of the twenty-one stations (triangles). The locations of the seismic stations and events
21 source-receiver paths, we assume that fundamental-mode
are listed in Table 1. For each of the 11
Rayleigh-wave perturbations δk(ν) have been measured at eight selected frequencies between ν
0.01 Hz
and ν
0.1 Hz. These wavenumber perturbations are related to the 2D, depth-independent velocity per-
turbations δ lnβ(x, y) via a 2D, frequency-dependent sensitivity kernel (see Appendix A for more details):

≈

×

≈

δk(ν) =

K2D(x, y, ν) δ lnβ(x, y) dx dy.

Z Z

(14)

≈

0.1 Hz) kernel K2D(x, y, ν) for a
0.01 Hz) and highest-frequency (ν
Plots of the lowest-frequency (ν
typical source-receiver pair are shown in the left two panels of Fig. 5. Because ﬁnite-frequency scattering
and diﬀraction eﬀects are accounted for in the kernels K2D(x, y, ν), there is signiﬁcant oﬀ-path sensitivity
of the measurements δk(ν) within the ﬁrst one or two Fresnel zones [Zhou et al.(2004)]. All kernels
K2D(x, y, ν) and distances are computed in the ﬂat-earth earth approximation.

The study region, which is 35◦ (north-south) by 25◦ (east-west), is subdivided into Nx×

64 =
4096 equal-sized rectangles, and the discretized model vector m consists of the unknown constant values
of δ lnβ(x, y) within each rectangle. To compute the matrix A, which maps the discretized model m onto
the data d (consisting of multiple δk(ν)), each kernel K2D(x, y, ν) is sampled nx ×
ny times on each of
the Nx ×

Ny model-vector rectangles and a Riemann sum is used to compute the quantity

Ny = 64

≈

×

K2D(x, y, ν) dx dy

Z Zrectangle(k,l)

∆x∆y
nxny Xm,n

≈

K2D (xl −

∆x/2 + (m

1/2)δx, yk −

−

∆y/2 + (n

1/2)δy, ν) ,

−

×

×

(15)
Ny grid on which the
where δx = ∆x/nx and δy = ∆y/ny. A schematic representation of the Nx ×
spatial-domain model m is speciﬁed and the nx ×
ny integration subgrid is shown in Fig. 3. We choose
nx = ny = 32 since we have found that doubling this to nx = ny = 64 yields a change of less than one
percent in the integrated value of A. The dimensions of the resulting matrix A are 1848 (number of
stations
number of wavenumbers) by 4096 (number of model-vector pixels). To
give an idea of the overall degree of coverage, we have plotted the sum (over all station event pairs) of the
absolute value of all of the lowest-frequency and all the highest-frequency discretized kernels in the right
two panels of Fig. 5. It is clear that much of the study area, particularly in the northwest and southeast,
is completely uncovered (as is typical of real-world, regional seismic experiments).

number of events

Using the matrix A and the input model minput with a sharp, low-velocity East African rift superim-
posed on a broad, high-velocity cratonic structure, we compute synthetic data d = Aminput +e, where we
have added Gaussian noise e with zero mean and a standard deviation equal to two percent of the largest
Aminput
synthetic wavenumber perturbation, i.e. σ = 0.02 max(
). By adopting a constant standard
|
|
deviation σ, errors at the highest frequency ν and unperturbed wavenumber k(ν) are more than an order
of magnitude smaller than those for the lowest frequency and wavenumber data, where the signal-to-noise
ratio may be close to unity. Since ﬁnite-frequency inversions include the eﬀect of scattered wave energy,
a high precision of the measurement δk(ν) at high frequency ν is realistic. The purpose of the proposed
algorithm is now to reconstruct m from the knowledge of the noisy data d, the matrix A and the linear
equations Am = d.

6

(k, l) = (1, 1)

xmax

ymax

∆y

ymin

xmin

∆x

(k, l) = (Ny, Nx)

∆x

∆y

δy

δx

δx/2

δy/2

Ny grid used to specify
Figure 3: Schematic representation of the 2D Cartesian grids used. Left: Nx ×
ny grid used to compute the kernel matrix A via
the model m. Right: Blowup of the ﬁner-scale nx ×
the approximate integration (15). Since the study region is rectangular in shape (see Fig. 4) and since
Nx = Ny and nx = ny, the actual ∆x
δy integration subpixels are also
×
rectangular, rather than square as shown.

∆y model pixels and δx

×

Table 1: List of positions of seismic stations and earthquake events used in the synthetic inversion.

Stations

Events

longitude
29.02◦
49.10◦
44.15◦
30.82◦
46.34◦
39.17◦
32.78◦
44.15◦
28.84◦
40.33◦
33.67◦

latitude
1.86◦
−
12.85◦
11.80◦
7.84◦
−
12.33◦
19.02◦
5.06◦
14.57◦
1.16◦
14.20◦
3.05◦

−

longitude
33.3203◦
35.1382◦
32.7712◦
33.2588◦
29.6927◦
38.6170◦
30.3988◦
36.5695◦
37.4763◦
36.7192◦
35.7965◦
36.6983◦
34.3462◦
34.0560◦
35.4007◦
33.2415◦
33.1842◦
33.5180◦
34.7315◦
36.0163◦
32.0832◦

latitude
7.9073◦
4.3238◦
9.2958◦
8.1060◦
4.8392◦
5.3018◦
5.1168◦
5.3223◦
5.3775◦
3.8422◦
4.9040◦
2.7252◦
4.9610◦
6.0192◦
5.2508◦
8.9835◦
4.7145◦
6.9372◦
4.6403◦
3.8892◦
5.0878◦

−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−

7

input

ℓ1

ℓ2

ℓ2 (wavelets)

30°

40°

50°

30°

40°

50°

30°

40°

50°

30°

40°

50°

Figure 4: From left to right: Toy 2D velocity model for the East African rift and adjacent continental
craton, showing the seismic stations (triangles) and earthquake events (circles); reconstructed model using
the two-step ℓ1-penalization method; reconstruction using the spatial-domain ℓ2 method; reconstruction
using the wavelet-domain ℓ2 method. The two-step ℓ1 model is that obtained after 1000 + 1000 iterations,
whereas both ℓ2 models are after 2000 Landweber iterations. Red denotes low anomalous velocity,
δ lnβ(x, y) < 0, and blue denotes high velocity, δ lnβ(x, y) > 0. The absolute magnitude
is
irrelevant, since the inverse problem Am = d is linear and the synthetic data are constructed from the
input model minput (leftmost map) via d = Aminput + e.

δ lnβ(x, y)
|
|

0.01 Hz

0.1 Hz

0.01 Hz

0.1 Hz

20°

10°

0°

−10°

20°

10°

0°

−10°

20°

10°

0°

−10°

20°

10°

0°

−10°

20°

10°

0°

−10°

20°

10°

0°

−10°

30°

40°

50°

30°

40°

50°

30°

40°

50°

30°

40°

50°

≈

Figure 5: Left: Map view of a typical two-dimensional sensitivity kernel K2D(x, y, ν) at the lowest
frequency considered, ν
0.1 Hz) kernel for the
0.01 Hz. Second from left: Highest-frequency (ν
same source-receiver path. Both kernels exhibit structure on a much ﬁner scale than the resolution of
ny numerical integration to compute the matrix A in eq. (15). Red
the model, necessitating the nx ×
denotes negative values, K2D(x, y, ν) < 0, and blue denotes positive values, K2D(x, y, ν) > 0. The cross-
path tapering of the kernels as a result of the ﬁnite time-domain taper, eqs (A6)–(A7), is clearly visible.
Second from right: The sum (over all source-receiver pairs) of the absolute value of the lowest frequency
(ν
0.01 Hz) integrated kernels (as computed in eq. 15). Far right: The sum (over all source-receiver
0.1 Hz) integrated kernels (as computed in
pairs) of the absolute value of the highest frequency (ν
eq. 15). The coverage is adequate in the vicinity of the East African rift (by design of the original seismic
deployment) but poor elsewhere.

≈

≈

≈

20°

10°

0°

−10°

20°

10°

0°

−10°

8

Figure 6: Spatial-domain structure of the 2D dual-tree complex wavelets used in the reconstruction (ﬁgure
taken/adapted from [Selesnick et al.(2006)]). First row: real part, second row: imaginary part, third row:
norm squared (i.e. sum of the squares of the top two plots). The directional character of each of the six
wavelet functions is clear. Four diﬀerent wavelet scales, i.e. four diﬀerent replicas of this picture, each a
factor of two smaller than the one above it, are used in both the ℓ1 and ℓ2 wavelet-basis inversions.

×

For our purposes we will make use of the overcomplete 2D wavelet basis described by [Kingsbury(2002)]
and [Selesnick et al.(2006)] because of its ability to distinguish diﬀerent directions (see Fig. 6). We use
642 = 16 384 wavelet and scaling coeﬃcients w (four times the
four wavelet scales, for a total of 4
number of model coeﬃcients m). The starting point for the iterations in both the ℓ1 and ℓ2 inversions
is w = 0 and m = 0. As explained in the previous section we renormalize the ℓ1 thresholded iteration
−1/2
max (which in our case equals 4884.5) where λmax is the largest eigenvalue of AT A.
by choosing α = λ
We let the iteration run for 1000 steps, adjust the data (two-step procedure) and let the second-step
algorithm run for another 1000 steps. The threshold τ is chosen by hand in such a way as to arrive at
d
a ﬁnal value for the variance-adjusted misﬁt, χ2 =
2 /σ2, that is approximately equal to 1848
2
k
(the number of data). The noisy data d are thus ﬁt to within their standard errors σ and no better;
pushing the ﬁt beyond this would amount to ﬁtting the noise e, which would lead to undesirable artifacts
in the resulting model m.

Am

−

k

k , wim
k )

It should also be noted that the thresholding is done on pairs of wavelet coeﬃcients: The wavelets
come in pairs (at the same scale, position and orientation) that we interpret as real and imaginary part
of a complex wavelet, i.e. thresholding corresponds to (wre
| →
(Re(˜z), Im(˜z)). This particular method of thresholding is borrowed from image denoising where it
is found to make a big diﬀerence in avoiding artifacts [Guleryuz(2006), van Spaendonck et al.(2003),
Selesnick et al.(2005)]. Furthermore, the threshold for the diagonally oriented wavelets is multiplied by
ψotherk1. We choose the threshold τs for the scaling coeﬃcients to
1.2395 because
be 1/10th of the threshold τw for the wavelet coeﬃcients; since the scaling coeﬃcients correspond to a
few large-scale averages (64 in our case versus more than 16 000 ﬁner-scale wavelet coeﬃcients) it is not
so important that these be sparse. Likewise, in the wavelet-basis ℓ2 inversions, we set the penalization
parameter for the scaling coeﬃcients to 1/10th the value of the penalization parameter for the wavelet
coeﬃcients.

k1 = 1.2395

z
˜z = zSτ (
|

k + iwim

z = wre

k →

ψ±45◦

)/
|

k∇

k∇

z
|

→

The two-step ℓ1 algorithm takes about ten minutes for 1000 + 1000 iterations on a 1.5GHz PC. The
result of the ℓ1 inversion is compared with the outcome of both of the ℓ2 methods, with and without
using wavelets, with the thresholding or penalization parameter τ chosen in every case to achieve the
same data ﬁt: χ2
1848 (see Fig. 7). The number of Landweber iterations is 2000, so that the total
number of two-step ℓ1 and single-step ℓ2 iterations is the same. The spatial-domain ℓ2-regularization
method yields a relative modeling error
k2 of about 74%, whereas the two-step ℓ1
k2/
method yields a relative modeling error of only 47% (see Fig. 8), and is clearly less noisy (compare the

minput

minput

m

−

≈

k

k

9

4000

3500

3000

2500

2000

χ2

1500

0

.

.

start of second step in two-step method

200

400

600

800

1200

1400

1600

1800

2000

1000
iterations

Figure 7: Graph of the variance-adjusted data ﬁt χ2 =
2 /σ2 versus the number of iterations:
2
two-step ℓ1-regularization method (solid line), spatial-domain ℓ2 method (dashed line) and wavelet-basis
ℓ2 method (dotted line ). The thresholding and penalization parameter τ has in each case been tailored
so that the ﬁnal value of χ2, after 1000 + 1000 or 2000 iterations, is equal to the number of data, namely
1848. Note the improvement in the rate of convergence toward the model with χ2 = 1848 after the
implementation of the second step in the two-step ℓ1 iteration.

−

k

k

d

Am

middle two maps in Fig. 4). The wavelet-basis ℓ2-regularized inversion (rightmost map in Fig. 4) is only
slightly less noisy, with a relative modelling error of about 55% (Fig. 8). One feature that can never be
recovered in any of the reconstructions is the southern part of the rift, which does not lie between any
station-event pair.

In Fig. 9 we compare the wavelet coeﬃcients w of the input model, the two-step ℓ1 reconstruction
and the wavelet-basis ℓ2 reconstruction.
In accordance with our basic assumption, the ℓ1-regularized
model is sparse in the wavelet basis. Most of the small-scale coeﬃcients w are zero —in agreement with
the original model on the left— indicating the eﬀectiveness of the iterative thresholding algorithm. The
wavelet coeﬃcients of the wavelet ℓ2 reconstruction are clearly not sparse. Also this solution seems to
suﬀer from large-scale artifacts (see Fig. 4, rightmost map).

In the leftmost plot in Fig. 10 we show χ2 versus

w
k1 tradeoﬀ curves for the ℓ1 reconstruction method,
k
both with and without using the two-step procedure. After 1000 + 1000 iterations, the ℓ1 wavelet norm
w
k1 of the two-step reconstructed model is lower — for the same value of χ2 — than the corresponding
k
norm of the model produced by 2000 iterations of the ﬁrst step, with no subsequent redeﬁnition of
the data d and reiteration. This is an indication that 2000 total iterations is inadequate to achieve full
convergence, since the fully converged model, which minimizes the functional I1(w) given in eq. (1), must
be the minimum-norm model for a ﬁxed value of χ2 by deﬁnition. A much larger number of iterations
seems to be required to guarantee convergence. To construct the second set of tradeoﬀ curves in Fig. 10,
we employed 150 000 + 150 000 iterations in the two-step case and 300 000 in the single-step case; such a
large number would be prohibitive in any larger-scale, more realistic, 3D application. We have chosen to
limit the iteration counts to 1000 + 1000 or 2000 in all of our model-space comparisons, since any changes
in the spatial-domain features of the models m are barely discernible to the eye with further iteration.
The rightmost plot in Fig. 10 shows the principal advantage of using the two-step iteration procedure:
for the same total number of iterations, either 1000 + 1000 = 2000 or 150 000 + 150 000 = 300 000, the
number of nonzero wavelet coeﬃcients of the two-step models is always lower than the corresponding
number for the single-step models. The two-step ℓ1 procedure therefore leads more quickly to a sparser
wavelet-basis solution, as expected.

We also compared the single-step and two-step ℓ1 inversion methods with the corresponding ℓ2 re-
construction methods, both with and without wavelets, for a number of other input synthetic models.
These include three checkerboard patterns of decreasing scale and a model similar to the geologically

10

.

1

0.8

0.6

0.4

0.2

0

2
k

t
u
p
n

i

m
k
/
2
k

t
u
p
n

i

m
−
m
k

.

start of second step in two-step method

200

400

600

800

1200

1400

1600

1800

2000

1000
iterations

Figure 8: Graph showing the relative modeling error
k2 versus the number of
iterations: two-step ℓ1 method (solid line), spatial-domain ℓ2 method (dashed line) and wavelet-basis
ℓ2 method (dotted line). The ℓ1-regularization method clearly yields the most faithful reconstruction of
the input model minput. Note the (slight) improvement in the rate of decrease of the modelling error
following the start of the second step in the two-step ℓ1 iteration.

k2/

−

k

k

m

minput

minput

input

ℓ1

ℓ2 (wavelets)

Figure 9: Graphical display of (the modulus of) the wavelet and scaling coeﬃcients. Left: coeﬃcients
of the synthetic input model minput. Middle: coeﬃcients of the two-step ℓ1 model after 1000 + 1000
iterations. Right: coeﬃcients of the wavelet-basis ℓ2 model after 2000 iterations. The four wavelet scales
are plotted, smallest to largest, top to bottom. Each row shows the six diﬀerent wavelet directions, plotted
next to each other in the same left-to-right order as the wavelets plotted in Fig. 6. Scaling coeﬃcients
are plotted on the bottom row. White denotes a zero coeﬃcient, wi = 0. Each rectangle corresponds to
the spatial domain 25◦E – 50◦E by 15◦S – 20◦N.

11

one-step
two-step

χ2=1848

2300

2200

2100

χ2

2000

1900

1800

1700

1600

7

one-step
two-step

χ2=1848

2300

2200

2100

χ2

2000

1900

1800

1700

1600

0

300 000
iterations

2000 iterations

2000 iterations

300 000
iterations

8

9

10

11

13

14

15

16

17

12
||w||1

50

100

150
250
number of non-zero wavelet coefﬁcients

200

300

w

Figure 10: Left: Data misﬁt χ2 versus ℓ1 wavelet norm
||1 tradeoﬀ curve. Right: Alternative tradeoﬀ
curve showing χ2 versus the number of nonzero wavelet coeﬃcients of the model m. Diﬀerent values
of the thresholding parameter τ were used to determine each point on the various curves. Circles: one-
step method, after either 2000 or 300 000 iterations; crosses: two-step method after an equivalent number
(either 1000+1000 or 150 000+150 000) of total iterations. The relative positions of the one-step and two-
step curves suggests that 300 000 total iterations is suﬃcient to achieve full convergence. The horizontal
dotted lines show the statistically meaningful value of the noisy data misﬁt, χ2 = 1848 (the number of
data).

||

inspired one in Fig. 4, but with a more curvaceous low-velocity rift (see Fig. 11). Both the single-step ℓ1
reconstructions and the ℓ2 reconstructions are computed using 2000 iterations, whereas the two-step ℓ1
models are computed using 1000 + 1000 iterations. In all cases, the two-step ℓ1 models are the most par-
simonious and therefore to most geoscientists the most acceptable. One could consider using smoothness
damping to improve the quality of the ℓ2 images; however, this would be done at the cost of resolving
the sharpness of the rift structure. A nitpicker could perhaps also argue that the “rift” structure in the
model produced by the ℓ1 procedure extends further northwards, albeit diminished in amplitude, whereas
conventional ℓ2 regularization without wavelets exhibits a sharper cutoﬀ, more like the input model. It
achieves this sharp cutoﬀ, however, at the expense of many artifacts elsewhere, especially along dominant
ray directions. Perhaps the most noteworthy feature of the ℓ1 regularization method is its suppression
of the artifacts resembling high-frequency kernel images that are streaked along surface-wave raypaths in
all the ℓ2 models, to the north of the rift and within the craton. This is one of the most serious artifacts
that plague conventional seismic tomography: ℓ2 regularization frequently if not always seems to enhance
the well-sampled regions of the model. The ℓ1 wavelet-basis reconstructions show no signs of this familiar
deﬁciency.

The computational bottleneck in the present 2D synthetic study is not the wavelet transform — which
is fast, certainly on a model m of modest dimension 64
64 — or even the number of iterations, but it
is simply the size of the matrix A. A signiﬁcant amount of time is needed to accurately pre-compute A,
and considerable memory is needed to store the computed elements in memory; this is necessary because
the product AT A is used in every step of the iteration. Doubling of the resolution in every direction
results in a fourfold increase in size of the model m, and a sixteen-fold increase in the number of elements
in the square matrix AT A. All calculations were performed using Matlab; software for the 2D dual-tree
wavelets was downloaded from [Selesnick et al.(2006)].

×

12

input

ℓ1 (one-step)

ℓ1 (two-step)

ℓ2

ℓ2 (wavelets)

−10°

−10°

−10°

−10°

−10°

30°

40°

50°

30°

40°

50°

30°

40°

50°

30°

40°

50°

30°

40°

50°

−10°

−10°

−10°

−10°

−10°

30°

40°

50°

30°

40°

50°

30°

40°

50°

30°

40°

50°

30°

40°

50°

−10°

−10°

−10°

−10°

−10°

30°

40°

50°

30°

40°

50°

30°

40°

50°

30°

40°

50°

30°

40°

50°

−10°

−10°

−10°

−10°

−10°

30°

40°

50°

30°

40°

50°

30°

40°

50°

30°

40°

50°

30°

40°

50°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

20°

10°

0°

−10°

−10°

−10°

−10°

−10°

30°

40°

50°

30°

40°

50°

30°

40°

50°

30°

40°

50°

30°

40°

50°

Figure 11: Results of applying diﬀerent reconstruction techniques to a number of diﬀerent 2D toy models.
From left to right: Original input model; ℓ1 reconstruction (2000 iterations, single-step procedure); ℓ1
13
reconstruction (1000 + 1000 iterations, two–step procedure); ℓ2 reconstruction (2000 iterations, without
wavelets); ℓ2 reconstruction (2000 iterations, with wavelets).

4 Conclusions

We tested several new methods of regularization through wavelet decomposition of a toy 2D tomographic
problem characterized by both smooth and sharp velocity anomalies. A variety of synthetic inversion
experiments show that minimization of the ℓ1-norm of a wavelet decomposition of the model leads to
tomographic images that are parsimonious in the sense that they use only a few wavelets and still represent
both smooth and sharp features well without introducing signiﬁcant blurring or artifacts. The ℓ1-norm
performs signiﬁcantly better than an ℓ2 regularization on either the model or its wavelet decomposition.
In particular, raypath-associated artifacts are almost completely suppressed.

The choice of dual-tree complex wavelets in 2D, representing six space directions, is suﬃcient to
avoid directional bias, and eﬃcient in modeling both smooth features such as the cratonic structure as
well as sharp features such as the rift structure in our simpliﬁed synthetic model. Numerical comparisons
between the inversion results and the input model used to generate the data conﬁrm the superiority of the
ℓ1-norm regularization. Though in real-world inversions such ground-truth information is not available,
one can argue that the ℓ1 inversion method serves the principle of parsimony well and is to be preferred
over more common methods. If the tomographic object (such as the real earth) is too complex to be well
represented by a parsimonious expansion in wavelets, neither method is able to resolve such complexity
adequately with a limited data set, as shown in the bottom rows of Fig. 11, where even the ℓ1 inversions
begin to show the eﬀects of raypath distribution. In this case, we expect that the principle of parsimony
can be usefully applied once a richer family of building blocks is considered.

The only drawback of the method, so far, is the slow convergence of the ℓ1 surrogate-functional
iteration procedure. Our preference for the thresholded algorithm used here arises from the fact that
its convergence is guaranteed even though the ℓ1 problem is nonlinear. We have introduced a two-step
procedure that leads to a signiﬁcant speedup; however, Fig. 10 indicates that even 1000+1000 iterations do
not suﬃce for complete convergence (it nevertheless produces an excellent approximation). A potentially
promising approach towards further convergence improvement is to combine an eﬃcient linear method
(such as e.g. conjugate-gradient) with an adaptive thresholding scheme. This would then avoid the need
to precompute the largest eigenvalue of AT A and facilitate the application of the ℓ1 method to a larger,
3D, study of body-wave tomography.

Financial support for this work was provided by NSF grant DMS-0530865. I.L. is a postdoctoral fellow
with the F.W.O.-Vlaanderen (Belgium).

5 Acknowledgments

References

[Candes et al.(2006)] Candes, E., Romberg, J. & Tao, T., 2006. Stable signal recovery from incomplete

and inaccurate measurements, to appear in Comm. Pure Appl. Math.

[Constable et al.(1987)] Constable, S.C., Parker, R.L. & Constable, C.G., 1987. Occam’s inversion: a
practical algorithm for generating smooth models from electromagnetic sounding data, Geophys., 52,
289–300.

[Daubechies(1992)] Daubechies, I., 1992. Ten Lectures on Wavelets, SIAM Press, Philadelphia.

[Daubechies et al.(2004)] Daubechies, I., Defrise, M. & De Mol, C., 2004. An iterative thresholding algo-
rithm for linear inverse problems with a sparsity constraint. Comm. Pure App. Math., 57, 1413–1541,
arXiv/FA/0307152.

14

[Deal & Nolet(1999)] Deal, M.M. & Nolet, G., 1999. Slab temperature and thickness from seismic to-
mography 2. Izu-Bonin, Japan and Kuril subduction zones, J. Geophys. Res., 104, 28803–28812.

[Deal et al.(1999)] Deal, M.M., Nolet, G. & van der Hilst, R.D., 1999. Slab temperature and thickness
from seismic tomography, 1. Method and application to Tonga, J. Geophys. Res., 104, 28789–28802.

[de Hoop & van der Hilst(2005)] de Hoop, M. V. & van der Hilst, R. D., 2005. On sensitivity kernels for

wave equation tomography, Geophys. J. Int., 160, 621–633.

[Donoho(2004)] Donoho, D. L., 2006. For most large underdetermined systems of linear equations the

minimal ℓ1-norm solution is also the sparsest solution, Comm. Pure Appl. Math., 59, 797–829.

[Dziewonski et al.(1975)] Dziewonski, A.M., Hager, B.H. & O’Connell, R.J., 1975. Large scale hetero-

geneities in the lower mantle, J. Geophys. Res., 82, 239–255.

[Dziewonski & Woodhouse(1987)] Dziewonski, A.M. & Woodhouse, J.H., 1987. Global images of the

Earth interior, Science, 236, 37–48.

[Guleryuz(2006)] Guleryuz, O.G, 2003. Weighted overcomplete denoising, In Conference Record of the

Thirty-Seventh Asilomar Conference on Signals, Systems and Computers, 2, 1992–1996.

[Kingsbury(1999)] Kingsbury, N., 1999. Image processing with complex wavelets, Phil. Trans. Roy. Soc.

Lond., A357, 2543–2560.

[Kingsbury(2002)] Kingsbury, N. G., 2002. Complex wavelets for shift invariant analysis and ﬁltering of

signals, Applied and Computational Harmonic Analysis, 10, 234–253.

[Landweber(1951)] Landweber, L., 1951. An iterative formula for Fredholm integral equations of the ﬁrst

kind, Am. J. Math., 73, 615–624

[Masters et al.(1996)] Masters, G., Johnson, S., Laske, G. & Bolton, H., 1996. A shear veolcity model of

the mantle, Phil. Trans. Roy. Soc. Lond., A354, 1385–1410.

[Nolet(1987)] Nolet, G., 1987. Seismic wave propagation and seismic tomography, In G. Nolet, editor,

Seismic Tomography, pages 1–23, Dordrecht, Reidel.

[Owens et al.(1995)] Owens, T.J., Nyblade, A.A. & Langston, C.A., 1995. The Tanzania broadband

experiment, IRIS Newsletter, 14, 1.

images, Geophys., 64, 874–887.

[Portniaguine & Zhdanov(1999)] Portniaguine, O. & Zhdanov, M.S., 1999. Focusing geophysical inversion

[Selesnick et al.(2005)] Selesnick, I. W., Baraniuk, R. G. & Kingsbury, N., 2005. The dual-tree complex
wavelet transform — A coherent framework for multiscale signal and image processing, IEEE Signal
Processing Magazine, 22, 123-151.

[Selesnick et al.(2006)] Selesnick, I., Cai, S. & Li, K., 2006. MATLAB implementation of wavelet trans-

forms, http://taco.poly.edu/WaveletSoftware/.

[Spakman & Nolet(1988)] Spakman, W. & Nolet, G., 1988. Imaging algorithms, accuracy and resolu-
tion in delay-time tomography, in N.J. Vlaar et al., editor, Mathematical Geophysics, pages 155–187,
Hingham, Mass., Reidel.

[Trampert & Snieder(1996)] Trampert, J. & Snieder, R., 1996. Model estimations biased by truncated

expansions: possible artifacts in seismic tomography, Science, 271, 1257–1260.

15

scatterer
l′

l′′

η

l

source

receiver

Figure 12: Schematic map view of the single-scattering geometry in our simpliﬁed 2D, ﬂat-earth, surface-
wave inversion problem. The quantity l is the horizontal epicentral distance between the source and
receiver; l′ and l′′ are the lengths of the ﬁrst and second legs of the detour path, respectively, and the
angle η measures the deﬂection of the wave at the scatterer.

[VanDecar & Snieder(1994)] VanDecar, J.C. & Snieder, R., 1994. Obtaining smooth solutions to large,

linear, inverse problems, Geophysics, 59, 818–829.

[van Spaendonck et al.(2003)] van Spaendonck, R., Blu, T., Baraniuk, R. & Vetterli, M., 2003. Orthogo-
nal Hilbert transform ﬁlter banks and wavelets, IEEE International Conference on Acoustics, Speech,
and Signal Processing (ICASSP), 6, 505-508.

[Zhou et al.(2004)] Zhou, Y., Dahlen, F.A. & Nolet, G., 2004. Three-dimensional sensitivity kernels for

surface wave observables, Geophys. J. Int., 158, 142–168.

A Two-dimensional sensitivity kernels

The toy linear inverse problem Am = d used in this paper is designed to incorporate all the impor-
tant characteristics of a real-world regional tomographic inversion, while at the same time being small
enough to allow for repeated experimenting with reasonable CPU times on a single workstation. For
this reason, we limit attention to surface-wave dispersion data, speciﬁcally perturbations δk(ν) in the
wavenumber k(ν), presumed to be measured in rad/m, of the fundamental (n = 0) Rayleigh mode at
temporal frequency ν, measured in Hz. Finite-frequency theory based upon the Born approximation
[Zhou et al.(2004)] gives a linear relationship between such wavenumber perturbations and the 3D per-
turbations in the fractional shear-wave velocity δ lnβ(x) within the earth:

δk(ν) =

Z Z Z

K3D(x, ν) δ lnβ(x) d3x.

(A1)

Making use of a number of ﬂat-earth approximations that do not fundamentally aﬀect the nature of the
inverse problem, we can write the 3D Fr´echet sensitivity kernel K3D(x, ν), for the simplest case of an
explosive source with an isotropic radiation pattern and a measurement made on the vertical component
at the receiver, in the form

K3D(x, ν) = [e0(z, ν) + e1(z, ν) cos η + e2(z, ν) cos 2η]

1
2

1
8πk(ν)l l′l′′ (cid:19)

(cid:18)

sin[k(ν)(l

+ l

′

′′

l + π/4)] ,

−

(A2)
where z is the depth, l is the epicentral distance measured in m on the surface of the earth, and l′ and l′′
are the horizontal distances of the scatterer x = (x, y, z) from the source and receiver, respectively. The
quantity η is the scattering angle, measured at the surface projection (x, y) of x, as shown in Figure 12.
Expressions for the depth-dependent functions e0(z, ν), e1(z, ν) and e2(z, ν) can be found in the appendix
of [Zhou et al.(2004)].

16

To simplify matters even further, we assume that the velocity perturbation δ lnβ(x) is independent
of depth z and dependent only upon the horizontal Cartesian coordinates x and y. Upon integrating the
factors e0(z, ν), e1(z, ν) and e2(z, ν) over depth,

E0(ν) =

e0(z, ν) dz,

E1(ν) =

e1(z, ν) dz,

E2(ν) =

e2(z, ν) dz,

(A3)

∞

Z
0

∞

Z
0

∞

Z
0

we may then relate δk(ν) to δ lnβ(x, y) via a 2D sensitivity kernel:

δk(ν) =

K2D(x, y, ν) δ lnβ(x, y) dx dy,

Z Z

(A4)

where

K2D(x, y, ν) = [E0(ν) + E1(ν) cos η + E2(ν) cos 2η]

1
2

1
8πk(ν)l l′l′′ (cid:19)

(cid:18)

sin[k(ν)(l′ + l′′

l + π/4)] .

(A5)

−

The rapidly oscillating sinusoidal function sin[k(ν)(l′ + l′′
l + π/4)] in eq. (A5) is constant on ellipses,
l′ + l′′ = constant, having the surface projections of the source and receiver as foci. The cos η and
cos 2η dependence and the term involving the integrable singularity 1/√l′l′′ act to slowly modulate this
dominant elliptical dependence.

−

Eqs (A4) and (A5) are valid, subject to the already noted approximations, for a monochromatic
wavenumber perturbation δk(ν), whereas actual surface-wave dispersion measurements must of necessity
be made on a portion of a seismogram of ﬁnite length, typically multiplied by a time-domain taper h(t).
[Zhou et al.(2004)] show that the eﬀect of such a ﬁnite-length taper can be accounted for by modifying
the taper as follows:

K2D(x, y, ν)

K2D(x, y, ν) h((l′ + l′′)/C(ν)),

→

(A6)

where C(ν) is the the group velocity at frequency ν measured in m/s. This modiﬁcation has the eﬀect of
limiting the cross-path width of the Fr´echet kernel K(x, y, ν), since h(t) = 0 for large detour times. We
assume the data δk(ν) have been measured using a Hann or cosine taper, of duration ﬁve wave periods
centered on the group arrival time:

h(t) = 


0
1
2 [1
0

−

cos 2πν(t

tarrival −

−

2.5/ν)]

for
for
for

2.5/ν
tarrival −
t
2.5/ν
tarrival + 2.5/ν

t
≤
tarrival −
t
≥

≤

≤

tarrival + 2.5/ν

(A7)

where tarrival = l/C(ν). Since l′ + l′′
ﬁnite-record-length sensitivity kernel (A6).

≥



≥

l only the t

tarrival portion of the taper (A7) contributes to the

The group velocity C(ν), unperturbed wavenumber k(ν) and auxiliary variables E0(ν), E1(ν) and
E2(ν) for fundamental-mode Rayleigh waves are listed in Table 2 at the eight selected frequencies ν;
the corresponding wave periods vary roughly between 100 and 10 s. Since E0(ν), E1(ν) and E2(ν)
are all negative, a positive velocity perturbation, δ lnβ(x, y) > 0, gives rise to a negative wavenumber
perturbation, δk(ν) < 0, i.e. an apparently longer wavelength wave, as expected. See Fig. 5 for two
examples of sensitivity kernels K2D(x, y, ν) computed in this way. It is noteworthy that a 2D surface-
wave inversion based upon eqs (A4)–(A7) diﬀers from the common approach of inverting for a 2D phase
velocity map at a single speciﬁed frequency ν: such maps are strictly incompatible with the notion of
ﬁnite frequency, where no local phase velocity can be deﬁned except when very crude approximations are
made; for a discussion of this issue see [Zhou et al.(2004)].

B Notes on wavelets

The basic building block of the 1D discrete wavelet transform (DWT) is a ﬁlter bank. It consists of a
high-pass ﬁlter g (i.e. a generalized diﬀerence) and a low-pass ﬁlter h (i.e. a generalized average) that

17

Table 2: Parameters ν, C(ν), k(ν), E0(ν), E1(ν) and E2(ν) needed to compute the simpliﬁed 2D sensitivity
kernels K2D(x, y, ν). Fundamental-mode Rayleigh-wave measurements δk(ν) are presumed to have been
made at eight frequencies ranging between ν

0.1 Hz (10 s period).

ν (mHz) C (m/s)
10.742
15.625
20.508
30.273
40.039
50.781
70.313
99.609

3831.3
3829.8
3751.3
3434.4
3064.8
2861.6
2872.8
2971.5

≈

≈

0.01 Hz (100 s period) and ν
k (10−4m−1) E0 (10−9m−2) E1 (10−9m−2) E2 (10−9m−2)
0.165 37
0.245 11
0.325 77
0.495 75
0.684 98
0.914 30
1.344 6
1.973 3

0.061 743
0.129 84
0.222 47
0.489 28
0.944 65
1.815 0
4.130 0
8.884 8

0.079 642
0.126 90
0.176 86
0.368 58
1.078 3
2.788 5
6.417 5

−
−
−
−
−
−
−
11.684

−
−
−
−
−
10.769
22.322
47.879

0.359 72
0.776 64
1.365 6
3.217 7
6.216 1

−
−
−
−
−
−
−
−

−
−
−

−

m

h

g

2

↓

2

↓

2

↑

2

↑

˜h

˜g

m+

m

h

g

2

2

↓

↓

h

g

2

2

↓

↓

h

g

2

2

↓

↓

Figure B1: Left: Schematic representation of a perfect-reconstruction ﬁlter bank that can be used to
decompose or reconstruct a 1D signal x. Right: A standard wavelet tree.

are applied to a given signal m (i.e. a list of numbers) in the following way: m is convolved with g and
downsampled, m is convolved with h and downsampled. This results in two signals, each with half the
length of the original one. The process can be inverted by upsampling (inserting zeroes) the two resulting
sequences and convolving each with two (carefully matched) ﬁlters ˜g and ˜h and then adding the two. A
traditional way of representing this procedure is shown in the left of Fig. B1. It turns out that there
exist ﬁnite ﬁlters that give rise to perfect reconstruction (these use ﬁnite convolutions only and lead to
compactly supported wavelets); moreover in some very special cases, one can have that ﬁnite ˜g and ˜h are
the reverse of g and h (corresponding to compactly supported orthogonal wavelets). The Haar wavelets
have g = ( 1
2 ), but there exist longer (perfect reconstruction) ﬁnite ﬁlters (which give
2 ,
rise to smoother wavelets). The so-called D4 wavelets correspond to h = (1 + √3, 3 + √3, 3
√3)/4√2 and g = (1
1

2 ) and h = ( 1

3 + √3, 3 + √3,

√3)/4√2.

√3, 1

2 , 1

√3,

−

−

−

1

The 1D discrete wavelet transform is deﬁned by the iteration of the analysis ﬁlter bank on the low-
pass outcomes (see right side of Fig. B1). In this way, successive levels of detail are stripped of the input
signal m (and stored in wavelet coeﬃcients), leaving a very coarse average (stored in so-called scaling
coeﬃcients). This construction is called a wavelet tree. It not only deﬁnes the DWT but also provides
its practical implementation. When using ﬁnite ﬁlters, the construction automatically gives rise to a
computationally eﬃcient algorithm: as a result of the subsampling each step cost only half as much time
as the previous one. The total number of operations then is kN + kN/2 + kN/4 + kN/8 + . . . = 2kN ,
less than the

(N 2) for a generic linear transformation.

−

−

−

−

A standard way of generating wavelets in 2D is to form the direct product of 1D wavelets, i.e. the
ﬁlters are applied to rows and columns of an image (lo-lo, lo-hi, hi-lo and hi-hi). This, however, has the
marked disadvantage of poor directional sensitivity. In this study, to obtain better directional sensitivity,

O

18

ky

ky

kx

kx

Figure B2: Partitioning of the 2D Fourier domain (kx, ky) by the supports of the Fourier transform of
wavelet functions. Only two wavelet scales are shown with the ﬁnest one on the outside. In practice the
supports have smooth (overlapping) tapers. Left: With the complex 2D wavelets used in this paper, all
squares come in pairs giving rise to six dominant directions (as indicated by the hatch patterns). Right:
The standard (direct product) 2D construction only has horizontal and vertical sensitivity; the ‘corner’
(hi-hi) squares encode both 45◦ and

45◦ at the same time.

we use the complex 2D wavelets developed by [Kingsbury(2002)]. These are constructed also by direct
product but from two simultaneous wavelet trees (see [Kingsbury(1999)] for a diagram of such a dual tree).
The qualitative diﬀerence between these two constructions is best seen in the Fourier domain. Fig. B2
shows a schematic representation of the supports of the Fourier transforms of the wavelet functions, both
for the usual 2D wavelet construction and for the 2D complex wavelets. The two are fundamentally
diﬀerent: whereas the usual separable 2D wavelet construction gives rise to a horizontal, a vertical and
one (!) diagonal part at each scale, the complex 2D construction has six diﬀerent inherent directions per
scale. A careful choice of the diﬀerent ﬁlters also leads to an (almost) tight frame (i.e. the inverse wavelet
transform almost coincides with the transpose).

The price to pay for these beneﬁts is the redundancy.

In 2D the complex wavelets generate four
times as many coeﬃcients as there are pixels in the original image (two trees and real and imaginary
64 spatial-domain images we use in Section 3 give rise to 16 320 =
parts of the output). E.g. the 64
42 scaling coeﬃcients (see e.g. Fig. 9).
2
Together this is 16 384 which equals 4

(322 + 162 + 82 + 42) wavelet coeﬃcients and 64 = 2

642.

×

×

×

×

×

6

2

−

×

19

