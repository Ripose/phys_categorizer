5
0
0
2
 
l
u
J
 
7
2
 
 
]
h
p
-
o
e
g
.
s
c
i
s
y
h
p
[
 
 
1
v
7
9
1
7
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Magnitude clustering and dynamical scaling in trigger models for earthquake
forecasting

Eugenio Lippiello,1 Cataldo Godano2 and Lucilla de Arcangelis3
1 Physics Department and CNISM, University of Naples ”Federico II”, 80125 Napoli, Italy
2 Department of Environmental Sciences and CNISM,
Second University of Naples, 81100 Caserta, Italy
3 Department of Information Engineering and CNISM,
Second University of Naples, 81031 Aversa (CE), Italy

One of the main interests in seismology is the formulation of models able to describe the clustering
in time occurrence of earthquakes. Analysis of the Southern California Catalog shows magnitude
clustering in correspondence to temporal clustering. Here we propose a dynamical scaling hypothesis
in which time is rescaled in terms of magnitude. This hypothesis is introduced in the context of
a generalized trigger model and gives account for clustering in time and magnitude for earthquake
occurrence. The model is able to generate a synthetic catalog reproducing magnitude and inter-even
time distribution of thirty years California seismicity.

PACS numbers: 64.60.Ht,91.30.Dk,89.75.Da

The great interest in the study of earthquake occurrence is linked to the challenge of predicting the time, the
location and the energy of the next earthquake. The energy release E in a seismic event can be expressed by the
magnitude M via the logarithm relation M ∝ log E [1], and the magnitude distribution is described by an exponential
law usually referred as the Gutenberg-Richter (GR) law [2] P (M ) ∼ 10−bM , where b is a parameter close to one.
The logarithm relation leads to a power law behaviour for the energy distribution, which is generally the signature of
critical phenomena.

It is widely observed that earthquakes tend to occur in bursts. These bursts start immediately following a large
main event, giving rise to the main-aftershock sequences, described by the Omori law [3]. This states that the number
of aftershocks n(t) decays in time as n(t) ∼ (t + c)−p where p is generally close to 1 and c is an initial time introduced
in order to avoid the divergence at t = 0. The most important implication of this law is that we cannot assume a
Poissonian occurrence for earthquakes, namely characterized by a constant rate of occurrence, but rather a clustered
one.

Another signature of non-Poissonian behaviour for earthquake occurrence is the complex distribution of the inter-
occurrence times between two successive events.
In fact, for a Poissonian process, this distribution would be an
exponential whereas experimental data exhibit a more complex behaviour [4]. Moreover, one can compute the intertime
distribution D(∆t, ML) where ∆t is time distance between successive events occurred inside a ﬁnite geographic region
and with magnitude greater than a given threshold ML. Indicating with PC (M ) the cumulative magnitude distribution
inside the considered region, one observes [4, 5]

D(∆t, ML) = PC (ML)f (PC (ML)∆t)

(1)

where f is a universal function, independent on ML and on the geographical region. The observed universality is a
further signature of criticality and indicates that D(∆t, ML) is an appropriate quantity to characterize the temporal
clustering of earthquakes.

A widely used approach to earthquakes clustering is provided by ”trigger models” [6]. These assume a Poissonian
occurrence of triggering events, whereas the occurrence of the ”triggered” earthquakes is described in terms of a
correlation function with previous events. Among the trigger models the Epidemic Type Aftershocks Sequence
(ETAS), introduced by Kagan-Knopoﬀ [7] and developed by Ogata [8], describes mainshocks and aftershocks on the
same footing. More precisely, each earthquake can generate ”its own aftershocks” and furthermore the number of
these aftershocks depends exponentially on the magnitude of the ”main”. The model has been deeply investigated
analytically and numerically [9].

In this paper we are interested in the description of temporal evolution of seismic activity. For this reason we
neglect spatial dependencies and treat seismicity as a stochastic process Mi(ti), where Mi is the magnitude of the
i − th earthquake occurred at time ti inside a large but ﬁnite geographic region. The process is deﬁned by the
conditional probability density p(M (t)|{Mi(ti)}) to have an earthquake of magnitude M at time t given the history
of past events {Mi(ti)}. Here we consider a generalized version of the trigger model by Vere-Jones

p(M (t)|{Mi(ti)}) =

p(M (t)|Mi(ti)) + µP (M )

(2)

Xi:ti<t

2

(a)

(b)

1,5

j

1

 

R
&

 

Q

 
j

0,5

j

 

R
&

 

Q

j

0

1,5

1

0,5

0

0

50

150

200

100
j

FIG. 1: (Color online) (a) Experimental distributions of the quantities Qj (red ◦) and Rj (black continuous line) for the
−1 and in order to improve the comparison Qj is vertically shifted by
California Catalog. Rj is measured in unit of (6hours)
the constant amount −1.5. Peaks for Rj indicate main-after shock sequences. (b) Numerical distributions of Qj and Rj from
Eq.(7).

where p(M (t)|Mi(ti)) is the ”two-point” conditional probability density, µ is a Poissonian rate and the magnitude
distribution P (M ) ∼ 10−bM obeys the GR law. Diﬀerent forms of p(M (t)|Mi(ti)) correspond to diﬀerent models for
seismicity. In the ETAS model one assumes [8]

p(M (t)|Mi(ti)) = P (M )g(t − ti; Mi)

(3)

where the propagator g(t − ti; Mi) ∝ 10αMi(t − ti + c)−p. In order to have a normalized probability one must impose
p > 1. Moreover, if α ≥ b the model presents ﬁnite time singularity unless one assumes a large magnitude cut-oﬀ [10].
Alternatively, one must take α < b as supported by some experimental observations [11].

P

A strong assumption of the ETAS model is the factorization in Eq.(3), which states that the magnitude of an
earthquake is completely independent on the magnitudes and times of occurrence of previous events. In order to
test this assumption with real seismic data, we observe that the quantity PC (ML) ∼ 10−bML takes the role of a
i 10−bMi]
characteristic time scale in Eq.(1). Hence, if one considers a subset of N events, the quantity Q = N/[
i(ti − ti−1)], where the sum is inside the chosen subset. To this
can be related to the rate of occurrence R = N/[
extent, we divide data recorded in the Southern California Catalog (1975-2004) [12] in subsequent sets of 200 events
with M ≥ 2.5 and we compute the quantities Qj and Rj inside the j-th subset. If the magnitude distribution were
constant in time, as supposed in Eq. (3), Qj should ﬂuctuate around an average value. Conversely, the experimental
Qj displays scattered and narrow peaks (Fig.1a). Interestingly, these peaks are closely located to peaks in the Rj
distribution.
It is well known that peaks of Rj are located soon after main-shocks and indicate the presence of
main-after shock sequences. Fig.1a, then, shows that in subsets of the catalog where activity has an higher rate,
the probability to have large magnitude events is also raised. This aspect can be directly investigated by computing
the cumulative magnitude distribution PC (M ) only inside the ensemble of main-aftershock sequences. Considering
only sequences with main-shock magnitude M ≥ 6, one obtains that PC (M ) exhibits a GR behaviour with a best
ﬁt b-value b = 0.75, lower than the b-value obtained for the whole catalog (b = 0.95) within the 95% signiﬁcativity
level. This result further supports the idea that large earthquakes not only produce the clustering in time described
by the Omori law, but also a clustering in magnitude. The ETAS model does not take into account this last physical
mechanism.

P

In order to include the magnitude clustering within a trigger model approach, we propose a dynamical scaling
p (Mj −Mi) so that the
hypothesis: the magnitude diﬀerence Mi − Mj ﬁxes a characteristic time scale τij = k10
conditional probability is magnitude independent when times are rescaled by τij and k is a constant measured in
seconds

b

p(Mi(ti)|Mj(tj)) = F

(ti − tj)
τij

(cid:21)

(cid:20)

(4)

Let us then consider the probability to have an event of magnitude M at time t given a triggering event at time t0
dM0P (M, t|M0, t0)P (M0). Assuming the GR law for P (M0) and using

of arbitrary magnitude M0, p(M, t − t0) =

R

Eq.(4), one ﬁnds

p(M, t − t0) =

10bM (t−t0)p

10−bM
(t − t0)p Z
0

F (z1/p)dz.

From this equation we obtain both the GR and Omori law independently of the speciﬁc form of F (z) provided that
the appropriate constraints are imposed at small and large z. In fact, assuming that the conditional probability (6) is
maximal soon after the triggering event, must be F (0) > 0. Furthermore, in order to have normalized distributions,
the conditional probability must decay to zero for large time separation and a constraint on the behaviour of F (z1/p)
must be imposed at large z, namely a decay faster than 1/z. Because of this constraints, the integral in the rhs of
Eq.(5) is a constant for large t − t0, and the GR and Omori law directly follows from Eq.(4). The above observation
suggests that statistical features of the trigger model can be independent on the detailed form of F (z) once the scaling
Eq.(4) is assumed. This hypothesis together with the relationship between numerical and experimental behaviour can
be directly tested in numerical simulations.

In a numerical protocol one assumes at initial time t0 = 0 a single event of arbitrary magnitude chosen in a ﬁxed
range [Mmin, Mmax]. Time is then increased of a unit step t = t0 + 1, a trial magnitude is randomly chosen in the
interval [Mmin, Mmax] and Eq.(2) gives the probability to have an earthquake in the time window (t0, t0 + 1). If this
probability is larger than a random number between 0 and 1, an earthquake takes place, its magnitude and time of
occurrence are stored and successively used for the evaluation of probability for future events. Time is then increased
and in this way one constructs a synthetic catalog of Ne events. The term µ in Eq.(2) represents an additional source
of earthquakes Poissonian distributed in time with a magnitude chosen from the GR distribution with b = 0.8.

Following this protocol, we generate sequences of 15000 events using a power law form for F (z)

F (z) =

A
zλ + γ

and then we compute the numerical distributions D(∆t, ML) and P (M ). These distributions are compared with the
experimental data from the Southern California Catalog. For diﬀerent values of λ, it is always possible to ﬁnd a
set of parameters A, γ, b/p, µ such that numerical data reproduce, on average, the statistical features of earthquake
occurrence both in time and in magnitude. The parameter k is ﬁxed a posteriori in order to obtain the collapse
between numerical and experimental data.

In Fig.2 we plot the experimental and numerical D(∆t, ML) considering two diﬀerent values of λ (λ = 1.2 and 5)
and ML (ML = 1.5 and 2.5). In the inset we also present the magnitude distributions. Data for diﬀerent values of
the parameters follow a universal curve and the same collapse is obtained for other values of λ > 1. The accordance
between experimental and numerical curves indicates that the hypothesis of dynamical scaling is able to reproduce
two fundamental properties of seismic occurrence, namely the GR law and Eq. (1), independently of the details of
F (z) [13].

The ETAS model is a particular case of Eq.(6) corresponding to γ = 0 and λ ≃ 1. We want to stress the important
diﬀerence due to the presence of a non-zero γ. From a mathematical point of view, the constant γ avoids the ﬁnite
time singularity of the ETAS model with α = b discussed previously [9]. From a physical point of view, the constant
γ gives rise to the observed clustering in magnitude. Indeed, for a given mainshock of magnitude Mj at time tj, at
each time (ti > tj) it is possible to deﬁne a suﬃciently large magnitude diﬀerence ∆M such that, if Mj − Mi > ∆M ,
we have that zλ is negligible with respect to γ and therefore F [(ti − tj)/τij] ≃ A/γ. In other words after a large event,
small earthquakes tend to be equiprobable.

We have also performed more extensive simulations using a diﬀerent expression for F (z)

F (z) =

A
ez − 1 + γ

Eq.(7) states that two events of magnitude Mi and Mj are correlated over a characteristic time τij and become
independent when ti − tj > τij . As a consequence only a small fraction of previous events can aﬀect the probability
of future earthquakes so that, after a certain time, Earth crust loses memory of previous seismicity. This aspect is
perhaps more realistic with respect to the idea, contained in a power law correlation, that events are all correlated
with each other and also gives rise to important implications for seismic forecasting. The construction of seismic
catalogs, indeed, dates back to about 50 years, and according to Eq.(7) one can have good estimates of seismic hazard
without considering previous seismicity. This is no longer true if one assumes a power law time decorrelation of the
type (6) especially for small values of λ. We want also to point out that a general state-rate formulation [15] gives rise

3

(5)

(6)

(7)

4

0
10

)

L

M

,
t

∆
(
D
L

)

M

(

1
-

C

P

-2

10

-4

10

λ=1.2  ML=1.5
λ=5  ML=1.5
λ=1.2  ML=2.5
λ=5  ML=2.5

1

2

3

5

6

M
4

7

0
10

-2

10

-4

10

P(M)

2
10

3
10

PC(ML)∆t

4
10

5
10

FIG. 2: (Color online) The intertime distribution obtained using Eq. (6), with two diﬀerent values of λ = 1.2, 5 and ML =
1.5, 2.5. Continuous and broken curve are the experimental D(∆t, ML) with ML = 1.5 and ML = 2.5 respectively. For λ = 1.2
−6,
we set k = 210sec, A = 1.410
γ = 0.1. In the inset the magnitude distribution of the experimental catalog (black line) and numerical catalog with λ = 1.2
(red ◦) and λ = 5 (green (cid:3)).

−7, γ = 1. For λ = 5 we set k = 420sec, A = 1.910

−4sec−1, µ = 1.510

−4sec−1, µ = 410

to correlations between earthquakes that decay exponentially in time. We ﬁnally observe, that taking into account
only a fraction of previous events in the evaluation of conditional probabilities, the numerical procedure considerably
speeds up. In the case of long temporal correlation CPU time grows with the number of events as N 2
e , whereas in
the case of an exponential tail the growth is linear in Ne. For this reason, assuming the functional form (7) one can
simulate very large sequences of events. In particular for a diﬀerent choice of parameters, one can construct synthetic
catalogs containing the same number of events (Ne = 245000 with M ≥ 1.5) of the experimental California Catalog.
In ﬁg. 3 we compare numerical and experimental distributions D(∆t, ML) for three diﬀerent values of ML. For each
value of ML, the numerical curve reproduces the experimental data and obviously fulﬁll Eq.(1) (inset (a) in Fig.(3)).
Also the numerical magnitude distribution P (M ) is in very good agreement with the experimental one (inset (b) in
Fig.(3)). Finally, evaluation of quantities Qj and Rj for the synthetic catalog leads, as expected, to the same clustering
behaviour as for experimental data (Fig.1b). After ﬁxing k, we express numerical time unit in seconds and we observe
that numerical catalog corresponds to a period of about 9.9 ∗ 109sec ≃ 30 years. Therefore our model is able to
construct a synthetic catalog covering about 30 years that contains about the same number of events and displays the
same statistical organization in magnitude and time of occurrence as real California Catalog. The high eﬃciency of
the model in reproducing past seismicity indicates that the model is a good tool for earthquake forecasting. In fact,
given a seismic history, Eq.(2) together with Eq.s(4, 7) gives the probability to have an earthquake of magnitude M
at time t inside a considered geographic region. Our approach is diﬀerent from the Reasenberg-Jones method [16],
which is currently used for evaluation of seismic hazard. This method is based on the generalized Omori law that gives
c)−
p, where tM and MM
for the rate of occurrence of magnitude M aftershocks, P (t, M ) =
are the time of occurrence and magnitude of the main-shock. The starting set of parameters (
A) is estimated
b,
b
from previous seismic sequences, and then their value is continuously updated as soon as new data become available.
However, strong ﬂuctuations in the magnitude distribution observed in Fig.1 suggest that the extrapolated
b from
the previous subset may not give the correct value to use for event forecasting. Furthermore, one has an improving
parameters estimation as the sequence evolves, but at the same time hazard is decreasing. Conversely in our model
parameters (A, b/p, γ) are evaluated on the basis of the entire history of 245, 000 events leading to a more precise
estimation. Nevertheless, due to the stochastic nature of the process, one observes ﬂuctuations of
p from one
sequence to the other (Fig.1b). Our model, furthermore, also allows hazard estimation outside the Omori sequence
and therefore long term forecasting.

b(M−MM )(t − tM +
A10
b

b and

p,

c,

b

b

b

b

b

b

b

b

b

We ﬁnally observe that also spatial distributions of seismic events reveal some kinds of scale invariance [17, 18, 19].
These indicate that also spatial distribution originates from a critical behaviour of the Earth crust suggesting that a
dynamical scaling hypothesis as in Eq.(4) can also work if one appropriately introduces spatial dependencies. In this
way it would be possible to construct seismic hazard maps.

Acknowledgements. This work is part of the project of the Regional Center of Competence ”Analysis and Monitoring of
Environmental Risk” supported by the European Community on Provision 3.16. This research was also supported by EU
Network Number MRTN-CT-2003-504712, MIUR-PRIN 2004, MIUR-FIRB 2001.

5

P(M)

(b)

-1

10

-2

10

-3

10

-4

-5

10

10

1

2

3

5

6

7

4
M

0
10

-2

10

)

L

M

,
t

∆
(
D

1
10
-4

10

(a)

-6

10

0

10

PC(ML)∆t
3
10

4
10

2
10

5
10

)

L

M

,
t

∆
(
D
L

)

M

(

1
-

C

P

0

10

-2

10

-4

10

-6

10

2

10

4

10

6

10

PC(ML)∆t (sec)

FIG. 3: (Color online) The intertime distribution as a function of ∆tPc(ML) obtained using Eq.(7) (black circle ◦) and
compared with the experimental distributions (red (cid:3)) for three diﬀerent values of ML (ML = 1.5, 2.5, 3.5, from top to bottom).
We set k = 4.9 ∗ 104sec, A = 6.1 ∗ 10−5sec−1, µ = 2 ∗ 10−5, γ = 0.1. In inset (a) the scaling behaviour as in Eq.(1) and in inset
(b) the experimental (red) and numerical (black) magnitude distribution.

[1] H. Kanamori, D.L. Anderson, Bull. Seize. Soc. Am. 65, 1073 (1975).
[2] B. Gutenberg, C.F. Richter, Bull. Seism. Soc. Am. 34, 185 (1944).
[3] F. Omori, J. Coll. Sci. Imp. Univ. Tokyo 7, 111, (1894).
[4] A. Corral, Phys. Rev. Lett. 92, 108501 (2004).
[5] P. Bak, K. Christensen, L. Danon and Scanlon T., Phys. Rev. Lett. 88, 178501, (2002)
[6] J. F. D. Vere-Jones, J. Roy. Statist. Soc., B32, 1, (1970)
[7] Y. Y. Kagan and L. Knopoﬀ, Science 236, 1563, (1987)
[8] Y. Ogata, J. Amer. Stat. Assoc. 83, 9, (1988)
[9] A. Helmstetter and D. Sornette, Phys. Rev. E 66 061104 1, (2002); A. Helmstetter and D. Sornette, J. Geophys. Res. 107

2237, (2002)

[10] Y. Y. Kagan, Geophys. J. Int. 106, 123, (1991)
[11] A. Helmstetter, Phys. Rev. Lett. 91 058501, (2003)
[12] Southern California Seismographic Network, http: //www.scecdc.scec.org/ftp/catalogs/SCSN/
[13] A condition on λ should be imposed from the observation that, taking a single event at t = t0 and neglecting the Poissonian
−λp. Hence, one is tempted to ﬁx λ ≃ 1 in order to reproduce
term in Eq. (2) one obtains a power law P (t − t0) ∼ (t − t0)
the Omori law. Nevertheless considering µ > 0, also for λ diﬀerent than one, one can recover Omori law with p belonging
to the experimental range. This observation, for instance, can be indirectly extracted from the short time behaviour of
D(∆t, ML) [14].

[14] M.S. Mega et al., Phys. Rev. Lett. 90, 188501 (2003)
[15] J.Dieterich, J. Geophys. Res. 99, 2601 (1994)
[16] P.A. Reasenberg and L.M. Jones, Science 243, 1173 (1989)
[17] T.Hirata and M.Imoto, Geophys. J. Int. 107, 155 (1991)
[18] J. Davidsen and M. Paczuski, Phys. Rev. Lett. 94, 048501 (2005)
[19] C. Godano, and F. Pingue, Geophys. Res. Lett. in press

