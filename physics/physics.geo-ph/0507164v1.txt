5
0
0
2
 
l
u
J
 
1
2
 
 
]
h
p
-
o
e
g
.
s
c
i
s
y
h
p
[
 
 
1
v
4
6
1
7
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A way to synchronize models with seismic
faults for earthquake forecasting: Insights
from a simple stochastic model

´Alvaro Gonz´alez a,1 Miguel V´azquez-Prada b Javier B. G´omez a
Amalio F. Pacheco b
aDepartamento de Ciencias de la Tierra. Universidad de Zaragoza.
C./ Pedro Cerbuna, 12. 50009 Zaragoza, Spain.
bDepartamento de F´isica Te´orica and BIFI. Universidad de Zaragoza.
C./ Pedro Cerbuna, 12. 50009 Zaragoza, Spain.

Abstract

Numerical models of seismic faults are starting to be used for determining the fu-
ture behaviour of seismic faults and fault networks. Their ﬁnal goal would be to
forecast future large earthquakes. In order to use them for this task, it is neces-
sary to synchronize each model with the current status of the actual fault or fault
network it simulates (just as, for example, meteorologists synchronize their models
with the atmosphere by incorporating current atmospheric data in them). However,
lithospheric dynamics is largely unobservable: important parameters cannot (or can
rarely) be measured in Nature. Earthquakes, though, provide indirect but measur-
able clues of the stress and strain status in the lithosphere, which should be helpful
for the accurate synchronization of the models.

The rupture area is one of the measurable parameters of actual earthquakes. Here
we explore how this can be used to at least synchronize fault models between them-
selves and forecast synthetic earthquakes. Our purpose here is to forecast synthetic
earthquakes in a simple but stochastic (random) fault model. By imposing the rup-
ture area of the synthetic earthquakes of this model on other models, the latter
become partially synchronized with the ﬁrst one. We use these partially synchro-
nized models to successfully forecast most of the largest earthquakes generated by
the ﬁrst model. This forecasting strategy outperforms others that only take into
account the earthquake series. Our results suggest that probably a good way to
synchronize more detailed models with real faults is to force them to reproduce the
sequence of previous earthquake ruptures on the faults. This hypothesis could be
tested in the future with more detailed models and actual seismic data.

Key words: Characteristic earthquakes, earthquake prediction, fault model,
seismic modelling, seismic quiescence, synthetic-earthquake catalogues.

Preprint submitted to Elsevier Science

20 February 2014

1 Introduction: Data assimilation in dynamical fault models

Numerical models are now frequently used to simulate the seismic behaviour of
real faults (e.g. Kato and Seno, 2003; Fitzenz and Miller, 2004; Kuroki et al.,
2004) and fault networks (e.g. Ward, 2000; Hashimoto, 2001; Robinson and Benites,
2001; Rundle et al., 2001; Soloviev and Ismail-Zadeh, 2003; Robinson, 2004;
Rundle et al., 2004). In these models, fault planes separate lithospheric blocks
that are strained at speciﬁc rates, and sudden slips (earthquakes) are gener-
ated by the faults according to certain friction and/or rupture laws. Although
no completely realistic dynamical model presently exists, these simulations
are now suﬃciently credible to begin to play a substantial role in scientiﬁc
studies of earthquake probability and hazard (Ward, 2000). The ﬁnal goals of
the numerical modelling of seismicity are not diﬀerent from, for example, the
goals of numerical models of the atmosphere. A good model should be able to

(1) reproduce the general characteristics of the system,
(2) mimic the state of the system at the present moment, and
(3) forecast the future evolution of the system.

Most numerical models of seismicity have been designed to achieve the ﬁrst
goal, by reproducing general characteristics of earthquakes such as their size-
frequency distribution (e.g. Bak and Tang, 1989; Olami et al., 1992; Dahmen et al.,
1998; Preston et al., 2000; V´azquez-Prada et al., 2002), or the generation of
aftershock and foreshocks (e.g. Hainzl et al., 1999). When a model is designed
this way, it is left to evolve freely according to its rules, and all that is checked
is whether the overall results of the model are similar to the observations made
in Nature or not.

When dealing with the second goal, new issues arise. It requires data assimila-
tion, that is, the process of absorbing and incorporating observed information
into the model. By this process, the model is tuned and synchronized, at least
partially, with the real system it tries to simulate. In a meteorological model,
data of atmospheric pressure, temperature, humidity, cloud cover, precipita-
tion, etc. measured in a given moment at diﬀerent locations and heights can
be included. With this procedure, the model becomes a reasonably good repre-
sentation of the atmosphere at that moment. Then it can be used to calculate
the probable future atmospheric evolution (i.e. the third goal cited above).

Seismic data assimilation poses greater problems than its meteorological equiv-
alent. This explains (at least partially) the relative delay in developing reli-
able forecasts of large earthquakes. The inner workings of both the atmo-
sphere (Houghton, 2002) and the lithosphere (Goltz, 1997; Turcotte, 1997;

1 Corresponding author.
E-mail: Alvaro.Gonzalez@unizar.es

2

Keilis-Borok, 2002) are complex and chaotic, so they are inherently diﬃcult to
forecast. However, while Meteorologists can probe the atmosphere every day at
diﬀerent places and heights (and assimilate the obtained data in their models
in near real-time), lithospheric variables of paramount importance, such as the
stress and strain, can be measured only in certain places, and not at any time:
earthquakes have unobservable dynamics (Rundle et al., 2003). For example,
the best current compendium of stress magnitudes and directions in the litho-
sphere is the World Stress Map (Zoback, 1992; Reinecker et al., 2004), whose
entries are point static time-averaged estimates of maximum and minimum
principal stresses in space. And the direct measurements of stress on active
fault zones at depth are still scarce (e.g. Ikeda et al., 2001; Tsukahara et al.,
2001; Yamamoto and Yabe, 2001; Hickman and Zoback, 2004; Boness and Zoback,
2004). The dynamical models would need better spatial and temporal infor-
mation of stress, both more abundant and more systematically collected than
that currently available (Rundle et al., 2004). It is thus necessary to seek ways
to tune and synchronize the models with more abundant observable data.

A ﬁrst step of data assimilation in models of earthquake faults is to intro-
duce information regarding the topology (that is, the shape and location) of
the active faults and their long-term behaviour. For example, the long-term
fault slip rate, and the average recurrence interval of the largest earthquakes
in the fault can be estimated from paleoseismological studies and should be
included in the models (Grant and Gould, 2004). Examples of this approach
are the works of Rundle et al. (2001, 2004) and Robinson (2004). The surface
deformation measured via Global Positioning System (GPS) networks and by
Synthetic Aperture Radar Interferometry (InSAR) can also constitute input
data for the dynamical fault models (Rundle et al., 2004). Earthquakes them-
selves are indeed the most obvious observable events of lithospheric dynamics,
and could provide the most detailed data available to assimilate in the models,
but how? The earthquake rupture area could be an important clue.

The rupture area and slip distribution in real earthquakes can be very complex
(Sieh, 1996; Kanamori and Brodsky, 2004), but can be estimated in a variety
of ways. The actual slip distribution can be obtained by inverting the ob-
served seismic waveforms (Kanamori and Brodsky, 2004) and/or by geodetic
modelling of surface displacement (Yabuki and Matsuura, 1992). Some earth-
quakes produce surface ruptures, which are useful for estimating the rupture
area (Stirling et al., 2002). Although most surface ruptures occur in large
shocks, with magnitudes larger than 6, they have been reported for earth-
quakes with magnitudes ML down to 2.5 (see the extensive compilation of
historic earthquakes with surface rupture by Yeats et al., 1997, pp. 473-485).
Also, the rupture area can be estimated from the seismic moment, (which is
calculated from seismic, geodetic or geological data; Kanamori and Brodsky,
2004) or from the moment magnitude (Wells and Coppersmith, 1994; Stirling et al.,
2002; Dowrick and Rhoades, 2004). Frequently the location of early after-

3

shocks is used to determine the rupture area of the mainshock (Wells and Coppersmith,
1994), although the aftershock zone tends to grow with time (Kisslinger, 1996)
and is not necessarily a good indicator of that area (Yagi et al., 1999).

Complex models with realistic fault topology are able to reproduce the rup-
ture area and coseismic slip of historical earthquakes. It is thus possible to
force the model to reproduce the rupture of a historical earthquake, and let it
evolve from that moment onwards to see what could happen in the future. For
example, Ward (2000) developed a model including the network of main faults
in the San Francisco Bay Area (California). He forced the model to reproduce
the San Andreas Fault surface coseismic slip of the 1906 San Francisco earth-
quake, and let it evolve freely from that earthquake onwards, in an attempt to
simulate the probable sequence of earthquake ruptures during the next 3000
years.

But considering only the data of the largest earthquake in the series is probably
not suﬃcient to properly synchronize the model. Complex and chaotic systems
are very sensitive to the initial conditions. The information regarding only
one event probably does not suﬃciently constrain the initial conditions, and
the calculated evolution will probably be a particular case of a large range
of possible outcomes. Will this panorama improve by forcing the model to
reproduce all the observed earthquake ruptures, including the small ones?
Probably yes. To check whether this idea works, at least with a simple model,
is the purpose of this paper.

In the following sections, our goal will be to forecast the largest earthquakes
generated by the minimalist model, a simple numerical fault model. We will
show that when all the earthquake ruptures generated by this model are im-
posed on other, similar models, these become partially synchronized with the
former. We use them to declare alarms that eﬃciently mark the occurrence of
the largest shocks in the ﬁrst model. The results are much better than those
obtained with other strategies that consider only the earthquake series. The
model, albeit simplistic, is stochastic (it involves randomness), so its eﬃcient
forecasting is not trivial. We will describe how this stochasticity can be dealt
with, by using an approach similar to the so-called ensemble forecasting used
in Meteorology (Palmer et al., 2005). The method could be used in other more
detailed and realistic models (stochastic or not) to test our general conclusion:
that they might be partially synchronized with actual faults by being forced
to reproduce the series of observed earthquake ruptures.

In the next section we describe the model and its properties. Then, we outline
the general scheme of prediction and the forecasting strategies used as refer-
ence to assess the merits of any other predictive method in the model. Finally,
the method based on partial synchronization is explained and its possible
utility discussed.

4

2 The minimalist model

In this section we will describe the minimalist model, the numerical model
whose largest synthetic earthquakes we will try to forecast. We introduced
this model in a previous paper (V´azquez-Prada et al., 2002). The minimalist
model has mainly two, apparently contradictory, advantages for the purpose
of this paper: it is simple but, at the same time, it is diﬃcult to forecast.
Because it is simple, several of its properties can be derived analytically, and
it can be characterized in detail with numerical simulations which do not
require an impractical amount of computer time. Because it is stochastic, it
is diﬃcult to forecast, so the results we will obtain here are not trivial. In the
following paragraphs we will explain how the model works, and what are its
main properties, comparing them with those of actual faults.

2.1 How the model works

The model is a simple (hence its name) cellular automaton. Cellular automata
are frequently used to model seismic faults. In these models, the fault plane
is divided into a grid of cells, and the time evolves in discrete time steps.
Each cell’s state is updated at each time step according to rules that usually
depend on the state of the cell or that of its neighbors in the previous time
step. These rules can be designed according to certain friction laws (Ben-Zion,
2001), stress transfer (Olami et al., 1992; Hainzl et al., 1999; Preston et al.,
2000), and the eﬀect of ﬂuids (Miller et al., 1999). In the minimalist model,
as well as in other very simple cellular automata (e.g. Newman and Turcotte,
2002; Gonz´alez et al., 2005), these details are ignored: the model is driven
stochastically, there are only two possible states for each cell, and the earth-
quakes are generated according to simpliﬁed breaking rules.

Let us now explain the simpliﬁed view of earthquake generation that the model
tries to sketch. In actual faults, the regional stress strains the rock blocks of
the fault, making portions (patches) of the fault plane to become metastable.
That is, they are static, but store enough elastic energy to propagate an earth-
quake rupture once triggered. Diﬀerent processes (for example, aseismic creep
and plastic deformation) dissipate stress along the fault plane, so stress is
not directly converted into elastic strain. Earthquakes rupture some of the
metastable patches of the fault, that then become stable, thus relieving strain.
The hypocentre of an earthquake is usually located in a particularly strong
patch of the fault plane, called “asperity” (Kanamori and Stewart, 1978; Aki,
1984; Das, 2003; Lei et al., 2003). Asperities appear to be persistent features
where earthquake ruptures start once and again (Aki, 1984; Okada et al.,
2003). Once the rupture starts, it propagates along the fault plane until it

5

arrives at a patch of the fault that is not suﬃciently strained. Then the rup-
ture cannot propagate further, and is arrested. The relatively stable patch that
is not suﬃciently strained and that arrests the rupture is called the “barrier”
(Das and Aki, 1977; Aki, 1984; Das, 2003).

The model sketches these features as follows. It divides the plane of a fault into
an array of equal cells, as depicted in Fig. 1. In previous papers (V´azquez-Prada et al.,
2002, 2003; L´opez-Ruiz et al., 2004; G´omez and Pacheco, 2004; Gonz´alez et al.,
2004), this array was drawn vertically, in order to simplify its mathematical
description. Here the model will be drawn horizontally, in order to sketch the
fault plane in a way more similar to that of actual faults (which are usually
longer along the strike than along the dip). Some other cellular automaton
models discretize the fault plane in a similar way (e.g. Rundle et al., 2004).
There is a total of N cells, each denoted by an index i. The parameter N is the
only one that can be changed in the model. The cells can only be in one of two
states: “empty” (stable) or “occupied” (metastable). The state of the model
at each time step can be described simply by stating which cells are occupied
and which are not. The increase of regional stress, as in other simple models
(Bak and Tang, 1989; Newman and Turcotte, 2002; Castellaro and Mulargia,
2001; Gonz´alez et al., 2005), is represented by the random addition of “stress
particles”. This randomness is a way of dealing with the complex stress in-
crease in actual faults. At each time step, one cell is selected randomly, and
a new particle arrives on it. That is, each cell has the same probability, 1/N
of receiving the new stress particle. If the chosen cell is empty, the particle
“occupies” it. This means that the regional stress has produced enough strain
on that cell to make it metastable. If the cell is already occupied, that stress
particle is lost; this is analogous to stress dissipation on the fault plane. The
total number of occupied cells represents the total elastic strain on the fault.

In the model, we assume that the asperity is the ﬁrst cell, i = 1, placed at
one end of the array. This option is chosen because it simpliﬁes the analytical
description of the model. The stable cells act as barriers to earthquake rupture.
When a stress particle ﬁlls cell i = 1, a rupture starts, and propagates through
all the consecutive metastable cells until it is arrested by a stable cell. That is,
if all the successive cells i = 1 to i = k are occupied, and cell k + 1 is empty,
then the eﬀect of the earthquake is to empty all the cells from i = 1 to i = k.
The other cells, i > k remain unaltered. The cell k + 1 is a barrier: it is empty
(stable), so the rupture cannot propagate through it. The size (rupture area)
of the earthquake is k, the number of cells broken in the synthetic earthquake.
Thus, the earthquake size in the model is discrete, 1 ≤ k ≤ N. Earthquakes, in
practice, are instantaneous in the model (they do not last for any time step).
This represents the fact that earthquake ruptures are, indeed, much faster
than the slow stress loading represented by the addition of particles.

The random addition of particles is what makes the model stochastic. It also

6

Fig. 1. The minimalist model as a sketch of a seismic fault. The fault plane is divided
into an array of N equal cells, denoted with an index i, 1 ≤ i ≤ N . The increase
of regional stress is represented by the random addition of “stress particles” to the
cells. Earthquake ruptures start at an asperity, the cell i = 1, when a stress particle
arrives to it. The rupture propagates through all the consecutive metastable cells
(occupied by particles). The rupture area is k, the number of cells broken. The
ﬁgure depicts an earthquake with k = 3.

determines the rate at which earthquakes occur in the model. At each time
step, independently of the previous earthquake history, there is a probability
1/N for the incoming stress particle to arrive at cell i = 1 and start an
earthquake. Thus an earthquake, on average, occurs every N steps. The time
between any two consecutive earthquakes is purely random (Poissonian, with
rate 1/N).

The cellular-automaton approach of this model is similar to that of the “for-
est ﬁre” models, in which clusters of interconnected occupied cells (“trees”)
“burn” and are reset to empty when they are randomly struck by “lightning”
(Drossel and Schwabl, 1992; Henley, 1993). The utility of this kind of models
for earthquake physics has been noted by Rundle et al. (2003). In the min-
imalist model there is no random “lightning”: the clusters of interconnected
metastable sites are only emptied if they are connected to the cell i = 1 and
if this fails.

2.2 Main properties of the model

In this section, we will brieﬂy review some properties of actual seismic faults
that the minimalist model, despite its simplicity, is able to reproduce. The min-
imalist model, of course, lacks the detailed description of the seismic process
that a fully dynamical model can display. For example, it does not include the
eﬀects of fault friction, elastic stress transfer, or the role of ﬂuids that more
complex models can take into account. This detailed description, as noted
before, was sacriﬁced in order to simplify the model analysis.

7

Fig. 2. The size-frequency distribution of earthquakes in the minimalist model. The
earthquake size (rupture area) is k, the number of cells broken by the earthquake.
The magnitude would be proportional to the logarithm of k. The curves for any N
overlap, except for the characteristic earthquakes (with k = N ). The distributions
shown are for N = 10, 100 and 1000.

In the previous subsection we already noted some similarities between the
model and actual faults that were looked for when designing the model. Apart
from these, the minimalist model spontaneously displays some other charac-
teristics that can be compared with those of actual faults: the earthquake
size-frequency distribution, the pattern of strain loading on the fault, the seis-
mic quiescence, the duration of the earthquake cycle, and the stress shadow.

2.2.1 Earthquake size-frequency distribution

The size-frequency distribution of earthquakes in the minimalist model (Fig. 2)
is an example of the so-called characteristic earthquake distribution (Wesnousky et al.,
1983; Schwartz and Coppersmith, 1984; Youngs and Coppersmith, 1985; Wesnousky,
1994). In this distribution, the small and medium-size shocks follow a power
law, while the maximum-size events (k = N in the model), have a distinctly
higher frequency than the extrapolation of this power law would indicate. This
kind of distribution is shown by earthquakes in at least some seismic faults
(Stirling et al., 1996). For a discussion of this distribution and the insight
gained with the minimalist and other models, see Appendix A.

The most widely used scale of earthquake magnitudes is the moment magni-
tude, which is proportional to the logarithm of the rupture area (Kanamori and Anderson,
1975). For this reason, we use a logarithmic scale for k in Fig. 2. In this ﬁgure it
can also be seen that the probability of the characteristic earthquake depends
on N, while the probability of smaller earthquakes (k < N) overlap for models
with diﬀerent N (V´azquez-Prada et al., 2002). For a detailed description of
the tendency of the size-frequency relationship of events when the system size
grows to inﬁnity, see L´opez-Ruiz et al. (2004).

8

Fig. 3. The number of occupied cells in a minimalist model with N = 20, for ten
seismic cycles. This number is analogous to the total elastic strain accumulated in
the fault. Sudden drops correspond to earthquakes. Each seismic cycle ends with
an earthquake of size N .

2.2.2 Pattern of strain loading

On actual faults, the strain does not accumulate uniformly along the seismic
cycle. Instead, the strain loading rate is faster just after a large earthquake,
and decreases over time (Michael, 2005). In the minimalist model, a similar
eﬀect is observed (Fig. 3). The total elastic strain in the model is represented
by the occupation, that is the total number of occupied cells. Just after a
large earthquake, this number increases rapidly, and then more slowly. The
cause is that when more cells are occupied, it is less probable for the incoming
stress particles to land on empty cells. This pattern can be complicated by
intermediate, non-characteristic earthquakes. Just before the next characteris-
tic earthquake, the occupation reaches a steady state (“plateau”), which gives
rise to the next property of the model.

2.2.3 Seismic quiescence

On actual faults, a period of reduced seismic activity, called seismic quiescence,
is observed during months or years before many mainshocks (Wyss and Habermann,
1988; Scholz, 2002). As mentioned above, the number of occupied cells in the
minimalist model reaches a plateau just before each characteristic earthquake
(Fig. 3). Once this plateau starts (when N − 1 cells, from i = 2 to i = N,
are occupied), only the characteristic earthquake can be produced, and, on
average, N time steps have to elapse until a stress particle hit the asperity
cell (i = 1) and generates the earthquake. Thus, the average duration of the
plateau with seismic quiescence is N time steps.

9

Fig. 4. The discrete distribution function of the duration (in time steps, n) of the
seismic cycle in a minimalist model with size N = 20. Note that cycles shorter than
N time steps cannot occur.

2.2.4 Duration of the earthquake cycle

The earthquake cycle of a fault is the time between two consecutive large
earthquakes that rupture the whole fault or most of it (e.g. Scholz and Gupta,
2000). These quakes that break most of or all the fault are called charac-
teristic earthquakes (Schwartz et al., 1981; Coppersmith and Schwartz, 1983;
Wesnousky et al., 1983; Schwartz and Coppersmith, 1984). In the model, the
characteristic earthquakes are those that rupture the N cells. These are the
ones we will try to forecast later on. The seismic cycle in actual faults is not
periodic. The times between large earthquakes follow a certain statistical dis-
tribution which is still not well known. There are several distributions able to
describe the recurrence of large earthquakes (e.g. gamma, lognormal, Weibull,
Brownian passage time; Michael, 2005), and the distribution of the seismic
cycles in the minimalist model is one of them.

In the model, the number of time steps (particle throws) elapsed since the
last characteristic earthquake is called n. The duration of the seismic cycles is
statistically distributed according to a discrete probability distribution, that
depends on N and is denoted PN (n). This distribution is well known. It can
be analytically derived for models with small N (G´omez and Pacheco, 2004).
For any N, it can be measured in detail by simulating numerically the evo-
lution of the model during some millions of seismic cycles. This distribution
is useful for describing the recurrence of large earthquakes on actual faults
(G´omez and Pacheco, 2004). It is drawn for N = 20 in Fig. 4. Note that the
consecutive earthquakes of any size in the model take place according to a
purely random, Poisson distribution, but that the time distribution of earth-
quakes of a speciﬁc size is not Poissonian, as this depends on the size and
time of occurrence of the previous events. As a speciﬁc case, the distribu-
tion of characteristic earthquakes, Pn(N) is not Poissonian. This is discussed
further in the next subsection.

10

2.2.5 Stress shadow

When a fault generates a large earthquake, the elastic strain is reduced, and
a minimum time has to elapse until the fault, by slow tectonic deformation,
accumulates enough strain to generate another large earthquake. This eﬀect is
called stress shadow (Harris, 2000). In the minimalist model there is a stress
shadow: if an event of size k takes place, at least k time steps have to elapse
before another event of that size can occur. As a speciﬁc case, if a characteristic
earthquake takes place, at least N time steps have to elapse before the next
characteristic earthquake.

3 General scheme of forecasting

In this section we will explain the general framework for the forecasting of the
largest earthquakes in the model. As a ﬁrst remark, we have to consider that
the model is stochastic, so it is not predictable with absolute precision. Only
simple deterministic systems are fully predictable. The evolution of complex
systems, such as the atmosphere or the lithosphere (even if it were determinis-
tic) is very sensitive to the initial conditions. As these complex systems cannot
be fully characterized, they turn out not to be fully predictable either.

Earthquake prediction (Keilis-Borok, 2002; Keilis-Borok and Soloviev, 2003;
Rundle et al., 2003), as well as some atmospheric predictions (Mason, 2003),
is frequently regarded as a binary forecast: one has to decide whether a large
earthquake is going to occur or not, in a certain time-space window, instead
of calculating the exact probability of this event. In this binary-forecasting
approach, an “alarm” is declared when a large earthquake is expected. If it
takes place when the alarm is on, the outcome is a successful forecast. If it
takes place when the alarm is oﬀ, there has been a prediction failure. If the
alarm was declared during a certain period, but the expected earthquake did
not happen, that constitutes a false alarm.

Note that for using this approach it is necessary to deﬁne precisely what the
target earthquakes are that we wish to forecast. Usually they are deﬁned as
those with a magnitude larger than a given threshold, both when dealing with
actual earthquakes (Keilis-Borok and Soloviev, 2003; Rundle et al., 2003) or
with synthetic ones (e.g. Pepke and Carlson, 1994; Hainzl et al., 2000). In the
minimalist model, it is natural to choose as target events the characteristic
earthquakes (size k = N), as they mark a distinct peak in the size-frequency
diagram, being much more frequent than other large earthquakes.

A way to quantify the forecasting ability of a certain strategy is to compute
the fraction of errors, fe, and the fraction of alarm time, fa (Molchan, 1997).

11

Given a certain time series of the model, fe is the ratio of the total number
of prediction failures to the total number of target events. And fa is the ratio
of the total time during which the alarm was on to the total duration of the
time series. The fraction of false alarms, ff , is included in fa, and is the ratio
of the total duration of false alarms to the total duration of the time series.

Of course, a good forecasting strategy should render small fa, fe and ff .
However, as a general rule, a strategy that renders low fe tends to produce
large fa and ff . Dealing with real seismicity, both a failure and an alarm are
costly. Eventually, decision-makers would need to consider what is less costly:
to predict most of the dangerous earthquakes, but declaring many alarms, or
to declare fewer alarms but failing the forecast of more large shocks (Molchan,
1997). Depending on the trade-oﬀ between costs and beneﬁts, one should try
to minimize a loss function, L, that can depend on fa, fe and/or ff .

In the next section, we will describe the forecasting strategies that we will use
to compare the merits of the new strategy proposed in this paper, based on
synchronizing models between themselves. In the ﬁrst of the subsections we
will indicate the loss function we will try to minimize in the forecasting of the
model.

4 Forecasting strategies for comparison

We describe three forecasting strategies, based on the earthquake series, that
we will use to asses the merits of the new strategy described later in this
paper. The ﬁrst two strategies (the random guessing strategy and the so-
called reference strategy) can be used in any system. The third is speciﬁc to
the minimalist model, and serves to ideally determine its maximum theoretical
predictability.

4.1 Random guessing strategy

In this strategy, the alarm is randomly turned on and oﬀ, during a certain
fraction of alarm time, fa. It is simple to apply this strategy to any cellular
automaton model. Here, in each time step, the alarm is on with a probability
p. As a result, the alarm will be on during a fraction p of time steps (fa = p).
When the target earthquake ﬁnally occurs in a certain time step, there will be
a probability p for the alarm to be on. Thus, on average, a fraction p of target
earthquakes will be predicted, and a fraction fe = 1 − p will be prediction
failures, so fa + fe = 1. This strategy has two trivial cases: if the alarm is
always on (fa = 1), all the target earthquakes are “forecasted” (fe = 0).

12

Conversely, if the alarm is always oﬀ (fa = 0), we fail to predict any of them.

To be statistically signiﬁcant, any forecasting strategy must render better
results than a random guess. A natural way to measure this improvement is
to consider the loss function L = fa + fe. Then, L = 1 means that the strategy
performs as a random guess, and L = 0 means a perfect prediction. If L > 1,
the strategy is performing exactly the opposite to how it should. Thus, the
exact reverse strategy should be considered, and this will provide the opposite
results (f ′

a = 1 − fa, and f ′

e = 1 − fe).

4.2 Reference strategy

Of course, the random guessing strategy depicted above is only useful as a
baseline, but does not serve to provide a real signiﬁcant forecast. In this subsec-
tion we describe the simplest meaningful forecasting strategy one can consider
for any system. This will be called the reference strategy, and any forecasting
procedure more complex than this should render better results.

The reference strategy consists simply in declaring an alarm some time after
each target event, and maintaining it on until the next target event (Newman and Turcotte,
2002; V´azquez-Prada et al., 2003; Gonz´alez et al., 2005). As a general rule,
the shorter this time, the bigger fa and the lesser fe. Which time is best,
then? For the minimalist model, we can look for the number of time steps
n to use with this strategy for obtaining a lesser L. In a previous paper
(V´azquez-Prada et al., 2003) we observed that eﬀectively, for each N, there
is a n that minimizes L. In Fig. 5, the minimum L that can be obtained
with this strategy is plotted for N between 2 and 20, in the curve labeled
“Reference”. This method does not generate any false alarm, nor take into
account the occurrence of earthquakes smaller than the characteristic ones.
The only information required is PN (n), the probability distribution func-
tion of the duration of the cycles (V´azquez-Prada et al., 2003). Taking into
account smaller earthquakes, the forecast can be modestly improved in the
model (V´azquez-Prada et al., 2003).

4.3 Ideal strategy

As the minimalist model is very simple, it is possible to explore its maximum
predictability. The ideal strategy needed for getting this result, unlike the two
previously described, is model-speciﬁc. It is deduced in Appendix B. This ideal
result could only be obtained if we could “see” inside the model to check at
each time step which cells are occupied and which are not. Thus it requires
a perfect knowledge of the system, and equivalent strategies cannot be used

13

Fig. 5. Loss function (L) obtained with the diﬀerent forecasting methods used in
this paper, for various system sizes (2 ≤ N ≤ 20). A random guessing strategy
would render L = 1 for any N , while L = 0 would mean a perfect prediction. The
shadowed zone is unattainable for any forecasting strategy used in the minimalist
model, and the strategy that marks its upper limit is called “Ideal”. The “Reference”
strategy is based only on the series of the largest earthquakes in the model. The
three strategies labelled “Clones” are based on the synchronization of models with
the minimalist model whose largest earthquakes we try to forecast.

with actual faults where we cannot know the detailed state of stress and
strain. In Appendix B it is deduced that the alarm should be declared at the
instant in which N − 1 cells of the model are full (just at the beginning of
the plateau commented on in Section 2.2.3). Then, it should be maintained on
until the next characteristic earthquake. This is a no-error strategy (fe = 0,
and L = fa). As the model is stochastic, fa is not zero; a minimum alarm
time is needed to forecast all the characteristic earthquakes. It is given by
fa = L = N/hni, where hni is the average duration of the cycles (which
depends on N). This L is also plotted in Fig. 5, in the curve labelled “Ideal”.
This is the rigorous minimum L that can be obtained in the model. A good
forecasting strategy should produce a L lesser than the “Reference” curve and
as close as possible to the “Ideal” curve.

5 Synchronization-based forecasting

In this section we will describe the novel forecasting method based on the
synchronization between models, obtained by imposing the rupture area of a
minimalist model onto other similar models. This section expands and com-
plements our previous results (Gonz´alez et al., 2004).

14

We will try to forecast the characteristic earthquakes generated by a mini-
malist model with N cells. This model will be called master. We will consider
this master as if it were an actual fault, from which we can know the rupture
area of its earthquakes (equivalent to the number of cells broken, k), but not
the strain or stress at depth (equivalent to the occupation state of the model
cells). As in an actual fault, we cannot change the state of the master at any
moment.

In this forecasting approach we will use other models, which we call clones
(Gonz´alez et al., 2004). These are equivalent to the models that a scientist
devises for forecasting the future evolution of the fault. We will modify their
evolution at will, and their governing rules will be diﬀerent than those of the
master. In this paper, for simplicity, we will consider that the clones are also
arrays of N cells. The average duration of the earthquake cycle in the model
(average recurrence interval of the characteristic earthquakes), hni, strongly
depends on N (G´omez and Pacheco, 2004). Choosing a diﬀerent N for the
clones will imply a diﬀerent loading rate of the cells and a diﬀerent average
recurrence interval of the characteristic earthquakes in the clones than in the
master. These eﬀects would require further tuning of the clones, which would
complicate the following discussion.

Let us describe in the following paragraphs the general outline of the proce-
dure. We will use a total of Q clones, that will be loaded (one particle per
time step and per clone) at the same time as the master, but randomly and
independently to the master and to each other. We will apply some procedures
for partially synchronizing the clones with the master. If in a given time step
the master does not generate any earthquake, we will oblige the clones not to
generate any earthquake either. If the master does generate an earthquake,
we will force the clones to reproduce the rupture area of this earthquake, as
described below in more detail. Note that, although the master and the clones
are driven simultaneously, the eﬀects of the master are dealt with ﬁrst.

Why use several clones? The master and the clones are all stochastic, so each
one evolves with time in a diﬀerent way. By using several clones, we can take
into account a broad range of possible evolutions. By using only one clone,
we could not be very sure that it is satisfactorily mimicking the evolution of
the master. However, if several of these Q clones are in the same state, then
it is more probable that the master is also in that state. If the clones were
deterministic, only one would be required.

We have commented before (Section 4.3 and Appendix B) that the ideal fore-
casting strategy for the minimalist model will be to declare the alarm just
when N − 1 cells of the model become occupied. Then the master enters the
stage of seismic quiescence, or plateau, and the next earthquake is the char-
acteristic one. We will try to determine this ideal instant as well as possible

15

with the clones. For this, we will use a “democratic” procedure: we will declare
an alarm when a minimum of q clones “vote” (become occupied to a certain
threshold, described below). Later on we will explore the combinations of Q
and q that render the best results. Once the alarm is declared, it is maintained
on until the next earthquake in the master. If it is a characteristic one, this is a
successful prediction. Its rupture is imposed on the clones (so we reset all the
cells of the clones to empty) and a new cycle starts. If the next earthquake is
not a characteristic one, this represents a false alarm. We will disconnect the
alarm, and impose the rupture on the clones as is done with any other earth-
quake. Of course, if a characteristic earthquake takes place when the clones
have still not declared the alarm (when less than q clones have voted), this is
a prediction failure. If the clones declare an alarm in the same time step in
which the master generates a characteristic earthquake, we also consider this
as a prediction failure.

We will follow three approaches, each implying a lesser knowledge of how the
master model works. They are depicted in Fig. 6 and described as follows:

(1) This ﬁrst approach will indicate which is the best result that can be ob-
tained with this synchronization-based forecasting. For this reason, the
clones are indeed minimalist models identical to the master (Gonz´alez et al.,
2004). We assume as known that, just after an earthquake with rupture
area k, the ﬁrst k + 1 cells in the master, for sure, are stable (the k just
broken plus the one that acts as a barrier for the rupture). Thus, if the
master generates an earthquake of size k, we will reset to empty the ﬁrst
k + 1 cells of the clones. We also consider as known that the cell i = 1 is
the asperity that triggers the ruptures. So if the master does not generate
any earthquake, the particles in the clones will be randomly thrown to
the cells i ≥ 2, thus precluding any earthquake in the clones. A clone
votes when N − 1 of its cells are full.

(2) In this second approach, we are more ignorant about how the master
works. We do not know where the asperity nor the barrier that stops the
rupture are placed; we only know which cells have ruptured. If the master
generates an earthquake of size k, we will reset to empty only the ﬁrst k
cells of the clones. If it does not generate an earthquake, we will throw
the stress particles to any of the cells in the clones. A clone votes when
its N cells are full.

(3) In the third approach, we only know the size of the earthquake, and
thus its rupture area k, but not exactly which cells of the master have
ruptured in the earthquake. If there is an earthquake in the master, we
will randomly empty k occupied cells of each clone. If the clone has less
than k occupied cells, all are emptied. If the master does not generate
an earthquake, we will throw the stress particles to any of the cells in
the clones. A clone votes when its N cells are full. In this approach
the position of the cells in the clone are irrelevant. Each clone is thus

16

Fig. 6. Sketch that shows how the rupture area of an earthquake in the master
model (M) is imposed on the clones (C), for each of the three synchronization-based
approaches. In this example, the master generates an earthquake with rupture area
k = 3. In the ﬁrst approach (C1), the ﬁrst k + 1 cells rupture and will be reset to
empty. In the second one (C2), this occurs only with the ﬁrst k cells. In the third
approach (C3), this happens to k occupied cells chosen randomly. The ﬁrst cell of
the clones can be occupied only in the second and third approaches.

equivalent to the so-called box model (Gonz´alez et al., 2005).

Note that, ideally, the clones should have the same number of occupied cells as
the master. For this reason, as a way to measure the degree of synchronization
between a clone and the master, we used (Gonz´alez et al., 2004) the fraction
of time, τ , during which both of them have the same number of occupied cells.
If two independent masters run simultaneously, they have the same number
of occupied cells, just by chance, during a certain τ . When a clone and a
master are compared, this τ greatly increases, as shown in Fig. 7: partial
synchronization is achieved. The best results, as expected, are achieved with
the ﬁrst of the three approaches.

The results of fa, fe, ff and L = fa + fe, for diﬀerent values of Q and q can
be plotted as in the diagrams of Fig. 8. In this ﬁgure we have plotted only
results corresponding to the ﬁrst of the three approaches and N = 20, but
similar ﬁgures, with the same overall properties, can be drawn for the other
two approaches and for any N. There are simple trends in these graphs. In
Section 3 we noted that, in general, a forecasting strategy that produces lower
fe tends to produce higher fa and ff . If Q is ﬁxed (same row), the greater the
q, the later the alarm is declared, so fa and ff are lesser and fe is greater. If
q is ﬁxed (same column), the greater the Q, the earlier the alarm is declared,
resulting in the opposite trend.

We are interested in ﬁnding the combinations of Q and q that minimize L.

17

Fig. 7. (a) The fraction of time, τ , during which two models have the same number
of occupied cells. This depends on whether they are two independent masters (τ0)
or a master and a clone (governed by one of the three diﬀerent synchronization
approaches: τ1, τ2 and τ3). (b) The relative improvement, deﬁned as τn/τ0.

The interesting fact is that the sum fa + fe shows a rectilinear “valley” for
certain combinations of Q and q, marked with squares in the graph of Fig. 8.
This valley goes down as Q and q increase. In Fig. 9 it can be observed that
the valley goes down indeﬁnitely, tending to a lowest asymptotic value of L.
We estimate this value, as a function of Q, with a three-parameter exponential
ﬁt of the form F = a exp[b/(Q + c)], where a, b, and c are parameters. The
value of a is the asymptotic one for Q → ∞. This value is represented, for
each N, in Fig. 5. The fa, ff and fe also have asymptotic trends along this
valley of L, also plotted in Fig 9. They can also be ﬁtted with the same kind of
three-parameter distribution, to estimate their asymptotic values as Q → ∞.
A nice property is that, as shown in Fig. 9 for a certain case, these forecasting
approaches predict most of the characteristic earthquakes (fe is low), and have
a very small fraction of false alarms.

As can be noted in Fig. 5, the minimum L obtained for the three diﬀerent
approaches is almost the same, so the optimizing procedure based on choosing
Q and q counteracts the diﬀerent performance of single clones, depicted in
Fig. 7. The second and third approaches give only slightly greater L than the
ﬁrst one. The diﬀerences are large only for small Ns. Another diﬀerence, not
shown in the ﬁgures, is that L decays to its asymptotic value more slowly in
the second and third approaches than in the ﬁrst one. That is, they need more
clones than in the ﬁrst approach to achieve a given low L. This is because
the ﬁrst approach synchronizes more eﬃciently each individual clone with
the master (Fig. 7). In any case, around thirty to forty clones already give a
result very close to the asymptotic one. Note how the strategy performs much
better than a random guess, and also much better than the reference strategy
described in Section 4.2. Its results are intermediate between the ideal forecast
and the reference one.

Another way to measure the synchronization of the clones with the master is
drawn in Fig. 10. The ideal strategy (Section 4.3 and Appendix B), would be

18

Fig. 8. Fraction of alarm time (fa), fraction of false alarm time (ff ), fraction of
errors (fe), and loss function (L) obtained with the the ﬁrst synchronization-based
forecasting approach, for N = 20 and diﬀerent numbers of clones (Q) and votes (q).
The squared cells mark a rectilinear valley in the values of L.

Fig. 9. Loss function (L), fraction of alarm time (fa), fraction of false alarm time (ff )
and fraction of errors (fe) obtained with the ﬁrst synchronization-based forecasting
approach, for N = 20 and diﬀerent numbers of clones (Q) along the rectilinear
valley observed in L in Fig. 8 (the ﬁrst ﬁve points of each curve correspond to the
cells marked in that ﬁgure).

19

Fig. 10. Probability that a clone or thirty clones (with q = 5; the uppermost squared
cell in L in Fig. 8) declare an alarm in a given time, around the instant when it
should for obtaining the ideal forecast.

to declare the alarm just when N − 1 cells of the master are full. The ﬁgure
shows how a single clone connects the alarm around that moment, but a group
of clones does a much better job.

6 Discussion and conclusions

In this paper we have tried to provide some insight into how to synchronize
numerical models with seismic faults, in order to better forecast large earth-
quakes in them. The idea is that, although we can rarely measure the stress
and strain in actual faults, we can estimate the rupture area and coseismic
displacement of their earthquakes. If we force a calibrated model to reproduce
every earthquake rupture of the fault it simulates, probably the model will
be synchronized with the fault. Then it could be used to forecast the future
evolution of the fault, including future large earthquakes. This idea is not com-
pletely new: e.g. Ward (2000) forced a model to reproduce a large-earthquake
rupture and run the model forward to see what could happen in the future.
The results of this paper expand on earlier ones (Gonz´alez et al., 2004), and
are still only theoretical, but fully quantitative. We demonstrate that it is
possible to partially synchronize numerical fault models between themselves,
and use this to forecast synthetic earthquakes.

One of the models, called the master, evolves freely. We consider it as an actual
fault, from which we can know the rupture area of its earthquakes, but not
the strain or stress at depth. Our goal is to forecast the largest earthquakes it
generates. In the synchronization-based forecasting, we use several other mod-
els, called clones, similar to the master (calibrated to have the same average
recurrence interval of large earthquakes that the master has). These clones are
equivalent to the models that can be devised to simulate a seismic fault. They
are run simultaneously and independently to the master and to each other. We

20

force them to reproduce the series of earthquake ruptures of the master, and
this makes them partially synchronized with it. In simple words, if the master
does not generate an earthquake, we preclude any earthquake in the clones;
if the master does generate an earthquake, we impose the same rupture area
on the clones. When several of the clones indicate that a large earthquake is
impending in the master, we declare an alarm. This eﬃciently predicts most
of the largest earthquakes of the master, with a relatively low fraction of total
alarm time and few false alarms. These results are robust; they are almost the
same when the exact rules for imposing the earthquake ruptures vary. This
synchronization-based forecasting outperforms other procedures based only on
the earthquake series of the model.

The master and the clones are stochastic (random), so each individual clone
is only partially synchronized with the master. However, when several clones
are in the same state, then it is more likely that the master is also in this
state, so the group of clones makes a much better forecasting job than only
one clone does. If the clones were deterministic, as a general rule only one
would be needed; more clones would have identical evolutions if run with the
same initial conditions.

The procedure developed here is a kind of ensemble forecasting, in which
several models are run to obtain a better picture of how a system will evolve.
This concept is used in atmospheric forecasting (Palmer et al., 2005): several
models are run simultaneously, and their average result has a larger forecasting
ability than that of an individual model (Houghton, 2002; Palmer et al., 2005).
Each model in this approach has slightly diﬀerent initial conditions, to take
into account measurement errors and then to represent one possible state of the
atmosphere, among various possibilities. In our approach, each clone marks
a possible state of the master among a range of possible options. Several
deterministic clones could also be used with diﬀerent initial conditions.

Our procedure also shares some similarities with certain earthquake forecast-
ing algorithms (Kossobokov et al., 1999; Keilis-Borok and Soloviev, 2003), in
which several seismicity functions are evaluated in real time. When several
of these functions indicate that a large earthquake is probable, an alarm is
declared. In our approach, the clones are performing a role similar to these
functions, monitoring what is happening in the master.

Our theoretical proposal is that a possible way to synchronize more complex,
calibrated models with real faults might be to force them to reproduce the past
series of earthquakes (with the same rupture area and/or coseismic displace-
ment). This would need to be tested in the future. Also it will be possible to
test whether this procedure works in the forecasting of synthetic earthquakes
in other models.

21

Forcing the models to reproduce only one large observed rupture (as in Ward,
2000) probably is not enough (this is certainly the case in our stochastic
model). Complex and chaotic systems, such as the lithosphere, are very sensi-
tive to initial conditions. Forcing the model to reproduce only one rupture is a
necessary and laudable ﬁrst step, but probably does not constrain the initial
conditions suﬃciently. We propose that every observed rupture, albeit small,
should be considered. Small earthquakes are much more frequent than large
ones, thus providing much more data. Moreover, they provide insight into
the mechanical state of the crust (Seeber and Armbruster, 2000) and into the
mechanics of earthquake rupture (Rubin, 2002). Their location may indicate
the patch of the fault plane which is experiencing higher stresses and is likely
to rupture in the next large shock (Schorlemmer and Wiemer, 2005). Finally,
they are important in the transfer of stress within the lithosphere, and in
earthquake triggering (Helmstetter et al., 2005).

7 Acknowledgments

´A.G. thanks Robert Shcherbakov for helping him to view the model with
new eyes. We are also grateful to the University of Zaragoza Institute of Bio-
computation and Physics of Complex Systems (BIFI) for allowing us to use
their supercomputing facilities. The Spanish Ministry of Science and Educa-
tion funded this research by means of the project BFM2002-01798, and the
grant AP2002-1347 held by ´A.G.

A Size-frequency distributions of earthquakes in faults

This appendix deals with two distributions proposed in the literature for the
size-frequency relationship of earthquakes in faults: The Gutenber-Richter and
the characteristic earthquake distributions. We also give some insights gained
from the minimalist and other numerical models on this topic.

It is generally considered that the regional seismicity of large enough geo-
graphic areas, averaged during long enough time intervals (Molchan et al.,
1997), follows the Gutenberg-Richter law (Ishimoto and Iida, 1939; Gutenberg and Richter,
1944, 1954),

logNGR(> m) = −bm + a,

(A.1)

where NGR is the cumulative number of earthquakes with a magnitude greater
than m occurring in a speciﬁed area and time and b and a are empirical

22

parameters. This relation holds for a certain magnitude interval, and is a
power law when magnitude is expressed in terms of rupture area (Aki, 1981):

NGR(> A) = CA−b,

(A.2)

where NGR is the cumulative number of earthquakes with rupture area greater
than A occurring in a speciﬁed area and time, and C is an empirical parameter.
The b-value, common to both equations, varies from one region to another,
generally within the range 0.8 < b < 1.2 (Frohlich and Davis, 1993), and also
may depend on the depth of the hypocentres considered (Molchan et al., 1997;
Kagan, 1999; Gerstenberger et al., 2001).

However, the Gutenberg-Richter law may not hold for the seismicity par-
ticular to a single fault or fault segment. At the beginning of the 1980’s,
certain geologic investigations led to the hypothesis that most of the seis-
mic moment on a fault or fault segment is released by repetition of the
largest earthquakes it can produce, given its area. Such earthquakes were
called characteristic (Schwartz et al., 1981; Coppersmith and Schwartz, 1983;
Wesnousky et al., 1983; Schwartz and Coppersmith, 1984). This characteristic-
earthquake model for earthquake recurrence on faults is one possible option
among other alternatives (Scholz, 2002), and is frequently assumed in many
seismic hazard studies. In the characteristic-earthquake size-frequency distri-
bution, that suggested for individual faults according to this model (Wesnousky et al.,
1983; Schwartz and Coppersmith, 1984; Youngs and Coppersmith, 1985; Wesnousky,
1994), only small earthquakes would follow the Gutenberg-Richter law. The
frequency of medium-sized events would be very low, or they might even be ab-
sent. However, the frequency of the characteristic earthquakes would be higher
than that estimated by extrapolating the Gutenberg-Richter distribution of
the smaller events.

Later studies added further support to this hypothesis (e.g. Wesnousky, 1994;
Stirling et al., 1996; Sieh, 1996), and raised debate on the topic (Kagan, 1996;
Wesnousky, 1996). There is also concern over the possibility that poor statis-
tics of large earthquakes could produce artifacts in the size-frequency distri-
butions (Stein and Newman, 2004). Numerical models can generate as many
synthetic earthquakes as desired, and thus overcome these sampling prob-
lems. Some insights into real seismicity (Stirling et al., 1996) and into numer-
ical models (e.g. Rundle and Klein, 1993; Main, 1996; Dahmen et al., 1998;
Steacy and McCloskey, 1999; Moreno et al., 1999; Hainzl and Z¨oller, 2001; Heimpel,
2003; Z¨oller et al., 2005) have indicated that the heterogenity of the fault sys-
tem may inﬂuence the shape of the size frequency distribution of earthquakes:
fault systems with complex traces and models with heterogeneous fault planes
tend to display Gutenberg-Richter distributions, while faults with simple ge-
ometry and models with low heterogeneity tend to display characteristic-
earthquake behavior. In general, earthquake ruptures can span all or most

23

the fault plane if this is homogeneous, while the barriers in an heterogeneous
plane tend to arrest the rupture, preventing it from spanning the whole plane.
Aki (1984) also noted that the characteristic earthquakes appear to be asso-
ciated to those faults with a relatively homogeneous fault plane with stable
asperities. This may be the case of the minimalist model, where all the cells
have the same properties, and earthquakes always start in the same asperity.

The characteristic earthquakes, in which all or most of the fault plane breaks,
are also possible because the faults are ﬁnite (e.g. Heimpel, 2003). Charac-
teristic earthquakes are thus a certain ﬁnite-size eﬀect. This is also true for
the minimalist model, where the probability of the characteristic earthquake
tends to zero as the system size (N) grows (L´opez-Ruiz et al., 2004).

In large enough geographic regions, encompassing a large enough number of
active seismic faults, the Gutenberg-Richter law can result from the addi-
tion of the characteristic-earthquake distributed seismicity from each fault
(Wesnousky et al., 1983; Molchan et al., 1997), if the distribution of fault sizes
and fault slip rates is taken into account (Wesnousky et al., 1983). This was
also checked in the minimalist model. Fault sizes in Nature are distributed ac-
cording to a power law (fractal) distribution. A population of non-interacting
minimalist models whose Ns follow this fractal scaling generates Gutenberg-
Richter distributed seismicity (L´opez-Ruiz et al., 2004).

B Deduction of the ideal forecasting strategy

In this appendix we will deduce the ideal strategy outlined in Section 4.3.
This strategy renders the lowest (best) value of L = fa + fe achievable in the
minimalist model.

For this reasoning we would consider every cycle of the model as composed
of two independent and consecutive stages. The ﬁrst, that will be called the
loading stage, starts just after the occurrence of a characteristic earthquake.
During this stage the total number of occupied cells grows, but not in a mono-
tonic way, because the particles may land in already occupied cells (and then
be dissipated), and also because of the occurrence of non-characteristic earth-
quakes. As commented on in Section 2.2.2, during this ﬁrst stage, the occupa-
tion grows faster when none or few of the cells are occupied, that is, after a
large earthquake, and more slowly when many cells are occupied, because it
is less probable for the stress particles to arrive at empty cells. When N − 1
cells (all but the ﬁrst one) become occupied, this ﬁrst stage ends and the sec-
ond stage, that will be called the hitting stage (or plateau in the occupation),
starts. In this second stage, the system resides statically in the state of maxi-
mum occupancy until a particle arrives at the ﬁrst cell. Then, a characteristic

24

event occurs, all the cells are emptied, and a new cycle begins. The hitting
stage can be mathematically treated as a form of Russian roulette.

Both the time spent by the system in the loading stage, x, and in the hitting
stage, y, are statistically distributed. The distribution of y, denoted by P2(y),
is geometric. Considering that, in each time step, the probability of hitting
the ﬁrst cell is p = 1/N, and its complementary is q = 1 − 1/N, it follows that

P2(y) =

1 −

1
N (cid:18)

y−1

,

1
N (cid:19)

whose mean is

hyi = N,

and whose standard deviation is

σ = N

1 −

s

1
N

.

The time elapsed between consecutive characteristic events has been denoted
by n, which is statistically distributed according to the function PN (n). Keep-
ing this notation, and bearing in mind that the variables x and y are indepen-
dent, results in

hni = hxi + hyi.

That is, the mean length of the cycles hni is the sum of the mean lengths of
the two stages.

It is clear that the best L would be obtained only if we knew the state of
occupation of the system and could mark, for each cycle, the instant at which
the stage of loading concludes. In this case, fe = 0, but because the hitting
stage is completely stochastic, fa (and thus L) cannot be nil.

Let us explore the result of L obtained if we turn the alarm on at a given
value y = y0 within the second stage of all the cycles. With this strategy, the
fraction of errors is given by

fe(y0) =

P2(y),

y0

1
X

and inserting Eq. B.1 we obtain

fe(y0) = 1 − qy0.

25

(B.1)

(B.2)

(B.3)

(B.4)

(B.5)

(B.6)

(B.7)

(B.8)

(B.9)

(B.10)

With respect to to the fraction of alarm, its form is

∞

fa(y0) =

y0
X

(y − y0) · P2(y)

hxi + hyi

,

and inserting Eq. B.1, we get

fa(y0) =

Nqy0
hxi + N

.

L(y0) = 1 − qy0 +

Nqy0
hxi + N

.

Note the important contribution of the ﬁrst stage of the process in the de-
nominator. Thus, the speciﬁc form of the loss function is

It is noteworthy that in the absence of the ﬁrst stage, i.e. in the hypothesis
of a pure geometric distribution, the value of L would be 1, not dependent on
the value of y0. In this sense, the geometrical and the Poisson distributions are
equivalent. The minimum value of L in Eq. B.9 as a function of y0 is obtained
for y0 = 0, i.e. just after the end of the ﬁrst stage, when the N − 1 upper cells
of the system are full. And this minimum value is

Lmin =

N
hni

.

This result constitutes a rigorous lower bound for the expected accuracy of
any forecasting strategy in the minimalist model. For this model, hni increases
rapidly as N grows (G´omez and Pacheco, 2004). This implies that the min-
imum L, obtained with this optimal forecasting strategy, decreases as N in-
creases, as shown by the curve labeled as “Ideal” in Fig. 4.2. That is to say,
minimalist models with more cells are more predictable.

References

Aki, K., 1981. A probabilistic synthesis of precursory phenomena. In: Simp-
son, D.W., Richards, P.G. (Eds.), Earthquake Prediction: An International
Review. American Geophysical Union, Washington D. C., Maurice Ewing
Series, vol. 4, pp. 566-574.

Aki, K., 1984. Asperities, barriers, characteristic earthquakes and strong mo-

tion prediction. Journal of Geophysical Research 89, 5867-5872.

26

Bak, P., Tang, C., 1989. Earthquakes as a self-organized critical phenomenon.

Journal of Geophysical Research 94, 15635-15637.

Ben-Zion, Y., 2001. Dynamic ruptures in recent models of earthquake faults,

Journal of the Mechanics and Physics of Solids 49, 2209-2244.

Boness, N.L., Zoback, M.D., 2004. Stress-induced seismic velocity anisotropy
and physical properties in the SAFOD Pilot Hole in Parkﬁeld, CA. Geo-
physical Research Letters 31, L15S17, doi:10.1029/2003GL019020.

Castellaro, S., Mulargia, F., 2001. A simple but eﬀective cellular automaton

for earthquakes. Geophysical Journal International 144, 609-624.

Coppersmith, K.J., Schwartz, D.P., 1983. The characteristic earthquake
model: Implications to recurrence on the San Andreas fault (abstract).
Earthquake Notes 54, 61.

Dahmen, K., Erta¸s, D., Ben-Zion, Y., 1998. Gutenberg-Richter and charac-
teristic earthquake behavior in simple mean-ﬁeld models of heterogeneous
faults. Physical Review E 58, 1494-1501.

Das, S., 2003. Spontaneous complex earthquake rupture propagation. Pure

and Applied Geophysics 160, 579-602.

Das, S., Aki, K., 1977. Fault plane with barriers: a versatile earthquake model.

Journal of Geophysical Research 82, 5658-5670.

Dowrick, D.J., Rhoades, D.A., 2004. Relations between earthquake magnitude
and fault rupture dimensions: How regionally variable are they? Bulletin of
the Seismological Society of America 94, 776-788.

Drossel, B., Schwabl, F., 1992. Self-organized criticality in a forest-ﬁre model.

Physica A 191, 47-50.

Fitzenz, D.D., Miller, S.A., 2004. New insights on stress rotations from a
forward regional model of the San Andreas fault system near its Big
Bend in southern California. Journal of Geophysical Research 109, B08404,
doi:10.1029/2003JB002890.

Frohlich, C., Davis, S.D., 1993. Teleseismic b values; or, much Ado about 1.0.

Journal of Geophysical Research 98, 631-644.

Gerstenberger, M.; Wiemer, S., Giardini, D., 2001. A systematic test of the
hypothesis that the b value varies with depth in California. Geophysical
Research Letters 28, 57-60.

Goltz, C., 1997. Fractal and Chaotic Properties of Earthquakes. Springer-

Verlag, Berlin, Germany, p. 178.

G´omez, J.B., Pacheco, A.F., 2004. The minimalist model of characteristic
earthquakes as a useful tool for description of the recurrence of large earth-
quakes. Bulletin of the Seismological Society of America 94, 1960-1967.
Gonz´alez, ´A., G´omez, J.B., Pacheco, A.F., 2005. The occupation of a box as
a toy model for the seismic cycle of a fault. American Journal of Physics,
in press. http://arxiv.org/abs/physics/0502048

Gonz´alez, ´A., V´azquez-Prada, M., G´omez, J.B., Pacheco, A.F., 2004. Using
synchronization to improve the forecasting of large relaxations in a cellular-
automaton model. Europhysics Letters 68, 611-617.

Grant, L.B., Gould, M.M., 2004. Assimilation of paleoseismic data for earth-

27

quake simulation. Pure and Applied Geophysics 161, 2295-2306.

Gutenberg, B., Richter, C.F., 1944. Frequency of earthquakes in California.

Bulletin of the Seismological Society of America 34, 185-188.

Gutenberg, B. and Richter, C.F., 1954. Seismicity of the Earth and Associated
Phenomena, 2nd edn. Princeton University Press, Princeton, New Jersey,
USA, p. 310.

Hainzl, S., Z¨oller, G., 2001. The role of disorder and stress concentration in

nonconservative fault systems. Physica A 294, 67-84.

Hainzl, S., Z¨oller, G., Kurths, J., 1999. Self-organized criticality model for
earthquakes: Quiescence, foreshocks and aftershocks. International Journal
of Bifurcation and Chaos 9, 2249-2255.

Hainzl, S., Z¨oller, G., Kurths, J., Zschau, J., 2000. Seismic quiescence as an
indicator for large earthquakes in a sytem of self-organized criticality. Geo-
physical Researh Letters 27, 597-600.

Harris, R.A., 2000. Earthquake stress triggers, stress shadows, and seismic

hazard. Current Science 79, 1215-1225.

Hashimoto, M., 2001. Complexity in the recurrence of large earthquakes in
southwestern Japan: A simulation with an interacting fault system model.
Earth, Planets and Space 53, 249-259.

Heimpel, M.H., 2003. Characteristic scales of earthquake rupture from numer-

ical models. Nonlinear Processes in Geophysics 10, 573-584.

Helmstetter, A., Kagan, Y.Y., Jackson, D.D., 2005. Importance of small earth-
quakes for stress transfers and earthquake triggering. Journal of Geophysical
Research 110, B05S08, doi:10.1029/2004JB003286.

Henley, C.L., 1993. Statics of a “self-organized” percolation model. Physical

Review Letters 71, 2741-2744.

Hickman, S., Zoback, M., 2004. Stress orientations and magnitudes in
the SAFOD pilot hole. Geophysical Research Letters 31, L15S12,
doi:10.1029/2004GL020043.

Houghton, J., 2002. The Physics of Atmospheres. Cambridge University Press,

Cambridge, UK, p. 320.

Ikeda, R., Iio, Y., Omura, K., 2001. In situ stress measurements in NIED
boreholes in and around the fault zone near the 1995 Hyogo-ken Nanbu
earthquake, Japan. The Island Arc 10, 252-260.

Ishimoto, M., Iida, K., 1939. Observations sur les s´eismes enregistr´es par le
micros´eismographe construit derni`erement (I). Bulletin of the Earthquake
Research Institute, University of Tokyo 17, 443-478.

Kagan, Y.Y., 1996. Comment on “The Gutenberg-Richter or characteristic
earthquake distribution, which is it?” by Steven G. Wesnousky. Bulletin of
the Seismological Society of America 86, 274-285.

Kagan, Y.Y., 1999. Universality of the seismic moment-frequency relation.

Pure and Applied Geophysics 155, 537-573.

Kanamori, H., Anderson, D.L., 1975. Theoretical basis of some empirical re-
lations in seismology. Bulletin of the Seismological Society of America 65,
1073-1095.

28

Kanamori, H., Brodsky, E.E., 2004. The physics of earthquakes. Reports on

Progress in Physics 67, 1429-1496.

Kanamori, H., Stewart, G.S., 1978. Seismological aspects of Guatemala earth-
quake on february 4, 1976. Journal of Geophysical Research 83, 3427-3434.
Kato, N., Seno, T., 2003. Hypocenter depths of large interplate earthquakes
and their relation to seismic coupling. Earth and Planetary Science Letters
210, 53-63.

Keilis-Borok, V.I., 2002. Earthquake prediction: State-of-the-art and emerging
possibilities. Annual Review of Earth and Planetary Sciences 30, 1-33.
Keilis-Borok, V.I., Soloviev, A.A. (Eds.), 2003. Nonlinear Dynamics of the

Lithosphere and Earthquake Prediction, Springer, Berlin, p. 337.

Kisslinger, C., 1996. Aftershocks and fault-zone properties. Advances in Geo-

physics 38, 1-36.

Kossobokov, V.G., Romashkova, L.L., Keilis-Borok, V.I., Healy, J.H., 1999.
Testing earthquake prediction algorithms: Statistically signiﬁcant advance
prediction of the largest earthquakes in the Circum-Paciﬁc, 1992-1997.
Physics of the Earth and Planetary Interiors 111, 187-196.

Kuroki, H., Ito, H.M., Takayama, H., Yoshida, A., 2004. 3-D simulation of the
occurrence of slow slip events in the Tokai region with a rate- and state-
dependent friction law. Bulletin of the Seismological Society of America 94,
2037-2050.

Lei, X., Kusunose, K., Satoh, T., Nishizawa, O., 2003. The hierarchical rup-
ture process of a fault: An experimental study. Physics of the Earth and
Planetary Interiors 137, 213-228.

L´opez-Ruiz, R., V´azquez-Prada, M., G´omez, J.B., Pacheco, A.F., 2004. A
model of characteristic earthquakes and its implications for regional seis-
micity. Terra Nova 16, 116-120.

Main, I., 1996. Statistical physics, seismogenesis, and seismic hazard. Reviews

of Geophysics 34, 433-462.

Mason, I.B., 2003. Binary forecasts. In: Joliﬀe, I.T., Stephenson D.B (Eds.),
Forecast Veriﬁcation: A Practitione’s Guide in Atmospheric Science. Wiley,
West Sussex, England, pp. 37-76 (references in pp. 215-226).

Michael, A.J., 2005. Viscoelasticity, postseismic slip, fault interactions, and
the recurrence of large earthquakes. Bulletin of the Seismological Society of
America, in press.

Miller, S.A., Ben-Zion, Y., Burg, J.-P., 1999. A three-dimensional ﬂuid-
controlled earthquake model: Behavior and implications. Journal of Geo-
physical Research 104, 10621-10638.

Molchan, G.M., 1997. Earthquake prediction as a decision-making problem.

Pure and Applied Geophysics 149, 233-247.

Molchan, G.M., Kronrod, T., Panza, G.F., 1997. Multiscale seismicity model
for seismic risk. Bulletin of the Seismological Society of America 87, 1220-
1229.

Moreno, Y., G´omez, J.B., Pacheco, A.F., 1999. Self organized criticality in a

ﬁber-bundle-type model. Physica A 274, 400-409.

29

Newman, W.I., Turcotte, D.L., 2002. A simple model for the earthquake cycle
combining self-organized complexity with critical point behavior. Nonlinear
Processes in Geophysics 9, 453-461.

Okada, T., Matsuzawa, T., Hasegawa, A., 2003. Comparison of source areas
of M4.8±0.1 repeating earthquakes oﬀ Kamaishi, NE Japan: are asperities
persistent features? Earth and Planetary Science Letters 213, 361-374.
Olami, Z., Feder, H.J.S., Christensen, K., 1992. Self-organized criticality in
a continuous, nonconservative cellular automaton modeling earthquakes.
Physical Review Letters 68, 1244-1247.

Palmer, T.N., Shutts, G.J., Hagedorn, R., Doblas-Reyes, F.J., Jung, T., Leut-
becher, M., 2005. Representing model uncertainty in weather and climate
prediction. Annual Review of Earth and Planetary Sciences 33, 163-193.
Pepke, S.L., Carlson, J.M., 1994. Predictability of self-organizing systems.

Physical Review E 50, 236-242.

Preston, E.F., S´a Martins, J.S., Rundle, J.B., Anghel, M., Klein, W., 2000.
Models of earthquake faults with long-range stress transfer. Computing in
Science and Engineering 2, 34-41.

Reinecker, J., Heidbach, O., Tingay, M., Connolly, P., M¨uller, B., 2004. The
2004 release of the World Stress Map (available online at www.world-stress-
map.org).

Robinson, R., 2004. Potential earthquake triggering in a complex fault net-
work: the northern South Island, New Zealand. Geophysical Journal Inter-
national 159, 734-748.

Robinson, R., Benites, R., 2001. Upgrading a synthetic seismicity model for
more realistic fault ruptures. Geophysical Research Letters 28, 1843-1846.
Rubin, A.M., 2002. Aftershocks of microearthquakes as probes of the
rupture. Journal of Geophysical Research 107, 2142,

mechanics of
doi:10.1029/2001JB000496.

Rundle, J.B., Klein, W., 1993. Scaling and critical phenomena in a cellular
automaton slider-block model for earthquakes. Journal of Statistical Physics
72, 405-413.

Rundle, J.B., Rundle, P.B., Donnellan, A., Fox, G., 2004. Gutenberg-Richter
statistics in topologically realistic system-level earthquake stress-evolution
simulations. Earth, Planets and Space 56, 761-771.

Rundle, P.B., Rundle, J.B., Tiampo, K.F., Sa Martins, J.S., McGinnis, S.
Klein, W., 2001. Nonlinear network dynamics on earthquake fault systems.
Physical Review Letters 87, 148501.

Rundle, J.B., Turcotte, D.L., Shcherbakov, R., Klein, W., Sammis, C.,
2003. Statistical physics approach to understanding the multiscale dy-
namics of earthquake fault systems. Reviews of Geophysics 41, 1019,
doi:10.1029/2003RG000135.

Scholz, C.H., 2002. The Mechanics of Earthquakes and Faulting. 2nd edn.

Cambridge University Press. Cambridge, United Kingdom. p. 496.

Scholz, C.H., Gupta, A., 2000. Fault interactions and seismic hazard. Journal

of Geodynamics 29, 459-467.

30

Schorlemmer, D., Wiemer, S., 2005. Microseismicity data forecast rupture

area. Nature 434, 1086.

Schwartz, D.P., Coppersmith, K.J., 1984. Fault behavior and characteristic
earthquakes: Examples from the Wasatch and San Andreas fault zones.
Journal of Geophysical Research 89, 5681-5698.

Schwartz, D.P., Coppersmith, K.J., Swan III, F.H., Somerville, P. and Sav-
age, W.U., 1981. Characteristic earthquakes on intraplate normal faults
(abstract). Earthquake Notes 52, 71.

Seeber, L., Armbruster, J.G., 2000. Earthquakes as beacons of stress change.

Nature 407, 69-72.

Sieh, K., 1996. The repetition of large-earthquake ruptures. Proceedings of
the National Academy of Sciences of the United States of America 93, 3764-
3771.

Soloviev, A., Ismail-Zadeh, A., 2003. Models of dynamics of block-and-fault
systems. In: Keilis-Borok, V.I. and Soloviev, A.A. (Eds.), Nonlinear Dy-
namics of the Lithosphere and Earthquake Prediction. Springer, Berlin,
Germany, pp. 71-139 references in pp. 311-332),

Steacy, S.J., McCloskey, J., 1999. Heterogeneity and the earthquake
magnitude-frequency distribution. Geophysical Research Letters 26, 899-
902.

Stein, S., Newman, A., 2004. Characteristic and uncharacteristic earthquakes
as possible artifacts: applications to the New Madrid and Wabash seismic
zones. Seismological Research Letters 75, 173-187.

Stirling, M., Rhoades, D., Berryman, K., 2002. Comparison of earthquake
scaling relations derived from data of the instrumental and preinstrumental
era. Bulletin of the Seismological Society of America 92, 812-830.

Stirling, M.W., Wesnousky, S.G., Shimazaki, K., 1996. Fault trace complexity,
cumulative slip, and the shape of the magnitude-frequency distribution for
strike-slip faults: A global survey. Geophysical Journal International 124,
833-868.

Tsukahara, H., Ikeda, R., Yamamoto, K., 2001. In situ stress measurements

in a borehole close to the Nojima Fault. The Island Arc 10, 261-265.

Turcotte, D.L., 1997. Fractals and Chaos in Geology and Geophysics, 2nd

edition Cambridge University Press, Cambridge, UK, p. 412.

V´azquez-Prada, M., Gonz´alez, ´A., G´omez, J.B., Pacheco, A.F., 2002. A min-
imalist model of characteristic earthquakes. Nonlinear Processes in Geo-
physics 9, 513-519.

V´azquez-Prada, M., Gonz´alez, ´A., G´omez, J.B., Pacheco, A.F., 2003. Forecast-
ing characteristic earthquakes in a minimalist model. Nonlinear Processes
in Geophysics 10, 565-571.

Ward, S.N., 2000. San Francisco Bay area earthquake simulations: A step
toward a standard physical earthquake model. Bulletin of the Seismological
Society of America 90, 370-386.

Wells, D.L., Coppersmith, K.J., 1994. New empirical relationships among mag-
nitude, rupture length, rupture width, rupture area, and surface displace-

31

ment. Bulletin of the Seismological Society of America 84, 974-1002.

Wesnousky, S.G., 1994. The Gutenberg-Richter or characteristic earthquake
distribution, which is it? Bulletin of the Seismological Society of America
84, 1940-1959.

Wesnousky, S.G., 1996. Reply to Kagan’s comment on “The Gutenberg-
Richter or characteristic earthquake distribution, which is it?”. Bulletin of
the Seismological Society of America 86, 286-291.

Wesnousky, S.G.; Scholz, C.H.; Shimazaki, K., Matsuda, T., 1983. Earthquake
frequency distribution and the mechanics of faulting. Journal of Geophysical
Research 88, 9331-9340.

Wyss, M., Habermann, R.E., 1988. Precursory seismic quiescence. Pure and

Applied Geophysics 126, 319-332.

Yabuki, T., Matsuura, M., 1992. Geodetic data inversion using a bayesian in-
formation criterion for spatial-distribution of fault slip. Geophysical Journal
International 109, 363-375.

Yagi, Y., Kikuchi, M., Yoshida, S., Sagiya, T., 1999. Comparison of the coseis-
mic rupture with the aftershock distribution in the Hyuga-nada earthquakes
of 1996. Geophysical Research Letters 26, 3161-3164.

Yamamoto, K., Yabe, Y., 2001. Stresses at sites close to the Nojima Fault

measured from core samples. The Island Arc 10, 266-281.

Yeats, R.S., Sieh, K., Allen, C.R., 1997. The Geology of Earthquakes. Oxford

University Press, New York, USA, p. 568.

Youngs, R.R., Coppersmith, K.J., 1985. Implications of fault slip rates and
earthquake recurrence models to probabilistic seismic hazard estimates. Bul-
letin of the Seismological Society of America 75, 939-964.

Zoback, M.L., 1992. 1st-order and 2nd-order patterns of stress in the
lithosphere–The World Stress Map project. Journal of Geophysical Research
97, 11703-11728.

Z¨oller, G., Holschneider, M., Ben-Zion,Y., 2005. The role of heterogeneities as
a tuning parameter of earthquakes dynamics. Pure and Applied Geophysics
162, 1027-1049.

32

