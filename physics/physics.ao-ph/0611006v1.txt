6
0
0
2
 
v
o
N
 
1
 
 
]
h
p
-
o
a
.
s
c
i
s
y
h
p
[
 
 
1
v
6
0
0
1
1
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Comparing classical and Bayesian methods for predicting
hurricane landfall rates

Tim Hall, GISS
and
Stephen Jewson∗

February 2, 2008

Abstract

We compare classical and Bayesian methods for ﬁtting the poisson distribution to the number of

hurricanes making landfall on sections of the US coastline.

1 Introduction

The occurrence of a number of hurricanes making landfall on the US coastline in 2004 and 2005 has
increased the level of interest in the question of how to estimate the risk of hurricane damage in diﬀerent
locations. There are many aspects to this problem, such as questions about the number of hurricanes
occurring in diﬀerent regions, their size, their intensity, their speed, the detailed structure of their wind-
ﬁeld, how they decay when they reach land, how much damage the winds will cause to structures, and
so on. In this paper, we address one small part of one of these questions: how to estimate the distri-
bution of the number of hurricanes that make landfall on any short stretch of coastline using historical
hurricane data. This question itself has various aspects to it, such as to what extent we can extrapolate
historical hurricane data in space and to what extent the changing climate is changing the distribution
of the number of hurricanes. We don’t attempt to deal with all these issues (at least not here and now).
Rather, we focus on one very small part of the problem, which is to look at the most simple statistical
methods that one might use to estimate hurricane landfall rates, ignoring the complex issue of climate
change completely. Given the historical data on hurricane landfalls, we consider three basic methods
one can consider using to estimate the distribution of hurricanes hitting a certain region: the ﬁrst is the
classical method of moments, the second is the classical maximum likelihood ﬁtting procedure, and the
third is a Bayesian prediction procedure. The point of this paper is to discuss these three procedures,
and compare their pros and cons when applied to this particular problem.
In section 2 we describe the question we want to address in more detail. In section 3 we describe the
classical methods. In section 4 we describe the Bayesian method. In section 5 we perform a numerical
comparison of the two methods. In section 6 we discuss one theoretical way in which these methods can
be compared. In section 7 we apply the two methods to observed hurricane landfall data, and compare
the results using cross-validation. Finally in section 8 we discuss what we ﬁnd.

2 Setup

We now give a mathematical summary of the problem we are considering.
We consider a short section of the US coastline, and we wish to estimate the distribution of the number
of hurricanes crossing this section of coastline. We have m years of historical hurricane data that we can
use to estimate this distribution. In practice m has values of between 50 and 150 years, depending on
the extent to which one is willing to use earlier and hence less accurate data. In our examples below we
will use the 54 years of data from 1950 to 2003.
During these m years of history there have been i hurricanes making landfall on our section of coastline.
To illustrate possible values of i, ﬁgure 1 shows the numbers of hurricanes making landfall in each of
39 arbitrary segments along the US coastline during our 54 year period. If we were to consider smaller
segments, or more intense hurricanes only, then the values of i would be smaller.

∗Correspondence address: Email: x@stephenjewson.com

We will assume that the distribution of the number of hurricanes making landfall is constant in time.
This is probably not true: recent years appear to have seen an increase in the numbers of hurricanes,
for instance. Our goal, however, is not to deal with that issue (we, and others, have discussed ways to
address that elsewhere), but to look at the basic statistics of this problem. We will also assume that the
number of hurricanes within a year is given by a poisson process. This is also probably not true, but
again making this simpliﬁcation allows us to look at and think about some important statistical issues.
To summarise: given m years of historical hurricane data in which there have been i hurricanes, and
assuming stationarity and the poisson distribution, how should we estimate the probability f (n) of n
hurricanes hitting this segment of coastline in a single year? Since we are assuming that f is a poisson
distribution, f (n) is given by:

where λ is the real unknown expected number of hurricanes per year.
For convenience below we will use the shorthand that:

3 Classical methods for ﬁtting the poisson distribution

There are two classical approaches to this problem: method of moments, and maximum likelihood. We
discuss them in turn.

3.1 Method of moments

Method of moments works as follows. We equate the observed annual mean number of hurricanes (which
is i

m ) to the modelled rate ˆλ:

and we substitute this estimate ˆλ into equation 1 in place of the real λ, giving:

That’s it: ˆf (n) is then our estimate of f (n).

3.2 Maximum likelihood

Maximum likelihood works as follows. The likelihood is deﬁned as the probability of the observed data
given the model and the parameters of the model. Considering likelihood as a function of the parameter
λ, we vary λ and ﬁnd the maximum of the likelihood. The value of λ that maximises the likelihood is
then plugged into equation 1.
Applying this in practice in our example, we note that we can consider a poisson with rate λ for m years
as giving the same distribution of numbers of events as a poisson with rate λm, once.
The likelihood is thus given by:

f (n) =

e−λλn
n!

g(λ, n) =

e−λλn
n!

ˆλ =

i
m

ˆf (n) =

e−ˆλˆλn
n!

Taking logs:

Diﬀerentiating this by λ:

L(λ) =

e−λm(λm)i
i!

l = logL

= log

e−λm(λm)i
i!
= −λm + ilog(λm) − log(i!)

(cid:21)

(cid:20)

∂l
∂λ

= −m +

i
λ

(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

(9)

Setting this equal to zero gives:

and this is then substituted into equation 1 in place of the real λ, giving

ˆλ =

i
m

ˆf (n) =

e−ˆλˆλn
n!

3.3 Discussion of the classical methods

We see that method of moments and maximum likelihood give the same results. Do these two methods
make sense? Both are based on the idea that, in order to model the distribution of hurricanes, we should
choose our single best estimate of the rate λ. Prima facie, this seems reasonable, but it can certainly be
criticised. The main criticism is: why use only our best estimate? What about all the other estimates
of the rate that one might make, which are not quite as likely to be correct? Given the small amount
of data for hurricanes for short sections of coastline, it seems likely that there is quite a large range of
reasonable estimates for λ. Instead of using just the most likely of this range of estimates, perhaps we
should use them all in some way.
Another criticism is: consider the case where i = 0. In other words, we have a section of coastline where
there haven’t been any hurricanes in the last m years. What do the classical methods give us? Our
estimate of the rate is ˆλ = i
0
n! = 0.
In other words, because we haven’t seen any hurricanes in the last m years we conclude that it must be
completely impossible that a hurricane might strike us in the future. This is clearly an illogical conclusion:
there are many stretches of coastline that haven’t experienced a hurricane strike in recent times, but for
which, on a meteorological basis, it is quite clearly possible that they could experience such a strike.
In fact, this second criticism is related to the ﬁrst. If there haven’t been any hurricanes in the last m
years, it may well be the case that an appropriate conclusion should be that the most likely value of λ
is 0, but it is very clear that we also need to consider the (perhaps small) possibility that λ is actually
greater than zero.
One ﬁnal criticism of the classical methods is: note that the values of i and m only occur as the ratio i
m
in these methods. The absolute value of m doesn’t make any diﬀerence at all, and so there can be no
accounting for the extra accuracy that extra years of data might bring (or vice versa).
These criticisms lead us onto Bayesian methods, in which we move beyond just considering the single
most likely value of λ, and consider a range of possible values.

m = 0, and hence our estimate of the distribution is ˆf = e

m = 0

−0

n

4 Bayesian methods for ﬁtting the poisson distribution

The Bayesian method we describe works as follows. Based on the discussion in the previous section, we
will express our prediction for the distribution of the number of hurricanes as an integral over all possible
hurricane rates that might have given us the observed data, rather than just the most likely rate. The
prediction is then:

ˆf (n|i) =

f (n|λ)f (λ|i)dλ.

Z

The ﬁrst term in the integral (f (n|λ)) is the probability of n hurricanes, given a certain value of λ. The
second term gives the probability of each value of λ, given the observation of i hurricanes in the last m
years. We can think of this integral as a weighted average of predictions f (n|λ), where f (λ|i) gives the
weights. f (λ|i) is often known as the posterior density of λ.
How, then, can we calculate f (λ|i)? Applying Bayes’ theorem, we can factorise f (λ|i) into:

f (λ|i) ∝ f (i|λ)f (λ)

The ﬁrst term on the right hand side can be evaluated easily:
poisson distribution.
The second term, known as the prior, needs a little more thought. If we have prior information on the
distribution of possible values of λ, we can use this prior distribution to include that information in the
analysis. In this article, however, we will assume that we have no such prior information. Instead, we will
try and choose f (λ) so as to be neutral with respect to diﬀerent possible values of λ (such a choice is often
known as a ‘reference prior’, or ‘uninformative prior’). Unfortunately, there doesn’t seem to be a single

it’s just the probability density of the

(10)

(11)

(12)

(13)

unambiguous choice for what this neutral prior should be. We have found the following 3 reasonable
suggestions:

• p(λ) = c, a constant value, justiﬁed on the basis that this puts equal weights on all possible values

2 , known as the Jeﬀrey’s prior, and justiﬁed on the basis that it is invariant to changes

of λ

• p(λ) = cλ− 1

in the scale of λ

• p(λ) = c
λ

We can combine these 3 possibilities into one general form:

f (λ) = cλα

where α has the values 0, −1/2 or −1 in our three cases.
This then gives

We can calculate the constant of proportionality c using the fact that the integral of f (λ|i) must be 1 for
it to be a probability distribution:

f (λ|i) ∝ f (i|λ)f (λ)
∝ cf (i|λ)λα

f (λ|i)dλ = c

f (i|λ)dλ

Z

e−λm(λm)iλα
i!

dλ

−λmλi+αdλ

e

e

−ssi+α ds
m

(i + α)!

Z

= c

=

=

=

Z

Z
c
mii!
c
mii!
cm−α−1
i!

Z

= 1

c =

m1+αi!
(i + α)!

f (λ) =

m1+αi!λα
(i + α)!

f (λ|i) =

m
(i + α)!

−λm(mλ)i+α

e

= mg(λm, i + α)

f (λ|i) =

m
(−1)!

−λm(mλ)

e

−1

implying that

and hence the prior is:

and the posterior distribution for λ is:

Note that this last line should not be read to imply that the distribution of f (λ|i) is a poisson distribution,
since now the roles of the parameter and the random variable are switched. In fact this is a gamma
distribution.
Now consider the case α = −1, i = 0. The posterior becomes:

This is not a proper posterior density, since the integral is not ﬁnite, so we reject the α = −1 prior,
leaving just the cases α = 0 and α = −1/2.
Figure 2 shows the posterior densities for m = 54 and i = 0, 2, 4, 6, for both priors. We see that the
diﬀerences are rather small.

(14)

(15)

(16)

(17)

(18)

(19)

(20)

(21)

(22)

(23)

(24)

(25)

(26)

(27)

Where are the maximum values of these posterior distributions? Diﬀerentiating the prior wrt λ gives:

dp
dλ

=

mi−1−αe−λmλi+α−1
(i + α)!

[i + α − λm]

Setting this equal to zero then gives:

λ =

i + α
m

For the α = 0 prior, this gives λ = i/m, which agrees exactly with the maximum likelihood estimate of
λ. This is, of course, because the posterior is equal to (or proportional to) the likelihood for a constant
prior.
For the α = −1/2 prior, this gives the slightly lower value of λ = (i − 1/2)/m. The use of a prior that
weights towards λ = 0 has shifted the maximum slightly relative to the maximum in the likelihood. The
implication is that this value of λ is now the most likely (which we ﬁnd slightly surprising).
What about the mean value of λ under these posterior distributions?

mean =

−λm(mλ)i+αλdλ

e

m
(i + α)!

Z

Z
m1+α+i
(i + α)!
m1+α+i
(i + α)!
1
m

Z
(i + α + 1)!
(i + α)!

=

=

=

λi+α+1e

−λmdλ

−s

e

s
m

i+α+1 ds
m

(cid:16)

(cid:17)

For the α = 0 prior this gives mean lambda = (i + 1)/m, while for the α = −1/2 prior this gives the
rather unpleasant looking mean = (i+3/2)!
1
m . Note that both of these values are larger than the mean
(i+1/2)!
that comes from the classical analysis, which is i/m. This is because the uncertainty wrt the possibility
of values of λ greater than i/m adds more to the calculation of the mean than the uncertainty wrt the
possibility of values of λ lower than i/m takes away. This is especially noticeable for the case i = 0,
where the two means are both above zero in the Bayesian case.
Substituting the prior into our expression for the Bayesian forecast, equation 12, gives:

f (n|i) =

f (n|λ)f (λ|i)dλ

Z

Z
mi+α+1
n!(i + α)!
mi+α+1
n!(i + α)!

Z

=

=

=

=

g(λ, n)mg(λm, i + α)dλ

−(m+1)λλn+i+αdλ

e

1
m + 1

i+α+n+1

(i + α + n)!

(cid:18)
(i + α + n)!
(i + α)!n!

(cid:19)

m
m + 1

i+α+1

n

1
m + 1

(cid:18)
This is now our estimate for the distribution for the number of hurricanes, based on Bayesian reasoning,
and is, in fact, the negative binomial distribution.

(cid:19)

(cid:19)

(cid:18)

4.1 Discussion of the Bayesian method

There are a number of interesting implications of equation 38.
The ﬁrst is simply that, to predict, or ‘model’ the poisson distribution, one shouldn’t actually use the
poisson distribution: one should use the negative binomial instead.1. This is because of parameter
1Although it is important to realise that the negative binomial in this case is ﬁtted using i and m, and not using the
standard methods for ﬁtting the negative binomial such as method of moments, which would give diﬀerent parameter values
and would only be valid if we thought that the negative binomial, not the poisson, was a good model for the underlying
data.

(28)

(29)

(30)

(31)

(32)

(33)

(34)

(35)

(36)

(37)

(38)

uncertainty. The fact that we don’t know the exact value of the parameter λ, and that we represent
that uncertainty using a distribution, converts the poisson into the negative binomial (even if we are still
considering the events to be independent).
The second interesting implication, already mentioned above, is that the mean of our forecast is now
higher than for the classical case. The mean of the classical forecast (which is i
m ) arises simply because
the mean is given by the value of the rate, and the value of the rate is chosen to be the maximum
i
m . The Bayesian mean, on the other hand, arises through consideration of exactly
likelihood value of
what can be inferred from the observation of i hurricanes in m years. We feel that the Bayesian forecast
mean is thus much more strongly justiﬁed than the classical mean.
One particular case of interest is when i = 0: in this case the mean predicted number of hurricanes is
created entirely from the possibility of the rate being higher than the most likely estimate of the rate.
The fourth interesting implication is the variance of the forecast.
The variance can be calculated as:

variance =

−λm(mλ)i+αλ2dλ

e

m
(i + α)!

Z

Z
m1+α+i
(i + α)!
m1+α+i
(i + α)!
1
m2

=

=

=

λi+α+2e

−λmdλ

−s

e

s
m

i+α+2 ds
m

Z
(i + α + 2)!
(i + α)!

(cid:16)

(cid:17)

This is larger than the variance of the classically ﬁtted poisson, which is i
to the mean is not 1, as it is for the poisson, but is greater than 1.
The ﬁfth interesting implication is that we now have a non-trivial distribution for the possible number
of future hurricanes, even in the case when i = 0, given by:

m2 , and the ratio of the variance

2

p(n|i = 0) =

(i + α + n)!
(i + α)!n!

m
m + 1

i+α+1

=

(α + n)!
(α)!n!

(cid:19)
α+1

(cid:18)
m
m + 1

(cid:18)

1
m + 1

(cid:18)

(cid:19)

(cid:18)

(cid:19)

n

1
m + 1
n

(cid:19)

So, interestingly, even if there have never been any hurricanes in the past, this method still predicts a
non-zero probability for hurricanes in the future. This seems reasonable: since m is ﬁnite, we can’t rule
out the possibility that we haven’t just been very lucky over the last m years and avoided any hurricane
strikes.

5 Numerical comparison

In this section, we perform a numerical comparison of forecasts from the classical and Bayesian methods,
for diﬀerent values of i. We ask the question: how much diﬀerence does it really make to the ﬁnal
probabilities we predict if we use the Bayesian method? We have already seen that for i = 0 there is a
big diﬀerence between the two methods (the classical method predicts zero probabilities for n > 0, while
the Bayesian methods predict non-zero probabilities) but what about for larger values of i?. Figure 3
shows predictive distributions from the classical and Bayesian methods, for m = 54, and values of i of
1,5, 10 and 20. We see large diﬀerences between the classical and Bayesian methods for all the values
of i tested. The Bayesian methods give a ﬂatter, broader distribution, as expected, and the probability
of extreme numbers of hurricanes is much higher. The diﬀerences between the two Bayesian methods,
however, are much smaller, with the α = 0 method giving a slightly ﬂatter, broader distribution.
At this point, we weigh up the pros and cons of the two priors that we are still considering, and make
a decision as to which to use. In favour of the α = −1/2 prior, there is a piece of (slightly esoteric)
theoretical reasoning related to the Fisher information and transformations of scale. In favour of the
α = 0, we have that:

• a ﬂat prior in λ reﬂects our desire to avoid having the prior inﬂuence the ﬁnal result, while the

α = −1/2 prior weights towards lower values of λ

(39)

(40)

(41)

(42)

(43)

(44)

• the ﬂat prior gives an intuitively reasonable value of the most likely value of λ, while the α = −1/2

gives a most likely value that conﬂicts with intuition

• the mathematics is simpler

• the diﬀerences between forecasts made by the two priors is very small (relative to the diﬀerence

between classical and Bayesian priors)

• it is slightly more conservative (i.e. gives wider distributions)

Based on this we conclude that we prefer the α = 0 prior.
For convenience, we now summarise the key properties of this prior.

5.1 Summary of properties for the uniform prior

posterior =

−λm(mλ)i

e

prior = m
m
i!
(i + n)!
(i+)!n!
i + 1
m

predictive probability =

forecast mean =

forecast variance =

(i + 1)(i + 2)
m2

i
m

maximum of the posterior =

m
m + 1

i+1

n

1
m + 1

(cid:18)

(cid:19)

(cid:18)

(cid:19)

6 Scoring probabilistic forecasts

We now change tack slightly, and consider how one might evaluate a prediction of the distribution of
the number of hurricanes. The scoring system we will use is based on the out-of-sample log-likelihood,
which we have previously discussed and used in a number studies, such as Jewson and Penzer (2006).
We believe this is the most obvious score to use for comparing probabilistic forecasts, and it is closely
related to a large body theory concerning the cross-entropy and the Kullback-Leibler divergence.
The out-of-sample likelihood is deﬁned loosely as the expectation of the log of the probability of the
observations given the forecast. This is only a loose deﬁnition because to make it precise we need to
specify what we mean by expectation, and there are several possibilities. This is discussed in more detail
in Jewson and Penzer (2006). In this section we will deﬁne the expectation as being over all future values,
holding the historical data (the value of i) ﬁxed, and over all possible values for the unknown parameters
(this is the score S3 in Jewson and Penzer (2006)).
For the classical prediction methods, the score is:

S3 =

mg(λm, i)

g(λ, n) log g

, n

dλ

Z

 

n
X

= m

g(λm, i)g(λ, n) log g

, n

dλ

i
m

i
m

(cid:18)

(cid:18)

(cid:19)!

(cid:19)

(cid:19)

= m

log g

, n

g(λm, i)g(λ, n)dλ

= m

log g

, n

e−λm(λm)i
i!

e−λλn
n!

dλ

log g

, n

−λ(m+1)λi+ndλ

e

n (cid:18)Z
X

n
X

n
X

=

=

=

n
X

n
X

n
X

log g

, n

−λλi+ndλ

e

log g

, n

(i + n)!

i+n+1

Z

i+n+1

Z

(cid:18)

(cid:18)

1
m + 1

1
m + 1

(cid:19)

(cid:19)

i
m

i
m

(cid:18)

(cid:18)
i
m

i
m

i
m

(cid:18)

(cid:18)

(cid:18)

(cid:19) Z

(cid:19) Z
mi+1
i!n!

mi+1
i!n!

mi+1
i!n!

(cid:19)

(cid:19)

(cid:19)

(45)

(46)

(47)

(48)

(49)

(50)

(51)

(52)

(53)

(54)

(55)

(56)

(57)

(58)

(59)

(63)

=

log g

n
X

i
m

, n

(cid:18)

(cid:19)

(i + n)!
i!n!

m
m + 1

i+1

n

1
m + 1

(cid:18)

(cid:19)

(cid:18)

(cid:19)

For the Bayesian prediction method the score is:

S3 =

mg(λm, i)

g(λ, n)log

Z

m

Z
mi+1
i!

mi+1
i!

n
X

 
e−λm(λm)i
i!

"
e−λλn
n!

 

n
X
(i + n)!
i!n!

(i + n)!
i!n!

1
n!

1
n!

log

log

"

"

n
X

n
X

i+1

m
m + 1

(cid:18)

(cid:19)

n (cid:18)
X

1
m + 1

i+1

n

1
m + 1

(cid:18)
i+1

#!
n

(cid:19)
1
m + 1

(cid:19)

(cid:18)

#!

(cid:19)

(cid:19)
m
m + 1

(i + n)!
i!n!

m
m + 1

(cid:18)

(i + n)!
i!n!

log

"

i+1

m
m + 1

(cid:19)

(cid:18)

i+1

(cid:18)
1
m + 1

n

n

(cid:19)

# Z

i+n+1

m
m + 1

(cid:19)
n (i + n)!
i!n!

1
m + 1

(cid:19)
(i + n)!
i!n!

(cid:18)

log

"

1
m + 1

# (cid:18)

m
m + 1

(cid:19)
i+1

(cid:18)

(cid:19)

(cid:18)

1
m + 1

n

#

(cid:19)

(cid:18)

(cid:18)

(cid:19)

=

=

=

=

dλ

(60)

−(m+1)λλn+idλ

e

(61)

(i + n)!

(62)

We now plot these scores (the classical forecast score and the Bayesian forecast score) for m = 54 and
for a few values of i, in ﬁgure 4. We see that the Bayesian score always beats the classical score, but the
diﬀerence between the scores reduces as i increases.

7 Empirical comparison

Finally, we compare the classical and Bayes prediction methods for real data. Our comparison is based
on a carefully constructed cross-validation procedure (the Quenouille-Tukey jackknife) to make it as fair
and realistic as possible. It works as follows:

• we loop over the 54 years of data, missing out each year in turn

• we ﬁt the two models to the remaining 53 years of data

• we calculate the log of the probability of the 54th year of data for both models

• we average together the logs of the probabilities over the 54 years

• we repeat this for each of our 39 gates along the US coastline

The scoring system being used can be considered as an empirical version of the predictive log-likelihood
score that we use in section 6, where the expectation is now over the loop in the jackknife (which doesn’t,
however, correspond exactly to the deﬁnition of expectation used in section 6).
Results from this comparison are shown in ﬁgure 5. We see that the Bayesian method beats the classical
method for each one of the 39 gates. The diﬀerence are largest for the segments where there are fewest
hurricanes, as we’d expect.
Finally, ﬁgure 6 shows the actual probabilities predicted for the occurrence of 1 hurricane by gate for the
classical and Bayesian methods. We see that the probabilities are mostly reasonable similar, but that big
diﬀerences occur where there are very few historical hurricanes.

8 Discussion

We have discussed the question of how to predict the distribution of the number of hurricanes crossing
segments of the US coastline. We have taken a very simple approach based on the assumptions that events
are independent, and that the underlying poisson rates are constant in time. This simple framework
allows us to compare classical and Bayesian statistical methods in some detail. We derive expressions
for the classical and Bayesian forecasts, and further expressions for their performance under an expected
predictive log-likelihood scoring system. At a theoretical level we ﬁnd that the Bayesian method performs
better. We then test our classical and Bayesian prediction methods on real hurricane data, using a jack-
knife cross-validation scheme. We ﬁnd that the Bayesian method does better in practice too, but that

again the diﬀerences in the forecasts are only signiﬁcant for those sections of coastline with very low
historical hurricane rates.
The next stage of our research is to compare these forecasts of landfall rates with forecasts derived from
the basin-wide track model we have described in a series of recent papers (Hall and Jewson, 2005).

References

T Hall and S Jewson. Statistical modelling of tropical cyclone tracks part 6: non-normal innovations.

arXiv:physics/0512135, 2005.

S Jewson and J Penzer. Weather derivative pricing and the normal distribution: ﬁtting the variance to

maximise expected predictive log-likelihood. http://ssrn.com/abstract=911569, 2006.

Figure 1: The observed numbers of hurricanes crossing 39 straight-line segments approximating the
North American coastline, for the period 1950-2003.

0 2 4 6 8

0 2 4 6 8

lambda

lambda

y
t
i
s
n
e
d

y
t
i
s
n
e
d

0
3
.
0

5
1
.
0

0
0
.
0

0
3

.

0

5
1

.

0

0
0

.

0

y
t
i
s
n
e
d

y
t
i
s
n
e
d

0
3
.
0

5
1
.
0

0
0
.
0

0
3

.

0

5
1

.

0

0
0

.

0

0 2 4 6 8

0 2 4 6 8

lambda

lambda

Figure 2: The posterior density for the poisson rate, given 54 years of data and 0,2,4 and 6 observed
hurricanes making landfall over that 54 year period.

0 5

15

25

0 5

15

25

obs. no. of hu=1

obs. no. of hu=5

y
t
i
s
n
e
d
 
d
e
t
c
d
e
r
p

i

y
t
i
s
n
e
d

 

i

d
e
t
c
d
e
r
p

4
.
0

2
.
0

0
.
0

0
1

.

0

0
0

.

0

y
t
i
s
n
e
d
 
d
e
t
c
d
e
r
p

i

y
t
i
s
n
e
d

 

i

d
e
t
c
d
e
r
p

0
2
.
0

0
1
.
0

0
0
.
0

8
0

.

0

4
0

.

0

0
0

.

0

0 5

15

25

0 5

15

25

obs. no. of hu=10

obs. no. of hu=20

Figure 3: Predictions of future hurricane numbers, based on either 1, 5, 10 or 20 historical hurricanes
making landfall in a 54 year period. The solid line shows classical predictions and the dotted line shows
Bayesian predictions.

classical / bayesian score

S3 score

1.00 1.10 1.20

−0.8

−0.4

i

2
0

i

2
0

0

1
0

3
0

4
0

F
i
g
u
r
e

4
:

T
h
e
o
r
e
t
i
c
a
l

s
c
o
r
e
s

f
r
o
m

t
h
e
B
a
y
e
s
i
a
n

a
n
d

c
l
a
s
s
i
c
a
l

p
r
e
d
i
c
t
i
o
n
s
.

0

1
0

3
0

4
0

Figure 5: Performance of the classical and Bayesian prediction methods, evaluated using cross-validation,
for the number of hurricanes crossing our 39 coastline segments. The score is the out-of-sample expected
predictive log-likelihood. The top right panel shows the score for the classical prediction, the middle
right panel shows the score for the Bayesian prediction, and the bottom right panel shows the diﬀerence
between the two. We see that the Bayesian method wins for every segment.

Figure 6: Probabilities of one hurricane making landfall in a year, from classical and Bayesian predictions.
The top panel shows the probabilities themselves (classical=cirles, Bayesian=squares). The middle panel
shows the diﬀerences, and the bottom panel shows the diﬀerences divided by the classical probabilities.
In the bottom panel values of 2 are actually inﬁnity. We see that the Bayesian probabilities are all higher,
although only by a small absolute amount. The relative diﬀerences are also small for most gates, except
where there are either no historical hurricanes, or a very small number of historical hurricanes.

predicted density

0.0

0.1

0.2

0.3

0.4

o
b
s
.
 
n
o
.
 
o
f
 
h
u
=
1

0

5

1
0

1
5

2
0

2
5

3
0

predicted density

0.00

0.05

0.10

0.15

0.20

o
b
s
.
 
n
o
.
 
o
f
 
h
u
=
5

0

5

1
0

1
5

2
0

2
5

3
0

predicted density

0.00

0.05

0.10

0.15

o
b
s
.
 
n
o
.
 
o
f
 
h
u
=
1
0

0

5

1
0

1
5

2
0

2
5

3
0

predicted density

0.00

0.02

0.04

0.06

0.08

0.10

o
b
s
.
 
n
o
.
 
o
f
 
h
u
=
2
0

0

5

1
0

1
5

2
0

2
5

3
0

