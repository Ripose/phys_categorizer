6
0
0
2
 
r
p
A
 
9
1
 
 
]
h
p
-
o
a
.
s
c
i
s
y
h
p
[
 
 
1
v
8
5
1
4
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Rainfall Advection using Velocimetry by
Multiresolution Viscous Alignment ∗

Sai Ravela
Earth, Atmospheric and Planetary Sciences
Virat Chatdarong
Civil and Environmental Engineering
Massachusetts Institute of Technology
ravela@mit.edu

April 10, 2006

Abstract

An algorithm to estimate motion from satellite imagery is presented.

Dense displacement ﬁelds are computed from time-separated images of of

signiﬁcant convective activity using a Bayesian formulation of the motion

estimation problem. Ordinarily this motion estimation problem is ill-posed;

there are far too many degrees of freedom than necessary to represent the

motion. Therefore, some form of regularization becomes necessary and by

imposing smoothness and non-divergence as desirable properties of the es-

timated displacement vector ﬁeld, excellent solutions are obtained. Our ap-

proach provides a marked improvement over other methods in conventional

∗This material is supported in part by NSF ITR 0121182 and DDDAS 0540259.

1

1 INTRODUCTION

2

use.

In contrast to correlation based approaches, the displacement ﬁelds

produced by our method are dense, spatial consistency of the displacement

vector ﬁeld is implicit, and higher-order and small-scale deformations can

be easily handled. In contrast with optic-ﬂow algorithms, we can produce

solutions at large separations of mesoscale features between large time-steps

or where the deformation is rapidly evolving.

1 Introduction

Environmental data assimilation is the methodology for combining imperfect model

predictions with uncertain data in a way that acknowledges their respective un-

certainties. The proper framework for state estimation includes sequential [15],

ensemble-based [14] and variational [20, 5] methods.

The difﬁculties created by improperly represented error are particularly appar-

ent in mesoscale meteorological phenomena such as thunderstorms, squall-lines,

hurricanes, precipitation, and fronts. We are particularly interested in rainfall data-

assimilation, where rainfall measurements from satellite data, radar data, or in-situ

measurements are used to condition a rainfall model. Such conditional simula-

tions are valuable both for producing estimates at the current time (nowcasting),

as well as for short-term forecasting.

There are a countless number of models developed to simulate the rainfall

process. In general, there are two types of models that can deal with spatial and

1 INTRODUCTION

3

temporal characteristics of rainfall. The ﬁrst category is the meteorological model

or the quantitative precipitation forecasting model. It involves a large, complex

set of differential equations seeking to represent complete physical processes con-

trolling rainfall and other weather related variables. Examples of these models in-

clude the ﬁfth-generation Mesoscale Model (MM5) [3, 4, 16], the step-mountain

Eta coordinate model [1, 2, 13], and the Regional Atmospheric Modeling System

(RAMS) [7, 12], etc. The second type is the spatiotemporal stochastic rainfall

model. It aims to summarize the spatial and temporal characteristics of rainfall by

a small set of parameters [6, 18, 11, 8, 22, 25]. This type of model usually sim-

ulates the birth and decay of rain-cells and evolve them through space and time

using simple physical descriptions. Despite signiﬁcant differences among these

rainfall models, the concept of propagating rainfall through space and time are

relatively similar.

The major ingredient required to advect rainfall is a velocity ﬁeld. Large

spatial-scale (synoptic) winds are inappropriate for this purpose for a variety of

reasons. Ironically, synoptic observations can be sparse to be used directly and

although synoptic-scale wind analyses produced from them (and models) do pro-

duce dense spatial estimates, such estimates often do not contain variability at the

meso-scales of interest. The motion of mesoscale convective activity is a natural

source for velocimetry. Indeed, there exist products that deduce “winds” by esti-

mating the motion of temperature, vapor and other ﬁelds evolving in time [9, 10].

1 INTRODUCTION

4

In this paper, we present an algorithm for velocimetry from observed motion

from satellite observations such as GOES, AMSU, TRMM, or radar data such as

NOWRAD. This algorithm follows from a Bayesian formulation of the motion es-

timation problem, where a dense displacement ﬁeld is estimated from two images

of cloud-top temperature of rain-cells separated in time. Ordinarily, the motion

estimation problem is ill-posed, because the displacement ﬁeld has far too many

degrees of freedom than the motion. Therefore, some form of regularization be-

comes necessary and by imposing smoothness and non-divergence as desirable

properties of the estimated displacement vector ﬁeld solutions can be obtained.

This approach provides marked improvement over other methods in conven-

tional use. In contrast to correlation based approaches used for deriving velocity

from GOES imagery, the displacement ﬁelds are dense, quality control is implicit,

and higher-order and small-scale deformations can be easily handled. In contrast

with optic-ﬂow algorithms [21, 17], we can produce solutions at large separa-

tions of mesoscale features between large time-steps or where the deformation is

rapidly evolving.

After formulating the motion estimation problem and providing a solution,

we extend the algorithm using a multi-resolution procedure. The primary ad-

vantage of a multi-resolution approach is to produce displacement ﬁelds quickly.

The secondary advantage is to structure the estimation homotopically; coarse or

low-frequency information is used ﬁrst to produce velocity estimates over which

2 RELATEDWORK

5

deformation adjustments from ﬁner-scale structures is superposed. The result is a

powerful algorithm for velocimetry by alignment. As such, it is useful in a variety

of situations including, for example, (a) estimating winds, (b) estimating transport

of tracers, (c) Particle Image Velocimetry, (d) Advecting Rainfall models etc.

2 Related Work

There are two dominant approaches to computing ﬂow from observations directly.

The ﬁrst is correlation-based and the second is based on optic ﬂow.

In correlation based approaches [19], a region of interest (or patch) is identiﬁed

in the ﬁrst image and correlated within a search window in the second image. The

location of the best match is then used to compute a displacement vector. When

the input image or ﬁeld is tiled, possibly overlapping, and regions of interest are

extracted from each tile location, the result is velocimetry at regular intervals and

is most commonly used for Particle Image Velocimetry (PIV). In certain instances

it is useful to deﬁne interest-points or salient features around which to extract re-

gions of interest. In particular, if the ﬁeld has many areas with negligible spatial

variability, then matches are undeﬁned. As a quality control measure then, match-

ing is restricted only to those regions of interest that have interesting variability,

or interest points.

There are several disadvantages to correlation-based approaches. First, by

2 RELATEDWORK

6

construction it is assumed that the entire ROI purely translates from one image to

the other. This is not always the case, but is a reasonable approximation when the

right length scale can be found. However, when higher-order deformations (shears

for example) are present, correlation based approaches cannot be expected to work

well. Second, correlation based approaches assume that a unique match can be

found in a way that is substantially better than correlation elsewhere. This is only

true if the features are well-deﬁned and identiﬁed. Third, there is no implicit con-

sistency across regions of interest in correlation-based ﬂow. Neighboring regions

of interest can and often do match at wildly different and inconsistent locations.

This calls for a signiﬁcant overhead in terms of quality control. Fourth, it is not

clear how the search window size (that is the area over which a region of interest

is matched in the subsequent frame) is determined. This window size varies both

in space (as the velocity varies spatially) and time (as velocity varies with time).

A larger search window portends a larger probability to miss the real target, and

a smaller search window can lead to false negatives or false positives. Finally,

where interest points are used as a preprocessing step to correlation, the velocity

ﬁeld produced is necessarily sparse, and therefore, leaves hanging the question of

how to produce dense ﬂow ﬁelds. Our proposed algorithm handles all these issues

in a simple and direct way.

More closely related to the proposed approach is optic ﬂow [21, 17]. This

method arises from what is known as the brightness constraint equation, which

7

(1)

(2)

2 RELATEDWORK

is a statement of conservation of brightness (intensity) mass, expressed by the

continuity equation evaluated at each pixel or grid node of X.

∂X
∂t

+ q · ∇X = 0

Here X is the brightness or intensity scalar ﬁeld and q a displacement vector-

ﬁeld. Solutions to the optic ﬂow equation can be formulated using the well-known

method by [21], which can be stated as a solution to the following system of

equations:

(∇X)(∇X)T q = −(∇X)

∂X
∂t

The right-hand side is completely determined from a pair of images and the

coefﬁcient or stiffness matrix on the left-hand side is the second-derivative of the

auto correlation matrix, also known as the windowed second-moment matrix, or

Harris interest operator, which is sensitive to “corners” in an image. This formula-

tion arises directly from a quadratic formulation, which can in turn be synthesized

from a Bayesian formulation under a Gaussian assumption. Thus, we can write

that we seek to minimize

J(q) = ||X(r − q) − Y ||

(3)

2 RELATEDWORK

8

Then solve this problem via the Euler-Lagrange equation:

∂J(q)
∂q

= ∇X|r−q(X(r − q) − Y ) = 0

(4)

The solution is obtained by linearizing (4), that is,

∇X|r−q(X(r) − ∇X · q − Y ) = 0

∇X(∇X)T q = −∇X(Y − (X(r))

(5)

There are several disadvantages to this algorithm. First, much like correlation

with feature detection, equation 5 is evaluated at pixels where the second-moment

matrix is full-rank, which corresponds to locations where features are present.

There is no clear way of propagating information obtained at sparse locations to

locations where direct computation of displacement is not possible due to poor

conditioning of the second-moment matrix. For the same reason, it cannot han-

dle tangential ﬂows. The brightness constraint equation can only represent ﬂows

along brightness streamlines. When tangential motion is present, detected mo-

tion at extreme ends a moving curve cannot be propagated easily into the interior.

Our method provides some degree of spatial smoothness common in geophysical

ﬂuid transport, and uses regularization constraints to propagate ﬂow information

to nodes where feature strengths are weak.

Second, the linearization implicit in (5) precludes large displacements; struc-

tures must be closely overlapping in successive images, which can also be seen

3 VELOCIMETRYBYFIELDALIGNMENT

9

from the continuity equation (1). Therefore, this method is very useful for densely

sampled motion, such as ego-motion resulting from a moving, jittering camera,

but is not as useful for sparsely sampled ﬂow arising from structures moving in a

scene. In the latter case, to ameliorate the effects of large expected displacement,

multi-resolution approaches have been proposed. Even so, much like determining

the size of the search window in correlation, determining the number of resolu-

tions is an ad-hoc procedure. Our method can handle large displacements and

we also propose a multi-resolution approach, but the primary motivation there is

improved computational speed.

3 Velocimetry by Field Alignment

The main approach consists of solving a nonlinear quadratic estimation problem

for a ﬁeld of displacements. Solutions to this problem are obtained by regularizing

the an ill-posed inverse problem. The material presented in this section is derived

directly from work by Ravela [24], and Ravela et al. [23]. Here we reformulate

their original formulation to allow only position adjustments.

To make this framework more explicit it is useful to introduce some nota-

tion. Let X = X(r) = {X[rT

1 ] . . . X[rT

m]} be the ﬁrst image, written as a vec-

tor, deﬁned over a spatially discretized computational grid Ω, and rT = {ri =

(xi, yi)T , i ∈ Ω} be the position indices. Let q be a vector of displacements, that

3 VELOCIMETRYBYFIELDALIGNMENT

10

is qT = {qi = (∆xi, ∆yi)T , i ∈ Ω}. Then the notation X(r − q) represents

displacement of X by q. The displacement ﬁeld q is real-valued, so X(r − q)

must be evaluated by interpolation if necessary. It is important to understand that

this displacement ﬁeld represents a warping of the underlying grid, whose effect

is to move structures in the image around, see Figure 1.

Figure 1: A graphical illustration of ﬁeld alignment. State vector on a discretized
grid is moved by deforming its grid (r) by a displacement (q).

In a probabilistic sense, we may suppose that ﬁnding q that has the maximum

a posteriori probability in the distribution P (q|X , Y) is appropriate. Without loss

of generality, X is a random variable corresponding to the image or ﬁeld at a given

time and Y is random variable for a ﬁeld at a future time. Using Bayes rule we

3 VELOCIMETRYBYFIELDALIGNMENT

11

obtain P (Q = q|X = X, Y = Y ) ∝ P (Y = Y, X = X|q)P (q). If we make a

Gaussian assumption of the component densities, we can write:

P (X, Y |q) =

1

n

e− 1

1
2

(2π)

2 |R|

T
2 (Y −X(r−q))

R−1(Y −X(r−q))

(6)

This equation says that the observations separated in time can be related using

a Gaussian model to the displaced state X(r- q), where X(r) is deﬁned on the

original grid, and q is a displacement ﬁeld. We use the linear observation model

here, and therefore, Y = HX(r − q) + η, η ∼ N(0, R).. We should emphasize

here that the observation vector is ﬁxed. It’s elements are always deﬁned from

the original grid. In fully observed ﬁelds, H is an identity matrix, and for many

applications R, reﬂecting the noise in the ﬁeld, can also be modeled as an identity

matrix.

P (q) =

e−L(q)

1
C

(7)

This equation speciﬁes a displacement prior. This prior is constructed from

an energy function L(q) which expresses constraints on the displacement ﬁeld.

The proposed method for constructing L is drawn from the nature of the expected

displacement ﬁeld. Displacements can be represented as smooth ﬂow ﬁelds in

many ﬂuid ﬂows and smoothness naturally leads to a Tikhonov type formulation

12

(8)

3 VELOCIMETRYBYFIELDALIGNMENT

[26] and, in particular, L(q) is designed as a gradient and a divergence penalty

term. These constraints, expressed in quadratic form are:

L(q) =

w1
2 X
j∈Ω

tr{[∇qj][∇qj]T } +

w2
2 X
j∈Ω

[∇ · qj]2

In Equation 8, qj refers to the jth grid index and tr is the trace. Equation 8 is

a weak constraint, weighted by the corresponding weights w1 and w2. Note that

the constant C can be deﬁned to make Equation 7 a proper probability density. In

particular, deﬁne Z(q) = e−L(q) and deﬁne C =

Z(q)dq. This integral exists

Rq

and converges.

With these deﬁnitions of probabilities, we are in a position to construct an

objective by evaluating the log probability. We propose a solution using Euler-

Lagrange equations. Deﬁning p = r − qThese can be written as:

∂J
∂q

= ∇X|pH T R−1 (H X (p) − Y ) +

(9)

∂L
∂q

= 0

Using the regularization constraints ( 9) at a node i now becomes:

w1∇2qi + w2∇(∇ · qi) + h∇X f T |pH T R−1

(cid:16)H hX f (p)i − Y (cid:17)ii

= 0

(10)

Equation 10 is the ﬁeld alignment formulation. It introduces a forcing based

on the residual between the model- and observation-ﬁelds. The constraints on the

3 VELOCIMETRYBYFIELDALIGNMENT

13

displacement ﬁeld allow the forcing to propagate to a consistent solution. Equa-

tion 10 is also non-linear, and is solved iteratively, as a Poisson equation. During

each iteration q is computed by holding the forcing term constant. The estimate of

displacement at each iteration is then used to deform a copy of the original fore-

cast model-ﬁeld using bi-cubic interpolation for the next iteration. The process

is repeated until a small displacement residual is obtained, the misﬁt with obser-

vations does not improve, or an iteration limit is reached. Upon convergence, we

have an aligned image X(ˆp), and a displacement ﬁeld ˆq =

q(d), for individual

N

Pd=1

displacements q(d) at iterations d = 1 . . . D

3.1 Multi-resolution Alignment and Velocimetry

The convergence of solution to the alignment equation is super-linearly dependent

on the expected displacement between the two ﬁelds. Therefore, it is desirable to

solve it in a coarse-to-ﬁne manner, which serves two principal advantages. The

ﬁrst, as the following construction will show, is to substantially speed-up the time

to alignment because decimated (or coarse-resolution) representations of a pair of

ﬁelds has smaller expected displacement than a pair at ﬁner resolution.

Second, decimation or resolution reduction also implies that ﬁner structure or

higher spatial frequencies will be attenuated. This smoothness in the coarsened-

ﬁeld intensities directly translates to smoothness in ﬂow-ﬁelds using ( 9). Thus, a

3 VELOCIMETRYBYFIELDALIGNMENT

14

coarse-to-ﬁne method for alignment can incrementally add velocity contributions

from higher-frequencies, that is it incrementally incorporates higher-order vari-

ability in the displacement ﬁeld. Many of the advantages of a multi-resolution

approach have been previously explored in the context of visual motion estima-

tion, including the famous pyramid algorithm and architecture for matching and

ﬂow and our implementation borrows from this central idea.

Figure 2: The multi-resolution algorithm is shown for two-levels and requires ﬁve
steps, labeled (1) through (5). See text for explanation.

The multi-resolution algorithm is depicted in Figure 2 for two levels. The

4 EXAMPLE

15

input images X and Y are decimated to generate coarse resolution images X1

and Y1 respectively (step 1). Let us suppose that this scaling is by a factor of

0 < s < 1 (most commonly s = 0.5). Displacement is computed for this level

ﬁrst, and let us call this ˆq1 (step 2). This displacement ﬁeld is downscaled by

a factor of s, using simple (bicubic) interpolation, to produce a prior estimate of

displacement at level 0, written ˆq10 = s−1ˆq0(s−1r) (step 3). The source image at

level 0, that is X0 = X is displaced by ˆq10 (step 4) and thus X(r − ˆq10) is aligned

with Y0 to produce a displacement estimate ˆq0 (step 5). The total displacement

relating source image X with target ﬁeld Y is simply ˆq0 + ˆq10. Multiple levels

of resolution can be implemented from this framework recursively.

4 Example

Figure 3: CIMSS Winds derived from GOES data at 2006-04-06-06Z (left) and
pressure (right). The velocity vectors are sparse and contain signiﬁcant diver-
gence.

4 EXAMPLE

16

Figure 4: CIMSS Winds derived from GOES data at 2006-04-06-09Z (left) and
pressure (right). The velocity vectors are sparse and contain signiﬁcant diver-
gence.

The performance of this algorithm is illustrated in a velocimetry computation.

To compare, we use CIMSS wind-data satellite data [10], depicted in Figure 3, and

Figure 4 obtained from CIMSS analysis on 2006-06-04 at 06Z and 09Z respec-

tively. CIMSS wind-data is shown over the US great plains, and were obtained

from the ’sounder.’ The red dots indicate the original location of the data. The left

subplot shows wind speed (in degree/hr). The right ones show pressure, and the

location of raw measurements in red.

It can be seen in the maps shown in Figure 3 and Figure 4 that current method

to produce winds generate sparse vectors and, further, has substantial divergence.

Whilst this can be thought of as accurately representing turbulence, in reality these

vectors are more likely the result of weak quality control. The primary methodol-

ogy used here is to identify features in an image, extract regions of interest around

4 EXAMPLE

17

them and search for them in subsequent frames. This, by deﬁnition produces

sparse velocity estimates (features are sparse), leaving unanswered how to sys-

tematically incorporate appropriate spatial interpolation functions for the velocity.

Since regions of interest are essentially treated as being statistically independent,

mismatches can produce widely varying displacement vectors. Such mis-matches

can easily occur in correlation based approaches when the features are not distin-

guishing or substantial deformations occur from one time to another in a region

of interest. A more detailed discussion is presented in Section 2.

In contrast, our method produces dense ﬂow ﬁelds, and quality control is im-

plicit from regularization constraints. Figure 5(a,b) shows a pair of NOWRAD

images at 2006-06-01-0800Z and 2006-06-01-0900Z respectively, and the com-

puted ﬂow ﬁeld in Figure 5(c). Similarly, Figure 5(d,e,f) show the GOES images

and velocity from the same time frame over the deep convective rainfall region in

the Great Plains example. The velocities are in good agreement with CIMSS de-

rived winds where magnitudes are concerned, but the ﬂow-ﬁelds are smooth and

visual conﬁrmation of the alignment provides convincing evidence that they are

correct.

5 CONCLUSIONS

5 Conclusions

18

Our method is a Bayesian perspective of the velocimetry problem. It has several

distinct advantages: (a) It is useful for a wide range of observation modalities.

(b) Our approach does not require features to be identiﬁed for computing velocity.

This is a signiﬁcant advantage because features cannot often be clearly delineated,

and are by deﬁnition sparse. (c) Our approach implicitly uses quality control in

terms of smoothness, and produces dense ﬂow-ﬁelds. (d) our approach can be

integrated easily with current operational implementations, thereby making this

effort more likely to have a real impact. Finally, it should be noted that the reg-

ularization constraint in ﬁeld alignment is a weak constraint and the weights de-

termine how strongly the constraints inﬂuence the ﬂow ﬁeld. The constraint in L

is modeled as such because we expect the ﬂuid ﬂow to be smooth. From a reg-

ularization point of view, there can be other choices [27] as well. The proposed

method can be used for a variety of velocimetry applications including PIV, ve-

locity from tracer-transport, and velocity from GOES and other satellite data, and

an application of this is to advect rain-cells produced by a rainfall model, with

realistic wind-forcing.

REFERENCES

References

19

[1] T. L. Black. The new nmc moesoscale eta model: Description and forecast

examples. Weather and Forecasting, 9(2):265–278, 1994.

[2] T. L. Black, D. Deaven, and G. DiMego. The step-mountain eta coordinate

model: 80 km early version and objective veriﬁcations. NWS/NOAA Tech.

Procedures Bull., 1993. 412: p. 31., 412:31, 1993.

[3] F. Chen and J. Dudhia. Coupling an advanced land surface-hydrology model

with the penn state-ncar mm5 modeling system. part i: Model implementa-

tion and sensitivity. Monthly Weather Review, 129(4):569–585, 2001.

[4] F. Chen and J. Dudhia. Coupling an advanced land surface-hydrology model

with the penn state-ncar mm5 modeling system. part ii: Preliminary model

validation. Monthly Weather Review, 129(4):587–604, 2001.

[5] P. Courtier. Variational methods. J. Meteor. Soc. Japan, 75, 1997.

[6] P. Cowpertwait. Further developments of the neyman-scott clustered point

process for modeling rainfall. Water Resource Research, 27(7), 1991.

[7] A. Orlandi et al. Rainfall assimilation in rams by means of the kuo parame-

terisation inversion: Method and preliminary results. Journal of Hydrology,

288(1-2):20–35, 2004.

REFERENCES

20

[8] C. Onof et al. Rainfall modelling using poisson-cluster processes: A review

of developments. Stochastic Environmental Research and Risk Assessment,

2000.

[9] C. S. Velden et al. Upper-tropospheric winds derived from geostationary

satellite water vapor observations. Bulletin of the American Meteorological

Society, 78(2):173–195, 1997.

[10] C. Velden et al. Recent innovations in deriving tropospheric winds from

meteorological satellites. Bulletin of the American Meteorological Society,

86(2):205–223, 2005.

147, 2005.

[11] H. Moradkhani et al. Dual state-parameter estimation of hydrological mod-

els using ensemble kalman ﬁlter. Advances in Water Resources, 28(2):135–

[12] R. A. Pielke et al. A comprehensive meteorological modeling system rams.

Meteorology and Atmospheric Physics, 49(1-4):69–91, 1992.

[13] R. Rogers et al. Changes to the operational ”early” eta analysis forecast

system at the national centers for environmental prediction. Weather and

Forecasting, 11(3):391–413, 1996.

[14] G. Evensen. The ensemble kalman ﬁlter: Theoretical formulation and prac-

tical implementation. Ocean Dynamics, 53:342–367, 2003.

REFERENCES

21

[15] A. Gelb. Applied Optimal Estimation. MIT Press, 1974.

[16] G. Grell, J. Dudhia, and D.R. Stauffer. A description of the ﬁfth genera-

tion penn state/ncar mesoscale model (mm5). Technical Report TN-398+IA,

NCAR, 1993.

[17] D. J. Heeger. Optical ﬂow from spatiotemporal ﬁlters. International Journal

of Computer Vision, pages 279–302, 1988.

[18] M. N. Khaliq and C. Cunnane. Modelling point rainfall occurrences with

the modiﬁed bartlett-lewis rectangular pulses model. Journal of Hydrology,

180(1):109–138, 1996.

[19] D. T. Lawton. Processing translational motion sequences. Computer Vision,

Graphics and Image Processing, 22:116–144, 1983.

[20] A. C. Lorenc. Analysis method for numerical weather predictin. Q. J. R.

Meteorol. Soc., 112:1177–1194, 1986.

[21] H.-H Nagel. Displacement vectors derived from second order intensity vari-

ations in image sequences. Computer Vision, Graphics and Image Process-

ing, 21:85–117, 1983.

REFERENCES

22

[22] T. M. Over and V. K. Gupta. A space-time theory of mesoscale rainfall

using random cascades. Journal of Geophysical Research, 101(D21):319–

332, 1996.

497–505, 2006.

[23] S. Ravela. Amplitude-position formulation of data assimilation. In ICCS

2006, Lecture Notes in Computer Science, number 3993 in Part III, pages

[24] S. Ravela, K. Emanuel, and D. McLaughlin. Data assimilation by ﬁeld align-

ment. Physica (D) - to appear, 2006.

[25] I. Rodriguez-Iturbe, D.R. Cox, and V. Isham. A point process model for

rainfall: Further developments. Proceedings of the Royal Society of London.

Series A, Mathematical and Physical Sciences, 417(1853):283–298, 1988.

[26] A.N. Tikhonov and V. Y. Arsenin. Solutions of Ill-Posed Problems. Wiley,

New York, 1977.

Review, 108, 1980.

[27] G. Wabha and J. Wendelberger. Some new mathematical methods for varia-

tional objective analysis using splines and cross-validation. Monthly Weather

REFERENCES

23

Figure 5: Deriving velocimetry information from satellite observations, Nexrad
(top), GOES (bottom). See text for more information.

