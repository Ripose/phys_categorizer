0
0
0
2
 
v
o
N
 
6
1
 
 
]
h
p
-
m
o
t
a
.
s
c
i
s
y
h
p
[
 
 
1
v
9
3
0
1
1
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Extension of Kohn-Sham theory to excited states by means of an oﬀ-diagonal density
array

Abraham Klein ∗
Department of Physics, University of Pennsylvania, Philadelphia, PA 19104-6396

Reiner M. Dreizler †
Instit¨ut f¨ur Theoretische Physik, Universit¨at Frankfurt, D-60054 Frankfurt
(February 20, 2014)

Early work extending the Kohn-Sham theory to excited states was based on replacing the study of
the ground-state energy as a functional of the ground-state density by a study of an ensemble average
of the Hamiltonian as a functional of the corresponding average density. We suggest and develop
an alternative to this description of excited states that utilizes the matrix of the density operator
taken between any two states of the included space. Such an approach provides more detailed
information about the states included, for example, transition probabilities between discrete states
of local one-body operators. The new theory is also based on a variational principle for the trace of
the Hamiltonian over the space of states that we wish to describe viewed, however, as a functional
of the associated array of matrix elements of the density. It ﬁnds expression in a matrix version of
Kohn-Sham theory. To illustrate the formalism, we study a suitably deﬁned weak-coupling limit and
derive from it an eigenvalue equation that has the form of the random phase approximation. The
result can be identiﬁed with a similar equation derived directly from the time-dependent Kohn-Sham
equation and applied recently with considerable success to molecular excitations. We prove, within
the deﬁned approximations, that the eigenvalues can be interpreted as true excitation energies, a
result not accessible to the time-dependent Kohn-Sham scheme.

31.15.Ew, 32.15.Ne, 31.15.Pf

I. INTRODUCTION

Density functional theory (DFT) was designed originally as a theory of the ground-state density and energy of a
many-particle system [1–5]. For an extension to include the calculation of excitation energies, several lines of thought
have been developed. The earliest one was based on a minimum principle [6,7] for the trace of the Hamiltonian over a
set of the lowest-energy eigenstates of the system. This theory was then extended to a suitably weighted sum over the
same set of eigenstates [8]. The expanded version of the Hohenberg-Kohn theorem, in either case, is that the average
energy is a unique functional of the corresponding average density. Excitation energies are obtained (essentially) by
taking diﬀerences between averages over almost overlapping sets. This approach has not been developed beyond the
cited work.

Recently, considerable attention has been focused on the development of other methods for studying excitation
In this
energies. One powerful approach is based on time-dependent density functional theory (TDDFT) [9–14].
approach, one studies the linear response of the time-dependent density to a time-dependent external ﬁeld. The
Fourier transform of the susceptibility (density-density correlation function), which is the essential ingredient for the
calculation of dynamic polarizabilities, has poles at the true eigenstates of the system. By application of TDDFT one
can derive both a formally exact inhomogeneous integral equation for the correlation function and a related eigenvalue
equation for the excitation energies. Results obtained for simple systems by the approximate solution of this equation
are promising [10,14].

TDDFT has also been applied to the excitation-energy problem in a diﬀerent way, with less `a priori justiﬁcation than
the above method, but with impressive results upon application [15–20]. In this approach, an eigenvalue equation that
has the form of a random phase approximation (RPA) is derived directly from the Kohn-Sham (KS) time-dependent
equation, which we call TDKST, in analogy with the procedure applied to time-dependent Hartree-Fock theory. The

∗aklein@nucth.physics.upenn.edu
†dreizler@th.physik.uni-frankfurt.de

1

interpretation of the eigenvalue as a true excitation energy is taken for granted in the literature cited. One of the
results of the present work is that this interpretation can be justiﬁed for a suitably deﬁned set of excitations.

Finally, we call attention to several recent studies of the excited state problem that involve extensions of the
variationally based KS theory to individual excited states [21,22]. For these methods, as well, applications to simple
systems seem promising. Improved exchange and correlation kernels necessary for all these methods and a connection
with many-body perturbation theory are discussed in [23], whereas in [24] an improved exchange-correlation potential
is utilized to provide more accurate continuum KS orbitals needed for excited state and polarizability calculations.

In this paper, we appear initially to be taking a step backwards by returning to a study of the trace variational
principle [25–27]. Instead of considering the average energy as a functional of the average density, however, we argue
for the introduction of a matrix array of densities, i. e., all matrix elements of the density operator among all states
of the chosen ensemble, and for an investigation of the average energy as a functional of this matrix array. In Sec.
II we present arguments to indicate how the Hohenberg-Kohn (HK) analysis can be extended to this case yielding
a matrix Thomas-Fermi (MTF) equation. We subsequently (Sec. III) generalize the KS analysis, deriving a matrix
Kohn-Sham equation (MKS), that contains not only the expected ingredient, a matrix eﬀective potential, but also a
matrix of Lagrange multipliers arising from number conservation in each state of the chosen subset; this matrix can be
diagonalized, but not otherwise transformed away. By combining solutions of the MKS equations, we can construct
the density array.

As an application of this theory, we study, in Sec. IV, the MKS equations in what we term the weak-coupling
limit. In this limit, we include only the ground state and excited states characterized (largely) as linear combinations
of Slater determinants with only one excited particle compared to the ground-state determinant (and therefore one
hole). Reference to higher excited states and simple assumptions concerning their properties do eventually enter
the discussion. The major consequence of this analysis is an eigenvalue equation for the aforementioned Lagrange
multipliers (relative to their ground-state value) that has the form of the random phase approximation. This equation
has the same structure as that deduced from TDKST. Assuming that the ground-state KS problem has been solved,
the major unknown ingredient in these equations, an exchange-correlation interaction, can be identiﬁed with the
corresponding quantity utilized in TDKST, at least in the adiabatic limit utilized in the RPA calculations.

There remains the problem of the physical signiﬁcance of the eigenvalues of the RPA formalism. In the work based
on TDKST, it is simply assumed that these may be identiﬁed with true excitation energies. In our work, they appear
as Lagrange multipliers to enforce number conservation in excited states. In our formalism true excitation energies
can be calculated, in principle, from a diﬀerence of adjacent averages of the Hamiltonian, as in previous applications of
the trace variational principle. In Sec. V we carry out such a calculation, and show that with an extended deﬁnition of
the weak coupling approximation, consonant with the traditional interpretation of the RPA as a boson approximation,
the interpretation of the eigenvalues as excitation energies is justiﬁed. In a concluding section, we summarize our
considerations.

II. HOHENBERG-KOHN ARGUMENTS

The Hamiltonian is written as

ˆH = ˆT + ˆV + ˆW + ˆY ,

the sum of the kinetic energy, the electrostatic interaction of the electrons with the nucleus, the Coulomb repulsion
of the electrons, and an additional ﬁctitious external source term that will be set to zero for actual calculations. The
following considerations apply, however, to any many body Hamiltonian of similar structure. The various terms have
the forms (x stands for the space-spin pair (r, s)), in atomic units,

Z

Z

Z

Z

Z

ˆT =

dx ˆψ†(x)(

2) ˆψ(x)

1
2 ∇

−

=

ˆψ†τ ˆψ,

ˆV =

dx ˆψ†(x) ˆψ(x)v(r),

ˆW =

dxdx′

ˆψ†(x) ˆψ†(x′) ˆψ(x′) ˆψ(x),

1

r
|

r′

−

|

ˆY =

dxdx′y(x, x′)ˆη(x, x′),

ˆη = ˆψ†(x) ˆψ(x) ˆψ†(x′) ˆψ(x′).

2

(2.1)

(2.2)

(2.3)

(2.4)

(2.5)

(2.6)

ˆY is a combination of one and two body forces. For the traces of these operators over the ensembles introduced below,
we use the same symbols without hats.

In the following we shall base our arguments on the variational principle for the trace of the Hamiltonian over the
lowest M eigenstates of the system [6–8,25–27]. We consider the case where the M + 1st state has a higher energy
than the M th state. This is the normal, but not absolutely necessary, criterion for choosing M . In order to achieve
our goals, beyond a certain point our considerations will be heuristic rather than rigorous.

Let

be the space of included states (I = 1...M ). For any operator ˆO, we deﬁne the restricted trace

=

I
{|

i}

S

O(M) =

M

XI=1

I
h

ˆO
|

I
|

,
i

where it is convenient in the further development not to divide by M . Unless more than one value of M occurs in
the same equation, we shall otherwise drop the superscript. We then consider a set of propositions formulated in
imitation of the Hohenberg-Kohn (HK) theorem [1]:

(i) Every choice of a function y(x, x′) in (2.5) determines a space
through the solution of the Schr¨odinger equation.
S
ˆη(x, x′)
I
I
(ii)
|
|
h
(iii) This relationship is single-valued and invertible. This can be proved by an adaptation of the standard HK

determines the correlation function η(x, x′) =

.
i

S

P

argument, as we now show. Suppose that

It follows that η

S →
= η′. We prove this by using the trace variational principle to establish two inequalities,

S →

S

η,

′

=

η′.

Here, for example, HS[y] is the ensemble average of ˆH over the set
is a functional of y. Adding (2.10) and (2.11) and assuming that η = η′, we obtain the usual contradiction

, where it is further emphasized that this average

S

Thus

is a single-valued functional of η.

S

Considering H to be a functional of η, we write the variational principle in the form

HS[y] + HS ′ [y′] < HS ′[y′] + HS[y].

We shall not attempt, however, to implement the variational principle in this version. Instead, using completeness,
we introduce the formula

As long as M is ﬁnite, this is an asymmetric formula. Since our aim is to utilize the quantities

as variational parameters, this asymmetry presents a problem that can be dealt with (approximately) in two ways. In
the ﬁrst method, which will be studied in this paper, we shall deﬁne the “matrix” n as a square matrix, M
M , but
choose M only large enough to encompass a well-deﬁned small set of states. (In extreme cases, this may well be only
the ground state and one or a few excited states.) Nevertheless, in (2.14) we must allow completeness to have its full
sway, as a matter of both mathematical and physical rigor. Indeed, for any physical situation of which we are aware,

×

HS[y] < HS ′[y′] +

(y

−

Z

y′)η′,

HS ′ [y′] < HS[y] +

(y′

y)η.

Z

−

δH =

δη = 0.

δH
δη

Z

η(x, x′) =

M

∞

ˆψ†(x) ˆψ(x)
I ′
|
|

I
h
XI ′=1
XI=1
ˆψ†(x′) ˆψ(x′)
I ′
I
|
|

×h

.
i

i

n(x)I ′I =

I
h

ˆψ†(x) ˆψ(x)
I ′
|
|

i

3

(2.7)

(2.8)

(2.9)

(2.10)

(2.11)

(2.12)

(2.13)

(2.14)

(2.15)

6
6
there will always be values of I ′ outside the set M , for which the matrix elements connecting these states to states I
within the set are as numerically signiﬁcant as essential elements belonging to the set n. We deal with this situation
M , I ′ > M can be approximated as functionals of n. We call this
by assuming that the matrix elements nII ′ , I
assumption a closure approximation, whose speciﬁc form will depend on the physics of the speciﬁc application.

≤

In the second method, which applies, for example, to the rotational spectrum of molecules or nuclei, we have a
situation, where starting from the ground state, there is a chain of matrix elements of the density that are signiﬁcantly
(an order of magnitude or more) larger than can be found for any other chain (without the intervention of at least
one smaller matrix element). We have in mind the rotational bands built upon the ground state. Of course there are
similar structures built upon excited (vibrational) states, but starting from the ground state, such a sequence involves
at least one smaller matrix element of the density connecting the ground and vibrational structures. In such cases, in
order to produce correct physics, the initial set M must be very large or, in an ideal limit, inﬁnite. To deal with the
vibrational excitations moreover, we have to deal with sets of large sets. This is not as formidable as it sounds, but,
in any event, will not be studied in the present work.

Returning to the formal development, with the help of (2.15), (2.14) can be rewritten (summation convention)

η(x, x′) = n(x′)II ′n(x)I ′I

= n(x′)II ′n∗(x)II ′ .

Thus we may replace the variational principle (2.13) by the form

δH
δn δn.
We emphasize that our conﬁdence in the application of (2.17), which is expressed in terms of the matrix elements of
n within the included space, depends on the validity of the closure approximation. ¿From Eq. (2.17) we can derive
a generalized Thomas-Fermi (TF) equation by imposing the number conservation constraints. If N is the number of
electrons, we have

(2.17)

δH =

Z

Introducing a set of Lagrange multipliers µII ′, we now write

and conclude that

dxn(x)II ′ = N δII ′.

Z

δH

µII ′

−

Z

δn(x)I ′I = 0,

δH
δn(x) I ′I

= µII ′ ,

which is the generalized TF equation for the present case.

III. GENERALIZED KOHN-SHAM SCHEME

n(x)II ′ is the limit x

x′ of the oﬀ-diagonal one-body density matrix

→

ρ(xI

x′I ′) =
|

I ′
h

ˆψ†(x′) ˆψ(x)
I
|
|

.
i

ρ(xI

x′I ′) =
|

λJ ΦJ (xI)Φ∗

J (x′I ′),

XJ
0,

λJ

≥

dx Φ∗

J (xI)ΦJ ′ (xI) = δJJ ′ ,

XI Z

dx ρ(xI

xI ′) = N δII ′ .
|

Z

4

Since ρ is a positive deﬁnite matrix, it can be brought to diagonal form, a move that generalizes the concept of natural
orbitals. We thus write

(2.16)

(2.18)

(2.19)

(2.20)

(3.1)

(3.2)

(3.3)

(3.4)

(3.5)

Here Eqs. (3.2) and (3.3) deﬁne the eigenfunctions and eigenvalues of the generalized density matrix, (3.4) expresses
the property that the ΦJ (xI) are unit vectors in the space labeled jointly by the single-particle coordinates and the
, and (3.5) expresses number conservation. It follows from these equations that
eigenvalues of the states in the set

In imitation of ground-state KS theory, we introduce a mapping from the oﬀ-diagonal density to a quasi-independent-

particle oﬀ-diagonal density,

S

dxρ(xI

xI) =
|

XJ

XI Z

λJ = N M.

ns(x)II ′ ,

n(x)II ′
→
ns(x)II ′ =

ϕJ (xI)ϕ∗

J (xI ′),

XJ
J (xI)ϕJ ′ (xI) = δJJ ′ ,

dxϕ∗

XI Z

dxns(x)II ′ = N δII ′.

Z

1 = N M.

XJ

δH
J (xI)

δϕ∗

X Z

δϕ∗

J (xI) + c.c. = 0,

H = T s + (V + W + T

T s),

−

T s =

ϕ∗

J tϕJ .

XJ Z

vs(x)II ′ =

(V + W + T

δ
δn(x)I ′I
δ
δns(x)I ′I

=

(V + W + T

T s),

−

T s).

−

Though we use the same symbol J to label orbitals as for the case of natural orbitals, here the similarity stops. For
the latter, J is, in principle, an unbounded set. For the present alternative, the set labeled by J is strictly a ﬁnite set
as determined by the sum (cf. (3.6)),

We next show how the variational principle may be used to obtain equations for the orbitals ϕJ so that in fact the

matrices n and ns are equal. We shall utilize the variational principle in the form

together with its complex conjugate. Setting the extra source term Y , deﬁned in (2.5) to zero and imitating the
procedure for the ground-state theory, we decompose

Enforcing the equality of n and ns, we deﬁne an eﬀective single-particle potential matrix,

The discussion of the decomposition of this matrix single-particle operator into constituent interesting parts will be
taken up in Sec. IV.

With the help of Eqs. (3.13-3.16), we derive from the variational principle (3.12) the conditions

To derive generalized single-particle equations of motion from the variational principle, we add the constraint condi-
tions

X Z

− X Z

δϕ∗

J (xI)[τ δII ′ + vs(x)II ′ ]ϕJ (xI ′) + c.c. = 0.

δϕ∗

J (xI)[ǫJ δII ′ + ν(x)II ′ ]ϕJ (xI ′) + c.c. = 0 .

5

(3.6)

(3.7)

(3.8)

(3.9)

(3.10)

(3.11)

(3.12)

(3.13)

(3.14)

(3.15)

(3.16)

(3.17)

(3.18)

Here ǫJ is the Lagrange multiplier for the normalization condition contained as part of (3.9). (As usual, the or-
thogonality condition need not be imposed, since it will be automatically satisﬁed by the solutions of the emerging
equations.) The unfamiliar term containing the Lagrange multiplier matrix ν(x)II ′ has the form of an additional
potential matrix, whose purpose is to enforce the condition [28] that n = ns. We shall study this quantity further be-
low. Combining Eqs. (3.17) and (3.18), we derive (together with it complex conjugate) the generalized single-particle
equation

ǫJ ϕJ (xI) = [tδII ′ + vs(x)II ′

νs(x)II ′ ]ϕJ (xI).

−

At this juncture it is appropriate to wonder if (3.19) can be related to TDKST. We cannot expect a general
connection, since the latter describes the consequences of the application of a time-dependent external ﬁeld, whereas
in the theory under development, the “time dependence” is a purely internal matter expressed by an oﬀ-diagonal
array of densities and eﬀective potentials. Nevertheless, a connection between the two formalisms will be made for
the application studied in Sec. IV, the so-called weak-coupling limit.
We conclude the present section by showing that (cf. Eq. (2.20))

up to an additive constant. It is thus a non-trivial matrix and cannot be absorbed into the eigenvalues ǫJ . To prove
(3.20), we can work backwards from the sum of (3.17) and (3.18) to the equation

ν(x)II ′ = µII ′ ,

0 =

X Z (cid:20)

X Z (cid:20)

X Z (cid:20)

=

=

δH
δns(x)II ′ −

δH
δn(x)II ′ −
δH
δn(x)II ′ −

ν(x)II ′

δns(x)I ′I

(cid:21)

(cid:21)

ν(x)II ′

δn(x)I ′I

µII ′

δn(x)I ′I .

(cid:21)

In passing from (3.21) to (3.22), we have used the equality ns = n.
In writing (3.23), we have repeated (2.19).
Comparing (3.22) with (3.23), we arrive at (3.20), again up to an additive constant. In the following sections, we shall
use the summation convention consistently both for the coordinate x and for the index I, and for the index J most
of the time.

IV. APPLICATION TO THE WEAK COUPLING LIMIT

In the course of this section, we shall transform and approximate Eq. (3.19), leading to an eigenvalue equation
that will determine oﬀ-diagonal elements of the matrix n. We shall do so in an approximation, the weak-coupling
approximation, that is roughly equivalent to a linear response approach. Assuming that the matrix µ can be chosen
diagonal (see immediately below), the eigenvalues are the quantities

λI = µII

µ00.

(4.1)

−
The proof that the matrix µ can be chosen diagonal goes as follows: Though we trace over a set of states labeled
I and originally identiﬁed as eigenstates of the reference system, the entire formalism is invariant under a unitary
transformation within the included space. Such a transformation can be chosen to diagonalize µ if it isn’t already
diagonal. The relation of the quantities in Eq. (4.1) to the excitation energies of the system is not immediately
apparent, even though this identiﬁcation has been made in the recent literature with remarkable empirical success
[15–20]. We shall address this problem in Sec. V.

Though the derivation of the main result of this section, the eigenvalue equation, can be carried out directly from
the generalized KS equation, we present the discussion in a form that makes more immediate contact with the density
functional form of the theory. The ﬁrst step, which is completely general, is to transform Eq. (3.19) into an equation
for the matrix ns

II ′(x, x′). First rewrite Eq. (3.19), remembering Eq. (4.1), as

Recalling the deﬁnition

ǫJ ϕJ (xI) = (hs

λ)II ′ (xx′)ϕJ (x′I ′),

II ′(xx′) =
ns

ϕJ (xI)ϕ∗

J (x′I ′),

−

XJ

6

(3.19)

(3.20)

(3.21)

(3.22)

(3.23)

(4.2)

(4.3)

(4.4)

(4.5)

(4.6)

(4.7)

(4.8)
(4.9)

we can form from Eq. (4.2) and its complex conjugate two equivalent but distinct values of the sum
J (x′I ′). The diﬀerence of these forms yields the generalized density-matrix equation

J ǫJ ϕJ (xI)ϕ∗

P

II ′ (xx′)(λI ′
ns

λI ) = ns

II ′′(xx′′)hs

I ′′I ′(x′′x′)

II ′′(xx′′)ns
hs

I ′′I ′(x′′x′),

−

−

that will provide the starting point for our further considerations.

Before continuing on our main path we note that by introducing time-dependent matrix elements

where O takes on the values ns and hs, Eq. (4.4), may be written in the form

OII ′ (t)

OII ′ exp[

i(λI

λI ′ )t],

≡

−

−

i

d
dt

−

ns(t) = [ns(t), hs(t)].

This resembles the fundamental equation of TDKST, in density matrix form, except that the bold-face type reminds
us that we are dealing with quantum-mechanical operators rather than c-numbers. This can be converted into a form
of TDKST, however, by assuming the existence of a wave packet
that is a linear combination of the ground state
and excited states of interest, for which we can also replace the average of the products that appear in the commutator
by the product of the averages. However, this derivation of TDKST is not suitable for our purposes. We therefore
return to the direct study of Eq. (4.4) in the limit of interest.

Ψ
|

i

In the weak coupling approximation, we conﬁne our attention to the ground state 0 and to a single excited state 1
(up to magnetic degeneracy) which belongs to a subset of the states I to be characterized. It will turn out that the
equations to be derived will characterize an entire subset of the states I, i. e., the state 1 will belong to a well-deﬁned
subset. We associate the ground state with the Slater determinant of the ground-state KS scheme. The excited states
of immediate interest to us will be associated with linear combinations of determinants of the same complete set
of orbitals in which one particle in a previously occupied orbital is promoted to a previously unoccupied orbital, a
so-called particle-hole (ph) excitation. Here the word association is meant to imply that these are states that have
overwhelmingly larger overlap with such determinants than they have with any other determinant of KS orbitals. We
may also imagine that there are states that have maximum overlap with determinants characterized by ν particle-ν
hole excitations. It is convenient below to designate the space of 1p-1h states as I1, as opposed to the general Iν .

To reduce Eq. (4.4) to a useful and ultimately recognizable form, we introduce a set of assumptions concerning
relative orders of magnitude of certain matrix elements, whose validity is obvious in the limit of vanishing two-particle
interaction (and is discussed further below)

>> ns

| 0I2|

>> ...,

>>

ns
ns
0I1 |
00|
|
|
ns
ns
,
I1I1 | ≈ |
00|
|
ns
ns
I1I ′
0I2 |
1 | ≈ |
|

if I1 6
We shall consider diagonal elements to be of zero order, elements connecting states Iν to Iν+p to be of pth order.

= I ′
1.

We interrupt the formal development in order to examine the assumptions Eqs. (4.7-4.9). Since the density matrix
elements are bilinear combinations of the generalized single-particle amplitudes ϕJ (xI), it is convenient to discuss the
assumptions of the weak coupling approximation in terms of the latter quantities. We assume that the indices J can
be identiﬁed as a pair (I, h) where I is now any state, ground or excited, of the reference system, and h identiﬁes one
of the occupied single-particle orbitals of the KS theory. Thus each value of J of interest to us speciﬁes a one-hole
state with parentage (largely) in one of the states of the reference system. We introduce next the concept of hierarchy
of states. Here the ground state stands by itself, and we shall think of it roughly as a Slater determinant occupied
by the lowest orbitals in an eﬀective external potential, as in the KS theory. At the ﬁrst level of the hierarchy is a
set of excited states of approximately one-particle, one-hole character, formed by linear combinations of particle-hole
excitations, At the next level are the two-particle, two-hole excitations, etc. In Sec. V we go further and treat the
excited states as boson excitations, as suggested by the form of the eigenvalue equation that is the major result of
this section. Notice that in the weak coupling picture, not only are nII ′ and vs
II ′ matrices in the space of states of
the reference system, but so also is ϕIh(I ′).

Considering assumption (4.8) ﬁrst, it asserts that for I belonging to the ﬁrst few levels of the hierarchy, if N , the
number of particles is not too small, in lowest approximation matrix elements diagonal in I are equal to their value
for I = 0. It is easiest to see this for the density itself, since the wave functions of the excited states diﬀer from those
of the ground state by at most a few particles out of N . That it follows for the other quantities is a consequence of
their relation to the density, as will be seen from further study below. We shall consider all diagonal matrix elements
to be zero order quantities. A further assumption, in terms of this scale, is that matrix elements in which I and I ′

7

belong to adjacent levels in the hierarchy are, on the average, of order (1/√N ) compared to zero order quantities. For
the sorting of our equations, we also need the assumption that matrix elements in which I, I ′ diﬀer by two levels or
refer to two diﬀerent states of the same level are second order quantities, i. e., of the order of the product of ﬁrst order
quantities. Of course, it has to be veriﬁed a posteriori that the solutions found are in accord with these statements.
Our aim is to apply these assumptions to choose those matrix elements of Eq. (4.4) that characterize the state 0
and the states I1. To carry out this program, we must look more closely into the structure of the eﬀective interaction
vs. First we rewrite the trace of the Hamiltonian in the form

(4.10)

(4.11)

(4.12)

(4.13)

(4.14)

(4.17)

(4.18)

which deﬁnes H xc. It follows that

H = T s + V + W c + H xc,

W c =

II ′(x)
ns

I ′I (x′),
ns

1
2

1

−

x
|

x′

|

II ′ (x) =
vs

(V + W c + H xc)

δns

δ
I ′I (x)
= v(x)δII ′ + vc
1

x
|

x′

−

|

II ′ (x) =
vc

II ′ (x′).
ns

II ′ (x) + vxc

II ′ (x),

The main reason for exhibiting these formulas is to recognize, as we shall see in more detail below, that the oﬀ-diagonal
elements of h are at least linear in the corresponding oﬀ-diagonal elements of ns. This is obvious from Eq. (4.14) for
the Coulomb contribution and will be argued more closely later for vxc. Thus we may safely assume that that the
matrix elements of h are the same order of magnitude as the corresponding matrix elements of ns.

Turning ﬁnally to the matrix elements of Eq. (4.4), we consider ﬁrst the ground or 00 element. Neglecting terms of

second order and higher, we ﬁnd

00(xx′′)hs
ns

00(x′′x′)

00(xx′′)ns
hs

00(x′′x′) = 0.

−
It is consistent with our approximations to identify ns
00 (in leading approximation only) with the ground state density
of KS theory and hs
00 with the KS single-particle Hamiltonian. Equation (4.15) is thus the KS equation in density
matrix form and determines a complete set of orbitals ϕa(x), where a = h will refer to the orbitals occupied in the
ground-state determinant and a = p those unoccupied.

Consider next the ﬁrst-order matrix element 01. Retaining only ﬁrst-order contributions (leading corrections are

(4.15)

third order), we may write

λ1ns

01(xx′) = ns

00(xx′′)hs

01(x′′x′) + ns

01(xx′′)hs

11(x′′x′)

00(xx′′)ns
hs

01(x′′x′)

01(xx′′)ns
hs

11(x′′x′).

(4.16)

−

−

As a ﬁrst step in the evaluation of this equation, we may, according to Eq. (4.8), set the 11 matrix elements equal to
the 00 ones. We also drop the subscripts 00 understanding these according to the previous identiﬁcation to be the
standard KS quantities. If we can exhibit hs
01, Eq. (4.16) will have the
form of a linear eigenvalue problem. First we have (the matrix elements in question are local functions of x)

01 as an (approximate) linear functional of ns

01(x) = vc
hs
01(x) =
vc

01(x) + vxc

01 (x),
01(x′).
ns

1

x′

x
|

|
We see that vc is, by deﬁnition, already of the desired form.

−

We turn then to vxc. Our approach to this quantity is to revert to the study of H xc, deﬁned in Eq. (4.10), which
10, the latter two
we consider, in line with assumptions previously made, a functional of n00 ≈
considered as small quantities. (It is also a functional of the other oﬀ-diagonal elements, ns
1′0, where 1′ refers
to any of the other states at level one of the hierachy of states. It is simply that this dependence does not enter into
the current discussion). We then expand H xc as a functional Taylor series in these quantities,

01, and of ns
01′ and ns

n, of ns

H xc = H xc

|0 +

δH xc
10(x) |0ns
δns
δ2H xc
01(x′) |0ns
10(x)δns

+

δns

10(x) +

δH xc
01(x) |0ns
δns

10(x)ns

01(x′) +

01(x) +

1
2
δ2H xc
01(x)δns

δ2H xc
10(x)δns
δns
01(x′) |0ns

δns

10(x′) |0ns
01(x)ns

1
2

10(x)ns

10(x′)

01(x′) + ... .

(4.19)

8

Strictly, the quantity H xc

0 and its functional derivatives still depend on n11 as well as n00. It suﬃces to ignore the
|
diﬀerence of the two quantities in the present discussion, but we shall have to remember and include the diﬀerence in
the arguments of Sec. V. We note further that only the ﬁrst and fourth of the terms shown explicitly in this equation
are non-vanishing. Recall that H xc is a trace and therefore invariant under a unitary transformation in the space of
states I. Its dependence on the matrix n must also be in the form of traces over these indices. As we can see on
the example of the Coulomb interaction, this dependence is more general than traces of products of n at the same
point, but in any event it follows that for every factor of ns
01, at
a generally diﬀerent point. The simpliﬁcation described above follows. We thus compute to ﬁrst order

10 at some spatial point, there must be a factor of ns

01 (x) =
vxc

01(x′) |0ns
x′
, n)ns
−
|
01(x′).
, n)ns
|
In passing from the second to the third line of this equation, i. e., in ignoring the state-dependence of f , we are
making an approximation equivalent to the adiabatic approximation widely used in TDKST. With the deﬁnition (the
dependence on n being understood)

01(x′)

01(x′)

(4.20)

≡
≈

δ2H xc
10(x)δns
δns
x
f10,10(
|
x′
x
f (
−
|

Eq. (4.16) may be rewritten as

x
f ef f (
|

−

x′

) =
|

1

−

x
|

x′

|

x
+ f (
|

x′

),
|

−

λ1ns

x′
01(xx′) = ns(xx′)f ef f (
x′′
|
hs(xx′′)ns
01(x′′x′)

−

01(x′′) + ns
01(xx′′)hs(x′′x′)
)ns
|
x′′
x
ns(xx′)f ef f (
|
−

)ns
|

01(x′′).

−

−

.

The ﬁnal task with respect to this equation is to convert it into a standard RPA form. Toward this end we reexpress

the matrices ns and ns

01 in terms of the KS single-particle functions, ϕa(x), satisfying the KS equation

First of all we have the familiar equation

Next we must evaluate the sum

hs(xx′)ϕa(x′) = ǫaϕa(x).

ns(xx′) = ϕh(x)ϕh(x′).

01(xx′) = ϕJ (x0)ϕ∗
ns

J (x′1).

Here we must introduce assumptions concerning which values of J contribute to the required order. In the space of
the eigenstates of the fully interacting system, we are concerned with the ground state and with states that are largely
ph excitations of this state. When we remove one particle (create a hole h), we expect to encounter states that can
be characterized as either 0h or 1h, and these are the values of J that we assign in the sum (4.25). If we consistently
use the approximations ϕ0h(0)

ϕh, the weak-coupling value of Eq. (4.25) becomes

≈

ϕ1h(1)
01(xx′) = ϕh(x)ϕ∗
ns

≈

0h(x′1) + ϕ1h(x0)ϕ∗

h(x′).

The ﬁnal form for this quantity is achieved by expanding the ﬁrst-order amplitudes in terms of KS modes,

The restriction of the sums on the right-hand sides of these equations is also consistent with the weak-coupling picture
painted above. Strictly the amplitudes X, Y should carry superscripts 1, identifying the eigenstate to which they refer,
but we shall suppress these except when required for clarity, as in Sec. V. Finally then,

01(xx′) = ϕh(x)ϕ∗
ns

p(x′)X ∗

ph + ϕ∗

p(x)ϕh(x′)Y ∗
ph.

Introducing Eqs. (4.24) and (4.29) into Eq. (4.22), we can project out equations for X ∗

ph and Y ∗

ph. We quote the

complex conjugate of these equations:

ϕ0h(1) = ϕpXph,
ϕ1h(0) = ϕpY ∗
ph.

9

(4.21)

(4.22)

(4.23)

(4.24)

(4.25)

(4.26)

(4.27)
(4.28)

(4.29)

The equations found are of the same form as those of the random phase approximation (RPA). Solutions are to be

normalized in the usual way, according to the conditions (Appendix B),

(ǫh

(ǫh

−

−

ǫp + λ1)Xph = (f ef f )ph′hp′ Xp′h′ + (f ef f )pp′hh′Yp′h′,
λ1)Yph = (f ef f )hp′ph′ Yp′h′ + (f ef f )hh′pp′ Xp′h′,
ǫp
x
b (x′)f ef f (
|

−
(f ef f )abcd = ϕ∗

)ϕc(x)ϕd(x′).
|

a(x)ϕ∗

x′

−

Xph
(
|

2
|

Yph

2) = 1.
|

− |

Xph

As is well known, two diﬀerent non-degenerate solutions of the RPA equations are orthogonal with the same metric
as in (4.33).

It is important to emphasize what has been accomplished by the calculations of this section. With the help of
Eq. (4.29), for instance, we can calculate the oﬀ-diagonal matrix elements of the density between the ground state
and the ﬁrst level of excited states. This can be applied, for example to the calculation of the corresponding matrix
elements of the electric dipole moment. However, just as in the case of KS theory, where we ﬁnd single-particle
energies that bear no simple relation, except for the most loosely bound orbit, to physical energy diﬀerences, so in
the present case as well the eigenvalues, which ﬁrst enter as Lagrange multipliers in the variational principle, do not
appear to have a simple relation to excitation energies. We turn next to a more detailed study of this question.

V. EXCITATIONS AS ENERGY DIFFERENCES

We shall discover in this section that with the help of additional assumptions concerning the RPA limit that are
consonant with its signiﬁcance as a quasi-boson approximation, the eigenvalues λ1 of Eqs. (4.30) and (4.31) can be
identiﬁed with true excitation energies of the system. In principle the energy diﬀerences can be calculated from the
expression

H (2)

2H (1)

−

ˆH
|

I
|

i −

2

0
h

ˆH
|

0
|

i

I
≡ XI=0,1
h
= E1 −

E0,

where EI is the energy of state I. This diﬀerence will be evaluated with the aid of Eqs. (4.10), (4.11), and the
simpliﬁed version of (4.19). These equations refer in turn to H (2) or H (1), as required. The result that we shall
establish is

E1 −

E0 = (ǫp

Xph
ǫh)(
|

2
|

−

Yph

2) + X ∗
|

− |

ph[fph′hp′ Xp′h′ + fpp′hh′Yp′h′ ] + Y ∗

ph[fhp′ph′ Yp′h′ + fhh′pp′ Xp′h′].

(5.2)

But the right hand side of this equation is easily seen from Eqs. (4.30) and (4.31) to equal λ1, provided that we make
use of Eq. (4.33).

It is simplest to evaluate the diﬀerence (5.1) ﬁrst for the interaction terms. Consider, for instance, the Coulomb

diﬀerence,

V c(2)

2V c(1) =

−

[ns

11(x)ns

11(x′)

00(x)ns
ns

00(x′) + 2ns

01(x)ns

10(x′)]

1
2

1

x
|

−
1

x′

x′

{

≈

x
|
= [ns

|

−
11(x)

−

|
[ns

11(x)

−
00(x)]ns
ns

−
00(x)]vc(x) +
ns

00(x′) + ns

01(x)ns

10(x′)
}

,

1

x
|

x′

−

|

01(x)ns
ns

10(x′)],

where the simpliﬁcation is made possible by the fact that the diﬀerence ns
in the RPA amplitudes. The corresponding diﬀerence involving the exchange-correlation energy can be written

00, as we shall prove below, is quadratic

11 −

ns

H xc(2)

)ns
|
The ﬁrst term of this equation is the value, to the required order, of H xc(2)
Next we see that the second terms of Eqs. (5.3) and (5.4) combine to give

x
00(x)]vxc(x) + f (
ns
|

2H xc(1) = [ns

11(x)

x′

−

−

−

|0 −

01(x)ns

10(x′)],

2H xc(1)

|0.

(4.30)

(4.31)

(4.32)

(4.33)

(5.1)

(5.3)

(5.4)

10

x
f ef f (
|

x′

)ns
|

−

01(x)ns

10(x′) = X ∗

ph[fph′hp′ Xp′h′ + fpp′hh′Yp′h′ ] + Y ∗

ph[fhp′ph′ Yp′h′ + fhh′pp′ Xp′h′],

(5.5)

which has been evaluated with the help of Eq. (4.29). This is already seen to be the interaction terms of Eq. (5.2).

The remaining terms of Eqs. (5.3) and (5.4), as well as the contributions arising from the kinetic energy and the

external potential depend on the value of

11(x)
ns

00(x) = ϕ∗
ns

J (x1)ϕJ (x1)

J (x0)ϕJ (x0).
ϕ∗

−

−

To enumerate the states J that contribute to this diﬀerence we shall picture the state 1 as an elementary boson
excitation, as is done in the standard approach to the RPA. The relations that follow from this assumption will lead,
as we shall see, to a quantitative form of closure approximation that is essential to the calculation. By the notation
1′ we shall mean a double
1
1′h.
excitation with diﬀerent bosons. Thus for the amplitudes ϕJ (1), we consider the values J = 0h, 1h, 1
The contributions from the latter two values are evaluated in boson (closure) approximation as

1, we shall mean a double boson excitation with the same boson, whereas by 1

1h, 1

×

×

×

×

ϕ1×1h(1) = √2ϕ1(0),
ϕ1×1′h(1) = ϕ1′ (0).

For the amplitude ϕJ (0), the required values are J = 0h, 1h, 1′h. For the diﬀerence (5.6), we thus ﬁnd

ns
11 −

ns
00 = ϕ∗

0h(1)ϕ0h(1) + ϕ∗

1h(0)ϕ1h(0) + ϕ∗

1h(1)ϕ1h(1)

ϕ∗

0h(0)ϕ0h(0).

−

The total contribution of the ﬁrst two terms of Eq. (5.9) to the energy diﬀerence under study, obtained by substi-
tuting Eqs. (4.27) and (4.28) and applying the result to the sum of single-particle operators that add up to the KS
Hamiltonian hs, is found to be ǫp(
2), one of the single-particle terms in Eq.(5.2). The evaluation of the
Xph
|
|
remaining terms of Eq. (5.9) is carried by studying the normalization conditions, Eq. (3.9). We calculate

2 +
|

Yph
|

1 =

2
ϕ0h(I)
|
|

XI

1 =

2
ϕ1h(I)
|
|

XI

=

2 +
ϕ0h(0)
|
|

2 +
ϕ0h(1)
|
|

2,
ϕ0h(1′)
|
|

XI ′6=I

=

2 +
ϕ1h(1)
|
|

2 +
ϕ1h(0)
|
|

ϕ1h(1
|

2 +
1)
|

×

ϕ1h(1
|

×

2
1′)
|

2 +
ϕ1h(1)
|

2 + 2
ϕ1h(0)
|
|

2 +
ϕ0h(1)
|
|

≈ |

2,
ϕ0h(1′)
|
|

X1′6=1

X1′6=1

ϕ0h(x0) = ϕh(x)[1

1
2 |

Xph

2
|

−

−

1
2 X1′6=1

′

X 1
|

ph|

2],

ϕ1h(x1) = ϕh(x)[1

Xph

2
|

−

− |

1
2 |

Yph

2
|

−

1
2 X1′6=1

′

X 1
|

ph|

2].

where the last evaluation has made use of the boson approximation expressed by Eqs. (5.7) and (5.8). These equations
are satisﬁed by the normalization changes

Combining these results and applying them to the last two terms of Eq. (5.9), suitably multiplied by the sum of terms
that comprise hs leads to the ﬁnal contribution

2 +
|

Yph
|

2) to the theorem stated in Eq. (5.2).
|

Xph
ǫh(
|

−

VI. CONCLUDING REMARKS

In this paper, we have developed yet another formalism for the study of excited states within a framework that
generalizes the basic ideas of KS theory. The main novelty in our approach compared to other methods is that the
latter work with a single density, be it the average in the ground state, in an excited state, an ensemble average, or the
average in a suitably chosen time-dependent state. On the other hand, we arrive by somewhat circuitous reasoning

11

(5.6)

(5.7)
(5.8)

(5.9)

(5.10)

(5.11)

(5.12)

(5.13)

at a formalism involving an entire array of matrix elements of the density operator taken among a pre-selected set of
states. The application of the variational principle for the trace of the Hamiltonian then leads to a generalized KS
scheme in terms of orbitals that depend not only on the coordinate x, but also on a label I for one of the included
states. We have examined the consequences of this formalism for the weak-coupling limit. We did this by framing
a set of assumptions, including a closure approximation, in order to identify the most important amplitudes and
their equations that characterize the ground state and a simple class of excited states that are composed of 1p-1h
excitations of the ground state.

In this way, we regained ﬁrst the ground-state KS theory and second derived an eigenvalue equation of RPA form.
By approximating a state-dependent (frequency-dependent) eﬀective interaction by a state-independent (frequency
independent) eﬀective interaction, the eigenvalue equation became identical to one that can be derived from TDKST,
that has been quite successful in application, especially to the description of excited states that are known to be
of the simple type included in our assumptions. A problem of interpretation remains in that the derivation from
TDKST contains no argument to justify that the eigenvalues can be associated with observed excitations. The same
diﬃculty applies to our derivation, in that the eigenvalues enter the formalism as Lagrange multipliers arising from the
conservation of electrons in the given state. Exploiting our assumptions to the fullest extent, we are able, nevertheless,
to prove a theorem that the Lagrange multipliers that enter the scheme can be equated to real energy diﬀerences.

As formulated, the reasoning described in this paper can be extended to improve the approximations that we have
so far achieved for 1p-1h states, as well as to study more complicated exited states, e. g., of 2p-2h character. The
application to rotational spectra might also be intriguing.

ACKNOWLEDGMENT

One of the authors (AK) is grateful to the Humboldt Foundation for support of this work and to his co-author for

his hospitality.

APPENDIX A: RELATION OF WEAK-COUPLING LIMIT TO TIME-DEPENDENT DENSITY
FUNCTIONAL THEORY

In this section, we shall connect the linearized RPA equations (4.30) and (4.31) with a corresponding linearized

approximation to TDDFT. We start with TDDFT in density-matrix form

i

dρs
dt

= [(τ + vs(t)), ρs],

ρs(xt, x′t) =

ϕh(xt)ϕ∗

h(x′t),

Xh
δ
δn(xt)

vs(xt) =

(V (t) + W (t) + T (t)

T s(t)).

−

Here ϕ(xt) are the N instantaneous eigenfunctions of τ + vs(t) of lowest energy, deﬁning a time-dependent Slater
determinant whose kinetic energy is T s(t), and V (t), for example, is the expectation value of ˆV in the time-dependent
wave-function

We are interested in the physical situation where the time-dependence of the state vector arises not from an explicitly
time-dependent external ﬁeld but from the fact that initially the state vector is a superposition of the ground state
(predominately) and a small amplitude for one of the excited states. We thus assume that

.
Ψ(t)
i
|

ρs(xt, x′t) = ρ0(x, x′) + [ρ1(x, x′) exp(

ρ1(x, x′) =

[Xphϕp(x)ϕ∗

Xph

−
h(x′) + Yphϕh(x)ϕ∗

iλt) + c.c.],
p(x′)].

In (A4) and below the superscript 0 identiﬁes quantities associated with the KS ground-state theory. If ρs(t) was the
physical one-particle density matrix, we could understand λ as a physical excitation energy, but no such claim can be
made for what we are doing.

What follows now is close to a standard derivation of the RPA. We insert (A4) and (A5) into (A1) and, considering
the amplitudes X and Y as ﬁrst order quantities, we expand to ﬁrst order. For this purpose, we need the expansion,

12

(A1)

(A2)

(A3)

(A4)

(A5)

vs(xt) = v0(x) +

f (x, x′)n1(x′),

Z

f (x, x′) =

δv0(x)
δn0(x′)
n1(x) = ρ1(x, x).

,

In Eqs. (A6) and (A7), we have already made the adiabatic approximation by ignoring the time dependence of f . As
a consequence, the quantity called f in this appendix can be identiﬁed with the quantity f ef f of the text. ¿From the
zero order term, we regain the KS theory for the ground state. ¿From the ﬁrst order terms proportional to exp(
iλt),
for example, we ﬁnd

−

λρ1(x, x′) = [(τ + v0), ρ1](x, x′) +

dx′′[

, ρ0](x, x′)n1(x′′).

δv0
δn(x′′)

Z

Taking, in turn, the ph and hp matrix elements of (A9), we ﬁnd the familiar equations

[ǫh
[ǫh

−
−

−

ǫp + λ]Xph = fph′hp′ Xp′h′ + fpp′hh′Yp′h′ ,
λ]Yph = fhp′ph′ Yp′h′ + fhh′pp′ Xp′h′ .
ǫp

APPENDIX B: RPA NORMALIZATION CONDITION

We deﬁne mode operators for the ﬁeld ˆψ(x) by expanding in terms of the KS modes,

ˆψ(x) =

aaϕa(x),

Xa

a =

h, p

. From the commutation relations for particle-hole pairs,

{

}

[a†

hap, a†

p′ah′ ] = δhh′ δpp′

δhh′a†

p′ ap

δpp′ ah′a†
h,

−

−

we obtain an approximate sum rule by taking the expectation value in the state
intermediate states
pa′
a†
0
instance,
p|
|

, introducing a complete set of
i
, and retaining only the ﬁrst term on the right hand side (on the justiﬁed assumption that, for
i
i
|
is, on the average small compared to unity). With the deﬁnitions

0
h

0
|

i

we have

ξi
ph =
ηi
ph =

0
h
0
h

a†
hap
|
a†
pah
|

i
|
i
|

,
i
,
i

[ξi

phξi∗
p′h′

ηi
p′h′ηi∗

ph] = δpp′ δhh′ .

Xi

−

We would like to identify the quantities ξ and η with the quantities X and Y , where the latter satisfy Eqs. (4.30)
and (4.31). Equation (B5) would then constitute the completeness relation for the solutions of these equations, and
as is well-known, a completeness relation and orthogonality of solutions with the corresponding metric implies the
= ni0(x).
normalization condition Eq. (4.33). Toward this end, we consider two diﬀerent evaluations of
On the one hand we have in an approximate evaluation based on the physical picture,

ˆψ†(x) ˆψ(x)
i
|
|

0
h

i

ni0(x) =

a(x)ϕb(x)
ϕ∗
0
h

a†
aab
|

i
|

i

Xab

Xph

∼=

[ϕ∗

p(x)ϕh(x)
0
h

a†
pah
|

] + ϕ∗
i

h(x)ϕp(x)
0
h

a†
hap
|

i
|

i
|

.
i

On the other hand, from the generalized KS mapping ni0 →
p(x)ϕh(x)Y i

ni0(x) =

[ϕ∗

ph + ϕ∗

h(x)ϕp(x)X i

ph].

ns

i0 and Eq. (4.29, we have

Xph

13

(A6)

(A7)

(A8)

(A9)

(A10)
(A11)

(B1)

(B2)

(B3)

(B4)

(B5)

(B6)

(B7)

The identiﬁcations ξ = X and η = Y are consistent with these equations. We actually have,

[ϕ∗

h(x)ϕp(x)(ξi

X i

ph) + ϕ∗

p(x)ϕh(x)(ηi

Y i
ph)] = 0.

ph −

ph −

Xph

(B8)

If the points in the single-particle functions were distinct, the result we seek would follow trivially from orthonormality
of these functions. If we take the modes to be complex functions and assume that we can cut oﬀ the expansion (B1)
at a ﬁnite number of terms, then by choosing a suﬃciently large set of distinct values of x, we can still obtain the
desired consequence from Eq. (B8).

[1] P. Hohenberg and W. Kohn, Phys. Rev. 136B, 864 (1964).
[2] W. Kohn and L. J. Sham, Phys. Rev. 140A, 1133 (1965).
[3] R. G. Parr and W. Yang, Density-Functional Theory of Atoms and Molecules, (Oxford U. Press, New York, 1989).
[4] R. M. Dreizler and E. K. U. Gross, Density Functional Theory, An Approach to the Quantum Many-Body Problem,

(Springer-Verlag, Berlin, 1990).

[5] A. Holas and M. H. March, in Topics in Current Chemistry, Vol. 180, ed. R. F. Nalewajski (Springer, Berlin, 1996), p. 57.
[6] R. Courant and D. Hilbert, Methods of Mathematical Physics (Interscience, New York, 1965), Vol. 1, p. 459.
[7] A. K. Theophilou, J. Phys. C 12, 5419 (1979).
[8] E. K. U. Gross, L. N. Oliveira, and W. Kohn, Phys. Rev. A 37, 2805 (1988); 37, 2809 (1988); 37, 2821 1988).
[9] E. K. U. Gross, J. F. Dobson, and M. Petersilka, in Topics in Current Chemistry, Vol. 181, ed. R. F. Nalewajski (Springer,

[10] M. Petersilka, U. J. Gossmann, and E. K. U. Gross, Phys. Rev. Lett. 76, 1212 (1996).
[11] J. F. Dobson, M. J. Buner, and E. K. U. Gross, Phys. Rev. Lett. 79, 1905 (1997).
[12] M. E. Casida, in Recent Advances in Density Functional Methods, Part I, ed. D. P. Chong (World Scientiﬁc, Singapore,

[13] M. e. Casida et al, in Nonlinear Optical Materials, ed. S. P. Karna and A. T. Yeates (American Chemical Society, Wash-

Berlin, 1996), p. 81.

1995), p. 155.

ington), p. 145.

[14] C. Jamorski, M. E. Casida, and D. R. Salahub, J. Chem. Phys. 104, 5134 (1996).
[15] R. Bauernschmitt and R. Ahlrichs, Chem. Phys. Lett. 256, 454 (1996).
[16] R. Bauernschmitt, M. H¨aser, O. Treutler, and R. Ahlrichs, Chem. Phys. Lett. 264, 573 (1997).
[17] S. Hirata and M. Head-Gordon, Chem. Phys. Lett. 302, 375 (1999).
[18] S. Hirata and M. Head-Gordon, Chem. Phys. Lett. 314, 291 (1999).
[19] K. B. Wiberg, R. E. Stratmann, and M. J. Frisch, Chem. Phys. Lett. 297, 60 (1998).
[20] R. E. Stratmann, G. E. Scuseria, and M. J. Frisch, J. Chem. Phys. 109, 8218 (1998).
[21] A. G¨orling, Phys. Rev. A 59, 3359 (1999).
[22] M. Levy and A. Nagy, Phys. Rev. Lett. 83, 4361 (1999)
[23] X. Gonze and M. Scheﬄer, Phys. Rev. Lett. 82, 4416 (1999).
[24] D. J. Tozer and N. C. Handy, J. Chem. Phys. 109, 10180 (1998).
[25] A. K. Kerman and A. Klein, Phys. Rev. 132, 1326 (1963).
[26] G. Do Dang et al, Nucl. Phys. A114, 501 (1968).
[27] A. Klein, Phys. Rev. C30, 1680 (1984).
[28] A. Klein and R. M. Dreizler, Phys. Rev. A58, 1581 (1998).

14

