1
0
0
2
 
n
a
J
 
6
2
 
 
]
h
p
-
c
c
a
.
s
c
i
s
y
h
p
[
 
 
1
v
0
9
0
1
0
1
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Some Limit Theorems for Linear Oscillators
with Noise in the Coeﬃcients∗

V. Balandin∗ and H. Mais†

∗ Institute for Nuclear Research of RAS,
60th October Anniversary Pr., 7a, Moscow 117 312, Russia

† Deutsches Elektronen-Synchrotron DESY, Hamburg

November 24, 2013

Abstract

Using the tools and methods developed in [1] limit theorems are
proven for the linear oscillator with random coeﬃcients. The asymp-
totic behaviour of the moments is studied in detail. The technique
presented in this paper can be applied to general linear systems with
noise and is well suited for the investigation of stochastic beam dy-
namics in accelerators.

∗extended version including proofs of a contribution by V. B. at the Workshop ”Non-
linear and Stochastic Beam Dynamics in Accelerators - a Challenge to Theoretical and
Computational Physics” L¨uneburg (1997)

1

Contents

1 Linear Oscillator with Noise in the Coeﬃcients

2 Special Basis in the Space of Polynomials

3 Stopped Process

4 Asymptotic Behaviour of Moments

5 Nonresonant Case

6 First and Second Order Moments

7 Comparison with White Noise Model

8 Another Noise Model

3

6

8

9

12

17

19

21

9 Proof of the Theorems

24
9.1 Proof of the Theorem A . . . . . . . . . . . . . . . . . . . . . 24
9.2 Proof of the Theorem B . . . . . . . . . . . . . . . . . . . . . 26
9.3 Sketch of the Proof of the Theorem D . . . . . . . . . . . . . . 40

2

(1)

(2)

1 Linear Oscillator with Noise in the Coeﬃ-

cients

Starting point of our investigation is a nondegenerate ( ω0 6
linear oscillator under the inﬂuence of noise
ε
ω0

¨x + ε (γ(t) + ε α) ˙x + ω2
0

1 +

η(t)

x = ε ω0 ξ(t)

(cid:18)

(cid:19)

or written as a system of two ﬁrst-order diﬀerential equations

= 0 ) damped

˙x = ω0 z




˙z =

ω0 x + ε (ξ

γ z

η x)

ε2 α z

−

−

−

−

|

|

ε

< 1 .


ε is small parameter
The ε2 proportionality of the deterministic term in the damping part is
connected with the fact that we will discuss the dynamics on time scales
O(1/ε2) (it is the minimum time scale where the stochastic eﬀects could es-
sentially inﬂuence the dynamics of our oscillator). If the damping will be
weaker it will not aﬀect the dynamics and we can neglect it, and if it will
be stronger it will completely change the picture of the dynamics, the typ-
ical time scales become exponentially large O(exp(1/εa)), a > 0 for positive
damping and it will require other methods (see, for example [2]) that are
beyond the scope of this paper.

Noise has been introduced in the damping part (γ(t)), as a modulation

of the frequency ω0 (η(t)) and as an external driving force ξ(t).

As a model of noise we shall take stochastic processes deﬁned by the

following scalar products

η(t) = ~b(t)

~y(t),

ξ(t) = ~h(t)

~y(t),

γ(t) = ~d(t)

~y(t)

·
with nonrandom n-dimensional vectors ~b, ~h and ~d which are quasiperiodic
in t and which can be expanded into Fourier series

·

·

~b(t) =

~bm exp(iνmt),

~b−m =

~h(t) =

~hm exp(iνmt),

~h−m =

+∞

m=−∞
X

+∞

m=−∞
X

3

∗

~bm
(cid:16)

(cid:17)

∗

~hm
(cid:16)

(cid:17)

+∞

~d(t) =

~dm exp(iνmt),

m=−∞
X
with real frequencies νm satisfying the condition

~d−m =

~dm

∗

(cid:16)

(cid:17)

νl + νm = 0

m + l = 0.

⇔

In the main part of this paper the vector ~y(t)
solution of the linear system of Ito’s stochastic diﬀerential equations

is assumed to be a

∈

Rn

d ~y = A ~y

dt + B d ~w(t)

·

(3)

where A and B are (n
r) real constant matrices respectively,
×
and ~w(t) is an r-dimensional Brownian motion, other choices for the noise
model will be described later on.

n) and (n

×

As smoothness properties of the vector functions ~b, ~h and ~d we shall

require the convergence of the series 1

+∞

m=−∞ |
X

p

νm|

~bm
(cid:16)(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

+

~hm
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

+

~dm

(cid:12)
(cid:12)
(cid:12)

(cid:17)

(cid:12)
(cid:12)
(cid:12)

<

,

∞

We denote

p = 0, 1

(4)

F =

p

Z :

∈

n

~bp|
|

+

~hp|
|

+

~dp| 6

|

= 0

o

and introduce

Fk =

k ω0| 6
Besides the smoothness condition (4) we also require

νp + νq −

(p, q)

F :

×

∈

F

{

|

= 0

.

}

min
k ∈ {0,1,2,3,4}

inf
(p, q) ∈ Fk |

νp + νq −

k ω0| ≥

δ2
f > 0.

(5)

The condition (5) does not exclude resonances but requires them to be iso-
lated. This can be easily changed to some kind of Diophantine conditions

1 For a complex vector ~w
w1

1 + . . . + wn

w∗
·
use the norm
p
compatible with the spherical norm for vectors.

Cn we use the usual spherical norm

~w =
n) matrices with complex coeﬃcients we shall
= √λ where λ is the greatest eigenvalue of the matrix M ∗M , which is

∈
n and for a (n

= √ ~w

M
|

~w
|

w∗

×

·

|

|

·

4

with increasing smoothness properties (4). Note that (5) is always satis-
ﬁed for periodic functions (i.e. νp = p
ν) and for ﬁnite trigonometrical
polynomials with arbitrary frequencies.

·

In this paper we will assume that all eigenvalues λk of the matrix A in

(3) have negative real parts, i.e.

δ2
s < 0,
Re λk ≤ −

k = 1, . . . , n

(6)

From this it follows (see, for example [3]) that if the initial random vector
~w(0)
for
= ~0 and

~y0 , independent of the r-dimensional Brownian motion ~w(t)
~y0i
0 < t <
h
covariance matrix

, has a normal distribution with mean value

∞

−

∞

~y⊤
0

~y0 ·

D

E

Z0

=

exp(τ A) BB⊤ exp(τ A⊤) dτ def= D

then the solution of (3) ~y(t, ~y0) is a stationary, zero-mean Gaussian process,
with covariance function

exp(τ A) D

; τ

D exp(τ A⊤)

; τ

0

0

≥

≤

ρ(τ ) = 




(7)

Although, later on we shall not restrict the initial conditions for
in our noise model to be equal to the above mentioned initial conditions
generating stationary solutions of the system (3) 2, all results will nevertheless
be expressed in terms of the spectral density associated with the covariance
function (7) Ψ(ω) = Ψc(ω)

i Ψs(ω) where 3

~y

Ψc(ω) =

cos(ωτ )ρ(τ )dτ =

A
A2 + ω2I ·

−

D

−

∞

Z0

2For simplicity we even shall take the initial condition to be a point in n-dimensional
Euclidean space, but if one will follow the proofs of the theorems it will be clear that
all results of this paper will be correct if we use as initial condition an arbitrary random
vector, independent of the r-dimensional Brownian motion ~w(t)
,
∞
additionally assuming that some moments of ~y0 are ﬁnite.

~w(0) for 0 < t <

−

3Note that if the matrices A and B−1 commute we use notation A

B for the product

AB−1.

5

Ψs(ω) =

sin(ωτ )ρ(τ )dτ =

ωI
A2 + ω2I ·

D

∞

Z0

For further purposes let us note that independently from real ω the norm
of the matrix Ψ(ω) admits the estimate

Ψ(ω)
|

| ≤

¯C

(8)

and is unimportant for us.

where ¯C is some positive constant whose exact value depends on δ2
BB⊤
(cid:12)
(cid:12)
(cid:12)
2 Special Basis in the Space of Polynomials

(cid:12)
(cid:12)
(cid:12)

s and

Often, the inﬂuence of noise in systems such as (1) is studied by considering
its inﬂuence on the unperturbed invariants of motion such as energy

r =

1
2

x2 + z2
(cid:16)

(cid:17)

or functions of the energy. For our later study of arbitrary moments we
introduce a special time dependent (non-autonomous) basis in the space of
polynomials.

For all nonnegative integers m, k we deﬁne

Im, k = exp (i (m

k) ω0 t)

−

x + iz

m

x

(cid:18)

2 (cid:19)

(cid:18)

k

iz
−
2 (cid:19)

It is easy to check that the functions introduced above admit the following
properties

a.

∂
∂t + ω0

(cid:16)

z ∂

∂x −

x ∂
∂z

(cid:16)

(cid:17)(cid:17)

Im, k = 0

Im2, k2 = Im1+m2, k1+k2

b. Im1, k1 ·
c.

Im, k = I ∗

d. Im, m =

k, m

m

r
2

(cid:16)

(cid:17)

e.

Im, k|

|

2 = Im, k ·

I ∗
m, k =

r
2

m+k

(cid:16)

(cid:17)

6

Representing x and z as

x =

x + iz
2

+

x

iz

−
2

= exp(iω0t)I0, 1 + exp(

iω0t)I1, 0

−

z =

x + iz

x

iz

2i −

−
2i

= i exp(iω0t)I0, 1 −
zk (0

i exp(

iω0t)I1, 0

−

and using property b we can express xm−k
m) with the help
of the binomial theorem in the form of a linear combination of the functions
Ip, q

≤

≤

k

·

xm−k

zk = (i)k

·

·

−

m−k

k

·

Xp = 0

(
Xq = 0

−

1)q

 

m

k

−
p

k
q !

!  

exp(i(m

2(p + q)) ω0t)

Ip+q, m−(p+q).

·

For m

Im, k are functions with complex values. However, we can
also use as basis real valued functions Um, k and Vm, k which are deﬁned by

= k

Um, k =

Im, k + Ik, m
2

= Uk, m,

Vm, k =

Ik, m

Im, k −
2i

=

Vk, m.

−

Note further that the functions Um, k and Vm, k can be easily expressed

through the real valued functions ¯Um, k and ¯Vm, k

¯Um, k = (cid:16)

m

x+iz
2

x−iz
2

x+iz
2

m

x−iz
2

(cid:17)

(cid:16)

(cid:17)

(cid:16)

(cid:17)

(cid:16)

(cid:17)

+

2

k

k

k

k

¯Vm, k = (cid:16)

m

x+iz
2

x−iz
2

(cid:17)

(cid:16)

(cid:17)

x+iz
2

m

x−iz
2

(cid:17)

(cid:16)

(cid:17)

−
2 i

(cid:16)

which do not depend on time t with help of the following simple formula

Um, k

Vm, k






= 









−

−

cos((m

k) ω0t)

sin((m

k) ω0t)

sin((m

k) ω0t)

cos((m

k) ω0t)

−

−

¯Um, k

¯Vm, k











· 



−

7

6
3 Stopped Process

Although a suitable choice for A and B in (3) allows one to approximate
a wide range of spectral functions (with appropriate choice of A and B one
can obtain for the y1 component of the vector ~y every spectral function
which is the ratio of two polynomials), the solution of this equation has
the disadvantage that it also allows with positive probability arbitrary big
excursions during ﬁnite ﬁxed time intervals. In order to remove this eﬀect
and also to apply our proof technique we have to freeze and truncate the
process.

Let c(ε) be some positive function of ε deﬁned on the set ε

= 0 . For
Rn we introduce a random value

m(~y0) = inf

every natural m and for every point ~y0 ∈
m = τ ε
τ ε
6∈
{
where ~y(t)
is the solution of the system (3) which with probability one
satisﬁes the initial condition ~y(0) = ~y0 . So with probability one for m1 ≤
m2

(t, ~y(t))

< c(ε)

[0, m)

× {

~y
|

~y :

0 :

}}

≥

t

|

Then with probability one there exists a limit (ﬁnite or inﬁnite) when m
of the sequence τ ε

→ ∞

0

τ ε
m1 ≤

≤

τ ε
m2.

m which we will denote as
τ ε(~y0) def= lim

τ ε
m(~y0).

m→∞

In other words τ ε(~y0) is the exit time from an open ball
< c(ε) for
the solution of (3) starting with probability one from initial point ~y0. Note
that if the matrix BB⊤ is nondegenerate then this exit time is ﬁnite with
probability one.

~y
|

|

{

t, τ ε

The joint solution of the systems (2), (3) (x(t), z(t), ~y(t)) is a Marko-
vian diﬀusion process in (n + 2)-dimensional Euclidean space. Let sε
t =
min
. For the noise model (3) for reasons which we explained above
we shall not study the moments of the stochastic process (x(t), z(t), ~y(t)) ,
t )) (stopped
but the moments of the stochastic process
process). We shall use the time scale O (ε−2) and the diﬀerence between t
and sε
t

for this time scale can be estimated with the help of the following

t ), ~y(sε

t ), z(sε

(x(sε

}

Theorem A: There exist positive constants a and b so that for any

initial point ~y0 and for any positive L
L
ε2

exp(a

τ ε <

~y0|
|

P

(cid:19) ≤ (cid:18)

(cid:18)

2) + a

exp(

b c2(ε))

(9)

L
ε2

(cid:19)

−

8

6
Rewriting the left hand side of the inequality (9) in the form

P

τ ε <

(cid:18)

L
ε2

(cid:19)

= P

max
0≤t≤L/ε2 |

t

 

−

sε
t |

> 0

!

we see that on the time scale considered the measure of the set where t
will go to zero as ε
other hand to apply the technique of our proof we require that

= sε
t
faster then b−1 log (ε−2). On the

0 if c2(ε)

→ ∞

→

εc3(ε) = 0

lim
ε→0

so that we can not allow c(ε) go to inﬁnity too fast.

4 Asymptotic Behaviour of Moments

Let us introduce functions ¯cl(m, k) of integer arguments m, k
the help of

≥

0 with

m
4 


−

¯c1(m, k) =

(m

1) Ψ∗(ω0 + νp) ~hp ·

−

~bl + i~dl
(cid:16)

(cid:17)

−

νl−νp = ω0 n
X

(k + 1) Ψ∗(2ω0 + νp)

~bp + i~dp
(cid:16)

(cid:17)

~hl −

·

k Ψ∗(νp)

−

~bp + i~dp
(cid:16)

(cid:17)

~hl −

·

k Ψ∗(ω0 + νp) ~hp ·

~bl −

i~dl

+

(cid:16)

(cid:17) o

+

νl−νp = −ω0 n
X

mΨ⊤(νp)

i~d ∗
p

~b ∗
p −
(cid:16)

·

(cid:17)

~h ∗

l −

kΨ⊤(ω0 + νp) ~h ∗
p ·

i~d ∗
l

~b ∗
l −
(cid:16)

(cid:17) o





¯c2(m, k) =

m(m
−
4

−

1)

Ψ∗(ω0 + νp) ~hp ·

~hl

Xνl−νp = 2ω0

¯c3(m, k) =

1)

m(m
−
4

Ψ∗(ω0 + νp) ~hp ·

~bl −

i~dl

+

(cid:16)

(cid:17)

Xνl−νp = 3ω0 n

9

6
+ Ψ∗(2ω0 + νp)

~bp + i~dp
(cid:16)

·

(cid:17)

~hl

o

¯c4(m, k) =

m(m
−
4

−

1)

Ψ∗(2ω0 + νp)

~bp + i~dp
(cid:16)

·

(cid:17)

(cid:16)

~bl −

i~dl

(cid:17)

Xνl−νp = 4ω0

¯c5(m, k) =

k Ψ∗(νp)

~bp + i~dp
(cid:16)

·

(cid:17)

(cid:16)

~bl −

i~dl

(cid:17)

+

Xνl−νp = 2ω0 n

m
4 


+ (k + 1) Ψ∗(2ω0 + νp)

~bp + i~dp
(cid:16)

·

(cid:17)

(cid:16)

~bl −

i~dl

−

(cid:17)

(m

−

−

1) Ψ∗(2ω0 + νp)

~bp + i~dp
(cid:16)

·

(cid:17)

~bl + i~dl
(cid:16)

−

(cid:17) o

−

Xνl−νp = −2ω0

m Ψ⊤(νp)

~b ∗
p −
(cid:16)

i~d ∗
p

~b ∗
l −
(cid:16)

·

(cid:17)

i~d ∗
l

¯c6(m, k) =

Ψ(ω0 + νp) + Ψ∗(ω0 + νp)

∞

m k
4

p=−∞ h
X

(cid:17)





~hp

~hp ·

i

¯c7(m, k) =

m + k
2

−

α +

∞

p=−∞ (

X

m k
4

h

Ψ(νp) + Ψ∗(νp)

~bp + i~dp

~bp + i~dp
(cid:16)

(cid:17)

·

(cid:17)

−

i (cid:16)

m2
4

−

Ψ(νp)

~bp −

i~dp

~bp + i~dp
(cid:16)

(cid:17)

·

(cid:17)

(cid:16)

−

k2
4

Ψ∗(νp)

~bp + i~dp
(cid:16)

·

(cid:17)

(cid:16)

~bp −

i~dp

(cid:17)

+

(m + 1)k
4

m(k + 1)
4

"

+

Ψ(2ω0 + νp) +

~bp + i~dp
~bp + i~dp
(cid:16)
(cid:16)
(cid:17)
cl(m, k) are correctly
By using (4) and (8) it is not hard to show that
deﬁned because the series converge absolutely for every ﬁxed values of m
and k .

Ψ∗(2ω0 + νp)

(cid:17)

#

·

)

10

Now in correspondence with an arbitrary two index array am, k and

nonnegative integer N

m, k

0,

m + k

N

≥

≤
(am, k; N) with (N + 1)(N + 2)/2 components with the

we deﬁne a vector ~
V
help of the rule

Vl(am, k; N) = am, k,

l =

(m + k)(m + k + 1)
2

+ k + 1

This ordering corresponds to the following ordering of the elements of the
array am, k (take by rows)

a0, 1
a1, 1

a0, 0
a1, 0
a2, 0
...
aN, 0 aN −1, 1 aN −2, 2

a0, 2

. . . a0, N

Consider now the system of ordinary diﬀerential equations with constant

coeﬃcients

d
dτ

~
V

(am, k; N) = ¯

KN ~
V

(am, k; N)

generated with the help of the rule

d
dτ am, k = ¯c2(m, k) am−2, k

+ ¯c ∗

2 (k, m) am, k−2

+

+

(10)

(11)

¯c1(m, k) am−1, k

+ ¯c ∗

1 (k, m) am, k−1

¯c3(m, k) am−2, k+1 + ¯c ∗

3 (k, m) am+1, k−2 +

¯c4(m, k) am−2, k+2 + ¯c ∗

4 (k, m) am+2, k−2 +

¯c5(m, k) am−1, k+1 + ¯c ∗

5 (k, m) am+1, k−1 +

¯c6(m, k) am−1, k−1 + ¯c7(m, k) am, k

where on the right hand side of (11) we take into account only terms with
nonnegative indices.

11

Theorem B: Let the function c(ε) satisfy the condition

εc3(ε) = 0

lim
ε→0

Then for arbitrary initial points x0, z0, ~y0 , and for arbitrary nonnegative
integer N and positive L

lim
ε→0

max
0≤t≤L/ε2

¯
M

N (ε2sε
−1

t ) ~
V

(Im, k(sε

t ); N)

~
V

−

(Im, k(0); N)

= 0

where the matrix
of linear ordinary diﬀerential equations with constant coeﬃcients (10).

¯
MN (τ ) is the fundamental matrix solution of the system
Remark 1: For further purposes it is important to note that the state-

ment of the theorem B can also be written in the form

D

(cid:12)
(cid:12)
(cid:12)

E(cid:12)
(cid:12)
(cid:12)

lim
ε→0

max
0≤t≤L/ε2

~aN (ε2sε
t )
(cid:12)
D
(cid:12)
(cid:12)

~
V

·

(Im, k(sε

t ), N)

−

~
V

·

~aN (0)

(Im, k(0), N)

= 0

E(cid:12)
(cid:12)
(cid:12)

where ~aN (τ ) is an arbitrary (N + 1)(N + 2)/2-dimensional vector satisfying

¯
K
Remark 2: For physical applications one can neglect the small diﬀerence

⊤
N ~aN

(12)

−

=

d~aN
dτ

between t and sε

t (see theorem A)and we have

~
V

D

(Im, k(t), N)

≈

E

MN (ε2t) ~
¯
V

(Im, k(0), N)

5 Nonresonant Case

Let us now deﬁne what we mean by nonresonant.
Deﬁnition: We shall say that there are no resonances of order m

if for all integers p, q such that (p, q)

F

F

∈
= νp + νq

×

m ω0 6

Deﬁnition: We shall say that there are no resonances up to order m

if for all integers p, q such that (p, q)

F

F

0

≥

0

≥

k ω0 6

= νp + νq

∈

×
for k = 1, . . . , m

12

In the nonresonant case only the values of ¯c6(m, k) and ¯c7(m, k) will

be diﬀerent from zero. Introduce for them special notations

Am, k = ¯c7(m, k),

Cm, k = ¯c6(m, k)

A

∗
k, m.

Cm, k =

Ck, m
Am, k

Note that
and it is also a real valued function i.e.
satisﬁes

Cm, k is a symmetrical function of its arguments, i.e.
Am, k =
imaginary parts of

Cm, k =
∗
m, k, and the function
C

For the following let us also introduce special notations for the real and

Am, k
Am, k = Am, k +
Bm, k = Am, k − Ak, m
¯
2
Am, k and ¯
Bm, k for reasons which will become clear later diﬀu-
Am, m and
Theorem C: Let there be no resonances up to order 4 and let the

We shall call ¯
sion coeﬃcient and tune shift respectively. Note that ¯
¯
Bm, m = 0.
function c(ε) satisfy the condition

Am, m =

Ak, m

2i

¯

,

εc3(ε) = 0

lim
ε→0

Then for any initial points x0, z0, ~y0 , for any nonnegative integers m , k
and for any positive L

q

Xp=0

(cid:12)
*
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

lim
ε→0

max
0≤t≤L/ε2

am, k
p

(ε2sε

t )Im−p, k−p(sε
t )

am, k
p

(0)Im−p, k−p(0)

= 0

q

−

Xp=0

q = min

are an arbitrary
and the functions
where
solution of the system of linear ordinary diﬀerential equations with constant
coeﬃcients

m, k

(τ )

}

{

am, k
p

+(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

dam, k
0
dτ

=

−Am, k am, k

0

dam, k
p
dτ

=

−Am−p, k−p am, k

p − Cm−p+1, k−p+1 am, k

p−1

p = 1, . . . , q

13

The proof of this theorem can be obtained from the remark to the theorem

B with help of some straightforward calculations.

Remark 1: We would like to note that for the study of the behaviour
of ﬁrst order moments (i.e. when m + k = 1) we actually need to avoid
resonances in theorem B up to order 2 only.

Remark 2: The general solution of the system of diﬀerential equations

for the coeﬃcients am, k

has the form

p

am, k
p

(τ ) =

am, k
p

(0)

− Cm−p+1, k−p+1

am, k
p−1 (ζ)

exp (

Am−p, k−p ζ) dζ

·





am, k
0

(τ ) = am, k

(0)

0

exp (

−Am, k τ )

·

τ

Z0

exp (

−Am−p, k−p τ )

·

p = 1, . . . , q

Choosing the initial conditions

am, k
0

(0) = 1,

am, k
p

(0) = 0,

p = 1, . . . , q

the statement of the theorem C can be rewritten in the form

Im, k(0)

am, k
p

(ε2sε

t )Im−p, k−p(sε
t )

= 0

exp(

ε2

Am, ksε

t )Im, k(sε
t )

*

−

In the case when m

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
and Vm, k
Um, k = Uk, m and Vm, k =
when m > k . So we have

− 


−

= k we can use the real valued functions Um, k
instead of the complex valued Im, k . Due to the symmetries
Vk, m it is enough to consider only the case

Corollary 1: Let there be no resonances up to order 4 and let the

function c(ε) satisfy the condition

lim
ε→0

max
0≤t≤L/ε2

q

−

Xp=1

εc3(ε) = 0

lim
ε→0

14



·







+(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

6
Then for any initial points x0, z0, ~y0 , for any nonnegative integers m, k
satisfying m > k , and for any positive L

M m, k
p

(ε2sε
t )

~W m, k
p

(sε
t )

M m, k
p

(0)

~W m, k
p

(0)

= 0

·

·

k

−

Xp=0

lim
ε→0

max
0≤t≤L/ε2

where

k

Xp=0

(cid:12)
*
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
Um−p, k−p(τ )

Vm−p, k−p(τ )

~W m, k
p

(τ ) = 

,



M m, k
p

(τ ) = 



and the functions αm, k
(τ ) are an arbitrary real solution of
the system of linear ordinary diﬀerential equations with constant coeﬃcients

(τ ) and βm, k










p

p

+(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)



αm, k
p

(τ )

βm, k
p

(τ )

−

βm, k
p

(τ )

αm, k
p

(τ )

αm, k
0

βm, k
0

d
dτ 








= ¯Rm, k

0 

αm, k
0

βm, k
0









αm, k
p

βm, k
p

d
dτ 








= ¯Rm, k

p 

αm, k
p

βm, k
p









− Cm−p+1, k−p+1 



αm, k
p−1

βm, k
p−1






p = 1, . . . , k

¯Rm, k

p = 

−

¯
m−p, k−p
A
¯
m−p, k−p
B

¯
m−p, k−p
B
¯
m−p, k−p
A

−









−

For the important particular case when we do not have an external noise
~0 and hence
, αm, k
p

Cm, k = 0) the diﬀerential equations deﬁning the functions am, m

0 (that means that we can put ~h(t)

in our system, i.e. ξ(t)
all
and βm, k

admit the simple solution

≡

≡

p

p

am, m
0

(τ ) = exp(

αm, k
0

(τ )

βm, k
0

(τ )











= exp(

¯
Am, kτ ) 
−




−

(0)

0

¯
Am, mτ ) am, m
−
cos( ¯

sin( ¯

Bm, kτ )
Bm, kτ ) cos( ¯
15

sin( ¯

Bm, kτ )
Bm, kτ )











αm, k
0

(0)

βm, k
0

(0)






am, m
p

(τ )

0,

≡

αm, k
p

(τ )

0,

≡

βm, k
p

(τ )

≡

0,

p

= 0

Choosing initial conditions

am, m
0

(0) = 1,

αm, k
0

(0) = 1,

βm, k
0

(0) = 0

we get the following

Corollary 2: Let ξ(t)

0 and let there be no resonances of orders 2

and 4, and let the function c(ε) satisfy the condition

≡

εc3(ε) = 0

lim
ε→0

Then for any initial points x0, z0, ~y0 , for any nonnegative integers m, k
satisfying m

k , and for any positive L

≥

lim
ε→0

max
0≤t≤L/ε2

exp

−
(cid:16)

ε2 ¯

Am, m sε

t

(cid:17)

rm (sε
t )

rm(0)

= 0

−

(cid:12)
D
(cid:12)
(cid:12)

for k = m and

E(cid:12)
(cid:12)
(cid:12)

exp

*

ε2 ¯

Am,k sε

t

−

¯M k

m(sε

t ) 

(cid:16)

(cid:17)

lim
ε→0

max
0≤t≤L/ε2 (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

¯Um,k(sε
t )

¯Vm,k(sε
t )






− 



¯Um,k(0)

¯Vm,k(0)

= 0

+






(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

¯M k

m(τ ) = 




cos

m,kτ

sin

−

m,kτ

∆ε
(cid:16)
∆ε
(cid:16)

(cid:17)

(cid:17)

sin

m,kτ

cos



where

∆ε
(cid:16)
∆ε
(cid:16)

m,kτ




otherwise.

(cid:17)

(cid:17)

, ∆ε



m,k = (m

k) ω0 −

−

ε2 ¯

Bm,k

For the important case of constant vectors ~b , ~h and ~d the formulae
Am, k, ¯

for ¯

Bm, k and
m + k
2

−

α

Cm, k take the simpliﬁed form
Ψc(0) ~b

~b +

k)2

(m

−

−
4

·

(m + k)2
4

Ψc(0) ~d

~d +

·

¯
Am, k =

16

6
+

m + 2mk + k
4

(cid:20)

Ψc(2ω0) ~b

~b + Ψc(2ω0) ~d

~d +

·

Ψs(2ω0)
(cid:16)

−

Ψ⊤

s (2ω0)

~d

~b

·

(cid:21)

(cid:17)

·

−
4

m2

k2

¯
Bm, k =

Ψc(0) + Ψ⊤
(cid:16)

c (0)
(cid:17)

~d

~b +

·

+

m

k

−
4

(cid:20)

Ψs(2ω0) ~b

~b + Ψs(2ω0) ~d

~d

·

·

−

(cid:16)

Ψc(2ω0)

Ψ⊤

c (2ω0)

−

~d

~b

·

(cid:21)

(cid:17)

Cm, k =

mk
2

Ψc(ω0) ~h

~h

·

6 First and Second Order Moments

First order moments in the nonresonant case:

Corollary C1: Let there be no resonances up to order 2 and let the

function c(ε) satisfy the condition

(cid:12)
(cid:12)
*
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

cos

sin





εc3(ε) = 0

lim
ε→0

Then for any initial points x0, z0, ~y0 and for any positive L

lim
ε→0

max
0≤t≤L/ε2

exp

ε2 ¯
A1, 0 sε

t

(cid:17)

−
(cid:16)

M(sε

t ) 

where

x(sε
t )

z(sε
t )









− 



M(τ ) = 

(cid:16)(cid:16)

ω0 −

ε2 ¯

B1, 0

ω0 −

ε2 ¯

B1, 0

τ

τ

sin

−

ω0 −

ε2 ¯

B1, 0

(cid:17)

(cid:17)

(cid:16)(cid:16)

cos

ω0 −

ε2 ¯

B1, 0

(cid:16)(cid:16)

(cid:16)(cid:16)
Second order moments in nonresonant case:
Corollary C2: Let there be no resonances up to order 4 and let the

(cid:17)

(cid:17)

(cid:17)

(cid:17)

function c(ε) satisfy the condition

εc3(ε) = 0.

lim
ε→0

Then for any initial points x0, z0, ~y0 ∈
17

Rn and for any positive L

= 0

x0

z0

+






(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:17)

(cid:17)

τ

τ







lim
ε→0

max
0≤t≤L/ε2

r0 −

−

ε2 2

C1, 1sε

t

= 0

r (sε
t )
(cid:12)
D
(cid:12)
(cid:12)
for ¯

A1, 1 = 0 and

E(cid:12)
(cid:12)
(cid:12)

lim
ε→0

max
0≤t≤L/ε2

r (sε

t ) +

(cid:12)
* 
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2
C1, 1
¯
A1, 1 !

exp

ε2 ¯
A1, 1sε

t

−

(cid:16)

−  

(cid:17)

r0 +

otherwise.

= 0

2
C1, 1
¯
A1, 1 !+(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

To estimate the behaviour of the remainder of the second moments we

shall use the functions

Corollary C3: Let there be no resonances up to order 4 and let the

function c(ε) satisfy the condition

¯U2, 0 =

x2

z2

−
4

¯V2, 0 =

xz
2

εc3(ε) = 0

lim
ε→0

Then for any initial points x0, z0, ~y0 and for any positive L

exp

*

ε2 ¯

A2, 0 sε

t

−

(cid:16)

(cid:17)

M(sε

t ) 

lim
ε→0

where

max
0≤t≤L/ε2 (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

¯U2, 0(sε
t )

¯V2, 0(sε
t )









− 



¯U2, 0(0)

¯V2, 0(0)

= 0

+






(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

M(τ ) = 

cos

sin

(cid:16)(cid:16)

(cid:16)(cid:16)

2ω0 −

ε2 ¯

B2, 0

2ω0 −

ε2 ¯

B2, 0

τ

τ

(cid:17)

(cid:17)

(cid:17)

(cid:17)





sin

−

2ω0 −

ε2 ¯

B2, 0

cos

2ω0 −

ε2 ¯

B2, 0

(cid:16)(cid:16)

(cid:16)(cid:16)

τ

τ

(cid:17)

(cid:17)

(cid:17)

(cid:17)







18

7 Comparison with White Noise Model

As a special case we consider white noise in this chapter i.e.

~y = C ˙~w(t)

(13)

(14)

where C is a real constant (n
Brownian motion. Substituting (13) into (2) we have

×

r) matrix and ~w(t) is an r-dimensional

dx = ω0 z dt





dz =

ω0 x dt

ε2 α z dt + ε C ⊤

−

−

z ~d

x~b

−

−

~h
(cid:16)

·

(cid:17)

d ~w(t)

As usual for the case of multiplicative noise we shall treat the system (14)
as a system of Stratonovich’s stochastic diﬀerential equations.

Introduce the matrix Φ = 1

2CC ⊤ which plays the role of the spectral
density for the noise model (13) and deﬁne functions ˘cl(m, k) with the help
of

˘c1(m, k) =

m
2

(m

2k

−

1) Φ ~hp ·

~bl −

i (m + 2k) Φ ~hp ·

~dl

−

,

o

νl−νp = ω0 n
X

˘c2(m, k) =

m(m
−
4

−

1)

Φ ~hp ·

~hl,

Xνl−νp = 2ω0

˘c3(m, k) =

1)

m(m
−
2

Φ ~hp ·

~bl −

i~dl

,

(cid:16)

(cid:17)

Xνl−νp = 3ω0

˘c4(m, k) =

m(m
−
4

−

1)

Φ

~bp + i~dp
(cid:16)

~bl −

i~dl

,

(cid:17)

·

(cid:17)

(cid:16)

Xνl−νp = 4ω0

˘c5(m, k) =

m
2

(m + k) Φ ~dp ·

−

~dl +

Xνl−νp = 2ω0 n

+ (k

m + 1) Φ ~bp ·

~bl + i (2k + 1) Φ ~bp ·

~dl

−

,

o

19

˘c6(m, k) =

∞

mk
2

p = −∞
X

Φ ~hp ·

~hp,

˘c7(m, k) =

α +

−

m + k
2

−

4mk

m(m

1)

k(k

1)

∞

−
4

−

−

Φ ~bp ·

~bp +

p = −∞
X

+

4mk + m(m + 1) + k(k + 1)
4

∞

p = −∞
X

Φ ~dp ·

~dp + i

−
2

m2

k2

∞

Φ ~dp ·

~bp.

p = −∞
X

Consider now the system of ordinary diﬀerential equations with constant

coeﬃcients

d
dτ

~
V

(am, k; N) = ˘

KN ~
V

(am, k; N)

generated with the help of the rule

d
dτ am, k = ˘c2(m, k) am−2, k

+ ˘c ∗

2 (k, m) am, k−2

˘c1(m, k) am−1, k

+ ˘c ∗

1 (k, m) am, k−1

˘c3(m, k) am−2, k+1 + ˘c ∗

3 (k, m) am+1, k−2 +

˘c4(m, k) am−2, k+2 + ˘c ∗

4 (k, m) am+2, k−2 +

˘c5(m, k) am−1, k+1 + ˘c ∗

5 (k, m) am+1, k−1 +

˘c6(m, k) am−1, k−1 + ˘c7(m, k) am, k

where on the right hand side of (16) we take into account only terms with
nonnegative indices.

Theorem D: For any initial points x0, z0, ~y0 , for any nonnegative

integer N and for any positive L

lim
ε→0

max
0≤t≤L/ε2

˘
M

−1

N (ε2t) ~
V

(Im, k(t); N)

(Im, k(0); N)

= 0

~
V

−

D

(cid:12)
(cid:12)
(cid:12)

20

(15)

(16)

+

+

E(cid:12)
(cid:12)
(cid:12)

where the matrix
of linear ordinary diﬀerential equations with constant coeﬃcients (15).

˘
MN (τ ) is the fundamental matrix solution of the system
Note that in this case and for the noise model introduced below we have
not to distinguish between sε
t and t. We also mention that if we substitute
into the expressions of ¯cl(m, k) the matrix Φ instead of the matrix Ψ
(”spectral density” of white noise) we exactly get ˘cl(m, k) .

8 Another Noise Model

The technique derived in this paper can be applied to a wide class of noise
models. As a model of noise in this section we consider the stochastic pro-
cesses represented by the following trigonometrical polynomials4 (cosine and
sine functions with random phases)

η(t) =

ηm exp (i (νmt + ~vm ·

~y )) ,

η−m = (ηm)∗

ξ(t) =

ξm exp (i (νmt + ~vm ·

~y )) ,

ξ−m = (ξm)∗

γ(t) =

γm exp (i (νmt + ~vm ·

~y )) ,

γ−m = (γm)∗

Rn satisfying the conditions

with real νm and ~vm ∈
~vm + ~vl|
νl + νm|
+
|
where the integers m, l obey m, l =

|

system

∈

= 0

m + l = 0

⇔

q, . . . , q.

−

The vector ~y

Rn is assumed to be a solution of the following Ito’s

d ~y = √2 B d ~w(t)

4In order not to deal with conditions similar to (4) and (5) we consider the case of a
ﬁnite trigonometrical sum. The extension to the case of inﬁnite series and also the proof
of the theorem E we leave as an exercise for the interested reader.

m=−q
X

m=−q
X

q

q

q

m=−q
X

21

where B is a real constant (n
Brownian motion. For simplicity we assume that the (n
~vm | 6
is nondegenerate and
deterministic harmonics in our perturbation model).

r) matrix and ~w(t) is an r-dimensional
n) matrix B B⊤
q, . . . , q (i.e. we do not have

= 0 for all m =

−

×

×

|

q, . . . , q we introduce real vectors ~up = B⊤~vp ∈
−
= 0, and a function Ω (ω, ~up)

Rr which

For p =
~up| 6
|

satisfy

~up|
Ω (ω, ~up) = |
~up|
|

2 + i ω
4 + ω2

and deﬁne ˜cl(m, k) as follow

˜c1(m, k) =

(m

{

1) Ω (ω0 + νp, ~up) ξp (ηl −

−

iγl)

−

m
4








X|νp+νl+ω0|+
+|~vp+~vl|=0

(k + 1) Ω (2ω0 + νp, ~up) (ηp + i γp) ξl −

−

k Ω (ω0 + νp, ~up) ξp (ηl + i γl)

k Ω (νp, ~up) (ηp + i γp) ξl}

+

−

−

+

X|νl−νp+ω0|+
+|~vl−~vp|=0

m Ω∗ (νp, ~up)
n

(cid:16)

η∗
p −

iγ∗
p

(cid:17)

ξl −

k Ω∗ (ω0 + νp, ~up) ξ∗

p (ηl + iγl)

o








˜c2(m, k) =

m(m
−
4

−

1)

X|νp+νl+2ω0|+
+|~vp+~vl|=0

Ω (ω0 + νp, ~up) ξp ξl

˜c3(m, k) =

1)

m(m
−
4

Ω (ω0 + νp, ~up) ξp (ηl + iγl) +

X|νp+νl+3ω0|+
+|~vp+~vl|=0

{

22

+ Ω (2ω0 + νp, ~up) (ηp + iγp) ξl}

˜c4(m, k) =

m(m
−
4

−

1)

X|νp+νl+4ω0|+
+|~vp+~vl|=0

Ω (2ω0 + νp, ~up) (ηp + iγp) (ηl + iγl)

˜c5(m, k) =

k Ω (νp, ~up) (ηp + iγp) (ηl + iγl) +

m
4








{

X|νp+νl+2ω0|+
+|~vp+~vl|=0

+ (k + 1) Ω (2ω0 + νp, ~up) (ηp + iγp) (ηl + iγl)

−

(m

1) Ω (2ω0 + νp, ~up) (ηp + iγp) (ηl −

−

−

iγl)

} −

−

X|νl−νp+2ω0|+
+|~vl−~vp|=0

m Ω∗ (νp, ~up)

η∗
p −

iγ∗
p

(cid:16)

(cid:17)

(ηl + iγl)





˜c6(m, k) =

q

mk
2

p=−q
X

~up|
|

2

~up|
|

4 + (νp + ω0)2 |

2

ξp|

˜c7(m, k) =

m + k
2

−

α +

mk
2

q

p=−q
X

2

~up|
|
4 + ν2
~up|
|

p |

ηp + iγp|

2 +

+

m2 + k2
4

q

p=−q
X

2

~up|
|
4 + ν2
~up|
|

p (cid:16)

2

γp|

|

2

ηp|

− |

+

(cid:17)

23

+

m + 2mk + k
4

q

2

~up|
|

p=−q
X

~up|
|

4 + (νp + 2 ω0)2 |

ηp + iγp|

2 +

m2

k2

q

+ i

−
4

2

~up|
|
4 + ν2
~up|
|

p (cid:16)

p=−q
X

ηp γ∗

p + η∗

pγp

+

(cid:17)

m

k

q

+ i

−
4

p=−q
X

~up|
|

νp + 2 ω0

4 + (νp + 2 ω0)2 |

2

ηp + iγp|

Theorem E: For any initial points x0, z0, ~y0 , for any nonnegative

integer N and for any positive L

lim
ε→0

max
0≤t≤L/ε2

˜
M

−1

N (ε2t) ~
V

(Im, k(t); N)

(Im, k(0); N)

= 0

~
V

−

where the matrix
of linear ordinary diﬀerential equations with constant coeﬃcients

D
˜
MN (τ ) is the fundamental matrix solution of the system

E(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

d
dτ

~
V

(am, k; N) = ˜

KN ~
V

(am, k; N)

generated with the help of the rule (16) in which we use ˜cl(m, k) instead of
˘cl(m, k).

9 Proof of the Theorems

The purpose of this section is to give a detailed proof of the theorems.

9.1 Proof of the Theorem A

1. From the fact that all eigenvalues of the matrix A have negative
real parts it follows that there exists a quadratic form v( ~y ) satisfying the
conditions

2

~y
C1 |

|

≤

v( ~y )

2

~y
C2 |

|

≤

A~y

grad ~y v( ~y )

·

2

~y
C3 |

|

≤ −

24

Here and below Ci are some positive constants the exact values of which are
unimportant for us.

2. Let ˆL be the generating diﬀerential operator of the n-dimensional

Markovian diﬀusion process ~y i.e.

ˆL =

∂
∂t

+ A~y

grad ~y +

·

BB⊤ grad ~y ·

grad ~y

(17)

3. Introduce the function w( ~y ) = exp(ψ v( ~y )) for wich

1
2

·

grad ~y w = ψ w

grad ~y v

∂2w
∂ym∂yk

= ψ

∂2v
∂ym∂yk

 

+ ψ

∂v
∂ym ·

∂v
∂yk !

w

and hence

ˆLw = ψ

A~y

grad ~y v +

·





n

1
2

Xm, k = 1 (cid:16)

BB⊤

m,k  

(cid:17)

∂2v
∂ym∂yk

+ ψ

∂v
∂ym ·

w

∂v
∂yk !


From this it follows that there exist constants C4 and C5 independent of

the value of ψ such that

ˆL w

ψ

≤

2 +

~y
C3 |

|

(cid:18)−

~y
C4 + ψ C5 |

|

2

w

(cid:19)

1
2

Taking now ψ = C3/2C5 we get

ˆL w

ψ
2

≤

~y
C3 |
−
(cid:16)

|

2 + C4

w

(cid:17)

4. Deﬁne the constant χ as the maximum of the right side in inequality

(18) with respect to the variables ~y

(18)

(19)

Obviously one has

ψ
2

ψ
2

χ = max

~y∈Rn  

~y
C3 |
−
(cid:16)

|

2 + C4

w

!

(cid:17)

0

χ

≤

≤

C4 exp

ψ

C2 C4

(cid:18)

C3 (cid:19)

25

From (18) and (19) it follows, that the function

will satisfy the inequality

ˆw = w + χ

L
ε2 −

(cid:18)

t
(cid:19)

ˆL ˆw

0

≤

(20)

(21)

5. Let ˜sε

t = sε

stochastic process ˆw ( ˜sε

t ∧

L
ε2 . From (20) and (21) immediately follows that the
t ) is a nonnegative supermartingale, and hence

P

τε <

(cid:18)

L
ε2

(cid:19) ≤

P

sup
t ≥ 0 |

 

~y (˜sε
t )

| ≥

c(ε)

! ≤

P

sup
t≥0

 

ˆw (˜sε
t )

≥

exp(ψC1c2(ε))

exp(ψv(~y0)) + χ

exp(

ψC1c2(ε))

! ≤ (cid:18)

L
ε2

(cid:19)

−

The ﬁrst two inequalities in the sequence shown above are almost obvi-
ous, and the last one follows from the property of the stochastic process
ˆw (˜sε
to be a nonnegative supermartingale. For ﬁnishing the proof take
t )
a = max(χ, C2ψ) and b = C1ψ .

9.2 Proof of the Theorem B

1. The joint solution of the systems (2), (3) is a Markovian diﬀusion
process in the (n + 2)-dimensional Euclidean space. Let L be the gener-
ating diﬀerential operator of this stochastic process. Separating the orders
according to ε we can represent L in the form

L = L0 + ε Lε + ε2 Lε2

(22)

where the diﬀerential operators L0 , Lε , Lε2 are deﬁned as follows

L0 = ω0

∂
∂x −

x

∂
∂z !

z
 

+ ˆL,

Lε = (ξ

γ z

η x)

−

−

∂
∂z

,

Lε2 =

α z

−

∂
∂z

and ˆL is the generating diﬀerential operator of the n-dimensional Markovian
diﬀusion process ~y given by (17).

26

2. Now we wish to show that there exist functions uε

m, k satisfying

L0 uε

m, k =

Lε Im, k

−

Representing the operator Lε in the form

Lε =

ξ

(η + iγ) exp(i ω0 t) I0, 1 −

−

(η

−

iγ) exp(

i ω0 t) I1, 0

−

(cid:18)
and calculating 5

∂Im, k
∂z

= i

m
2

exp(i ω0 t) Im−1, k −

i

k
2

−

exp(

i ω0 t) Im,k−1

(24)

and taking into account property b we have

Lε Im, k =

m ξ exp(i ω0 t) Im−1, k −

k ξ exp(

i ω0 t) Im, k−1 +

−

i
2 (cid:18)

(23)

∂
∂z

(cid:19) ·

[ k (η + iγ)

m (η

iγ)] Im, k +

−

−

k (η

iγ) exp(

−

Looking for the uε

i 2 ω0 t) Im+1, k−1 −
−
m, k in analogous form

m (η + iγ) exp(i 2 ω0 t) Im−1, k+1

(cid:19)

uε
m,k =

m a1 exp(i ω0 t) Im−1, k + k a∗

1 exp(

i ω0 t) Im, k−1 +

−

i
2 (cid:18) −

(m a∗

2 −

k a2) Im, k +

m a3 exp(i 2 ω0 t) Im−1, k+1 −

k a∗

3 exp(

i 2 ω0 t) Im+1, k−1

−

(cid:19)

5Starting from this point it is convenient to extend the deﬁnition of the function Ip, q
to negative indices assuming that if p < 0 or q < 0 then Ip, q
0 . In general, after
this extension one has to be careful with respect to the application of the property b, but
we have not to worry about it, because the only source of lowering indices in this paper
is diﬀerentiation and hence if the function Ip, q with negative index will appear we shall
have automatically zero multiplyer in front of it.

≡

27

we get the system deﬁning the unknown al

ˆL a1 + iω0 a1 = ξ

ˆL a2 = η + iγ

ˆL a3 + i 2 ω0 a3 = η + iγ






·

+∞

p=−∞
X

ˆL al =

d~al
dt

 

+ A⊤ ~al

~y

! ·

Choosing al

in the form al = ~al(t)

~y , where

~al(t) =

~al, p exp(i νp t)

(26)

and taking into account that

we reduce the system (25) to a system of algebraic equations for the Fourier
coeﬃcients

(25)

(27)

Λ⊤(ω0 + νp) ~a1, p = ~hp

Λ⊤(νp) ~a2, p = ~bp + i~dp

Λ⊤(2 ω0 + νp) ~a3, p = ~bp + i~dp






Λ(ω) = A + i ω I.

where we have used the notation

So among the characteristic roots of A we have no purely imaginary or zero
values the matrix Λ(ω) is invertiable for an arbitrary real ω and hence the
system (27) has a unique solution, which can be expressed as follows

~a1, p = Λ−⊤(ω0 + νp) ~hp =

Λ∗(ω0 + νp)
A⊤ A⊤ + (ω0 + νp)2I

~hp

~a2, p = Λ−⊤(νp)

~bp + i~dp
(cid:16)

(cid:17)

=

Λ∗(νp)
A⊤ A⊤ + ν2
p I

~bp + i~dp
(cid:16)

(cid:17)

28

~a3, p = Λ−⊤(2ω0 + νp)

Using the estimate

~bp + i~dp
(cid:16)

(cid:17)

=

Λ∗(2ω0 + νp)
A⊤ A⊤ + (2ω0 + νp)2I

~bp + i~dp
(cid:16)

(cid:17)

Λ−⊤(ω)

(cid:12)
(cid:12)
(cid:12)

≤

(cid:12)
(cid:12)
(cid:12)

1
δ2
s

~bp
(cid:12)
(cid:12)
(cid:12)

which is valid for an arbitrary real ω we get for ~al, p

~al, p| ≤
|

1
δ2
s (cid:16)(cid:12)
(cid:12)
(cid:12)

~hp

+

+

~dp

(cid:12)
(cid:12)
(cid:12)
which together with (4) guarantees the absolute convergence and the possi-
bility of diﬀerentiating the series (26) term by term.

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:17)

3. Calculating Lε2 Im, k and Lε uε

m, k we get

Lε2 Im, k + Lε uε

m, k =

c2(m, k) Im−2, k

+ c∗

2(k, m) Im, k−2

c1(m, k) Im−1, k

+ c∗

1(k, m) Im, k−1

+

+

c3(m, k) Im−2, k+1 + c∗

3(k, m) Im+1, k−2 +

c4(m, k) Im−2, k+2 + c∗

4(k, m) Im+2, k−2 +

c5(m, k) Im−1, k+1 + c∗

5(k, m) Im+1, k−1 +

c6(m, k) Im−1, k−1 + c7(m, k) Im, k

(28)

29

m
4

m
4

m
4

m
4

h

h

h

−

m
4

h
2α
h
(m

−

m
4

m
4

−

−

h

where the functions cl(m, k) are given by the following expressions

c1(m, k) =

( k a2 −

m a∗

2 + (k + 1) a3 ) ξ +

k (a1 + a∗

1)(η + iγ)

(m

1) a1 (η

iγ)

exp(i ω0 t)

−

−

−

i

c2(m, k) =

(m

1) a1 ξ

exp(i 2 ω0 t)

c3(m, k) =

(m

1) a1 (η + iγ) + (m

1) a3 ξ

exp(i 3 ω0 t)

i

−

−

−

−

i

i

c4(m, k) =

(m

1) a3 (η + iγ)

exp(i 4 ω0 t)

c5(m, k) =

( k a2 −

−

m a∗

2 + (k + 1) a3) (η + iγ) +

c6(m, k) =

k (a1 + a∗

1) ξ

1) a3 (η

iγ)

exp(i 2 ω0 t)

−

i

i

c7(m, k) =

2α + (k a2 −

k
4

h
2α + (m a∗
h

2 −

m a∗

2 + (k + 1) a3)(η

iγ)

−

−

k a2 + (m + 1) a∗

3)(η + iγ)

i

i

Note that c6(m, k) = c∗
4. Introduce a (n

×

6(k, m) and c7(m, k) = c∗

7(k, m) .

n) matrix K(~y) = ~y

~y ⊤ with the elements kij = yiyj .

It is easy to check, that this matrix satisﬁes the equation

·

ˆL K = AK + KA⊤ + B B⊤

The usefulness of this matrix for the following is connected with the fact that
for arbitrary complex vectors ~a and ~c

(~a

~y )

(~c

~y ) = K ~a

~c ∗ = K ~c

~a ∗

·
5. Deﬁne the (n

·

·
n) matrix-function Pω = Pω( ~y ) with the help of the

·

·

(29)

integral

Pω =

exp(iωτ ) exp(Aτ )K(~y) exp(A⊤τ ) dτ

(30)

×

∞

−

Z0

30

This integral converges because all the characteristic roots of A have negative
real parts. Introduce the new integration variable τ ′ = τ + t , where t is
some parameter. Then (30) becomes

Pω =

exp(iω(τ ′

t)) exp(A(τ ′

t))K(~y) exp(A⊤(τ ′

t)) dτ ′

(31)

−

−

−

∞

−

Zt

Diﬀerentiating (31) with respect to t and using that due to (30) Pω does
not depend on t , we obtain

dPω
dt

= K

APω −

−

PωA⊤

iωPω = 0

−

(32)

Calculating ˆL Pω and taking into account (32) we get

ˆL Pω = APω + PωA⊤

C(ω) =

iωPω + K

C(ω)

(33)

−

−

−

where we have introduced the notation

C(ω) =

exp(iωτ ) exp(Aτ )BB⊤ exp(A⊤τ ) dτ,

C(0) = D

∞

Z0

For the following let us rewrite (33) in the form

ˆL Pω + iωPω = K

C(ω)

−

Note that for some positive constant C1 the norms of the matrices Pω and
C(ω) can be estimated uniformly with respect to real ω as follows (using 6)

Pω | ≤

|

C1
~y
δ2
s |

|

2,

C(ω)

|

| ≤

C1
δ2
s

6. Now we wish to show that there exist functions gl(m, k) 6 satisfying

ˆL gl(m, k) + cl(m, k) = ¯cl(m, k),

l = 1, . . . , 7

and these functions have continuous ﬁrst and continuous ﬁrst and second
derivatives with respect to the variables t and ~y respectively, and these

6Of course, gl(m, k) like cl(m, k) are also functions of t and ~y

(34)

(35)

31

functions together with the above derivative are bounded with respect to the
variable t for ﬁxed values of m, k, ~y .

We shall show this for l = 2 and the rest can be done by analogy.
Due to (29) and the reality of the vector ~h (that is ~h = ~h ∗ ) we have

c2(m, k) =

a1 ξ exp(i 2 ω0 t) =

1)

m(m
−
4

1)

m(m
−
4

~h ∗

K ~a1 ·

(cid:16)

(cid:17)

exp(i 2 ω0 t) =

1)

m(m
−
4

K ~a1 ·

(cid:16)

~h
(cid:17)

exp(i 2 ω0 t)

Substituting in the last expression the Fourier series of the vectors ~a1 and
~h we transform c2(m, k) into the form

c2(m, k) =

∞

1)

m(m
−
4

Xp, l = −∞ (cid:16)

K ~a1, p ·

~hl

exp(i(νp −

(cid:17)

νl + 2ω0)t) =

1)

m(m
−
4






For ω

= 0 introduce the matrix

K~a1, p ·

~hl +

K~a1, p ·

~hl

exp(i(νp −

νl + 2ω0)t)

Xνl−νp = 2ω0

Xνl−νp 6= 2ω0 (cid:16)

(cid:17)






Q(ω) =

C(ω)

Pω

−

i
ω

and denote P =

P0. Taking into account (34) we have

ˆL (Q(ω) exp(iωt)) =

K exp(iωt)

and

ˆL P = D

K

−

−

−

Choosing now

g2(m, k) =

1)

m(m
−
4

P~a1, p ·

~hl +

Q(νp −

νl + 2ω0)~a1, p ·

exp(i(νp −

νl + 2ω0)t)

Xνl−νp 6= 2ω0 (cid:16)






Xνl−νp = 2ω0






~hl

(cid:17)

32

6
we obtain

ˆL g2(m, k) + c2(m, k) =

1)

m(m
−
4

D ~a1, p ·

~hl

Xνl−νp = 2ω0

which just coincides with the expression for ¯c2(m, k) if we take into account
that

D ~a1, p = D

Λ∗(ω0 + νp)
A⊤ A⊤ + (ω0 + νp)2I

~hp =

Ψ∗(ω0 + νp) ~hp

(36)

−

Due to (35) and (5) we have

max

P

, max

νl−νp 6= 2ω0 |

Q(νp −

|

( |

νl + 2ω0)

| ) ≤

C1
~y
δ2
s  |

|

2 +

1
δ2
f !

and hence, as it can be easily shown, the series deﬁning the function g2(m, k)
converges absolutely with

g2(m, k)

|

| ≤

1)

m(m
−
4

C1
~y
δ2
s  |

|

2 +

1
δ2
f ! 


∞

p=−∞ |
X

∞

~hp

(37)

~a1, p|



p=−∞ (cid:12)
X
(cid:12)
(cid:12)






(cid:12)
(cid:12)

(cid:12)

The function g2(m, k) is a quadratic polynomial in ~y and so we need

to worry about their partial derivative with respect to t only. Expressing

∂g2(m, k)
∂t

=

1)

m(m
−
4

i µp, l

Q(µp, l) ~a1, p ·

Xµp, l 6= 0

(cid:16)

~hl

(cid:17)

exp(iµp, lt)

where µp, l = νp −
µp, l| ≤

|

νl + 2ω0 and using the very rough estimate for

µp, l|

|

C2(1 +

)(1 +

νp|

|

),

νl|

|

C2 = max

1, 2

{

ω0| }

|

we get that the series deﬁning the partial derivative with respect to the
variable t converges absolutely with

∂g2(m, k)
∂t

1)

m(m
−
4

C1
~y
δ2
s  |

|

2 +

1
δ2
f !

C2·

≤

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

∞

· 


p=−∞
X

(1 +

)

νp|

|

~a1, p|
|



(1 +

)

νp|

|

(38)

∞

p=−∞
X




33

~hp
(cid:12)
(cid:12)
(cid:12)





(cid:12)
(cid:12)
(cid:12)

Note that expressions similar to (36) hold also for D~a2, p and D~a3, p

D ~a2, p =

Ψ∗(νp)

−

~bp + i~dp
(cid:16)

(cid:17)

D ~a3, p =

Ψ∗(2ω0 + νp)

−

~bp + i~dp
(cid:16)

(cid:17)

7. Deﬁning uε2

m, k as

uε2
m, k = g2(m, k) Im−2, k

+ g∗

2(k, m) Im, k−2

+

+

g1(m, k) Im−1, k

+ g∗

1(k, m) Im, k−1

g3(m, k) Im−2, k+1 + g∗

3(k, m) Im+1, k−2 +

g4(m, k) Im−2, k+2 + g∗

4(k, m) Im+2, k−2 +

g5(m, k) Im−1, k+1 + g∗

5(k, m) Im+1, k−1 +

g6(m, k) Im−1, k−1 + g7(m, k) Im, k

and acting on the function

by means of the operator L we have

˜Im, k = Im, k + ε uε

m, k + ε2 uε2

m, k

(39)

L ˜Im, k =

L0 + εLε + ε2Lε2
(cid:16)

(cid:17)

˜Im, k =

L0 Im, k + ε

m, k + Lε Im, k

+

L0 uε
(cid:16)

ε2

L0 uε2

m, k + Lε2 Im, k + Lε uε

m, k

+ ε3Rm, k

where for the remainder Rm, k we have the expression

(cid:16)

Rm, k = Lε2 uε

m, k + Lε uε2

m, k + εLε2 uε2

m, k

(40)

(41)

(cid:17)

(cid:17)

34

Due to our construction of the functions Im, k , uε
follows that

m, k and uε2

m, k from (40) it

L ˜Im, k = ε2 (¯c2(m, k) Im−2, k

+ ¯c ∗

2 (k, m) Im, k−2

¯c1(m, k) Im−1, k

+ ¯c ∗

1 (k, m) Im, k−1

¯c3(m, k) Im−2, k+1 + ¯c ∗

3 (k, m) Im+1, k−2 +

+

+

¯c4(m, k) Im−2, k+2 + ¯c ∗

4 (k, m) Im+2, k−2 +

(42)

¯c5(m, k) Im−1, k+1 + ¯c ∗

5 (k, m) Im+1, k−1 +

¯c6(m, k) Im−1, k−1 + ¯c7(m, k) Im, k)

+

ε3 Rm, k

8. So

p+q
2

r
2 (cid:19)

m+k
2

r
2 (cid:19)

|

(cid:18)

=

1 +

Ip, q |
m + k , then for some positive constant C3 independent of m
m, k deﬁned above and Rm, k can be roughly

m, k , uε2

Im, k |

= 1 +

≤

(cid:18)

|

for p + q
≤
and k the functions uε
estimated as follows

≤

(cid:12)
(cid:12)
(cid:12)

uε
m, k

(cid:12)
(cid:12)
(cid:12)
uε2
m, k

(cid:12)
(cid:12)
(cid:12)

≤

(cid:12)
(cid:12)
(cid:12)

C3(m + k)

(1 +

~y
|

|

Im, k |

)

|

C3(m + k)2

2

~y
|

|

1 +
(cid:16)

(1 +

Im, k |
)

|

C3(m + k)3

1 +

3

~y
|

|

(1 +

Im, k |

)

|

(cid:16)

(cid:17)

(cid:17)

Rm, k | ≤

|
Im, m |

9. So

|
of m we have from (42)
L ˜Im, m ≤

ε2 C4 m2 (1 + Im, m) + ε3

Rm, m |

|

Using the estimate (45) we can rewrite (46) in the form
L ˜Im, m ≤

Hm (1 + Im, m)

ε2

35

(43)

(44)

(45)

(46)

(47)

= Im, m then for some positive constant C4 independent

and for uε

m, m + ε uε2

m, m we have from (43) and (44)

m, m + ε uε2
uε

m, m

≤ Gm (1 + Im, m)

Here

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

Hm = m2

C4 + ε 8 m C3
(cid:16)

(cid:16)

1 +

3

~y
|

|

(cid:17)(cid:17)

Gm = 2 m C3

~y
|

|

(cid:16)

+ ε 2 m

1 +
(cid:16)

2

~y
|

|

(cid:17)(cid:17)

Let ¯

Hm and ¯

Gm be some positive constants. Consider the function

vm =

1 + ˜Im, m

exp

(cid:16)

(cid:17)

ε2

 −

1

¯
Hm
ε ¯
Gm
−

t
!

for which after some straightforward calculations we have

L vm ≤

ε2

Hm −

 

(cid:16)

¯
Hm

(cid:17)

+ ε

1

¯
Hm
ε ¯
Gm (cid:16)
−

Gm −

¯
Cm

! ·
(cid:17)

Choosing now

(1 + Im, m) exp

·

ε2

 −

1

¯
Hm
ε ¯
Gm
−

t
!

¯
Hm = m2

(cid:16)

C4 + ε 8 m C3

1 + c3(ε)

(cid:16)

(cid:17)(cid:17)

(48)

(49)

(50)

(51)

¯
Gm = 2 m C3

c(ε) + ε 2 m
(cid:16)

1 + c2(ε)
(cid:16)

and assuming that ε is small enough to guarantee 1
(51) that L vm ≤
0 on the set

−
c(ε) and hence

| ≤

~y
|
vm (sε
t )

h

i ≤ h

vm (0)
i

Using that with probability one

(cid:17)(cid:17)
ε ¯
Gm > 0 we get from

(52)

1 + ˜Im, m (sε
t )

(1 + Im, m (sε

t ))

≤

1 + ε ¯
Gm
(cid:16)

(cid:17)

36

1 + ˜Im, m (sε
t )

≥
and hence with probability one

(cid:16)

1

ε ¯
Gm

−

(cid:17)

(1 + Im, m (sε

t ))

1

ε ¯
Gm

−

(cid:16)

(cid:17)

(1 + Im, m (sε

t )) exp

ε2

 −

1

¯
Hm
ε ¯
Gm
−

t
! ≤

vm (sε
t )

vm (0)

≤

1 + ε ¯
Gm
(cid:16)

(cid:17)

(1 + Im, m (0))

we have from (52) the estimate

1 + Im, m (sε
t )
h

i ≤

1 + Im, m (0)
i

exp

ε2

 

1

1 + ε ¯
Gm
ε ¯
1
Gm h

−

¯
Hm
ε ¯
Gm
−

t
!

which for the following is rewritten in the form

max
0≤t≤L/ε2

1 + Im, m (sε
t )
h

i ≤

¯
Dm h

1 + Im, m (0)
i

(53)

where

¯
Dm =

1 + ε ¯
Gm
ε ¯
1
Gm

exp

1

 

−
10. Denoting um, k = uε
˜Rm, k = Rm, k −

L ¯

,

Hm
ε ¯
Gm !
−
m, k + εuε2

lim
ε→0

¯
Dm = exp

m2LC4
(cid:16)

(cid:17)

m, k and introducing the new remainder

¯c2(m, k) um−2, k

¯c ∗
2 (k, m) um, k−2

−

−

¯c1(m, k) um−1, k

−
¯c3(m, k) um−2, k+1 −
¯c4(m, k) um−2, k+2 −
¯c5(m, k) um−1, k+1 −
¯c6(m, k) um−1, k−1 −

¯c ∗
1 (k, m) um, k−1

−
¯c ∗
3 (k, m) um+1, k−2 −
¯c ∗
4 (k, m) um+2, k−2 −
¯c ∗
5 (k, m) um+1, k−1 −
¯c7(m, k) um, k

which admits the estimate (as follows from (43)-(44))

˜Rm, k

C5(m + k)3(1 + ε(m + k))

1 +

3

~y
|

|

(cid:17)

(1 +

Im, k |

)

|

(cid:16)

(54)

(cid:12)
(cid:12)
(cid:12)

≤

(cid:12)
(cid:12)
(cid:12)

37

we get from (42)

L ˜Im, k = ε2

¯c2(m, k) ˜Im−2, k
(cid:16)
¯c1(m, k) ˜Im−1, k

+ ¯c ∗

2 (k, m) ˜Im, k−2

+ ¯c ∗

1 (k, m) ˜Im, k−1

+

+

¯c3(m, k) ˜Im−2, k+1 + ¯c ∗

3 (k, m) ˜Im+1, k−2 +

¯c4(m, k) ˜Im−2, k+2 + ¯c ∗

4 (k, m) ˜Im+2, k−2 +

(55)

¯c5(m, k) ˜Im−1, k+1 + ¯c ∗

5 (k, m) ˜Im+1, k−1 +

¯c6(m, k) ˜Im−1, k−1 + ¯c7(m, k) ˜Im, k

+

(cid:17)

ε3 ˜Rm, k

Let now N be as in the theorem B. Using notation ~
V

rewrite (55) in the form of the following system

(

∗

; N) we can

L ~
V

( ˜Im, k; N) = ε2 ¯

KN ~
V
where the matrix ¯
KN is the same as in (10).
¯
MN (τ ) is assumed to be the fundamental matrix solution
The matrix
of (10). That means that the matrix

( ˜Im, k; N) + ε3 ~
V

( ˜Rm, k; N)

−1
N (ε2t) satisﬁes

(56)

d
dt

¯
M

−1
N (ε2t) =

ε2 ¯
M

−

Applying the operator L to the vector
into account (56), (57) we obtain

−1

¯
M
N (ε2t) ¯
KN ,
¯
M

¯
M
N (ε2t) ~
V

−1

−1
N (0) = I

(57)

( ˜Im, k(t); N) and taking

L

¯
M
(cid:16)

−1

N (ε2t) ~
V

( ˜Im, k(t); N)

= ε3 ¯
M

−1

N (ε2t) ~
V

( ˜Rm, k(t); N)

(58)

(cid:17)

From (58) and Dynkin’s formula (see, for example [4]) it follows that

¯
M

−1
N (ε2sε

t ) ~
V

( ˜Im, k(sε

t ); N)

~
V

−

( ˜Im, k(0); N)

=

E

D

= ε3

¯
M

−1

N (ε2τ ) ~
V

( ˜Rm, k(τ ); N) dτ

+

sε
t

*

Z0

38

or, equivalently

¯
M

N (ε2sε
−1

t ) ~
V

(Im, k(sε

t ); N)

~
V

−

(Im, k(0); N)

=

E

= ε

(um, k(0); N)

¯
M

N (ε2sε
−1

t ) ~
V

−

(um, k(sε

t ); N)

+

E

D

~
V

·

D

+ ε3

sε
t

*

Z0

From (59) we obtain

¯
M

−1

N (ε2τ ) ~
V

( ˜Rm, k(τ ); N) dτ

+

(59)

max
0≤t≤L/ε2

¯
M

N (ε2sε
−1

t ) ~
V

(Im, k(sε

t ); N)

~
V

−

(Im, k(0); N)

ε

·

max
0≤τ ≤L

≤

(cid:12)
D
(cid:12)
(cid:12)
−1
N (τ )

(cid:12)
(cid:12)
(cid:12)

¯
M
(cid:12)
(cid:12)
(cid:12)

max
0≤t≤L/ε2

2

D

~
V
(cid:12)
(cid:12)
(cid:12)

Let us deﬁne now [m] as the smallest integer which is bigger or equal to m.
Using (43), (44), (54) and simple inequalities like

(um, k(sε

t ); N)

+ L

( ˜Rm, k(sε

t ); N)

(60)

~
V
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

E

(cid:12)
(cid:12)
(cid:12)

≤

E(cid:12)
(cid:12)
(cid:12)

~y

|

| ≤

1 +

~y

|

2

|

1 +

Im, k | ≤

|

2

1 + I[ N
(cid:18)

2 ], [ N
2 ]

,

(cid:19)

m + k

N

≤

we can obtain

~
V
n(cid:12)
(cid:12)
(cid:12)

max

(um, k; N)

,

( ˜Rm, k; N)

~
V
(cid:12)
(cid:12)
(cid:12)

3

~y
|

|

(cid:12)
(cid:12)
(cid:12)
1 +
(cid:16)

≤

o

(cid:12)
(cid:12)
(cid:12)
1 + I[ N

2 ], [ N
2 ]

(cid:19)

C6N 5 (1 + εN)

≤

(cid:17) (cid:18)
Taking into account (53) we have from (61)

(61)

(um, k(sε

t ); N)

+ L

( ˜Rm, k(sε

t ); N)

max
0≤t≤L/ε2

2
D

~
V
(cid:12)
(cid:12)
(cid:12)

≤

E

(cid:12)
(cid:12)
(cid:12)

C6N 5 (1 + εN)

≤

1 + c3(ε)
(cid:16)

(cid:17)

D[ N
2 ]

1 + I[ N
(cid:18)

2 ], [ N

2 ](0)
(cid:19)

~
V

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(2 + L) ¯

39

which together with

max
0≤τ ≤L

−1
N (τ )

¯
M

≤

exp(C7N 2)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

and (60) gives the ﬁnal estimate we need

max
0≤t≤L/ε2

¯
M

N (ε2sε
−1

t ) ~
V

(Im, k(sε

t ); N)

~
V

−

(Im, k(0); N)

(cid:12)
D
(cid:12)
(cid:12)

≤

E(cid:12)
(cid:12)
(cid:12)

ε

1 + c3(ε)

P

1 + I[ N
(cid:18)

2 ], [ N

2 ](0)
(cid:19)

(cid:17)

≤

(cid:16)

(62)

where

P = C6N 5 (1 + εN) (2 + L) ¯

2 ] exp(C7N 2)

D[ N

Taking the limit ε

0 we have from (62) the proof of the theorem B

with speed of convergence ε c3(ε).

→

11. To prove the remark to the theorem B we apply the operator L to
( ˜Im, k(t); N) with the result that

the function ~aN (ε2t)

~
·
V
( ˜Im, k(t); N)

(cid:17)

L

~aN (ε2t)
(cid:16)

~
V

·

= ε3 ~aN (ε2t)

( ˜Rm, k(t); N)

(63)

~
V

·

The rest of the proof is just repeating all the steps from the previous point
with the usage (63) instead of (58).

9.3 Sketch of the Proof of the Theorem D

1. The solution of the system (14) is a Markovian diﬀusion process in the
2-dimensional Euclidean space. Let L be a generating diﬀerential operator
of this stochastic process. Separating the orders according to ε we can
represent L in the form

L = L0 + ε2 Lε2

(64)

where the diﬀerential operators L0 and Lε2 are deﬁned as follows

L0 =

+ ω0

∂
∂t

∂
∂x −

x

∂
∂z !

z

 

40

Lε2 =

z

~d

Φ ~d
(cid:16)

·

−

(cid:17)

(cid:16)

α

+ x Φ ~b

~d

·

−

Φ ~h

~d

·

(cid:17)

∂
∂z

+

+

Φ ~h

~h

2x Φ ~h

~b

2z Φ ~h

~d +

·

−

·

−

·

(cid:16)

+ x2 Φ ~b

~b + 2xz Φ ~d

~b + z2 Φ ~d

~d

·

·

∂2
∂z2

·

(cid:17)

2. Now we wish to calculate Lε2 Im, k . Representing the operator Lε2 in

the form

Lε2 =

Φ~h

~d +

Φ~b

~d

i α + i Φ~d

~d

exp(i ω0 t) I0, 1 +

(cid:18) −

·

·

−

h

·

i

+

Φ~b

~d + i α

·

h

i Φ~d

~d

·

−

i

exp(

i ω0 t) I1, 0

−

∂
∂z

+

(cid:19) ·

+

~h

Φ~h
(cid:18)

·

−

h

2

Φ~h

~b + i Φ~h

~d

exp(i ω0 t) I0, 1 −

·

i

·

−

2

Φ~h

~b

i Φ~h

~d

exp(

i ω0 t) I1, 0 + 2

Φ~b

~b + Φ~b

~d

I1, 1 +

−

h

·

−

·

i

·

h

·

i

+

Φ~b

~b

Φ~d

~d + 2 i Φ~d

~b

exp(i 2 ω0 t) I0, 2 +

·

−

·

h

·

i

+

Φ~b

~b

Φ~d

~d

·

−

·

−

h

2 i Φ~d

~b

exp(

i 2 ω0 t) I2, 0

·

i

−

∂2
∂z2

(cid:19) ·

taking into account (24), property b and the expression

∂2Im, k
∂z2 =

mk
2

Im−1, k−1 −

1)

m(m
−
4

−

exp(i 2 ω0 t) Im−2, k −

k(k

1)

−
4

exp(

i 2 ω0 t) Im,k−2

−

41

we obtain that Lε2 Im ,k is given by the right hand side of (28) with cl(m, k)
as follows

c1(m, k) =

m
2

(m

2k

−

−

·

−

1) Φ~h

~b

i (m + 2k) Φ~h

~d

exp(i ω0 t)

·

i

c2(m, k) =

Φ~h

~h

exp(i 2 ω0 t)

h
m(m−1)
4

−

·

·

i
~b
(cid:16)

i ~d

−

h

h

h

c3(m, k) =

m(m−1)
2

Φ~h

exp(i 3 ω0 t)

c4(m, k) =

m(m−1)
4

−

c5(m, k) =

m
2

α
h

−

Φ

~b + i ~d
(cid:16)

(m + k) Φ ~d

(cid:17) i
~b
(cid:16)
~d + (k

−

·

(cid:17)

·

i ~d

−

exp(i 4 ω0 t)

(cid:17) i
m + 1) Φ~b

~b +

·

i (2k + 1) Φ~b

~d

exp(i 2 ω0 t)

·

i

c6(m, k) =

mk

2 Φ~h

~h

·

c7(m, k) =

m+k

2 α + 4mk−m(m−1)−k(k−1)

4

Φ~b

~b +

−

·

2

4mk+m(m+1)+k(k+1)
4

Φ ~d

~d + i m2−k2

Φ ~d

~b

·
3. Now, like in the proof of theorem B, we want to show that there exist

·

for ﬁxed m and k functions gl(m, k) bounded in t and satisfying

∂gl(m, k)
∂t

+ cl(m, k) = ˘cl(m, k),

l = 1, . . . , 7

We shall show it for l = 4 and the rest can be done by analogy.

Substituting in the expression for c4(m, k) the Fourier series of the vectors

~b and ~d we obtain

c4(m, k) =

m(m
−
2

−

1)

∞

Xp, l = −∞ h

Φ

~bp + ~dp
(cid:16)

·

(cid:17)

(cid:16)

~bl −

~dl

(cid:17)i

exp(i µp, lt) =

= ˘c4(m, k)

1)

m(m
−
4

−

Φ

~bp + ~dp
(cid:16)

·

(cid:17)

(cid:16)

~bl −

~dl

(cid:17)i

Xµp, l 6= 0 h

exp(i µp, lt)

where µp, l = νp −

νl + 4ω0 .

42

So the problem will be solved if the series

c4(m, k) = i

1)

m(m
−
4

Xµp, l 6= 0

Φ

~bp + ~dp
(cid:16)

·
(cid:17)
µp, l

(cid:16)

~bl −

~dl

exp(i µp, lt)

(cid:17)

converges and can be diﬀerentiated term by term. The absolute convergence
and diﬀerentiability can be easily shown using (4) and (5) with the ﬁnal
estimates

g4(m, k)

|

| ≤

1)

m(m
−
2

Φ
|
|
δ2
f

∂g4(m, k)
∂t

1)

m(m
−
2

Φ
|

≤

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

∞

~bp

+

~dp





p=−∞ (cid:12)
X
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)





(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

∞

~bp

+

| 


p=−∞ (cid:12)
X
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

2

~dp
(cid:12)
(cid:12)
(cid:12)


(cid:12)
(cid:12)

(cid:12)

4. The rest follows the simpliﬁed version of the proof of the theorem B.

References

[1] Balandin, V.V., A Method of Perturbed Lyapunov Functions in the Study
of the Asymptotical Behaviour of the Solutions of Ordinary Diﬀerential
Equations with Small Stochastic Perturbations Leading to Markovian
Diﬀusion Processes, Candidate Dissertation, Moscow State University,
1987.

[2] Freidlin, M.I., Wentzell, A.D. Random Perturbations of Dynamical Sys-

tem, Springer-Verlag, 1984.

[3] Karatzas, I., Shreve, S.E., Brownian Motion and Stochastic Calculus,

Graduate Texts in Mathematics 113, Springer-Verlag, 1987.

[4] Kushner, H.J., Stochastic Stability and Control, ACADEMIC PRESS,

New-York/London, 1967.

43

