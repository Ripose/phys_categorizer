1
0
0
2
 
v
o
N
 
4
1
 
 
]
t
e
d
-
s
n
i
.
s
c
i
s
y
h
p
[
 
 
1
v
7
2
1
1
1
1
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A COST-EFFICIENT PC BASED FRAME GRABBER AS BEAM
DIAGNOSTIC TOOL IN AN EPICS ENVIRONMENT∗

B. Franksen, R. Bakker, B. Kuner, J. Rahn, H. R¨udiger, BESSY, Berlin, Germany

THAP045

Abstract

Analysis of video images is a common way to determine
properties of an electron or synchrotron radiation beam. At
BESSY cost-efﬁcient frame grabber hardware running on a
Windows PC allows to perform such analysis in real-time.
Life video images on the PC monitor give operators a direct
view of the beam, enhanced by optional artiﬁcial coloring
and graphical overlays. In order to integrate the application
into the EPICS [1] environment, it contains a Channel Ac-
cess [2] (CA) server, making the numerical results and the
application’s control commands accessible over a network
through CA process variables. A newly developed C++
class library is used to provide the variables with the usual
attributes required by advanced CA clients like graphical
display managers.

1

INTRODUCTION

In accelerator facilities the quality of the service depends
among other factors on the geometrical properties of the
beam, the most interesting aspect being its cross-section
proﬁle. It is thus common to install cameras and to display
the resulting video images on some screen in the control
room. Single images are often digitized and saved to disk
for later processing by specialized image analysis tools.
However, there are applications for which this is not suf-
ﬁcient, because the results of the image analysis need to be
available in real-time.1

One of these applications is to enhance the optical quali-
ties of the life video images as a human-readable diagnostic
tool by artiﬁcial coloring and by adding graphical overlays.
Others include feedback systems that automatically detect
deviations from the desired geometry and correct them if
possible or otherwise signal an alarm condition. Such sys-
tems are under consideration in response to the constantly
rising demands for further improvement of the beam qual-
ity. In all cases a well-deﬁned set of scalar variables that
characterize the geometrical properties of the beam proﬁle
needs to be extracted from the huge amount of raw pixel
data.

The standard setup for such a system incorporates a

monochrome2 CCD camera (to produce the video data
stream), a frame grabber card (to digitize the video data),
and ﬁnally some piece of software to perform the online
image analysis and to enable interaction with users through
high-level client applications.

This paper concentrates on two speciﬁc problem areas
that appeared during the design and implementation of such
a system at BESSY for which we found solutions that
might be of general interest.

First, a suitable set of numerical values that characterize
the beam proﬁle geometry had to be found, with the bound-
ary condition that these must be computable in real-time for
high-resolution images arriving at a rate in the order of ten
frames per second. The application of statistical methods
made it possible to achieve this goal. This will be discussed
in Section 2.

Second, the solution had to be integrated into an EPICS
based control system, while remaining cost-efﬁcient and
adaptable to changing demands.3 Since cost-efﬁciency
rules out VME based hardware in favor of standard Win-
dows PC technology, integration became a non-trivial is-
sue. We discuss this in greater detail in Section 3.

2 USING STATISTICAL METHODS FOR

EFFICIENT IMAGE ANALYSIS

2.1 Requirements

Modern CCD cameras and frame grabbers deliver images
with a resolution in the order of 400,000 pixels per frame.
The typical rates at which video images are delivered and
grabbed is around 10 Hz.
Interesting geometrical prop-
erties of the beam include position, diameter (in various
directions) and orientation (if the proﬁle is not circular).
These should be extracted from the raw pixel data without
loss of the precision provided by the hardware, such that
each frame can be processed and displayed on a computer
monitor in 1/10 of a second. Processing includes artiﬁcial
coloring as well as the addition of graphical overlays to in-
dicate the results of the image analysis in a more intuitive
way. We can expect the image to resemble a more or less
elliptically shaped ‘smeared’ spot, superimposed by vary-
ing amounts of background noise.

2For technical reasons, acquiring color images is normally not consid-

3One the reasons being that the high-level applications still remain to

∗ Funded by the Bundesministerium f¨ur Bildung, Wissenschaft,

Forschung und Technologie (BMBF) and the Land Berlin

1Whenever used in this paper, the term ‘real-time’ refers to ‘soft real-
time’, i.e. occasional violations of the timing constraints are acceptable as
long as they are not exceeded on average.

ered useful.

be speciﬁed.

These demands immediately rule out a number of meth-
ods for image analysis (such as ﬁtting or edge detection),
simply because they cannot be implemented efﬁciently
enough. Instead, the expected geometry suggests a much
simpler approach using statistical methods, the application
of which resulted in a system that is able to meet the re-
quired timing constraints on a 500 MHz Pentium PC under
Windows NT 4.0.

2.2

Statistical Image Analysis

The main idea is to interprete the image as a two-
dimensional probability distribution. With this identiﬁca-
tion, the center of the beam corresponds to the distribu-
tion’s ﬁrst moment, the mean value. In order to ﬁnd out
how far the beam is ‘smeared out’ and in which direction,
we also need to consider the second moments. For a two-
dimensional distribution, these are given by the elements of
the two-by-two covariance matrix, i.e. the four values covij
. The diagonal elements vari = covii are
with i, j
the variances, the respective square roots σi = √vari the
standard deviations in the direction of i, where i may be
either x or y.

x, y

∈ {

}

The single fact that the covariance matrix is symmetric,
i.e. that covxy = covyx, implies that it can be diagonalized
by singular value decomposition (SVD) and furthermore,
that any pair of linearly independent eigenvectors are mu-
tually orthogonal. There is exactly one angle in the interval
[0, π/2[ such that after applying a rotation around this an-
gle, the mixed covariances become zero and the two vari-
ances become extreme (with respect to the angle of rota-
tion), i.e. one will be minimal, the other one maximal. This
shows that any two-dimensional distribution (assuming it is
not completely direction independent) has exactly one di-
rection of maximal deviation and one of minimal deviation,
and that these directions are mutually orthogonal and can
be determined by an SVD of the covariance matrix. The
latter has to be computed only once using any arbitrarily
chosen coordinate system.

The crucial point here is that the mere computation of
ﬁve scalar values – two for the mean value, three for the
covariance matrix – implicitly contains information about
the deviations in all directions, i.e. the exact shape of the
so called ellipse of standard deviation. If the distribution of
the beam intensity is nearly gaussian (as we can normally
expect it to be), this ellipse is a good approximation of the
geometry of the beam proﬁle. Moreover, these ﬁve numer-
ical values can be computed very efﬁciently.

2.3 Efﬁcient Calculation

The reason for this is twofold: First, they can be accumu-
lated in one single pass over the image. Second, during that
single pass, only simple arithmetical operations need to be
performed. More speciﬁcally, for each frame it sufﬁces to
accumulate the six values p, px, py, px2, py2, and pxy for
each pixel value p at coordinates x and y. With standard
camera resolutions, a monochrome color depth of 8 bits

per pixel, and a compiler which supports 64 bit integer em-
ulation (like Microsoft’s Visual C++ does), ﬂoating point
operations can be completely avoided inside this loop.

The additional computations necessary e.g. for calibra-
tion and SVD are much less critical, since they need to be
performed only once per frame – instead of once per pixel.
Analytical solution of the SVD gives the eigenvalues of the
covariance matrix (or equivalently the maximum and min-
imum deviations) as

varx + vary
2

varx

vary

−
2

2

(cid:19)

± s

(cid:18)

+ covxy,

which are assumed at the angles

2 covxy

1
2

arctan

varx

vary (cid:19)
2.4 Background Noise

−

(cid:18)

π
2

+ n

(n = 0, 1, 2, . . .).

An important factor when using statistical methods as de-
scribed above is the amount of background noise. Even
if the beam’s contribution to the signal is near to the ideal
gaussian distribution, additional noise will make the devi-
ation from the center appear larger than it actually is. This
effect must be compensated for, especially since the level of
noise has the tendency to depend on various external condi-
tions, including the ring current, i.e. beam intensity. Three
methods are presented here that can be used to deal with
this problem. The system developed at BESSY provides
all three methods, conﬁgurable by the user or high-level
applications.

One rather simple approach is to cut off any signal below
a certain threshold, the height of which must be determined
experimentally. While being very efﬁcient to implement,
this approach is of limited use if the noise level varies too
much.

A more advanced approach is to dynamically determine
the level of background by an integration over a suitable
closed path around the beam, typically the border of the
image or the so called area of interest to be analyzed. This
value will be subtracted from the whole area. This ap-
proach works well if the noise is evenly distributed over the
area. It is not too costly to implement, since the number of
pixels to be scanned is far lower than that of the whole area.
A third method might be appropriate in situations where
strong background radiation is present even without a
beam. In this case, it makes sense to record an image of this
background and to subtract it pixel by pixel from the image
to be analyzed. This approach implies a greater penalty on
efﬁciency and rules out automatic gain control by the cam-
era. Nevertheless, there appear to be situations where this
is the only way to get reliable results.

3 INTEGRATION INTO AN EPICS

ENVIRONMENT

EPICS uses a communication protocol called Channel Ac-
cess (CA), which is specialized for efﬁcient communica-

tion in large distributed control systems.
It follows the
client-server paradigm in that low-level I/O controllers
(IOCs) are servers for process variables (PVs), while high-
level applications (e.g. user interfaces) act as clients who
monitor, query, or update these variables.4 Normally, the
server side is implicitly programmed by the conﬁguration
of a runtime database.

Thus, implementing the image analysis tool on an IOC
would have been the easiest way to get CA server fun-
cionality. Since the current EPICS release only supports
VME/VxWorks as target platform for IOCs, the solution
would have to be based on a VME frame grabber card.
Unfortunately, the market for these cards is very thin and
the available hardware extremely expensive. Cost-efﬁcient
frame grabbers are found almost exclusively in the PC mar-
ket and drivers are normally only available for MS Win-
dows.

Since, for obvious reasons of reliability and mainte-
nance cost, extending our infrastructure to support Win-
dows PCs was out of the question, it was decided to make
the PC/Windows solution a stand-alone system. Commu-
nication with the users through high-level applications was
restricted to a well-deﬁned set of CA variables. This was
possible due to some recent development efforts by the
EPICS community regarding the so called Portable CA
Server (CAS) library.

3.1 The Portable CA Server Library

This library, written in C++, enables developers to program
a CA server on any of the supported host platforms (includ-
ing MS Windows) independently of the runtime database
support provided by the EPICS IOC core. However, due
to some historical ballast,5, using the CAS library is not as
straight-forward as the apparently nice and clean interface
seems to suggest. This is especially true if the server tool is
supposed to deliver not only the plain values of its PVs, but
also the usual attributes associated with these values, such
as alarm and display limits, timestamps, alarm status and
alarm severity. Support for attributes is essential because
they are routinely requested by high-level applications such
as display managers.
In contrast to the traditional IOC
case, where all this functionality is already taken care of
by the runtime system, providing these attributes through
the portable CAS is the tedious and error-prone task of the
programmer.

It was decided that a clean solution to this problem
would involve some effort and that to make this effort more
worthwhile, it should be generic enough to be usable as an
independent library on top of the CAS. Starting from an ex-
isting code base written by Kay-Uwe Kasemir from LANL,
the ﬁnal result was a class library named XCas [3].

4This is a somewhat simpliﬁed description. For details, see [1].
5This refers mainly to the so-called Generic Data Descriptor (GDD,
see [2]) a C++ development originating from the time when the ﬁrst C++
compilers appeared that did not even support virtual functions.

3.2 The XCas Library

Being easy to use, not requiring expert knowledge of C++,
was one of the major design goals. This necessarily in-
cluded shielding the user from any low-level details of the
CAS interface. PVs are automatically provided with all at-
tributes suitable for the chosen data type. Adding a process
variable to a program requires nothing more elaborate than
the declaration of an object of one of the supplied classes.
In fact, the classes were modelled after the standard EPICS
database records; consequently the base class was named
Record and the standard PV attributes were implemented
as record Fields, including the aspect of being not only ac-
cessible as attributes to some PV but also as independent
PVs in themselves. This enables clients to directly con-
trol or monitor these attributes in a way similar to runtime
database records and their associated ﬁelds. The classes
provide complete functionality and are not normally meant
to be subclassed (although they can be, if desired). Facili-
ties to install callbacks to react to external updates of PVs
are implemeted using class templates to avoid the usual
type casts. The server itself acts completely hidden and is
set up and invoked only by internal methods of class Record
and its (few) specialized descendants.

4 CONCLUSIONS

We have shown that by using statistical methods the image
analysis of high-resolution video data can be implemented
efﬁciently enough to meet the real-time requirements aris-
ing from the adoption of advanced feedback control and
error detection facilities that rely not only on the beam po-
sition but also on parameters to identify the shape and di-
rection of the beam’s cross-section proﬁle.

We have further shown that an image analysis tool capa-
ble to meet these requirements can be based on a target plat-
form with a competitive market. The Portable CA Server
library can be effectively used for the integration into an
EPICS control system without exposing the latter to the
shortcomings in reliability and maintainability commonly
associated with the chosen platform. The effort to decou-
ple such a tool from the intricacies of dealing with the more
difﬁcult aspects of the interface to the Portable CAS has re-
sulted in an independent class library, which can be used to
simplify the process of writing any sort of CA server tools.

5 REFERENCES

[1] EPICS (Experimental Physics and Industrial Control Sys-

tem), http://www.aps.anl.gov/epics

[2] Channel Access,

http://lansce.lanl.gov/lansce8/Epics/ca/ca.htm

[3] EPICS XCas Module,

http://www-csr.bessy.de/control/SoftDist/XCas

