2
0
0
2
 
v
o
N
 
8
 
 
]
t
e
d
-
s
n
i
.
s
c
i
s
y
h
p
[
 
 
1
v
1
4
0
1
1
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Modeling Copper Cables and Connectors∗

Eric C. Hannah†
Intel Corporation
RNB6-37, 2200 Mission College Blvd.,
Santa Clara, CA 95052-8119
(Dated: August 12, 2013)

High-speed data busses constructed from copper components are both diﬃcult to model and
important to accurately simulate. Using analytic signal theory and an extension of the skin eﬀect
for non-uniform conductivity, experimental data taken from IEEE 1394-1995 cables and connectors is
used to predict the transfer function of a 4.5 meter cable with two connectors. With these techniques
any length of cable between two connectors can be simulated with high accuracy, including all
the cable and connector losses and the inﬁnitely summed standing waves that occur between the
connectors.

Keywords: copper interconnect, analytic signal, skin eﬀect, transmission line

I.

INTRODUCTION

Modern high-speed busses send data streams across
long runs of copper, often at data rates in excess of 1
gigabit/second. Connectors at the ends of copper cables
create discontinuities that phase shift the electrical sig-
nals and cause reﬂections. Mathematically characterizing
these copper systems with high accuracy is challenging
and often performed with awkward lumped-circuit mod-
els. In this paper I demonstrate methods that provide a
new level of accuracy and convenience in modeling such
systems. To demonstrate the accuracy of this method the
IEEE 1394-1995 connector and cable system is analyzed
for jitter and losses.

II. COPPER INTERCONNECT

Figure 1 shows a simple copper interconnect consisting
of two connectors and a long run of two parallel copper
wires.

We restrict the discussion to the diﬀerential mode of
excitation, excluding common mode eﬀects – and also
neglect cross-talk and EMI issues. The connectors have
complex eﬀects upon the phase and amplitude of each
Fourier component of the electrical waves incident upon
them. They cannot be treated as simple lumped ele-
ments in high-speed systems. Next, the wires have dis-
tributed eﬀects upon the electrical waves and should not

FIG. 1: Copper interconnect

∗ c(cid:13)2002, All Rights Reserved
†eric.hannah@intel.com

Typeset by REVTEX

be treated as a transmission line with a simple skin depth
eﬀect – real wires have non-uniform conductivity due to
stresses and alloying eﬀects in their manufacturing. Fi-
nally, the entire system acts as a lossy resonator with
standing wave modes.

Accurate modeling and simulation of this simple a sys-
tem is both diﬃcult and necessary. High-speed cable sys-
tems may have frequency-dependent losses speciﬁed to
the 1 dB level and jitter budgets deﬁned to 100 ps – for
5 meters of cable. Errors in the predicted waveforms are
catastrophic in systems that may ship in the 100 million
units per year volume.

III. ANALYTIC SIGNALS

The analytic signal[1] is a complex-number represen-
tation of a signal. The basic notion is that we start with
a real-valued signal which has no explicit phase informa-
tion, make this into the corresponding analytic signal,
and thereby determine the phase factors of the complex
signal. (See Appendix A). Analytic signals are essential
for proper modeling of copper interconnects.

A. Amplitude-Phase-Frequency ambiguity

Following [4] we write a signal in the form

u(t) = a(t) cos φ(t)

= a(t) cos(ω(t)t + Φ(t)),

u(t)

∈ R

(1)

≡

a(t), Φ(t), and ω(t)
dφ/dt are the amplitude, phase,
and frequency of the signal. However, for a real-valued
signal u(t), this is an equation relating two unknowns to
a single known. It may be argued that given the smooth
envelope of maximums and the zero-crossings we know
what the amplitude and frequency are. To a certain ex-
tent this viewpoint is eﬀective for narrowband signals. It
is totally inapplicable for wideband signals.

It is advantageous to work with complex signals

w(t) = u(t) + ıv(t) = a(t)eıφ(t)

(2)

The continuous-time analytic signal z(t) corresponding
to x(t) is most simply deﬁned in the frequency domain
as

constructed by adding an imaginary part v(t) to the real
signal u(t). For complex signals the amplitude, phase
and fequency are well deﬁned

Z(f )

≡ (

2X(f ),
X(0),
0,

f > 0
f = 0
f < 0

2

(8)

(3)

(4)

(5)

(6)

which is inverse transformed to obtain z(t). Note that the
value of Z(f ) at f = 0 is deﬁned to reﬂect the mathemat-
ical behavior of the Fourier transform at a discontinuity,
which yields the average of the values on either side of the
discontinuity. It can be shown that the imaginary part
of z(t) is the Hilbert transform of the real signal x(t).

2. Discrete-Time ”Analytic” signal properties

Again following Marple[3] we consider the properties
appropriate for an analytic-like discrete-time signal z[n]
corresponding to a real-valued discrete-time signal x[n]
of ﬁnite duration T .

The spectrum of the signal x[n] is obtained from the

discrete-time Fourier transform (DTFT)

X(f ) = T

x[n]e(

−

ı2πf nT ),

N

1

−

n=0
X

f = 0, 1, . . . , N

1

−

(9)

The DTFT is evaluated with a fast Fourier transform.
Next form the N -point one-sided discrete-time ”analytic”
signal transform

X(0),
2X(m),
X[ N
2 ],
0,

1

≤

N
2 + 1

1

m = 0
N
m
2 −
≤
m = N
2
m

N

≤

≤

1

−

(10)

Z(m)

≡





Compute using an N -point inverse DTFT

z[n]

1
N T

≡

N

1

−

m=0
X

Z[m]e(+ı2πmn/N )

(11)

to yield the complex discrete-time ”analytic” signal for
the same sample rate as the original signal x[n].

One justiﬁcation for setting the special value at m =
N
2 is that 0 Hz and the Nyquist frequency terms are
shared boundaries between negative and positive fre-
quency halves of the periodic spectrum, and division
into respective one-sided positive and negative spectra
requires that these terms be split between the two spec-
tral halves.

a2(t) = u2 + v2 =

w
|

2
|

φ(t) = arctan[

v
u

]

ω(t) = Im[

w′
w

]

If v(t) is the Hilbert transform of u(t) then w(t) is the

analytic signal. The Hilbert transform is

H[u(t)]

1
π

≡

∞

Z

−∞

u(s)
s
t

−

ds

Vakman[4] has demonstrated that only the Hilbert-
transform imaginary part of the complex signal satisﬁes
the following conditions: 1) amplitude continuity and dif-
ferentiability under small perturbations, 2) phase-value
independence of signal scaling, and, 3) harmonic corre-
spondence, i.e., sine waves of constant frequency and am-
plitude retain their values.

The analytic signal provides a cogent and global deﬁ-
nition of the amplitude, phase and frequency of a signal.
The analytic signal is implicitly implemented in radio
devices such as ﬁlters and modulators. Finally, the ana-
lytic signal provides accurate estimates of the amplitude,
phase and frequency of wide-band signals even in the
presence of substantial noise.

B. Fourier transform for analytic signals

To eﬃciently convert time-dependent real signals to

analytic signals we use the Fourier transform.

1. Continuous-time analytic signal

Following Marple[3] let x(t) be a real-valued, ﬁnite-
<
with the corresponding continuous-time Fourier

energy signal deﬁned over the temporal interval
t <
transform (CTFT)

−∞

∞

X(f ) =

∞

x(t)e(

−

ı2πf t)dt

(7)

deﬁned over the frequency interval
. Be-
cause x(t) is real, the CFTF is complex-conjugate sym-
metric, X(

f ) = X ∗(f ).

< f <

−∞

∞

−

Z

−∞

IV. EXPERIMENTAL METHODS

We set up in the laboratory a standard IEEE 1394-1995
connector and cable assembly which was interfaced to a

Tektronics Digital Sampling Scope with a Time Domain
Reﬂectometry module (TDR). TDR data from produc-
tion cables and connectors was analyzed for impedance
discontinuities and then used to model data-dependent
jitter.

A. Time domain reﬂectometry

TDR directly measures the reﬂected voltage from a
test ﬁxture as a function of delay time. A step function
with a very short risetime is launched into the connected
system. After the launch trigger the input of the system
is monitored for voltage levels. Voltage levels are aﬀected
by spatial variations in the impedance of the connected
system, as changes in impedance scatter the outgoing
waveform back towards the source point.

B. Digital sampling oscilloscope operation

The Tektronix 11801B oscilloscope contains a two-
channel 20GHz bandwidth sampling head. The oscillo-
scope functions in equivalent-time sampling. A sampling
interval is deﬁned as the horizontal time divided by the
record length (number of deﬁned samples). As an exam-
ple, for a sample interval of 200ps/div the oscilloscope
advances by one sample interval (200ps) after each trig-
ger event. Hence, for a record length of 512, it would
take 512 trigger events for the oscilloscope to advance to
the end of the screen.

TDR operation adds a step recovery diode circuit that
generates a step pulse with a 40 ps rise time into the
Device Under Test at the 0 time strobe. All the reﬂected
signals are sampled by the DSO system to show the time
proﬁle of the DUT’s reﬂections.

V. EXPERIMENTAL WORK

The connector was a surface-mount style and the cable
was a D7 style. Only one connector and cable assembly
was tested though our results correspond closely to data
given to us conﬁdentially by other companies.

The Figure 2 shows the diﬀerential TDR signal for
a production 1394-1995 connector and cable. Figure 3
shows the TDR data for a connector with the cable re-
moved. We see there is a substantial dip in the connec-
tor’s impedance.

It is useful to convert TDR data into an equivalent
impedance proﬁle. For diﬀerential TDR the conversion
formula is:

Z = 100 Ω (

(12)

1 + ρ
ρ
1

−

)

Note that the cable impedance in Figure 4 is above the
100 Ohms level (about 105 Ohms). The ideal 1394 cable
diﬀerential impedance is 110 Ohms.

3

FIG. 2: TDR of connector and cable

FIG. 3: TDR of connector with cable disconnected

A. Complex impedance of the connector

Following the numerical algorithm given above we now
create the analytic signal representation of Figure 4’s
impedance proﬁle (which has no phase information).
This algorithm will generate the imaginary component of
the impedance. Figure 5 is the resulting analytic signal.
The top line is the real part of the analytic signal and the
bottom, broken line, is the imaginary part. Taken as a
complex function this diagram is the complex impedance
proﬁle of the connector. A lumped-circuit approximation

FIG. 4: Equivalent impedance proﬁle

4

FIG. 6: Synthetic pulse

FIG. 5: Equivalent impedance proﬁle

for this would require a series of capacitors and inductors
to match each minimum and maximum in the trace – a
large number of components. Additionally, such a se-
ries of components would have secondary reﬂections that
would need to be added into the ﬁtting procedure so that
the total, consistent, electrical system matched the TDR
data.

B. S-parameters

(13)

(14)

We now want to derive the frequency-dependent S-
parameters for transmission through and reﬂectance oﬀ
the connector.

The deﬁnition of the transmission coeﬃcient, S12, is:

S12(ω) = T (ω) =

2Zload(ω)
Zload(ω) + Z0(ω)

Similarly the deﬁnition of the reﬂection coeﬃcient S11 is:

S11(ω) = R(ω) =

Zload(ω)
Z0(ω)
Zload(ω) + Z0(ω)

−

The most straightforward way to derive these coeﬃ-
cients for the connector is to create a synthetic pulse with
an exactly known Fourier transform (see Figure 6), use
the time proﬁle of the TDR derived connector complex
impedance to calculate reﬂectance (see Figure 7 – mag-
nitude only) and transmission (see Figure 8 – magnitude
only) synthetic pulse patterns, then Fourier transform
the time proﬁle of these pulses to get the analytic spec-
tra. One subtlety is to use the variation of the measured
impedance from the nominal 110Ω value of the trans-
mission line, not the absolute impedance. It is only the
variations from the uniform value that scatters waves into
the backward direction. For accuracy we use the actual
transmission line impedance value measured (by suitable
averaging away from the connector). A further subtlety
is that we have implicitly summed up all the internal re-
ﬂections inside the connector by using the TDR data.

FIG. 7: Reﬂected pulse

Finally, we divide the analytic spectrum of the re-
ﬂected and transmitted pulses by the analytic spectrum
of the original pulse to get the complex ratio at each
frequency, which is the transfer ratio as a function of fre-
quency. This procedure simulates using a Network Ana-
lyer. Figure 9 is the S matrix function for S12, Figure
10 is S11. Using the above complex-valued reﬂection
function we can validate this approach by simulating the
reﬂection of an ideal step function. This should match
the original ρ data. Figure 11 shows an almost exact ﬁt
with the experimental data (dashed and oﬀset by 0.05
from the simulation).

VI. CABLES

The next element to consider for copper interconnect
is the cable. We need to determine an accurate model
that captures the experimental data.

FIG. 8: Transmitted pulse

FIG. 9: |S12|

FIG. 12: TDR data for 4.5 meter cable

5

outward trip and on the return trip. By analyzing the
amplitude and phase changes long cables apply to each
Fourier component we can derive a very accurate model
of the cable’s distributed parameters, e.g., loss per unit
length, incremental inductance, etc.

B. Cable equations

−

−

−

−

∂zi(z, t) =

g v(z, t)

c ∂tv(z, t)

(16)

where r is the resistance of the cable per unit length, c is
the capacitance, and l is the inductance. More generally
we can make r frequency dependent. g is the transverse
conductance between the two conductors, the g term is
neglected by assuming there are no dielectric losses. As
a subtle point, c and l are assumed to be determined by
the cable’s wire diameters, i.e., we are assuming perfect
conductors and perfect shielding in the above partial dif-
ferential equations. We will correct for the eﬀects of skin
depth on these equations later.

We need to solve these equations for one-way energy
ﬂow on an inﬁnitely long cable. First we assume a har-
monic time dependence

v′(z)e−

ı t ω =

r i(z)e−

ı t ω

+ ı l ω i(z)e−

ı t ω

(17)

−

(cid:0)

(cid:1)

i′(z)e−

ı t ω = ı c ω v(z)e−

ı t ω

(18)

Removing the common time dependence

v′(z) =
−
i′(z) = ı c ω v(z)

(r i(z)) + ı l ω i(z),

(19)

FIG. 10: |S11|

Two-conductor cables operating purely in diﬀerential
mode are described by the partial diﬀerential equations

A. Experimental data

∂zv(z, t) =

r i(z, t)

l ∂ti(z, t)

(15)

Figure 12 shows the experimental data for a 4.5 me-
ter D7 cable with a shorted end. This data was taken
by using TDR. The time axis measures roundtrip delay
times. The ringing waveform on the left side is due to the
ﬁxture used to couple the TDR equipment to the cable
and is excised from successive analysis. There are several
things to note about this ﬁgure. First there is a linear
rise in resistance as time progresses. This is due to the
DC resistance of the cable. The TDR pulse scatters oﬀ
this incremental resistance and produces a gradual series
of return signals that add up to the observed ramp. The
next feature is the abrupt drop at about 50 ns time delay.
This is where the TDR pulse hits the short at the end of
the cable. For a very short cable this drop would be al-
most perfectly vertical. For long cables the return pulse
has been modiﬁed by the cable imperfections both on the

FIG. 11: Simulated TDR vs real TDR

Now we solve these diﬀerential equations

6

(20)

(21)

(22)

(23)

Collecting coeﬃcients between outgoing and ingoing waves

1 + e2 z √

−

ı c r ω

c l ω2

−

C(1)

1 + e2 z √

−

ı c r ω

c l ω2

−

(r

ı l ω) C(2)

v(z) =

(cid:16)

2 ez √

−

ı c r ω

−

(cid:17)
c l ω2

− (cid:16)

2 ez √

−

ı c r ω

c l ω2 √

−

−

−
(cid:17)
ı c r ω
−

−

c l ω2

i(z) =

ı
2 c
−
(cid:16)
ez √

−

1 + e2 z √

−

ı c r ω

c l ω2

−

ω C(1)

ı c r ω

c l ω2 √

−

ı c r ω

c l ω2

(cid:17)
−

−

1 + e2 z √
(cid:16)

2 ez √

−

+

ı c r ω

c l ω2

−

C(2)

ı c r ω

(cid:17)
c l ω2

−

−

i(z) =

√

ı
2 c ω C(1)
−
ı c r ω
−
ez √

−
ı c r ω

c l ω2 + C(2)
c l ω2

2

−

−

+ ez √
−

ı c r ω

c l ω2

−

ı
2 c ω C(1)
ı c r ω

c l ω2

+

C(2)
2

√

(cid:18)

−

−

(cid:19)

C(1)
2 +

2 √

v(z) =

+ ez √
−

ı c r ω

−

ı
2 l ω C(2)
ı c r ω

c l ω2

−

−

r C(2)
ı c r ω
−
ez √
c l ω2

−

√
c l ω2

c l ω2 −
−
ı c r ω
−
C(1)

2 −

2 √

(cid:18)

r C(2)
ı c r ω

−

−

+

c l ω2

ı
2 l ω C(2)
ı c r ω

c l ω2

(cid:19)

−

√

−

We now deﬁne C(2) to eliminate the incoming wave

We have

C(2) =

ı c ω C(1)
ı c r ω

c l ω2

−

√

−

v(z) = ez √
−

(c ω (ı r+l ω)) C(1)

i(z) =

ı c ez √
√

−

−

ı c r ω

−
ı c r ω

−

c l ω2

ω C(1)

c l ω2

We now derive the cable’s attenuation factor. Focusing

upon v(z) and setting C(1) = 1 we have

v(z) = ez √
−

(c ω (ı r+l ω))

(27)

To further simplify this equation we note that r is a small
impedance compared to the inductive impedance of the
cable, for all high enough frequencies. By expanding the
square root around the large inductive term and dropping
the imaginary phase-determining part, we derive the loss
per unit length of the cable.

In log terms

Which results in

loss = e

−(√c r z)
2 √l

logLoss = −

(√c r z)
2 √l

r = −

2 √l logLoss
√c z

This formula allows us to determine r as a function of
frequency from the experimentally measured cable loss
versus frequency relationship. We set z to the measured
length of the cable, times 2 to account for the roundtrip,
to derive the r per unit length values. This frequency-
dependent r function produces a much more accurate
model for real cables then a simple skin depth eﬀect
model.

In Appendix B we show that the skin eﬀect produces
both a resistive term, due to losses in the wire from the
ﬁnite conductivity of the metal, and an additional induc-
tive term, due to the ﬁnite penetration of magnetic ﬂux
into the wire. After we measure the real part of r from
the experimental cable data we add back the skin eﬀect’s
additional inductive eﬀects by using the ”complex” resis-
tance value: rextracted(1

ı).

−

C. Experimental cable results

Figure 12 shows the full experimental data set. The
most interesting part of the data set is the sharp return
step. To isolate just this element we window the data
set with a gaussian envelope, centered upon the step,
but broad enough to preserve the lower frequency com-
ponents. Figure 13 shows the result.

To compare the experimental data with a known wave-
form we do the same gaussian windowing with an ideal
return pulse that has been scaled and positioned to best
match the experimental data. Figure 14 shows this wave-
form.

After Fourier transforming both of these windowed
pulses we divide the experimental Fourier components
by the ideal Fourier components, frequency by frequency.

(24)

(25)

(26)

(28)

(29)

(30)

7

FIG. 13: Windowed cable data

FIG. 16: Cable resistance

FIG. 14: Windowed ideal model

FIG. 17: Experimental edge (bold) compared with the mod-
eled edge

Figure 15 shows the loss function of the measured cable.

Using the formula above we derive the cable’s mea-

sured resistance factor shown in Figure 16.

Figure 17 shows a close-up of the experimental TDR’s
step edge versus a simulation based upon the mathemat-
ical methods we’ve developed above. The bold plot is the
data. We see reasonable agreement.

H(ω) is the cable transfer function, T (ω) is the trans-
mission coeﬃcient for the connectors, and R(ω) is the
reﬂection coeﬃcient for the connectors.

Using the connector and cable models we’ve derived we
have the composite transfer funcition shown in Figure
18, where we’ve made the cable very short. Signﬁcant
resonances are visible.

VII. CONNECTOR PLUS CABLE SYSTEMS

VIII. EYE DIAGRAMS

Given two connectors and a length of connecting cable
we have an inﬁnity of reﬂections which sum up to a net
transfer function deﬁned by

H(ω)T 2(ω)

R2(ω)H 2(ω)

S

∞

=

1

−

(31)

An important quantity to determine for a copper in-
terconnect system is the eye diagram. We synthesize a
stressful set of data transitions, apply them to the copper
system transfer function, and see how the output pattern
looks. The basic technique is to convert a bit pattern to
a pulse pattern with the right timing, e.g., rise/fall times,
etc. We produce a discrete, time-sampled waveform from

FIG. 15: Cable losses

FIG. 18: Two connectors and a short length of cable

8

FIG. 19: 400 Mbps eye diagram

the pulse pattern, Fourier transform it, multiply by the
transfer function, then inverse Fourier transform to get
the output waveform in time.

· · ·

00000000

01011111

ble/connectors system:
00000000
11111111 11111110

We use the following bit pattern to test the ca-
11000001 01001111 10101000
11111111

00000000
repeating.
Figure 19 shows the result of this analysis. We have
sliced the output waveform into 1 bit-time length seg-
ments and then aligned and superimposed these slices.
The result of the simulations is a very accurate model
of experimentally determined eye diagrams (not shown
here). Eye diagram simulations permit the determination
of useful things like total system margins, jitter budgets,
etc.

IX. CONCLUSIONS

TDR Oscilloscopes are readily available pieces of
equipment. By using TDR techniques along with the
mathematical methods described in this paper it is pos-
sible to characterize and model many of the interesting
features of a copper interconnect system.

APPENDIX A: THE ANALYTIC SIGNAL

We have used analytic signals (see Gabor[1]) to de-
termine the phases of complex-valued transfer functions
when all we originally had was the real part of the func-
tion. In this appendix the theory behind analytic signals
is discussed.

The essential assumption behind analytic signals is
that we are dealing with a linear system that obeys
causality, i.e., responses occur after inputs in time. The
most general way to express this is by the integral equa-
tion:

φ(t) =

d´tK(t

´t)g(´t)

(A1)

Z

−

−

´t) is the Green’s function for the system (e.g., cable,
K(t
connector), g(´t) in the input (e.g., incident voltage wave-
form), and φ(t) is the system’s response (e.g., reﬂected,

FIG. 20: Integration contour

transmitted waves). This integral equation comprehends
all the time lags of the linear system. We require causal-
ity which means that K(t) = 0 for t < 0. The function of
interest for our system is the Fourier transform of K(t)
and the condition K(t) = 0 for t < 0 implies that the
Fourier transform

f (z) =

dteitzK(t)

(A2)

Z

→

z
|

| → ∞

of K(t) has no singularities for Im(z) > 0, and that
f (z)

in the upper half z-plane.

0 for

We now apply Cauchy’s formula to a contour consisting
of the real axis and a large upper semicircle, see Figure
20. By the above condition on f (z) we have the con-
tribution from the semicircle to the line integral along
the contour going to zero. This implies that Cauchy’s
formula reduces to

f (z) =

1
2iπ

f (ζ)
z
ζ

−

Zreal axis

dζ, Imz > 0

(A3)

The function of physical interest is f (z) on the real axis
(i.e., real-valued frequencies). Deﬁne the function F (x)
to be

F (x)

lim
0
ǫ
→

≡

f (x + iǫ)

(A4)

where ǫ is positive. Then it follows that

2iπF (x) = lim
0
→

ǫ

F (´x)
x

−

d´x

iǫ

∞

Z
−∞
∞

´x
−
F (´x)
x
´x

−

Z

−∞

= P

d´x + iπF (x)

where P designates the Cauchy principal value. Thus

F (x) =

1
iπ

P

∞

Z

−∞

F (´x)
x
´x

−

d´x

ReF (x) =

P

1
π

∞

Z

−∞

ImF (´x)
x
´x

−

d´x,

(A5)

(A6)

(A7)

1
ImF (x) = −
π

P

∞

ReF (´x)
x
´x

d´x,

(A8)

where * denotes complex conjugation. This implies the
relationship

−

−∞

Z
These are dispersion relations for the function of phys-
ical interest F (x) and the last equation clearly shows
how to calculate the imaginary component of any trans-
fer function from knowledge of its real part. This equa-
tion is the Hilbert transform. Note in our application x
is frequency.

As a simple example let us consider a simple low-pass
RC circuit with unit R and unit C in series. Vin is ap-
plied across the series combination and Vout is measured
across the capacitor. The complex transfer function is

Vout
Vin

=

1
−
iω

1
iω

1

−

=

1

1

iω

−

Vout
Vin

=

1
1 + ω2 +

iω
1 + ω2

real part =

1
1 + ω2

(A9)

(A10)

(A11)

We now assume that all we know is the real part of
the transfer function. The goal is to use analytic signal
theory to derive the correct imaginary part. Negative
frequencies don’t make sense physically in this situation
but this form of F possesses the symmetry:

9

(A13)

(A14)

(A15)

F (x) =

1
iπ

P

+

1
iπ

0

F ∗(´x)
´x + x

d´x

∞

∞

Z
P

0

Z

F (´x)
x
´x

−

d´x

For the imaginary part

1
ImF (x) = −
π
1
π

+

P

P

∞

−

∞

−

ReF (´x)
´x + x
ReF (´x)
´x

x

−

d´x

d´x

0

Z

0
Z

2
ImF (x) = −
π

P

∞

xReF (´x)
´x2

x2 d´x

0
Z

−

Putting in the explicit value of F

2
ImF (ω) = −
π
2
= −
π

P

P

0
Z

0
Z

ω
1+ ´ω2

´ω2

−

ω2 d´ω
ω

∞

∞

(´ω2

ω2)(1 + ´ω2)

−

d´ω

(A16)

which can be expressed in real and imaginary parts ex-
plicitly as

which simpliﬁes to

f (

z) = +f ∗(z∗)

−

(A12)

Given the deﬁnition of the Principal part:

ω

∞

P

0
Z

(´ω2

ω2)(1 + ´ω2)

−

d´ω = lim
0
0
hZ
→

δ

ω

δ

−

ω

(´ω2

ω2)(1 + ´ω2)

−

d´ω +

∞

ω+δ

Z

ω

(´ω2

ω2)(1 + ´ω2)

−

d´ω

i

(A17)

where δ is positive. Performing the integrations

ImF (x) =

ω
1 + ω2

(A18)

which is exactly the imaginary part of the transfer func-
tion.

quasi-static regime – where we neglect the displacement
current contribution to the magnetic ﬁeld.

APPENDIX B: SKIN EFFECT

(B1)

Accurate prediction of the behavior of copper trans-
mission lines requires proper modeling of the losses and
incremental inductance factors caused by the skin eﬀect.
Here we treat the skin eﬀect without the usual assump-
tion of spatially constant conductivity.

Following Jackson[2]we restrict Maxwell’s equations to
isotropic-response media, and the

weak ﬁelds,

linear,

the

the

With

vector

deﬁnition

potential,
of
B = ∇ × A, Faraday’s law shows that the curl of
E + ∂A/∂t vanishes. This implies that we can write
E = −∂A/∂t − ∇Φ. Assuming negligible free charge
and that the time-varying B is the sole source of the
electric ﬁeld, we may set the scalar potential Φ to
zero and have E = −∂A/∂t. Note that we have the

∇ × E + ∂B

∇ × H = J
∇ • B = 0
∂t = 0
J = σE
B = µH

10

Assuming the wire diameter is much smaller that the
wavelengths of interest, we drop the φ dependence. Given
that a constant amount of current is ﬂowing along the z
axis of the wire we see that the curl of A at the surface of
the wire must be constant, independent of z. This follows
from the relationship between B and A and Gauss’s law
relating the magnetic ﬁeld around a contour and the en-
closed current. E is very small in the deep interior of the
wire at high enough frequencies, thus A is very small at
the center of the wire. We also assume that E is parallel
to the wire at its surface, given there is no free charge on
the surface. The only non-trivial dependence is that of
σ and A on ρ and z. We ignore σ’s and A’s dependence
upon z since each diﬀerent position along the wire will
have an independent voltage drop due to the very small
skin depth expected at interesting frequencies – the net
voltage to driving current ratio for the entire cable is
simply the average along the wire’s length. Thus we as-
sume a uniform and constant dependence along z for the
diﬀusion equation. We now have a set of equations to
solve

subsidiary conditions ∇ • E = 0 and ∇ • A = 0. For
media of uniform, frequency-independent permeability
µ, Ampere’s law can be written ∇ × B =µJ = µσE.
Elimination of B and E in favor of A and use of the
identity, ∇ × ∇ × A = ∇(∇ • A)
2A,
vector
− ∇
yields the diﬀusion equation for the vector potential

∇2A = µσ

∂A
∂t

(B2)

This equation, which obviously also holds for the elec-
tric ﬁeld is valid for spatially varying, but frequency-
independent conductivity. If the conductivity is constant
in space it follows that the magnetic induction and the
current density also satisfy the same diﬀusion equation.
This situation gives the usual skin depth eﬀect. Constant
conductivity is a poor approximation for real wires which
are subject to varying alloy concentrations and stresses
due to processing. The goal of this appendix is to de-
rive the overall relationship between the driving current
and electric ﬁelds in realistic wires with spatially varying
conductivity.

To proceed we assume cylindrical coordinates along the
wire, harmonic time dependence, and use complex phasor
ıωt. After dropping
notation, A(ρ, φ, z, t) = A(ρ, φ, z)e−
the common exponential factor

∇2A(ρ, φ, z) =

ıωµσ(ρ, φ, z)A(ρ, φ, z)

(B3)

−

2Az(ρ, z) =

1
ρ

∂
∂ρ

(ρ

∂Az
∂ρ

) + (

∂2Az
∂z2 →

0) =

ıωµσ(ρ)Az(ρ),

2Aρ(ρ, z) =

1
ρ

∂
∂ρ

(ρ

∂Aρ
∂ρ

) + (

∂2Aρ
∂z2 →

0) =

ıωµσ(ρ)Aρ(ρ),

−

−

∇

∇

∇ × A

∼
= eφ((

∂Aρ
∂z →

0)

−

∂Az(ρ)
∂ρ

)

|ρ=rwire

= Bsurface,

(B4)

(B5)

(B6)

Aρ(0) = Az(0) ∼= 0,

(B7)

Az(0) ∼= 0

(B11)

Aρ(rwire) = 0
Aρ(rwire) = 0 – since the electric ﬁeld at the surface of
the wire is strictly oriented along the wire’s axis. Given
the boundary conditions we see the Aρ always remains
zero. There are no terms in the partial diﬀerential equa-
tion for Aρ that can drive a non-zero value anywhere, Aρ
being decoupled from Az. All that remains is

(B8)

2Az(ρ, z) =

∇

1
ρ

∂
∂ρ

(ρ

∂Az
∂ρ

−

) =

ıωµσ(ρ)Az(ρ),

(B9)

As a ﬁrst step we solve these equations for spatially

constant σ

4√

−

−

Az(ρ) = J0(

1√µσωρ)c1 + Y0(

1√µσωρ)c2

(B12)
, thus to preserve the small value of Az at

Y0(0) =
the origen of the wire we set c2 to zero.

−∞

4√

−

−

Az(ρ) = J0(

1√µσωρ)c1,

(B13)

4√

−

−

∇ × A

∼
= −eφ

∂Az(ρ)
∂ρ

|ρ=rwire

= Bsurface,

(B10)

∂Az(ρ)
∂ρ

= J1(

4√

1√µσωρ)c1

4√

1√µσω

(B14)

−

−

−

Setting the derivative at ρ = rwire equal to the surface

magnetic ﬁeld we have the full solution

Az(ρ) =

−

4√

1√µσωJ1(

−

Bsurface
4√

−

−

1√µσωrwire)

J0(

4√

−

−

1√µσωρ),

∂Az(ρ)
∂ρ

=

Bsurface

−

J1(

4√

−

−

1√µσωrwire)

J1(

4√

−

−

1√µσωρ)

which describes a thin layer of excitation diminishing
rapidly in the interior of the wire.

We now want to determine the relationship between

the electric ﬁeld and the magnetic induction at the wire’s
surface. The magnetic induction at the surface is a direct
function of the driving current inside the wire.

Ez(ρ) =

∂Az(ρ)/∂t = ıωAz(ρ) =

−

−

4√

1√µσωJ1(

−

ıωBsurface
4√

−

−

1√µσωrwire)

J0(

4√

−

−

1√µσωρ),

(B17)

B =µH,

(B18)

B = ∇ × A = eφ((

∂Aρ(ρ)

0)

∂z →

−

∂Az(ρ)
∂ρ

)

we get

Hφ =

Bφ
µ

=

1
µ

∂Az(ρ)
∂ρ

−

=

Bsurface
4√

µJ1(

−

−

1√µσωrwire)

J1(

4√

−

−

1√µσωρ)

which is proportional to the total driving current in the
wire. Consequently

Ez(ρ)
Hφ(ρ)

=

−

4√

1√µωJ0(
−
−
4√
√σJ1(
−

4√

−

1√µσωρ)

1√µσωρ)

−
The two Bessel functions grow at the same rate for large
arguments and their ratio
ı. Consequently we have
the wire surface result

→

(B21)

Ez(rwire)
Hφ(rwire)

=

4√

−

1√µωı
√σ

−

=

(1

ı)
−
√2 ×

real parameters

Thus the electric ﬁeld along the wire has a constant phase
shift relative to the driving current. This formula justiﬁes
the use of the complex constant times the measured high
frequency resistance in the transmission line equations –
again for constant σ.

For the case of spatially varying σ we simplify mat-
ters by assuming a semi-inﬁnite slab of material with the
vacuum-matter interface at x = 0, extending along y and

11

(B15)

(B16)

(B19)

(B20)

(B22)

σ(x) = σ0 + ǫσ1(x), ǫ

1,

(B26)

≪

σ1(x)A0(x)

z to inﬁnity. Assume the applied magnetic induction is
parallel to the y axis. This implies the vector potential
only has a z component. Because skin depths are much
smaller than wire radii for most problems of interest – a
1D approach is reasonable.

2Az(x) =

∇

∂2Az
∂x2 =

−

ıωµσ(x)Az(x),

(B23)

∇ × A = ey

∂Az(x)
∂x

|x=0= Bsurface

Az(x

) = 0

→ ∞
The simplest solution is to assume a Taylor’s series
expansion for all the terms in the equation. To simplify
further we assume that the spatially varying conductivity
is a small perturbation added to a constant conductivity.

Az(x) = A0(x) + ǫA1(x) + ǫ2A2(x) +

(B27)

· · ·

∂2Az(x)

∂x2 =

∂2A0(x)

∂x2 + ǫ

∂2A1(x)

∂x2 +

· · ·

(B28)

Applying these series to the diﬀusion equation we sepa-
rate out the various contributions to the diﬀerent powers
of ǫ

∂2A0(x)

∂x2 =

−

ıωµσ0A0(x)

(B29)

∂2A1(x)

∂x2 =

−

ıωµ(σ0A1(x) + σ1(x)A0(x))

(B30)

· · ·
The solution to the A0 equation with the correct

boundary behavior at x =

is

A0(x) = c1e−

ıωµσ0x

= c1

∞

√

(
−

−

ıωµσ0x)n
n!

(B31)

∞
√

−

n=0
X

An important thing to notice is that the A0(x) solu-
tion multiplies σ1(x) in the equation determining A1(x).
Since A0(x) is an exponentially decreasing function away
from the surface, the variations in σ1(x) far away from
the surface become irrelevant to A1(x). This explains
why modeling the skin eﬀect losses as a general function
of frequency is necessary for accuracy. As the frequency
changes, the skin depth changes – thereby averaging the
wire’s conductivity over a diﬀerent spatial scale.

To solve the A1 equation we expand as follows

σ1(x) =

∞

snxn

n=0
X

n=0
X

A1(x) =

∞

anxn

(B24)

(B25)

∂2A1(x)
∂x2

⇒

n(n

1)anxn
−

2

−

(n + 2)(n + 1)an+2xn

=

=

∞

n=0
X
∞

n=0
X

12

(B32)

(B33)

(B34)

= c1

n

∞

n=0
X

j=0
X

√

(
−

ıωµσ0)n
j)!

−
(n

j

−

sjxn

×

−

(B35)

Expanding the equations and separating by powers of x
we ﬁnd an inﬁnite series of equations for the progressively
higher order coeﬃcients. The ﬁrst two equations are

2a2 + ıωµσ0a0 + ıωµc1 ×

s0

= 0

(B36)

2a3 + ıωµσ0a1 + ıωµc1(

3

×

√
ıωµσ0)
−
−
+ıωµc1 ×

s0
×
s1 = 0

(B37)

Clearly a0 and a1 are unconstrained by the recursion
relationship. In the case where all the sn = 0 then an = 0
as well – there being only a zero solution when there is
no driving perturbation. Setting the ﬁrst two coeﬃcients
to zero to match this limiting case, we see that the per-
turbed solution only has ﬁnite terms of quadratic and
higher power. This implies that at the wire’s surface
(x = 0) there is no change in either the vector potential
or its curl from the perturbation in σ. Thus the con-
stant phase relationship between the electric ﬁeld and
the driving current in the wire remains as in the con-
stant conductivity case.

ACKNOWLEDGMENTS

The author would like to thank Steve Midford for pro-

viding the experimental data.

[1] Dennis Gabor. Theory of communication. J. Inst. Elect.

47(9):2600–2603, September 1999.

Eng., 93:429–457, 1946.

[2] John David Jackson. Classical Electrodynamics, Third

Edition, page 239. John Wiley & Sons, Inc., 1999.

[3] S. Lawrence Marple, Jr. Computing the discrete-time an-
IEEE Trans. Signal Processing,

alytic signal via FFT.

[4] David Vakman. On the analytic signal, the Teager-Kaiser
energy algorithm, and other methods for deﬁning am-
IEEE Trans. Signal Processing,
plitude and frequency.
44(4):791, April 1996.

13

