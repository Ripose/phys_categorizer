5
0
0
2
 
p
e
S
 
1
2
 
 
]
t
e
d
-
s
n
i
.
s
c
i
s
y
h
p
[
 
 
1
v
4
7
1
9
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

SMU-HEP-05-08
ATL-COM-PHYS-2005-052
February 15, 2014

Signiﬁcance Calculation and a New Analysis Method
in Searching for New Physics at the LHC

Yongsheng Gao, Liang Lu, Xinlei Wang

Southern Methodist University
Dallas, TX 75275-0175, USA

Abstract

The ATLAS and CMS experiments at the LHC have great physics potential in dis-
covering many possible new particles in a very large mass range up to the TeV scale.
We are familiar with the signiﬁcance calculation in searching for and observation of a
physics signal with known location and shape. The same calculation is no longer valid
when either the location or the shape of the signal is unknown. Using a physics signal
with known shape but unknown location as an example, we demonstrate in detail why the
current signiﬁcance calculation fails. We ﬁnd the signiﬁcance calculation of the current
“Sliding-Window” method at the LHC is over-estimated. The signiﬁcance and sensitiv-
ity of the “Sliding-Window” method also strongly depend on the speciﬁcs of the method
and the situation it applies to. We describe general procedures for signiﬁcance calcula-
tion and comparing diﬀerent search schemes. We then apply the procedures to compare
the “Sliding-Window” method with a new analysis method in searching for a signal with
known shape but unknown location. The new method uses maximum likelihood ﬁts with
ﬂoating parameters and scans the parameter space for the best ﬁt to the entire sample.
We ﬁnd that the new maximum likelihood scan method is signiﬁcantly more sensitive
than current “Sliding-Window” approaches. Unlike the “Sliding-Window” method, the
sensitivity of the new method is insensitive to the exact location of the new physics signal
we search. Detailed comparison results are given.

1 Introduction

The Large Hadron Collider (LHC) at CERN will open a new frontier in particle physics due to
its higher collision energy and luminosity as compared to the existing accelerators. The general-
purpose ATLAS and CMS experiments at the LHC will employ precision tracking, calorimetry
and muon measurements over a large solid angle to identify and measure electrons, muons,
photons, jets and missing energy accurately. Therefore, they have great physics potential in
discovering many possible new particles. Among them are the Standard Model (SM) Higgs
boson, supersymmetric (SUSY) and other new particles beyond the SM. All of them can have
masses in a very large range up to the TeV scale.

1

We are all very familiar with the signiﬁcance calculation in searching for and observation of
a physics signal with known location and shape. The same calculation is no longer valid when
either the location or the shape of the signal is unknown, which is the case for many of the
possible new physics signals at the LHC.

In Section 2, we give a short review of the signiﬁcance calculation and current analysis
strategy in High Energy Physics (HEP) and at the LHC. Using a signal with known shape but
unknown location as an example, we discuss in detail in Section 3 the problems of the current
signiﬁcance calculation. We then describe general procedures for signiﬁcance calculation and
comparing diﬀerent search schemes in Section 4.
In Section 5, we describe a new analysis
method and compare it with the current “Sliding-Window” approaches. Detailed comparison
results are also given in this Section. Summary and discussion are given in Section 6. In this
note we limit ourselves to the signiﬁcance calculation and analysis method used in searching
for an individual decay mode of new physics signals.

2 Review of Signiﬁcance Calculation and Current Anal-

ysis Strategy to Search for New Physics at the LHC

In the ﬁeld of HEP, a common strategy to detect a physics signal is to search for an excess of
events in a certain region of a kinematic observable. The observation probability is given by
Poisson statistics:

P (n, B) =

e−BBn
n!

(1)

where B is the number of the expected events to be observed in the region, and n is the number
of the observed events in this region. When B is large (over 25, for instance), the signiﬁcance
of an observation can be approximated well by S/√B of Gaussian statistics, where S = n
B.
In HEP, the signiﬁcance of an observation is deﬁned by the probability that such an obser-
vation is due to statistical ﬂuctuation of background events. When we claim an observation has
a signiﬁcance of 5σ, the common criterion for a HEP discovery, the probability that the claimed
discovery is due to statistical ﬂuctuation of background events, known as the Type I error rate
10−7. The background ﬂuctuation probabilities which
in statistics, needs to be less than 2.9
deﬁne the 1 to 5σ signiﬁcances in HEP are shown in Table 1.

−

×

Table 1: The deﬁnition of signiﬁcance in HEP and the corresponding background statistical
ﬂuctuation probabilities.

Signiﬁcance
Probability that the observation
of the excess of events is due to
background statistical ﬂuctuation

1σ

2σ

3σ

4σ

15.87% 2.28% 0.14% 3.2

10−5

2.9

10−7

×

5σ

×

2

If the expected mass spectrum of a physics signal is a Gaussian distribution with center µ
and standard deviation σ, the mass region used to calculate the signiﬁcance for searching for
2σ around the center µ. Including regions where the
and observation of this signal is usually
physics signal has little chance to show up only increases B and decreases S/√B. This is why
2σ
the region in which to search for the signal and calculate signiﬁcance is usually limited to
around the Gaussian center µ, in order to maximize the discovery potential and observation
signiﬁcance. This approach has been widely and successfully used in many HEP experiments at
CESR, Tevatron, LEP, KEK-B, PEP-II, etc. It is only valid when searching for and observation
of a physics signal with known location and shape, i.e., when the kinematic region for the
signiﬁcance calculation is uniquely deﬁned.

±

±

One of the new challenges for the ATLAS and CMS experiments is that we do not know
the masses of the new particles we will be searching for. The current analysis method proposed
for new particle searches at the LHC is to use a “Sliding-Window”, i.e., look for an excess
of events in a series of narrow regions or windows over the entire available kinematic range.
The location and width of each window is given by the expectations of the new particle with a
speciﬁc mass and the corresponding width. The expected signiﬁcances for new particle searches
are only determined by the S and B values within these narrow windows [1, 2, 3]. For example,
the expected signiﬁcances in searches for the SM Higgs as a function of the Higgs mass with
the ATLAS detector [1] are shown in Figure 1. Each point in this plot is calculated using the
S and B values in an expected narrow window, usually
2σ around the expected Gaussian
center [1, 2].

±

3 Problem with the Current Signiﬁcance Calculation and

Analysis Method at the LHC

There is a fundamental problem in the above signiﬁcance calculation. The signiﬁcance of an
observation is deﬁned according to the probability that such an observation is due to statistical
ﬂuctuation of background events, i.e., the Type I error rate. The current expected signiﬁcance
calculation is only correct if we know exactly the location and shape of the new physics signal
for which we are searching, and we use only one window in which to search and calculate the
In the “Sliding-Window” method, we search for an excess of events in any of
signiﬁcance.
the narrow windows over a wide kinematic range, but still use the S and B of each narrow
window to calculate the signiﬁcance of the observation. Therefore, the probability of observing
a “signiﬁcant” excess of events due to background statistical ﬂuctuation in any window will
be much higher [4]. This “false-positives” problem caused by multiple testing has been long
recognized in statistics [5, 6].

We use simple simulations to demonstrate this problem. Assume that we search for a
possible Gaussian signal with a standard derivation σ=1.0 but an unknown mean between 2.0
and 98.0, and that the expected distribution of the background is ﬂat between 0.0 and 100.0.
We generate 13,450,000 background-only Monte Carlo (MC) experiments (referred to as the
“background-only sample”) with each experiment containing 500 events generated from a ﬂat
distribution between 0.0 and 100.0.

3

Figure 1: The expected signiﬁcance for observing SM Higgs boson as a function of the Higgs
mass at ATLAS. The statistical signiﬁcances are plotted for individual channels, as well as for
the combination of all channels, assuming an integrated luminosity of 100 fb−1. Each point
in the curve is calculated based on the S and B values of a narrow mass window using the
“Sliding-Window” method.

4

We use a “Sliding-Window” with a ﬁxed width of 4.0 and move the center of this ﬁxed-
width window from 2.0 to 98.0 with various step sizes of 16.0, 8.0, 4.0, 2.0, 1.0, 0.5, 0.2 and 0.1,
respectively to search for an excess of events in any of the windows. The ﬁxed width of 4.0 of the
2σ around the unknown Gaussian mean. The signiﬁcance in
“Sliding-Window” corresponds to
any one window of a MC experiment is calculated by S/√B according to the current signiﬁcance
calculation, where n is the number of events in that window of the experiment, S = n
B, and
B = 20.

−

±

The probabilities that we observe at least one window with S/√B > 1, 2, 3, 4, 5 (i.e.
“1”, “2”, “3”, “4” and “5”σ according to the current signiﬁcance calculation) in any of the
background-only sample experiment are shown in Table 2. This probability is deﬁned as the
number of background-only MC experiments which contain at least one “1”, “2”, “3”, “4” and
“5”σ-eﬀect window divided by the total number of background-only MC experiments. From
Table 2, we can see that the probabilities of positive observations are much higher than the
background ﬂuctuation probabilities that deﬁne the signiﬁcances in HEP. Furthermore, the
probability of ﬁnding a signal of given signiﬁcance increases as the step size of the “Sliding-
Window” decreases, i.e., as more windows are scanned over the same kinematic range. While
each individual window follows Poisson or Gaussian statistics reasonably well, the probability
of observing an excess in any of the multiple windows is much higher than that for an individual
window. Table 2 clearly shows the problems of the signiﬁcance calculation in searching for new
physics signals with an unknown location. It is due to the fact that we search for an excess
of events over multiple narrow windows, but the signiﬁcance is still calculated according to an
individual window.

Table 2: The probability of observing at least one “1”, “2”, “3”, “4” and “5”σ-eﬀect window
in any background-only MC experiment using the “Sliding-Window” method with various step
sizes. The background ﬂuctuation probabilities which deﬁne the 1 to 5σ signiﬁcances in HEP
are also listed for comparison.

Signiﬁcance (S/√B)
Step Size = 16
Step Size = 8
Step Size = 4
Step Size = 2
Step Size = 1
Step Size = 0.5
Step Size = 0.2
Step Size = 0.1
HEP Signiﬁcance
Background Fluctuation Prob.

“3”σ

“1”σ
“2”σ
70.89% 20.42% 1.522%
91.56% 35.25% 2.818%
99.72% 58.53% 5.380%
99.99% 77.86% 9.635%
100.0% 89.03% 14.86%
100.0% 94.33% 19.97%
100.0% 97.17% 25.42%
100.0% 98.01% 28.21%
2σ

“4”σ
0.11%
0.20%
0.39%
0.73%
1.24%
1.83%
2.56%
2.98%
4σ

1σ

3σ
15.87% 2.28% 0.14% 0.0032% 2.9

“5”σ
0.002%
0.003%
0.007%
0.015%
0.027%
0.042%
0.064%
0.078%
5σ
10−7

×

5

4 Procedures for Signiﬁcance Calculation and Compar-

ing Diﬀerent Analysis Approaches.

Each analysis approach or search scheme can be described by two measures. The Type I error
rate measures how often false signals are claimed when there are only background events. The
signiﬁcance of an observation as deﬁned according to this error rate is shown in Table 1. The
Power or Sensitivity measures how often real signals can be found correctly when they are
present. There is a correlation between the two measures, the Type I error rate increases with
increasing sensitivity. Therefore, we need to set one of these two measures to the same value
for both schemes and compare the other measure, in order to quantitatively compare diﬀerent
search schemes.

We can see from Table 2 that the “signiﬁcance” calculated by S/√B of the “Sliding-
Window” method is highly over-estimated compared to the HEP signiﬁcance deﬁnition. Fur-
thermore, it also strongly depends on the step size of the “Sliding-Window” used to scan the
kinematic range and the total range of the kinematic region, i.e. the speciﬁcs of the search
scheme and the situation it applies to. We need to evaluate the signiﬁcance reported by each
scheme so it truly reﬂects our signiﬁcance deﬁnition. The procedures to calculate signiﬁcance
and comparing diﬀerent search schemes are as follows:

1. Use background-only MC experiments to evaluate the signiﬁcance of all search schemes.
After the evaluation, all the search schemes should be normalized to have the same Type
I error rates, which follow the HEP signiﬁcance deﬁnition.

2. Use signal-embedded MC experiments to evaluate the sensitivity of the search schemes.

The search scheme with the higher sensitivity is the better one.

These procedures are applied to compare a new analysis method with the current “Sliding-

Window”approaches in the following Section.

5 A New Analysis Method and a Comparison with the

“Sliding-Window” Approaches

An alternative approach is to apply an unbinned maximum likelihood scan method with ﬂoating
parameters to the entire sample and search for the best ﬁt to the sample over the entire
It is intended to minimize the sensitivity of the signiﬁcance to local
parameter space [4].
ﬂuctuations. We follow the procedures described in Section 4 to compare the current “Sliding-
Window” approaches with this new method for this example [7].

1. We search for a possible Gaussian signal (σ=1.0 with unknown mean between 2.0 and
98.0) on top of a ﬂat background in the 13,450,000 background-only MC experiments
(“background-only sample”) using each search scheme. We then evaluate the signiﬁcance
of each scheme so that it follows the HEP signiﬁcance deﬁnition for the background-only
sample.

6

2. We generate signal-embedded MC experiments and perform the same search using each
search scheme. We then calculate the sensitivities of ﬁnding the embedded signal for each
search scheme based on the signiﬁcances deﬁned by the background-only sample.

For the “Sliding-Window” approach in Step 1, we make a table which deﬁnes the new cutoﬀ
values of S/√B which follow the HEP signiﬁcance deﬁnition for the background-only sample.
Similarly for the new approach, we ﬁnd out the values of the Maximum Likelihood ﬁt output
which corresponds to 1, 2, 3, 4 and 5σ for the background-only sample according to the HEP
signiﬁcance deﬁnition.

5.1 Signiﬁcance Evaluation of “Sliding-Window” Approaches

We use the background-only sample to evaluate the signiﬁcance of the “Sliding-Window” ap-
proach. For each experiment, we use a “Sliding-Window” with ﬁxed width of 4 and move
the center of the window from 2.0 to 98.0 with step sizes of 16, 8, 4, 2, 1, 0.5, 0.2 and 0.1,
respectively, to search for the window with the maximum S/√B. For each step size, we plot
the maximum S/√B for all the background-only sample. We then ﬁnd the corresponding
cutoﬀ values on the plot which follow the HEP signiﬁcance deﬁnition. For example, the max-
imum S/√B from “Sliding-Window” approaches with step sizes of 16, 4, 1, and 0.1 for the
background-only sample are shown in Figure 2. In the “Sliding-Window” approach with step
size of 0.1, we ﬁnd that 84.13% of the experiments have at least one window with S/√B >
3.35, and 97.72% of the experiments have at least one window with S/√B > 4.02. According
to our HEP signiﬁcance deﬁnition in Table 1, the experiments which contain windows with
S/√B > 3.35 are deﬁned as 1σ for the “Sliding-Window” approach with step size of 0.1 in this
case. Similarly, the experiments which contain window with S/√B > 4.02 are deﬁned as 2σ.
The new S/√B cutoﬀ values which follow our HEP signiﬁcances deﬁnition for the “Sliding-
Window” approaches with various step sizes are given in Table 3. The cutoﬀ values are not
continuous, because S = n

B, B = 20, and both n and S are integers.

−

Table 3: The S/√B cutoﬀ values which correspond to the HEP signiﬁcance deﬁnition for a
“Sliding-Window” approach with diﬀerent step sizes.

Signiﬁcance
Step Size = 16
Step Size = 8
Step Size = 4
Step Size = 2
Step Size = 1
Step Size = 0.5
Step Size = 0.2
Step Size = 0.1

1σ
2.01
2.23
2.68
2.90
2.90
3.13
3.13
3.35

2σ
2.90
3.13
3.35
3.57
3.80
3.80
4.02
4.02

3σ
3.80
4.02
4.24
4.47
4.47
4.69
4.91
4.91

4σ
4.91
5.14
5.36
5.36
5.59
5.81
5.81
5.81

5σ
6.03
6.26
6.48
6.48
6.48
6.93
6.93
6.93

7

Figure 2: The maximum S/√B from “Sliding-Window” approaches with step sizes of 16, 4, 1,
and 0.1 for the 13,450,000 background-only MC experiments.

8

5.2 Signiﬁcance Evaluation of the New Analysis Method

We use the same background-only sample to evaluate the signiﬁcance for the new approach. In
this speciﬁc example we search for a Gaussian signal (σ=1.0 with unknown mean between 2.0
and 98.0) on top of a uniform background. The Likelihood is then calculated as:

L(Y

µ) =

|

P (yi|

µ)

n

Y
i=1

(2)

(3)

(4)

where the Y are the data per experiment, and yi is the individual data point in each experiment
µ) is the normalized probability density of yi as a
where i = 1, 2, 3, ..., n (n = 500). P (yi|
function of the parameter µ which is the unknown mean of the Gaussian signal. The normalized
probability density is given by:

P (yi|

µ) =

(1

p)

−
100

+

p
√2π

e− 1

2 (yi−µ)2

µ) over the
where 100 is the normalization factor which guarantees that the integral of P (yi|
range from 0.0 to 100.0 is equal to 1. p is the probability of the data point being the Gaussian
p) is the probability of the data point being the background. The opti-
signal. Similarly, (1
mization process attempts to ﬁnd the µ parameter that maximizes L(Y
µ) for each experiment,
or minimizes

µ)). We use

log(L(Y

−

|

−

|

X
i=1
as the maximum likelihood output to simplify the calculation.

−

log((1

p) + p

100
√2π

2 (yi−µ)2

e− 1

)

500

For the MC experiment generation and maximum likelihood analysis we used the statistical
computing software R [8, 9]. R is a language and environment for statistical computing and
graphics. It is a GNU project developed at Bell Laboratories and provides a wide variety of
statistical and graphical techniques (linear and nonlinear modeling, classical statistical tests,
time-series analysis, classiﬁcation, clustering, ...) [10]. We have also tried other statistical
software packages such as SAS [11], Matlab[12] and the HEP software package RooFit [13]
to generate the MC experiments, and perform the maximum likelihood ﬁts. The results with
diﬀerent analysis tools are all consistent. We decided to use R because it is faster than the
other packages.

In order to ﬁnd the best ﬁt with a ﬂoating µ parameter for each experiment, we break down
the µ parameter region from 2.0 to 98.0 into 96 equal intervals [14]. We perform one maximum
likelihood ﬁt for each interval to ﬁnd the best ﬁt. We then compare all 96 ﬁts to ﬁnd the overall
best ﬁt for the entire µ parameter space for this experiment. The maximum likelihood output
of the best ﬁt for the background-only sample is shown in Figure 3. Because 84.13% of the
background-only MC experiments have a maximum likelihood output below 4.00, the cutoﬀ
value for 1σ is set at 4.00. Similarly, 5.94 is set as the cutoﬀ value for 2σ. The cutoﬀ values for
1 to 5σ signiﬁcances for the new analysis method in this example are given in Table 4.

After these evaluations, the signiﬁcances reported by the “Sliding-Window” approaches
and the new analysis method are all adjusted to follow the HEP signiﬁcance deﬁnition for

9

Figure 3: The Maximum Likelihood output for 13,450,000 background-only MC experiments.
The top plot is in linear scale while the bottom plot is in log scale.

10

Table 4: The cutoﬀ values of the maximum likelihood output for the new analysis method in
this example.

Fraction of background-only Cutoﬀ value Signiﬁcance

experiments below cutoﬀ
84.13%
97.72%
99.86%
99.9968%
2.9

10−5)%

(1

−

×

4.00
5.94
8.71
12.48
16.61

1σ
2σ
3σ
4σ
5σ

background-only sample. We can then compare the sensitivity of these approaches using the
signal-embedded MC experiments.

5.3 Sensitivity Comparison of “Sliding-Window” Approaches with

the New Analysis Method

We generate signal-embedded MC experiments to calculate the Power or Sensitivity of each
approach. Each experiment contains a small number (5, 10, 15, 20, 25, 30, and 35) of signal
events generated according to a Gaussian distribution with σ=1.0 and a speciﬁc Gaussian mean
(42.00, 46.00, 48.00, 49.00, 49.50, 49.75, 49.90, 49.95, and 50.00) [7]. Each signal-embedded
experiment contains one set of these signal events embedded with 500 background events gen-
erated with a ﬂat distribution between 0.0 and 100.0. A total of 630,000 signal-embedded MC
experiments are generated, with 10,000 experiments for each set of Gaussian signal parameters.
For example, 10,000 experiments each with 5 Gaussian signal events with Gaussian mean at
42.00 embedded into 500 background events are generated. The maximum likelihood output
for each signal-embedded experiment is normalized to 500 events before comparing with the
cutoﬀ values from background-only experiments.

We use these signal-embedded experiments to calculate the sensitivity of the “Sliding-
Window” approaches. We use a “Sliding-Window” of ﬁxed width of 4.0 and move the center of
this ﬁxed-width window from 2.0 to 98.0 with various step sizes of 16.0, 8.0, 4.0, 2.0, 1.0, 0.5, 0.2
and 0.1, respectively, to search for the window with the maximum S/√B for each experiment.
The success of ﬁnding the embedded signal in an experiment is deﬁned as when the center of
the most signiﬁcant window is found within 1.0 of the Gaussian mean of the embedded signal
events. The signiﬁcance of this window is deﬁned according to the cutoﬀ values in Table 3.

We use the same signal-embedded experiments to calculate the sensitivity of the new analysis
method. For each experiment, we break down the µ parameter region from 2.0 to 98.0 into 96
equal intervals. We perform one maximum likelihood ﬁt for each interval to ﬁnd the best ﬁt for
this interval and the corresponding µ value. We then compare all 96 ﬁts to ﬁnd the best overall
ﬁt for the entire µ parameter space and its corresponding µ value for each experiment. The
success of ﬁnding the embedded signal in an experiment is deﬁned as when the µ value of the

11

best ﬁt in the entire µ parameter space falls within 1.0 of the Gaussian mean of the embedded
signal events. Similarly, the signiﬁcance is deﬁned according to the cutoﬀ values in Table 4.

The sensitivity of the “Sliding-Window” approaches with various step sizes is very sensitive
to the exact value of the Gaussian mean of the embedded signal events. Therefore, we choose the
best-case and worst-case scenarios for each “Sliding-Window” approach with a speciﬁc step size.
2σ region of the embedded Gaussian
The best-case scenario corresponds to a case where the
signal falls exactly inside one of the “Sliding-Windows”. The worst-case scenario corresponds
to a case when the embedded Gaussian signal falls exactly between two neighboring “Sliding-
Windows”. In Table 5, we show the Gaussian means of the embedded Gaussian signals for the
best-case and worst-case scenarios for various “Sliding-Window” step sizes.

±

Table 5: The Gaussian means of the embedded Gaussian signal for the best-case and worse-case
scenarios of the “Sliding-Window” approaches with various step sizes.

Step Size Gaussian Mean of embedded signal Gaussian Mean of embedded signal

16
8
4
2
1
0.5
0.2
0.1

Best-Case Scenario
50.00
50.00
50.00
50.00
50.00
50.00
50.00
50.00

Worst-Case Scenario
42.00
46.00
48.00
49.00
49.50
49.75
49.90
49.95

For each set of the 10,000 signal-embedded MC experiments, we calculate how many times
the embedded signals are correctly found by each approach with a signiﬁcance greater than 1, 2,
3, 4 and 5σ according to the HEP signiﬁcance deﬁnitions. For the “Sliding-Window” approach
with a speciﬁc step size, two numbers are reported, according to the best-case and worst-case
scenarios respectively. In contrast, the new approach scans the parameter space and performs
a maximum likelihood ﬁt at each small interval to cover the entire parameter space to search
for the best ﬁt of the entire sample. Thus, it is not sensitive to the exact value of the Gaussian
mean of the embedded signal. We ﬁnd the number is independent of the exact location of the
embedded Gaussian signal for the new analysis method.

The work and results for 5, 10, 15, 20, 25, 30 and 35 signal events embedded with Gaussian
means at 42.00, 46.00, 48.00, 49.00, 49.50, 49.75, 49.90 and 50.00 are shown in Ref. [7]. The
results for 10, 20, and 30 signal events embedded are shown in Tables 6, 7 and 8. We can see
that the number of signal embedded experiments successfully found with a certain signiﬁcance
is much lower than what expected from S/√B calculations. This is a price we have to pay for
not knowing the exact location of the signal. Furthermore, for the “Sliding-Window” method,
If the step
the sensitivity strongly depends on the exact location of the embedded signal.
size is greater than 1, the embedded signals are totally missed for the worst-case scenarios.

12

Table 6: The number of signal embedded experiments successfully found with 1, 2, 3, 4 and 5σ
signiﬁcance in the 10,000 MC experiments each with 10 signal events embedded.

Signiﬁcance
Scenario
Step Size = 16
Step Size = 8
Step Size = 4
Step Size = 2
Step Size = 1
Step Size = 0.5
Step Size = 0.2
Step Size = 0.1
New Approach

1σ

4σ

5σ

2σ

3σ
Best/Worst Best/Worst Best/Worst Best/Worst Best/Worst
433/0
271/0
176/0
107/0
143/68
156/120
97/70
106/78
153

4795/0
3897/0
1839/0
1691/0
1915/1031
2011/1728
2011/1728
1598/1465
2328

1859/0
947/0
652/0
619/0
537/274
807/706
562/484
599/548
819

39/0
23/0
16/0
16/0
9/1
11/2
11/2
13/2
17

1/0
1/0
1/0
1/0
1/0
2/0
2/0
1/0
2

For step size of 1 or less, there are still signiﬁcant diﬀerences in the sensitivities between the
best-case and worse-case scenarios, depends on the step size of the “Sliding-Window” used to
scan the kinematic range. In comparison, the new analysis method is independent of the exact
location of the Gaussian mean of the embedded signal events. This is because the new method
scans the entire parameter space for the best ﬁt to the entire experiment. The maximum
S/√B from “Sliding-Window” approaches with step sizes of 16, 4, 1, and 0.1 for the best-
case scenario MC experiments each with 20 signal events embedded are shown in Figure 4.
Similarly, the maximum S/√B from “Sliding-Window” approaches with step sizes of 16, 4,
1, and 0.1 for the worst-case scenario MC experiments each with 20 signal events embedded
are shown in Figure 5. The maximum likelihood output of the best ﬁts for MC experiments
with 5, 10, 20 and 30 signal embedded are shown in Figure 6. Compared to “Sliding-Window”
approaches with a step size small enough not to miss the worst-case scenarios, the sensitivity
of the new analysis method is signiﬁcantly higher. This means that the new analysis approach
is a signiﬁcantly better and more sensitive scheme to search for new physics signals at the LHC
than the current “Sliding-Window” method.

The analysis method described above performs a scan of the entire parameter space using
unbinned maximum likelihood ﬁts at every small interval of the parameter space. It is very
CPU-intensive. The 13.45 million background-only and 630,000 signal embedded MC experi-
ments were generated and analyzed in several months with about 10 dual-CPU servers.

6 Summary and Discussion

We have examined the signiﬁcance calculation and analysis methods in searching for an individ-
ual decay mode of a new physics signal at the LHC. Unlike the search for a physics signal with
known location and shape, the signiﬁcance calculation for new physics signals with unknown
location or shape strongly depends on the details of the search scheme and the situation it

13

Figure 4: The maximum S/√B from “Sliding-Window” approaches with step sizes of 16, 4, 1,
and 0.1 for the best-case scenario 10,000 MC experiments each with 20 signal events embedded.

14

Figure 5: The maximum S/√B from “Sliding-Window” approaches with step sizes of 16, 4, 1,
and 0.1 for the worst-case scenario 10,000 MC experiments each with 20 signal events embedded.

15

Figure 6: The Maximum Likelihood output for MC experiments with 5, 10, 20, 30 signal events
embedded respectively.

16

Table 7: The number of signal embedded experiments successfully found with 1, 2, 3, 4 and 5σ
signiﬁcance in the 10,000 MC experiments each with 20 signal events embedded.

Signiﬁcance
Scenario
Step Size = 16
Step Size = 8
Step Size = 4
Step Size = 2
Step Size = 1
Step Size = 0.5
Step Size = 0.2
Step Size = 0.1
New Approach

1σ

5σ

4σ

2σ

3σ
Best/Worst Best/Worst Best/Worst Best/Worst Best/Worst
6302/0
5435/0
4542/0
3642/0
4032/2509
4020/3782
3274/3061
3416/3268
4073

2215/0
1616/0
1190/0
1182/0
965/634
1046/965
1046/965
1119/1051
1209

9834/0
9694/0
8932/0
8439/0
8086/4955
7795/7264
7795/7264
7538/7277
9116

8969/0
7844/0
7135/0
6867/0
6365/3913
6812/6273
6217/5747
6314/6034
7406

356/0
240/0
158/0
156/0
174/112
130/100
130/100
149/111
206

applies to. Using a signal with known shape but unknown location as an example, we have
demonstrated that the signiﬁcance calculation using the current “Sliding-Window” method at
the LHC is over-estimated. This is because we search for an excess of events over multiple
narrow windows, but the signiﬁcance is still calculated according to an individual window. The
signiﬁcance and sensitivity of the “Sliding-Window” method strongly depends on the speciﬁcs
of the method and the situation it applies to, e.g. the step size of the “Sliding-Window” used
to scan the available kinematic range, the total available kinematic range to search for the new
physics signal, and the exact location of the new physics signal, etc.

We describe general procedures for signiﬁcance calculation and comparing the current
“Sliding-Window” approach with a new analysis method. The proposed new analysis method
uses maximum likelihood ﬁts with ﬂoating parameters and scans the parameter space for the
best ﬁt to the entire sample. We ﬁnd the results of the new analysis method is independent
of the location of the new physics signal and signiﬁcantly more sensitive in searching for new
physics signal than the current “Sliding-Window” approach.

While the LHC experiments have great potential in discovering many possible new physics
signals, we need to be extremely careful in evaluating the signiﬁcance of an observation from
the real LHC data. Because possible new physics can show up in many kinematic observables,
over a very large kinematic range, the ﬂuctuation probability of background events will be
much higher. For individual decay modes of new physics signals, the expected signiﬁcances
in observing the new physics signal will be much smaller than current expectations. Com-
bining independent decay modes of the same new physics signal will be essential to establish
the discovery of the new physics signal. Signiﬁcant observations of the same new particle in
independent decay modes at consistent locations will be the most eﬀective way to establish
the discovery of this new particle. Careful evaluation of the observation signiﬁcance in each
individual decay mode following the general procedures described in this note is the starting
point, before we can evaluate the signiﬁcance of the observations of independent decay modes.

17

Table 8: The number of signal embedded experiments successfully found with 1, 2, 3, 4 and 5σ
signiﬁcance in the 10,000 MC experiments each with 30 signal events embedded.

Signiﬁcance
Scenario
Step Size = 16
Step Size = 8
Step Size = 4
Step Size = 2
Step Size = 1
Step Size = 0.5
Step Size = 0.2
Step Size = 0.1
New Approach

1σ

2σ

4σ

5σ

3σ
Best/Worst Best/Worst Best/Worst Best/Worst Best/Worst
9963/0
9917/0
9841/0
9633/0
9412/6490
9152/8665
9046/8558
9006/8742
9723

5936/0
5079/0
4238/0
4232/0
4560/3285
3847/3683
3847/3683
4049/3944
4332

9215/0
8792/0
8249/0
8210/0
7787/5444
7743/7331
7743/7331
7792/7603
8024

10000/0
10000/0
9998/0
9904/0
9542/6589
9249/8784
9249/8784
9183/8945
9985

10000/0
9993/0
9987/0
9886/0
9532/6584
9246/8781
9238/8778
9178/8934
9974

7 Acknowledgment

The authors would like to thank the members of the SMU HEP group for their encouragements
and useful discussions. This work is supported by the U.S. Department of Energy under grant
number DE-FG02-04ER41299.

References

[1] ATLAS Collaboration, “ATLAS Detector and Physics Performance: Technical Design

Report, 2”, CERN-LHCC-99-015, ATLAS-TDR-15

[2] ATLAS notes on searching for new particles at the LHC, available at CERN Document

Server http://cdsweb.cern.ch/

http://cdsweb.cern.ch/

[3] CMS notes on searching for new particles at the LHC, available at CERN Document Server

[4] Y. Gao, “New Analysis Strategy to Search for New Particles at LHC”, hep-ex/0310011.

[5] E. L. Lehmann, “A Theory of some Multiple Decision Problems”, The Annals of Mathe-

matical Statistics, Vol. 28 1, 1, (1957).

[6] R. O’Neill and G. B. Wetherill, “The Present State of Multiple Comparison Methods”,
Journal of the Royal Statistical Society. Series B (Methodological), Vol. 33 2, 218, (1971).

[7] Liang Lu’s Ph.D thesis at Southern Methodist University. The detailed results of this work

are described in this thesis.

18

[8] The R Project for Statistical Computing, http://www.r-project.org/.

[9] Bill Venables, An Introduction to R, ISBN 3-900051-12-7.

[10] Brian Ripley, R Data Import/Export, ISBN 3-900051-10-0.

[11] An Introduction to SAS, http://www.itc.virginia.edu/research/sas/training/v8/.

[12] Documentation for MathWorks Products, Release

14 with Service Pack

2,

[13] Wouter Verkerke, David Kirkby, The RooFit Toolkit

for Data Modeling,

http://www.mathworks.com/.

http://rooﬁt.sourceforge.net/.

package.

[14] Private communication with David Kirkby and Wouter Verkerke, authors of the RooFit

19

