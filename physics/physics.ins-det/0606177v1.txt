6
0
0
2
 
n
u
J
 
0
2
 
 
]
t
e
d
-
s
n
i
.
s
c
i
s
y
h
p
[
 
 
1
v
7
7
1
6
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A statistical method for luminosity monitoring
in high energy collider experiments

Jo˜ao Bastos1, Jo˜ao Carvalho1, Michael Schmelling2
1LIP-Coimbra, Univ. de Coimbra, P-3004-516 Coimbra, Portugal
2Max-Planck-Institut f¨ur Kernphysik, D-69029 Heidelberg, Germany

Abstract

A statistical method which uses a combination of two subdetectors to
monitor the luminosity in high energy interactions is presented. To illus-
trate its performance, this method was applied to random triggered min-
imum bias data collected in the commissioning period of the HERA-B
experiment in spring 2000. It is found that luminosity estimates with
an intrinsic systematic error of 3% can be obtained.

1 Introduction

The precise determination of the luminosity of experimental data is required
for absolute cross section measurements. Luminosity l is deﬁned as the pro-
portionality factor between interaction rate and cross section for the process
under consideration. The integrated luminosity L relates cross section σ and
interaction count N for a time interval T , i.e.

l(t) =

1
σ

dN
dt

and thus

L =

l(t)dt =

(1)

T

Z
0

N
σ

.

Given the cross section σ for a particular process, such as the inelastic
cross section in high energy hadronic interactions, the determination of the
integrated luminosity for a given data set is equivalent to determining the
number of interactions of that process. For the following we will focus on col-
lider experiments, where a bunched beam produces events with a well deﬁned
time structure, and where the number of interactions per bunch crossing will
ﬂuctuate statistically.

As a ﬁrst approach, determining the number of interactions could be accom-
plished by simply counting the number of reconstructed primary vertices in the

1

data. To achieve that, the vertex reconstruction eﬃciencies must be known.
Additionally, two neighboring vertices may be merged by the reconstruction
package while others may be split. Therefore, the probabilities for these pro-
cesses must also be calculated, which is often diﬃcult and introduces poorly
known systematic errors. An alternative technique consists in extracting the
total number of interactions from inclusive quantities in the reconstructed data
which are proportional to the number of primary collisions in an event, such
as the number of hits or the total energy deposition. Obviously, the main
diﬃculty associated with this approach is the need for an absolute calibration,
that is, the average signal for a single interaction must be known.

In a diﬀerent approach (the so called“statistical method”), a poissonian
distribution for the number of interactions per bunch crossing is assumed and
the average number of interactions is extracted from the number of empty
events in the data sample. The advantage of this method is that nothing
about the average signal for a single interaction has to be known or assumed.
However, the acceptances for tagging non-empty events must be estimated and
the occurrence of noise events, which may be tagged as non-empty, must be
taken into account.

In this paper a method for determining the integrated luminosity by count-
ing the fraction of empty events simultaneously in two subdetectors is pro-
posed. With this procedure the detector acceptances for a single interaction
and the fraction of noise events can in principle be obtained from data, relax-
ing the dependence on Monte Carlo simulations to derive these quantities and
the introduction of systematic errors which are diﬃcult to estimate.

This paper is organized as follows. In the next section, an expression for the
probability to observe an empty event is derived, assuming that the distribu-
tion of the number of interactions per bunch crossing follows Poisson statistics
but allowing also for non-negligible rate ﬂuctuations. Based on this, in Section
3, the Two-System Statistical Method (TSSM) is introduced. It is shown how
counting the fraction of empty events in either of two subdetectors and si-
multaneously in both allows to determine the acceptance of both subdetectors
and the mean number of interactions in the data. In Section 4, this procedure
is applied to minimum bias events collected in the commissioning period of
the HERA-B experiment [1] in spring 2000. The conclusions are presented in
Section 5.

2 Counting Empty Events

A particle collider usually has circulating beams with many bunches contribut-
ing to the observed interaction rate. Since the individual bunch currents, in

2

general, can diﬀer by signiﬁcant amounts, the following analysis is formulated
for an ensemble of distinguishable bunches. This entails a slight complication
of the formalism, but, as will become clear later, gains a lot of information
which can be exploited in the analysis.

For the start let us assume that the distribution of the number of inter-
actions per bunch crossing follows Poisson statistics. If the average number
of interaction produced by bunch number i is µi, the probability to observe n
interactions in an event from this bunch crossing is

P (n, i) =

µn
i
n!

e−µi.

Now suppose that a certain subdetector is used to count the number of empty
events in the data set. An event is tagged as being empty if a quantity associ-
ated with this subdetector (e.g. hits, tracks, energy deposition, etc.) is below
a speciﬁed threshold value. This value represents a compromise between a
large eﬃciency for tagging non-empty interactions and an eﬀective exclusion
of noisy “events” in which no interaction has occurred. The probability to
observe an empty event in this system is

P (0, i) = (1 − q)

(1 − a(n))P (n, i),

(3)

where a(n) is the acceptance, or eﬃciency, to tag an event with n interactions
as non-empty and q is the probability to observe an event due to noise in the
subdetector or to background (i.e. beam gas interactions). If the probability
to pass the tagging threshold is independent of the number of primary inter-
actions, which to a good approximation is valid if the threshold is set such
that a single interaction has a large probability to exceed it, then a(n) can be
approximated by

a(n) = 1 − (1 − a)n

where a ≡ a(1) is the eﬃciency to tag a single interaction as non-empty. Sub-
stituting Eq. (2) and (3) into Eq. (4) one gets

P (0, i) = (1 − q)e−aµi.

However, some bunches may suﬀer from rate instabilities so that Eq. (2)
does no longer describe the interaction multiplicities correctly. In this case,
the average number of interactions µi is no longer constant but it ﬂuctuates
by a random amount νi around its central value, µi → µi + νi. With g(νi) the
probability density function of those ﬂuctuations, the probability to observe

(2)

(4)

(5)

∞

Xn=0

3

an empty event becomes

P (0, i) = (1 − q)

e−a(µi + νi)g(νi)dνi

∞

Z

−µi

Assuming further that the ﬂuctuations around µi are Gaussian distributed,
with zero average hνii = 0 and standard deviation σi ≪ µi, Eq. (6) can be
integrated analytically to yield

P (0, i) = (1 − q) exp

−aµi +

(cid:18)

1
2

a2σ2

i (cid:19)

.

One sees that rate ﬂuctuations enter as second order eﬀects, i.e. as long as
they are small the assumption of poissonian distribution for interaction mul-
tiplicities is a good approximation. Large rate ﬂuctuations, however, have a
sizeable impact and have to be taken into account in the analysis.

3 The Two-System Statistical Method

Now let us consider two subdetectors or combinations of subdetectors, which
will be denoted by “system 1” and “system 2”. According to Eq. (7) the
probabilities pk, k = {1, 2} to observe an empty event in either of the two
systems are

pk i ≡ P (0, i)k = (1 − qk) exp

−akµi +

(8)

(cid:18)

1
2

kσ2
a2

i (cid:19)

where qk is the probability to record an event due to background or noise in
system k and ak is the eﬃciency to tag single interactions in this system. If
the two systems are independent the probability p0 to observe an empty event
simultaneously in both subdetectors is given by an analogous expression

p0 i = (1 − q0) exp

−a0µi +

(cid:18)

1
2

0σ2
a2

i (cid:19)

,

where q0 = q1 + q2 − q1q2 and a0 = a1 + a2 − a1a2.

In order to get a handle on rate ﬂuctuations, we now combine the statistical
approach with a measurement based on an inclusive quantity, which is insen-
sitive to deviations from a poissonian for the interaction multiplicities. This
is achieved by expressing µi in terms of a bunch dependent inclusive quantity
hnii which is proportional to the number of interactions per bunch crossing,

(6)

(7)

(9)

(10)

hnii = τ µi .

4

The parameter τ is the mean value of the inclusive quantity per interaction
within the detector acceptance. Substituting Eq. (10) in Eq. (8) and (9) we
have

pk i = (1 − qk) exp

−ak

, with

k = {0, 1, 2} .

(11)

hnii
τ

+

1
2

kσ2
a2

i (cid:19)

(cid:18)

If there are no rate ﬂuctuations, σi ≃ 0, ∀i, the global (bunch independent)
parameters, qk, ak and τ , can be obtained from Eq. (11) by ﬁtting the values of
pk i as a function of the observable hnii. Once τ is known, the average number
of interactions µi for every bunch is calculated according to Eq. (10). From
µi and the number of recorded interactions in each of the bunches, the total
number of interactions in the data sample and thus the integrated luminosity
can be calculated.

In case that rate ﬂuctuations are present for some bunches, those bunches
have to be identiﬁed and removed from the global ﬁt. This can be achieved by
considering the following relation between the probabilities pki,

ln

p0i
p1ip2i

= a1a2 (cid:20)

hnii
τ

+ σ2

i (cid:18)

1 − a0 −

1
2

a1a2(cid:19)(cid:21)

.

(12)

In case of negligible rate ﬂuctuations we have a simple linear relation between
ln(p0i/p1ip2i) and hnii. Bunches with signiﬁcant rate ﬂuctuations would deviate
from that relation and can be excluded from the global ﬁt. Note that Eq. (12)
also has the potential to detect situations where all bunches are subject to rate
ﬂuctuations. In this case one has no outlier bunches, but a straight line ﬁt to
ln(p0i/p1ip1i) versus hnii would not pass through the origin, unless σ2
i and µi
are proportional.

4 Application to HERA-B Minimum Bias Data

To illustrate its properties, the proposed method was applied to minimum bias
events, collected with a simple random trigger during the HERA-B commis-
sioning period in spring 2000. Applying the TSSM to real data shows how the
considerations that went into its design cope with problems arising under real-
istic conditions. With respect to HERA-B, please note that the random-trigger
based method described in this paper should not be confused with other ones
employed by the HERA-B collaboration for luminosity measurements, such as
for example the method [2] applied to the interaction-triggered data recorded
in 2002/2003.

HERA-B is a large acceptance ﬁxed target experiment that studies the
interactions of 920 GeV protons with wire targets placed in the beam halo

5

of the HERA storage ring, at DESY. The HERA-B target [3] consists of two
stations separated by 4 cm along the beam. Each station comprises four wires
of diﬀerent materials, with dimensions ranging from 0.5 to 1 mm along the
beam and from 50 to 100 µm perpendicular to the beam. Each wire can be
independently moved inside the beam halo in order to adjust the interaction
rate. The reconstruction of primary and secondary vertices is performed by
a silicon micro-strip Vertex Detector System [4]. The main tracker is divided
into the Inner Tracker [5], composed of micro-strip gas chambers with gas
electron multipliers, and the Outer Tracker [6] made of honeycomb drift cells.
Particle identiﬁcation is performed by a ring imaging Cherenkov detector [7],
an electromagnetic calorimeter [8] and a muon detector [9].

The runs analysed in the following were taken with four diﬀerent target
materials: carbon, aluminum, titanium and tungsten. The nominal interaction
rates ranged from 2 to 20 MHz. In the HERA proton ring there are 220 slots for
bunches separated by 96 ns. Usually only 180 of these are ﬁlled with protons.
In Fig. 1 one can see the number of recorded events as a functions of the bunch
number for a run of 500k events taken with a carbon wire target. As can be
seen, the data acquisition system samples all bunches very uniformly (even the
ones which are nominally empty).

s
t
n
e
v
e
 
f
o
 
r
e
b
m
u
n

 

2500

2000

1500

1000

500

0
0

25

50

75 100 125 150 175 200

 bunch number

Figure 1: Number of events recorded with a random trigger as a function of
bunch number. Bunches that are nominally empty are also sampled.

At HERA-B inelastic interactions dominate the total visible cross section
and therefore they are the natural reference process for luminosity determina-
tion. Elastic scattering events are normally outside the detectors acceptances
and contribute marginally to the rate. The inelastic cross section of pA col-
lisions was measured by several ﬁxed target experiments, for a large number

6

of target materials and beam energies [10, 11, 12, 13, 14, 15]. It is found to
be approximately independent of the incident particle energy and a power law
dependence on the target atomic weight A is well ﬁtted by the experimental
data [16]. The inelastic cross section comprises a non-diﬀractive and a diﬀrac-
tive component. Since for the latter both experimental acceptance and the
contribution to the total cross section are small, it is a good approximation
to assume that only the non-diﬀractive component of the inelastic cross sec-
tion contributes to the luminosity determination. The resulting bias can be
estimated by Monte Carlo simulations.

4.1 Mean number of tracks per bunch crossing

In Eq. (10) µi was expressed in terms of an inclusive quantity which is pro-
portional to the number of interactions per bunch crossing. In the following
we choose this quantity to be the mean number of reconstructed tracks hnti
which, to a good approximation, scales linearly with the number of primary
collisions, i.e. hnti = τ µi, where τ is the mean number of reconstructed tracks
in one interaction. The validity of this assumption was checked with a Monte
Carlo simulation based on the FRITIOF 7.02 generator [17] and the subse-
quent simulation of the HERA-B detector. In order to exclusively select tracks
originating from primary interactions, and eliminate non-target related tracks
from secondary decays such as KS → π+π− and conversions γ → e+e−, the
following selection criteria were applied to all tracks in the event. Only tracks
containing at least 6 reconstructed hits in the vertex detector (VDS) are ac-
cepted. To avoid counting multiply reconstructed tracks (the so-called clones),
tracks sharing a VDS segment with a previously accepted track were rejected.
Finally, an impact parameter below 1 mm at the primary vertex is required.
The plot on the left of Fig. 2 shows a Monte Carlo simulation for the mean
number of reconstructed tracks hntin which satisfy these criteria as a function
of the number n of superimposed interactions. One sees that hntin indeed
scales linearly with interaction rate up to 4 superimposed interactions, which
corresponds to a rate of about 40 MHz. Furthermore, heavier target materials
yield higher track multiplicities. The plot on the right of Fig. 2 shows hntii as
a function of the bunch number i for the same run considered in Fig. 1. There
are remarkable variations in the track multiplicities between diﬀerent bunches,
which clearly indicates distinct contributions to the total rate. In this plot, we
can also identify the bunches which are nominally empty and contribute only
marginally to the rate.

7

s
k
c
a
r
t
 
f
o
 
r
e
b
m
u
n
 
e
g
a
r
e
v
a

40

35

30

25

20

15

10

5

0

14

t

>
n
<

12

10

8

6

4

2

0 0.5 1 1.5 2 2.5

3 3.5 4 4.5 5
primary interactions

0

0

25

50

75 100 125 150 175 200

 bunch number

Figure 2: Average number of reconstructed tracks as a function of the number
of superimposed primary interactions, given by a Monte Carlo simulation (left);
Average number of reconstructed tracks as a function of the bunch number for
a run taken with the carbon wire (right).

4.2 Deﬁning the systems

In principle, any subdetector or combination of subdetectors in the experiment
can be chosen as a system for counting empty events. In order to minimize the
dependence on Monte Carlo simulations, the requirement is a large acceptance
for tagging non-empty events, reasonably low noise levels and good stability
with time. We have chosen the most stable subdetectors in the data taking
period of year 2000. System 1 consists of the vertex detector (VDS). An event
is not empty in this system if:

• there is at least 1 reconstructed track satisfying the track selection cri-

teria explained above.

System 2 is a combination of the ring imaging Cherenkov counter (RICH)
and the electromagnetic calorimeter (ECAL). An event is considered to be not
empty in this system if the following conditions are both fulﬁlled:

• there are at least 30 reconstructed hits in the RICH.

• the deposited energy in the inner part of the ECAL is above 5 GeV.

In Fig. 3 we can see the distributions of number of tracks satisfying the
track selection criteria (a), number of hits in the Cherenkov detector (b) and
the total energy deposition in the inner part of the electromagnetic calorimeter
(c) for a run taken with a carbon target wire.

8

a)

b)

c)

10 5

10 4

10 5

10 4

10 3

0

2

4

6

8 10 12 14 16 18

0 10 20 30 40 50 60 70 80 90

0

2

4

6

8 10 12 14 16 18

0

10

20

30

40

50

0

500 100015002000250030003500

0

100 200 300 400 500 600 700

RICH hits

ECAL energy (GeV)

70
60
VDS tracks

Figure 3: Distributions of (a) number of tracks satisfying the track selection
criteria, (b) number of hits in the RICH, and (c) energy deposition in inner
ECAL, for a run taken with the carbon wire. The inserts are a zoom to the
ﬁrst bins for each distribution.

In Fig. 4 we can ﬁnd the probabilities pki, k = {0, 1, 2}, estimated as
the fraction of empty events in system 1 (a), the fraction of empty events in
system 2 (b) and the fraction of empty events in both systems (c), for the
180 nominally ﬁlled bunches. Again, remarkable variations are found between
bunches, indicating diﬀerent contributions to the total interaction rate.

2
p

a)

0
p

b)

c)

10 5

10 4

10 3

10 2

10

1

1
p

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

10 5

10 4

10 3

10 2

10

1

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

25 50 75 100 125 150 175 200

25 50 75 100 125 150 175 200

25 50 75 100 125 150 175 200

 bunch number

 bunch number

 bunch number

Figure 4: Fraction of empty events as a function of bunch number in (a) system
1; (b) system 2; and (c) both systems.

Figure 5 shows ln(1/p1), ln(1/p2) and ln(p0/p1p2) as a function of hnti for
two diﬀerent runs. Each entry corresponds to one bunch. The top row is
for a run taken with the carbon wire and very small rate ﬂuctuations. The
bottom row corresponds to a run taken with an aluminum wire and large
rate ﬂuctuations. The global parameters are obtained from an unweighted
linear ﬁt, performed after the bunches subject to rate ﬂuctuations have been
removed from the ﬁt. These bunches are identiﬁed according to the constraint

10 5

10 4

10 3

10 2

10

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

10 5

10 4

10 3

10 2

9

on the probabilities pki given by Eq. (12).
In Fig. 6 one can see the ratio
ln(p0/p1p2)/hnti, which should be approximately constant for negligible rate
ﬂuctuations. For the run taken with the carbon target wire (left plot) this ratio
is reasonably constant, indicating the absence of signiﬁcant rate ﬂuctuations.
On the other hand, for the run taken with the aluminum target wire there are
bunches which are subject to deviations from Poisson statistics which can be
identiﬁed by having a lower than average value for ln(p0/p1p2)/hnti. Notice
that these bunches can also be identiﬁed in Fig. 5(f) below the main line (where
entries concentrate), since for a given hnti they will have a lower ln(p0/p1p2).

)

1
p
/
1
(
n
l

2

1.75

1.5

1.25

1

0.75

0.5

0.25

)

1
p
/
1
(
n
l

0

0

2

1.75

1.5

1.25

1

0.75

0.5

0.25

0

0

2

4

6

8

10

12

2

4

6

8

10

12

2

4

6

8

10

12

a)

)

2
p
/
1
(
n
l

2

1.75

1.5

1.25

1

0.75

0.5

0.25

1.75

1.5

1.25

1

0.75

0.5

0.25

0

0

2

14
>

<nt

d)

)

2
p
/
1
(
n
l

0

0

14
>

<nt

b)

2

)
)

 

2
p
1
p
(
/

0
p
(
n
l

1.75

1.5

1.25

1

0.75

0.5

0.25

0

0

2

)
)

 

2
p
1
p
(
/

0
p
(
n
l

1.75

1.5

1.25

1

0.75

0.5

0.25

0

0

14
>

<nt

e)

14
>

<nt

c)

14
>

<nt

f)

14
>

<nt

2

4

6

8

10

12

2

4

6

8

10

12

2

4

6

8

10

12

Figure 5: Plots of ln(1/p1), ln(1/p2) and ln(p0/p1p2) as a function of hnti. Each
dot represents a bunch. The plots in the top row refer to a run taken with
carbon target; the plots below refer to a run taken with aluminum target. The
global parameters are obtained from a linear ﬁt.

In Table 1 we give the average values over all runs of the eﬃciencies a1,2,
the noise-probabilities q1,2 and the average number of tracks per interaction
τ , obtained from the global ﬁts to the selected runs. It can be seen that the
eﬃciencies for system 1 are typically larger than for system 2. On the other
hand, the eﬃciencies are, within errors, quite similar for all target materials.
However, we could expect them to be larger for heavier materials, which yield
higher track multiplicities. The probabilities q1,2 are similar for runs acquired

10

t

>
n
<
/
)
)

 

2
p
1
p
(
/

0
p
(
n
l

0.16

0.14

0.12

0.1

0.08

0.06

0.04

0.02

0

0

t

>
n
<
/
)
)

 

2
p
1
p
(
/

0
p
(
n
l

0.1

0.08

0.06

0.04

0.02

0

0

25 50 75 100 125 150 175 200

25 50 75 100 125 150 175 200

 bunch number

 bunch number

Figure 6: Values of ln(p0/p1p2)/hnti as a function of bunch number for a run
taken with the carbon wire (left) and the aluminum wire (right).

a1

C 0.95 ± 0.02
0.93 ± 0.02
Al
0.97 ± 0.02
Ti
W 0.96 ± 0.06

a2
0.86 ± 0.02
0.83 ± 0.02
0.86 ± 0.02
0.87 ± 0.05

q1
0.0189 ± 0.0003
0.0516 ± 0.0008
0.0212 ± 0.0003
0.0177 ± 0.0002

q2
0.0116 ± 0.0001
0.0535 ± 0.0011
0.0142 ± 0.0002
0.0126 ± 0.0001

τ
7.69 ± 0.26
8.27 ± 0.24
9.95 ± 0.25
13.23 ± 0.99

Table 1: Bunch independent variables obtained from global ﬁts to nominally
ﬁlled bunches.

with carbon, titanium and tungsten targets, but larger for runs acquired with
the aluminum target. This fact may be explained by the large fraction of
coasting beam (unbunched protons uniformly distributed under the pulsed
bunch structure) which plagues all runs taken with this wire [18]. Furthermore,
because the runs taken with the aluminum wire target tend to show large rate
instabilities it is natural to speculate if these are related to the presence of
coasting beam.

The mean number of tracks per interaction τ increases, as expected, with
the atomic weight of the target material. This dependence is usually param-
eterized by a power law of the atomic weight: τ ∝ Aβ. If we ﬁt the values
of τ as a function of the target atomic weight A, we obtain β = 0.20 ± 0.02,
which is statistically compatible with the result β = 0.18 ± 0.02 obtained in
an independent study employing the HERA-B vertex detector [19].

Once τ is known, the average number of interactions per bunch crossing
µi can be calculated according to Eq. (10). Figure 7 shows the values of µi
for all bunches, for a run taken with the carbon target wire (a) and with the

11

aluminum target wire (b). First, it is noteworthy that bunches contribute
quite diﬀerently to the rate, even if the runs have ﬂat bunch spectra. In the
run taken with aluminum target we can see a large contribution of nominally
empty bunches to the total rate. This behaviour can be observed in other
runs taken with aluminum wire and, again, this can be explained by the large
fraction of coasting beam which is present in all runs taken with this wire.

a)

b)

2.5

2.25

2

1.75

1.5

1.25

1

0.75

0.5

0.25

0

0

2.5

2.25

2

1.75

1.5

1.25

1

0.75

0.5

0.25

0

0

25 50 75 100 125 150 175 200

25 50 75 100 125 150 175 200

 bunch number

 bunch number

Figure 7: Mean number of interactions as a function of bunch number for a
run taken (a) with a carbon target wire, and (b) with an aluminum target
wire. In plot (a) it can be seen the nominally empty bunches which contribute
marginally to the interaction rate. In plot (b) these bunches contribute sig-
niﬁcantly to the rate, which is a clear indication of the high levels of coasting
beam aﬀecting this run.

The total number of interactions Nint in a run is given by Nint =

220
i=1 Niµi,
where Ni is the total number of events due to bunch i. From Nint the luminosity
is obtained using Eq. (1) and the inelastic cross sections published in Ref. [16].

P

4.3 Systematic uncertainties

Because the ﬁnal states of proton-nucleus interactions sample a large phase-
space, certain event topologies may be outside the acceptance of both subde-
tectors, leading to systematic uncertainties in the measured luminosity. Events
which are not seen by both systems do not contribute to any ineﬃciency as
inferred by the TSSM, and thus lead to an overestimate of the true acceptance.
The systematic uncertainties of the statistical method were studied with a toy
Monte Carlo based on the interaction model MINT [20] and a coarse simula-
tion of the HERA-B detector based on angular acceptance cuts, some rough

12

m
m
estimates for the track ﬁnding eﬃciencies plus some assumption about noise
and smearing in the RICH and ECAL. The impact on the measured lumi-
nosity of diﬀractive contributions, rate ﬂuctuations by ±20%, target materials
covering the range from Carbon to Tungsten and nominal interaction rates
varying by a factor ±e were considered. It is found that for a detector such
as HERA-B, there is a small bias on the luminosity estimate from the TSSM.
Assuming that the reference cross section is the total inelastic cross section,
the luminosity estimate is between 3% and 6% too small. Using instead only
the non-diﬀractive inelastic cross section as a reference, the results are between
1% and 6% too high. Taking conservatively the larger of the two ranges and
correcting for the average bias, we conclude that the intrinsic systematic error
of the TSSM is around 3%. Note that this ﬁgure does not include systematic
uncertainties due to imperfect knowledge of the contributing cross sections.

5 Conclusions

A statistical method to measure the integrated luminosity of high energy in-
teractions at collider experiments was presented. The method starts from the
assumption that the number of interactions in a random triggered event follows
Poisson statistics. Then, two large acceptance subdetectors of the experiment
are considered. Counting the fraction of empty events in either of the two
subdetectors and simultaneously in both, as function of the bunch crossing
numbers, allows to infer the acceptance of the two subdetectors, noise contri-
butions and total number of interactions from the data alone, thereby reducing
the dependence of the analysis on Monte Carlo simulations. Introducing also
information from an inclusive quantity, the method was implemented such that
a bias due to rate ﬂuctuations, which tend to spoil the assumption of Pois-
son statistics for the interaction multiplicity of a given bunch, can be avoided.
This method was applied to random triggered minimum bias data collected in
the commissioning period of the HERA-B experiment in spring 2000. Without
correcting the luminosity estimates for the bias caused by those parts of the
cross section which are not seen by either of the two sub-systems considered,
the TSSM would have an intrinsic systematic error of 6%. For more hermetic
detectors and at higher energies even smaller uncertainties can be expected.
Correcting for the bias, the intrinsic systematic error of the method drops to
3%.

13

Acknowledgment

We would like to thank our colleagues from the HERA-B collaboration for
many useful discussions and their support in using HERA-B data to illus-
trate the method. This work was supported by the Max-Planck Society and
Funda¸c˜ao para a Ciˆencia e Tecnologia. One of us (JB) was covered by grant
BD/16272/98.

References

[1] E. Hartouni et al., HERA-B Technical Design Report, DESY-PRC 95/01.

[2] M. Bruschi, HERA-B 05-011, Physics 05-008, to be published.

[3] K. Ehret, Nucl. Instr. and Meth. A 446 (2000) 190.

[4] C. Bauer et al., Nucl. Instr. and Meth. A 453 (2000) 103.

[5] T. Zeuner, Nucl. Instr. and Meth. A 446 (2000) 324.; Y. Bagaturia et al.,

Nucl. Instr. and Meth. A 490 (2002) 223.

[6] M. Capeans, Nucl. Instr. and Meth. A 446 (2000) 317.

[7] J. Pyrlik, Nucl. Instr. and Meth. A 446 (2000) 299.; I. Ari˜no et al., Nucl.

Instr. and Meth. A 453 (2000) 289.

[8] G. Avoni. et al., Proc. of the IX Conference on Calorimetry in Particle
Physics, Annecy, France, October 9-14, 2000, Calorimetry in High Energy
Physics, (2001) 777.; A. Zoccoli, Nucl. Instr. and Meth. A 446 (2000) 246.

[9] M. Buchler et al., IEEE Trans. Nucl. Sci. 46 (1999) 126.; A. Areﬁev et

al., IEEE Trans. Nucl. Sci. 48 (2001) 1059.

[10] P.V.R. Murthy et al., Nucl. Phys. B 92 (1975) 269.

[11] G. Bellettini et al., Nucl. Phys. 79 (1966) 609.

[12] A.S. Carroll et al., Phys. Lett. B 80 (1979) 319.

[13] F. Fumuro et al., Nucl. Phys. B 152 (1979) 376.

[14] S.P. Denisov et al., Nucl. Phys. B 61 (1973) 62.

[15] T.J. Roberts et al., Nucl. Phys. B 159 (1979) 56.

14

[16] J. Carvalho, Nucl. Phys. A 725 (2003) 269.

[17] H. Pi, Comp. Phys. Comm. 71 (1992) 173.

[18] K. Ehret et al., Nucl. Instr. and Meth. A 456 (2001) 206.

[19] T. Perschke, PhD Thesis, University of M¨unchen (2000).

[20] M. Schmelling, Proc. of 40th Rencontres de Moriond on QCD and High
Energy Hadronic Interactions, La Thuile, Aosta Valley, Italy, 12-19 Mar
2005, hep-ph/0506028.

15

