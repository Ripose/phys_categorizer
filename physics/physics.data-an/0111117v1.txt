1
0
0
2
 
v
o
N
 
4
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
7
1
1
1
1
1
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Shape reconstruction in X-ray tomography from a small number of
projections using deformable models

Ali Mohammad–Djafari1

and Ken Sauer2

1 Laboratoire des Signaux et Syst`emes (CNRS–SUPELEC–UPS)
´Ecole Sup´erieure d’´Electricit´e
Plateau de Moulon, 91192 Gif–sur–Yvette Cedex, France

2 Department of Electrical Engineering
University of Notre Dame
Notre Dame, IN 46556, USA

Abstract. X-ray tomographic image reconstruction consists of determining an object
function from its projections. In many applications such as non-destructive testing, we
look for a fault region (air) in a homogeneous, known background (metal). The image
reconstruction problem then becomes the determination of the shape of the default re-
gion. Two approaches can be used: modeling the image as a binary Markov random ﬁeld
and estimating the pixels of the image, or modeling the shape of the fault and estimating
it directly from the projections. In this work we model the fault shape by a deformable
polygonal disc or a deformable polyhedral volume and propose a new method for directly
estimating the coordinates of its vertices from a very limited number of its projections.
The basic idea is not new, but in other competing methods, in general, the fault shape
is modeled by a small number of parameters (polygonal shapes with very small number
of vertices, snakes and deformable templates) and these parameters are estimated either
by least squares or by maximum likelihood methods. We propose modeling the shape
of the fault region by a polygon with a large number of vertices, allowing modeling of
nearly any shape and estimation of its vertices’ coordinates directly from the projections
by deﬁning the solution as the minimizer of an appropriate regularized criterion. This
formulation can also be interpreted as a maximum a posteriori (MAP) estimate in a
Bayesian estimation framework. To optimize this criterion we use either a simulated an-
nealing or a special purpose deterministic algorithm based on iterated conditional modes
(ICM). The simulated results are very encouraging, especially when the number and the
angles of projections are very limited.

key words: Computed tomography, Shape reconstruction, non destructive testing, Bayesian
MAP estimation

1.

Introduction

Tomographic image reconstruction in non destructive testing (NDT) is recent and
consists in determining an object f (x, y) from its projects p(r, φ):

p(r, φ) =

f (x, y)δ(r − x cos φ − y sin φ) dx dy

(1)

ZZ

1

In many image reconstruction applications, especially in NDT, we know that
f (x, y) has a constant value c1 inside a region P (fault region) and another constant
value c2 outside that region (safe or background region), e.g. metal & air.

f (x, y) =

c1
c2

(cid:26)

(x, y) ∈ P,

if
elsewhere

The image reconstruction problem becomes then the determination of the shape
of the fault region P .
In this work, without loss of generality, we assume that
c1 = 1 and c2 = 0 and model the shape of the object by its contour.

There has been many works in image reconstruction dealing with this problem.
To emphasis the originality and the place of this work, we give here a summary of
the diﬀerent approaches for this problem:

• The ﬁrst approach consists in discretizing the equation (1) to obtain:

p = Hf + n

where, f is the discretized values of the object f (x, y) (the pixel values of the
image), p is values of the projection data p(r, φ), n is a vector to represent the
modeling and measurement errors (noise) and H the discretized Radon operator.
Then the solution is deﬁned as the minimizer of a compound criterion

J(f ) = Q(p − Hf ) + λΩ(f ),

where λ is the regularization parameter and Q and Ω has to be chosen appro-
priately to reﬂect our prior knowledge on the noise and on the image. This
is the classical regularization approach of general image reconstruction problem.
One can also interpret J(f ) as the maximum a posteriori (MAP) criterion in the
Bayesian estimation framework where exp [−Q(f )] represents the likelihood term
and exp [−Ω(f )] the prior probability law.

This approach has been used with success in many applications (e.g. [1, 2, 3, 4])
but the cost of its calculation is huge due to the great dimension of f . Many works
have been done on choosing appropriate regularization functionals or equivalently
appropriate prior probability laws for f to enforce some special properties of the
image such as smoothness, positivity or piecewise smoothness [5, 6, 7, 8, 9]. Among
these, one can mention mainly two types of functions for Ω(f ):

Ω(f ) =

φ(fj ) with φ(x) = {|x|p, −x log x, log x, · · ·}

(5)

Entropic laws:

N

Xj=1

Markovian laws:

(2)

(3)

(4)

(6)

Ω(f ) =

φ(fj , fi)

N

Xj=1 Xi∈Nj

2

with convex potential functions:

φ(x, y) =

|x − y|p, −|x − y| log

, log cosh |x − y|, · · ·

(cid:26)

(cid:27)

x
y

or non convex potential functions:

φ(x, y) =

min{|x − y|2, 1},

(cid:26)

−1

1 + |x − y|2 , · · ·
(cid:27)

See for example [6] for the entropic laws, [7, 5] for scale invariant markovian laws
with convex potential functions and [8, 10, 9, 11] for markovian laws with non
convex potential functions and other speciﬁc choices.

• The second approach consists in modeling directly the closed contour of the
object as the zero-crossing of a smooth function u(x, y):

∂D = {(x, y) : u(x, y) = 0}

and f (x, y) =

c1
c2

(cid:26)

if u(x, y) > 0,
if u(x, y) < 0

,

(9)

and in deﬁning a time evolution for u (consequently the corresponding contour ∂D
and function f ) such that

∂D(t) = {(x, y) : u(x, y, t) = 0}

(10)

and such that as time t 7→ ∞ we arrive at a function u(x, y) such that the associated
f (x, y) is a solution to the inverse problem in a least square (LS) sense. This means
that the evolution of u and consequently the corresponding contour ∂D and object
f is such that the LS criterion

J(f ) = kp − R(f )k2

decreases during the evolution. In this approach the function u is assimilated to
a surface (of heat front wave) and the evolution of the contours ∂D is constraint
to be perpendicular to the surface. This means that the variation of the interior
region (δx, δy) is such that

(7)

(8)

(11)

(12)

(δx, δy) = α(x, y, t)

∇u
|∇u|

This is the Level-Set approach originally developed by Osher and Sethian [12] for
problems involving the motion of curves and surfaces and then adapted, used and
referred as snakes or active contour models by many authors in computer vision
[13, 14] and recently for inverse problems [15]. See also [16, 17] for the application
of the deformable templates in tomographic image reconstruction.

This approach also needs pixel or voxel representation of the image and its
calculation cost is huge, specially in 3D imaging systems. We are presently working
on this approach trying to extend it for minimizing a regularized criterion in place

3

of the the LS criterion (11) and implementing it in 2D and 3D tomographic image
reconstruction.

• The third approach starts by giving a parametric model for the object and then
tries to estimate these parameters using least squares (LS) or maximum likelihood
(ML) methods. In general, in this approach one chooses a parametric model such
as superposition of circular or elliptical homogeneous regions to be able to relate
analytically the projections to these parameters. For example, for a superposition
of elliptical homogeneous regions we have:

f (x, y) =

dkfk(x − αk, y − βk)

K

Xk=1

with fk(x, y) =

1 if
0 elsewhere

(cid:26)

(x/ak)2 + (y/bk)2 < 1,

where θ = {dk, αk, βk, ak, bk, k = 1, · · · , K} is a vector of parameters deﬁning
the parametric model of the image (density values, coordinates of the centers
and the two diameters of the ellipses). It is then easy to calculate analytically
the projections and the relation between the data and the unknown parameters
becomes:

p(r, φ) = h(r, φ; θ) + n(r, φ)

where h(r, φ; θ) has an analytic expression in θ. The LS or the ML estimate when
the noise is assumed to be zero mean, white and Gaussian, is then given by:

θ = arg min

kp(r, φ) − h(r, φ; θ)k2

θ (cid:8)

b

(cid:9)

This approach has also been used with success in image reconstruction [18, 19, 20,
21]. But, the range of applicability of these methods is limited to the cases where
the parametric models are actually appropriate.

• The fourth approach which is more appropriate to our problem of shape recon-
struction, consists in modeling directly the contour of the object by a function,
say g(θ) in a cylindrical coordinates (ρ, θ) such as:

D =

(x, y) : x2 + y2 = g2(θ)
(cid:9)
(cid:8)

.

The next step is then to relate the projections p(r, φ) to g(θ) which, in this case
is:

p(r, φ) =

δ(r − ρ cos(φ − θ))ρ dρ dθ.

(18)

2π

g(θ)

Z
0

Z
0

and ﬁnally to discretize this relation to obtain:

p = h(g) + n

(19)

(13)

(14)

(15)

(16)

(17)

4

where g represents the discretized values of g(θ) deﬁning the contour of the object
and h(g) represents the discretized version of the nonlinear operator (18) relating
projection data p and g. Then, one deﬁnes the solution as the argument which
minimizes

J(g) = ||p − h(g)||2 + λΩ(g),

(20)

where Ω(g) has to be chosen appropriately to reﬂect some regularity property of
the object’s contour.

In this case also one can consider J(g) as the MAP criterion with Q(g) =

||p − h(g)||2 as the likelihood term and Ω(g) as the prior one.
This approach has been used in image restoration [22], but it seems to be new in
image reconstruction applications and the proposed method in this work is in this
category. The originality of our work is to model the contour of the object by a
piecewise linear function which means that the object is modeled as a polygonal
region whose vertices are estimated directly from the projection data.

2. Proposed method

In this paper we propose to model the contour of the object (fault region) as
a periodic piecewise linear function or equivalently to model the shape of the
object as a polygonal region with a great number N of vertices to be able to
approximate any shape. Then we propose to estimate directly the coordinates
{(xj, yj), j = 1, · · · , N } of the vertices of this polygonal region from the projection
data.

f (x, y) =

1 (x, y) ∈ P
0 (x, y) 6∈ P

(cid:26)

y✻

p = h(z) + n

zj+1
zj

zj−1

✲
x

pi

z1

zN

φ

5

Figure 1: Proposed shape reconstruction modeling.

The idea of modeling the shape of the object as a polygonal region is not new
and some works have been done in image reconstruction applications. See for
example Milanfar, Karl & Willsky [23, 24, 25], but in general, in these works,
either a hypothesis of convexity of the polygonal region has been used which is
very restrictive in real applications or the number of vertices of the polygon is
restricted to a very small number. In our work we do not make neither of these
hypothesis; the polygon can be convex or not and we choose N suﬃciently great
to to be able to approximate appropriately any shape.

The solution is then deﬁned as the minimizer the following criterion

J(z) = ||p − h(z)||2 + λΩ(z),

(21)

where z = x + iy is a complex vector whose real and imaginary parts represent
the x and the y coordinates of the polygon vertices, h(z) represents the direct
operator which calculates the projections for any given z and Ω(z) is chosen to be
a function which reﬂects the regularity of the object contour. One can for example
choose the following function:

Ω(z) = 

|zj+1 − zj| − 2πR0

(22)

N

Xj=1



2



which favors a shape whose contour length is near a prior known value 2πR0. In
this work we used the following function:

Ω(z) =

|zj−1 − 2zj + zj+1|2 = 4

|zj − (zj−1 − zj+1)/2|2 ,

(23)

N

Xj=1

N

Xj=1

which favors a shape whose local curvature is limited. Note that |zj − (zj−1 − zj+1)/2|
is just the Euclidian distance between the point zj and the midpoint of the line seg-
ment passing through zj−1 and zj+1 and so this choice favors a shape whose local
curvature is limited. We can also give a probabilistic interpretation to this choice.
In fact we can consider zj as random variables with the following Markovian law:

p(zj|z) = p(zj|zj−1, zj+1) ∝ exp

−

1
2σ2 |zj − (zj−1 − zj+1)/2|2

.

(cid:21)

(cid:20)

(24)

Other functions are possible and are studied in this work.

In both cases, the criterion J(z) is multi-modal essentially due to the fact that
h(z) is a nonlinear function of z. Calculating the optimal solution corresponding
to the global minimum of (21) needs then carefully designed algorithms. For this
we propose the two following strategies:

• The ﬁrst is to use a global optimization technique such as simulated annealing.
This technique has given satisfactory results as it can be seen from the simulations
in the next section. However, this algorithm needs a great number of iterations
and some skills for choosing the ﬁrst temperature and cooling schedule, but the

6

overall calculations is not very important due to the fact that, in this algorithm,
at each iteration only one of the vertices zj is changed. So, at each step we need
to calculate the variation of the criterion due to this change which can be done
with a reasonable cost.

• The second is to ﬁnd an initial solution in the attractive region of the global
optimum and to use a local descent type algorithm such as the ICM (Iterated
conditional modes) of Besag [26, 27, 28] to ﬁnd the solution.

The main problem here is how to ﬁnd this initial solution. For this, we used
a moment based method proposed by Milanfar, Karl & Willsky [23, 24, 25] which
is accurate enough to obtain an initial solution which is not very far from the
optimum. The basic idea of this method is to relate the moments of the projections
to the moments of a class of polygonal regions obtained by an aﬃne transformation
of a regular polygonal region, and so to estimate a polygonal region whose corners
are on an ellipse and whose moments up to the second order matches those of the
projections.

However, there is no theoretical proof that this initial solution will be in the
attractive region of the global optimum. The next section will show some results
comparing the performances of these two methods as well as a comparison with
some other classical methods.

3. Simulation results

To measure the performances of the proposed method and keeping the objective
of using this method for NDT applications where the number of projections are
very limited, we simulated two cases where the objects have polygonal shapes with
N = 40 corners (hand-made) and calculated their projections for only 5 directions

φ = {−45, −22.5, 0, 22.5, 45}

degrees.

Then, we added some noise (white, Gaussian and centered) on them to simulate
the measurement errors. The signal to noise ratio (SNR) was chosen 20dB. We
deﬁne SNR as follows:

SN R = 10 log

i(pi − ¯p)2
i(ni − ¯n)2

P
P

where pi and ni are respectively data and noise samples and ¯p and ¯n their respective
mean values.

Finally, from these data we estimated the solutions by the proposed method
using either the simulated annealing (SA) or the iterated conditional modes (ICM)
algorithms.

Figure 2 shows these two objects and their relative simulated projections data.
In Figures 3 and 4, we give the reconstruction results obtained by the proposed
method using either the SA algorithm (Figure 3) or the ICM algorithm (Figure 4).
In these ﬁgures we show the original objects, the initial solutions, the intermediate
solutions during the iterations and the ﬁnal reconstructed objects obtained after
200 iterations.

7

Note that, the SA algorithm is theoretically independent of initialization while
the ICM is not. However, in these ﬁgures, for the purpose of the comparison, we
show the results obtained by the two algorithms with the same initialization.

To show that the method is not very sensible on the prior knowledge of the
vertices number, we give in Figure 5, the reconstruction results of the object 2 in
4 cases: N = 10, N = 20 and N = 30 and N = 40. As we can remark all the
reconstructed results seem satisfactory.

In Figure 6 we show a comparison between the results obtained by the proposed
method and those obtained either by a classical backprojection method or by some
other methods in the ﬁrst approach using (3) and (4) with diﬀerent regularization
functionals Ω(f ), more speciﬁcally:

− Gaussian Markov models (5) with the potential function φ(x, y) = |x − y|2
which can also be considered as a quadratic regularization method; and

− Compound Markov models with non convex potential functions φ(x, y) =

min

|x − y|2, 1

which is a truncated quadratic potential function.

(cid:8)

(cid:9)

In the ﬁrst case the criterion to optimize is convex and we used a conjugate gradient
(CG) algorithm to ﬁnd the optimized solution. In the second case the criterion
is not convex and we used a Graduated non convexity (GNC) based optimization
algorithm developed in [10, 9, 11] to ﬁnd the solution.

Note that, these results are given here to show the relative performances of
these methods in a very diﬃcult situation where we have only ﬁve projections.
In fact, in more comfortable situations (more projections uniformly distributed
around the object and high SNR) all these methods, even the simplest one such
as the classical backprojection will give similar and satisfactory results. Here, we
compare the results obtained from the same restricted set of data.

8

Projections

y

f(x,y)

Projections

y

f(x,y)

x

x

−80

−60

−40

−20

0

20

40

60

80

80

60

40

20

0

−20

−40

−60

−80

80

60

40

20

0

−20

−40

−60

−80

−80

−60

−40

−20

0

20

40

60

80

Figure 2: Original images and simulated projections data.

9

o: orig,    +: init,    *: rec.

o: orig,    +: init,    *: rec.

−30

−20

−10

10

20

30

−30

−20

−10

10

20

30

0
x

Figure 3: Reconstruction results using simulated annealing.
o) Original objects, +) Initializations,
the iterations and
⋆) Final reconstructed objects.

.) Evolution of the solutions during

o: orig,    +: init,    *: rec.

o: orig,    +: init,    *: rec.

y

0

30

20

10

−10

−20

−30

y

0

30

20

10

−10

−20

−30

0
x

0
x

y

0

30

20

10

−10

−20

−30

y

0

30

20

10

−10

−20

−30

−30

−20

−10

10

20

30

−30

−20

−10

10

20

30

0
x

Figure 4: Reconstruction results using a moment-based initialization and a local
descent (ICM) minimizer.
o) Original objects, +) Initializations,
the iterations and
⋆) Final reconstructed objects.

.) Evolution of the solutions during

10

a

o: orig,    +: init,    *: rec.

b

o: orig,    +: init,    *: rec.

y

0

y

0

30

20

10

−10

−20

−30

30

20

10

−10

−20

−30

0
x

c

0
x

−30

−20

−10

10

20

30

−30

−20

−10

10

20

30

o: orig,    +: init,    *: rec.

o: orig,    +: init,    *: rec.

y

0

y

0

−30

−20

−10

10

20

30

−30

−20

−10

10

20

30

Figure 5: Reconstruction results with diﬀerent number of vertices N of the same
object. The number of vertices of the original object is N = 40.

a) N = 10,

b) N = 20

c) N = 30

and

d) N = 40.

0
x

d

0
x

30

20

10

−10

−20

−30

30

20

10

−10

−20

−30

11

−30

−20

−10

0

10

20

30

−30

−20

−10

0

10

20

30

−30

−20

−10

0

10

20

30

a

Original

d

back

30

20

10

0

−10

−20

−30

−30

−20

−10

0

10

20

30

30

20

10

0

−10

−20

−30

−30

−20

−10

0

10

20

30

c

geom

f

gnc1

30

20

10

0

−10

−20

−30

−30

−20

−10

0

10

20

30

−30

−20

−10

0

10

20

30

−30

−20

−10

0

10

20

30

−30

−20

−10

0

10

20

30

Figure 6: A comparison with backprojection and some other classical methods:
a) Original objects,
b) Results obtained by the proposed method using the SA optimization algorithm,
c) Results obtained by the proposed method using the ICM algorithm,
d) Backprojection,
e) Gaussian Markov modeling MAP estimation and
f) Compound Markov modeling and GNC optimization algorithm.

b

geom

e

regq1

12

−30

−20

−10

0

10

20

30

−30

−20

−10

0

10

20

30

−30

−20

−10

10

20

30

a

Original

d

back

30

20

10

0

−10

−20

−30

−30

−20

−10

0

10

20

30

30

20

10

0

−10

−20

−30

−30

−20

−10

0

10

20

30

c

geom

0

f

gnc1

30

20

10

0

−10

−20

−30

−30

−20

−10

0

10

20

30

−30

−20

−10

0

10

20

30

−30

−20

−10

0

10

20

30

−30

−20

−10

0

10

20

30

Figure 7: A comparison with backprojection and some other classical methods:
a) Original objects,
b) Results obtained by the proposed method using the SA optimization algorithm,
c) Results obtained by the proposed method using the ICM algorithm,
d) Backprojection,
e) Gaussian Markov modeling MAP estimation and
f) Compound Markov modeling and GNC optimization algorithm.

b

geom

e

regq0

13

4. Conclusions

A new method for tomographic image reconstruction of a compact binary object
from a small number of its projections is proposed. The basic idea of the proposed
method is to model the compact binary object as a polygonal region whose vertices
coordinates are estimated directly from the projections using the Bayesian MAP
estimation framework or equivalently by optimizing a regularized criterion.

Unfortunately, this criterion is not unimodal. To ﬁnd the optimized solution

two algorithms have been proposed:
– a global optimization algorithm based on simulated annealing (SA) and
– a local descent-based method based on the Iterated Conditional Modes (ICM)
algorithm proposed originally by Besag, with a good initialization obtained by
using a moment based method.

The ﬁrst algorithm seems to give entire satisfaction. The second can also give
satisfaction, but it may also be plugged in a local minimum. In both algorithms
the main cost calculation is due to the calculus of the variation of the criterion
when one of the vertices coordinates is changed. We have written an eﬃcient
program to do this [29, 30].

An extension of this work to 3D image reconstruction with small number of
conic projections is in preparation [31, 32]. The ﬁnal objective of the proposed
method is for non destructive testing (NDT) image reconstruction applications
where we can use not only X-rays but also ultrasound or Eddy currents or a
combination of them [33, 34, 11] to localize and to characterize more accurately
any anomalies (air bulbs) in metallic structures.

References

1. G. Herman, H. Tuy, H. Langenberg, and P. Sabatier, Basic Methods of To-

mography and Inverse Problems. Adams Hilger, 1987.

2. A. Kak and M. Slaney, Principles of Computerized Tomographic Imaging. New

York, NY: IEEE Press, 1987.

3. S. Geman and D. McClure, “Statistical methods for tomographic image re-
construction,” in Proc. of the 46-th Session of the ISI, Bulletin of the ISI,
vol. 52, pp. 22–26, 1987.

4. G. Demoment, “Image reconstruction and restoration : Overview of common
estimation structure and problems,” IEEE Transactions on Acoustics Speech
and Signal Processing, vol. ASSP-37, pp. 2024–2036, December 1989.

5. S. Brette, J. Idier, and A. Mohammad-Djafari, “Scale invariant Markov mod-
els for linear inverse problems,” in Proc. of the Section on Bayesian Statistical
Sciences, (Alicante, Spain), pp. 266–270, American Statistical Association,
1994.

6. A. Mohammad-Djafari and J. Idier, A scale invariant Bayesian method to
solve linear inverse problems, pp. 121–134. MaxEnt93, Santa Barbara, U.S.A.:
Kluwer Academic Publishers, G. Heidbreder ed., 1996.

7. C. Bouman and K. Sauer, “A generalized Gaussian image model for edge-

14

preserving map estimation,” IEEE Transactions on Image Processing, vol. IP-
2, pp. 296–310, July 1993.

8. L. Bedini, I. Gerace, and A. Tonazzini, “A deterministic algorithm for re-
constructing images with interacting discontinuities,” Computer Vision and
Graphics and Image Processing, vol. 56, pp. 109–123, March 1994. AMD.
9. M. Nikolova, J. Idier, and A. Mohammad-Djafari, “Inversion of large-support
ill-posed linear operators using a piecewise Gaussian mrf,” tech. rep., gpi–
lss, to appear in IEEE Transactions on Image Processing, Gif-sur-Yvette,
France, 1997.

10. M. Nikolova, A. Mohammad-Djafari, and J. Idier, “Inversion of large-support
ill-conditioned linear operators using a Markov model with a line process,”
in Proceedings of IEEE ICASSP, vol. V, (Adelaide, Australia), pp. 357–360,
1994.

11. M. Nikolova and A. Mohammad-Djafari, “Eddy current tomography using a
binary Markov model,” Signal Processing, vol. 49, pp. 119–132, May 1996.
12. S. Osher and J. Sethian, “Fronts propagating with curvature-dependent speed:
Algorithms based on hamilton-jacobi formulations,” Journal of Computa-
tional Physics, vol. 79, pp. 12–49, 1988.

13. F. Catt´e, P. Lions, J. Morel, and T. Coll, “Image selective smoothing and edge
detection by nonlinear diﬀusion,” SIAM J. Num. Anal., vol. 29, pp. 182–193,
1992.

14. R. Malladi, J. Sethian, and B. Vemuri, “Shape modelling with front prop-
agation: A level-set approch,” IEEE Transactions on Pattern Analysis and
Machine Intelligence, vol. 17, 1995.

15. F. Santosa, “A level-set approch for inverse problems involving obstacles,”
Control, Optimisation and Calculus of Variations, vol. 1, pp. 17–33, 1996.
16. K. M. Hanson, G. S. Cunningham, and R. J. McKee, “Uncertainties in tomo-
graphic reconstructions based on deformable models,” in Image Processing,
K. M. Hanson, ed., Proc. SPIE, vol. 3034, pp. 276–286, 1997.

17. K. M. Hanson, G. S. Cunningham, and R. J. McKee, “Uncertainty assessment
for reconstructions based on deformable models,” Int. J. Imaging Systems and
Technology, vol. 8, pp. 506–512, 1997.

18. L. A. Shepp and Y. Vardi, “Maximum likelihood reconstruction for emission
tomography,” IEEE Trans. on Medical Imaging, vol. MI-1, pp. 113–122, 1982.
19. D. Rossi and A. Wilsky, “Reconstruction from projections based on detection
and estimation of objects,” ieeeASSP, vol. ASSP-32, no. 4, pp. 886–906, 1984.
20. J. Prince and A. Wilsky, “Reconstructing convex sets from support line mea-

surements,” ieeePAMI, vol. 12, no. 3, pp. 377–389, 1990.

21. J. Prince and A. Wilsky, “Convex set reconstruction using prior shape infor-

mation,” CVGIP, vol. 53, no. 5, pp. 413–427, 1991.

22. N. Friedland and A. Rosenfeld, “Compact object recognition using energy-
function-based optimization,” IEEE Transactions on Pattern Analysis and
Machine Intelligence, vol. 14, no. 7, pp. 770–777, 1992.

23. P. Milanfar, W. Karl, and A. Wilsky, “A moment-based variational approach
to tomographic reconstruction,” IEEE Transactions on Image Processing,

15

vol. 25, no. 9, pp. 772–781, 1994.

24. P. Milanfar, W. Karl, and A. Wilsky, “Reconstructing binary polygonal ob-
jects from projections: A statistical view,” CGVIP, vol. 56, no. 5, pp. 371–391,
1994.

25. P. Milanfar, G. Vergese, W. Karl, and A. Wilsky, “Reconstructing polygons
from moments with connections to array processing,” IEEE Transactions on
Signal Processing, vol. 43, no. 2, pp. 432–443, 1995.

26. J. E. Besag, “On the statistical analysis of dirty pictures (with discussion),”

Journal of the Royal Statistical Society B, vol. 48, no. 3, pp. 259–302, 1986.

27. J. E. Besag, “Digital image processing : Towards Bayesian image analysis,”

Journal of Applied Statistics, vol. 16, no. 3, pp. 395–407, 1989.

28. J. E. Besag and P. Green, “Spatial statistics and Bayesian computation,” J.

R. Statist. Soc. B, vol. 55, pp. 25–37, 1993.

29. A. Mohammad-Djafari, “Image reconstruction of a compact object from a
few number of projections,” in IASTED, Int. Conf. on Signal and Image
Processing (SIP’96), (Orlando, Florida, USA), pp. 325–329, 1996.

30. A. Mohammad-Djafari, “A Bayesian approach to shape reconstruction of a
compact object from a few number of projections,” in Maximum Entropy and
Bayesian Methods, (MaxEnt96, Aug. 96, Berg-en-Dal, South Africa), Kluwer
Academic Publishers, 1996.

31. A. Mohammad-Djafari and Y. Khayi, “Array processing techniques and shape
reconstruction in tomography,” in Proceedings of IEEE ICASSP, vol. II, (Mu-
nich, Germany), pp. 3785–3789, 1997.

32. A. Mohammad-Djafari, K. Sauer, Y. Khayi, and E. Cano, “Reconstruction of
the shape of a compact object from a few number of projections,” in IEEE
Int. Conf. on Image Processing (ICIP), vol. 1, (IEEE ICIP 97, Santa Barbara,
CA, USA), pp. 165–169, 1997.

33. S. Gautier, G. Le Besnerais, A. Mohammad-Djafari, and B. Lavayssi`ere, Data
fusion in the ﬁeld of non destructive testing. Santa Fe, U.S.A.: Kluwer Aca-
demic Publishers, K. Hanson ed., 1995.

34. D. Pr´emel and A. Mohammad-Djafari, “Eddy current tomography in cylindri-
cal geometry,” IEEE Transactions on Magnetics, vol. M-31, pp. 2000–2003,
May 1995.

16

