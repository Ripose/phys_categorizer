2
0
0
2
 
r
a

M
 
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
2
0
0
3
0
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Finding an Upper Limit in the Presence of Unknown Background

UCSB-HEP-2002-01

S. Yellin∗
Department of Physics, University of California,
Santa Barbara, Santa Barbara, CA 93106, USA
(Dated: February 5, 2008)

Experimenters report an upper limit if the signal they are trying to detect is non-existent or
below their experiment’s sensitivity. Such experiments may be contaminated with a background
too poorly understood to subtract. If the background is distributed diﬀerently in some parameter
from the expected signal, it is possible to take advantage of this diﬀerence to get a stronger limit
than would be possible if the diﬀerence in distribution were ignored. We discuss the “Maximum
Gap” method, which ﬁnds the best gap between events for setting an upper limit, and generalize to
“Optimum Interval” methods, which use intervals with especially few events. These methods, which
apply to the case of relatively small backgrounds, do not use binning, are relatively insensitive to
cuts on the range of the parameter, are parameter independent (i.e., do not change when a one-one
change of variables is made), and provide true, though possibly conservative, classical one-sided
conﬁdence intervals.

PACS numbers: 06.20.Dk, 14.80.-j, 14.80.L7, 95.35+d

I.

INTRODUCTION

Suppose we have an experiment whose events are dis-
tributed along a one-dimensional interval. The events
are produced by a process for which the expected shape
of the event distribution is known, but with an unknown
normalization. In addition to the signal, there may also
be a background whose expectation value per unit in-
terval is known, but one cannot completely exclude the
possibility of an additional background whose expecta-
tion value per unit interval is non-negative, but is other-
wise unknown. If the experimenters cannot exclude the
possibility that the unknown background is large enough
to account for all the events, they can only report an up-
per limit on the signal. Even experimenters who think
they understand a background well enough to subtract
it may wish to allow for the possibility that they are
mistaken by also presenting results without subtraction.
Methods based on likelihood, such as the approach of
Feldman-Cousins [1], or Bayesian analysis, cannot be ap-
plied because the likelihood associated with an unknown
background is unknown. An example of this situation is
analysis of an experiment which tries to detect recoil en-
ergies, Erecoil, deposited by WIMPs bouncing oﬀ atoms
in a detector. For a given WIMP mass, and assumed
WIMP velocity distribution, the shape of the distribu-
tion in Erecoil can be computed, but the WIMP cross
section is unknown, and it is hard to be certain that all
backgrounds are understood. The simplest way of deal-
ing with such a situation is to pick an interval in, say,
Erecoil, and take as upper limit the largest cross section
that would have a signiﬁcant probability, say 10%, of
giving as few events as were observed, assuming all ob-
served events were from WIMPs. One problem with this

∗email:yellin@slac.stanford.edu

naive method is that it can be very sensitive to the in-
terval chosen. It is typical for the bottom of a detector’s
range of sensitivity to be limited by noise or other back-
grounds. Thus if the interval extends to especially low
Erecoil, there will be many events, leading to a weaker
(higher) upper limit than is required by the data. On
the other hand, experimenters could inadvertently bias
the result by choosing the interval’s endpoints to give es-
pecially few events, with an upper limit that is lower than
is justiﬁed by the data. In order to avoid such a bias, one
might think it is best to avoid using the observed events
to select the interval used. But the procedures discussed
here take the opposite approach. The range is carefully
chosen to include especially few events compared with
the number expected from a signal. The way the range
is chosen makes the procedure especially insensitive to
unknown background, which tends to be most harmful
where there are especially many events compared with
the number expected from a signal. It would be a mis-
take to compute the upper limit as if the interval were
selected without using the data; so the computation is
designed to be correct for the way the data are used.

While the methods described here cannot be used to
identify a positive detection, they are appropriate for
obtaining upper limits from experiments whose back-
grounds are very low, but non-zero. These methods have
been used by the CDMS experiment [2].

II. MAXIMUM GAP METHOD

Figure 1 illustrates the Maximum Gap method. The
small rectangles along the horizontal axis represent
events, with the position on the horizontal axis repre-
senting some measured parameter, say “energy”, E. The
curve shows the event spectrum, dN/dE, expected from a
proposed cross section, σ. If there is a completely known
background, it is included in dN/dE. But whether or

2

E

 
t
i
n
U
 
r
e
p
 
r
e
b
m
u
N

 

 
t
n
e
v
E
d
e
t
c
e
p
x
E
=
E
d
/
N
d

 

 

Maximum Gap
= Maximum x
x
i
E

i+1
dN___
dE

x =
i

E

i

E i

E i+1

FIG. 1: Illustration of the Maximum Gap method. The horizontal axis is some parameter, “E”, measured for each event. The
smooth curve is the signal expected for the proposed cross section, including any known background. The events from signal,
known background, and unknown background are the small rectangles along the horizontal axis. The integral of the signal
between two events is “xi”.

not there is a completely known background, we assume
there is also an unknown background contaminating the
data. To set an upper limit, we vary the proposed size
of σ until it is just high enough to be rejected as being
too high. We seek a criterion for deciding if a proposed
signal is too high. Since there are especially many events
at low E, while dN/dE is not especially high there, those
events must be mostly from the unknown background. If
we only looked at the low energy part of the data, we
would have to set an especially weak (high) upper limit.
To ﬁnd the strongest (lowest) possible upper limit, we
should look at energies where there aren’t many events,
and therefore isn’t much background.

Between any two events, Ei and Ei+1, there is a gap.
For a given value of σ, the “size” of the gap can be char-
acterized by the value within the gap of the expected
number of events,

Ei+1

dN
dE

dE.

xi =

Z

Ei

(1)

The “maximum gap” is the one with the greatest “size”;

it is the largest of all the xi. The bigger we assume σ to
be, the bigger will be the size of the maximum gap in the
observed event distribution. If we want, we can choose σ
so large that there are millions of events expected in the
maximum gap. But such a large σ would be experimen-
tally excluded, for unless a mistake has been made, it is
almost impossible to ﬁnd zero events where millions are
expected. To express this idea in a less extreme form, a
particular choice of σ should be rejected as too large if,
with that choice of σ, there is a gap between adjacent
events with “too many” expected events. The criterion
for “too many” is that if the choice of σ were correct, a
random experiment would almost always give fewer ex-
pected events in its maximum gap. Call x the size of
the maximum gap in the random experiment. If the ran-
dom x is lower than the observed maximum gap size with
probability C0, the assumed value of σ is rejected as too
high with conﬁdence level C0. For a given σ and x, this
conﬁdence level can be computed. Call “µ” the expected
total number of events in the entire interval. C0, the
probability of the maximum gap size being smaller than

a particular value of x, is a function only of x and µ:

C0(x, µ) =

m

Xk=0

(kx − µ)ke−kx
k!

1 +

(cid:18)

k
µ − kx (cid:19)

,

(2)

where m is the greatest integer ≤ µ/x. For a 90% con-
ﬁdence level upper limit, increase σ until µ and the ob-
served x are such that C0 reaches 0.90.

Equation 2 can be evaluated relatively quickly when
C0 is near 0.9. When µ is small, so is m, and when µ
is large, the series can be truncated at relatively small k
without making a signiﬁcant error. Equation 2 is derived
in the Appendix.

While this method can be used with an arbitrary num-
ber of events in the data, it is most appropriate when
there are only a few events in the part of the range
that seems relatively free of background (small µ). The
method is not dependent on a choice for binning because
unbinned data are used. No Monte Carlo computation of
the conﬁdence level is needed because the same formula
for C0 applies independent of the functional form for the
shape of the expected event distribution. The result is a
conservative upper limit that is not too badly weakened
by a large unknown background in part of the region un-
der consideration; the method eﬀectively excludes regions
where a large unknown background causes events to be
too close together for the maximum gap to be there.

III. OPTIMUM INTERVAL METHODS

If there is a relatively high density of events in the data,
we may want to replace the “maximum gap” method by
one in which we consider, for example, the “maximum”
interval over which there is 1 event observed, or 2 events,
or n events, instead of zero events. But we do not want to
allow n to be chosen in a way that skews results to con-
form with our prejudices. Two methods will be discussed
for ﬁnding an upper limit with n selected automatically.
These two methods have in common that for a given in-
terval within the range of the experimental variable, they
deﬁne a quantity, Qn(x, ∗), that characterizes how badly
n, the observed number of events within the interval, is
exceeded by x, the number of events expected from the
assumed cross section. If Qn depends on other quantities
that represent details of the cross section, “∗” represents
those quantities. For both methods, Qn(x, ∗) is chosen
so that the bigger it is, the stronger is the evidence that
the true cross section is smaller than the assumed one.
The two methods diﬀer in what function Qn(x, ∗) is cho-
sen, but for both methods, Qn(x, ∗) increases when x
increases and it increases when n decreases. For both
methods one ﬁnds the “optimum interval”, the interval
that most strongly indicates that the observed signal is
too small for the proposed cross section. The optimum
interval tends to be one in which the unknown back-
ground is especially small. The overall test quantity used
for ﬁnding an upper limit on the cross section is QMax,

3

the maximum over all possible intervals of Qn(x, ∗). The
larger QMax is, the more reason one has to reject the as-
sumed cross section as being too high. A 90% conﬁdence
level upper limit on the cross section is one for which the
observed QMax is higher than would be expected from
90% of random experiments with that cross section.

The deﬁnition of QMax seems to imply that its determi-
nation requires checking an inﬁnite number of intervals.
But given any interval with n events, x, hence Qn(x, ∗),
can be increased without increasing n by expanding the
interval until it almost hits either another event or an
endpoint of the total experimental range. For determi-
nation of QMax one need only consider intervals that are
terminated by an event or by an endpoint of the total ex-
perimental range. If the experiment has N events, then
there are (N + 1)(N + 2)/2 such intervals, one of which
has Qn(x, ∗) = QMax.

The quantity “x” has been deﬁned so that it is param-
eter independent: a one-one transformation to another
variable in which the events are distributed leaves x un-
changed. We only consider Qn(x, ∗) whose deﬁnition is
parameter independent; so QMax is also unchanged under
a change of variable. One may therefore make a trans-
formation at a point from whatever variable is used, say
Erecoil, to a variable equal to the total number of events
expected in the interval between the point and the low-
est allowed value of Erecoil. No matter how events were
expected to be distributed in the original variable, in the
new variable they are distributed uniformly with unit
density. Thus any event distribution is equivalent to a
uniform distribution of unit density. The method may
depend on the total length of this uniform unit density
distribution, and in this new variable the total length
of the distribution is equal to the total expected num-
ber of events, µ, but it does not depend on the shape
of the original event distribution. Thus we can replace
“∗” with “µ”; Qn(x, ∗) ≡ Qn(x, µ). For a given value of
µ, the probability distribution of QMax is independent of
the shape of the expected distribution of events, and can
be computed once and for all (by Monte Carlo) using a
uniform event distribution. The function ¯QMax(C, µ) is
deﬁned to be the value such that fraction C of random
experiments with that µ, and no unknown background,
will give QMax < ¯QMax(C, µ). Thus the 90% conﬁdence
level upper limit on the cross section is where QMax of
the experiment equals ¯QMax(.9, µ).

The function ¯QMax(.9, µ) has certain peculiarities. For
example, it cannot be deﬁned for µ < 2.3026. The rea-
son for this limitation is that the largest possible value
for QMax is when there are zero events. But random
experiments with µ < 2.3026 get zero events more than
10% of the time. Random experiments therefore produce
the largest possible value of QMax more than 10% of the
time, and so the QMax of the data exceeds that of ran-
dom experiments less than 90% of the time. Thus no
cross section resulting in µ < 2.3026 can be excluded to
as high a conﬁdence level as 90%.

Another peculiarity of ¯QMax(.9, µ) is that it is not es-

pecially smooth as a function of µ; it tends to increase
rapidly near certain values of µ. To understand this
behavior, note that for a given value of µ, the maxi-
mum possible value of x, the expected number of events
in an interval, is x = µ. Thus the maximum possible
value over all x of Qn(x, µ) is Qn(µ, µ).
If Qn(µ, µ) is
less than ¯QMax(.9, µ) then intervals with n events can-
not have QMax = Qn for that value of µ. Furthermore,
since Qn(x, µ) decreases with increasing n, intervals with
m > n events also have Qm < QMax. For low enough
µ, only intervals with n = 0 need be considered. In this
case, the 90% conﬁdence upper limit for QMax occurs
when x in Q0(x, µ) is equal to x0(.9, µ), where x0(C, µ)
is the inverse of C0(x, µ); it is deﬁned as the value of x0
for which C0(x0, µ) = C. Thus for low enough µ (but
above 2.3026)

¯QMax(.9, µ) = Q0(x0(.9, µ), µ).

(3)

This formula for ¯QMax breaks down as soon as µ is large
enough to have Q1(µ, µ) > ¯QMax(.9, µ), for at this value
of µ it is possible for an interval with n = 1 to be QMax.
In general, the threshold µ for intervals with n points be-
ing able to produce QMax for conﬁdence level C is where

Qn(µ, µ) = ¯QMax(C, µ).

(4)

Every time a threshold in µ is passed that allows another
value of n to participate in producing QMax, the value of
¯QMax(C, µ) spurts upward.

Let us now discuss the two “optimum interval” meth-

ods separately.

A. Poisson Probability of More than n Events in
the Interval

For the ﬁrst optimum interval method, the Qn(x, µ)
for a particular interval within the experimental range is
the calculated (Poisson) probability of there being more
events in a random interval of that size than were actually
observed,

Qn(x, µ) ≡
≡

∞
k=n+1

pn(x) ≡ P (x, n + 1)
xk
0 dt tn
k! e−x =
R

x

n! e−t.

P

(5)

The last equality is proved by observing that both sides
have the same derivative, and they have the same value
at x = 0. P (x, a), the incomplete Gamma function, is
in CERNLIB [3] as GAPNC(a,x), DGAPNC(a,x), and
GAMDIS(x,a).

When the interval is chosen to be the entire experi-
mental range, and the number of events in the entire ex-
perimental range is N , then pN (µ) = 0.9 deﬁnes the 90%
conﬁdence level upper limit on µ. This method, which
we’ll call the “Poisson” method, is the “naive” method
mentioned in the Introduction. Because of the discreet

4

1

0.95

0.9

Total Expected Number of Events

10

2

10

FIG. 2: Plot of ¯pMax(.9, µ), the value of pMax for which the
90% conﬁdence level is reached, as a function of the total
number of events µ expected in the experimental range.

nature of N , the Poisson method does not have correct
coverage; for most values of the true µ, even in the ab-
sence of unknown background the Poisson method gives
a higher upper limit for a “90% conﬁdence level” than
is needed for the method to have a 90% probability of
containing the true µ. The methods introduced in this
paper do have correct coverage in the absence of unknown
background.

Let us now consider arbitrary intervals within the ex-
perimental range.
If pn, the calculated probability of
there being more events than were found in the inter-
val, is too large, then the cross section used in the cal-
culation must have been too large. For a given cross
section, ﬁnd the interval that excludes the cross section
most strongly; i.e., ﬁnd the interval that gives the largest
calculated probability of there being more events in the
interval than were actually observed. If that probability
is greater than would be expected in 90% of all random
experiments with that given cross section, then the as-
sumed cross section can be rejected as being too large
with 90% conﬁdence level.

Consider all possible intervals within the range of the
measurement. QMax is pMax, the maximum over the pn
for all possible intervals. If random experiments for the
same given cross section would give a smaller pMax 90%
of the time, then the cross section is rejected as too high
with 90% conﬁdence level. The function, ¯pMax(.9, µ), is
deﬁned as the pMax for which the 90% conﬁdence level
is reached at the given µ. A Monte Carlo program was
used to compute a table of the function for µ ≤ 70, and
the function is plotted in Fig. 2.

The threshold µ for n points being relevant in the cal-
culation of the 90% conﬁdence level is, from Eqs. 4 and
5, P (µ, n + 1) = ¯pMax(.9, µ). Table I shows approximate
values of the threshold µ for each n from 0 to 44. The
third digit of µ does not really deserve to be trusted since
¯pMax was computed from a Monte Carlo generated table.
As an example of usage of this table, if you are evalu-
ating pMax for a 90% conﬁdence level calculation with
µ = 25.0, then you need not consider intervals with more
than 12 events.

It was claimed that the value of ¯QMax(.9, µ) spurts up-

TABLE I: Threshold µ below which intervals with ≥ n events
need not be considered when computing pmax for the 90%
conﬁdence level.

5.156

µ(n) µ(n+1) µ(n+2) µ(n+3) µ(n+4)
n
0
9.661 11.599
7.584
2.303
5 13.427 15.193 16.900 18.559 20.176
10 21.771 23.355 24.880 26.419 27.922
15 29.428 30.891 32.359 33.808 35.251
20 36.701 38.100 39.519 40.913 42.317
25 43.700 45.091 46.465 47.827 49.193
30 50.561 51.902 53.255 54.589 55.926
35 57.264 58.603 59.920 61.237 62.549
40 63.868 65.179 66.478 67.791 69.080

ward when µ crosses a threshold where intervals with
more points can contribute to QMax. Notice the irregu-
larity in the curve of Fig. 2 just after µ = 5.156, where
n = 1 ﬁrst begins to contribute. Between µ = 2.3026 and
µ = 5.156, Eqs. 3 and 5 give

¯pMax(.9, µ) = p0(x0(.9, µ)) = 1 − e

−x0(.9,µ),

(6)

but after µ = 5.156, ¯pMax shoots above this value. The
smaller irregularity above µ = 7.584, where n = 2 begins
to contribute, is barely visible.

B. Conﬁdence Level For Intervals With ≤ n Events

Let us now turn to the second of the two opti-
mum interval methods. For random experiments with
a given cross section and no unknown background, de-
ﬁne Cn(x, µ) as the probability that all intervals with
≤ n events have a computed expectation value of the
number of events that is less than x. For example, the
n = 0 case is given by Eq. 2. The larger x is, the larger is
Cn(x, µ). For the actual experiment, the quantity used to
test whether, for a particular interval, the assumed cross
section seems too large is Qn(x, µ) = Cn(x, µ), where n
is the actual number of events in the interval, x is the
expected number of events in the interval, and µ is the
expected number of events in the entire range of the ex-
periment. The bigger Cn is, the stronger is our motive
for believing the assumed cross section is too large for
consistency with the data. We could pick a particular
value of n, with choice of the interval such as to max-
imize x for the given n, in which case Cn(x, µ) is the
conﬁdence level to which the cross section is excluded as
being too high. But we don’t want to risk biasing our
result by giving ourselves the freedom to choose n; so se-
lect as a rule that n is chosen to give the maximum Cn,
CMax. QMax is CMax, the maximum over all intervals of
Cn(x, µ). If 90% of all random experiments would get a
smaller CMax than was observed, then the assumed cross
section should be rejected with 90% conﬁdence.

With the help of a Monte Carlo program, Cn(x, µ) has
been tabulated. A Fortran routine interpolates the table
to compute Cn(x, µ) when n, x, and µ are within the

5

0.975

0.95

0.925

0.9

Total Expected Number of Events

10

2

10

FIG. 3: Plot of ¯CMax(.9, µ), the value of CMax for which the
90% conﬁdence level is reached, as a function of the total
number of events µ expected in the experimental range.

TABLE II: Threshold µ for which intervals with ≥ n events
need not be considered when computing CMax.

7.491

3.890

µ(n) µ(n+1) µ(n+2) µ(n+3) µ(n+4)
n
0
9.059
5.800
2.303
5 10.548 12.009 13.433 14.824 16.196
10 17.540 18.891 20.208 21.520 22.821
15 24.119 25.400 26.669 27.926 29.197
20 30.457 31.690 32.972 34.203 35.422
25 36.632 37.849 39.108 40.333 41.546
30 42.768 43.978 45.164 46.351 47.544
35 48.734 49.944 51.139 52.314 53.488

tabulated range. The routine applies when 0 < µ < 54.5
and when 0 ≤ n ≤ 50.

The function, ¯CMax(.9, µ), is deﬁned as the value of
CMax for which the 90% conﬁdence level is reached at
the given µ. It has been computed by Monte Carlo for
µ < 54.5. The result is shown in Fig. 3.

If one considers all intervals with ≤ n events, then
the largest expected number of events is less than µ if
and only if there are more than n events in the entire
experimental range. Thus Cn(µ, µ) is the probability of
> n events in the entire experimental range: Cn(µ, µ) =
P (µ, n + 1) (see Eq. 5).

As for the case of pMax, for each n there are thresh-
olds in µ where intervals with n events ﬁrst need to be
included when trying to ﬁnd CMax in a calculation of
the 90% conﬁdence level. Table II shows those thresh-
olds, which according to Eq. 4 occur when CMax(.9, µ) =
Cn(µ, µ) = P (µ, n + 1). It turns out that for both op-
timum interval methods, the thresholds where intervals
with n events need to be included in the computation of
QMax are when QMax(C, µ) = P (µ, n + 1). It is easy to
see many rapid increases in ¯CMax(.9, µ) of Fig. 3 when
thresholds given in table II are crossed.

IV. COMPARISONS OF THE METHODS

Two comparisons of the eﬀectiveness of the methods
were performed:
tests “(a)” and “(b)”. For test (a),
500, 000 zero-background Monte Carlo experiments were

6

0

10

20

30

40

10

30
Total Expected Number of Events

20

0.04

0.02

s
e
k
a
t
s
i
M

0

0

(a)

(b)

3

2

4

3

2

0

10

20

30

Total Expected Number of Events

FIG. 4: σMed/σTrue, the typical factor by which the upper
limit cross section exceeds the true cross section, when C0 is
used (dotted lines), when pMax is used (dash-dotted lines),
when CMax is used (dashed lines), and when the Poisson
method is used (solid lines). These ratios are a function of
µ, the total number of events expected from the true cross
section in the entire experimental range. The upper ﬁgure
(a) is when there is no background, and the lower ﬁgure (b)
is when there is just as much unknown background as there
is signal, but the background is concentrated in a part of the
experimental range that contains only half the total signal.

generated for each of 40 assumed cross sections. C0,
pMax, CMax, and the Poisson method were used to ﬁnd
the 90% conﬁdence level upper limits on the cross sec-
tion. For a given true cross section, σTrue, there is a cer-
tain median value, σMed, that is exceeded exactly 50% of
the time by the computed upper limit. Fig. 4(a) shows
σMed/σTrue as a function of µ. The dotted curve used C0
to determine the upper limit, the dash-dotted curve used
pMax, the dashed one used CMax, and the solid, jagged,
curve used the Poisson method. The Poisson method
gives a jagged curve because of the discrete nature of the
variable used to calculate the upper limit, the total num-
ber of detected events. For any cross section shape, when
there is no background, CMax gives a stronger limit than
pMax in most random experiments, and both are stronger
than C0. Even without background, for some values of
the true µ, CMax gives a stronger (lower) upper limit than
the Poisson method. This happens because the discrete
nature of the Poisson method causes it to have greater
than 90% coverage.

Test (b) was similar to test (a), but the Monte Carlo
program simulated a background unknown to the exper-
imenters. The total experimental region was split into a
high part and a low part, with background only in the
low part. Half the expected signal was placed in the low

FIG. 5: Fraction of cases for test (b) (see text) in which the
true cross section was higher than the upper limit on the cross
section computed using C0 (dotted), pMax (dash-dotted) and
CMax (dashed).

part, where the simulated background was twice the ex-
pected signal. For this case, the two lowest curves are
almost exactly on top of each other; Fig. 4(b) shows that
CMax and pMax get equally strong upper limits. C0 pro-
duces a weaker limit, and the Poisson method is weakest
of all.

From the deﬁnition of the 90% conﬁdence level upper
limit, test (a) results in an upper limit that is lower than
the true value exactly 10% of the time; i.e., all methods
except the Poisson make a mistake 10% of the time (the
discrete nature of the Poisson distribution results in its
making mistakes less than 10% of the time). But for test
(b), the unknown background raises the upper limit; so
all methods make a mistake less than 10% of the time.
Figure 5 shows the fraction of mistakes with test (b) us-
ing C0 (dotted), pMax (dash-dotted) and CMax (dashed).
Although CMax and pMax give equally strong upper lim-
its for test (b), CMax makes fewer mistakes. C0 makes
the most mistakes of the tested methods. Not shown is
the Poisson method; because its upper limit is so high, it
makes almost no mistakes.

V. CONCLUSIONS

Judging from the tests shown in Fig. 4 and Fig. 5,
the best of the methods discussed here is the optimum
interval method, with CMax. This method is useful for
experiments with small numbers of events when it is not
possible to make an accurate model of the background,
and it can also be used when experimenters want to show
an especially reliable upper limit that doesn’t depend
on trusting their ability to model the background. Be-
cause the optimum interval method automatically avoids
parts of the data range in which there are large back-
grounds, it is relatively insensitive to placement of the
cuts limiting the experimental range. Because the op-
timum interval method doesn’t use binned data, it can-
not be biased by how experimenters choose to bin their
data. Unlike Bayesian upper limits with a uniform prior,
the result of the optimum interval method is unchanged

when a change in variable is made. The optimum interval
method produces a true, though possibly conservative,
classical (frequentist) conﬁdence interval; at least 90% of
the time the method is used its 90% conﬁdence level up-
per limit will be correct, barring experimental systematic
errors.

Tables generated by Monte Carlo programs, along with
Fortran subroutines that interpolate the tables to eval-
uate the functions described in this paper, have been
placed on the web [4].

Acknowledgments

Thanks are due to Richard Schnee for useful discus-
sions, for suggesting improvements of this paper, and for
being the ﬁrst to apply its methods to an experimental
analysis.

This work has been supported by a grant from the

U.S. Department of Energy No. DE-FG03-91ER40618.

*

APPENDIX A: DERIVATION OF THE
EQUATION FOR C0

In order to derive Eq. 2, let us ﬁrst ﬁnd the probability
that the maximum gap size is less than x when there
are exactly n events, then get C0 by averaging n over a
Poisson distribution.

We assume n events are distributed in some variable,
y, according to a density distribution that integrates to
a total of µ expected events, and deﬁne P (x; n, µ) to be
the probability that the maximum gap size is less than
x. To see that this function is independent of the shape
of the density distribution, let us deﬁne z(y) to be the
number of events expected between the beginning of the
range and the particular value of y. This number is sim-
ply an integral of the expected density distribution. If we
express the data in terms of z, instead of y, the range of
z runs from 0 to µ, gap size between events is the same in
the two coordinate systems, but now is identical to coor-
dinate z distance between the events, and the expected
density distribution in this new coordinate is uniform.
Thus P (x; n, µ) is the probability that the maximum co-
ordinate distance between adjacent events is less than
x given that there are exactly n events distributed ran-
domly, independently, and uniformly between z = 0 and
z = µ. This way of characterizing P is independent of
the shape of the original density distribution expressed in
the old coordinate; hence the function P depends only on
x, n, and µ, but not on the shape of the original density
distribution.

The problem of ﬁnding P (x; n, µ) can be simpliﬁed by
making a coordinate change w(z) = z/µ. The new co-
ordinate runs from 0 to 1 instead of 0 to µ. With this
coordinate change, any set of n events with x equal to the
maximum gap between adjacent events becomes a set of

7

n events, still uniformly distributed, but with maximum
new coordinate distance between adjacent events equal
to x/µ. It follows that P (x/µ; n, 1) = P (x; n, µ), and we
need only solve the problem of ﬁnding P for µ = 1 to get
the solution for any value of µ. When µ is understood to
be 1, it will be dropped, and we will write P (x; n) to mean
the same as P (x; n, 1). The problem has been reduced
to one in which n points have been scattered randomly
in independent uniform probability distributions on the
interval (0, 1). We want to ﬁnd the probability that the
maximum empty interval has length less than x. We do
this with the help of a recursion relation that allows one
to compute P (x; n + 1) from knowledge of P (x; n).

P (x; n + 1) is the integral over t < x of the probability
that the lowest event is between t and t + dt and that the
rest of the n events in the remaining 1-t range has no gap
greater than x. The probability that the lowest event is
between t and t + dt is (number of ways of choosing one
particular event of the n + 1 events) times (probability
that the particular event will be between t and t + dt)
times (probability that each of the other n events will
be greater than t). We get a factor in the integrand
(n + 1) × dt × (1 − t)n. The other factor in the integrand
is the probability that there is no gap greater than x for
the remaining n events: P (x; n, 1 − t) = P (x/(1 − t); n).
The recursion relation for 0 < x < 1 is
x

P (x; n + 1) =

dt (n + 1)(1 − t)nP

x
1 − t

(cid:18)

; n

. (A1)

(cid:19)

Z

0

It is convenient to distinguish between various pieces
of the x range between 0 and µ, for it will turn out that
P (x; n, µ) takes on diﬀerent forms in diﬀerent pieces of
that range. If x is in the range µ/(m + 1) < x < µ/m,
we say P (x; n, µ) = Pm(x; n, µ), and we say x is in the
m’th range. Let us again restrict ourselves to µ = 1 and
consider Eq. A1.
If x is in the m’th range and, as in
Eq. A1, 0 < t < x, then x/(1 − t) is in either range m or
range (m − 1). The boundary between these two ranges
is at x/(1 − t) = 1/m; so t = 1 − mx. For m > 0 Eq. A1
becomes

Pm(x; n + 1)
n + 1

=

+

dt (1 − t)nPm

1−mx
0
(cid:16)
R
x
1−mx dt (1 − t)nPm−1
R

(cid:16)

x
1−t ; n

(cid:17)
x
1−t ; n

.

(cid:17)

(A2)

The appearance of m − 1 brings up the question of what
happens if m = 0. Let us interpret the m = 0 range to
be the one with 1/1 < x < 1/0 = ∞. Since the empty
space between events is certainly less than the length of
the whole interval, P0(x; n) = 1.

For m ≥ 0 it can be shown that

m

Pm(x; n) =

n+1
k
(cid:0)
(cid:1)
In this equation, we interpret (n
k ) as

(−1)k

Xk=0

(1 − kx)n.

(A3)

(n
k ) =

n!
k!(n − k)!

≡

Γ(n + 1)
Γ(k + 1)Γ(n − k + 1)

.

The gamma function is meaningful when analytically
continued, in which case (n
k ) is zero if k is an integer
that is less than zero or greater than n. In P (x; 0), the
maximum (and only) gap is always 1; so P0(x; 0) = 1 for
x > 1, while for m > 0, when 0 < x < 1, Pm(x; 0) = 0.
Since Eq. A3 is easily veriﬁed to be correct for all m ≥ 0
when n = 0, one may use induction with Eq. A2 to prove
Eq. A3 for all other n > 0. The simple but somewhat
tedious manipulations of sums will not be given here, ex-
cept for a useful identity in the induction step:

(n
k ) +

=

n
k−1
(cid:0)

(cid:1)

.

n+1
k
(cid:0)

(cid:1)

It follows from Eq. A3 that

8

Let us now compute C0, the probability for the max-
imum empty space between events in (0, µ) being less
than x given only that events are thrown according to
a uniform unit density. Average Eq. A4 over a Poisson
distribution with mean µ to get

C0 =

m

∞

Xk=0

Xn=0

e

−µ µn
n!

(−1)k

(1 − kx/µ)n,

(A5)

n+1
k
(cid:0)

(cid:1)

Pm(x; n, µ) =

(−1)k

(1 − kx/µ)n.

(A4)

m

Xk=0

n+1
k
(cid:0)

(cid:1)

which can be summed over n (again the manipulations
will not be shown here) to give Eq. 2.

[1] G. J. Feldman and R. D. Cousins, Phys. Rev. D 57, 3873

(1998).

[2] D. Abrams, et al., paper in preparation.

[3] http://wwwinfo.cern.ch/asdoc/shortwrupsdir/index.html
[4] http://www.slac.stanford.edu/∼yellin/ULsoftware.html

