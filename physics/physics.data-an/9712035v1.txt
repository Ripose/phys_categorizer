7
9
9
1
 
c
e
D
 
7
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
5
3
0
2
1
7
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Characteristic functions and process
identiﬁcation by neural networks

Joaquim A. Dente
Laborat´orio de Mecatr´onica, Departamento de Engenharia
Electrot´ecnica e Computadores, Instituto Superior T´ecnico,
Av. Rovisco Pais, 1096 Lisboa Codex, Portugal

Rui Vilela Mendes∗
Grupo de F´ısica-Matem´atica, Complexo II, Univ. de Lisboa,
Av. Gama Pinto 2, 1699 Lisboa Codex, Portugal
and
Centre de Physique Th´eorique, CNRS, Luminy,
Case 907, F 13288 Marseille Cedex 9, France

Abstract

Principal component analysis (PCA) algorithms use neural net-
works to extract the eigenvectors of the correlation matrix from the
data. However, if the process is non-Gaussian, PCA algorithms or
their higher order generalisations provide only incomplete or mislead-
ing information on the statistical properties of the data. To handle
such situations we propose neural network algorithms, with an hybrid
(supervised and unsupervised) learning scheme, which constructs the
characteristic function of the probability distribution and the tran-
sition functions of the stochastic process.
Illustrative examples are
presented, which include Cauchy and L´evy-type processes.

∗phone: 351 1 7950790, fax: 351 1 7954288, e-mail: vilela@alf4.cii.fc.ul.pt

1

1 Introduction

Let xi denote the output of node i in a neural network. Hebbian learning
(Hebb 1949) is a type of unsupervised learning where the neural network
connection strengths Wij are reinforced whenever the products xixj are large.
If Q is the correlation matrix

Qij = hxixji

(1)

and the Hebbian learning law is local, all the lines of the connection ma-
trix Wij will converge to the eigenvector of Q with the largest eigenvalue.
To obtain other eigenvector directions requires non-local laws (Sanger 1989,
Oja 1989, 1992, Dente and Vilela Mendes 1996). These principal component
analysis (PCA) algorithms ﬁnd the characteristic directions of the correlation
matrix Q. If the data has zero mean (hxii = 0) they are the orthogonal direc-
tions along which the data has maximum variance. If the data is Gaussian in
each channel, it is distributed as a hyperellipsoid and the correlation matrix
Q already contains all information about the statistical properties. This is
because higher order moments of the data may be obtained from the second
order moments. However, if the data is non-Gaussian, the PCA analysis is
not complete and higher order correlations are needed to characterise the sta-
tistical properties. This led some authors (Softy and Kammen 1991, Taylor
and Coombes 1993) to propose networks with higher order neurons to obtain
the higher order statistical correlations of the data. An higher order neuron
is one that is capable of accepting, in each of its input lines, data from two
or more channels at once. There is then a set of adjustable strengths Wij ,
Wij1j2 , · · · , Wij1···jn , n being the order of the neuron. Networks with higher
order neurons have interesting applications, for example in ﬁtting data to
a high-dimensional hypersurface. However there is a basic weakness in the
characterisation of the statistical properties of non-Gaussian data by higher
order moments. Existence of the moments of a distribution function depends
on the behaviour of this function at inﬁnity and it frequently happens that a
distribution has moments up to a certain order, but no higher ones. A well-
behaved probability distribution might even have no moments of order higher
than one (the mean). In addition a sequence of moments does not necessarily
determine a probability distribution function uniquely (Lukacs 1970). Two
diﬀerent distributions may have the same set of moments. Therefore, for

2

non-Gaussian data, the PCA algorithms or higher order generalisations may
lead to misleading results.

As an example consider the two-dimensional signal shown in Fig.1. Fig.
2 shows the evolution of the connection strengths W11 and W12 when this
signal is passed through a typical PCA algorithm. Large oscillations appear
and ﬁnally the algorithm overﬂows. Smaller learning rates do not introduce
qualitative modiﬁcations in this evolution. The values may at times appear
to stabilise, but large spikes do occur. The reason for this behaviour is that
the seemingly harmless data in Fig.1 is generated by a linear combination of
a Gaussian with the following distribution

p (x) = K

2 + x2

− 1
2

(cid:16)

(cid:17)

which has ﬁrst moment, but no moments of higher order.

To be concerned with non-Gaussian processes is not a pure academic
exercise because, in many applications, adequate tools are needed to analyse
such processes. For example, processes without higher order moments, in
particular those associated with L´evy statistics, are prominent in complex
processes such as relaxation in glassy materials, chaotic phase diﬀusion in
Josephson junctions and turbulent diﬀusion (Shlesinger et al 1993, Zumofen
and Klafter 1993, 1994).

Moments of an arbitrary probability distribution may not exist. However,
because every bounded and measurable function is integrable with respect to
any distribution, the existence of the characteristic function f (α) is always
assured (Lukacs 1970).

f (α) =

eiαxdF (x) =

Z

eiαx
D

E

(2)

where α and x are N-dimensional vectors, x is the data vector and F (x) its
distribution function.

The characteristic function is a compact and complete characterisation of
the probability distribution of the signal. If, in addition, one wishes to de-
scribe the time correlations of the stochastic process x(t), the corresponding
quantity is the characteristic functional (Hida 1980)

F (ξ) =

ei(x,ξ)dµ (x)

(3)

Z

3

where ξ (t) is a smooth function and the scalar product is

(x, ξ) =

dtx (t) ξ (t)

Z

(4)

where µ (x) is the probability measure over the sample paths of the process.
In the following we develop an algorithm to compute the characteristic
function from the data, by a learning process. The main idea is that in
the end of the learning process we should have a neural network which is a
representation of the characteristic function. This network is then available
to provide all the required information on the probability distribution of the
data being analysed. To obtain full information on the stochastic process,
a similar algorithm might be used to construct the characteristic functional.
However this turns out to be computationally very demanding. Instead we
develop a network to learn the transition function and from this the process
may be characterised.

2 Learning the characteristic function

Suppose we want to learn the characteristic function f (α) (Eq. 2) of a one-
dimensional signal x(t) in a domain α ∈ [α0, αN ] . The α-domain is divided
into N intervals by a sequence of values α0 α1 α2 · · · αN and a network is
constructed with N+1 intermediate layer nodes and an output node (Fig.3).
The learning parameters in the network are the connection strengths W0i
and the node parameters θi. The existence of the node parameter means that
the output of a node in the intermediate layer is θiχi (α), χi being a non-
linear function. The use of both connection strengths and node parameters in
neural networks makes them equivalent to a wide range of other connectionist
systems (Doyne Farmer 1990) and improves their performance in standard
applications (Dente and Vilela Mendes 1996). The learning laws for the
network of Fig.3 are:

θi (t + 1) = θi (t) + γ (cos αix (t) − θi (t))
W0i (t + 1) = W0i (t) +

η

j [θj (t) −

k W0k (t) χk (αj) θk (t)] θi (t) χi (αj)

(5)

γ, η > 0 . The intermediate layer nodes are equipped with a radial basis

P

P

4

function

χi (α) =

e−(α−αi)2/2σ2
k=0 e−(α−αk)2/2σ2
N

k

i

(6)

where in general we use σi = σ for all i. The output is a simple additive
node.

P

The learning constant γ should be suﬃciently small to insure that the
learning time is much smaller than the characteristic times of the data x(t).
If this condition is satisﬁed each node parameter θi tends to hcos αixi, the
real part of the characteristic function f (α) for α = αi.

The W0i learning law was chosen to minimise the error function

f (W ) =

θj −

W0kχk (αj) θk

(7)

1
2

Xj  

Xk

2

!

One sees that the learning scheme is an hybrid one, in the sense that the node
parameter θi learns, in an unsupervised way, (the real part of) the character-
istic function f (αi) and then, by a supervised learning scheme, the W0i’s are
adjusted to reproduce the θi value in the output whenever the input is αi.
Through the learning law (5) each node parameter θi converges to hcos αixi
and the interpolating nature of the radial basis functions guarantees that, af-
ter training, the network will approximate the real part of the characteristic
function for any α in the domain [α0, αN ].

A similar network is constructed for the imaginary part of the character-

istic function, where now

θi (t + 1) = θi (t) + γ (sin αix (t) − θi (t))

(8)

For higher dimensional data the scheme is similar. The number of re-
quired nodes is N d for a d-dimensional data vector x (t). For example for the
2-dimensional data of Fig.1 we have used a set of N 2 nodes (Fig.4)

Each node in the square lattice has two inputs for the two components
α1 and α2 of the vector argument of f (−→α ). The learning laws are, as before

θ(ij) (t + 1) = θ(ij) (t) + γ

cos −−→α(ij)
W0(ij) (t + 1) = W0(ij) (t) +
(cid:16)
(mn) W0(mn) (t) χ(mn)

θ(mn) (t)

−−→
x (t) − θ(ij) (t)

(cid:17)
θ(ij) (t) χ(ij)

−−→α(kl)
(cid:17)

(cid:16)

i

−−→α(kl)

(cid:16)

(cid:17)(9)

η

(kl)

θ(kl) (t) −

P

h

P

5

The pair (ij) denotes the position of the node in the square lattice and the
radial basis function is

χ(ij) (α) =

−(−→α −−−→α(ij))2
e

/2σ2

(ij)

−|−→α −−−→α(kl)|/2σ2

(kl)

(kl) e

(10)

P

Two networks are used, one for the real part of the characteristic function,
−−→
another for the imaginary part with, in Eqs.(9), cos −−→α(ij)
x (t) replaced by
sin −−→α(ij)

−−→
x (t).

Figs.5a-b shows the values computed by our algorithm for the real and
imaginary parts of the characteristic function corresponding to the two-
dimensional signal in Fig.1. On the left is a plot of the exact characteristic
In this case
function and on the right the values learned by the network.
we show only the mesh corresponding to the θi values. One obtains a 2.0%
accuracy for the real part and 4.5% accuracy for the imaginary part.

The convergence of the learning process is fast and the approximation is
reasonably good. Notice in particular the slope discontinuity at the origin
which reveals the non-existence of a second moment. The parameters used
for the learning laws in this example were γ=0.00036, η=1.8, σ=0.25. The
number of points in the training set is 25000.

For a second example the data was generated by a Weierstrass random

walk with probability distribution

p(x) =

δx,bj + δx,−bj

(11)

∞

1
6

Xj=0 (cid:18)

j

2
3 (cid:19)

(cid:16)

(cid:17)

and b=1.31, which is a process of the L´evy ﬂight type. The character-
istic function, obtained by the network, is shown in Fig. 6. Taking the
log (− log)of the network output one obtains the scaling exponent 1.49 near
α=0, close to the expected fractal dimension of the random walk path (1.5).
The parameters used for the learning laws in this example were γ=0.0005,
η=1.75, σ=0.1732. The number of points in the training set is 80000.

These examples test the algorithm as a process identiﬁer, in the sense
that, after the learning process, the network is a dynamical representation of
the characteristic function and may be used to perform all kinds of analysis
of the statistics of the data. There are other ways to obtain the characteristic
function of a probability distribution, which may be found in the statistical

6

inference literature (Prakasa Rao 1987). Our purpose in developing neural-
like algorithms for this purpose was both to have a device that, after learning,
is quick to evaluate and, at the same time, adjusts itself easily, through
continuous learning, to changing statistics. As the PCA algorithms that
extract the full correlation matrix, our neural algorithm laws are also non-
local. As a computation algorithm this is not a serious issue, but for hardware
implementations it might raise some problems.

3 Identiﬁcation of stochastic processes

As we have stated before the full characterisation of the time structure of a
stochastic process requires the knowledge of its characteristic functional (Eq.
3) for a dense set of functions ξ(t).

To construct an approximation to the characteristic functional we might
discretize the time and the inner product in the exponential becomes a sum
over the process sampled at a sequence of times.

F (ξ) =

k x(tk)ξ(tk)

ei
D

(12)

E

P
The problem would then be reduced to the construction of a multidimensional
characteristic function as in Section 2. In practice we would have to limit
the time-depth of the functional to a maximum of T time steps, T ∆t being
the maximum time-delay over which time correlations may be obtained. If
N is the number of diﬀerent x values for each k, the algorithm developed in
Section 2 requires N T nodes in the intermediate layer and, for any reasonably
large T , this method becomes computationally explosive.

An alternative and computationally simpler method consist in, restricting
ourselves to Markov processes, to characterise the process by the construc-
tion of networks to represent the transition function for ﬁxed time intervals.
From these networks the diﬀerential Chapman-Kolmogorov equation may
then be reconstructed. Let x(t) be a one dimension Markov process and
p (x2, t + ∆t|x1, t) its transition function, that is, the conditional probability
of ﬁnding the value x2 at time t + ∆t given x1 at time t. Assume further
that the process is stationary

p (x2, t + ∆t|x1, t) = p (x2, ∆t|x1, t)

(13)

7

The network that conﬁgures itself to represent this function is similar to
the one we used for the 2-dimensional characteristic function. It is sketched
It has a set of N 2 intermediate layer nodes with node pa-
in Fig.s 7a-b.
rameters, the node with coordinates −→x (ij) corresponding to the arguments
(x2(ij) = x0 + i∆x, x1(ij) = x0 + j∆x) in the transition function. The do-
main of both arguments is (x0, x0 + N∆x). For each pair (x2 = x(t + ∆t), x1 = x(t))
in the data set, the node parameters that are updated are those in the 4
columns containing the nearest neighbours of the point −→x = (x2, x1) (Fig.
7b). The learning rule is

Sj(t)θ(ij)(t) +

θ(ij)(t + 1) =

η(ij)(−→x ) exp
(kl) η(kl)(−→x ) exp
(cid:16)
Sj(t + 1)

(cid:16)

P

−|−→x −−→x (ij)|2

/α

−|−→x −−→x (kl)|2
(cid:17)
/α

(14)

(cid:17)

η(ij)(−→x ) exp

−

−→x − −→x (ij)

2

/α

Xi

Sj(t + 1) = Sj(t) +

(cid:18)
(kl) η(kl)(−→x ) exp
where η(ij)(−→x ) = 1 if (ij) is one of the nearest neighbours of the data point
and zero otherwise. α is a neighbourhood smoothing factor. Sj(t) is a column
normalisation factor. In the limit of large learning times the node parameters
approach the transition function

−→x − −→x (kl)

(cid:12)
(cid:12)
−
(cid:12)
(cid:18)

(cid:19)
/α

(15)

P

(cid:19)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

2

θ(ij) → p (x0 + i∆x, ∆t|x0 + j∆x)

(16)

As for the networks in Section 2, the intermediate layer nodes are equipped
with a radial basis function (Eq. 10) and the connection strengths in the
output additive node have a learning law identical to the second equation
in (9). The role of this part of the network is, as before, to obtain an
interpolating eﬀect.

What the algorithm of Eqs.(14) and (15) does is to compute recursively
the average number of transitions between points in the conﬁguration space
of the process. The spatial smoothing eﬀect of the algorithm automatically
insures a good representation of a continuous function from a ﬁnite data set.
Furthermore its recursive nature would be appropriate for the case of drifting
statistics.

For a stationary process, once the learning process has been achieved and
if ∆t is chosen to be suﬃciently small, the network itself may be used to

8

simulate the stationary Markov process. A complete characterisation of the
process may also be obtained by training a few similar networks for diﬀerent
(small) ∆t values and computing the coeﬃcient functions in the diﬀerential
Chapman-Kolmogorov equation (Gardiner 1983).

∂tp

′

−→z , t
(cid:16)
+
W (−→z |−→x , t
n

P

ij

+

d−→x

R

′

i

∂
∂zi

|−→y , t
Ai(−→z , t
)p(−→z , t
= −
|−→y , t)
)p(−→z , t
Bij(−→z , t
∂2
(cid:17)
(cid:16)
P
∂zi∂zj
′
′
|−→y , t) − W (−→x |−→z , t
)p(−→x , t
(cid:16)

′

′

′

′

|−→y , t)

(cid:17)
|−→y , t)

)p(−→z , t
(cid:17)

′

(17)

o

The coeﬃcients are obtained from the transition probabilities, noticing that
for all ǫ > 0

p(−→x , t + ∆t|−→z , t) = W (−→x |−→z , t) f or |−→x − −→z | ≥ ǫ

(18)

lim
∆t→0

dx(xi − zi)p(−→x , t + ∆t|−→z , t) = Ai(−→z , t) + O(ǫ)

(19)

lim
∆t→0

1
∆t Z|−→x −−→z |<ǫ

lim
∆t→0

1
∆t Z|−→x −−→z |<ǫ

dx(xi − zi)(xj − zj)p(−→x , t + ∆t|−→z , t) = Bij(−→z , t) + O(ǫ)

(20)
W (−→x |−→z , t) is the jumping kernel, Ai(−→z , t) the drift and Bij(−→z , t) the diﬀu-
sion coeﬃcient.

As an example we have considered a Markov process with jumping, drift
and diﬀusion. A typical sample path is shown in Fig. 8. Three networks
were trained on this process, to learn the transition function for t = ∆t, 2∆t
and 3∆t (∆t = 0.374ms). Fig. 9 shows the transition function for t = ∆t
and 3∆t. Fig. 10 shows two sections of the transition function for x2 = 0,
that is, p(x, ∆t|0, 0) and p(x, 3∆t|0, 0).

The networks were then used to extract the coeﬃcient functions A(x, t),
B(x, t) and W (x|z, t). To ﬁnd the drift A(x, t) we use Eq. (19). Fig. 11
shows the computed drift function and a least square linear ﬁt. Also shown
is a comparison with the exact drift function of the process.

To obtain the diﬀusion coeﬃcient B(x, t) we use (20). Fig. 12 shows the
diﬀusion coeﬃcient for diﬀerent ∆t values. ∆t is the smallest time step used

9

in the process simulation. Therefore B(x, t) = 2.6 is our estimate for the
diﬀusion coeﬃcient. In this case, because the diﬀusion coeﬃcient is found to
be a constant, the value of the jumping kernel W (x|z, t) is easily obtained
by integration around the local maxima xm of p(x, ∆t|z) with |x − z| > 0.2.

W =

1
∆t Z

xm+δ

xm−δ

p(x, ∆t|z)dx

(21)

with δ = 0.2. We conclude W (x|z) ∼= 300δ(|x − z| − 0.5). The parameters
used for the learning laws in this example were η=0.48, α=0.00021. The
number of points in the training set is 1000000.

REFERENCES
Dente, J. A. and Vilela Mendes, R. (1996), Unsupervised learning in
general connectionist systems, Network: Computation in Neural Systems 7,
123

Doyne Farmer, J. (1990), A Rosetta stone for connectionism, Physica

D42, 153

Gardiner, C. W. (1983), Handbook of stochastic methods (Springer, Berlin)
Hebb, D. O. (1949), The organisation of behaviour (Wiley, New York)
Hida, T. (1980), Brownian motion (Springer, Berlin)
Lukacs, E. (1970), Characteristic functions (Griﬃn, London)
Oja, E. (1989), Neural networks, principal components and subspaces Int.

J. of Neural Systems 1, 61

Oja, E. (1992), Principal components, minor components and linear neu-

ral networks, Neural Networks 5, 927

Prakasa Rao, B. L. S. (1987), Asymptotic theory of statistical inference

(Wiley, New York)

ics, Nature 363, 31

Sanger, T. D. (1989), Optimal unsupervised learning in a single-layer

linear feedforward neural network, Neural Networks 2, 459

Shlesinger, M. F., Zaslavski, G. M. and Klafter, J. (1993), Strange kinet-

Softky, W. R. and Kammen, D. M. (1991), Correlations in high dimen-
sional or asymmetric data sets: Hebbian neuronal processing, Neural Net-
works 4, 337

Taylor, J. G. and Coombes, S. (1993), Learning higher order correlations,

Neural Networks 6, 423

Zumofen, G. and Klafter, J. (1993), Scale-invariant motion in intermittent

chaotic systems, Physical Review E47, 851

10

Zumofen, G. and Klafter, J. (1994), Random walks in the standard map,

Europhysics Letters 25, 565

11

Fig.1 - A two-dimensional test signal

4

3

2

1

0

-1

-2

-3

+

+

+

+

+
+
+

+
+
+
+

+

+
+

+

+
+
+

+
+
+
+
+

+

+
+
+
+
+
+

+
+
+
+

+

+
+

+
+

+

+

+
+
+
+

+
+

+

+

+
+

+

+

+

+

+

+
+

+
+

+

+

+

+

+

+

+

+

+

+

+

+

+

+

+

+
+

+
+

+
+

+
+

+
+

+
+
+
+

+
+
+
+

+
+
+
+
+

+
+
+
+
+

+
+
+
+
+
+

+
+
+
+
+
+
+
+
+
+
+
+
+
+
++
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
++
+
+
+
+
+
+
+
+
+
+
+
+
++
+
+
+
+ +
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+ +
+
+
+
+
+
+
++
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+ + +
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
++
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
++
+
+
++
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+ +
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+

+
+
+
+
+
+
+
+

+
++
+
+
+
+
+
+
+

+
+
+

+
+
+

+
+

+
+

+
+

+

+

+

+

+

+

+

+

+

+
0

1

+
2

+

+

+

+
+
+
++
+
+
+
+

+

+

+

+

+

+
+

+

+

+

+

+

3

4

-4

-4

-3

-2

-1

-1

0

1

0

1

0

-1

0

1

2

3

4

5

6
x104

6
x104

f (a )

+

W00

W0 N

q

2

W01 W02

q

0

c

0

q

1

c

1

a

q

c

N

N

c

2

. . .

Fig. 3 Network to learn the characteristic function of a scalar process

1

2

3

4

5

Fig.2  -  Evolution  of  the  connection  strengths  W11 and W 12    in  a  PCA

network for the data in Fig.1

r
)

  f (
+
W0(ij)

q
c ( ij)

( ij )

Fig.4 Network to learn the characteristic function of a 2-dimensional signal

a 1

a 2

( )
x t

Fig.5a - Real part of the characteristic function for the data in Fig.1 (left)

and the mesh of q i values (right) obtained by the network.

a
ﬁ
Fig.5b - Imaginary part of the characteristic function for the data in Fig.1
(left) and the mesh of q i values (right) obtained by the network.

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

f(a )

1

0.8

0.6

0.4

0.2

-0.2

-0.4

o

o

o

o

o

o

o

o

o

0

o

o

-1

-0.5

0.5

1

0

a

Fig. 6-a Characteristic function for the Weierstrass random walk (b=1.31)

o o o o o oooooooooooooooooooooooooooooo

o

o

o

o

o

o

o

o

o

o

o

o

1

0

-1

-2

-3

-4

-5

-6

o

o

-4

-2
log(a
Fig.  6-b  log(-log)  of  the  characteristic  function  f(a )  for  the  Weierstrass

-0.5

-2.5

-3.5

-1.5

-1

-3

)

0

random walk (b=1.31)

p( x2, D

t| x1)

+

W0(ij)

q

( ij )

c ( ij)

x.

r
  

x2

= x(t + D

t )

x1 = x(t)

 

(a)

(b)
Fig.  7  (a)  Network  that  learns  the  transition  function  p( x2, D

t| x1)  of  a
stationary Markov process; (b) Nearest neighbours of the data point
r
x = ( x(t + D
  

t), x(t)).

2.5

1.5

0.5

2

1

0

7

6

5

4

3

2

1

-0.5

0.1

0.11

0.12

0.13

0.14

0.15

0.16

0.17

0.18

0.19

0.2

Fig. 8 Typical sample path of a stationary Markov process.

a)

 

b)

Fig. 9 Transition functions obtained for a) t=3D T and b) D T.

a

+

++
+
+
+
+
+
+

+

+
+
+

b

+

+

+
+
+
+
+
+

0.2

+

+

0

+
+
+
+
+

++++++++

+
+
+++
+
+

+
+

++++

++++++++++++++++++++++++++++
0
-0.8

-0.6

+++++++++++++++++++++++

-0.4

-0.2

++++++++
+
+
+
+
+++
+
+

++++++++++++
0.8

0.6

++++
+++++++++++++++++++++++
0.4

Fig. 10 Transition function  p( x, D T|0, 0) a) and  p( x,3D T|0, 0) b).

120

100

80

60

40

20

0
-0.15

100

95

90

85

80

75

70

65

60

55

50
-0.15

 

o

o

o o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o

o
o

o
o

o
o

o
o

o
o o
o

o
o

o
o

o
o

o
o

o
o

o

o
o

o

o
o

o

o

o

o

o

o
o

o
o

o
o

o

o
o

o
o

o
o

o
o

o
o

o
o

o
o

o
o

o
o

o

o

o
o

o

o

o

o

o

o

o

2

1

3

-0.1

-0.05

0

0.05

0.1

0.15

-0.1

-0.05

0

0.05

0.1

0.15

(a)

(b)

Fig. 11 (a) Computed drift function and linear least square fit. (b) Exact
drift function of the process (1), least square linear fits for (2) t=D T
and (3) t=2D T.

o o
*
*

*
o o o
* *
o

o o
* * *

2.5

o o

o o o

o o o
o
* * *

* * * * * *
+ + + + + + + + + + + + + + + +
+

o o

o o
o o

o o o

o o o
o o o
o o o
o o o
o o o
o o o
o o o o
o
o
o
+ + + + + + + + + + +
* * ** * * * * * * * * * * * * * * * * * * * * ** * * * * *
+ + + + + + + + + + + + + +
+ + +
+
+

+ + + + + + + + + +
+ + +

o
o

o
o

o

o o
o o

o o

o o
o o

o o o
o o o

o o
o o o
o

o
o

o

o

o o o

o o

o

o

+
+ + + + + + + + + +
+ + + + + +
+ + + +

+ + + +
* * * * * * * * * * * * * * * *

+ + + +

3

2

1

1.5

0.5

0
-0.15

-0.1

-0.05

0

0.05

0.1

0.15

Fig. 12 Diffusion function for D T (o), 2D T (+) and 3D T (*).

