4
0
0
2
 
b
e
F
 
7
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
5
8
0
2
0
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

FINDING TWO-DIMENSIONAL PEAKS

Z. K. SILAGADZE ∗

Abstract. Two-dimensional generalization of the original peak ﬁnding algorithm suggested
earlier is given. The ideology of the algorithm emerged from the well known quantum mechanical
tunneling property which enables small bodies to penetrate through narrow potential barriers. We
further merge this “quantum” ideology with the philosophy of Particle Swarm Optimization to get the
global optimization algorithm which can be called Quantum Swarm Optimization. The functionality
of the newborn algorithm is tested on some benchmark optimization problems.

Key words. Numerical optimization, Quantum Swarm Optimization

AMS subject classiﬁcations. 65K10, 65C35

1. Introduction. Some time ago we suggested a new algorithm for automatic
photopeak location in gamma-ray spectra from semiconductor and scintillator detec-
tors [1]. The algorithm was inspired by quantum mechanical property of small balls
to penetrate through narrow barriers and ﬁnd their way down to the potential wall
bottom even in the case of irregular potential shape.

In one dimensional case the idea was realized by means of ﬁnite Markov chain and
its invariant distribution [1]. States of this Markov chain correspond to channels of the
original histogram. The only nonzero transition probabilities are those which connect
a given state to its closest left and right neighbor states. Therefore the transition
probability matrix for our Markov chain has the form

0
P21
0

·
0

1
0
P32

0
P23
0

0
0
P34

·
·

·
·

·
·

0
0
0

·
·

P = 






·
·
·
·
0

·
·
·
·
·
·
·
·
1 0

.









As for the transition probabilities, the following expressions were used

(1.1)

with

(1.2)

Pi,i±1 =

Qi,i±1
Qi,i−1 + Qi,i+1

Qi,i±1 =

exp

Ni

Ni±k
−
Ni±k + Ni #

.

"

m

k=1
X

p

The number m is a parameter of the model which mimics the (inverse) mass of the
quantum ball and therefore allows to govern its penetrating ability.

The invariant distribution for the above described Markov chain can be given by

a simple analytic formula [2]

u2 =

u1 , u3 =

P12
P21

P12P23
P32P21

u1 ,

, un =

· · ·

P12P23 · · ·
Pn−1,n
Pn,n−1Pn−1,n−2 · · ·

P21

u1 ,

∗Budker Institute of Nuclear Physics, 630 090, Novosibirsk, Russia

1

where u1 is deﬁned from the normalization condition

ui = 1 .

n

i=1
X

Local maximums in the original spectrum are translated into the very sharp peaks

in the invariant distribution and therefore their location is facilitated.

The algorithm proved helpful in uniformity studies of NaJ(Tl) crystals for the
SND detector [3]. Another application of this “peak ampliﬁer”, to reﬁne the amplitude
ﬁt method in ATLAS Bs-mixing studies, was described in [4]. In this paper we will
try to extend the method also in the two-dimensional case.

2. Two-dimensional generalization. The following two-dimensional general-
n histograms the correspond-
ization seems straightforward. For two-dimensional n
ing Markov chain states will also form a two-dimensional array (i, j). Let u(k)
ij be
a probability for the state (i, j) to be occupied after k-steps of the Markov process.
Then

×

u(k+1)
lm =

Pij;lmu(k)
ij ,

n

i,j=1
X

where Pij;lm is a transition probability from the state (i, j) to the state (l, m). We will
assume that the only nonzero transition probabilities are those which connect a given
state to its closest left, right, up or down neighbor states. Then the generalization of
equations (1.1) and (1.2) is almost obvious. Namely, for the transition probabilities
we will take

Pij;i,j±1 =

Pij;i±1,j =

Qij;i,j±1
Qij;i,j−1 + Qij;i,j+1 + Qij;i−1,j + Qij;i+1,j
Qij;i±1,j
Qij;i,j−1 + Qij;i,j+1 + Qij;i−1,j + Qij;i+1,j

,

,

(2.1)

with

(2.2)

Qij;i±1,j =

Qij;i,j±1 =

m

k

k=1
X
m

l=−k
X
k

k=1
X

l=−k
X

exp

"

Nij

Ni+l,j±k
,
−
Ni+l,j±k + Nij #

exp

p
Ni±k,j+l
.
−
Ni±k,j+l + Nij #

Nij

"

p

We are interested in invariant distribution uij for this Markov chain, such that

n

i,j=1
X

Pij;lmuij = ulm.

Unfortunately, unlike to the one-dimensional case, this invariant distribution can not
be given by a simple analytic formula. But there is a way out: having at hand the
transition probabilities Pij;lm, we can simulate the corresponding Markov process
starting with some initial distribution u(0)
ij . Then after a suﬃciently large number
2

50

40

30

20

10

0

50

40

30

20

10

0

50

40

30

20

10

0

300

200

100

0
50

40

30

0.02

0.01

0
50

40

0.2

0.1

0
50

40

3

0

10

20

30

40

50

10 20 30 40 50

20

10

0

0

0

10

20

30

40

50

30

20

10

0

0

10 20 30 40 50

0

10

20

30

40

50

30

20

10

0

0

10 20 30 40 50

Fig. 2.1. The upper histograms represent the initial data in the contour and lego formats respec-
tively. The middle histograms show the corresponding probability distribution after 258 iterations
for the penetrating ability m = 3. The lower histograms represent the invariant distribution for the
penetrating ability m = 30.

of iterations we will end with almost invariant distribution irrespective to the initial
choice of u(0)
ij one can take the uniform distribution:

ij . For example, in the role of u(0)

u(0)
ij =

1
n2

.

For practical realization of the algorithm, it is desirable to have precise meaning
In our ﬁrst tests the following
of words “suﬃciently large number of iterations”.
stopping criterion was used. One stops at k-th iteration if the averaged relative
diﬀerence between u(k)
probability distributions is less than the desired
accuracy ǫ:

ij and u(k−1)

ij

(2.3)

2 |

u(k−1)
u(k)
ij
ij −
ij + u(k−1)
u(k)

ij

|

u(k)
ij < ǫ .

Xu(k)
ij 6=0

×

The performance of the algorithm is illustrated by Fig.2.1 for a 100

100 histogram
representing three overlapping Gaussians with diﬀerent widths. As expected, it works
much like to its one-dimensional cousin: the invariant probability distribution shows
sharp peaks at locations where the initial data has broad enough local maximums.
Note that in this concrete example the one iteration variability ǫ = 10−3 was reached
after 258 iterations for m = 3 and after 113 iterations for m = 30.
Convergence to the invariant distribution can be slow.

In the example given
above by Fig.2.1 the convergence is indeed slow for small penetrating abilities. If we
continue iterations for m = 3 further, the side peaks will slowly decay in favor of the
main peak corresponding to the global maximum. In the case of m = 3 it takes too
much iterations to reach the invariant distribution. However, as Fig.2.1 indicates, the
remarkable property to develop sharp peaks at locations of local maximums of the
initial histogram is already revealed by u(k)
ij when number of iterations k is of the
order of 300.

One can make the algorithm to emphasize minimums, not maximums, by just

reversing signs in the exponents:

exp

"

Nlm
Nij
Nlm + Nij # −→

−

exp

"−

Nlm
Nij
.
Nlm + Nij #

−

This is illustrated by Fig.2.2. Here the initial histogram is generated by using a variant
of the Griewank function [5]

p

p

(2.4)

F (x, y) =

(x

−

100)2 + (y
4000

−

100)2

cos (x

100) cos

−

−

y

100

−
√2

+ 1.

This function has the global minimum at a point x = 100, y = 100 and in the
y
histogramed interval 50
150 exhibits nearly thousand local min-
imums. Many of them are still visible in the probability distribution for penetrating
ability m = 3. But for m = 30 only one peak, corresponding to the global minimum,
remains.

150, 50

≤

≤

≤

≤

x

3. Quantum swarm optimization. The discussion above was focused on two-
dimensional histograms, while in practice more common problem is ﬁnding global
optimums of nonlinear functions. The algorithm in the form discussed so far is not

4

60

80

100

120

140

140

120

100

60 80 100 120 140

80

60

150
140
130
120
110
100
90
80
70
60
50

150
140
130
120
110
100
90
80
70
60
50

-3

x 10

0.4

0.2

0.002

0.001

0

140

60

80

100

120

140

120

100

80

60

60 80 100 120 140

Fig. 2.2. The probability distribution for the Griewank function. Upper histograms for m = 3,

lower histograms for m = 30.

suitable for this latter problem. However it is possible to merge its ideology with the
one of particle swarm optimization [6, 7, 8] to get a workable tool.

The particle swarm optimization was inspired by intriguing ability of bird ﬂocks to
ﬁnd spots with food, even though birds in the ﬂock had no previous knowledge of their
location and appearance. “This algorithm belongs ideologically to that philosophical
school that allows wisdom to emerge rather than trying to impose it, that emulates
nature rather than trying to control it, and that seeks to make things simpler rather
than more complex” [6]. This charming philosophy is indeed very attractive. So we
attempted to develop quantum swarm optimization - when each particle in the swarm
mimics the quantum behavior.

The algorithm that emerged goes as follows:

•

•

x

≤

xmax, ymin

initialize a swarm of np particles at random positions in the search space
xmin
ﬁnd a particle ib in the swarm with the best position (xb, yb), such that the
function F (x, y) under investigation has the most optimal value for the swarm
at (xb, yb).

ymax.

≤

≤

≤

y

5

•

•

•

−

−

(x

(xmax

xb)2 + (y

for each particle in the swarm ﬁnd the distance from the best position d =
yb)2. For the best particle instead take the maximal value
of these distances from the previous iteration (or for the ﬁrst iteration take
p
ymin)2 ).
d =
generate a random number r uniformly distributed in the interval 0
and ﬁnd the random step h = rd.
move the particle to left, right, up or down by the step h according to the
corresponding probabilities of such jumps:

xmin)2 + (ymax

p

≤

≤

−

−

1

r

pL =

pU =

qL
qL + qR + qU + qD
qU
qL + qR + qU + qD

, pR =

, pD =

qR
qL + qR + qU + qD
qD
qL + qR + qU + qD

,

,

qL =

exp

Is

qR =

exp

Is

y′=yu,y,yd
X

y′=yu,y,yd
X

x′=xu,x,xd
X

x′=xu,x,xd
X

qU =

exp

Is

F (xd, y′)
−
h

F (xu, y′)
−
h

F (x′, yd)
−
h

F (x, y)

F (x, y)

F (x, y)

F (x′, yu)
−
h

F (x, y)

,
(cid:19)

,
(cid:19)

,
(cid:19)

,
(cid:19)

(cid:18)

(cid:18)

(cid:18)

(cid:18)

(3.2)

qD =

exp

Is

(3.1)

where

and

(3.3)

xu = min (x + h, xmax), xd = max (x
yu = min (y + h, ymax), yd = max (y

−

h, xmin),
h, ymin).

−

At last Is = 1, if optimization means to ﬁnd the global maximum, and Is =

1, if the global minimum is searched.

•

•

−
do not stick at walls. If the particle is at the boundary of the search space,
it jumps away from the wall with the probability equaled one (that is the
probabilities of other three jumps are set to zero).
check whether the new position of the particle leads to the better optimum.
If yes, change ib and (xb, yb) accordingly.
when all particles from the swarm make their jumps, the iteration is ﬁnished.
Repeat it at a prescribed times or until some other stopping criteria are met.
To test the algorithm performance, we tried it on some benchmark optimization
test functions. For each test function and for each number of iterations one thou-
sand independent numerical experiments were performed and the success rate of the
algorithm was calculated. The criterion of success was the following

•

(3.4)

xf
|

−

xm

| ≤

yf
|

−

ym

| ≤

,
|

10−3
xm
|
10−3,
if
10−3
,
ym
|
|
10−3,
if
6

if
xm
|
if
ym
|

xm
|
| ≤
ym
|
| ≤

> 10−3

|
10−3

> 10−3

|
10−3

,

,

(cid:26)

(cid:26)

where (xm, ym) is the true position of the global optimum and (xf , yf ) is the position
found by the algorithm. The results are given in the table 3.1. The test functions itself
are deﬁned in the appendix. Here we give only some comments about the algorithm
performance.

Success rate of the algorithm in percentages for various test functions and for various numbers

of iterations. Swarm size np = 20.

Table 3.1

Function
Name
Chichinadze
Schwefel
Ackley
Matyas
Booth
Easom
Levy5
Goldstein-Price
Griewank
Rastrigin
Rosenbrock
Leon
Giunta
Beale
Bukin2
Bukin4
Bukin6
Styblinski-Tang
Zettl
Three Hump Camel
Schaﬀer
Levy13
McCormic

50
3.7
91
100
6.4
87.8
0.9
96.9
100
0.4
99.8
5.3
1.9
77.6
52.7
13.4
84.7
0.2
100
7.9
67
0
84.1
60.1

100
62.6
94.9
100
61.4
100
60.4
97.4
99.9
20.6
99.8
23.6
10.4
99.7
93.8
30.4
100
0.1
100
64
99.9
0.8
99.9
99.2

200
99.9
94.2
100
99.7
100
100
98.4
100
88.9
99.9
58.9
23.7
99.9
100
55.4
100
0
100
99.9
100
9.4
99.9
100

Iterations
400
300
100
100
96.1
94.4
100
100
100
100
100
100
100
100
98.3
98.2
100
100
95.6
93.8
99.9
99.7
83.9
74.3
50.6
38.1
100
100
100
100
78.1
67.9
100
100
0.1
0.1
100
99.9
100
100
100
100
23.3
16.2
99.9
100
100
100

500
100
94.7
100
100
100
100
97.8
100
96
99.9
88.3
54.9
100
100
85.2
100
0.3
100
100
100
22.4
100
100

600
100
94
100
100
100
100
98.6
100
95.8
99.9
92.1
61.2
99.9
100
89.2
100
0.3
100
100
100
26
100
100

700
100
94.7
100
100
100
100
98
100
96.5
99.6
94.8
68.6
99.9
100
88.9
100
0.2
100
100
100
25.4
100
100

For some test problems, such as Chichinadze, Ackley, Matyas, Booth, Easom,
Goldstein-Price, Beale, Bukin4, Styblinski-Tang, Zettl, McCormic and Three Hump
Camel Back, the algorithm is triumphant.

Matyas problem seems easy, because the function is only quadratic. However it is
very ﬂat near the line x = y and this leads to problems for many global optimization
algorithms.

Easom function is a unimodal test function which is expected to be hard for
any stochastic algorithms, because vicinity of its global minimum has a small area
compared to the search space. Surprisingly our algorithm performs quite well for
this function and one needs only about 200 iterations to ﬁnd the needle of the global
minimum in a haystack of the search space.

Schwefel function is deceptive enough to cause search algorithms to converge in the
wrong direction. This happens because the global minimum is geometrically distant
from the next best local minima. In some small fraction of events our algorithm is also
prone to converge in the wrong direction and in these cases the performance seems

7

not to improve by further increasing the number of iterations. But the success rate is
quite high. Therefore in this case it is more sensible to have two or more independent
tries of the algorithm with rather small number of iterations each.

Rastrigin function is a multimodal test function which have plenty of hills and
valleys. Our algorithm performs even better for this function, but the success is not
universal either.

Rosenbrock function is on contrary unimodal. Its minimum is situated in a banana
shaped valley with a ﬂat bottom and is not easy to ﬁnd. The algorithm shows rather
slow convergence in this case and the success rate is about 95% for 700 iterations.
Leon function is of the similar nature, with even more ﬂat bottom and the convergence
in this case is correspondingly more slow.

Griewank, Levy5 and Levy13 are multimodal test functions. They are considered
to be diﬃcult for local optimizers because of the very rugged landscapes and very
large number of local optima. For example, Levy5 has 760 local minima in the search
domain but only one global minimum and Levy13 has 900 local minima. Test results
reveal a small probability that our algorithm becomes stuck in one of the local minima.
Giunta function simulates the eﬀects of numerical noise by means of a high fre-
quency, low amplitude sine wave, added to the main part of the function. The algo-
rithm is successful for this function. However there is a very small probability that it
will fail.

The performance of the algorithm is not so good for Bukin2 function, and es-
pecially for the Schaﬀer function. This latter problem is hard because of the highly
variable data surface features many circular local optima, and our algorithm becomes,
unfortunately, often stuck in the optima nearest to the global one.

At last, the algorithm fails completely for the Bukin6 function. This function has
a long narrow valley which is readily identiﬁed by the algorithm. But the function
values diﬀer very small along the valley. Besides the surface is non-smooth in the valley
with numerous pitfalls. This problem seems hopeless for any stochastic algorithm
based heavily on random walks, because one has to chance upon a very vicinity of
the global optimum to be successful. The non-stochastic component of our algorithm
(calculation of jump probabilities to mimic the quantum tunneling) turns out to be
of little use for this particular problem.

4. Concluding remarks. The Quantum Swarm Optimization algorithm pre-
sented above emerged while trying to generalize in the two-dimensional case a “quan-
tum mechanical” algorithm for automatic location of photopeaks in the one dimen-
sional histograms [1].

“ Everything has been said before, but since nobody listens we have to keep
going back and beginning all over again” [9]. After this investigation was almost
ﬁnished, we discovered the paper [10] by Xie, Zhang and Yang with the similar idea
to use the simulation of particle-wave duality in optimization problems. However their
realization of the idea is quite diﬀerent.

Even earlier, Levy and Montalvo used the tunneling method for global optimiza-
tion [11], but without referring to quantum behavior. Their method consisted in a
transformation of the objective function, once a local minimum has been reached,
which destroys this local minimum and allows to tunnel classically to another valley.
We found also that the similar ideology to mimic Nature’s quantum behavior in
optimization problems emerged in quantum chemistry and led to such algorithms as
quantum annealing [12] and Quantum Path Minimization [13].

Nevertheless, the Quantum Swarm Optimization is conceptually rather diﬀerent

8

from these developments. We hope it is simple and eﬀective enough to ﬁnd an eco-
logical niche in a variety of global optimization algorithms.

Appendix. Here we collect the test functions deﬁnitions, locations of their opti-
mums and the boundaries of the search space. The majority of them was taken from
[14, 15, 16], but we also provide the original reference when known.

Chichinadze function [16, 17]

F (x, y) = x2

12x + 11 + 10 cos

x + 8 sin (5πx)

−

π
2

1
√5

−

exp

(y

0.5)2
−
2

,
(cid:19)

−

(cid:18)

30

−

≤

≤

x, y

30, Fmin(x, y) = F (5.90133, 0.5) =

43.3159.

−

Schweﬀel function [18]

x sin

F (x, y) =

x
|
p
500, Fmin(x, y) = F (420.9687, 420.9687) =

y
|
p

y sin

| −

,
|

−

837.9658.

−

500

x, y

−

≤

≤

Ackley function [19]

F (x, y) = 20[1

e−0.2√0.5(x2+y2)]

e0.5[cos (2πx)+cos (2πy)] + e,

−

−

35

−

≤

≤

x, y

35, Fmin(x, y) = F (0, 0) = 0.

Matyas function [15]

Booth function [16]

F (x, y) = 0.26(x2 + y2)

0.48xy,

−

10

−

≤

≤

x, y

10, Fmin(x, y) = F (0, 0) = 0.

F (x, y) = (x + 2y

7)2 + (2x + y

5)2

−

−

10

−

≤

≤

x, y

10, Fmin(x, y) = F (1, 3) = 0.

Easom function [20]

Levy5 function [15]

F (x, y) =

cos x cos y exp [

(x

−

−

π)2

(y

−

−

π)2],

−

100

x, y

100, Fmin(x, y) = F (π, π) =

−

≤

≤

1.

−

F (x, y) =

i cos [(i

1)x + i]

j cos [(j + 1)y + j]+

5

i=1
X

5

j=1
X

−

9

+(x + 1.42513)2 + (y + 0.80032)2,

100

x, y

100, Fmin(x, y) = F (

1.30685,

1.424845) =

176.1375.

−

≤

−

≤
Goldstein-Price function [15]

F (x, y) =

1 + (x + y + 1)2(19

14x + 3x2

14y + 6xy + 3y2)

−

−

(cid:2)
30 + (2x

×

(cid:2)

3y)2(18

32x + 12x2 + 48y

36xy + 27y2)

−

−

2

−

≤

≤

x, y

2, Fmin(x, y) = F (0,

1) = 3.

×

(cid:3)
,

(cid:3)

Griewank function [5, 15]

F (x, y) =

cos x cos

+ 1,

x2 + y2

200 −

−

−

−

−

y
√2

100

x, y

100, Fmin(x, y) = F (0, 0) = 0.

≤
Rastrigin function [21]

−

≤

F (x, y) = x2 + y2

10 cos (2πx)

10 cos (2πy) + 20,

−

−

5.12

x, y

5.12, Fmin(x, y) = F (0, 0) = 0.

−

≤

≤

Rosenbrock function [15]

F (x, y) = 100(y

x2)2 + (1

x)2,

−

−

1.2

x, y

1.2, Fmin(x, y) = F (1, 1) = 0.

−
Leon function [22]

≤

≤

F (x, y) = 100(y

x3)2 + (1

x)2,

−

−

1.2

x, y

−

≤

≤

1.2, Fmin(x, y) = F (1, 1) = 0.

Giunta function [23]

F (x, y) = sin

16
15

x

−

(cid:18)

1

+ sin2

(cid:19)

(cid:18)

16
15

x

−

(cid:19)

1
50

1

+

sin

4

16
15

x

−

1

+

(cid:19)(cid:21)

(cid:20)

(cid:18)

+ sin

16
15

y

−

(cid:18)

1

+ sin2

(cid:19)

(cid:18)

16
15

y

−

(cid:19)

1
50

1

+

sin

4

16
15

y

1

−

(cid:20)

(cid:18)

(cid:19)(cid:21)

+ 0.6,

1

−

≤

≤

x, y

1, Fmin(x, y) = F (0.45834282, 0.45834282) = 0.0602472184

10

Beale function [15]

F (x, y) = (1.5

x + xy)2 + (2.25

x + xy2)2 + (2.625

x + xy3)2,

−
4.5

x, y

−

≤

≤

−

−
4.5, Fmin(x, y) = F (3, 0) = 0.

Bukin2 function [24]

F (x, y) = 100(y

0.01x2 + 1) + 0.01(x + 10)2,

−
y

15

x

5,

3

3, Fmin(x, y) = F (

10, 0) = 0.

−
Bukin4 function [24]

≤

≤ −

−

≤

≤

F (x, y) = 100y2 + 0.01

x + 10
|
3, Fmin(x, y) = F (

,
|

10, 0) = 0.

15

x

−
Bukin6 function [24]

≤

≤ −

5,

3

y

−

≤

≤

F (x, y) = 100

y
|
p
y

0.01x2

+ 0.01

|

−
3, Fmin(x, y) = F (

x + 10
|

,
|

10, 1) = 0.

15

x

5,

3

≤
Styblinski-Tang function [25]

≤ −

−

−

≤

≤

F (x, y) =

x4

16x2 + 5x + y4

16y2 + 5y

,

1
2

−

2.903534,

2.903534) =

78.332.

(cid:3)

−

−

−

5

x, y

−

≤
Zettl function [22]

≤

(cid:2)
15, Fmin(x, y) = F (

−

F (x, y) = (x2 + y2

−
5, Fmin(x, y) = F (

2x)2 + 0.25x,

0.0299, 0) =

0.003791.

−

−

5

−

≤

x, y

≤

Three Hump Camel back function [14]

−

−

−

Schaﬀer function [26]

F (x, y) = 2x2

1.05x4 +

+ xy + y2,

−

x6
6

5

−

≤

≤

x, y

5, Fmin(x, y) = F (0, 0) = 0.

F (x, y) = 0.5 +

x2 + y2
0.5
sin
[1 + 0.001(x2 + y2)]2

−

,

p

100

x, y

100, Fmin(x, y) = F (0, 0) = 0.

−

≤

≤

Levy13 function [14]
F (x, y) = sin2 (3πx) + (x

≤
McCormic function [27]

−

1)2

1 + sin2 (3πy)

+ (y

1)2

1 + sin2 (2πy)

,

−

10

(cid:2)

(cid:2)
10, Fmin(x, y) = F (1, 1) = 0.

(cid:3)

(cid:3)

−
x, y

≤

F (x, y) = sin (x + y) + (x

1.5x + 2.5y + 1,

1.5

x

4,

3

x

≤

≤

−

≤

≤

−

4 Fmin(x, y) = F (

1.54719) =

1.9133.

−

y)2

−

−
0.54719,

−

−

11

Acknowledgments. Support from the INTAS grant No. 00-00679 is acknowl-

edged.

REFERENCES

[1] Z. K. Silagadze, A New algorithm for automatic photopeak searches, Nucl. Instrum. Meth.,

[2] W. Feller , An introduction in probability theory and its applications, vol.1, Wiley, New York,

A376 (1996), pp. 451–454.

1966.

[3] M. N. Achasov et al., Medium energy calorimetry at SND: Techniques and performances on
physics, in Lisbon 1999, Calorimetry in high energy physics proceedings, World Scientiﬁc,
Singapore, 2000, pp. 105–120.

[4] A. V. Bannikov, G. A. Chelkov and Z. K. Silagadze, B0
s

−
−
s a+
s →
s mixing studies, Dubna preprint JINR-E1-98-29,

−
s → φπ−, D

1 (D

→ D

K ∗0K −) decay channel in the ATLAS B0
Dubna, 1998.

[5] A. O. Griewank, Generalized descent for global optimization, J. Optim. Theory Appl., 34

[6] J. Kennedy and R. Eberhart, Particle Swarm Optimization, in Proceedings of IEEE Con-

ference on Neural Networks, Perth, Australia, 1995, pp. 1942–1948.

[7] J. Kennedy, R. C. Eberhart and Y. Shi, Swarm intelligence, Morgan Kaufmann Publishers,

(1981), pp. 11–39.

San Francisco, 2001.

[8] K. E. Parsopoulos and M. N. Vrahatis, Recent Approaches to Global Optimization Problems
Through Particle Swarm Optimization, Natural Computing, 1 (2002), pp. 235–306.

[9] Aphorism of Andre Gide.

[10] X. F. Xie, W. J.Zhang and Z. L. Yang, Solving numerical optimization problems by simu-
lating particle-wave duality and social information sharing, Int. Conf. on Artiﬁcial Intelli-
gence, Las Vegas, USA, 2002, pp. 1163-1169.

[11] A. V. Levy A. and Montalvo, The tunneling method for Global Optimization, SIAM J. of

Sci. and Stat. Comp. 6 (1985), pp. 15–29.

[12] For a review and references see, for example, T. Kadowaki, Study of Optimization Problems by
Quantum Annealing, Ph.D. thesis, Department of Physics, Tokyo Institute of Technology,
1998.

[13] P. Liu and B. J. Berne, Quantum path minimization: An eﬃcient method for global opti-

mization, J. Chem. Phys., 118 (2003), pp. 2999–3005.

[14] C. Jansson and O. Kn¨uppel, A global minimization method: The multi-dimensional case,

Technical Report 92-1, TU Hamburg-Harburg, 1992.

[15] C. Jansson and O. Kn¨uppel, Numerical results for a self-validating global optimization

method, Technical Report 94-1, TU Hamburg-Harburg, 1994.

[16] R. J. Van Iwaarden, An improved unconstrained global optimization algorithm, Ph.D. thesis,

University of Colorado at Denver, Denver, Colorado, 1996.

[17] V. Chichinadze, The ψ-transform for solving linear and nonlinear programming problems,

Automata 5 (1969), pp. 347–355.

[18] H.-P. Schwefel, Numerical optimization of computer models, Wiley & Sons, Chichester, 1981.
[19] D. H. Ackley, A connectionist machine for genetic hillclimbing, Kluwer Academic Publishers,

Boston, 1987.

Louisville, KY, 1990.

[20] E. E. Easom, A survey of global optimization techniques, M. Eng. thesis, Univ. Louisville,

[21] H.-M. Voigt, J. Born and I. Santibanez-Koref, A Multivalued Evolutionary Algorithm,
Technical Report TR-92-038, International Computer Science Institute, Berkeley, CA,
1992.

[22] S. Nagendra, Catalogue of Test Problems for Optimization Algorithm Veriﬁcation, Technical

Report 97-CRD-110, General Electric Company, 1997.

[23] A. A. Giunta, Aircraft multidisciplinary design optimization using design of experiments the-
ory and response surface modeling methods, MAD Center Report 97-05-01, Virginia Poly-
technic Institute & State University Blacksburg, VA, 1997.

[24] A. D. Bukin, New Minimization Strategy For Non-Smooth Functions, Budker Institute of

Nuclear Physics preprint BUDKER-INP-1997-79, Novosibirsk, 1997

[25] M. Styblinski and T. Tang, Experiments in nonconvex optimization: Stochastic approx-
imation with function smoothing and simulated annealing, Neural Networks, 3 (1990),
pp. 467-483.

[26] D. Whitley, K. Mathias, S. Rana and J. Dzubera, Evaluating Evolutionary Algorithms,

12

Artiﬁcial Intelligence, 85 (1996), pp. 245-276.

[27] K. Madsen and J. Zilinskas, Testing branch-and-bound methods for global optimization, IMM

technical report 05, Technical University of Denmark, 2000.

13

