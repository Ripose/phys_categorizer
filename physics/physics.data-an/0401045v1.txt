4
0
0
2
 
n
a
J
 
0
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
5
4
0
1
0
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

PHYSTAT2003, SLAC Sep. 8-11, 2003

1

Comments on Likelihood ﬁts with variable resolution

Giovanni Punzi
Scuola Normale Superiore and INFN, 56100 Pisa, Italy

Unbinned likelihood ﬁts are frequent in Physics, and often involve complex functions with several components.
We discuss the potential pitfalls of situations where the templates used in the ﬁt are not ﬁxed but depend on the
event observables, as it happens when the resolution of the measurement is event–dependent, and the procedure
to avoid them.

When several categories of events are present in the
same data sample, an unbinned Maximum Likelihood
ﬁt is often used to determine the proportion and the
properties of each class of events. This procedure
makes use of “templates”, representing the probability
distribution of the observables used in the ﬁt for each
class of events.
In the simplest cases the templates
are completely determined by the values assigned to
the parameters of the ﬁt, but frequently a more so-
phisticated approach is chosen where templates vary
on an event by event basis, according to the resolution
of the measurement for that particular event. These
variations are due to the dependence of resolution on
extra variables, that change on an event-by-event ba-
sis . This may happen, for instance, when events are
recorded by a detector that has diﬀerent resolutions
in diﬀerent regions within its acceptance.

A common example of this kind of ﬁt in HEP is
given by lifetime and/or mass ﬁts (see [1] for a sample
list of recent experimental papers), where variations
in resolution occur as a consequence of diﬀerent con-
ﬁguration of each individual decay. The same kind of
issue hovewer is likely to arise in other situations.

The purpose of this short paper is to point out some
potential pitfalls in this kind of ﬁtting procedure. I
will illustrate the point with reference to a simple toy
problem.

1. A toy problem

Consider an experiment in which two types of
events, A and B, can occur. Let f be the fraction
of type–A events, that is, the probability of a generic
event to be of type A. We want to extract a measure-
ment of f from a given sample of data. In order to do
this, we measure the value of an observable x, having
the following probability distributions:

p(x|A) = N (0, σ)
p(x|B) = N (1, σ)

Where σ is a known constant and N (µ, σ) is the nor-
mal distribution

This problem is easily solved using an “unbinned
Likelihood ﬁt”. This consists of maximizing the Like-

WELT002

lihood function:

L(f ) = Y
i

(f N (xi, 0, σ) + (1 − f )N (xi, 1, σ))

(1)

with respect to the required parameter f (here
N (x, µ, σ) indicates the gaussian function in the vari-
able x). This is very simple to perform with the help
of a numerical maximization program.

Let’s make a speciﬁc numeric example, where f =
1/3 and σ = 1 (see illustration in Fig. 1), and the
size of the data sample is 150 events. By repeteadly
generating MC samples of 150 events each, we obtain
the distribution of the Maximum Likelihood estimator
of f , which is shown in Fig. 2.

-2

0

2

4

x

Figure 1: Probability distribution of x for the toy
problem described in the text. Contribution of type–A
and type–B events are also shown.

Its mean is 0.3368 ± 0.0041 and SD = 0.083, in
agreement with expectations of 0.3333 and 0.088 re-
spectively (the latter coming from Fisher information
).

pHxL

0.35

0.3

0.25

0.2

0.15

0.1

0.05

80

60

40

20

0.2

0.4

0.6

0.8

1

Figure 2: Distribution of ML estimate of the fraction f
of type-A events (see text)

2

PHYSTAT2003, SLAC Sep. 8-11, 2003

2. A toy problem, with variable resolution

Let’s now suppose that the resolution of x is not
constant, but rather depends on the event: we are
assuming that each event xi comes together with an
individual value of σ (let it be σi). This situation
is encountered in many real–life problems, and the
common approach found in the literature is to simply
modify the Likelihood function as follows:

L(f ) = Y
i

f N (xi, 0, σi) + (1 − f )N (xi, 1, σi))

(2)

This looks like a pretty obvious generalization of ex-
pression (1). To test it in our toy problem, we mod-
iﬁed our toy MC from previous example, by making
σ ﬂuctuate at each event within an arbitrarily chosen
range (1.0 to 3.0), and again made repeated simulated
experiments of 150 events each, maximizing the Like-
lihood expression (2) to estimate f . The result of this
test is shown in Fig. 3, and rather surprisingly, shows
a very large bias with respect to the true value of f .

60

50

40

30

20

10

call it “conditional Likelihood”) rather than the full
distribution p(xi, σi|f ). The diﬀerence matters for ﬁt-
ting unless it happens that the distribution of σi is the
same for all types of events: p(σi|A) = p(σi|B). In
that case, p(σi) can be factored out, and the incom-
plete Likelihood of eq. (2) diﬀers from the true Likeli-
hood just by a factor independent of f , that does not
aﬀect the maximization.

In the speciﬁc MC test reported above, we simu-
lated a resolution 1.5 times worse for events of type
B than for type A, setting the σi distribution as ﬂat
between 1 and 2 for A-type events, and ﬂat between
1.5 and 3 for type-B events. We intentionally avoided
saying this explicitly before, in order to put the reader
in the typical situation encountered in reality, where
no attention is payed to the distribution of those reso-
lutions for the diﬀerent classes of events considered in
the ﬁt. It turns out from our example that this may
lead to very biased results.

In summary, expression (2) simply does not work for
ﬁtting, and by a large amount: it can be said to belong
to that particular class of solutions nicely deﬁned in
[2] as ‘SNW solutions’.

Conversely, if we use in ﬁtting the correct expres-
sion of the Likelihood (eq. 4) we get the result shown
in ﬁg. 4, showing a negligible bias. The resolution
of the ﬁt is also much better, as the diﬀerence in the
distributions of the σ themselves gets exploited in sep-
arating the two samples; this however is a minor point
in comparison with the bias issue.

0.2

0.4

0.6

0.8

1

Figure 3: Distribution of ML estimate of the fraction f
of type-A events, obtained from a ”conditional
Likelihood”

This may seem really odd, until one realizes that
this new problem is very diﬀerent from the previous
one. Our problem now has actually two observables:
each observation consists of the pair of values (xi, σi)
rather than just xi, and its probability density de-
pends on both. This means that the Likelihood must
now be written based on the probability distributions
of the (xi, σi) pair:

200

150

100

50

0.2

0.4

0.6

0.8

1

Figure 4: Distribution of ML estimate of the fraction f
of type-A events, using the full Likelihood function

L(f ) = Y
i

f p(xi, σi|A) + (1 − f )p(xi, σi|B)

(3)

3. Additional tests

Remembering that p(xi, σi|X) = p(xi|σi, X)p(σi|X)
we can write the correct expression of the Likelihood
for our problem as:

One may wonder at what features of the distribu-
tions make for a large bias. Table I shows results for
a few variants of the original problem. Tests include:

L(f ) = Y
i

f N (xi, 0, σi)p(σi|A)

• Equal-width ranges of σ.

+ (1 − f )N (xi, 1, σi)p(σi|B)

(4)

• Disjoint σ ranges.

where p(σi|X) is the pdf of σi for events of type X, an
element that was absent in eq. (2); in fact, comparing
the two expressions shows that (2) is actually the con-
ditional probability distribution p(xi|σi, f ) (one might

• Constant, but diﬀerent σ for A and B.

• Constant, and close σ’s for A and B.

• Same-mean σ distribution with diﬀerent widths.

WELT002

PHYSTAT2003, SLAC Sep. 8-11, 2003

3

Table I Results of MC ﬁtting tests.

Resolutions
σB
σA
1.0
1.0
[1.0, 2.0]
[1.0, 2.0]
[1.0, 2.0]
1.0
1.0
[0.5, 3.5]
1.0

2.0
1.1

“conditional” L (2)
σ( ˜fA)
0.336 ± 0.003 0.08

˜fA

True Likelihood

ˆfA

σ( ˆfA)

[1.5, 3.0] 0.514 ± 0.007 0.14 0.335 ± 0.002 0.03
[1.5, 2.5] 0.474 ± 0.007 0.14 0.335 ± 0.002 0.03
[2.0, 3.0] 0.579 ± 0.008 0.15 0.333 ± 0.000 0.00
0.645 ± 0.006 0.12 0.333 ± 0.000 0.00
0.374 ± 0.004 0.08 0.333 ± 0.000 0.00
[1.5, 2.5] 0.330 ± 0.006 0.12 0.332 ± 0.002 0.03
[1.0, 2.0] 0.482 ± 0.009 0.09 0.333 ± 0.000 0.00

(σA actually = 1.)

1.0
[0.5, 3.5]

modiﬁed L (5)

True Likelihood
[1.0, 2.0] 0.374 ± 0.004 0.08 0.333 ± 0.000 0.00
[1.0, 2.0] 0.414 ± 0.004 0.08 0.332 ± 0.003 0.03

• Only one type of events has variable sigma.

In almost every tried situation we found expres-
sion (2) to return largely biased results. The exception
occurs when the average σ is the same; the resolution
on f is however much worse than with the correct ex-
pression. It looks like the most important element is
the diﬀerence between the average values of σ for the
diﬀerent samples; the actual variability within each
sample seems less important.

A simpler situation exists, that is pretty common in
practice, where one has just one signal component over
a background, and the signal distribution contains a
variable sigma, while the background is represented
just by a ﬁxed template. In this case, expression (2)
becomes:

L(f ) = Y
i

f N (xi, 0, 1) + (1 − f )N (xi, 1, σi))

(5)

This expression of L is of course still incorrect, but
it better describes reality at least for one of the two
event categories by incorporating explicitly the infor-
mation that it has a ﬁxed sigma. Here a variable tem-
plate appears just in one component, and being this
the simplest conﬁguration with a variable template,
it is interesting to ask whether it yields a reasonable
approximation of the correct results.

If we apply this new Likelihood expression to the
last tested case, (σA = 1.0 and σB ∈ [1.0, 2.0]), we
ﬁnd that the result is still biased, although to a lesser
extent (Tab.
I). This shows that the distribution
of σ must be kept into account even in the simplest
situation, where it appears in only one component of
the ﬁt.

The mechanism underlying this problem is easier to
see by looking at a variant of the previous case. Sup-
pose that resolutions are the same as above, but for
events of type-A the variable σi is distributed over a
wide range (0.5-3-5); this is not the actual value of
the resolution for those events, that is still ﬁxed at 1,
so for type-A events it represents just an additional

WELT002

meaningless number. This is a deﬁnite possibility in
a real case, where the nature of type–A events may
be so diﬀerent from type–B to produce meaningless
values for the resolution estimator σi, that was de-
signed to work for type–B events – remember that
the distribution of A is given as ﬁxed. Note that the
expression used (5) does know that much, and cor-
rectly disregards the value of σi in the A hypothesis.
For events of type B, the variable σi correctly repre-
sents the sigma, event by event, of the observable x,
and the L function correctly accounts for this, too.

It may come as a surprise that the result is largely
biased. The reason for this rather spectacular failure
is that the second piece of L, related to B-type events,
gets confused by the presence of the events of type–A
with meaningless values of sigma: they unavoidably
enter both terms of L during the calculation. The
conclusion is: whenever you include σi in your Likeli-
hood expression, even for just one class of events, you
must also account for its distribution, and you must
do so for all event classes.

4. Conclusions

Whenever the templates used in a multi-component
ﬁt depend on additional observables, one should al-
ways use the correct, complete Likelihood expression
(4), including the explicit distributions of all observ-
ables for all classes of events. This is necessary even
if just one of the components is based on a variable
σ. The simpler expressions that are commonly used
should be considered unreliable unless one can show
that the distribution of the variable σ is the same for
all components.

A more general consideration suggested by the ex-
amples discussed above is that one should always be
wary of “intuitive” modiﬁcations of a Likelihood func-
tion. For every given problem there is only one correct
expression for the Likelihood (up to a multiplicative
constant factor), and it is crucial to verify in every
case that the expression used is the right one, rather
than rely on intuition.

References

[1] Recent examples of variable-resolution ﬁts in HEP
can be found in: B. Aubert et al. [Babar Collab.],
Phys.Rev.Lett. 91 (2003) 121801. K.Abe et al.
[Belle Collab.], Phys.Rev.Lett. 88 (2002) 171801.
P. Abreu et al.
, Eur.Phys.J.
C16 (2000) 555. ALEPH Collab., Phys.Lett. B492
(2000) 275-287. M. Paulini, Int. J. Mod.Phys. A14
(1999) 2791-2886.

[Delphi Collab.]

[2] J. Heinrich, these proceedings.

