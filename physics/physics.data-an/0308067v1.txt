3
0
0
2
 
g
u
A
 
8
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
7
6
0
8
0
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Exclusion regions and their power.

L. Fleysher,1, ∗ R. Fleysher,1, † T. J. Haines,2, ‡ A. I. Mincer,1, § and P. Nemethy1, ¶
1Department of Physics, New York University, New York, New York 10003
2Los Alamos National Laboratory, Los Alamos, New Mexico 87545
(Dated: August 17, 2003)

The question of exclusion region construction in new phenomenon searches has been causing
considerable discussions for many years and yet no clear mathematical deﬁnition of the problem
has been stated so far. In this paper we formulate the problem in mathematical terms and propose
a solution to the problem within the framework of statistical tests. The proposed solution avoids
problems of the currently used procedures.

PACS numbers: 02.50.Le, 02.50.Tt, 06.60.Mr, 06.20.Dk

I.

INTRODUCTION

When existence of a new phenomenon is proposed an
experiment is designed which exploits the diﬀerences be-
tween the adopted (old) and the new theories to check if
there is evidence to reject the old theory in favor of the
new one. It is this diﬀerence which provides the signal
in the experiment. If such a signal is found, a discovery
is claimed and the values of the parameters of the new
theory are measured. If, on the other hand, no evidence
contradicting the old theory is found, it is desirable to
set a constraint on the possible values of the parameters
of the new theory. The logic behind this is simple: if the
values of the parameters of the new theory were inside
a certain region of the parameter space, the experiment
would have found evidence against the old theory in fa-
vor of the new one. Since no evidence is actually found,
such a region is called the exclusion region.

Traditionally, the exclusion regions on the parame-
ters of a theory are constructed based on the upper
boundary of a classical one-sided conﬁdence interval. Of-
ten, the exclusion regions constructed by one experi-
ment rule out signals reported by the others (see, for
instance, CDMS [1] and DAMA [4] or LSND [3] and
KARMEN [2]). Therefore, the task of conﬁdence interval
construction receives considerable attention and is a sub-
ject of many controversies (see, for instance, [1, 2, 3, 4, 5,
6, 8, 9]). There are, however, serious problems associated
with the use of conﬁdence intervals for exclusion region
construction which are often overlooked. Indeed, one of
the pre-requisites of the theory of statistical estimation
based on the classical theory of probabilities [10] is the
knowledge that the observed data have arisen from the
phenomenon being observed. In other words, it is sup-
posed that there is no question whether the observed data
x were drawn from the probability distribution p1(x; µ);

∗Electronic address: lazar.ﬂeysher@physics.nyu.edu
†Electronic address: roman.ﬂeysher@physics.nyu.edu
‡Electronic address: haines@lanl.gov
§Electronic address: allen.mincer@nyu.edu
¶Electronic address: peter.nemethy@nyu.edu

it is known for a fact and an attempt is being made to
quantify the value of the parameter µ by constructing a
one-sided conﬁdence interval.

Hence, it is immediately seen that the classical theory
of estimation is not applicable to the situations when it
is not known that the phenomenon exists. The applica-
tion of the theory to such problems may lead to intervals
which do not have the desired conﬁdence level. Another
problem is that a conﬁdence interval constructed in such
a way may exclude values of the parameter µ for which
the experiment is insensitive (see, for instance, discus-
sions in [5, 7]).

Thus, the dissatisfaction with the classical theory of
estimation is not due to imperfections in the theory but
is caused by misuse of the theory and by lack of mathe-
matical clarity in problems solutions of which are sought
within the framework of the classical estimation theory.
Yet, it is desirable to be able to construct exclusion re-
gions objectively without the use of subjective priors.

In this work we formulate the question of what can be
stated regarding the parameter µ of the hypothesis H1(µ)
of presence of the new phenomenon when the hypothe-
sis H0 of absence of the new phenomenon is not rejected
based on the outcome of the experiment. We also pro-
pose a solution to this problem formulated within the
framework of hypothesis test formalism. In addition, we
propose a clear deﬁnition of the sensitivity of a detector.

II. STATEMENT OF THE PROBLEM AND ITS
SOLUTION

Consider an experiment searching for a new phe-
nomenon where a decision of plausibility of existence of
the new phenomenon is made with the help of a statis-
tical test [11]. In such a test, the hypothesis tested (the
null hypothesis H0) is the adopted (old) theory with the
alternative hypothesis H1 that the observed data is due
to the new phenomenon. Each of the hypotheses deﬁnes
a probability distribution of obtaining every possible out-
come x of the experiment p0(x) and p1(x) respectively.
The test is set up so that if the observed data lie within
some critical region wc, the null hypothesis is rejected
and is not rejected otherwise [11].

2

The error leading to an unjust rejection of the null hy-
pothesis is called the error of the ﬁrst kind and is denoted
by α. It is a common practice to construct the test in
such a way as to guarantee that the error does not ex-
ceed a preset value αc called the level of signiﬁcance. The
power of the test (1
β) is deﬁned as the probability of
rejecting the null hypothesis when the alternative is true.
In other words:

−

αc ≥ Zwc

p0(x)dx (1

β) =

p1(x)dx

−

Zwc

state that the values of the parameter µ of the alter-
native hypothesis for which the null hypothesis can not
be rejected reliably should not be excluded based on the
non-rejection of the null hypothesis.

To formulate this intuitive notion in mathematical
terms it should be realized that the composite hypothe-
sis H1(µ) can be considered as a set of simple hypotheses
H1(µ) corresponding to diﬀerent ﬁxed values of µ which
can be classiﬁed by the power of the test:

Example

(1

β(µ)) =

p1(x; µ) dx

−

Zwc

Suppose that the observable X is distributed according
to the Gaussian distribution with zero mean and known
dispersion σ2 if the new phenomenon does not exist. If,
however, the new phenomenon exists, the same observ-
able X is distributed according to Gaussian with the
same dispersion but positive mean µ. Thus, the hypothe-
ses of the origin of the observed data x are :

p0 =

1
√2πσ2

2

2

/2σ

e−x

p1 =

e−(x−µ)

2

2

/2σ

µ > 0

1
√2πσ2

The best critical region [11] is deﬁned as x

xc. That
is, if the observed data point x is greater than xc the null
hypothesis of absence of the new phenomenon is rejected.
Thus, in the proposed test signiﬁcance and power are:

≥

αc =

∞

1
√2πσ2 Z

xc

2

2

/2σ

e−x

dx

(1

β) =

−

∞

1
√2πσ2 Z

xc

e−(x−µ)

2

2

/2σ

dx

The level of signiﬁcance is often selected at αc = 1.35

10−3 which corresponds to xc = 3σ in this example.

·

Suppose further that the value of the parameter µ of
the alternative hypothesis is large (say µ = 5σ) and the
alternative hypothesis is true. Since the existence of the
new phenomenon is reported only if x > xc is observed,
the presence of the new phenomenon will be established
β) = 0.997. If the alternative hy-
with probability (1
pothesis is true, but the value of the parameter µ is small
(say µ = 1σ) the existence of the new phenomenon will
be established only in 0.023 cases. Thus, it is hopeless to
look for the new phenomenon using the constructed test
if the value of µ is small.

−

The general problem which is being addressed in this
paper is the following. Given a critical region wc con-
structed for a test of a null hypothesis H0 with respect to
a composite alternative hypothesis H1(µ) with unknown
value of µ, what kind of restriction can be set on admis-
sible values of µ if, based on the outcome of the test, the
Intuitively, one would
null hypothesis is not rejected.

If the constructed test has low power with respect
to the simple alternative hypothesis H1(µ), it is not a
surprise that no evidence against the null hypothesis is
found. Therefore, if the null hypothesis is not rejected,
the admissible values of the parameter µ for which the
power of the test is small should not be excluded based
on the outcome of the experiment.

−
−

If however, the constructed test has a high power with
respect to the simple alternative hypothesis H1(µ) and
no evidence against the null hypothesis is found, it may
be concluded that the admissible values of the parameter
µ for which the power of the test is higher than critical
βc) can be ruled out as unlikely. The critical
value (1
βc) of the power of the test is motivated by
value (1
the problem at hand and should be selected at 90% or
higher. The value µc of the parameter µ corresponding
βc) at
to the smallest acceptable power of the test (1
signiﬁcance αc is the demarcation point (or demarcation
hypersurface if µ is multi-dimensional) between the al-
lowed and excluded regions of values of the parameter µ.
In the example considered above, the demarcation point
βc) = 0.9 at signiﬁcance
corresponding to the power (1
10−3 is µc = 4.3σ. The values of µ greater
of αc = 1.35
than µc should be considered as unlikely when the null
hypothesis is not rejected.

−

−

·

Based on the preceding discussion, it is seen that it
is the power of the test which needs to be maximized
when constructing experiments. There are several ways
to achieve this. One way to increase the power is to set
a less stringent level of signiﬁcance (decrease xc in the
example considered) which comes at a price of increased
probability to falsely claim a discovery. The other, per-
haps more desirable way to increase the power is by fun-
damental modiﬁcation of the experimental setup. Such
modiﬁcation can be made keeping the signiﬁcance level
intact but may increase the operation cost. Examples of
this approach are increased observation time or sample
size. In the example considered here, the decrease in the
dispersion σ2 will increase the eﬃcacy of the experiment
with respect to weak signals keeping the signiﬁcance level
intact.

III. EXPERIMENT SENSITIVITY

µc
s

99% power
90% power
50% power

3

Another question which needs to be addressed is that
of sensitivity of an experiment and what it means. Even
though sensitivity is usually interpreted as the signal
strength which a detector is able to detect, this statement
lacks deﬁniteness because the detection is a statistical
process. Due to statistical ﬂuctuations a strong signal
might be missed and a weak signal might be detected.
Thus, the question of sensitivity of the experiment has
to be addressed within the framework of statistical tests
as well. Therefore, the question is: given a critical region
wc constructed for a test of a null hypothesis H0 what
is the eﬃcacy of the test with respect to a set of simple
alternative hypotheses H1(µ).

The answer, once again, can be found in terms of sig-
niﬁcance and power. It is reasonable to request that any
apparatus to be constructed should have a chance of sig-
nal detection of 50% or more with given level of signiﬁ-
cance. That is why it is proposed to quote the sensitivity
of a detector as such signal level that would provide at
least 50% power of the test at the speciﬁed level of sig-
niﬁcance and should not be regarded as “absolute” 100%
detection level.
In the example considered above, the
sensitivity of the experiment is µ = 3σ with signiﬁcance
1.35

10−3.

At this point it is important to note that two identical
experiments looking at identical signal at their sensitiv-
ity level may provide drastically diﬀerent outcomes. One
of the experiments may get lucky and state a discov-
ery of the phenomenon while the other one may not. It
should be stressed that based on that it is not possible
to conclude that outcome of one experiment rules out the
signal of the other one; there is no contradiction between
the two.
In order to conﬁrm or refute a signal detec-
tion made by an experiment at its sensitivity level, it is
required to conduct a new test which would have appre-
ciable (90% or more) power with respect to the claimed
signal strength with pre-speciﬁed signiﬁcance. Return-
ing to the considered example, to conﬁrm the discovery
made on this experiment a new test would have to be
built with the new dispersion σ2
old with the
same signiﬁcance of 1.35

new = 0.48σ2

10−3.

·

·

IV. POISSON PROCESS WITH KNOWN
BACKGROUND

The case of tremendous practical importance is when
the number n of observed events is distributed according
to the Poisson distribution

p(n; µ) =

µn
n!

e−µ

The experiment searching for a new phenomenon may

be a subject to background so that

 35

 30

 25

 20

 15

 10

 5

 0

 0

 30

 25

 20

 15

 10

 5

 0

 0

 2

 4

 6

 8

 10

 12

 14

 16

 20

 18
µb

FIG. 1: Signal with average strength µs ≥ µc
s can be detected
with corresponding probabilities of at least 50% 90% and 99%
at signiﬁcance 1.35 · 10−3 in the presence of known average
background µb.

µu
s

FC upper limit (most stringent)
FC upper limit (loosest)
99% power

 2

 4

 6

 8

 12

 10

µb

FIG. 2: The upper end µu
s of the 99% conﬁdence level inter-
val for µs from tables VIII, IX [5] can be anywhere between
the dashed and dotted lines. If the conﬁdence interval were
used to construct the exclusion region, the signals inside the
region which are below the solid line could be detected with
probability less than 99% at signiﬁcance 1.35 · 10−3.

0 is the average background rate and µs > 0.
where µb ≥
If the average background rate µb is known, the best
critical region against the stated alternative is con-
structed by

n

nc αc ≥

≥

∞

Xk=nc

p0(k, µb) = P (nc, µb)

where P (x, n) is complementary regularized incomplete
gamma function.

Thus,

if no evidence against the null hypothesis is
s on the values of µs cor-
βc) at signiﬁcance αc can

found, the demarcation point µc
responding to the power (1
be constructed by ﬁnding the value of µc

s such that:

−

(1

βc) =

−

∞

Xk=nc

p1(k, µb + µc

s) = P (nc, µb + µc
s)

p0(n; µb) =

e−µb p1(n; µb+µs) =

µn
b
n!

(µb + µs)n
n!

e−(µb+µs)

Figure 1 illustrates the situation for the signiﬁcance
10−3 and diﬀerent requested powers of the test.

of 1.35

·

It can be seen that even with zero average background
events expected, the signal can be reliably detected (with
99% probability) only if its average rate is above µs ≥
4.61. The surprisingly high value of the signal is due to
discrete nature of the Poisson distribution.

It might be interesting to visualize what would hap-
pen if the 99% conﬁdence interval [0; µu
s ] proposed in [5]
were used for the exclusion region construction. Because
the interval depends on the number of observed events,
the boundary µu
s may be anywhere between the dashed
and dotted lines on the ﬁgure 2. (The dotted line corre-
sponds to the most conﬁning interval when zero events is
observed while the dashed line represents the longest con-
ﬁdence interval obtainable with the left boundary ﬁxed
to zero. The ﬁgure is produced from the tables VIII and
IX from [5].) The values above the boundary µu
s would
be excluded with the conﬁdence of 99%. It is seen that
signals inside the exclusion region constructed based on
the 99% conﬁdence interval [5] which are below the solid
line will be detected with probability much smaller than
10−3.
99% at signiﬁcance 1.35

·

V. CONCLUSION

In this report we have considered a problem of what
can be stated regarding the parameter µ of alternative
hypothesis H1(µ) of presence of a new phenomenon when
no evidence against the null hypothesis H0 of absence
of the new phenomenon is found. We have proposed a
mathematical formulation of this problem and its solu-
tion within the framework of hypothesis tests theory [11].
We have also given reasons why the classical theory of
estimation [10] is not applicable in situations when the
origin of data is questioned.

Nevertheless, we recommend to continue to report the
classical conﬁdence intervals assuming that the sought for
new phenomenon exists for at least two reasons. First,
the conﬁdence intervals constructed now may be vali-

4

dated by a future experiment which will discover the ex-
istence of the new phenomenon. Second, the classical
conﬁdence interval provides information to future exper-
iments about what the value of the parameter might be.
However, we propose to discontinue the use of the clas-
sical conﬁdence intervals for construction of exclusion re-
gions when no evidence against the hypothesis of absence
of the new phenomenon is found. Instead, we propose to
construct the exclusion regions based on the power of
the test, since if the undiscovered process existed with
the parameter inside the exclusion region it would have
βc) or higher at sig-
been discovered with probability (1
niﬁcance αc. Other attractive features of the constructed
exclusion region are that less powerful experiments will
produce less conﬁning exclusion regions, the exclusion
regions do not shrink if the number of observed events
is less than the average expected background; the proce-
dure for exclusion region construction avoids problems at
physical boundaries on the parameter values and does not
exclude the values of the parameter for which the exper-
iment is insensitive. Also, the procedure of the exclusion
region construction outlined in this paper resolves the il-
lusory contradiction between the opposite results of two
independent observations made at the sensitivity level of
a detector.

−

It is proposed to call the detector sensitive if at the
speciﬁed level of signiﬁcance at least 50% power of the
test can be achieved.

Acknowledgments

This work is supported by the National Science
Foundation (Grant Numbers PHY-9901496 and PHY-
0206656), the U. S. Department of Energy Oﬃce of High
Energy Physics, the Los Alamos National Laboratory
LDRD program and the Los Alamos National Labora-
tory Institute of Nuclear and Particle Astrophysics and
Cosmology of the University of California.

[1] R. Abusaidi et al. Phys. Rev. Lett, 84:5699–5703, 2000.
[2] B. Armbruster et al. Phys. Rev. D, 65:112001, 2002.
[3] C. Athanassopoulos et al. Phys. Rev. C, 58:2489–2511,

[4] R. Bernabei et al. Phys. Lett. B, 424:195–201, 1998.
[5] G. J. Feldman and R. D. Cousins. Phys. Rev. D, 57:3873–

1998.

3889, 1998.

A480:763–770, 2002.

[8] O. Helene. Phys. Rev. D, 60:037901, 1999.
[9] F. James, L. Lyons, and Y. Perrin, editors. Proceedings
of the CERN Workshop on “Conﬁdence Limits”, 1999.
CERN 2000-005.

[10] J. Neyman. Philos. Trans. R. Soc. London, Series A,

236:333–380, 1937.

[6] Fermilab Workshop on “Conﬁdence Limits”, 2000.

[11] J. Neyman and E. S. Pearson. Philos. Trans. R. Soc.

http://conferences.fnal.gov/cl2k/.

[7] C. Giunti and M. Laveder. Nucl. Instrum. and Methods,

London, Series A, 231:289–337, 1933.

