6
0
0
2
 
n
u
J
 
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
6
0
0
6
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A Test for the Presence of a Signal

Wolfgang A. Rolke a

aDepartment of Mathematics, University of Puerto Rico - Mayag¨uez, Mayag¨uez,

PR 00681, USA,

Postal Address: PO Box 5959, Mayag¨uez, PR 00681,

Tel: (787) 255-1793, Email: wolfgang@puerto-rico.net

bDepartment of Physics, University of Puerto Rico - Mayag¨uez, Mayag¨uez, PR

Angel M. L´opez b

00681, USA

Abstract

channels.

Carlo

We describe a statistical hypothesis test for the presence of a signal based on the

likelihood ratio statistic. We derive the test for several cases of interest and also

show that for those cases the test works very well, even far out in the tails of the

distribution. We also study extensions of the test to cases where there are multiple

Key words: Likelihood ratio test, type I error probability, power of a test, Monte

Preprint submitted to Elsevier Science

29 February 2008

1 Introduction

In recent years much work has been done on the problem of setting limits

in the presence of nuisance parameters, beginning with the seminal paper by

Feldman and Cousins [1]. A fairly comprehensive solution of this problem was

given in Rolke, L´opez and Conrad [2]. In this paper we will study a related

problem, namely that of claiming a new discovery, say of a new particle or

decay mode. Statistically this falls under the heading of hypothesis testing.

We will describe a test derived in a fairly standard way called the likelihood

ratio test. The main contribution of this paper is the study of the performance

of this test. This is essential for two reasons. First, discoveries in high energy

physics require a very small false-positive, that is the probability of falsely

claiming a discovery has to be very small. This probability, in statistics called

the type I error probability α, is sometimes required to be as low as 2.87

10−7,

·

equivalent to a 5σ event. The likelihood ratio test is an approximate test, and

whether the approximation works this far out in the tail is a question that

needs to be investigated. Secondly, in high energy physics we can often make

use of multiple channels, which means we have problems with as many as 30

parameters, 20 of which are nuisance parameters. Again, what sample sizes

are needed to assure that the likelihood ratio test works here needs to be

ascertained.

2

2 Likelihood Ratio Test

We will consider the following general problem: we have data X from a distri-

bution with density f (x; θ) where θ is a vector of parameters with θ

Θ and Θ

is the entire parameter space. We wish to test the null hypothesis H0 : θ

Θ0

(no signal) vs the alternative hypothesis. Ha : θ

Θc

0 (some signal), where Θ0

∈

is some subset of Θ. The likelihood function is deﬁned by

∈

∈

and the likelihood ratio test statistic is deﬁned by

L(θ

x) = f (x; θ)

|

λ(x) =

supΘ0 L(θ
supΘ L(θ

x)
|
x)
|

Because L(θ

x)

0 and because the supremum in the numerator is taken

|

≥

over a subset of the supremum in the denominator we have 0

λ(x)

1.

≤

≤

Intuitively we can understand the statistic in the case of a discrete random

variable. In this case the numerator is the maximum probability of the ob-

served sample if the maximum is taken over all parameters allowed under the

null hypothesis. In the denominator we take the maximum over all possible

values of the parameter. The ratio of these is small if there are parameter

points in the alternative hypothesis for which the observed sample is much

more likely than for any parameter point in the null hypothesis. In this sit-

uation the we should then reject the null hypothesis. Therefore we ﬁnd the

likelihood ratio test to be: reject the null hypothesis if λ(x)

c, for some

≤

3

suitably chosen c, which in turn depends on the type I error probability α.

How do we ﬁnd c? For this we will use the following theorem: under some mild

regularity conditions if θ

Θ0 then

2 log λ(x) has a chi-square distribution as

∈

−

the sample size n

. The degrees of freedom of the chi-square distribution

→ ∞

is the diﬀerence between the number of free parameters speciﬁed by θ

Θ0

∈

and the number of free parameters speciﬁed by θ

Θ.

∈

A proof of this theorem is given in Stuard, Ord and Arnold [3] and a nice

discussion with examples can be found in Casella and Berger [4].

3 Some Speciﬁc Examples

3.1 A Counting Experiment with Background and Eﬃciency

We begin with a very common type of situation in high energy physics exper-

iments. After suitably chosen cuts we ﬁnd X events in the signal region, some

of which may be signal events. We can model X as a random variable with

a Poisson distribution with rate eµ + b where b is the background rate, µ the

signal rate and e the eﬃciency on the signal. We also have an independent

measurement Y of the background rate, either from data sidebands or from

Monte Carlo and we can model Y as a Poisson with rate τ b, where τ is the

relative size of the sidebands to the signal region or the relative size of the

Monte Carlo sample to the data sample, so that Y /τ is the point estimate of

4

the background rate in the signal region. Finally we have an independent mea-

surement of the eﬃciency Z, usually from Monte Carlo, and we will model Z

as a Gaussian with mean e and standard deviation σe. So we have the following

probability model:

X

P ois(eµ + b)

Y

P ois(τ b)

∼

∼

Z

N(e, σe)

∼

In this model µ is the parameter of interest, e and b are nuisance parameters

and τ and σe are assumed to be known. Now the joint density of X Y and Z

is given by

f (x, y, z; e, µ, b) =

(µ + b)x
x!

e−(µ+b) (τ b)y
y!

e−τ b

1

− 1
2
e

(z−e)2
σ2
e

2πσ2
e

q

Finding the denominator of the likelihood ratio test statistic λ means ﬁnding

the maximum likelihood estimators of e, µ, b. Taking the logarithm we have

log f (x, y, z; µ, b, e) = x log (eµ + b)

log(x!)

(eµ + b)+

−

−

y log(τ b)

log(y!)

(τ b)

−

−

−

1

2 log(2πσ2
e)

1
2

(z−e)2
σ2
e

−

and so

d

dµ log f (x, y, z; µ, b, e) = ex

e = 0

eµ+b −

d

db log f (x, y, z; µ, b, e) = x

1 + y

τ = 0

eµ+b −

b −

d

de log f (x, y, z; µ, b, e) = µx

µ + z−e
σ2
e

= 0

eµ+b −

We get

x
eµ+b = 1 and therefore the MLEs are given by

µ = x

y/τ,

b = y/τ

−

b

b

and

e = z.

b

5

We wish to test H0 : µ = 0 vs Ha : µ > 0, so under the null hypothesis we

have

and we ﬁnd

log f (x, y, z; 0, b, e) = x log (b)

log(x!)

b+

−

y log(τ b)

log(y!)

(τ b)

−

−

−

1

2 log(2πσ2
e)

1
2

(z−e)2
σ2
e

−

−

d

db log f (x, y, z; 0, b, e) = x

1 + y

τ = 0

b −

b −

d

de log f (x, y; 0, b, e) = z−e
σ2
e

= 0

which has the solutions

e = z. Now

1+τ and

b = x+y
e

e

( x+y
1+τ )/x!exp(− x+y

λ(x, y, z) = sup L(0,b,e|x,y,z)

=

f (x,y,z|

e)
b,
sup L(µ,b,e|x,y,z)= f (x,y,z|0,
e)
b,
µ,
e
e
b
b
b
/y!exp(−τ x+y
1+τ )
√2πσ2
− 1
2

1+τ )(τ x+y

1+τ )y

1

e
(z−z)2
σ2
e

1

e

√2πσ2

e

xx/x! exp(−x)yy/y! exp(−y)

− 1
2

e

(z−z)2
σ2
e

=

1+τ )x+y
( x+y
xxyy

τ y

One special case of this needs to be do be studied separately, namely the case

y = 0. In this case we can not take the logarithm and the maxima above have

to be found in a diﬀerent way. It turns out that the MLE’s are

µ = x,

b = 0

,

e = z, and under the null hypothesis we ﬁnd

b

we ﬁnd λ(x, 0, z) = (1 + τ )−x.

b

b

e = z. With this

1+τ and

b = x
e

e

First we note that the test statistic does no involve z, the estimate of the

eﬃciency. This is actually clear: the eﬃciency is for the detection of signal

events, but under the null hypothesis there are none. Of course the eﬃciency

6

will aﬀect the power curve: if e is small the observed x will be small and it

will be much harder to reject the null hypothesis.

Now from the general theory we know that

2 log λ(x, y, z) has a chi-square

−

distribution with 1 degree of freedom because in the general model there are

3 free parameters and under the null hypothesis there are 2. So if we denote

the test statistic by L(x, y) we get

L(x, y) =

2 log λ(x, y, z) =

−

2

x log(x) + y log(y)
h

−

(x + y) log

x+y
1+τ (cid:17) −

(cid:16)

y log(τ )

i

and we have L(X, Y )

χ2

1, approximately.

∼

Large values of L(x, y) indicate that the null hypothesis is wrong and should

be rejected. Such large values happen if x is much larger than y/τ but also

if x is much smaller. If we wished to reject the null hypothesis in both cases

we would use a rejection region of the form L(X, Y ) > c where c solves the

equation α = P (T1 > c). Here T1 ∼
1 degree of freedom. We will use the notation c = qχ2

χ2

1 is a chi-square random variable with

1(1

−

α) for the 1

α

−

quantile of a chi-square distribution with 1 df. Here, though, will only reject

7

the null hypothesis if we also have x > y/τ, and therefore we ﬁnd c as follows:

α = P (L(X, Y ) > c and X > Y /τ ) =

P (L(X, Y ) > c and X > Y /τ

X > Y /τ)P (X > Y /τ) + P (L(X, Y ) and X > Y /τ X < Y /τ )P (X <

|

P (L(X, Y ) > c

X > Y /τ )

|

1
2 + 0 = P (T1 > c)

1
2

·

·

so we will reject the null hypothesis if L(x, y) > qχ2

1(1

−

2α).

The situation described here has previously been studied in Rolke, L´opez and

Conrad [2] in the context of setting limits. They proposed a solution based

on the proﬁle likelihood. This solution is closely related to the test described

here. In fact it is the conﬁdence interval one ﬁnds when inverting the test

described above.

3.2 A Counting Experiment with Gaussian Background

Our next model is as follows: again we have X observations in the signal region

which we model as X

P ois(µ + b). Now, though, the background is modeled

as a Gaussian with Y

N(b, σb). This is often an appropriate model in high

energy physics, for example if the background estimate was found via Monte

∼

∼

Carlo. This model also allows us to incorporate systematic errors. We will not

include any eﬃciency here, as above the eﬃciency would not appear in the

8

test statistic anyway. We ﬁnd:

f (x, y; µ, b) =

(µ + b)x
x!

e−(µ+b)

1
2πσ2
b

exp(

(y

1
2

−

−
σ2
b

b)2

)

q

and so

log f (x, y; µ, b) = x log (µ + b)

log(x!)

(µ + b) + log

−

−

1
2πσ2
b

1
2

−

(y

b)2

−
σ2
b

Taking derivatives we ﬁnd the MLE’s to be

µ = x

y and

b = y. Under

q

−

b

b

H0 : µ = 0 we have

log f (x, y; 0, b) = x log (b)

log(x!)

b + log

−

−

1
2πσ2
b

1
2

−

(y

b)2

−
σ2
b

q

and now the maximum is found at

1
y
2 (cid:18)

−

b =

e

σ2

b +

(y

q

−

b)2 + 4σ2
σ2
bx

(cid:19)

With these the test statistic turns out to be

b)2
L(x, y) = (y−
σ2
b −
e

2x log(

b/x)

2x + 2

b

−

e

e

The rejection region of this test is the same as the one given above.

3.3 Multiple Channels

In high energy physics we can sometimes make use of multiple channels.

There are a number of possible extensions from one channel. We will be-

gin by discussing the following model: there are k channels and we have

Xi ∼

P ois(µi + bi), Yi ∼

P ois(τ ibi), i = 1, .., k, all independent. We will

9

discuss two ways to extend the methods above to multiple channels, both

with certain advantages and disadvantages.

3.3.1 Method 1: (Full LRT)

Let x = (x1, .., xk), y = (y1, .., yk), b = (b1, .., bk), µ = (µ1, .., µk), τ =

(τ 1, ..τ k), then the joint density is given by

f (x, y; µ, b) =

(µi + bi)xi
xi!

e−(µi+bi) (τ ibi)yi
yi!

e−τ ibi

k

Qi=1

and

log f (x, y

µ, b) =

|

k
i=1 xi log (µi + bi)

log(xi!)

(µi + bi) + yi log(τ ibi)

log(yi!)

(τ ibi)

−

−

−

−

P

The MLEs are given by

and we ﬁnd

b

bi = xi+yi
1+τ i
e

.

µi = xi−

yi/τ i and

bi = yi/τ i .Under H0 : µ1 = ..µk = 0
b

b)
λ(x, y) = f (x,y;0,
b)
µ,
f (x,y;
e
b

=

xi
xi+yi
1+τ i (cid:17)

(cid:16)

b
xi+yi
/xi! exp (−
1+τ i
xi
i /xi! exp (−xi)y

)
(cid:16)

x

τ i

yi

xi+yi
1+τ i (cid:17)
yi
i /yi! exp (−yi)

/yi! exp (−τ i

xi+yi
1+τ i

)

=

k

Qi=1

xi+yi

τ

yi
i

xi+yi
1+τ i (cid:17)
xi
i y
x

yi
i

(cid:16)

k

(cid:20)

Xi=1

so

−

2 log λ(x, y) = 2

xi log(xi) + yi log(yi)

(xi + yi) log

xi + yi
1 + τ i (cid:19) −

(cid:18)

yi log(τ i)

(cid:21)

−

10

so the test statistic Lk is given by

Lk(x, y) =

L(xi, yi)I(xi > yi/τ i)

k

Xi=1

where I is the indicator function, that is I(x > y) = 1 if x > y, and 0 otherwise.

In other words the test statistic in the multiple channel case is simply the sum

of the test statistics for each channel separately. This was shown here for the

case where Y is modeled as a Poisson but exactly the same holds when Y is

a Gaussian as well as for the case y = 0.

The test is then as follows: we reject H0 if Lk(x, y) > c where c = qχ2

k(1

α)

−

because there are 2k parameters under the full model and k parameters under

the null hypothesis. Again, though we need to adjust c because we will only

use channels where x > y/τ . For example, if we have 2 channels, there is a

25% chance what in neither channel x > y/τ , there is a 50% chance that

in exactly one channel x > y/τ and a 25% chance that x > y/τ in both

channels. If there are k channels the probability of exactly m channels with

x > y/τ is given by the probabilities from a binomial random variable as

p(m, k) =

0.5m(1

0.5)k−m =

0.5k. Therefore the critical value c is

k
m(cid:17)
(cid:16)

−

k
m(cid:17)

(cid:16)

found by solving the equation

α =

p(m, k)

P (Tm > c)

·

k

Xm=1

χ2

m. The solution to this equation has to be found numerically if

where Tm ∼
k
2.

≥

11

3.3.2 Method 2: (Max LRT)

Here we will use the following test: reject H0 if M = maxi{
yi/τ i}
events in any one channel. For this method the critical value c is found using

> c, that is, we claim a discovery if there is a signiﬁcant excess of

L(xi, yi)I(xi >

Bonferroni’s method. Say we want the test to have a type I error probability

α. Then:

α = P (reject H0 |

H0 true)=

P (M > c

µ = 0) =

|

P (maxi {

L(Xi, Yi) > c

µ = 0) =

} |

1

P (maxi{

−

L(Xi, Yi)

c

µ = 0) =

≤

|

P (L(Xi, Yi)

c for all i = 1, .., k

µ = 0) =

≤

|

1

−

1

n

−

Qi=1

P (L(Xi, Yi)

c

µ = 0) =

≤

|

So if each channel is tested using the type I error probability αI then the

overall type I error will be α = 1

(1

αI)k. Solving this for αI we ﬁnd

−

−

αI = 1

k√1

−

−

α and so if we test each channel using αI we will achieve an

overall type I error α. Therefore we reject H0 if M > c, where c = qχ2

1(1

−

As we shall see soon, which of these two methods performs better depends on

2(1

k√1

α)).

−

−

the experiment.

12

4 Multiple Channels - Same Signal Rate

The extension to multiple channels discussed in the last chapter assumes pos-

sibly diﬀerent signal rates in each channel. Another extension which could be

of interest is to a situation where it is a-priori known that if there is a signal

it will have the same rate in all the channels. The corresponding probability

models are as follows: Xi ∼
independent or Xi ∼
The MaxLrt test for this model is exactly the same as the one above. For

N(bi, σi), i = 1, .., k, all independent.

P ois(µ + bi), Yi ∼

P ois(µ + bi), Yi ∼

P ois(τ ibi), i = 1, .., k, all

the FullLrt model the numerator of the test statistic is the same as for the

diﬀerent signal rates model. Calculation of the denominator, which is equiva-

lent to the calculation of the maximum likelihood estimators, now has to be

done numerically, for example with an optimization routine such as MINUIT.

Moreover, the distribution of the test statistics, and therefore the calculation

of the critical values c can no longer be done analytically. Because for large

enough background rates this distribution does not depend on the true pa-

rameters the critical values can be found via Monte Carlo. We give a table

with critical values in the appendix. These critical values are based on 108

simulation runs.

13

5 Performance

How do the above tests perform? In order to be a proper test they ﬁrst of

all have to achieve the nominal type I error probability α. If they do we can

then further study their performance by considering their power function β(µ)

given by

β(µ) = P (reject H0|

true signal rate is µ)

Of course we have α = β(0). β(µ) gives us the discovery potential, that is the

probability of correctly claiming a discovery if the true signal rate is µ > 0.

β(µ) can generally be found via Monte Carlo. In some of the cases described

above, though, we can actually ﬁnd them by direct calculation. Say we have

X

P ois(eµ + b), Y

P ois(τ b) and the nominal type I error probability is

∼

∼

α. Then we reject H0 if x > y/τ and L(x, y) > c Now

β(µ) = P (reject H0 |

true signal rate is µ)=

P (L(X, Y ) > c) =

∞
y=0

∞
x=y I (L(x, y) > c) Pµ+b(X = x)Pτ b(Y = y) =

P

P

∞
y=0 Pτ b(Y = y)

∞
x=ψ(y) Pµ+b(X = x) =

P

∞
y=0 Pτ b(Y = y)Pµ+b(X

ψ(y)

1)

−

≤

P

P

where ψ(y) = minx≥y {

L(x, y) > c

.

}

14

First we will study the true type I error probability as a function of the back-

ground rate. In ﬁgure 1 we calculate α (expressed in sigma’s) for background

rates ranging from b = 5 to b = 150. Here we have used τ = 1. and α cor-

responding to 3σ, 4σ and 5σ. It is clear that even for moderate background

rates (say b > 30) the true type I error is basically the same as the nominal

one. Of course in real life we don’t know the true b but if we observe say 50

events in the data sidebands (at τ = 1) we can be reasonably sure that in fact

b > 30.

In ﬁgure 2 we have the power curves for b = 100, τ = 1, µ from 0 to 150

and α corresponding to 3σ, 4σ and 5σ. This clearly shows the ”penalty” of

requiring a discovery threshold of 5σ: at that level the true signal rate has to

be 83 just to have a 50-50 chance of making a discovery. If 3σ is used a rate

of 47 is suﬃcient, and for 4σ it is 65.

For the case Y

N(b, σb) exact calculation of β(µ) is still possible but some-

∼

what slower because it involves numerical integration of dozens of integrals.

In ﬁgure 3 we calculated the true type I error α when the background rate

ranges from b = 10 to b = 100 and σb = √b. It is clear that even for small

background rates the true type I error is basically the same as the nominal

one, even at 5σ.

Let us consider the case of multiple channels. At least for the case of 2 channels

we can still calculate β(µ1, µ2) exactly, although this now requires evaluation

15

of four nested loops and is therefore fairly slow. For situations with more than

2 channels we will have to use Monte Carlo to calculate β (µ). In ﬁgure 4 we

have the case b1 = b2 = 10 : 100 and τ 1 = τ 2 = 1 and using both methods.

We see that both achieve the nominal type I error probability α, even out at

5σ.

In ﬁgure 5 we have the results of the following simulation: b1 = .. = bk = 50,

all τ i = 1 and k = 1, ..10. As we see the Full Lrt method becomes increasingly

conservative whereas the Max Lrt method has a true α consistently close to

the nominal one. For more than 4 channels and 5σ the points for the FullLrt

method are missing because the true type I error probability is smaller than

10−10 and would take to long to calculate.

In ﬁgure 6 we have the power curves for the following situation: we have 10

channels with b1 = .. = b10 = 50, all τ i = 1 and µ1 = .. = µ10 = µ going

from 0 to 50. So we have equal signal rates in all the channels. Here Full Lrt

performs better than Max Lrt, for example at the 3σ level it needs about a

signal rate of about 15 to have a 90% chance for a discovery whereas Max Lrt

needs a signal rate of about 30.

In the next simulation we again have b1 = .. = b10 = 50, all τ i = 1. Now

µ2 = .. = µ10 = 0 and µ1 goes from 0 to 100. In other words in 9 of the 10

channels there is no signal, whereas there is a signal in one channel. Now it

is Max Lrt which does better than Full Lrt. This is not surprising because

16

the maximum makes this method more sensitive to the ”strongest” channel

whereas the sum makes Full Lrt more sensitive to a ”balance” of the channels.

In practice, of course, a decision which method to use has to be made before

any data is seen, but the decision can be made based on what the researcher

expects to ﬁnd, signals in many channels (use Full Lrt) or signals in just a few

channels (use Max Lrt). If there is reason to expect one or the other we would

recommend Max Lrt because its true type I error stays closer to the nominal

one as the number of channels goes up.

6 Summary

We have discussed a hypothesis test for the presence of a signal. For the case

of a Poisson distributed signal with a background that has either a Poisson or

a Gaussian distribution we have carried out the calculations and done an ex-

tensive performance study. We have shown that the test achieves the nominal

type I error probability α, even at a 5σ level. We extended the test to the case

of multiple channels with two possible tests and showed that both achieve the

nominal α. Either one or the other has better performance depending on the

speciﬁc experiment.

17

References

[1] R.D. Cousins, G.J. Feldman, “A Uniﬁed Approach to the Classical Statis-

tical Analysis of Small Signals”, Phys. Rev, D57, (1998) 3873.

[2] W.A. Rolke, A. L´opez and J. Conrad, “Limits and Conﬁdence Intervals in

the Presence of Nuisance Parameters”, Nuclear Instruments and Methods

A, 551/2-3, 2005, pp. 493-503, physics/0403059

[3] A. Stuart, J.K.Ord and S. Arnold, “Advanced Theory of Statistics, Volume

2A: Classical Inference and the Linear Model ”, 6th Ed., London Oxford

[4] G. Casella and R.L. Berger, “Statistical Inference”, 2nd Ed., Duxbery

University Press (1999)

Press, (2002)

18

7 Appendix

Critical values c for FullLrt Method - Diﬀerent Signal Rates

Channels

3σ

4σ

5σ

Channels

3σ

4σ

5σ

1

2

3

4

5

6

7

8

9

9.00

16.00

25.00

11

22.38

31.64

42.69

11.17

18.55

27.87

12

23.38

32.80

43.99

12.86

20.54

30.12

13

24.36

33.93

45.26

14.32

22.26

32.07

14

25.32

35.03

46.50

15.65

23.82

33.85

15

26.27

36.12

47.72

16.90

25.28

35.50

16

27.20

37.18

48.91

18.08

26.66

37.06

17

28.12

38.23

50.08

19.21

27.97

38.55

18

29.02

39.26

51.23

20.30

29.23

39.98

19

29.92

40.28

52.37

10

21.35

30.46

41.36

20

30.80

41.28

53.49

19

Critical values c for FullLrt Method

Same Signal Rates

Channels

3σ

4σ

5σ

1

2

3

4

5

6

9.00

16.00

25.00

10.3

17.3

26.5

11.2

18.4

27.7

12.0

19.1

28.4

12.7

19.9

28.8

13.4

20.6

29.8

20

Fig. 1. True Type I error α for the case of a Poisson distibuted background with

rate b varying from 5 to 150 and τ = 1. Curves for the three nominal type I errors

corresponding to 3σ, 4σ and 5σ are shown.

21

Fig. 2. Power of the test when the background rate b = 50 with τ = 1.

22

Fig. 3. True Type I error α for the case of a Gaussian distibuted background and

σb = √b.

23

Fig. 4. True Type I error probability for the case of two channels. Background is

modeled as Poissons with the same rate and with τ 1 = τ 2 = 1.

24

Fig. 5. True type I error probability as a function of the number of channels. We

have between 2 and 9 channels, b1 = .. = bk = 50, all τ i = 1. For the nominal

5σ level the true type I error of the Full Lrt method is less than 10−10 and is not

shown.

25

Fig. 6. Power of the two tests in the case of 10 channels with b1 = .. = b10 = 50, all

τ i = 1 and µ1 = .. = µ10

26

Fig. 7. Power of the two tests in the case of 10 channels with b1 = .. = b10 = 50, all

τ i = 1. µ2 = .. = µ10 = 0 and µ1 goes from 0 to 100.

27

5sigma
4sigma
3sigma

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
x
x

x
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
x
x
x
x

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

i

)
a
m
g
s
 
f
o
 
s
t
i
n
u
 
n
i
(
 
y
t
i
l
i

b
a
b
o
r
P

 
r
o
r
r

E

 
I
 
e
p
y
T
 
e
u
r
T

5
.
5

0
.
5

5
.
4

0
.
4

5
.
3

0
.
3

5
.
2

x

x

x
x

x
x

x
x
x
x

x
x
x

0

50

100

150

Background Rate

5sigma
4sigma
3sigma

t
s
e
T
 
e
h
t
 
f
o
 
r
e
w
o
P

0
.
1

8
.
0

6
.
0

4
.
0

2
.
0

0
.
0

0

50

100

150

Signal Rate

i

)
a
m
g
s
 
f
o
 
s
t
i
n
u
 
n
i
(
 
y
t
i
l
i

b
a
b
o
r
P

 
r
o
r
r

E

 
I
 
e
p
y
T
 
e
u
r
T

0
.
6

5
.
5

0
.
5

5
.
4

0
.
4

5
.
3

0
.
3

5
.
2

5sigma
4sigma
3sigma

x

x

x x x x x x x x x x x x x x x x x

x

x x x x x x x x x x x x x x x x x x

x x x x x x x x x x x x x x x x x x x

20

40

60

80

100

Background Rate

i

)
a
m
g
s
 
f
o
 
s
t
i
n
u
 
n
i
(
 
y
t
i
l
i

b
a
b
o
r
P

 
r
o
r
r

E

 
I
 
e
p
y
T
 
e
u
r
T

0
.
6

5
.
5

0
.
5

5
.
4

0
.
4

5
.
3

0
.
3

5
.
2

x
o

Full Lrt
Max Lrt

5sigma
4sigma
3sigma

o o o o o o o o o o o o o o o o o o
x x x x x x x x x x x x x x x x x x x
o

o o o o o o o o o o o o o o o o o o o
x x x x x x x x x x x x x x x x x x x

o o o o o o o o o o o o o o o o o o o
x x x x x x x x x x x x x x x x x x x

20

40

60

80

100

b1(=b2)

o

x

x
o

i

)
a
m
g
s
 
f
o
 
s
t
i
n
u
 
n
i
(
 
y
t
i
l
i

b
a
b
o
r
P

 
r
o
r
r

E

 
I
 
e
p
y
T
 
e
u
r
T

0
.
6

5
.
5

0
.
5

5
.
4

5
.
3

5
.
2

x
o

Full Lrt
Max Lrt

5sigma
4sigma
3sigma

x
o

x
o

x
o

o
x

o
x

o

x

x
o

0
.
4

o
x

o
x

x
o

o
x

o
x

o
x

x
o

0
.
3

o
x

x
o

x
o

x
o

o
x

o
x

o
x

o
x

2

3

4

5

6

7

8

9

Number of Channels

r
e
w
o
P

0
.
1

8
.
0

6
.
0

4
.
0

2
.
0

0
.
0

x
o

Full Lrt
Max Lrt

5sigma
4sigma
3sigma

x

o
x
o
x
o

10

x
o
x
o
x
o

o
x
o
o
x
x

0

x
x
x
o
o

o

x
x
x
o

o

o

x
x
x
o

o

o

x
x
x
o

o

o

x
x

x

o

o

o

x
x
x

o

o

o

x

x

x
o

o
o

20

x

x

o

x
o
o

30

40

50

Signal Rate

r
e
w
o
P

0
.
1

8
.
0

6
.
0

4
.
0

2
.
0

0
.
0

x
o

Full Lrt
Max Lrt

5sigma
4sigma
3sigma

o

x

o

o o o o o o
x x x x x
o o o o
x
o
x
o
x
o
x
o
o

x

x

x

o

x

x

o

x

o

x

o

o

x

o

x

o

x

o

x

o

o

x

o

x

o

x

o

x

x

o

x

o

x

x

o

x

x

x

o

x

x

o

x

o

o

x

x

o

o

x

o
o
x
x
o
o
x x x x x x x x
x x x x x
o o o o o o o o o
x x x x x x x x x x
o o o o
o o o o o o

o

0

20

40

60

80

100

Signal Rate

