6
0
0
2
 
t
c
O
 
1
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
1
8
0
0
1
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

High-Order Correlation Funtions

of Binary Multi-Step Markov Chains

V. N. Karazin Kharkov National University, 4 Svoboda Sq., Kharkov 61077, Ukraine

S. S. Apostolov, Z. A. Mayzelis

O. V. Usatenko

, V. A. Yampol'skii

∗

A. Ya. Usikov Institute for Radiophysis and Eletronis

Ukrainian Aademy of Siene, 12 Proskura Street, 61085 Kharkov, Ukraine

Two approahes to studying the orrelation funtions of the binary Markov sequenes are on-

sidered. The (cid:28)rst of them is based on the study of probability of ourring di(cid:27)erent (cid:17)words(cid:17) in

the sequene. The other one uses reurrene relations for orrelation funtions. These methods are

applied for two important partiular lasses of the Markov hains. These lasses inlude the Markov

hains with permutative onditional probability funtions and the additive Markov hains with the

small memory funtions. The exiting property of the self-similarity (disovered in Phys. Rev. Lett.

90, 110601 (2003) for the additive Markov hain with the step-wise memory funtion) is proved to

be the intrinsi property of any permutative Markov hain. Appliability of the orrelation funtions

of the additive Markov hains with the small memory funtions to alulating the thermodynami

harateristis of the lassial Ising spin hain with long-range interation is disussed.

PACS numbers: 05.40.-a, 02.50.Ga, 87.10.+e

I.

INTRODUCTION

The problem of long-range orrelated random symboli systems (LRCS) has been under study for a long time in

many areas of ontemporary physis [1, 2, 3, 4, 5, 6℄, biology [7, 8, 9, 10, 11, 12℄, eonomis [8, 13, 14℄, linguistis [15,

16, 17, 18, 19℄, et. Among the ways to get a orret insight into the nature of orrelations of omplex dynami

systems, the use of the multi-step Markov hains is of great importane beause it enables onstruting a random

sequene with the presribed orrelated properties in the most natural way [19, 20, 21℄. Also the additive Markov

hains with small memory funtions are of interest for the non-extensive thermodynamis of Ising spin hains [22, 23℄.

The multi-step binary Markov hain is haraterized by the onditional probability of the defined symbol ai (for
example, ai = 1) ourring after previous symbols within the memory length N , i.e., after N -word. We define the
L-word TL , or the word of length L, as the set of L sequential symbols. The Markov hain an be easily onstruted by

the sequential generation of symbols using the presribed onditional probability funtion. The onditional probability

points to the diret assoiation between the symbols. At the same time, the orrelation funtions desribe the impliit

interation between the symbols. Correlation funtions of all orders determine ompletely every statistial property

of any random sequene. So, the problem of finding the orrelation funtions of high orders is essential. The aim of

the paper is to find the orrelation funtions of different orders of the binary Markov hain using two approahes and

to examine their properties.

The paper is organized as follows. The seond Setion desribes the method of alulating statistial harateristis

of the Markov hain via the onditional probability funtion. Here the property of the self-similarity of the orrelated

random sequenes is also disussed. The third Setion is devoted to a method for finding the orrelation funtions

using reurrene relations for them. The appliations of the proposed general algorithms to some onrete lasses of

hains are presented.

II.

DIRECT METHOD FOR CALCULATING STATISTICAL CHARACTERISTICS OF THE

MARKOV CHAIN

In this setion, we desribe a diret method of finding following harateristis of the N -steps Markov hains: the
probability P (TN ) of the N -words ourring, the probability P (TL) of ourring the words of an arbitrary length L,

and the high-order orrelation funtions.

∗

usatenkoire.kharkov.ua

2

(1)

(2)

(3)

(4)

(5)

It is known that all statistial properties of Markov sequene are determined ompletely by the onditional proba-

bility funtion. Along with this funtion, it is onvenient to employ the probabilities P (TN ) of the N -words ourring.
All other harateristis of the hain an be found using these probabilities. Though the alulation of P (TN ) is

quite a hallenge in the general ase, we sueed in obtaining the analytial results for some partiular ases (see

Subse. II C).

The N -step Markov hain is a sequene of random symbols ai , i

}. It possesses the
following property: the probability of symbol ai to have a ertain value, under the ondition that the values of all
previous symbols are given, depends on the values of N previous symbols only,

−

−

∈

{

Z =

. . . ,

2,

1, 0, 1, 2, . . .

We refer to N as the memory depth.

P (ai = a

. . . , ai−2, ai−1) = P (ai = a

|

ai−N , . . . , ai−2, ai−1).
|

In this paper we onsider binary hains only, but some results an be generalized to non-binary sequenes as well.

A. Probabilities of the

-words ourring

N

We start examining the statistial properties of the Markov hains with searhing the probabilities of the N -words

ourring. There are 2N

different N -words in the arbitrary Markov hain whih is haraterized by 2N

probabilities

of these words ourring. They an be found using evident formulas of the probability theory,

Here A

B means that events A and B our simultaneously and event B is opposite to the event B . Eqs. (2), (3)

∩

yield the following equation,

P (a1a2 . . . aN ) =

aa1 . . . aN −1)P (aa1 . . . aN −1).

P (aN |

Xa=0,1

This equation, being written for all possible values of symbols a1, . . . , aN , along with the normalization requirement,

P (A) = P (A

B) + P (A

B),

P (A

∩
B)P (B).
B) = P (A
|

∩

∩

P (a1a2 . . . aN ) = 1,

Xai=0,1
i=1,...,N

is in fat the set of linear equations. From this set, one an obtain all sought probabilities P (TN ). Though set (4), (5)
ontains 2N + 1 equations, it has a single solution beause one of Eqs. (4) is a linear ombination of others.

B. Probabilities of arbitrary words ourring and orrelation funtions

Using Eq. (2) we an alulate the probability P (TL) with L < N by reduing the N -words to the L-word

(a1a2 . . . as),

P (a1a2 . . . aL) =

P (a1a2 . . . aN ),

L < N.

(6)

Xai =0,1
i=L+1,...,N

This equation represents the probability of the L-word ourring as the average of the probabilities to have the
N -word ontaining this L-word. It is possible to redue the N -word to the shorter L-word by summing over different
sets of symbols at the left and right edges of the N -word.

The word of length L greater than N an be presented as the ombination of the word of length N and (L

symbols following after it. Aording to the definition of the Markov hain, eah of these (L
on a ertain value with the probability depending on the preedent N -word. The (L

N )
N ) symbols an take
N )-fold use of Eq. (3) yields

−

−

−

the following equation,

P (a1a2 . . . aL) = P (a1a2 . . . aN )

arar+1 . . . aN +r−1),

L > N.

(7)

L−N

Yr=1

P (aN +r|

Let us define a orrelation funtion of the sth order:

Ks(i1, i2, . . . , is) = (ai1 −

¯ai1 )(ai2 −

¯ai2 ) . . . (ais −

¯ais),

where · · · is the statistial average over the ensemble of hains. We onsider ergodi hain. Aording to the Markov

theorem (see, e.g., Ref. [24℄), this property is valid for the homogenous Markov hains if the onditional probability

does not take on values 0 and 1. In this ase averaging over the ensemble of hains and over the hain oinide.

Formally, funtion Ks depends on s arguments (s different indexes of the symbols), but we do onsider homogenous
1) arguments, i.e., the distanes between the indexes,

Markov hains. Therefore, orrelation funtion Ks depends on (s
i2, . . . , rs−1 = is −
r1 = i2 −
Ks(r1, r2, . . . , rs−1) = (a0 −

i1, r2 = i3 −

¯a)(ar1 −

−

is−1 . Its definition is written as

¯a)(ar1+r2 −

¯a) . . . (ar1+...+rs−1 −

¯a).

Here ¯a is the average number of unities in the sequene and notation · · · is the statistial average over the hain,
1
2M + 1

f (ar1, . . . , ar1+...+rs) = lim
M→∞

f (ai+r1 , . . . , ai+r1+...+rs).

M

(10)

Xi=−M

Introduing the notation,

R0 = 0,

Rk =

ri,

di = ai −

¯a,

k

Xi=1

we rewrite definition (9) of the orrelation funtion,

Ks(r1, r2, . . . , rs−1) =

dR0dR1 . . . dRs−1P (aR0 aR1 . . . aRs−1).

Now we an omplement the set of symbols aR0, aR1 , . . . , aRs−1 with the symbols between them. Finally we have

the following formula,

Ks(r1, r2, . . . , rs−1) =

dR0 dR1 . . . dRs−1P (a0a1 . . . aRs−1).

(13)

=0,1

XaRi
i=0,...,s−1

Xai =0,1
i=0,...,Rs−1

Here probabilities P (a0a1 . . . aRs−1) should be alulated using Eqs. (6) or (7).

C. Permutative Markov hains

Solving linear system (4), (5) for the general ase is a hallenging problem. Here we demonstrate the appliation of

the desribed method to a ertain lass of the Markov hains. We assume that the onditional probability funtion

of the hain under onsideration is independent of the order of symbols in the previous N -word. We refer to suh

sequenes as the permutative Markov hains.

1. Probabilities of word ourring in the permutative Markov hain

It

is

onvenient

to introdue a new abbreviated notation for

the

onditional probability funtion

a1a2 . . . aN ) = pk(aN +1). Here k = a1 + a2 + . . . + aN is the number of unities in N -word (a1a2 . . . aN ).

P (aN +1|
Besides, we define pk(1) as pk .

Now we seek the solution of system (4), (5) in the form

bN (k) = bN (a1 + a2 + . . . + aN ) = P (a1a2 . . . aN ).

In other words, the probability of the N -word ourring depends on the number of unities in this N -word only. Then

Eq. (4) an be rewritten as the following reurrene relation,

bN (k) = pk−1bN (k

1) + pkbN (k).

−

3

(8)

(9)

(11)

(12)

(14)

(15)

The solution of this equation is

Here probability bN (0) an be obtained from Eq. (5),

The probability P (a1a2 . . . aN ), Eq. (14), does not depend on the order of symbols in N -word (a1a2 . . . aN ). From
Eq. (6) and the above statement it follows that the probability P (TL) of a short word (with L < N ) ourring is
likewise independent of the order of symbols in this word. Denoting this probability by bL(k) = bL(a1 +a2 +. . .+aL) =
P (a1a2 . . . aL) we arrived at the following formula,

The probability of the long L-word (with L > N ) ourring does depend on the order of the symbols in this word.

Using Eq. (7) we have

Here qi = ai+1 + ai+2 + . . . + ai+N . Equations (16)-(18) are the generalization of results earlier obtained in [21, 25℄

for the additive binary Markov hain with the step-wise memory funtion.

Here we present analytial results from the alulation of the orrelation funtions of arguments r1, . . . , rs−1 satis-
fying the ondition r1 + . . . + rs−1 < N . For this purpose we express the fration of unities in the hain using Eq. (18),

For the permutative Markov hains under onsideration, the orrelation funtion of arguments r1, . . . , rs−1 depends
on their number s only. Equation (13) yields

bN (k) = bN (0)

k

Yr=1

pr−1
pr
1

.

−

bN (0) =

N

k

Ck
N

(cid:16)

Xk=0

Yr=1

−1

,

pr−1
1

−

pr (cid:17)

Ck

n =

=

k!(n

k)!

Γ(k + 1)Γ(n

k + 1)

.

Γ(n + 1)

−

n!

−

bL(k) =

Cm

N −LbN (k + m).

N −L

Xm=0

P (a1a2 . . . aL) = bN (q0)

pqr−1 (aN +r).

L−N

Yr=1

2. Correlation funtions

a = b1(1) =

bN (k)Ck−1
N −1.

N

Xk=1

Ks(r1, r2, . . . , rs−1) = Ks =

bN (k)SN (k, s, a),

N

Xk=0

SN (k, s, ¯a) =

min{s,k}

Xj=0

¯a)s−jCk−j

N −jCj
s .

(
−

pk =

ν + µ

1
2 −

2k
N −

(cid:18)

,

1

(cid:19)

In partiular, the binary orrelation funtion K2(r) of any permutative hain is onstant for the values of arguments
less than the memory depth: K2(r) = K2,

r < N .

If we apply all derived formulas to the additive Markov hain with the step-wise memory funtion,

4

(16)

(17)

(18)

(19)

(20)

(21)

(22)

(23)

we get the orrelation funtions of order s,

Ks =

Γ(n1 + n2)
Γ(n1)

¯a)s−kCk
s

(
−

Γ(n1 + k)
Γ(n1 + n2 + k)

.

s

Xk=0

Here

¯a =

n1
n1 + n2

, n1 =

N (1

−

2(µ + ν))
4µ

, n2 =

N (1

−

2(µ
4µ

ν))

.

−

For s = 2 we reover the results previously obtained in [21, 25℄ for the binary orrelation funtion K2 .

D. Self-similarity of the permutative Markov hain

In this subsetion we point out an interesting property of the permutative Markov hains, namely, their self-

similarity. The disussion of this issue for the step-like memory funtion is presented in paper [25℄.

Let us redue the N -step Markov sequene by regularly (or randomly) removing some symbols and introdue the

deimation parameter λ = N ∗/N, 1/N < λ < 1, whih represents the fration of symbols kept in the hain.

Due to approahment of symbols in the sequene after the deimation proedure, the binary orrelation funtion

K2(r) transforms into

K ∗

2 (r) = 


(1
∞

r/λ
− {
}
K2(r + l)Cl

r/λ
{
}
λ)lλr,

l+r−1(1

−

)K2([r/λ]) +

K2([r/λ] + 1),

Pl=0

regular deimation,

random deimation,

(26)

x
}
The orrelation funtion K2(r) of the permutative Markov hain is equal to onstant value K2 with arguments
1)
1)


where [x] is the maximal integer number less than x and {
r 6 N
2 (r) at r 6 λ(N
take on the same value K2 . In the ase of the random deimation we have only an exponentially small (at N
differene between the orrelation funtion K ∗
2 (r) and value K2 ,

1. Aording to Eq. (26) (regular deimation), the values of the orrelation funtion K ∗

−
≫

= x

[x].

−

−

K ∗
|

2 (r)

K2|

−

6

A
√¯λN

exp

a(¯λ, λ)N

r = ¯λN,

¯λ < λ.

−

(cid:0)

,
(cid:1)

Here the new funtion a(¯λ, λ) and onstant A are introdued,

a(¯λ, λ) = ¯λ ln

¯λ
λ (cid:19)

(cid:18)

+ (1

¯λ) ln

−

¯λ
λ (cid:19)

1
1

(cid:18)

−
−

> 0,

A =

e
√π

K2|
|
(cid:0)

+ max
r>N |

.

K2(r)
|
(cid:1)

Thus, the orrelation funtion of the deimated sequene is onstant (or asymptotially onstant) at the region

r < N ∗

. This property is referred to as the self-similarity.

The self-similarity is the intrinsi property of the permutative Markov hains. It is possible to show that, in the

general ase, the onditional probability funtion of the deimated N -step Markov sequene is of infinite memory

depth. This is beause its onditional probability is (cid:17)blurred(cid:17) by the deimation proedure and beomes dependent

on all previous symbols.

with a onstant binary orrelation funtion K2(r) at r < N ,

So, the self-similarity is the property of the binary orrelation funtion only and inheres in all random sequenes

K2(r) = K2, 1 6 r < N

⇒ Self-similarity.

III. CORRELATION FUNCTIONS AND CHARACTERISTIC EQUATIONS

In this Setion, we deal with the reurrene relations to find the orrelation funtions. In Subsetion A we show that

these relations yield the expliit expression for the orrelation funtions via the roots of the harateristi equations.

Subsetion B is devoted to appliations of this method. The last Subsetion ontains some generalizations of the

above-mentioned reurrene relations.

The proedure of finding the orrelation funtions Ks is based on the mathematial indution method. In other
words, we suppose that all orrelation funtions Kl of the orders less than s are found. For the onveniene sake, we
admit that K0 = 1 and K1 = 0.

5

(24)

(25)

(27)

(28)

(29)

A. High-order orrelation funtions of the additive Markov hain

Consider the N -step Markov hain with the additive onditional probability funtion,

P (ai = 1

ai−N . . . ai−1) = ¯a +
|

F (r)(ai−r −

¯a).

N

Xr=1

Here funtion F (r), r = 1, . . . , N , is referred to as the memory funtion and ¯a is the fration of unities in the above

sequene (for details see Ref. [26℄).

Let us find the reurrene relations for the orrelation funtions of N -step additive Markov hain. For this purpose,
we first alulate expliitly the average over symbol ar1+...+rs−1 in Eq. (9). Using the notation of Se. II B and Eq. (30),
) = 1, we an rewrite Eq. (9) for arbitrary ri > 0,
and taking into aount equation P (aRs−1 = 1
i = 1, . . . , s

) + P (aRs−1 = 0

1, in the form,

|·

|·

−

(aR0 −

¯a) . . . (aRs−1 −

¯a) =

= (a0 −

¯a) . . . (aRs−2 −

−

¯a)((1

¯a)P (aRs−1 = 1

TN,Rs−1)
|

−

¯aP (aRs−1 = 0

TN,Rs−1)) =
|

(31)

Here TN,Rs−1 is the set of symbols (aRs−1−N , . . . , aRs−1−1). In that way, we obtain the fundamental reurrene relation
onneting the orrelation funtions of different orders s,

= (a0 −

¯a) . . . (aRs−2 −

¯a)

F (r)(aRs−1−r −

¯a).

N

Xr=1

Ks(r1, . . . , rs−1) =

F (r)Ks(r1, . . . , rs−1 −

r).

N

Xr=1

N

Xr=1

K2(r1) =

F (r)K2(r1 −

r),

In the partiular ase s = 2, this equation,

was obtained and disussed in [26℄. Reurrene relation (32) is orret for ri > 0, i = 1, . . . , s
1. Provided that
rs−1 6 N , the last argument of the orrelation funtion in the right-hand side of Eq. (32) is negative or zero and one

−

should interpret it in the following manner, whih is referred to as (cid:17)ol lating(cid:17) . If the orrelation funtion has negative

arguments, we must reorganize it aording to definition (9). For example,

K4(2, 2,

3) =

−

(a0 −
(cid:10)

¯a)(a2 −

¯a)(a4 −

¯a)(a1 −

=

¯a)
(cid:11)

If the orrelation funtion has zero arguments (indexes i and k of two multipliers (ai −
should employ the property of the binary hain: a2

0, 1

i = ai , ai =

¯a) and (ak −

=

(a0 −

¯a)(a1 −

¯a)(a2 −

¯a)(a4 −

= K4(1, 1, 2).

¯a)
(cid:11)

(cid:10)

(34)

¯a) oinide) one

¯a)2 = (1

(ai −

{
2¯a)(ai −

−

}. Thus, we have
¯a).

¯a) + ¯a(1

−

With this property we an write the useful relations for the orrelation funtion ontaining zero arguments in

different positions among all arguments of Ks ,

Ks(0, r2, . . . , rs−1) = (1

2¯a)Ks−1(r2, . . . , rs−1) + ¯a(1

Ks(r1, . . . , rk−1, 0, rk+1, . . . , rs−1) = (1

+¯a(1

¯a)Ks−2(r1, . . . , rk−1 + rk+1, . . . , rs),

−

−

−

¯a)Ks−2(r3, . . . , rs−1),
2¯a)Ks−1(r1, . . . , rk−1, rk+1, . . . , rs−1)+
= 1, s,
¯a)Ks−2(r1, . . . , rs−3).

k

−

−

−

Ks(r1, . . . , rs−2, 0) = (1

2¯a)Ks−1(r1, . . . , rs−2) + ¯a(1

6

(30)

(32)

(33)

(35)

6
The general solution of Eq. (32) an be represented as a linear ombination,

Ks(r1, . . . , rs−1) =

Lj(r1, . . . , rs−2)ξrs−1

j

, ri > 0 (i = 1, . . . , s

1),

−

N

Xj=1

of powers of the roots ξj , j = 1, . . . , N , of the harateristi equation,

ξN

F (j)ξN −j = 0.

N

−

Xj=1

New funtions Lj(r1, . . . , rs−2), i.e. oeffiients of linear form Eq. (36), in their turn, should be defined. All one has
to do is to substitute Eq. (36) into (cid:17)ollated(cid:17) Eq. (32) for 0 < rs−1 < N . Finally, this proedure yields the reurrene
relations for the sought funtions Lj .

The general solution of this reurrene relation is redued to the form,

where ηk , k = 1, . . . , N (N

1)/2, are the roots of the new harateristi equation

−

Li(r1, . . . , rs−2) =

Mik(r1, . . . , rs−3)ηrs−2

,

k

N (N −1)/2

Xk=1

det Υ(η) = 0,

From the (cid:17)ollating(cid:17) proedure we an find the next reurrene relations for funtions Mij et. Using this algorithm

we an find, in priniple, the orrelation funtions of all orders.

Υij(η) = (η/ξj)i−1

ξi−1
j + δ1i,

i, j = 1, . . . , N.

−

B. Appliation of the algorithm

All results obtained in this subsetion are orret for the additive Markov hain, but some of them are valid for

the non-additive hain as well.

The first simple result is that the orrelation funtions of all odd orders are zero for the additive Markov hain with

) and K1 = 0.
) is expressed only in term of K2m−1(
¯a = 1/2. This results from Eq. (35): funtion K2m+1(
·
·
) (the binary orrelation funtion) for an additive Markov hain
The orrelation funtion of the seond order K2(
·

an be found from Eq. (32):

where ξj , j = 1, . . . , N , are the roots of the harateristi equation (37). Coeffiients Lj should be obtained by the

ollating:

K2(r) =

Ljξr
j ,

r >

N,

−

N

Xj=1

K2(0) = ¯a(1

¯a); K2(

r) = K2(r),

0 < r < N.

−

−

P (ai = 1
|

ai−N . . . ai−1)
|

¯a

−

| ≪

1.

Paper [21℄ ontains an analysis of this equations in the ase of the additive Markov hain with the step-wise memory

funtion. Below we present the results of alulation for the orrelation funtion of a weakly orrelated hain,

This ase is very important from the physial point of view beause the statistial properties of the equilibrium long-

range orrelated Ising hains an be represented and onsidered as the Markov hains. Speifially, the Markov hain

with the small memory funtion is statistially equivalent to the weakly orrelated Ising hain (see Refs. [22, 23℄).

7

(36)

(37)

(38)

(39)

(40)

(41)

(42)

(43)

8

(44)

(45)

For the orrelation funtion of even order of the unbiased (¯a = 1/2) additive hain we have

K2(r)

F (r),

0 < r < N, K(0) =

1
4

,

1
4

≈

s

Yj=1

K2s(r1, . . . , r2s−1) =

K2(r2j−1),

rj > 0, j = 1, . . . , 2s

1.

−

The latter equation is orret for the non-additive sequene as well. In the ase of one-step Markov hain, N = 1,
this equation is exat. But if N > 1 one should interpret it as the asymptotial equality. At N = 2, the exat result
) of the additive hain is,
for the orrelation funtion K4(
·

K4(r1, r2, r3) = K2(r1)K2(r3) + (

K2(r1 + r3)

K2(r1)K2(r3)

.

−

(cid:19)

(46)

ξ1ξ2)r2

−

1
4

(cid:18)

Here ξ1 and ξ2 are the roots of the harateristi equation,

−
And finally, Eq. (32) allows us to express the memory funtion in terms the presribed orrelation funtions Ks . In
Ref. [26℄, the method of onstruting the orrelated binary sequene with presribed binary orrelation funtion K2

−

(47)

ξ2

F (1)ξ

F (2) = 0.

was earlier disussed.

C. Generalized algorithm of (cid:28)nding the orrelation funtions

Here we generalize the algorithm proposed in Subse. III A for the additive Markov hains to the arbitrary binary

multi-step Markov hains.

The onditional probability funtion of the N -step binary Markov hain an be written as

P (ai = 1

ai−N . . . ai−1) =
|

F (l1, l2, . . . , lN )

Xlj =0,1
j=1,...,N

N

Yr=1

(ai−r −

¯a)lr .

(48)

It is a general form for the arbitrary binary funtion, beause P (
argument aj . We refer to funtion F (l1, l2, . . . , lN ) as the generalized memory funtion.

·|·

) an be thought of a linear funtion of eah

Equation (48) an be applied to the additive Markov hain desribed by Eq. (30), namely,

F (0, 0, . . . , 0) = ¯a,

F (0, . . . , 0

, 1, 0, . . . , 0

) = F (r),

r = 1, 2, . . . , N,

(49)

N −r
| {z }
F (l1, l2, . . . , lN ) = 0,

r−1
| {z }

l1 + l2 + . . . + lN > 1.

Now we obtain the reurrene relation for the orrelation funtion with the oeffiients expressed via the generalized

memory funtion. aording to the proedure performed in Subsetion III A, we substitute the last symbol ar1+...+rs−1
) in the form of Eq. (48). As a result one
in Eq. (9) (for rj > 0, j = 1, . . . , s

1) for its onditional probability P (

−

·|·

gets,

Ks(r1, . . . , rs−1) = (F (0, 0, . . . , 0)
F (l1, l2, . . . , lN )Ks+k−1(r1, . . . , rs−2, rs−1 −

¯a)Ks−1(r1, . . . , rs−2)+
ρk, ρk −

−

ρk−1, . . . , ρ2 −

ρ1),

(50)

+

Xlj =0,1
j=1,...,N

where k = l1 + . . . + lN 6

Note that some summands in Eq. (50) an have non-positive arguments if rs−1 6 N . For this ase, one should

= 0. The inreasing numbers ρj , j = 1, . . . , k are the indexes, for whih lρj 6

= 0.

apply the (cid:17)ollating(cid:17) proedure to this equation.

Thus, the algorithm for finding of the orrelation funtions an be formulated as follows:

1. To obtain the orrelation funtion Ks(r1, r2, . . . , rs−1) at ri > 0, i = 1, 2, . . . , s

1, we should use Eq. (50)
and exeute the (cid:17)ollating(cid:17) proedure. We find that funtion Ks(r1, . . . , rs−1) is expressed via the orrelation
funtions with the sum of their arguments less than initial sum r1 + . . . + rs−1 .

−

9

2. Using Eq. (50) and performing the (cid:17)ollating(cid:17) proedure m times with respet to the obtained orrelation

funtions, we derive a relation between funtion Ks(r1, . . . , rs−1) and some other orrelation funtions.

(a) If all of them have the order less than s, we obtain the reurrene relation for the orrelation funtion
of the sth order. This relation an be solved by the method of harateristi equations without exeuting

item 3. (A similar ase takes plae for the additive Markov hain.)

(b) In the opposite ase, for m > r1 + r2 + . . . + rs−1 −

N , funtion Ks(r1, . . . , rs−1) is expressed via the
orrelation funtions with the sums of their arguments less than N . Some of these funtions are of the
order greater than s. Then we should go to the next item of the algorithm.

3. All orrelation funtions with the sum of arguments less than N should be found from a set of linear equations.

To this end we write Eq. (50) for every suh orrelation funtion. After exeuting the (cid:17)ollating(cid:17) proedure we

2N −1
(cid:0)

1

2N −1
(cid:0)

1

obtain the set of

linear equations for

(cid:1)

−
) in Eq. (48) using an arbitrary fixed
) in Eq. (9) and P (
In some partiular ases, it is onvenient to define Ks(
·
value ˜a (for example, ˜a = 1/2) instead of the average ¯a. In this inident every reasoning remain valid provided that
the value of ¯a is hanged to ˜a in Eqs. (50) and (35), and K1 = 0 is hanged to K1 = ˜a
¯a. To obtain average ¯a we
should add Eq. (50), written for K1 , to the set of equations in item 3 of the algorithm. Then we arrive at the set of
2N −1
sought values of the orrelation funtions and one of the average ¯a. Besides,
one an use ˜a instead of ¯a in the different physial problems, whih are relevant to the Markov hain. For instane,
the energy in the Ising model is more onvenient to express in terms or funtion K2(r) = (ai −

1/2)(ai+r −

2N −1
(cid:0)

1/2).

·|·

−

−

−

1

(cid:1)

(cid:1)

sought values of the orrelation funtions.

linear equations and

IV. CONCLUSION

Thus, we have demonstrated two approahes to determining the statistial properties of the binary Markov hains.

The first of them should be used if the probabilities of N -words ourring an be easily found. The orrelation funtions

of different orders an be expressed via these probabilities. The examples of these hains is the permutative Markov

sequenes. The seond approah allows one to find the orrelation funtions diretly from the reurrene relations

onneting them with the memory funtion. In the general ase, these relations ontain the orrelation funtions of

different orders and, hene, they are diffiult to solve. In the ase of additive hains, this relations are simplified and

their use helps to find the solutions.

[1℄ U. Baluani, M. H. Lee, V. Tognetti, Phys. Rep. 373, 409 (2003).

[2℄ I. M. Sokolov, Phys. Rev. Lett. 90, 080601 (2003).

[3℄ A. Bunde, S. Havlin, E. Kosienly-Bunde, H.-J. Shellenhuber, Physia A 302, 255 (2001).

[4℄ H. N. Yang, Y.-P. Zhao, A. Chan, T.-M. Lu, and G. C. Wang, Phys. Rev. B 56, 4224 (1997).

[5℄ S. N. Ma jumdar, A. J. Bray, S. J. Cornell, and C. Sire, Phys. Rev. Lett. 77, 3704 (1996).

[6℄ S. Halvin, R. Selinger, M. Shwartz, H. E. Stanley, and A. Bunde, Phys. Rev. Lett. 61, 1438 (1988).

[9℄ S. V. Buldyrev, A. L. Goldberger, S. Havlin, R. N. Mantegna, M. E. Matsa, C.-K. Peng, M. Simons, H. E. Stanley, Phys.

[11℄ R. M. Yulmetyev, N. Emelyanova, P. H(cid:4)anggi, and F. Gafarov, A. Prohorov, Phyia A 316, 671 (2002).

[7℄ R. F. Voss, Phys. Rev. Lett. 68, 3805 (1992).

[8℄ H. E. Stanley et. al., Physia A 224,302 (1996).

Rev. E 51, 5084 (1995).

[10℄ A. Provata and Y. Almirantis, Physia A 247, 482 (1997).

[12℄ B. Hao, J. Qi, Mod. Phys. Lett., 17, 1 (2003).

[13℄ R. N. Mantegna, H. E. Stanley, Nature (London) 376, 46 (1995).

[14℄ Y. C. Zhang, Europhys. News, 29, 51 (1998).

[15℄ A. Shenkel, J. Zhang, and Y. C. Zhang, Fratals 1, 47 (1993).

[16℄ I. Kanter and D. A. Kessler, Phys. Rev. Lett. 74, 4559 (1995).

[17℄ P. Kokol, V. Podgorele, Complexity International, 7, 1 (2000).

[18℄ W. Ebeling, A. Neiman, T. Poshel, arXiv:ond-mat/0204076.

[19℄ O. V. Usatenko and V. A. Yampol'skii, Phys. Rev. Lett. 90, 110601 (2003).

[20℄ O. V. Usatenko, V. A. Yampol'skii, K. E. Kehedzhy and S. S. Mel'nyk, Phys. Rev. E 68, 061107 (2003).

[21℄ S. S. Melnyk, O. V. Usatenko, V. A. Yampol'skii, S. S. Apostolov, and Z. A. Mayzelis, arXiv:physis/0603171 ; to be

[22℄ S. S. Apostolov, Z. A. Mayzelis, O. V. Usatenko, and V. A. Yampol'skii, arXiv:physis/0603172 ; to be published in

published in J. Phys. A: Math. Gen.

Europhys. Lett.

[23℄ S. S. Apostolov, Z. A. Mayzelis, O. V. Usatenko, and V. A. Yampol'skii, to be published in Vestnik KhNU. Ser. Fiz. (in

[24℄ A. N. Shiryaev, Probability (Springer, New York, 1996).

Russian).

Fratals and Chaos.

[25℄ Z. A. Mayzelis, S. S. Melnyk, O. V. Usatenko, and V. A. Yampol'skii, arXiv:physis/0603170 ; to be published in Solitons,

[26℄ S. S. Melnyk, O. V. Usatenko, and V. A. Yampol'skii, Physia A, 361, 405 (2006); arXiv:physis/0412169 .

10

