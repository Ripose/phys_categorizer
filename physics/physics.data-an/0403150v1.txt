4
0
0
2
 
r
a

M
 
1
3
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
0
5
1
3
0
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A hidden Markov Model for image fusion and
their joint segmentation in medical image
computing

Olivier FERON and Ali MOHAMMAD-DJAFARI

Laboratoire des signaux et syst`emes,
Sup´elec, plateau de Moulon,
3, rue Joliot Curie,
91192 Gif-sur-Yvette
{feron,djafari}@lss.supelec.fr,

Abstract. In this work we propose a Bayesian framework for fully au-
tomated image fusion and their joint segmentation. More speciﬁcally,
we consider the case where we have observed images of the same object
through diﬀerent image processes or through diﬀerent spectral bands.
The objective of this work is then to propose a coherent approach to
combine these data sets and obtain a segmented image which can be
considered as the fusion result of these observations.
The proposed approach is based on a Hidden Markov Modeling (HMM)
of the images with common segmentation, or equivalently, with com-
mon hidden classiﬁcation label variables which are modeled by the Potts
Markov Random Field. We propose an appropriate Markov Chain Monte
Carlo (MCMC) algorithm to implement the method and show some sim-
ulation results and applications.

key words :
Data fusion, Segmentation, multispectral images, HMM, MCMC, Gibbs
Algorithm.

1 Introduction

Data fusion and multi-source information has become a very active area of re-
search in many domains : industrial nondestructive testing and evaluation ([1]),
industrial inspection ([2]), and medical imaging [3,4,5,6,7]. For example in mag-
netic resonance (MR) image segmentation, one can use multispectral images to
accentuate the diﬀerencies in physical characteristics of the anatomical tissues.
In this case we must fuse information of these multispectral images to obtain
segmentation.
The main problem is how to combine the information contents of diﬀerent sets
of data gi(r). Very often the data sets gi, and corresponding images fi, do not
represent the same quantities. A general model for these problems can be the
following :

gi(r) = [Hifi](r) + εi(r),

i = 1, . . . , M

(1)

2

where Hi are the functional operators of the measuring systems, or a registration
operators if the observations have to be registered. We may note that estimating
fi given each set of data gi is an inverse problem by itself. In this work we
propose to reconstruct images fi and to construct a common segmentation at
the same time. This fused segmentation will be presented by an image z. In this

(a)

(b)

Fig. 1. Examples of images for data fusion and joint segmentation. a) PD (Pro-
ton Dennsity),T1 and T2-weighted slices of brain MR images. b) T1-weighted,
T2-weighted and T1-weighted with contrast agent transversal slices of a 3D brain
MR images with additive gaussian noise.

paper we consider the case where the measuring data systems can be assumed
almost perfect and the observations are registered, which means that we can
write :

gi(r) = fi(r) + εi(r),

i = 1, . . . , M

(2)

for r ∈ R2. If we have, for example, multispectral images, then gi’s represent
observations taken at diﬀerent spectral bands. In a multimodal case, gi can
represent CT and PET images.
Our aim is then to obtain a common segmentation of N observations and to
reconstruct fi, i = 1, . . . , N at the same time. Figure 1 shows two examples of
applications in MR images.
This paper is organized as follows : In section 2 we introduce the common feature
z, model the relation between the images fi to it through p(fi|z) and its proper
characteristics through a prior law p(z). In section 3 we give detailed expressions
of the a posteriori law and propose a general structure of the MCMC algorithm
to estimate f and z. Finally, in section 4 we present some simulation results to
show the performances of the proposed method.

3

2 Modeling for Bayesian data fusion

In this paper we consider the model (2) where after discretization and using the
notations gi = [gi(1), . . . , gi(S)]T and g = (gi)i=1,...,M , fi = [fi(1), . . . , fi(S)]T
and f = (fi)i=1,...,M , and εi = [εi(1), . . . , εi(S)]T and ε = (εi)i=1,...,M , with S
the total number of pixels of the images fi, we have :

g = f + ε,

or gi = fi + εi,

i = 1, . . . , M

(3)

Within this model and assuming Gaussian independant noises, p(εi) = N (0, σ2
we have

εi I),

p(g|f ) =

p(gi|fi) =

pεi (gi − fi)

M

i=1
Y

M

i=1
Y

As we want to reconstruct an image with statistically homogeneous regions, it
is natural to introduce a hidden variable z = (z(1), . . . , z(S)) ∈ {1, . . . , K}S
which represents a common classiﬁcation of the images fi. The problem is now
to estimate the set of variables (f , z) using the Bayesian approach :

p(f , z|g) = p(f |z, g) p(z|g)

(4)

Thus to be able to give an expression for p(f , z|g) using the Bayes formula, we
need to deﬁne p(gi|fi), p(fi|z), p(gi|z) and p(z).
Assuming εi centered, white and Gaussian, ans S the number of pixels of an
image, we have :

p(gi|fi) = N (fi, σ2

εiI) =

S
2

1
2πσ2

(cid:18)

εi (cid:19)

exp

−

||gi − fi||2

1
2σ2
εi

(cid:26)

(cid:27)

To assign p(fi|z) we ﬁrst deﬁne the sets of pixels which are in the same class :

Rk = {r : z(r) = k},
fik = {fi(r) : z(r) = k}

|Rk| = nk

Then we assume that all the pixels of an image fi which are in the same class
will be characterized by a mean mik and a variance σ2

i k :

p(fi(r)|z(r) = k) = N (mik, σ2

i k)

With these notations we have :

p(fik) = N (mik1, σ2
K

i kI)

p(fi|z) =

N (mik1, σ2

i kI)

k=1
Y
K

=

1

2πσ2
i k







k=1
Y



q

nk

exp

−

(cid:26)

1
2σ2
i k

||fik − mik1||2

,

i = 1, . . . , M.

(cid:27)

4

The next step is to deﬁne p(gi|z). To do this we may use the relation (3) and
the laws p(fi|z) and p(εi) to obtain

p(gi(r)|z(r) = k) = N (mik, σ2

i k + σ2

εi )

Finally we have to assign p(z). As we introduced the hidden variable z for ﬁnding
statistically homogeneous regions in images, it is natural to deﬁne a spatial
dependency on these labels. The simplest model to account for this desired local
spatial dependency is a Potts Markov Random Field model :

1
T (α)




p(z) =

exp

α

δ(z(r) − z(s))

,








Xs∈V(r)

r∈S
X
where S is the set of pixels, δ(0) = 1, δ(t) = 0 if t 6= 0, V(r) denotes the
neighborhood of the pixel r (here we consider a neighborhood of 4 pixels) and
α represents the degree of the spatial dependency of the variable z. This pa-
rameter will be ﬁxed for our algorithm. We have now all the necessary prior
laws p(gi|fi), p(fi|z), p(gi|z) and p(z) and then we can give an expression for
p(f , z|g). However these probability laws have in general unknown parameters
such as σ2
i k in p(fi|z). In a full Bayesian approach,
we have to assign prior laws to these ”hyperparameters”. Then the choice of
prior laws for the hyperparameters is still an open problem. In [8] the authors
used diﬀerential geometry tools to construct particular priors which contain as
particular case the entropic and conjugate priors. In this paper we choose this
last one.
Let mi = (mik)k=1,...,K and σ2
i k)k=1,...,K be the means and the variances
of the pixels in diﬀerent regions of the images fi as deﬁned before. We deﬁne θi
as the set of all the parameters which must be estimated :

εi in p(gi|fi) or mik and σ2

i = (σ2

θi = (σ2

εi , mi, σ2

i ),

i = 1, . . . , M

0 , βεi

and we note θ = (θi)i=1,...,M . When applied the particular priors of ([8]) for our
case, we ﬁnd the following conjugate priors :
– Inverse Gamma IG(αεi
i k,

0 ) and IG(αi0, βi0) respectively for the variances

εi and σ2
σ2

i 0) for the means mik.

– Gaussian N (mi0, σ2
The hyper-hyperparameters αi0, βi0, mi0 and σ2
i 0 are ﬁxed and the results
are not in general too sensitive to their exact values. However in case of noisy
images we can constrain small value on σ2
i 0 in order to force the reconstruction
of homogeneous regions.

3 A posteriori distributions for the Gibbs algorithm

The Bayesian approach consists now to estimate the whole set of variables
(f , z, θ) following the joint a posteriori distribution p(f , z, θ|g). It is diﬃcult to

5

simulate a joint sample (ˆf , ˆz, ˆθ) directly from his joint a posteriori distribution.
However we can note that considering the prior laws deﬁned before, we are able
to simulate the conditionnal a posteriori laws p(f , z|g, θ) and p(θ|g, f , z). That
is why we propose a Gibbs algorithm to estimate (ˆf , ˆz, ˆθ), splitting ﬁrst this set
of variables into two subsets, (f , z) and (θ) :

p(f , z|g, θ) = p(f |z, g, θ)p(z|g, θ)

Then the sampling of this joint distribution is obtained by sampling ﬁrst p(z|g, θ)
and then sampling p(f |z, g, θ). We will now deﬁne the conditionnal a posteriori
distribution we use for the Gibbs algorithm.

Sampling z|g, θ :
for this step we have :

p(z|g, θ) ∝ p(g|z, θ) p(z) =

p(gi|z, θ1) p(z)

M

i=1
Y

As we choosed a Potts Markov Random Field model for the labels, we may note
that an exact sampling of the a posteriori distribution p(z|g, θ) is impossible.
However we propose in section 4 a parallel implementation of the Gibbs sam-
pling for resolving this problem.

Sampling fi|gi, z, θi :
We can write the a posteriori law p(fi(r)|gi(r), z(r), θi) as follows :

p(fi(r)|gi(r), z(r) = k, θi) = N (mi

apost
k

, σ2
i

apost
k

)

where

mi

apost
k

= σ2
i

apost
k

gi(r)
σ2
εi

+

mik
σ2
i k(cid:19)

(cid:18)

and σ2
i

apost
k

=

−1

1
σ2
εi

+

1
σ2
i k(cid:19)

(cid:18)

sampling θi|fi, gi, z :
We have the following relation :

p(θi|fi, gi, z) ∝ p(σ2

εi |fi, gi) p(mi, σ2

i |fi, z)

and using again the Bayes formula, the a posteriori distributions are calculated
from the prior selection ﬁxed before and we have
i k), with

i 0 ∼ N (µik, v2

- mik|fi, z, σ2

i k, mi0, σ2

µik = v2
i k

mi0
σ2
i 0

 

+

1
σ2
i k

fi(r)

!

r∈Rk
X

and v2

i k =

−1

nk
σ2
i k

+

1
σ2
i 0 (cid:19)

(cid:18)

- σ2

i k|fi, z, αi0, βi0 ∼ IG(αik, βik), with
nk
2

αik = αi0 +

and βik = βi0 +

1
2

(fi(r) − mik)2

r∈Rk
X

6

- σ2

εi |fi, gi ∼ IG(νi, Σi), with

νi =

+ αεi
0 ,

S
2

S = number of pixels and Σi =

||gi − fi||2 + βεi
0

(5)

1
2

4 Parallel implementation of the Gibbs algorithm

As we choosed a ﬁrst order neighborhood system for the labels, we may also
note that it is possible to implement the Gibbs algorithm in parallel. Indeed,
we can decompose the whole set of pixels into two subsets forming a chessboard
(see ﬁgure 2). In this case if we ﬁx the black (respectively white) labels, then
the white (respectively black) labels become independant. This decomposition

black labels

white labels

Fig. 2. Chessboard decomposition of the labels z

reduces the complexity of the Gibbs algorithm because we can simulate the whole
set of labels in only two steps. The Parallel Gibbs algorithm we implemented is
then the following : given an initial state ( ˆθ1, ˆθ2, ˆz)(0),

Parallel Gibbs sampling

repeat until convergence

1. simulate ˆzB

simulate ˆzW
simulate ˆfi
2. simulate ˆθi

(n) ∼ p(z| ˆzW
(n) ∼ p(z| ˆzB
(n)

(n−1), g, ˆθ
(n), g, ˆθ
∼ p(fi|gi, ˆz(n), ˆθi
(n)
∼ p(θi| ˆfi

, ˆz(n), gi)

(n)

(n−1)

(n−1)

)

)

(n−1)

)

5 Simulation and results

Here we illustrate two examples of MRI images : PD, T1-weightd and T2-
weighted slices of a MR brain image, which are (188×193) images for the ﬁrst ex-
ample, and T1-weighted,T2-weightedand T1-weighted with contrast agent slices
of a MR brain image, which are (289 × 236) images for the second example. In
this last we have added a gaussian noise.
Figures 3 and 4 show the data fusion result of the proposed method. As it is seen
on these ﬁgures the fusionned segmentations we obtain contain all the regions
and boundaries of the observations, but we have not yet compared with other

7

(a)

(b)

Fig. 3. Results of data fusion from MRI images. a)observations (up) and recon-
structed images (down) . b) result of data fusion with 7 labels.

methods to see the performances of our algorithm. Also the presence of noise in
ﬁgure 4 do not really aﬀect the result of segmentation and, at the same time,
the proposed algorithm give visibly improved reconstructed images.

(a)

(b)

Fig. 4. Results of data fusion from MRI images. a)observations (up) and recon-
structed images (down) . b) result of data fusion with 7 labels.

In both applications we have satisfactory results of image fusion, even when
images present a great number of homogeneous regions and boundaries. Note
also that in both applications we ﬁxed a prior small value of σ2
i 0 to improve
the reconstructed images. Another way may be the introduction of some local
spatial dependency between the neighboring pixels of images fi(r). This point
is under development and we will report soon on the results.

8

6 Conclusion

We proposed a Bayesian method for data fusion of images, with a Potts Markov
Random Field model on the hidden variable z. We illustrated how a joint seg-
mentation and reconstruction can be obtained in case of MRI images. We showed
then how reconstruction and fusion can be computed at the same time using a
MCMC algorithm. We considered the case of noisy images and showed that the
joint segmentation is not greatly aﬀected. This method give an unsupervised seg-
mentation which do not take into account particular shapes and then can give
good results in many diﬀerent cases. However we assume for the moment that
the observed images are registered. We think that this modelisation is promising
for introducing registration operators Hi and then implementing common seg-
mentation and registration at the same time. Another perspective is to introduce
spatial dependency directly on the images fi for involving the reconstruction.

References

1. S. Gautier, G. Le Besnerais, A. Mohammad-Djafari, and B. Lavayssi`ere, Data
fusion in the ﬁeld of non destructive testing. Maximum Entropy and Bayesian
Methods, Santa Fe, nm: Kluwer Academic Publ., K. Hanson ed., 1995.

2. T. Bass, “Intrusion detection systems and multisensor data fusion,” in Comm. of

the ACM, vol. 43, pp. 99–105, 2000.

3. G. Matsopoulos, S. Marshall, and J. Brunt, “Multiresolution morphological fuson
of mr and ct images of the human brain,” in IEEE Proceedings on Vision, Image
and Signal Processing, vol.141 Issue : 3, (Seattle), pp. 137–142, 1994.

4. B. Johnston and B. Mackiewitch, “Segmentation of multiple sclerosis lesions in in-
tensity corrected multispectral mri,” in IEEE Trans. on medical imaging, pp. 154–
169, 1996.

5. C.-M. Wang and C. C.-C. Chen et al., “Detection of spectral signatures in multi-
spectral mr images for classiﬁcation,” in IEEE Trans. on medical imaging, pp. 50–
61, 2003.

6. E. Reddick and J. Glass et al., “Automated segmentation and classiﬁcation of
multispectral magnetic resonance images of brain using artiﬁcial neural networks,”
in IEEE Trans. on medical imaging, pp. 911–918, 1997.

7. M. Ahmed and M. Yamany et al., “A modiﬁed fuzzy c-means algorithm for bias
ﬁeld estimation and segmentation of mri data,” in IEEE Trans. on medical imaging,
pp. 193–199, 2002.

8. H. Snoussi and A. Mohammad-Djafari, “Information Geometry and Prior Selec-
tion.,” in Bayesian Inference and Maximum Entropy Methods (C. Williams, ed.),
pp. 307–327, MaxEnt Workshops, American Institute of Physics, August 2002.
9. K. Held and E. Kops et al., “Markov random ﬁeld segmentation of brain mr im-

ages,” in IEEE Trans. on medical imaging, pp. 878–886, 1997.

10. G. Gindi, M. Lee, A. Rangarajan, and I. G. Zubal, “Bayesian reconstruction of
functional images using anatomical information as priors,” IEEE Transactions on
Medical Imaging, vol. 12, no. 4, pp. 670–680, 1993.

11. S. Gautier, J. Idier, A. Mohammad-Djafari, and B. Lavayssi`ere, “X-ray and ul-
trasound data fusion,” in Proceedings of the International Conference on Image
Processing, (Chicago, il), pp. 366–369, October 1998.

12. T. Hebert and R. Leahy, “A generalized em algorithm for 3-D Bayesian recon-
struction from Poisson data using Gibbs priors,” IEEE Transactions on Medical
Imaging, vol. 8, pp. 194–202, June 1989.

13. C. Robert, M´ethodes de Monte-Carlo par chaˆınes de Markov. Paris, France: Eco-

nomica, 1996.

9

