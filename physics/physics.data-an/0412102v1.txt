4
0
0
2
 
c
e
D
 
7
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
2
0
1
2
1
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Optimal Determination of the Equilibrium Displacement of a Damped Harmonic
Oscillator in the Presence of Thermal Noise

Michael W. Moore, Jason H. Steﬀen,∗ and Paul E. Boynton
University of Washington, Department of Physics
(Dated: February 2, 2008)

Using a matched ﬁlter technique, we derive the minimum variance, unbiased estimator for the
equilibrium displacement of a damped harmonic oscillator in thermal equilibrium when interactions
with the thermal bath are the leading source of noise. We compare the variance in this optimal
estimator with the variance in other, commonly used estimators in the presence of pure thermal
noise and pure white noise. We also compare the variance in these estimators for a mixture of
white and thermal noise. This result has implications for experimental design and the collection
and analysis of data.

PACS numbers: 02.50, 02.60
Keywords: Thermal Noise, Damped Harmonic Oscillator, Power Spectrum, Torsion Device, Data Analysis,
Random Walk

I.

INTRODUCTION

The torsion pendulum is currently used in a number of
experimental programs to test theories of gravity ([1] and
references therein). This work involves the detection of
extremely small torques and requires the experimental-
ist to design measurements whose precision approaches
the fundamental limit posed by thermal noise prescribed
by optimal (minimum variance, unbiased) statistical es-
timation techniques. This requirement is familiar to the
community engaged in these studies, and those readers
will immediately ask why we need still another treatment
of thermal noise on a damped harmonic oscillator. To an-
swer this question, we begin with a simple example that
illustrates a major shortcoming in customary methodolo-
gies.

Consider a linear oscillator in thermal equilibrium with
a heat bath at absolute temperature, T . The equilibrium
displacement of the pendulum, c, can be estimated by
measuring the instantaneous displacement of the oscilla-
tor, x(t), at t = 0

ˆcins = x(0)

(1)

where the circumﬂex indicates a parameter estimate.
The ensemble of such estimates is a random variable (the
estimator), and it is represented by ˆCins. We will use
the convention that a capital letter represents an ensem-
ble and a lower-case letter represents a realization of the
ensemble. The equipartition theorem prescribes the vari-
ance of the instantaneous estimator

var( ˆCins) =

kbT
κ ≡

σ2,

(2)

where kb is the Boltzmann constant and κ is the torsional
spring constant.

∗jsteﬀen@astro.washington.edu

If the data used in a parameter estimate is a continuous
time series, x(t), one can deﬁne another estimator that
has smaller variance than the instantaneous estimator. A
familiar approach, the “boxcar” estimate, is an average
of the displacement of the oscillator over the time series
starting at t = 0 and ending at t = τ ,

ˆcbox =

x(t)dt.

τ

1
τ

(3)

0
Z
For the case of an oscillator dominated by thermal noise,
one can calculate the variance of the boxcar estimator
using the Fourier methods presented later in this article

2σ2
ωω4
0τ 2
(cid:16)
ω3

−

−

(cid:0)(cid:0)

(cid:1)

var( ˆCbox) =

3γ2ω + ω3 + 2γ3ωτ + 2γω3τ

+ e−γτ

3γ2ω

cos(ωτ ) +

γ3

3γω2

sin(ωτ )

−

(cid:0)

(cid:1)

(cid:1)(cid:17)(4)

p

ω2

κ/m is the undamped oscillation fre-
where ω0 =
γ2
quency, γ is the decay coeﬃcient, and ω =
is the damped oscillation frequency. The quality fac-
tor, Q = ωr/(2γ), is traditionally deﬁned in terms of
2γ2, but to simplify
the resonant frequency, ωr =
equations appearing later, it is convenient to deﬁne an
alternate quality factor, Q0 = ω0/(2γ), in terms of the
undamped frequency. Similarly, we state the duration of
the data sample in units of undamped oscillation periods,
N = ω0τ /(2π).

0 −

0 −

ω2

p

p

The solid curve in Figure 1 shows the logarithm of
var( ˆCbox)/σ2 versus the logarithm of N for an oscilla-
tor of quality factor, Q0 = 50. It is apparent that the
boxcar estimate is not optimal for the thermal-noise-
dominated pendulum because the variance does not de-
crease monotonically with increasing sample duration τ .
Adding more data cannot degrade the optimal estimate
of a parameter. What then is the optimal estimate, ˆcop?
We assert that the dashed curve in Figure 1 represents
the variance of the optimal estimator, var( ˆCop)/σ2. This

2

(5)

(6)

100

10−2

10−4

)

C

€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€

(
r
a
v

2
Σ

10−4

10−2

100

N

102

FIG. 1: The solid curve is the variance of the boxcar estimator
of the equilibrium displacement, in units of the variance of
the instantaneous estimator, versus the duration of the data
sample in undamped oscillator periods. The oscillator has
a quality factor of Q0 = 50. The dashed curve is a plot of
the variance of the optimal estimator, also in terms of the
variance of the instantaneous estimator and for Q0 = 50.

curve is qualitatively consistent with what one would ex-
pect from an optimal estimator—it does decrease mono-
tonically with increasing τ , and it lies on or below the
boxcar estimator for all values of τ . In this paper, we de-
rive a closed-form expression for ˆcop under fairly general
assumptions. The point of presenting this example is that
up to now a solution to this basic estimation problem has
not appeared in the experimental literature. This is the
gap we wish to ﬁll with this article.

It is somewhat surprising that as we approach the
100th anniversary of Einstein’s seminal work on Brow-
nian motion [2] there remain several, arguably canoni-
cal, questions whose answers are not widely known in
the physics community. Aside from the large number of
people who have looked at the problem, several notable
minds have studied Brownian motion on a damped har-
monic oscillator. For example, in Chandrasekhar’s 1943
Reviews of Modern Physics article, “Stochastic Problems
in Physics and Astronomy” [3], one learns that given the
initial displacement and velocity, x0 and v0, of a damped
harmonic oscillator at t = 0, the probability distribution
function for the displacement x at time t > 0 is

where




W (x, t; x0, v0) =

 

4πβkbT

m

x

x0e−βt/2

−

exp 

−

(cid:16)

1
2

×

m
t
0 ψ2(ψ)dψ !
β1t
+ β
R
cosh
2

(cid:16)

(cid:16)

(cid:17)
4βkbT

−

β1t
2

β1 sinh
t
(cid:17)(cid:17)
(cid:16)
0 ψ2(ψ)dψ
R

2v0

β1 e−βt/2 sinh

β1t
2

(cid:16)

(cid:17)(cid:17)

2






1
2ω2
0β −

e−βt
0β2
1β

2ω2

(cid:18)

β1t
2

(cid:18)

(cid:19)

2β2 sinh2

+ ββ1 sinh(β1t) + β2
1

(cid:19)

t

ψ2(ψ)dψ =

0
Z
β2
β1 =
β = 2γ.

(cid:0)

4ω2
0

−

1
2

(cid:1)

This result completely describes the stochastic time evo-
lution of a damped harmonic oscillator in contact with
a heat bath. For a theorist, the problem is solved. And
in a limited sense, this assessment is correct. Proba-
bility theory, which produces equation (5), attempts to
characterize the measured values one would obtain given
the parameters of the system. A statistical approach, on
the other hand, is concerned with the inverse problem:
to determine a measurement/inference scheme that pro-
vides optimal estimates for the relevant parameters. As
such, a statistical characterization is of keen interest for
experimentalists because it provides insight into both the
design of the experiment and analysis of the experimental
data.

To answer typical statistical questions that experimen-
talists wish to ask regarding the damped harmonic oscil-
lator, the autocovariance function of the stationary ther-
mal noise ensemble provides suﬃcient information.
Its
form

δXth(t)δXth(t + ∆t)

(cid:10)

= σ2e−γ|∆t|

(cid:11)
∆t
cos(ω
|

) +
|

sin(ω

∆t
|

)
|

γ
ω

(cid:16)

(cid:17)

(7)

(cid:17)

(cid:16)

is much simpler than (5) because of the time-translation
invariance of the stationary noise ensemble. Using either
(5) or (7) one can calculate the variance of a particular
estimator, but neither equation alone yields the minimum
variance, unbiased estimator.

The question of optimal estimation has been stud-
ied extensively.
In particular, because of applications
to radar, optimal ﬁlter theory was intensely developed
during World War II. For stationary noise processes, an-
alyzing statistical estimation in the Fourier basis greatly
simpliﬁes the problem because the noise ﬂuctuations in
various Fourier components are not correlated one with
another. The power spectrum of the thermal noise en-
semble corresponding to the autocovariace shown in (7),

S [δXth] =

8σ2γω2
0
2
+ (4πγν)2

ω2
0

,

(2πν)2

−

(cid:16)

(cid:17)

is a Fourier representation containing the same informa-
tion. Basically, optimal ﬁlter theory states that the op-
timal estimate is a weighted least-squares sum in Fourier
space with the weights being determined by the signal-
to-noise ratios of the various Fourier components.

No detailed mathematical derivation is needed to ob-
tain an optimal estimator for the constant c. Since the
deﬂection parameterized by c has only a zero-frequency
Fourier component, the optimal estimator, ˆCop, will also
have only a zero-frequency component. Thus, for any sta-
tionary noise process, optimal ﬁlter theory dictates that
ˆCop is the boxcar estimator. Yet, according to the dis-
cussion of Figure 1, it would appear that optimal ﬁlter
theory produces the wrong result.

≫

This discrepancy arises because there are certain as-
sumptions that must be satisﬁed in order for optimal
ﬁlter theory to be valid. Chief among these assumptions
is that the discrete Fourier components of the noise from
ﬁnite duration data samples should be a good approxi-
mation to the continuous Fourier components of the noise
from inﬁnite duration data samples. For N
Q0, where
N is the number of undamped oscillation periods, this re-
quirement is satisﬁed, and Figure 1 shows that var( ˆCbox)
does indeed approach var( ˆCop) for N
50. For N < Q0,
the narrowband thermal noise of a damped harmonic os-
cillator does not satisfy the above requirement, and op-
timal ﬁlter theory is not valid in that regime. When
performing atomic force cantilever experiments for which
the resonant frequency is measured in kiloHertz and the
characteristic damping time, 1/γ, is measured in seconds,
waiting for N
Q0 is a realistic possibility. For torsion
balance experiments with milliHertz resonant frequen-
cies and characteristic damping times of weeks, however,
waiting for N
Q0 in order to simplify the data analy-
sis is clearly impractical. The majority of torsion balance
experiments are conducted in the “bumpy” regime of the
boxcar estimator in Figure 1 where optimal ﬁlter theory
fails most miserably.

≫

≫

≫

Insight to the character of this problem has been
suggested by Priestly [4] in the treatment of a related
question[10]. Moreover, a formal solution was posed
by Grenander [5], but we ﬁnd that it provides the
physicist with neither a great deal of physical insight
nor a straightforward means of translating the results

3

into equations involving measurements and the physical
model. We therefore construct our derivation with meth-
ods and tools more familiar to the experimental commu-
nity and refer the interested reader to Grenander for a
rigorous mathematical development.

Having set out the question, we now present the an-

swer. The optimal estimate of deﬂection is

xi + xf + Q0ω0τ xm + Q0

vf −vi
ω0

ˆcop =

2 + Q0ω0τ

(cid:16)

,

(cid:17)

(9)

(8)

where xi = x(0), xf = x(τ ), vi = v(0), vf = v(τ ), and
xm is the boxcar estimate (3). The variance of the cor-
responding estimator

var( ˆCop) =

2σ2
2 + Q0ω0τ

(10)

is the smallest possible for an unbiased estimator of c
constrained to using data of duration τ . The dashed line
in Figure 1 is a plot of (10) for Q0 = 50. The derivation
and discussion of (9) and (10) are the major topics of this
paper. It is not immediately apparent how these results
follow from either (7) or (8), but the simplicity of (10)
implies that symmetries and appropriate transformations
streamline the solution. The complexity of (5) suggests
the problem can become diﬃcult if these symmetries are
ignored.

In section II we present the estimation of linear param-
eters in the presence of noise and show how to calculate
the variance in the parameter estimators using the spec-
tral power density of the noise process in the fundamental
observable. We then derive the minimum variance, un-
biased estimator of the equilibrium displacement of the
torsion pendulum in the presence of white noise and ther-
mal noise in section III. Section IV examines the eﬀects
of multiple noise processes on the variance of diﬀerent
estimators. In particular we examine a superposition of
white noise and thermal noise as well as transients caused
by nonthermal disturbances to the oscillator.

II. LINEAR PARAMETERS

A. Estimating Linear Parameters

A realization of data x(t) is a combination of the phys-
ical signal, denoted x(t; ρ) as explained shortly, and a
term representing additive noise

x(t) = x(t; ρ) + δx(t).

(11)

We use the convention that a Greek letter ρ represents
the physical value of the corresponding parameter p upon
which the signal depends. A linear parameter is esti-
mated by projecting a realization of the data x(t) onto
an estimating function e ˆp(t)

ˆp =

e ˆp(t)x(t)dt.

(12)

∞

−∞

Z

4

In the absence of noise, the data matches the physical
signal and an unbiased estimating function returns the
physical value of the parameter

are the cosine and sine transforms of the estimating func-
tion. We choose the normalization of (19) to preserve
Parseval’s relation,

ρ =

e ˆp(t)x(t; ρ)dt.

(13)

F 2[e ˆp(t); ν]dν =

(e ˆp(t))2 dt.

(20)

∞

0
Z

∞

−∞

Z

∞

−∞

Z

Nearly any time domain ﬁlter f ˆp(t) can be normalized
to create a valid estimating function by requiring that the
relation (13) be satisﬁed. Thus, for linear parameters, the
ﬁlter f ˆp(t) gives the estimating function

e ˆp(t)

≡

f ˆp(t)
∞
−∞ f ˆp(t)x(t; 1)dt
R

(14)

where x(t; 1) is the unit-amplitude signal. The only re-
striction on f ˆp(t) is that must not be orthogonal to the
signal.

B. Calculating the Variance of Linear Parameter
Estimates

Throughout the remainder of this paper we will often
drop the explicit dependence on ν of the Fourier energy
density (FED) of the estimating function and the spec-
tral power density (SPD) of the noise process and the
dependence on t of the data and of the estimating func-
tion.

C. Power Density of Stationary Noise Processes

The construction of the SPD in (17) requires that the
time-dependent autocovariance operator be known a pri-
ori. In many instances a construction that uses the spec-
tral information about a noise process is more transpar-
ent. We present and discuss our preferred deﬁnition of
the noise SPD in this section.

The inverse transform of equation (17) is equal to the

∞

0
Z

∞

0
Z

The variance in a parameter estimator is found using
the estimating function and the autocovariance operator

autocovariance operator

var( ˆP ) =

τ

τ

0 Z
0

Z

e ˆp(t1)

δX(t1)δX(t2)
i
h

e ˆp(t2)dt1dt2,

S[δX] cos(2πν(t

t′))dν =

−

δX(t)δX(t′)
i
h

.

(21)

The special case where t = t′ gives the instantaneous
variance of the noise ensemble

(15)

where we recall that capital letters represent ensembles.
This time-domain representation, however, is not neces-
sarily the most convenient or intuitively appealing for-
mulation of the variance. For some noise processes, the
Fourier basis is superior, yielding the expression

var( ˆP ) =

F 2[e ˆp(t); ν]S[δX(t); ν]dν,

(16)

∞

1
2

0
Z

where we denote functionals or linear operators with
square brackets. The spectral power density of the noise,
S[δX(t); ν], is given by

S[δX(t); ν] = 2

∞

−∞ h
Z

δX(t)δX(t′)
i

cos(2πν(t

t′))dt′,

where

−

(17)
and F 2[e ˆp(t); ν], which we call the Fourier energy density
of the estimating function, is

S[δX]dν =

= var(δX(t))

(22)

(δX(t))2
D

E

and shows that the SPD characterizes the contribution to
the estimator variance from the noise contained in each
inﬁnitesimal frequency bin. Our preferred deﬁnition of
the noise SPD is therefore

S[δX; ν]

lim
∆ν→0

≡

∆ν

(FC [δX; ν

∆ν/2])2

±

+ (FS[δX; ν

∆ν/2])2

(23)

= lim
∆ν→0

∆ν

F 2[δX; ν

±

±
∆ν/2]

E

E

D

D

FC [δx(t); ν

∆ν/2]

δx(t) cos(2πνt)dt

(24)

±

±

√2

√2

≡

≡

1
2∆ν

Z

− 1
2∆ν
1
2∆ν

− 1
2∆ν

Z

F 2[e ˆp(t); ν] = (FC [e ˆp(t); ν])2 + (FS[e ˆp(t); ν])2 ,

(18)

FS[δx(t); ν

∆ν/2]

δx(t) sin(2πνt)dt

where

FC [e ˆp(t); ν] = √2

e ˆp(t) cos(2πνt)dt

FS[e ˆp(t); ν] = √2

e ˆp(t) sin(2πνt)dt

∞

Z

−∞
∞

−∞

Z

(19)

are the ﬁnite bandwidth Fourier components of a noise
realization.

The relations (24) are an essential aspect of a Fourier
deﬁnition of the SPD because the Fourier components of
a noise realization diverge as 1/√∆ν
√τ in the limit as
0 for a continuous noise spectrum. Furthermore, if
∆ν

∼

→

a realization of the noise were used in (23) instead of the
ensemble, S[δx; ν] = lim∆ν→0 ∆νF 2[δx; ν
∆ν/2], while
remaining ﬁnite, would not converge. Thus, the SPD is
a property of the noise ensemble, not of any particular
noise realization.

±

D. Examples of Stationary Noise Processes

We now calculate the variance in a parameter estima-
tor due to the inﬂuence of three distinct stationary noise
processes, monochromatic noise, white noise, and ther-
mal noise. We consider in detail the monochromatic case
because it gives insight to parameter estimation using
Fourier techniques and because it provides a straightfor-
ward way to verify the mutual consistency of the coeﬃ-
cients in the variance equation (16), in the two deﬁnitions
of the SPD (17) and (23), and in the normalization of the
Fourier transforms (19) and (24).

=

ǫ2
2

×

=

=

lim
∆ν→0
ǫ2
2
ǫ2
2

δ(ν

(δ(ν

−

ν0)

−

1. Monochromatic Noise

Consider the eﬀect of an additive monochromatic noise
component with amplitude ǫ, frequency ν0, and random
phase φ on a physical signal. A realization of the data is

5

This result, when substituted into equation (16), gives
the same value for the parameter variance as the direct
calculation, (27), and shows that the coeﬃcient of 1/2 in
(16) is consistent with our normalization convention for
the Fourier transforms, (19) and (24).

A rigorous derivation of the monochromatic SPD, us-

ing the deﬁnition (23), gives the same result as (29)

S[δXs; ν] = lim
∆ν→0

∆ν

F 2[δXs; ν

∆ν/2]

±

(cid:10)

(cid:11)

∆ν(ν2 + ν2
0 )

sin2

π(ν−ν0)
∆ν

+ sin2

π(ν+ν0)
∆ν

(cid:17)
ν0)2(ν + ν0)2

(cid:16)

(cid:17)(cid:17)

(cid:16)
π2(ν

(cid:16)
−
ν0) + δ(ν + ν0))

where the second term, δ(ν + ν0), was dropped because
the convention adopted in this paper does not allow neg-
ative frequencies. This derivation shows the consistency
of the two deﬁnitions of the SPD, (17) and (23).

(30)

2. White Noise

x(t) = x(t; ρ) + ǫ cos(2πν0t

φ).

(25)

−

Another example of a stationary noise process is white

The parameter estimate is then

noise, with equal power at all frequencies,

∞

ˆp =

e ˆpxdt

Z

−∞
∞

=

−∞

Z
= ρ +

ǫ
√2

e ˆp (x(t; ρ) + ǫ cos(2πν0t

φ)) dt

(26)

FC [e ˆp; ν0] cos φ +

FS[e ˆp; ν0] sin φ,

−

ǫ
√2

an ensemble of which (each with random phase) consti-
tutes the parameter estimator. The variance of this esti-
mator follows
var( ˆPs) =
1
2π
ǫ2
4

(FC [e ˆp; ν0] cos φ + FS[e ˆp; ν0] sin φ)2 dφ

( ˆPs −
h
ǫ2
2

0
Z
F 2[e ˆp; ν0],

ρ)2

=

=

2π

i

where the s subscript denotes the single frequency noise
model.

The variance in the ensemble of noise realizations is

var(δXs) =

(ǫ cos(2πν0t

(28)

A substitution of (28) into (22) requires the monochro-
matic SPD to be

D

Φ))2

=

−

E

ǫ2
2

.

S[δXs; ν] =

δ(ν

ν0).

(29)

ǫ2
2

−

S[δXwh] = constant = η.

(31)

This eliminates all two-point time correlations giving the
autocovariance operator

δXwh(t1)δXwh(t2)

=

(32)

η
2

δ(t1 −

t2).

(cid:10)

(cid:11)

Although ideal white noise yields inﬁnite power, for this
paper we restrict our attention to calculations for which
no non-physical results occur for pure white noise. The
variance in a parameter estimator may be written as
∞

var( ˆPwh) =

F 2[e ˆp]S[δXwh]dν

(33)

1
2
η
2
η
2

=

=

0
Z

∞

0
Z

∞

F 2[e ˆp]dν

e ˆp

2

dt,

3. Thermal Noise

(27)

−∞
where Parseval’s relation was invoked in the ﬁnal step.

Z

(cid:1)

(cid:0)

The spectral power density of thermal noise is obtained
beginning with the full equation of motion of the oscilla-
tor

m

d2
dt2 + ξ

d
dt

(cid:18)

+ κ

X(t) =

(t)

(34)

(cid:19)

F

F

where
(t) is the thermal driving force. According to
the ﬂuctuation dissipation theorem, the SPD of the driv-
ing force associated with the thermal bath is a constant
4kBT ξ [6, 7]. The response of the oscillator to this white
driving force gives the SPD in displacement (cf. (8))

S[δXth] =

m2

((2πν)2

4kBT ξ
0)2 + (4πγν)2
ω2

−

(35)

(cid:16)
The autocovariance operator is (cf. (7)).

(cid:17)

δXth(t)δXth(t + ∆t)
i
h
kbT e−γ|∆t|
κ

=

cos(ω

(cid:16)

∆t
|

) +
|

sin(ω

∆t
|

)
|

γ
ω

(cid:16)

(cid:17)

(cid:17)

(36)

The integral of the displacement SPD for thermal noise,
unlike the total power of displacement white noise is ﬁnite
and is related to the expectation value for the potential
energy of the oscillator

∞

0
Z

var(δXth) =

S[δXth]dν =

2

P.E.
i
h
κ

=

kBT
κ

= σ2.

(37)
In section III B we ﬁnd the optimal ﬁlter and calculate the
parameter variance for a torsion balance in the presence
of thermal noise.

E. The Structure of Figure 1

We now have the tools needed to describe the structure
of Figure 1, the variance in the boxcar estimator of the
equilibrium displacement of the oscillator as a function of
the sample time. The estimating function for the boxcar
is

eowh
ˆc

(t) = Θ(t; 0, τ )

1
τ

θ(t

where Θ(t; t1, t2)
t2) is the boxcar
t1)
function and θ(t) is the Heavyside (step) function. The
square of the Fourier transform of this estimating func-
tion gives the FED, 2 sinc2(πντ ),

θ(t

≡

−

−

−

(38)

(39)

F 2[eowh
ˆc

; ν] = 2

sin(πντ )
πντ

2

.

(cid:19)

(cid:18)

6

Frequency ™

FIG. 2: Cartoon of a Lorentzian and several sinc2(πντ ) FED
curves, each corresponding to a diﬀerent observation time, as
a function of frequency. The thick solid curve is a Lorentzian
peak with Q0 = 7.5 (chosen for cosmetic reasons). The dash-
two-dot FED curve corresponds to an observation time of
1/10 of a period, the dash-dot curve is for 1/2 a period, the
dashed curve is for 1.25 periods, the dotted is for 1.8 pe-
riods, and the thin-line solid curve is for 8 periods. We see
that, while the 1.25 period observation nulls much of the noise
from the Lorentzian peak, the 1.8 period observation allows a
contribution from the peak. The 8 period observation yields
no signiﬁcant contribution from the peak as the largest rel-
ative maxima of the FED have already passed the peak and
instead allow contributions from the constant portion of the
Lorentzian.

more signiﬁcantly. Figure 2 is a cartoon of a sample
Lorentzian peak and several FEDs, each with diﬀerent
sample times, as a function of frequency.

We see that for very short sample times all of the
Lorentzian noise contributes in nearly equal amounts be-
cause the sinc2(πντ ) envelope is nearly constant. As
the sample time increases, the high frequency noise con-
tributes less to the variance. Eventually, the relative min-
ima and maxima of the FED pass through the Lorentzian
peak and the corresponding relative minima and max-
ima of Figure 1 occur (primarily between 1 and 1/Q0
periods). Finally, for suﬃciently long sample times, the
central peak and several relative maxima of the FED are
so close to the origin that the constant, low-frequency
portion of the Lorentzian dominates the variance.

The SPD of thermal noise acting on the oscillator is
a Lorentzian (35), which for a high Q oscillator peaks
sharply near the resonance frequency.

When viewed as a function of frequency, the relative
maxima and minima of the FED become more densely
spaced as the observation time τ grows. In contrast, the
Lorentzian peak does not depend upon the observation
time and remains ﬁxed. Since the variance (16) is propor-
tional to the integral of the product of the SPD and the
FED, the portions of the SPD near the minima of the
FED contribute very little while the portions near the
maxima, particularly the central maximum, contribute

III. DERIVATION OF THE OPTIMAL FILTERS

Given that nearly any ﬁlter can be normalized to cre-
ate an estimating function, we use the calculus of varia-
tion to ﬁnd the optimal ﬁlter, f op
ˆp (t), that provides the
minimum variance, unbiased estimator. This procedure
requires constraints on the duration of the data sample
that are diﬃcult to express in the Fourier basis. As will
be seen below, working in the time domain overcomes
this challenge for white noise. In section III B we address
this problem for thermal noise.

7

(47)

(49)

(50)

A. Optimal Filters for White Noise

Consider the variance in a parameter estimate for the
oscillator in the presence of white noise and with data
from a continuous time series of length τ ,

var( ˆPwh) =

τ

e2
ˆpdt.

η
2

0
Z

(40)

We take the variation in this equation under the con-
straint (13), imposed by introducing a Lagrange multi-
plier λ, to obtain

δ

var( ˆPwh)

(cid:0)

τ

e ˆpx(t; ρ)dt

η
(cid:1)= δ
2
(cid:18)
τ

=

0
Z

τ

e2
ˆpdt

λ

−

0
Z
(ηe ˆp −

0
(cid:18)Z
λx(t; ρ)) δe ˆpdt.

ρ

−

(cid:19)(cid:19)

(41)

Requiring that this variation be zero for all time shows
that the optimal estimating function is proportional to
the signal, x(t; ρ).

A common expression of this ﬁlter, often called the
“matched” ﬁlter, has the form of the unit-amplitude sig-
nal

f owh
ˆp

(t)

≡

Θ(t; 0, τ )x(t; 1).

(42)

Normalizing the matched ﬁlter yields the optimal esti-
mating function for white noise

Thus, when working in the acceleration basis (the basis
of the thermal driving force), the matched ﬁlter provides
the miminum variance estimator. We deﬁne

z ˆp(t)

Θ(t; 0, τ )Ω[x(t; 1)].

(46)

≡

to be the matched ﬁlter in the acceleration basis. Note
that the transformation to the acceleration basis removes
information about the boundary conditions. This loss of
information is considered later. We normalize and apply
(46) to the stochastic driving force to ﬁnd the parameter
estimate

ˆp =

∞
−∞ z ˆpΩ[x(t)]dt
∞
−∞ z ˆpΩ[x(t; 1)]dt
R
R

.

We now use z ˆp(t) to ﬁnd a corresponding ﬁlter f ˆp(t)
that can be applied directly to the displacement data by
requiring

∞

−∞

∞

−∞

f ˆpxdt =

z ˆpΩ[x]dt

(48)

Z

Z
for all realizations of x. Integrating by parts yields the
solution,

z ˆpΩ[x]dt =

z ˆp (m¨x + ξ ˙x + κx) dt

∞

−∞

Z

(cid:20)

= 0

∞

Z

−∞
∞

∞

−∞ −
(cid:21)
Z
∞

∞

−∞

=

z ˆp (m ˙x + ξx)

( ˙z ˆp(m ˙x + ξx) + κz ˆpx) dt

eowh
ˆp =

τ

Θ(t; 0, τ )x(t; 1)
0 (x(t; 1))2 dt
R

.

(43)

+

(m¨z ˆp −

−∞

ξ ˙z ˆp + κz ˆp) xdt

−

m ˙z ˆpx
(cid:21)

∞

(cid:20)

−∞

Z
ΩT [z ˆp]xdt,

= 0 +

−∞

Z

The boxcar function, Θ, must be included in order to cal-
culate the FED of the estimating function when working
in the frequency domain.

B. Optimal Filters for Thermal Noise

Since the autocovariance operator for thermal noise
(7) is not diagonal, the optimal ﬁlter for thermal noise is
more challenging to ﬁnd, as the operator must be diago-
nalized. To accomplish this, we ﬁrst apply the equation-
of-motion operator Ω to the data to obtain the thermal
driving force

Ω[x(t)] =

m

+ κ

x(t).

(44)

d2
dt2 + ξ

d
dt

(cid:18)

(cid:19)

Because the driving force
= Ω[Xth(t)] is a white noise
process with spectral power density 4kBT ξ, it has the
same diagonal covariance operator as white noise (32)
but with η replaced by 4kBT ξ:

F

Ω[Xth(t1)]Ω[Xth(t2)]
i
h

Ω[δXth(t1)]Ω[δXth(t2)]
i
h

=
= 2kBT ξδ(t2 −

t1).

where we introduce the transpose equation-of-motion op-
erator

ΩT = m

d2
dt2 −

ξ

d
dt

+ κ.

Thus, the optimal ﬁlter for thermal noise in the displace-
ment basis obtained by a transformation from the accel-
eration basis is

ˆp (t) = ΩT [z ˆp(t)] = ΩT [Θ(t; 0, τ )Ω [x(t; 1)]]
f oa

(51)

where the oa superscript denotes that it is the opti-
mal acceleration ﬁlter. Since ΩT acts on the Heavyside
functions, f oa
ˆp (t) can contain terms involving Dirac delta
functions and their derivatives. Normalizing this ﬁlter
gives the optimal estimating function

eoa
ˆp (t) =

ΩT [Θ(t; 0, τ )Ω [x(t; 1)]]
τ +ǫ
−ǫ x(t; 1)ΩT [Θ(t; 0, τ )Ω [x(t; 1)]] dt
R

(52)

where we include the inﬁnitesimal ǫ to avoid ambiguity
regarding how the denominator is evaluated.

(45)

8

C. Estimating the Equilibrium Displacement

We now calculate the optimal ﬁlter and resulting pa-
rameter estimate for the equilibrium displacement of a
thermally perturbed oscillator. The results of this section
are valid only for estimating a single parameter. A sub-
sequent paper will cover the more general case of several
parameters. We assume that the viscous drag coeﬃcient
ξ and the torsional spring constant κ, or equivalently the
damping coeﬃcient γ and the frequency ω0, are known.

The optimal ﬁlter for c is

)

C

€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€

(
r
a
v

2
Σ

100

10−2

10−4

10−4

10−2

100

N

102

(δ(t)

δ(t

τ ))

−

−

FIG. 3: The variance of the estimator ˆC
. The solid curve
is using the boxcar estimate (3), the dotted line is using the
optimal acceleration-only estimate (55), and the dashed line
is the optimal estimate (9).

oa

ˆc (t; c) = ΩT [Θ(t; 0, τ )Ω [x(t; 1)]]
f oa
γ
ω2
0

= m2ω4
0

(θ(t)

τ ))

θ(t

−

−

−

2

(cid:18)
+

1
ω2
0

(δ′(t)

δ′(t

τ ))

−

−

(cid:19)

−

where δ′(t
t0) is the time derivative of the delta func-
tion. We normalize this ﬁlter to obtain the optimal esti-
mating function for the equilibrium displacement of the
oscillator,

eoa
ˆc (t) =

f oa
ˆc (t; c)
m2ω4
0τ

,

which yields the parameter estimate

τ

ˆcoa =

eoa
ˆc x(t)dt

0
Z
xf −

=

xi + Q0ω0τ xm + Q0

Q0ω0τ

(cid:16)

vf −vi
ω0

.

(cid:17)

(53)

(54)

(55)

The variance of the estimator corresponding to (55) is
easiest to calculate in the acceleration basis. A properly
normalized ﬁlter must satisfy

ˆcoa =

eoa
ˆc xdt =

yoa
ˆc Ω [x] dt

(56)

∞

−∞

Z

∞

−∞

Z

where

yoa
ˆc (t) =

Θ(t; 0, τ )
mω2
0τ

(57)

is the result of normalizing the acceleration basis ﬁlter zˆc
as in (14) replacing x(t; 1) with Ω[x(t; 1)] . The variance
in the estimator ˆCoa is given by

var( ˆCoa) =

F 2[y]S[Ω[δX]]dν

∞

1
2

0
Z
= 2kBT ξ

Z

.

=

2σ2
Q0ω0τ

∞

−∞

y2dt

The dotted line in Figure 3 shows the variance in the
estimator ˆCoa for Q0 = 50. We see that this variance
is indeed monotonic and smaller than the variance from
the boxcar estimate for sample times larger than about
0.01 periods, however, for very short sample times the
boxcar estimate has the smaller variance. This failure
results from the loss of information about the boundary
conditions when transforming to the acceleration basis as
mentioned in section III B. These boundary conditions,
when properly accounted for, rectify the failure of this
approach for small sample times.

The initial conditions are the natural boundary con-
ditions because causality dictates that they depend only
on the forces acting prior to the beginning of the sample.
Moreover, because the driving force on the oscillator is
white, the force time series before the sample is uncorre-
lated with that during or after. The initial displacement,
initial velocity, and the acting forces completely deter-
mine the displacement of the oscillator. We, therefore,
write the optimal parameter estimate as linear combina-
tion of the initial conditions and a (not necessarily opti-
mal) acceleration estimate

ˆcoth = w1xi + w2

+ w3ˆca.

(59)

vi
ω0

We wish to determine the choice of the constants w1, w2,
and w3 as well as the acceleration estimate that will pro-
duce the overall minimum variance, unbiased estimator.
Because the initial velocity contains no information
about the equilibrium displacement, w2 must be zero to
minimize the variance in the estimator that corresponds
to the parameter estimate (59). The variance is therefore

(58)

var( ˆC) = w2

1var(Xi) + w2

3var( ˆCa).

(60)

The condition that the estimator be unbiased provides
the constraint

w1 + w3 = 1

(61)

and minimizing the total variance establishes that the
weights w1 and w3 are proportional to the inverse vari-
ances. The weights are therefore given by

(62)

(63)

(64)

(65)

and

w1 =

var( ˆCa)
var(Xi) + var( ˆCa)

w3 =

var(Xi)
var(Xi) + var( ˆCa)

and the variance simpliﬁes to

var( ˆC) =

var(Xi)var( ˆCa)
var(Xi) + var( ˆCa)

.

This last expression is minimized when the optimal ac-
celeration estimator, described previously, is used for ˆCa.

The optimal parameter estimate is then

ˆcoth =

xivar( ˆCoa) + ˆcoavar(Xi)
var(Xi) + var( ˆCoa)

xi + xf + Q0ω0τ xm + Q0

=

2 + Q0ω0τ

(cid:16)

vf −vi
ω0

.

(cid:17)

Note that this parameter estimate has the same time-
reversal symmetry as both the noise and the signal—a
property that the acceleration-only estimate (55) does
not share—and that the weight assigned to the initial
displacement (62) is that which restores the symmetry.
The variance in the optimal parameter estimator is

9

IV. MULTIPLE NOISE PROCESSES

The noise background of a physical system is generally
a superposition of several noise processes. Such a combi-
nation renders the task of ﬁnding the optimal estimator
diﬃcult if not impossible because, among other things,
the basis in which the noise SPD is diagonal is unknown.
We investigate the eﬀects that superposed white noise
or residual transients caused by random, large amplitude
disturbances to the oscillator have on the variance of sev-
eral estimators: the boxcar, optimal thermal, and opti-
mal acceleration estimators, as well as one that we will
call the E¨ot-Wash (EW) estimator. The EW estimator
is related to the one used by the E¨ot-Wash experimental
gravity group at the University of Washington [8]. Since
the E¨ot-Wash group modulates their signal, their model
involves several parameters. Multi-parameter estimation
and a detailed analysis of the estimator used by the E¨ot-
Wash group will be covered in a subsequent paper.

A. Transients

Nonthermal disturbances to a high Q oscillator may
prevent the oscillator from ever reaching equilibrium with
the thermal bath since the relaxation time of transients
may be longer than the average time between the dis-
turbances. Because of this, the inclusion of the initial,
instantaneous displacement estimate, xi, in the optimal
estimate (65) can cause an increase in the variance of the
estimator. To overcome this, consider the optimal accel-
eration estimate in the acceleration basis (56) where the
data time series is solely a transient

var( ˆCoth) =

2σ2
2 + Q0ω0τ

.

(66)

coa =

ae−γt cos(ωt) + be−γt sin(ωt)

dt = 0.

(cid:3)

(67)

τ

yoa
ˆc Ω

0
Z

(cid:2)

The dashed curve in Figure 3 shows the optimal variance
as a function of the sample time duration. For short
time scales, the variance is constant and is dominated by
the uncertainty in determining the initial displacement
(2). For long time scales, the variance falls as 1/τ and
is dominated by the ﬂuctuations induced by the thermal
bath.

This behavior has implications for the utility of using
an active feedback mechanism to damp the oscillator in
an eﬀort to reduce the total variance of the parameter
estimator. While damping the motion of the oscillator
does indeed reduce the variance in the estimate of the
initial displacement, it does not change the variance due
to thermal excitiations because the thermal driving force
depends solely upon the temperature of the environment.
Consequently, the value of using a feedback system de-
pends upon the relative importance of the instantaneous
measurement and the acceleration measurement of the
equilibrium displacement for a particular experiment. In
many instances only the acceleration estimator is used
and a feedback mechanism provides no beneﬁt.

Consequently, no transient can contribute to the param-
eter estimate or the estimator variance when using the
acceleration estimate provided that the disturbance that
causes the transient does not occur while the data are
being aquired.

This shows that the acceleration estimator is supe-
rior under certain conditions. To ﬁnd these conditions
we calculate the variance in the two estimators when an
ensemble of random-phase disturbances with maximum
displacement amplitude ε cause a transient. The optimal
thermal estimator has a variance of (cf. (60) and (62))

var( ˆCoth) =

2σ2
2 + Q0ω0τ

+

ε2
2

2
2 + Q0ω0τ

(cid:18)

2

.

(cid:19)

(68)

Under the same conditions, the optimal acceleration es-
timator has a variance of

var( ˆCoa) =

2σ2
Q0ω0τ

.

(69)

10

)

€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€

C

(
r
a
v

)
p
o
C

(
r
a
v

1.5

1
0.7

0.4

0.2

0.1

)

€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€
€

C

(
r
a
v

)
p
o
C

(
r
a
v

1

0.7

0.4

0.2

0.1

1

1.5

2

5

7

10

1

1.5

2

5

7

10

3
N

3
N

FIG. 4: A plot of the normalized variance of the boxcar (di-
amond), the EW (ﬁlled circle), and the optimal (square) es-
timators in the presence of thermal noise as a function of
sample time (in terms of the number of periods). The results
are calculated to ﬁrst order in 1/Q0.

FIG. 5: A plot of the normalized variance of the EW (ﬁlled
circle) and boxcar (diamond) estimators in the presence of
white noise as a function of the sample time in terms of the
number of periods.

The acceleration estimate is superior when

ε2
2

> σ2

1 +

(cid:18)

2
Q0ω0τ

.

(cid:19)

(70)

With a high Q oscillator, we see that transients as small
as the thermal disturbances can render the optimal ther-
mal estimate inferior to the acceleration estimate. This
1/ω0Q0).
is true even when the sample time is small (τ
For this reason, the acceleration estimator is often used
in lieu of one that accounts for the initial displacement.

∼

B. White Noise and Thermal Noise Combined

1. E¨ot-Wash Approach

When additive white noise is present, the use of xi,
xf , vi, and vf in the optimal estimate yields inﬁnite vari-
ance in the optimal thermal estimator. However, if the
white noise does not dominate, one need not resort to
the boxcar estimate. The EW estimator is quite robust
for systems that are dominated by either white noise or
thermal noise. Its variance is within approximately 1/N
of the optimum in either case, where N is the number of
oscillation periods in the data sample.

The EW approach averages the data with itself delayed
by half of a period. A boxcar average is then taken for
an integer number of oscillation periods. The variance
in the EW estimator in the presence of purely thermal
noise is less than that of the boxcar estimator. Figure 4
shows a comparison of the variance of the EW estimator
with that of the optimal thermal estimate and the boxcar
estimate as a function of the sample time. We see that
the variance in the EW estimator is situated between
the boxcar and optimal estimates and it approaches the
optimal as roughly 1/N . The robustness of the EW es-
timator is manifest when we examine the variance of the

same estimators in the presence of white noise. Because
the optimal thermal estimator has inﬁnite variance for
this case, we show in ﬁgure 5 the variance in the EW
estimator compared with the variance of the boxcar in
the presence of white noise as a function of the sample
time.

Not only is the EW estimator robust under these
changes in the noise background, its variance is more
immune by a factor of 1/Q2
0 to the transient signal than
is the boxcar. To illustrate this property, consider a box-
car estimate. To leading order in 1/Q0 and for an integer
number of periods

ˆcowh =

x(t)dt

nP

nP

1
n

0
P Z
1
n

0
P Z
γ
ω

= c + b

+ O

2

1
Q0 (cid:19)

(cid:18)

=

(ae−γt cos(ωt) + be−γt sin(ωt) + c)dt

where
is the period of the damped oscillator. The
variance in the boxcar estimator, expressed to the same
order, is

P

var( ˆCowh) =

3σ2
Q0ωτ

+

ε2
2

2

.

1
Q0 (cid:19)

(cid:18)

In order for the fractional increase in variance to be small,
the amplitude of the transient disturbance, ε, must sat-
isfy

ε2
2 ≪

6Q0σ2
π
n

.

P

By comparison, with an extra half-period of data, the

(71)

(72)

(73)

EW estimate is

ˆcew =

1
2n

0
P Z
π
2

= c + a

nP

x(t)dt +

2

+ O

γ
ω

(cid:16)

(cid:17)

1
2n

P Z
3

1
Q0 (cid:19)

(cid:18)

and the variance of the estimator is

(n+1/2)P

x(t)dt

P/2

var( ˆCew) =

3σ2
Q0ω0τ

+

ε2
2

π2
4

4

.

1
Q0 (cid:19)

(cid:18)

In this case, a small increase in variance need only satisfy

(74)

(75)

(76)

a signiﬁcant relaxation of the constraint for the boxcar,
(73).

ε2
2 ≪

96Q3
n

0σ2
π3 ,

P

2. Numerical Results

Because it is generally diﬃcult to transform to a rep-
resentation in which an arbitrary mixture of noise has a
white power spectrum, numerical methods are often the
only option available to reduce the uncertainty in a mea-
surement due to the estimation technique. To employ
numerical methods the data is discretized. The optimal
estimator is then found using generalized least-squares
analysis [9]. As an example, we calculate the optimal es-
timator using one and one-half periods of data sampled
at 300 points. For a single linear parameter, the optimal
parameter estimate is found using a discrete ﬁlter given
by

eop
ˆp =

qT m−1

X q

−1

qT m−1
X

(77)

(cid:0)

where mX is the noise covariance matrix and q is some-
times called the design vector. The design vector is given
by the partial derivative of the parameterized data with
respect to the parameter at each time step

(cid:1)

q =

∂
∂c

x.

(78)

For the equilibrium displacement of the oscillator, each
component of the design vector is unity. The data is mul-
tiplied by the ﬁlter (77) to give the parameter estimate.
To investigate the changes in the optimal ﬁlter as the
noise background changes from pure white noise to pure
thermal noise, we normalized the noise covariance matri-
ces for white and thermal noise so that, with one and one
half periods of data, the EW estimator has unit variance.
We then combine some fraction of each of the covariance
matrices so that the sum of the admixture coeﬃcients
is unity. Figure 6 shows an interpolation of the optimal
estimating vector for diﬀerent mixtures of noise. We see
that the optimal ﬁlter starts as a boxcar for pure white

11

f op (t)

f op (t)

4

2

- 2

- 4

4

2

- 2

- 4

P
€€€€€€€
2

P
€€€€€€€
2

P

P

t

t

3 P
€€€€€€€€€€€€€
2

3 P
€€€€€€€€€€€€€
2

4

2

- 2

- 4

4

2

- 2

- 4

f op (t)

f op (t)

P
€€€€€€€
2

P
€€€€€€€
2

P

P

t

t

3 P
€€€€€€€€€€€€€
2

3 P
€€€€€€€€€€€€€
2

FIG. 6: Paneled plots of the optimal ﬁlters derived from 300
discrete datum for a mixture of white and thermal noise. The
top right corner is the optimal ﬁlter for pure white noise, top
left has 10% white, lower left has 1% white, and lower right
has 0.1% white noise.

noise and approaches the combination of a boxcar with
Dirac delta function derivatives (65) as the fraction of
white noise is decreased.

We evaluated the variance of the optimal estimator and
compared it with the unity variance of the EW estimator
for several noise mixtures. For the case of pure white
noise, the variance in the optimal estimator is 89% of the
variance in the EW estimator. The optimal estimator
variance is 90% of the EW estimator variance for 10%
white noise, 84% for 1% white noise, and 80% for 0.1%
white noise. For pure thermal noise (not shown), the
variance in the optimal estimator is 70% of that in the
EW estimator. This analysis is valid for a mixture of only
white noise and thermal noise; transient signals were not
included. Filters such as those shown in ﬁgure 6 are not
generally immune to transient signals. This fact again
illustrates the robustness of the EW estimator because,
in the variance, transient signals are only manifest at
fourth order in 1/Q0.

V. DISCUSSION

Equation (65) deﬁnes the minimum variance, unbiased
estimator for the equilibrium displacement of a damped
harmonic oscillator when statistical ﬂuctuations in ther-
mal equilibrium are the dominant source of noise.
In
deriving this estimate we chose to transform the observ-
able to the acceleration basis in which the thermal noise
spectral power density has a diagonal form (equal noise
power at all frequencies). Once in this “white noise” ba-
sis, the minimum variance estimator is determined by
application of the matched ﬁlter. A subsequent trans-
formation of this estimator back into the displacement
representation gives our result.

This closed-form solution is of great advantage to the
experimentalist. Such a solution for any noise process

serves to guide the design of an experimental apparatus
and the methods used to gather and reduce the experi-
mental data. The corresponding solution for white noise,
the boxcar estimator, has been used extensively as an
optimal estimator under proper criteria or as a point of
departure for the construction of an appropriate estima-
tor.

One example is the EW estimator which is robust and
near optimum under the restriction that the data sample
is a half-integer number of periods in duration. In a lab-
oratory such a requirement can often be met, but there
are circumstances where this criteron is either ineﬃcient,
not feasable, or may be entirely beyond the control of the
observer as is the case in relevant astrophysical scenar-
ios. In such situations the EW estimator would fail to be
near optimum and possibly fail to be deﬁned (e.g. if only
a single half period of data is given). Since the EW es-
timator does not generally apply, one might be tempted
to resort to the boxcar estimator. According to ﬁgure 1
the penalty for such a choice can be an increase in vari-
ance by a factor of order Q. Such an increase can occur
when the assumptions implicit in formulating optimal es-
timates, like the boxcar and optimal thermal estimates,
are not satisﬁed.

When both white and thermal noise processes are
present, neither solution is appropriate. Moreover, the
method used in section III to minimize the variance
(transforming to a diagonal representation) may not be
possible. Under certain circumstances one may ﬁnd an
estimator that is relatively immune to combinations of
noise, such as the EW estimator. More generally, the
only practical option is to discretize the data and use
least-squares methods to ﬁnd the optimal estimator nu-
merically.
In such situations, the interpretation of the
numerical results may not be obvious and the closed form
solution can provide appropriate guidance (c.f. ﬁgure 6).
While we have addressed some aspects of random noise
beyond thermal noise, there are several systematic eﬀects
that we have neglected. These eﬀects can be roughly di-
vided into two groups: eﬀects that can be modeled and
incorporated into the analysis of the data and those that
cannot. The latter group, which includes such things as

12

temperature ﬂuctuations, ﬁber anelasticity or nonlinear-
ity, and sudden relaxations of the ﬁber (ﬁber quakes),
will not be discussed in our articles. The former group,
which includes linear ﬁber drift, damped oscillations, sig-
nal modulation, etc. we will discuss. However, incorpo-
rating these eﬀects into the analysis requires an extension
of the techniques developed in this paper. In future pub-
lications we will address simultaneous ﬁtting for several
linear parameters (for example, to ﬁt for a modulated sig-
nal or linear ﬁber drift) and nonlinear parameters (such
as the oscillation frequency and damping coeﬃcient of
the oscillator).

These subsequent papers will also discuss some of the
implications that the analytic results have on experimen-
tal design. We have already mentioned at the end of sec-
tion III that the use of active feedback to damp the mo-
tion of the oscillator when estimating the equilibrium dis-
placement is beneﬁcial only if one uses the instantaneous
estimate (2) when determining the equilibrium displace-
ment of the oscillator—compare (55) and (65). Another
striking fact is revealed when ﬁtting for the oscillation fre-
quency of the oscillator. We will show that, for thermal
noise, the optimal estimate of the oscillation frequency
requires no more than four measurements of the displac-
ment of the oscillator each period. That is, there is no
direct beneﬁt from having ﬁve or more displacment mea-
surements for thermal-noise-limited experiments where
the oscillation frequency is the signal. These two exam-
ples demonstrate how an analytic expression for optimal
parameter estimators can have signiﬁcant implications
for the design of an experimental apparatus—insights
that do not emerge from numerical solutions.

Acknowledgments

We would like to thank Dr. Brian Walton, Dr. Don
Percival, and Dr. John Deeter for the useful discussions
we had concerning this work and the NSF (Grant PHY-
0244762) for partial support of this work.

[1] E. Fischbach and C. L. Talmage, The Search for Non-
Newtonian Gravity (Springer-Verlag, New York, 1999).

[2] A. Einstein, Ann. Phys. 17, 549 (1905).
[3] S. Chandrasehkar, Rev. Modern Phys. 15, 1 (1943).
[4] M. B. Priestley, Spectral Analysis and Time Series (Aca-

demic Press, New York, 1981).

[5] U. Grenander, Abstract Inference (Wiley, New York,

1981).

[6] H. B. Callen and T. A. Welton, Phys. Rev. 83, 34 (1951).
[7] H. B. Callen and R. F. Greene, Phys. Rev. 86, 702 (1952).
[8] C. D. Hoyle, D. J. Kapner, B. R. Heckel, E. G. Adel-
berger, J. H. Gundlach, U. Schmidt, and H. E. Swanson,
Phys. Rev. D 70, 042004 (2004), hep-ph/0405262.

[9] W. C. Hamilton, Statistics in Physical Science; Esti-

mation, Hypothesis Testing, and Least Squares (Ronald
Press Co., New York, 1964).

[10] In Spectral Analysis and Time Series, Priestley shows
from the work of Weiner and Kolmogorov that, given the
displacement of the oscillator from t = −∞ to t = 0, the
best estimate of the displacement of the oscillator at any
time in the future is to extrapolate the damped oscilla-
tion forward to that time. This result is the answer to a
related, but fundamentally diﬀerent question. It predicts
the best estimate of the displacement given the history of
the oscillator. It does not give the best estimate of the pa-
rameter corresponding to the equilibrium displacement.

