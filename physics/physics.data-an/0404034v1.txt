4
0
0
2
 
r
p
A
 
7
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
4
3
0
4
0
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Techniques for noise removal from EEG, EOG and air ﬂow
signals in sleep patients

Matthew J. Berrymana, Sheila Messera,b, Andrew Allisona, and Derek Abbotta
aCentre for Biomedical Engineering and
School of Electrical and Electronic Engineering,
The University of Adelaide, SA 5005, Australia.
bTexas Instruments Incorporated,
141 Stony Circle, Suite 130, MS 4110
Santa Rosa, California 95401, USA

ABSTRACT

Noise is present in the wide variety of signals obtained from sleep patients. This noise comes from a number
of sources, from presence of extraneous signals to adjustments in signal ampliﬁcation and shot noise in the
circuits used for data collection. The noise needs to be removed in order to maximize the information gained
about the patient using both manual and automatic analysis of the signals. Here we evaluate a number of new
techniques for removal of that noise, and the associated problem of separating the original signal sources.

Keywords: EEG, EOG, air ﬂow, sleep, blind source signal separation

1. INTRODUCTION

Electroencephalograph (EEG) and electrooculograph (EOG) measurement techniques provide valuable infor-
mation on sleep disorders.1, 2 Recent studies looking at memory and learning during sleep have used these
techniques as predictors of waking performance.1, 3, 4 Comparison of thoracic and abdominal movements asso-
ciated with breathing can reveal important information about breathing disorders and events such as apneas
and hypopneas during sleep.5–7

The process by which the EEG and EOG signals are recorded is described by Telpan,8 but a brief summary
is given here. The EEG and EOG signals are recorded by placing electrodes on the patient’s scalp. These
detect electric potentials generated by the ﬂow of ions in neural cells that set up electric dipoles between the
body of the neuron (soma) and the neural branches (apical dendrites). For the data we used, these signals
were ampliﬁed, then digitized at 250 Hz for the EEG and 50 Hz for the EOG signal. We estimate the mutual
information between the second EEG channel, from the left anterior position E1 to just below the opposite
ear, with the left EOG channel, from just to the side of the left eye to the position just above the nose between
the eyes. The signals are broken down into (typically) 30 second long epochs, these are then classiﬁed by a
human operator into various stages of sleep and wakefulness.

The main problems with analyzing the EEG and EOG signal are:

•

•

•

Notch ﬁltering of the the 50 Hz interference ripple from the signals also removes useful information.

Skin conductances can vary over time in diﬀerent ways in diﬀerent locations (however the gel used helps
prevent this problem).

Due to conductances across the skin, the signal received by an electrode is a mixture of the true signals
one is trying to measure.

Send correspondence to Derek Abbott

E-mail: dabbott@eleceng.adelaide.edu.au, Telephone: +61 8 8303 5748

The most signiﬁcant problem is the mixing of signals, this can be reduced using blind signal separation
techniques using higher order statistics.9, 10 The noise can then be removed using wavelet transforms.11–13
We also consider these techniques for the thoracic and abdominal movements, for which similar problems may
arise.7

Time and power spectra plots for one of the EOG and EEG sets of data is shown in Figure 1. Those for

one of the thoracic and abdominal sets of data are shown in Figure 2.

−4

x 10

−4

x 10

1

2

3

5

6

7

8

0

1

2

3

5

6

7

8

4
time (s)

4
time (s)

)

V

(
 
l
a
n
g
s

i

1.5

0.5

2

1

0

−0.5

−1

−1.5

0

−150

−200

)

B
d
(
 
r
e
w
o
p

−250

−300

−350

−400

0

)

V

(
 
l
a
n
g
s

i

2

0

−2

−150

−200

)

B
d
(
 
r
e
w
o
p

−250

−300

−350

−400

0

20

40

60

80

100

120

5

10

15

20

25

frequency (Hz)

frequency (Hz)

(a) The time and power spectrum plots for
the ﬁrst eight seconds of the EEG data. Note
there are many higher frequency signals super-
imposed on lower frequency signals, giving the
appearance of noise, however this is important
signal information that needs to be preserved.
Note that some of the EOG signal is present
on this signal.

(b) The time and power spectrum plots for the
ﬁrst eight seconds of the EOG data. Note the
lack of high frequency signals present in the
EEG signal, since we are concerned here with
low frequency muscle movement signals. The
sampling rate used was correspondingly lower
(50 Hz as opposed to 250 Hz for the EEG).

Figure 1. The time and power spectra plots for the ﬁrst eight seconds of the EEG and EOG data. Note the spectral
diﬀerences between the two, with the EEG having many higher frequency components.

2. METHODS

There are several problems to solve in eliminating noise from the signals. For the problem of the EOG and
EEG signals, we must ﬁrst make ensure the EOG and EEG signals have the same number of data points. To
do this we use a Gaussian smoothing procedure, that is detailed in subsection 2.1. Other related smoothing
procedures could be used, here we assume the distribution of the signal data is Gaussian, this is reasonably
true for the data we use. We then have the problem of separating the sources from the observed signals, which
contain a mixture of both. Three algorithms for this, detailed in subsections 2.4 to 2.6. The noise is removed
from both the sources using wavelet transforms as elaborated on in subsection 2.7. A ﬂowchart of the process
is shown in Figure 3.

To evaluate the performance of the blind signal separation used to separate the source data, and to evaluate
the noise removal we use an eﬃcient algorithm, given in subsection 2.8 to estimate the mutual information
between two signals. We expect this measure to decrease when comparing the original signals with the
separated signals, assuming greater independence between the separated signals, and to remain the same when
comparing the noisy signals with those where the noise has been removed, assuming the noise is uncorrelated

1

2

3

5

6

7

8

1

2

3

5

6

7

8

4
time (s)

4
time (s)

)

V

(
 
l
a
n
g
s

i

)

B
d
(
 
r
e
w
o
p

200

100

0

−100

−200

−300

0

100

50

0

−50

−100

0

)

V

(
 
l
a
n
g
s

i

)

B
d
(
 
r
e
w
o
p

200

100

0

−100

−200

−300

−400

−500

0

100

50

0

−50

−100

0

2

4

6

8

10

12

2

4

6

8

10

12

frequency (Hz)

frequency (Hz)

(a) Time and power spectrum plots for the ﬁrst
eight seconds of the thoracic breathing data.

(b) Time and power spectrum plots for the ﬁrst
eight seconds of the abdominal breathing data.

Figure 2. Time and power spectra plots for the ﬁrst eight seconds of the thoracic and abdominal breathing data. The
sampling rate was 25 Hz, allowing the capture of relatively slow breathing signals. Note the thoracic signal has a slight
phase lead over the abdominal breathing signal.

between the two signals. This is largely true for the signals of interest, although there may be some information
at certain frequencies that is correlated due to extraneous electromagnetic signals being received by the leads,
as they act as antennas. This is kept to a minimum through appropriate grounding.

2.1. Gaussian smoothing

The EEG signal has a sampling rate ﬁve times higher than the EOG (250 Hz to 50 Hz). These are recorded
simultaneously, so every ﬁfth time point in the EEG corresponds to a time point of the EOG signal. We use
Gaussian smoothing to reduce the number of data points in the EEG by a factor of ﬁve:

i+m

xjw (xj , xi)

s (i) =

Xj=i−m
i+m

,

w (xj, xi)

Xj=i−m

w (xj , xi) = e

−(xi−xj )

2

/(2ˆσ

2),

where the weights w (xj, xi) are

i is the discrete time point we are calculating the smoothed average for, and ˆσ2 is the estimate of variance
for the entire set of samples in the EEG signal. Now that the two sets of data, which can be written as
x (t) = [x1 (t) , x2 (t)]T , we can apply blind signal separation, using the following model of the data.

2.2. Data model for blind signal separation
We write the original, m-dimensional source data as s (t) = [s1 (t) , s2 (t, ) , . . . , sm (t)]T . It is assumed that the
sources are independent. We then consider an unknown linear model An×m generating the observed signals,
written as an n-dimensional vector x (t) = [x1 (t) , x2 (t) . . . , xn (t)]T by

x (t) = As (t) ,

(1)

(2)

(3)

Source 1

Source 2

Signal 1

Signal 2

Mixing

Blind
signal
separation

Est. source 1

Est. source 2

Denoising

Denoising 

Cleaned est. 
source 1

Cleaned est.
source 2

Figure 3. Flowchart showing the general steps involved in going from the original sources to the cleaned, estimated
sources. The optional Gaussian smoothing step is not shown.

where A is referred to as the mixing matrix. Being able to swap columns of A, and scaling a source by a scaling
change in a row of A means there is an ambiguity in both the permutation (of labeling) of the sources and
the scaling of the sources respectively. With this model of the data, we can now apply blind signal separation
techniques.

2.3. Blind signal separation

There are two key blind signal separation approaches that are combined to form the joint cumulant and
correlation (JCC) algorithm in subsection 2.6. They are the second order blind identiﬁcation (SOBI) algorithm,
discussed in subsection 2.4, and the joint approximate decomposition of eigenmatrices (JADE), discussed in
subsection 2.5. Both approaches have a common ﬁrst step, in which the data is whitened using a sphering
matrix W, which transforms the mixing matrix A into a unitary matrix U, which is a matrix for which
UUT = I.9, 10 The next step of estimating A is dependent on the choice of algorithm and detailed below.

2.4. SOBI algorithm

Given a hypothesis of sources with diﬀerent spectra and the linear model of Equation 3, we can calculate
time-delayed, cross-correlation matrices,

R (τ ) = E

x (t) x (t
h
ARs (τ ) AH .

τ )T

i

−

for τ

= 0 and

E [s1 (t) s1 (t

τ )]

−

Rs =








0
...
0

E [s2 (t) s2 (t

τ )]

−

0

0
. . .

0
0
. . .

· · ·
· · ·

0
0
...

0

E [sm (t) (t

τ )]

−

,








] the expectation operator. The correlation matrices can then be whitened,
for E[
·

R = WR (τ ) = URs (τ ) UT ,

= 0. The joint diagonalization of the set of p whitened correlation matrices

.9 The
t
∀
}
matrix U can only be uniquely determined iﬀ for any (i, j), there exists at least one lag τk such that
τ )].9 The mixing matrix is then estimated by ˆA = WU. An alternative
E [si (t) si (t
to the SOBI algorithm is the JADE algorithm.

i = 1, . . . , p
|

= E [sj (t) sj (t

R (τi)

τ )]

−

−

{

2.5. JADE algorithm

Here we assume the linear model of Equation 3 and assume independence of sources. To each n-dimensional
vector x is associated a quadicovariance matrix Q : M

N deﬁned by N = QM such that

→

Ni,j =

Cum (xi, xj, xk, xl) Mk,l,

X(k,l)

) is deﬁned as
where Cum (
·

Cum (xi, xj , xk, xl) = E [¯xi ¯xj ¯xk]

E [¯xi ¯xj] E [¯xk ¯xl]

E [¯xi ¯xk] E [¯xj ¯xl]

E [¯xi ¯xl] E [¯xj ¯xk] ,

(8)

−

−

−

E [xi], etcetera.14 As the set of n

n matrices is an n2-dimensional linear space, it can be
and where ¯xi = xi −
×
shown that there exist n2 real eigenvalues λr and n2 orthonormal eigenmatrices Mr satisfying QMr = λrMr.9
It can be proved that only n of the eigenvalues are non-zero,15 and joint diagonalizaton of the n corresponding
eigenmatrices, labeled Mr, gives the unitary matrix U .9 As with the SOBI algorithm, the mixing matrix is
estimated by ˆA = WU. Combining the two algorithms gives us the JCC algorithm.

(4)

(5)

(6)

(7)

6
6
6
2.6. JCC algorithm
In JCC, we use both the correlation information provided by the SOBI algorithm of subsection 2.4, R (τi), and
the cumulant quadricovariance eigenmatrices, Mr, provided by the JADE algorithm. Joint diagonalization
gives the unitary matrix U, which again acts to give an estimator A = WU. Using ˆA we separate the signals
into estimates of the original source data. We then consider removing the noise from this data, using wavelet
techniques.

2.7. Wavelet noise removal

The mathematical description of the continuous wavelet transform (CWT) of f
Mallat16 as

∈

L2 (R) is described by

where

is a family of orthogonal wavelets,

(W f ) (u, s) =

f (t) ψ∗

u,s (t) dt,

+∞

Z

−∞

ψu,s (t) =

,

1
√s
= 0 for (u, s)

= (u′, s′), and

ψu,s|
|

= 1,

ψu,s, ψu′,s′
h
+∞

i

ψu,s (t) dt = 0.

Z

−∞

The scale of the wavelet may conceptually be considered the inverse of the frequency.

The CWT reveals much detail about a signal, however due to the continuous nature it cannot be computed
for real signals on a digital computer. Therefore, the discrete wavelet transform (DWT) is normally used.
The DWT calculates the wavelet coeﬃcients at discrete intervals of time and scale instead of at all scales.
With the DWT, a fast version of the algorithm is possible, analogous to the fast Fourier transform. This
version of the algorithm makes use of the fact that if scales and positions are chosen based on powers of
In 1988, Mallat developed an eﬃcient way
two (dyadic scales and positions) the analysis is very eﬃcient.
to implement this algorithm, which is known as a two-channel sub-band coder.17
For a single level of
decomposition, this algorithm passes the signal through two complementary (high-pass and low-pass) ﬁlters
resulting in approximations which are high-scale, low-frequency components of the signal, and details, which
are low-scale, high-frequency components of the signal. This results in twice as many data-points so the data
is down-sampled. For further levels of decomposition, successive approximations may be iteratively broken
down into details and approximations as shown in Figure 4. Coeﬃcients below a certain level are regarded as
noise and thresholded out. Thresholding may be soft or hard. Hard thresholding is deﬁned as

and soft thresholding as

y = x
y = 0

for
for

> θ
θ

x
|
|
x
| ≤
|

x
y = sign(x)(
|
0
y =

| −

θ)

for
for

> θ
θ

x
|
|
x
| ≤
|

±

where x is the original signal, y is the thresholded signal, and θ is the threshold. Hard thresholding tends
to create discontinuities at x =
θ because any values of the signal less than the threshold are immediately
set to zero. With soft thresholding, the thresholded values are shrunk towards zero without creating the
discontinuities. The signal is then reconstructed without signiﬁcant loss of information. Then the signal may be
reconstructed by up-sampling, passing the approximations and details through the appropriate reconstruction
ﬁlters and combining the results. Based on SNR measures of wavelet performance, we used Daubechies wavelets
of order 5, with soft thresholding and a decomposition level of 5; although this is not the best for noise removal,
we are more interested in preservation of information when going from the estimated sources to the denoised
estimated sources.

To evaluate the performance of the above techniques we introduce a measure of mutual information.

(9)

(10)

(11)

(12)

(13)

6
Figure 4. This ﬁgure illustrates how (a) the discrete wavelet transform decomposes a signal into details and approx-
imations iteratively decomposing the approximations; (b) wavelet packets iteratively decompose the approximations
and details.

2.8. MI estimation algorithm

The following is an outline of the method we use in calculating the mutual information between the EEG and
EOG signals, as given in Kraskov et al..18

Mutual information for two signals X and Y is deﬁned in Equation 14

I (X, Y ) =

µ (x, y) log

∞

∞

Z

−∞ Z

−∞

µ (x, y)
µx (x) µy (y)

dxdy,

where µ, µx and µy are probability measures. We then take the set of points zi = (xi, yi) for the EEG xi and
EOG yi, i = 1, . . . N . Then we ﬁnd the kth closest neighbor of each zi according to the metric

{|
The kth nearest neighbor is then projected onto the x and y axes giving the distances ǫx (i) /2 and ǫy (i) /2
respectively. The mutual information is estimated by:

−

−

−

|}

|

z
|

z′

= max

x

x′

,
|

y
|

y′

.

ˆIk (X, Y )

ψ (k)

1/k

ψ (nx) + ψ (ny)

+ ψ (N ) ,

≈

−

− h

i

where ψ (

) is the digamma function given by
·

and

d
dz

N

Xi=1

ψ (z) =

ln Γ (z) ,

. . .
h

i

=

1
N

E [. . . (i)] .

3. RESULTS

(14)

(15)

(16)

(17)

(18)

3.1. Blind signal separation

We compared the blind signal separation for three algorithms, across four sets of data, two of thoracic and
abdomen (TA) breathing data, and two of EEG and EOG (EE) data. The diﬀerences in mutual information
between the signal data and the estimated source data are shown in Table 1. The higher the mutual informa-
tion, the better the algorithm is for separating the original sources, given the assumptions of that algorithm.

3.2. Wavelet denoising

For each of the generated estimates of the sources (three blind signal separation algorithms applied to four
pairs of signals) we estimated the mutual information between the estimates of the sources, and the denoised
estimates of the sources. These are given in Table 2. We observe no diﬀerence in mutual information between

Table 1. The diﬀerence in mutual information (in nats/sample) between the two estimated sources and the two signals,
ˆIk (est. sources) − ˆIk (signals), for the two sets of thoracic-abdominal (TA) data and the two sets of EEG and EOG
(EE) data. Nats are units of information, when a natural logarithm is used. This is computed for all three (SOBI,
JADE, and JCC) algorithms

TA1
1.0319

TA2
SOBI
0.4539
JADE < 0.0001 < 0.0001 < 0.0001 < 0.0001
JCC
0.4292

EE2
0.6101

EE1
0.4522

0.4032

0.5342

0.3640

Table 2. The diﬀerence in mutual information (in nats/sample) between the JADE estimated sources and the wavelet
denoised estimated sources is computed for the two sets of thoracic-abdominal (TA) data and the two sets of EEG and
EOG (EE) data, ˆIk (est. denoised sources) − ˆIk (est. sources). Nats are units of information, when a natural logarithm
is used.

TA1

TA2
< 0.0001 < 0.0001 < 0.0001

EE1

EE2
0.0001

4. DISCUSSION & CONCLUSIONS

For our particular set of thoracic and abdominal breathing data, the SOBI algorithm works well, with an
increase in the mutual information, probably because the sources have reasonably distinct spectra. Since the
JCC combines information from both the SOBI and JADE algorithms by way of joint diagonalization, it
introduces the problems associated with using the JADE algorithm for this data, namely that the sources are
not independent. The two sources have a high level of dependence, being almost synchronous during regular
breathing, tending to diﬀer only for compliant chests in young children or when a breathing obstruction
occurs.5, 7 Similarly, for the EEG and EOG data, although these are more independent, the SOBI algorithm
performs best at separating the original sources from the observed signals.

The wavelet denoising performs well, in that it preserves (as far as we can determine) the information present
in the signals. Further work will consider wavelet packet and matching pursuit denoising algorithms,17, 19, 20
and how these eﬀect mutual information between two diﬀerent channels. We will also consider the eﬀect of
swapping the denoising and blind signal separation techniques, in theory this should have little to no diﬀerence
on the results.

We acknowledge funding from The University of Adelaide. Useful discussions with Cosma Shalizi from the
Center for the Study of Complex Systems at the University of Michigan were greatly appreciated.

5. ACKNOWLEDGEMENTS

REFERENCES

1. K. Kaemingk, A. Pasvogel, J. Goodwin, M. S.A., F. Martinez, P. Enright, G. Rosen, W. Morgan,
R. Fregosi, and S. Quan, “Learning in children and sleep disordered breathing: ﬁndings of the Tucson
children’s assessment of sleep apnea (TuCASA) prospective cohort study,” Journal of the International
Neuropsychological Society 9, pp. 1016–1026, 2003.

2. E. Sforza, S. Grandin, C. Jouny, T. Rochat, and V. Ibanez, “Is waking electroencephalographic activity a
predictor of daytime sleepiness in sleep-related breathing disorders?,” European Respiratory Journal 19,
pp. 645–652, 2002.

3. A. Muzur, E. Pace-Schott, and J. Hobson, “The prefrontal cortex in sleep,” Trends in Cognitive Sciences

6, pp. 475–481, 2002.

4. P. Anderer, G. Gruber, G. Kl¨osch, W. Klimesch, B. Saletu, and J. Zeitlhofer, “Sleep and memory consol-

idation: the role of electrophysiological neuroimaging,” Somnologie 6, pp. 54–62, 2002.

5. K. Brown, R. Platt, and J. Bates, “Automated analysis of paradoxical ribcage motion during sleep in

infants,” Pediatric Pulmonology 33, pp. 33–46, 2002.

6. G. Prisk, J. Hammer, and C. Newth, “Techniques for measurement of thoracoabdominal asynchrony,”

Pediatric Pulmonology 34, pp. 462–472, 2002.

7. V. Menon and D. Agrawal, “Physics of quiet and suﬀocative breathing,” American Journal of Physics

71, pp. 474–478, 2003.

8. M. Teplan, “Fundamentals of eeg measurement,” Measurement Science Review 2, pp. 1–11, 2002.
9. I. Gorodnitsky and A. Belouchrani, “Joint cumulant and correlation based signal separation with appli-

cation to EEG data analysis,” in ICA 2001, 2001.

10. A. Belouchrani, K. Meraim, J.-F. Cardoso, and E. Moulines, “A blind source separation technique using

second order statistics,” IEEE Trans. on Sig. Proc. 45, pp. 434–444, Feb. 1997.

11. M. Matalgah and J. Knopp, “Improved noise stability multiresolution ﬁlters based on a class of wavelets,”
in Proceedings of the 37th Midwest Symposium on Circuits and Systems: Vol 2., pp. 817–820, IEEE, Aug.
1994.

12. O. Bertrand, J. Bohorquez, and J. Pernier, “Time-frequency digital ﬁltering based on an invertable
wavelet transform: an application to evoked potentials,” IEEE Transactions on Biomedical Engineering
41, pp. 77–88, Jan. 1994.

13. L. M. Lim, M. Akay, and J. A. Daubenspeck, “Identifying respiratory-related evoked potentials,” IEEE

Engineering in Medicine and Biology 14, pp. 174–178, Mar.Apr. 1995.

14. J.-F. Cardoso, “High-order contrasts for independent component analysis,” Neural Computation 11,

pp. 157–192, 1999.

15. J.-F. Cardoso and A. Souloumiac, “An eﬃcient technique for blind separation of complex source,” in

Proc. IEEE Sig. Proc. Workshop on Higher-Order Stat., pp. 275–279, 1993.

16. S. G. Mallat, A Wavelet Tour of Signal Processing, Academic Press, 1999.
17. S. G. Mallat, “A theory for multiresolution signal decomposition: the wavelet representation,” IEEE

Transactions on Pattern Analysis and Machine Intelligence 11, pp. 674–693, July 1989.

18. A. Kraskov, H. St¨ogbauer, and P. Grassberger, “Estimating mutual

information,” ArXiv cond-

mat/0305641 , May 2003.

19. S. G. Mallat and Z. Zhang, “Matching pursuits with time-frequency dictionaries,” IEEE Transactions on

Signal Processing 41, pp. 3397–3415, Dec. 1993.

20. S. Krishnan and R. M. Rangayyan, “Automatic denoising of knee-joint vibration signals using adaptive
time-frequency representations,” Medical and Biological Engineering and Computation 38, pp. 2–8, Jan.
2000.

