2
0
0
2
 
c
e
D
 
2
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
9
4
0
2
1
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Statistical Analysis of Composite Spectra

A. Y. Abul-Magd1,2, H. L. Harney1, M. H. Simbel1,2, and
H. A. Weidenm¨uller1

September 22, 2013

Abstract

We consider nearest–neighbor spacing distributions of composite
ensembles of levels. These are formed as a superposition of indepen-
dently unfolded sequences of levels containing only few levels each.
Two problems arise in the spectral analysis of such data. One prob-
lem lies in ﬁtting the nearest–neighbor spacing distribution function
to the histogram of level spacings obtained from the data. We show
that the method of Bayesian inference is superior to this procedure.
The second problem occurs when one unfolds such short sequences.
We show that the unfolding procedure generically leads to an overes-
timate of the chaoticity parameter. We discuss previous analyses of
nuclear data in the light of these results.

PACS number(s): 02.50.Tt, 05.45.Mt

1 INTRODUCTION

The statistical analysis of spectra aims at a comparison of the spectral ﬂuc-
tuation properties of a given physical system with theoretical predictions
like those of random–matrix theory (RMT), those for integrable systems, or
interpolations between these two limiting cases.

In many cases, the spectra under consideration involve a relatively small
number of levels. This is, in particular, the situation in the analysis of spectra
of nuclei in the ground–state domain [1, 2, 3, 4, 5, 6, 7, 8, 9]. Here one usually
deals with sequences of levels of the same spin and parity containing only 5 or

1

10 levels or so. Several or many such sequences are then combined to obtain
an ensemble of statistically relevant size. The sequences forming the ensemble
may involve levels of diﬀerent spin-parity or levels from diﬀerent nuclei, or
both. The resulting data set is typically analysed with regard to the nearest–
neighbor spacing (NNS) distribution only. Correlations between spacings of
levels are not investigated in view of the shortness of the individual sequences
under consideration.

In the present paper, we address two problems which arise in the analysis
of such data. First, we ask whether the usual procedure (i.e., the ﬁtting of
a histogram of the NNS distribution) is the optimal way of analysing the
data. We compare this method with the method of Bayesian inference which
has been successfully used to analyze the statistical properties of coupled
microwave resonators [10, 11]. Second, for a reliable statistical analysis, one
ﬁrst has to ”unfold” the individual sequences. This yields a new data set with
mean level spacing unity. Then, one has to combine these level sequences to
form a larger ensemble of spacings suitable for the statistical analysis. We
investigate the statistical accuracy of the unfolding procedure.

In Section 2 we give a brief summary of formulas for the NNS distribution
and of spectral analyses using these expressions. In Section 3, we give a short
account of Bayesian inference tailored to the problems just mentioned. In
Section 4, we address these two problems. Section 5 contains a summary and
our conclusions.

2 The NNS distribution

The canonical ensembles of random–matrix theory (RMT) [12] are classiﬁed
according to their symmetries. Here we focus attention on systems which are
invariant under time reversal and under space rotations. Such systems are
represented by the Gaussian orthogonal ensemble (GOE) of random matrices.
The NNS distribution of levels of the GOE is well approximated by Wigner’s
surmise [13]

pW(s) =

s exp

π
2

π
4

s2

(cid:19)

.

(cid:18)−

(1)

Here, s is the spacing of neighboring levels in units of the mean level spacing.
RMT was introduced originally to describe the spectral ﬂuctuation prop-
erties of complex quantum systems. More recently, it was conjectured [14]

2

that RMT also applies to quantum systems whose classical counterpart is
chaotic. This conjecture has enormously widened the range of applications
of RMT [15, 16] and has led to a juxtopposition of RMT and of the theo-
retical description of quantum systems which are integrable in the classical
limit. The latter possess a NNS distribution which is generically given by
the Poisson distribution,

pP(s) = exp (

s) .

−

(2)

There also exist intermediate situations. This is the case, for instance, in
mixed systems where in some parts of classical phase space, the motion is
regular and in other parts, it is chaotic. The spectral ﬂuctuations of mixed
systems are studied using formulae which interpolate between the Poisson
and Wigner distributions (see Refs [15, 17, 18] and references therein). Sys-
tems with singularities that are integrable in the absence of these singularities
(see, e.g., Refs. [19, 20, 21]) also possess intermediate statistics. An interme-
diate behavior between the GOE and Poisson statistics is also shown by the
spectrum of a fully chaotic system when a conserved symmetry is ignored.
We address the case of mixed symmetries in Section 4.1.

Another situation arises for systems with a weakly broken symmetry.
When a symmetry in a system is strictly conserved, the Hamiltonian becomes
block–diagonal. Each block represents a quantum number (or a set of quan-
tum numbers) of the symmetry and may be considered a member of a GOE.
Symmetry breaking is modelled by introducing oﬀ–diagonal blocks that cou-
ple blocks with diﬀerent quantum numbers. Examples are the studies of
isospin mixing in nuclei [22], and the ”complete” spectrum of low–lying states
of 26Al involving states with isospins T = 0 and 1 [5]. Such data oﬀer a testing
ground for studying the inﬂuence of isospin–symmetry breaking on the ﬂuc-
tuation properties of energy spectra (see, e.g., Refs. [1, 2, 3, 4, 5, 6, 7, 8, 9]).
However, the limited data available in 26Al (142 levels) precluded a deﬁni-
tive conclusion. In a recent experiment with monocrystalline quartz blocks,
Ellegaard et al. [23] measured about 1400 well–resolved acoustic resonances.
The properties of quartz allowed these authors to measure the gradual break-
ing of a point–group symmetry which is statistically fully equivalent to the
breaking of a quantum number like isospin. In an analogous experiment by
Richter and collaborators [24], two superconducting microwave resonators
were electomagnetically coupled. The number of observed levels was about

3

1500. This large number was crucial for the validity of the subsequent sta-
tistical analysis of the spectra [25, 10, 11]. We address the case of a weakly
broken symmetry in Section 4.1.

3 BAYESIAN ANALYSIS OF NNS

DISTRIBUTIONS

The Bayesian analysis of the NNS distribution proceeds in three steps. First,
we propose a probability distribution p(s, f ) for the observed spacings of
nearest neighbors. Second, we determine the posterior distribution P (f, s)
for the parameter f on which the distribution p depends. Third, we deduce
the optimum value of f together with its error.

3.1 Proposed NNS Distribution

{

si}

We consider a sequence S of N spacings s =
of nearest neighbors, with
i = 1, ..., N. We assume that the levels from which S is formed, all have
the same spin and parity. The levels may, however, diﬀer in other conserved
quantum numbers which are either unknown or ignored. The sequence S
can then be represented as a superposition of m independent subsequences Sj
each having fractional level density fj, with j = 1, ..., m, and with 0 < fj ≤
1
and
j = 1. In practice we often deal with a rather large set of sequences
S but consider only a single one in the present Section.

P
Let pj(s) denote the NNS distribution for subsequence Sj with j = 1, ..., m
and p(s) the NNS distribution of sequence S. We deﬁne the associated
∞
s ds′
s′ pj(x)dx for the subsequences and the gap
gap functions Ej (s) =
∞
s ds′
s′ p(x)dx for sequence S. Mehta [12] has shown
function E (s) =
R
R
that E(s) and the Ej(s) are related by
R

m
j=1 f 2

∞

∞

R

E (s) =

Ej (fjs) .

(3)

Given E (s), p(s) can be found by taking the second derivative of E (s). We
aim at an approximate evaluation of E (s) and, thence, of p(s).

We assume that each of the distributions pj(s) is determined by the
Gaussian orthogonal ensemble (GOE). To an excellent approximation, the

m

Yj=1

4

−

−

pj(s)’s are then given by the Wigner surmise Eq. (1). Using this assumption
in Eq. (3) makes E (s) a function of the (m
1) unknown parameters fj,
j = 1, ..., (m
1). This fact poses a diﬃculty because in practice, we do not
know the composition of the spectrum. We are not even sure of how many
quantum numbers other than spin and parity are conserved. To overcome
this diﬃculty, we use an approximate scheme ﬁrst proposed in Ref. [26]. This
scheme leads to an approximate NNS distribution for the sequence S which
depends on only a single parameter, the mean fractional level density f for
the superimposed subsequences. This quantity will eventually be used as a
ﬁt parameter.

We write the cumulative spacing distribution W (s) as

W (s) = 1

= 1 + exp

θ (s) + ln [

{

dθ(s)/ds]
}

−

,

(4)

dE(s)
ds

−

j=1 ln [Ej (fjs)].

where θ (s) = Σm
In Refs. [26], a simple expression for the
cumulative spacing distribution was obtained by expanding the exponent in
Eq. (4) in powers of s and neglecting terms of higher order than the second.
This procedure was motivated by the fact that p(s) is mainly determined by
short–range level correlations. We follow this procedure and obtain

W (s) = 1

exp

qs

−

(cid:18)−

−

π
4

Qs2

(cid:19)

q = 1

Σn

j=1f 2

j [1

pj (0)]

−

−

2
π (cid:18)

Q =

Σn

j=1f 2

j [1

pj (0)] +

j=1f 2

j [1

pj (0)]

−
j=1f 3
Σn
j

−

2
h

−

Σn
n
3pj (0)

−

p′
j (0)

.

i(cid:19)

−

2

o

The Wigner surmise for each of the pj’s implies pj(0) = 0 and p′
The parameter q given by Eq. (6) becomes

j(0) = π/2.

where

and

where

(5)

(6)

(7)

(8)

(9)

q = 1

f ,

f =

f 2
j .

−

m

Xj=1

5

P

j fj = 1, we cannot use the mean value of the fj’s as a measure of the
Since
mean fractional density. The parameter f with 0 < f
1 deﬁned in Eq. (9)
is the next best choice. We refer to f as to the mean fractional level density
for the superimposed sequences. The parameter Q is, in principle, given by
Eq. (7). We will, however, replace this condition by another one which is
found as follows.

≤

The approximate NNS distribution is obtained by diﬀerentiating expres-

sion (5) with respect to s,

p(s) =

dW (s)
ds

.

(10)

In going from Eq. (4) to Eq. (5), we have neglected higher powers of s in the
W (s)]. This neglect entails, however, that the distribu-
expansion of ln[1
tion (5) does not satisfy the condition of unit mean spacing

−

∞

0
Z

∞

0

Z

−

xp(x)dx =

[1

W (x)] dx = 1 .

(11)

In order to satisfy this condition we determine the parameter Q from Eq. (11)
while keeping Eq. (6) for the parameter q. We do so in order to maintain the
correct behavior of a collection of independent GOE subsequences at small
values of s. Hopefully, this approximation will take into account some of the
eﬀects of the neglected terms in the power–series expansion of the logarithm.
The proposed NNS distribution of the composite spectrum is then given by

p(s, f ) =

1

f + Q(f )

exp

(1

f ) s

Q(f )

(12)

−

(cid:20)

"−

−

−

πs
2 (cid:21)

πs2
4 #

,

where Q(f ) is deﬁned by the condition (11). This procedure yields an implicit
relation between Q and f which involves a complementary error function. We
have numerically solved the implicit equation and obtained Q(f ) for f in the
0.9. The resulting solution was approximated by the
f
interval of 0.1
≤
parabolic relation

≤

Q(f ) = f (0.7 + 0.3f ) .

(13)

With this approximation, the mean spacing diﬀers from unity by less than
0.5 %. The distribution (12) coincides with the exact expression up to the
6th decimal digit. The exact values were obtained by doubly diﬀerentiating
Eq. (3), see Ref. [12].

6

→

In this limit, p(s, f )

For a superposition of a large number of sequences, f is of the order
of 1/N.
p(s, 0) = pP(s) given by Eq. (2). This
expresses the well–known fact that the superposition of many GOE sequences
produces a Poisson distribution. On the other hand, when f
1, the
spectrum approaches the GOE behavior. Indeed, p(s, 1) coincides with the
Wigner distribution (1) as expected for a single GOE sequence. This is
why we refer to f as to the chaoticity parameter. A supposedly ”pure”
sequence of nuclear levels may not be pure, but rather a superposition of
subsequences corresponding to diﬀerent values of an ignored or unknown
quantum number. Then the mean value f of the fractional density of the
superimposed sequences is smaller than unity, and the composite sequence
looks rather regular.

→

[11].

A system with partially broken symmetries can also be approximately
represented by a superposition of independent sequences. This has been
shown in Ref.
In this case, the distribution (12) which diﬀers from
zero at s = 0, is not accurate for very small spacings because the symmetry–
breaking interaction lifts the degeneracies. However, this defect does not
aﬀect the long-range statistics (e.g., Σ2 or ∆3), nor the spacing distribution
beyond the domain of very small spacings. The magnitude of this domain
depends on the ratio of the strength of the symmetry–breaking interaction
to the mean level spacing.

In summary, Eq. (12) deﬁnes the probability distribution proposed for

the analysis of the data.

3.2 Posterior Distribution

We proceed to the second step of Bayesian inference, the calculation of the
posterior distribution for f given the events s. We ﬁrst determine the joint
probability distribution p (s
f ) of the set of spacings s = (s1, s2, ..., sN ). We
take the experimental sj to be statistically independent. This assumption
may not apply in general. Indeed, the GOE produces signiﬁcant correlations
between subsequent spacings. However, we are interested only in the NNS
distribution, and the assumption of statistical independence of subsequent
spacings is, therefore, irrelevant. We accordingly write

|

p (s

f ) =
|

p(si, f ) ,

(14)

N

Yi=1

7

with p(si, f ) given by Eq. (12). Bayes’ theorem then provides the posterior
distribution

P (f

s) =

|

p(s
f )µ(f )
|
M(s)

M(s) =

p (s

f ) µ (f ) df

1

0
Z

|

of the parameter f given the events s. Here, µ(f ) is the prior distribution
and

is the normalization. We use Jeﬀreys’ rule [27] to ﬁnd the prior distribution

µ(f )

p (s

f ) [ ∂ ln p (s

f ) / ∂f ]2 ds

|

|

∝ (cid:12)
Z
(cid:12)
(cid:12)
(cid:12)

1/2

.

(cid:12)
(cid:12)
(cid:12)
(cid:12)

We substitute Eq. (14) into formula (17), evaluate the integral numerically
and approximate the result by the polynomial

µ (f ) = 1.975

10.07f +48.96f 2

135.6f 3+205.6f 4

158.6f 5+48.63f 6 (18)

−

−

−

of sixth order in f .

The distribution p (s

f ) assumes very small values even for only moder-
ately large values of N. Because of this fact the accurate calculation of the
posterior distribution becomes a formidable task. In order to simplify the
calculation, we have rewritten Eq. (14) in the form

|

φ(f ) = (1

f )

f (0.7 + 0.3f )

ln

1

f +

f (0.7 + 0.3f ) s

+

s

h

i

π
4

−

s2

h

i − h

−

(cid:20)

π
2

where

Here, the notation

p (s

f ) = e−N φ(f ) ,
|

=

x
i

h

1
N

N

Xi=1

xi

has been used. By calculating the mean values
in Eq. (20) for various
spectra, one ﬁnds the function φ(f ) to have a deep minimum, say at f =
f0. One can therefore represent the numerical results in analytical form by
parametrizing φ as

h· · ·i

φ(f ) = A + B (f

f0)2 + C (f

f0)3 .

(22)

−

8

−

(15)

(16)

(17)

(19)

.

(cid:21)i
(20)

(21)

≃

In the analysis of the NNS distributions for the coupled microwave res-
onators [11], the number of spacings for each coupling has been so large
(N

1500) that a Gaussian function

PG (f

s)

exp

NB(f

|

∝

{−

f0)2

}

−

(23)

s ) very
has described the f –dependence of the posterior distribution P (f
|
well. Indeed, in the six cases under consideration in Ref. [11], the posterior
1/√2NB. In this range,
distribution almost vanishes except when
the function µ(f ) is nearly constant and the third–order term in Eq. (22) is
immaterial. Therefore, the posterior distributions obtained in that analysis
have been Gaussians. Each one is characterized by a mean value f0 and a
variance σ0 = 1/√2NB. The present analysis, however, addresses NNS dis-
tributions that involve a considerably smaller number of spacings. Therefore,
we cannot further simplify the approximations (18) and (22) and arrive at

f0| ≤

−

f

|

P (f

s) = cµ (f ) exp

B (f
h
as the expression for the posterior distribution. Here c = e−N A /M(s) is the
new normalization constant.

(24)

N

−

−

−

i(cid:17)

(cid:16)

|

f0)2 + C (f

f0)3

3.3 Best–Fit Value for f

The third and last step of the Bayesian analysis consists in determining the
best–ﬁt value of the chaoticity parameter f and its error for each NNS dis-
s ) is not Gaussian, the best–ﬁt value of f cannot be
tribution. When P (f
taken as the most probable value, i.e., as the value at the peak of the distribu-
tion. Rather we take the best–ﬁt value to be the mean value f and measure
the error by the standard deviation σ of the posterior distribution (24) using
the corresponding values of f0, B, and C, i.e.
1

|

1

f =

f P (f

s) df ,

and σ2 =

0
Z

|

2

f

P (f

f
(cid:16)

−

0
Z

(cid:17)

s) df .
|

(25)

4 ANALYSIS OF COMPOSITE

ENSEMBLES

The purpose of this Section is twofold. First, we test the method deﬁned in
Section 3. Second, we turn to another problem posed by the analysis of a

9

large number of short sequences: The unfolding procedure.

4.1 Test of the Bayesian Method

In order to test the method, we construct an ensemble that obeys the distri-
bution law (12) with a given value of the chaoticity parameter f0. We then
analyse this ensemble in two ways: We use the standard procedure of ﬁtting
the distribution formula Eq. (12) to a histogram of the spacings, and we use
the Bayesian method. We compare the results with each other and with the
“true” value f0 of the chaoticity parameter. The diﬀerence provides a mea-
sure of the reliability of the inference of f0 from the experimental spacings
for which the true value of f0 is unknown.

We construct the ensemble with the help of a random–number generator.
We choose average spacing unity and a ”true” value f0 = 0.6 for the chaoticity
parameter. This value is close to what has been obtained in the previous
analysis [6] of low–lying nuclear levels. We generate a set of random numbers
ri, i = 1, . . . , l from a distribution with unit density between 0 and 1. We
then equate the cumulative spacing distribution W of Eq. (5) with each of
these random numbers.
In each case, we calculate the spacing by solving
Eq. (5) for s, i.e., from the formula

si =

0.482 +

0.233

2.41 ln ri.

−

q

−

(26)

In this way, we generate three initial artiﬁcial ensembles of 50, 100, and 200
spacings.

We then subject the three ensembles to a statistical analysis. We ﬁrst
represent the spacing distributions for the three ensembles in terms of his-
tograms. The bin size for the histograms was taken once equal to 0.2 and
once equal to 0.3. We determine the chaoticity parameter f for each of the
six histograms by a χ2–ﬁt to the NNS distribution deﬁned by Eq. (12). The
results are given in Table I under the label “initial ensemble” and in Figs. 1
and 2. The Figures show that the shapes of the histograms do not exactly
follow the distribution (12), especially for the smallest ensemble. Increasing
the bin size of the histograms leads to shapes that better agree with the an-
alytical distribution. One clearly sees this by comparing Figs. 1 and 2. The
χ2–ﬁt values for f diﬀer from the true value 0.6, and the diﬀerence is statis-
tically signiﬁcant in spite of the systematic improvement that takes place as

10

the size of the ensemble increases from 50 to 200 spacings. This observation
suggests that one should not analyze a small sample of data using a ﬁt to a
histogram. We note, moreover, that the best–ﬁt values of f practically do
not change as one changes the size of the bins, and remain unsatisfactory.

We also determine f by the Bayesian method. We do this twice for each
distribution. First, we allow the prior distribution µ(f ) to vary according
to Eq. (18) and calculate the posterior distribution using Eq. (24). Second,
we take µ(f ) constant, and approximate the posterior distribution by the
Gaussian formula Eq. (23). In both cases we determine f and the variance
from a best–ﬁt procedure. The results are given in Table I under the label
“initial ensemble”. We ﬁnd that the Bayesian method correctly reproduces
the true value of f0 = 0.6 within the statistical error for all three distributions
involving 50, 100, and 200 spacings. The Gaussian approximation given by
Eq. (23) is satisfactory in these cases.

We conclude that for small samples of level spacings an analysis based
on the Bayesian method is more powerful than the standard procedure of
statistical analysis based on a ﬁt to histograms.

4.2 Test of the Unfolding Procedure

In the case of a single long sequence, unfolding is a standard procedure. This
is not so in the case of many short sequences. We call this a ”composite
ensemble”. One may believe that for such sequences, unfolding is altogether
irrelevant because the mean level density changes slowly. However, sequences
of levels of the same spin and parity taken from the nuclear ground–state
domain are examples to the contrary.

To test the standard unfolding procedure, we generate short sequences of
levels from the three ensembles constructed in Section 4.1. These are referred
to as the “initial” ensembles. Each such sequence is then artiﬁcially folded
with a monotonically increasing function of energy. An unfolding procedure
is subsequently applied to each sequence. The unfolding procedure does not
trivially reproduce the initial ensembles and yields the ”ﬁnal” ensembles.
The chaoticity parameter f is then determined for the ﬁnal ensembles using
the Bayesian method outlined in Section 4.1.

We have investigated the three ensembles generated in Section 4.1. For
the ensemble containing 50 spacings, we constructed 8 level sequences. There
are 3 sequences of 5 levels, 2 sequences of 6 levels, and one sequence each

11

of 9, of 10 and of 12 levels. For the ensemble containing 100 spacings, we
have arranged the set into 6 sequences of 5 levels, 4 sequences of 6 levels,
two sequences of 7 and two sequences of 10 levels, and one sequence each
of 8, 9, and 12 levels. For the ensemble containing 200 spacings, we chose
9 sequences of 5 levels, 6 sequences of 6 levels, 5 sequences of 7 levels, 3
sequences of 8 levels, 4 sequences of 10 levels, and one sequences each of
9, 17, and 24 levels. Our choices mirror typical sets of empirical data in
nuclei. For each sequence we deﬁne a ”ground” level at the energy ε0 which
is again determined by the random–number generator. The higher levels εi
are generated by adding spacings si belonging to the given sequence. We then
Ei}
construct ”intermediate” spectra
by folding the levels of each sequence
{
with the function
Ei = aεb
To make the test as realistic as possible, we determined the parameters a and
b by ﬁtting the excitation energies of the 2+ levels of thirty nuclei to Eq. (27).
We averaged the power b over the thirty cases. We then recalculated the val-
ues of a that reproduced the position of the highest level under consideration
in each nucleus, and ﬁnally took the average of a. This procedure yielded
a = 0.36 and b = 2.82. These parameter values were used to generate the
folded spectra.

(27)

i .

The intermediate spectra obtained in this manner are unfolded with the

constant–temperature formula [2]

N(E) = N0 + exp

E

E0

−
T

.

(cid:19)

(cid:18)

(28)

Since the energy dependence of the mean level density is not known in the
case of experimentally given sequences, we choose that dependence to be
diﬀerent in Eqs. (27) and (28). The parameters N0, E0 and T can easily be
related to those used by von Egidy et al. [2]. The unfolding was performed in
two versions. In a three–parameter version, one searches for N0, E0, and T ;
in a two–parameter version, one searches for E0 and T with N0 = 0. Then,
combining the spacings in each case, we obtain the three “ﬁnal” ensembles
of 50, 100, 200 spacings.

The results of these analyses are also given in Table I and Figs. 1 and 2.

From the Table and the Figures, we conclude the following:

(i) The analysis of the ﬁnal ensembles suggests that the results practically
do not depend on whether we use for unfolding of the spectra the three–

12

parameter function (28) or the two–parameter version. Such an insensitivity
of the resulting spacing distribution to the form of the unfolding function has
been claimed in previous analyses. It is indeed a condition for the validity of
the statistical analysis of spectral ﬂuctuations.

(ii) The unfolding procedure introduces a bias towards the GOE, i.e., the
best–ﬁt value of f is larger than the true one. This is borne out by both, the
Bayesian inference and the χ2-analysis of the ﬁnal distributions. Unfolding
smaller sequences yields spacings closer to the mean value (unity) because
the function N(E) used to unfold the raw data can be made to ﬁt them very
closely. In the limiting case when the number of levels equals the number
of parameters of N(E), the unfolding would yield a picked–fence spectrum.
Hence, the number of spacings in each sequence must be larger than the
number of parameters used in unfolding. Under this condition, increasing the
ensemble will improve the result. Table I shows that the ensemble containing
50 spacings appears to be almost chaotic both according to the Bayesian
analysis and to the χ2-ﬁt of the histogram. The values of f decrease as the
number of sequences increases although they are still far from the original
value f = 0.6 even in the case of 200 spacings.

(iii) In order to show that it is the large number of short sequences in the
composite ensemble which leads to an overestimation of f , we used another
ensemble of 50 spacings from which we created only 3 sequences. One of
the sequences contains 12 levels, one 17 levels, and one 24 levels. The initial
ensemble yielded f = 0.70
0.14, i.e., nearly the same value as previously
obtained by combining 8 sequences, see Table I. The three–parameter un-
0.13 for the chaoticity parameter of the
folding function yielded f = 0.73
ﬁnal ensemble instead of f = 0.91
0.08 obtained from the 8–sequence com-
posite ensemble. Analogously, the two–parameter unfolding function yielded
0.13 from the 3–sequence ensemble which is again in far bet-
f = 0.74
ter agreement with the true value than the result f = 0.88
0.10 from the
8–sequence ensemble.

±
±

±

±

±

5 SUMMARY AND CONCLUSION

In the present paper we have attempted to determine the reliability of a
statistical analysis of spectra. We have ﬁrst compared the usual χ2–ﬁt to
histograms with the Bayesian method. This was done by constructing three

13

artiﬁcial ensembles with known chaoticity parameter f containing 50, 100,
and 200 spacings. We have shown that the χ2–analysis of NNS distributions
with less than 100 spacings yields an incorrect estimation of f . The Bayesian
method infers f much more reliably. This method has been used previously
for the statistical analysis of spectra of 1500 spacings, but now we have
demonstrated its validity for our artiﬁcial spectra even when the number of
spacings is as small as 50.

We have then investigated the reliability of the unfolding procedure for
composite ensembles of levels consisting of many short sequences. This was
done by folding sequences of levels constructed from the initial artiﬁcial en-
sembles with a monotonically increasing function of energy and then unfold-
ing the resulting sequences using a diﬀerent unfolding function. The NNS
distributions obtained in this way were combined to form the three ﬁnal
artiﬁcial ensembles. The chaoticity parameter f of these ensembles is over-
estimated by about 50% for the ensemble containing 50 spacings, by 40%
for the one containing 100 spacings, and by 30% for the one containing 200
spacings. We have also shown that the overestimate is due to the occurrence
of many sequences containing a small number of levels each, and would be
alleviated if few long sequences were available instead.

We emphasize that these conclusions apply to all analyses of NNS distri-
butions of experimental nuclear spectra in the ground–state domain carried
out so far, see e.g. Refs. [1, 2, 3, 4, 5, 6, 7, 8, 9]. Most of these analyses
involve composite ensembles that combine levels from diﬀerent nuclei. Even
in the few cases where the levels under investigation are taken from a sin-
gle nucleus, levels of diﬀerent spin or parity are combined to obtain reliable
statistics. Therefore, the estimates of the chaoticity parameter of nuclear
dynamics in the ground–state region obtained in these papers as well as in
Ref. [28] should be regarded as upper limits: Nuclei at low excitation energy
are presumably more regular than we tend to believe.

Acknowledgement 1 The authors thank Professor J. H¨ufner for useful dis-
cussions. A.Y.A.-M. and M.H.S. acknowledge the ﬁnancial support granted
by Internationales B¨uro, Forschungszentrum J¨ulich, that permitted their stay
at the Max-Planck-Institut f¨ur Kernphysik, Heidelberg.

14

References

(1985).

[1] A. Y. Abul-Magd and H. A. Weidenm¨uller, Phys. Lett. B 162, 223

[2] T. von Egidy, A. N. Behkami, and H. H. Schmidt, Nucl. Phys. A 454,

109 (1986); Nucl. Phys. A 481, 189 (1988).

[3] G. E. Mitchell, E. G. Bilpuch, P. M. Endt, and J. F. Shriner, Jr., Phys.

Rev. Lett. 61, 1473 (1988); Z. Phys. A 335, 393 (1990).

[4] S. Raman, T. A. Walkiewicz, S. Kahane, E. T. Jurney, J. Sa, Z. G`acsi,
J.L. Weil, K. Allaart, G. Bonsignori, and J. F. Shriner, Jr., Phys. Rev.
C 43, 521 (1991).

[5] J. F. Shriner, Jr., E. G. Bilpuch, P. M. Endt and G. E. Mitchell, Z.

Phys. 335, 393 (1990).

[6] A. Y. Abul-Magd and M. H. Simbel, J. Phys. G 22, 1043 (1996); 24, 576

[7] J. D. Garrett, J. Q. Robinson, A. J. Foglia, and H.-Q. Jin, Phys. Lett.

(1998).

B 392, 24 (1997).

[8] J. Enders, T. Guhr, N. Huxel, P. von Neumann-Cosel, C. Ran-

gacharyulu, and A. Richter, Phys. Lett. B 486, 273 (2000).

[9] J. F. Shriner, C. A. Grossmann, and G. E. Mitchell, Phys. Rev. C 62,

054305 (2000).

[10] C. I. Barbosa and H. L. Harney, Phys. Rev. E 62, 1897 (2000).

[11] A. Y. Abul-Magd, C. Dembowski, H. L. Harney, and M. H. Simbel,

Phys. Rev. E 65, 056221 (2002).

[12] M. L. Mehta, Random Matrices, 2nd Edition, (Academic, New York,

[13] E. P. Wigner, Oak Ridge National Laboratory Report No. ORNL-2309,

1991).

1957.

15

[14] O. Bohigas, M.-J. Giannoni, and C. Schmit, Phys. Rev. Lett. 52, 1

[15] T. Guhr, A. M¨uller-Groeling, and H. A. Weidenm¨uller, Phys. Rep. 299,

(1984).

189 (1998).

[16] Y. Alhassid, Rev. Mod. Phys. 72, 895 (2000).

[17] F. M. Izrailev, Phys. Rep. 196, 299 (1990).

[18] A. Y. Abul-Magd, J. Phys. A 29, 1 (1996).

[19] P. R. Richens and M. V. Perry, Physica D 2, 495 (1998).

[20] D. Biswas and S. R. Jain, Phys. Rev. A 42, 3170 (1990).

[21] G. Date, S. R. Jain, and M. V. N. Murthy, Phys. Rev. E 51, 198 (1995).

[22] H. L. Harney, A. Richter, and H. A. Weidenm¨uller, Rev. Mod. Phys..

58, 607 (1986).

[23] C. Ellegaard, T. Guhr, K. Lindemann, J. Nyg˚ard, and M. Oxborrow,

Phys. Rev. Lett. 77, 4918 (1995).

[24] H. Alt , C.I. Barbosa, H.-D. Gr¨af, T. Guhr, H. L. Harney, ]R. Hoﬀerbert,

H. Rehfeld, and A. Richter, Phys. Rev. Lett. 81, 4847 (1998).

[25] A. Abd El-Hady , A. Y. Abul-Magd and M. H. Simbel, J. Phys. A 35,

2361 (2002).

Rev. C 54, 1675 (1996).

[26] A. Y. Abul-Magd and M. H. Simbel, Phys. Rev. E 54, 3293 (1996); Phys.

[27] H. Jeﬀreys, Proc. of the Roy. Soc. A 186, 453 (1946); H. Jeﬀreys Theory
of Probability, 3rd Edition, Oxford University Press, Oxford 1961.

[28] A. Abul-Magd, H. L. Harney, M. H. Simbel, and H. A. Weidenm¨uller,

in preparation.

16

Table I. χ2-ﬁt values for f

σ for “initial” and ”ﬁnal” ensembles of N

spacings of composite spectra as explained in the text.

±

Spectra
Initial ensemble

Final ensemble with
3-parametic unfolding

Final ensemble with
2-parametic unfolding

N = 50
Analysis method
0.90
0.2-bin Histogram
0.90
0.3-bin Histogram
0.67
Bayesian
Approximate Bayesian 0.69
0.94
0.2-bin Histogram
0.93
0.3-bin Histogram
0.91
Bayesian
Approximate Bayesian 1.07
0.97
0.2-bin Histogram
1.00
0.3-bin Histogram
0.88
Bayesian
Approximate Bayesian 1.01

±
±
±
±
±
±
±
±
±
±
±
±

0.12
0.14
0.14
0.14
0.12
0.14
0.08
0.15
0.11
0.09
0.10
0.15

N = 100
0.75
0.80
0.61
0.63
0.88
0.88
0.86
0.88
0.88
0.87
0.83
0.85

0.11
0.11
0.13
0.09
0.10
0.09
0.08
0.09
0.09
0.05
0.08
0.09

±
±
±
±
±
±
±
±
±
±
±
±

N = 200
0.71
0.72
0.63
0.63
0.82
0.81
0.78
0.79
0.80
0.79
0.77
0.77

0.06
0.06
0.07
0.07
0.08
0.05
0.06
0.06
0.05
0.04
0.06
0.07

±
±
±
±
±
±
±
±
±
±
±
±

17

Figure Captions
FIG. 1. χ2–ﬁts of the distribution (12) to histograms of ”ﬁnal” ensembles
of N spacings for composite spectra obtained by unfolding ”initial” spectra
generated using this same distribution with f = 0.6, with histogram bin size
0.2.

FIG. 2. χ2–ﬁts of the distribution (12) to histograms of ”ﬁnal” ensembles
of N spacings for composite spectra obtained by unfolding ”initial” spectra
generated using this same distribution with f = 0.6, with histogram bin size
0.3.

18

