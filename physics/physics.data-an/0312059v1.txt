3
0
0
2
 
c
e
D
 
9
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
9
5
0
2
1
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

PHYSTAT2003, SLAC, Stanford CA, September 8-11, 2003

1

Measures of Signiﬁcance in HEP and Astrophysics

James T. Linnemann
Michigan State University, E. Lansing, MI 48840, USA and
Los Alamos National Laboratory, Los Alamos, NM 87545, USA

I compare and discuss critically several measures of statistical signiﬁcance in common use in

astrophysics and in high energy physics. I also exhibit some relationships among them.

I.

INTRODUCTION

and thus one derives

Signiﬁcance testing for a possible signal in counting
experiments centers on the probability that an ob-
served count in a signal region, or one more extreme,
could have been produced solely by ﬂuctuations of the
background source(s) in that region. Statisticians re-
fer to this probability as a p-value. The traditions
for calculating signal signiﬁcance diﬀer between High
Energy Physics (HEP) and High Energy Gamma Ray
Astrophysics (GRA). Both ﬁelds often quote signif-
icances in terms of equivalent standard deviations of
the normal distributions (statisticians sometimes refer
to this as a Z-value).

I will present several of the commonly used meth-
ods in HEP and GRA, apply them to examples from
the literature, then discuss the results. Here I will
concentrate on observed signiﬁcance, the signiﬁcance
of a particular observation, rather than predictions of
signiﬁcance for a given technique as a function of ex-
posure. The prediction problem is slightly diﬀerent,
involving the power of the test, or the probability of
making an observation at a given signiﬁcance level.

GRA has emphasized simple, quickly-evaluated an-
alytical formulae for calculating Z directly (choos-
ing asymptotically normal variables), while HEP has
typically calculated probabilities (p-values) and then
translated into a Z-value by

p = P (s

observed

assume only background );

≥
1(p); Φ(z) = 1

|

Z = Φ−

√2π R

z

−∞

t2(cid:14)2 dt

e−

This relation can be written[1] for large Z > 1.5 as

Z

√u

≈

−

Ln u; u =

2Ln(p√2π)
√

−

giving a rough dependence of Z
Ln p. While
more general than the search for a simple formula for
Z-values, the HEP approach loses track of the analytic
structure of the problem.

∼

−

Observations in GRA typically consist of a count
of gamma rays when pointing directly at a potential
source, called an on-source count, Non. The analogous
quantity in HEP is the number of counts in a signal re-
gion. The background relevant to an observation of a
source is typically estimated in GRA by an oﬀ-source
observation. The relative exposure of the two obser-
vations is denoted by α = Ton/Tof f , often less than
unity. Then the background count mean’s estimate is
b = αNof f , its (Poisson) uncertainty δb = αpNof f ,

MOBT001

α = (δb)2/b

(1)

GRA expressions are couched in terms of α. I will also
use x = Non, y = Nof f , k = x + y for compactness.
In HEP, sometimes a side-band method of back-
ground estimation is used, rather like in a GRA mea-
surement; or b may be estimated as a sum of contri-
butions from Monte Carlo and data-based side-band
δb is quoted, where δb is
estimates, so that often b
±
derived from adding uncertainties in quadrature. One
can use Eq.1 to deﬁne α when comparing HEP re-
sults with GRA expressions. Non-integer values for
eﬀective Nof f result, but usually cause no problems.

II. Z-VALUE VARIABLES

−

−

Many expressions for Z are of the form of a ratio of
estimates of signal to its variance, where the signal is
αy. Then Z = s/√V ,
estimated by s = Non
b = x
where V is a variance estimate for s. A standard
GRA reference[2] gives as an example (their Equa-
tion 5) V5 = Non + α2Nof f . The authors note that
this expression treats Non and Nof f as independent;
this does not consistently calculate V under the null
hypothesis, µon = αµof f and in fact biases against
signals for α < 1 by overestimating V .
I have de-
= α(1 + α)Nof f , by using
rived a related formula, V5′
only the background to estimate the mean and vari-
ance: while not optimal, it at least is consistent with
the null. They also provide V9 = α(Non + Nof f ),
which better implements the null hypothesis. How-
ever, their widely-used recommendation is likelihood
ratio L(µs, µb)/L(µb),

ZL = √2 ( y Ln x(1+α)

kα + y Ln y(1+α)

k

1

2 .

)

ZL derives from the standard likelihood ratio test for a
composite hypothesis, and Wilks’ Theorem, giving its
asymptotic normal behavior. The numerator and de-
nominator likelihoods are each separately maximized:
one for a signal + background model, the other for a
background-only (null) model.

One may instead seek an asymptotically normal

variable with nearly constant variance[3],
pα(y + 3/8) ).

Z0 = 2

√1+α (px + 3/8

−
The 3/8 speeds convergence to normality from the un-
derlying discreteness.

2

PHYSTAT2003, SLAC, Stanford CA, September 8-11, 2003

A. Other Frequentist Methods

be shown to be identical to Z9 = s/V9.

One widely used form is Zsb = s/√b (sometimes[4]
called the “signal to noise ratio”). This entirely ig-
nores the uncertainty in the background estimate. It
is often used for optimizing selection criteria, because
of its simplicity. Slightly better is a ZP calculated
from the Poisson probability p-value:

≥

pP = P (

b) = P∞j=x e−
x
|

bbj/j! = Γ(x, 0, b)/Γ(x).
here written[6] in terms of an incomplete Γ function.
ZP still ignores uncertainty in b. Occasionally one
sees substitutions of b
b + δb as a feeble attempt to
incorporate the uncertainty in b.

→

Finally, one may view a signiﬁcance calculation di-
rectly as a p-value calculation which one could use
as a test of the null hypothesis. ZL use the standard
(non-optimal) test of a composite hypothesis against a
null. However, the relationship of the Poisson means,
whether µon > αµof f , is a special case of a composite
hypothesis test that admits a more optimal solution.
There exists a Uniformly Most Powerful test among
the class of Unbiased tests for this case, in the form
of a binomial proportion test for the ratio of the two
Poisson means[5]. The UMPU properties are, strictly
speaking, derived only with an assumption of random-
ization, that is, hiding the underlying discreteness by
adding a random number to the data. This test yields
a binomial probability p-value (using k = x + y):
k
w)k
w, k) = P
j=x

j,
where w = α/(1 + α) is the expected ratio of the
Poisson means for x and x + y. After some manipu-
lation, this can be written in terms of incomplete and
complete beta functions[1, 6], which is convenient for
numerical evaluation:

pBi = PBi(

j)! wj (1

x
|

j!(k

−

≥

k!

−

−

pBi = B(w, x, 1 + y)/B(x, 1 + y)

This test is conditional on x + y ﬁxed because of the
existence of a nuisance parameter: there are two Pois-
son means, but the quantity of interest is their ra-
tio. While this test is known to both the GRA[3] and
HEP[7] communities, it is common practice in neither,
and its optimality properties are not common knowl-
edge.

Given the (restricted) optimality of the test, and
the lack of a UMP test for this class of composite
hypotheses, this test ought to be more frequently used
to calculate signiﬁcance, even though it is clearly a
longer calculation than ZL. For moderate x, y, closed
forms in terms of special functions are available, while
some care is required for larger n. For ZB < 3, the
Z-values reported may be somewhat too small[3, 8],
but for typical applications one is more interested in
ZB > 4.

It is interesting to note that taking a normal ap-
proximation to the binomial test (that is, comparing
the diﬀerence of binomial proportion from its expected
value, to the square root of its normal-approximation
variance) yields (x/k
w)/k, which can

w)/pw(1

−

−

A diﬀerent approach attempts to move directly
from likelihood to signiﬁcance by using a 3rd-order
expansion[9]. The mathematics is interesting, combin-
ing two ﬁrst order estimates (which give signiﬁcance
to order 1/√n) to yield a 1/√n3 result. Typically,
the ﬁrst-order estimates are of the form of a normal
deviation, Zt (like Z9), and a likelihood ratio like ZL;
of these, the likelihood ratio is usually a better ﬁrst-
order estimate. The two are then combined into the
third order estimate by a formula such as
Z3 = ZL + 1
Ln(Zt/ZL).
ZL
Generically, Zt = ∆/√V is a Student t-like variable,
where ∆ is the diﬀerence of the maximum likelihood
value of θ (the parameter of interest) from its value un-
der the null hypothesis, and V is a variance estimate
derived from the Fisher Information ∂2L/∂2θ. The
attraction of the method is to achieve simple formu-
lae with accurate results. However, the mathematics
becomes more complex[10] when nuisance parameters
are included, as is needed when the background is im-
perfectly known. Here I will only compare the approx-
imate calculation for a perfectly known background to
the corresponding exact calculation, pP .

III. BAYESIAN METHODS

HEP common practice often involves Bayesian
methods of incorporating “systematic” uncertainties
for quantities such as eﬃciencies[11]. These methods
are also used for calculating signiﬁcances, particularly
when the background b is a sum of several contribu-
tions, since the method naturally extends to complex
situations where components of δb are correlated. The
typical calculation represents the lack of knowledge of
y); it is referred
b by a posterior density function p(b
|
to as a posterior density because it is posterior to the
oﬀ-source measurement y. The usual way of proceed-
ing is to calculate Poisson p-values pP = P (
b) as
x
|
was done above, but this time taking into account the
uncertainty in b by performing an average of p-values
weighted by the Bayesian posterior p(b

≥

pBa = R pP (

b) p(b
x
|

y) d b
|

≥

This can be evaluated by Monte Carlo integration, or
by a mixture of analytical and numerical methods. I
will pursue the latter course here. The most common
usage in HEP is to represent p(b
y) as a truncated
|
normal distribution

δb√2π

pN (b

exp −

, b > 0 .

y) = 1
|

(b
−
2(δb)2
If b is a sum of many contributions, its distribution
should asymptotically approach a normal. An alter-
native I have advocated in HEP[12], and which is also
known to the GRA communitity[13], is to start from
a ﬂat prior for b and derive the p(b
y) in the usual
|
Bayesian fashion, leading to a Gamma posterior:
β/y! , β = b/α.

αy)2

pΓ(b

y), that is
|

y) = βye−
|

MOBT001

PHYSTAT2003, SLAC, Stanford CA, September 8-11, 2003

3

This is most appropriate when a single contribution
to b dominates and its uncertainty is actually due to
counting statistics. I will refer to the Z-values which
result from these two choices as ZN for the normal
posterior, and ZΓ for the Gamma function posterior.
Choosing to represent pP as a sum, and performing
the b integration ﬁrst gives the p-value for the Gamma
posterior[13]
pΓ = P∞j=x

αj
(1+α)1+y+j

(y+j)!
j!y!

Despite appearances, pΓ is identical to pBi. The Beta
function representation of pBi is much more suitable
for large values of x, y. The two expressions can be
made somewhat closer by using w = α/(1 + α).

Bayesian practice typically focuses on direct com-
parison of speciﬁc hypotheses through the odds ratio.
However, predictive inference[14] is commonly used in
model checking (signiﬁcance testing is just checking
the background-only model). Predictive inference in
our case is directly related to calculating p(x
y), that
|
is, averaging over the unknown parameter b.

p(j

y) = R p(j
|

y) d b
|
Interestingly, some Bayesian practitioners go farther,
and are willing to calculate a “Bayesian p-value”[14],

b) p(b
|

pBayes = P∞j=x p(j

x)
|

which is precisely the pBa given above (there we
summed before integrating).

IV. COMPARISON OF RESULTS: RELATIVE
PERFORMANCE

I have taken several interesting test cases from the
HEP and GRA literature. The input values and Z-
value calculation results are shown in Table 1. For
the HEP cases, the values reported in the papers are
Non, b, and δb, while in the GRA case, the reported
values are Non, Nof f , and α. I have also included a
few artiﬁcial cases in order to sample the parameter
space reasonably.

It is worth remarking that there are numerical issues
to be faced in evaluation of the more complex meth-
ods. These remarks apply–at a minimum–to a Math-
ematica implementation. The Binomial is straightfor-
ward in its Beta function representation. The Bayes
p-value methods may involve an inﬁnite sum, and are
touchy and slow for large n;
[13] suggests approxi-
mating the summation by an integral. Fraser-Reid
and the Bayes p-value summation results may be sen-
sitive to whether integers are ﬂoating point values are
used. An alternative attack is to leave the pP as a Γ
function ratio and trade an integration for the inﬁnite
sum. Doing so in the Bayes Gaussian case is less un-
stable than summing, but for large n requires hints on
the location of the peak of the integrand.

For the purposes of the present section, I will take
the Frequentist UMPU Binomial ratio test as a refer-
ence standard, because of its optimality properties. I

MOBT001

will have more to say on this later.

None of these examples from the recent literature
was published with a seriously wrong signiﬁcance
level. To me, the most striking result in the table
is that the Bayes Gamma prior method produces re-
sults identical to the Binomial result (MSU graduate
student HyeongKwan Kim has proven the identity).

The method most used in HEP, Bayes with a nor-
mal posterior for b, produces Z’s always larger than
those from Bayes Gamma. Viewing the calculation as
averaging the Poisson p-value pP (b) over the posterior
for b, the shorter tails of the normal compared to the
gamma place less weight on the larger probabilities
(smaller p-values) obtained when the oﬀ-source mea-
surement happens to underestimate the true value of
b. The diﬀerence is most striking for large values of
α, that is, when the background estimate is performed
with less sensitivity than the signal estimate; in this
case, results diﬀering in signiﬁcance by over .5 σ can
occur. The most common method in GRA, the simple
Log Likelihood ratio formula, produces comparable or
slightly higher estimates of signiﬁcance, but seems less
vulnerable to problems at large α. It appears to claim
the highest signiﬁcance of these methods at small n.
The variance stabilization method Z0 presented in [3]
does not appear to be in general use in GRA, but
produces results of similar quality to the other two
mainstay methods. All methods agree for N > 500,
where the normal approximations are good, even out
to 3-6 σ tails.

The “not recommended” methods all produce re-
sults oﬀ by more than .5 σ for several low-statistics
cases. Z9, which approximates ZBi, does best; Z5 is
indeed biased against real signals compared to other
, while cur-
measures, and its alleged improvement Z5′
ing that problem, overestimates signiﬁcance as the
price for its less eﬃcient use of information compared
to Z9.

As expected, ignoring the uncertainty in the back-
ground estimate leads to overestimates of the signif-
icance. s/√b is much more over-optimistic than an
exact Poisson calculation, particularly for small n, or
α > 1, where the background uncertainty is most im-
portant. The best that can be said for s/√b is that it
is mostly monotonic in the true signiﬁcance, at least as
it is typically used (for comparing two selection crite-
ria with N varying by an order of magnitude at most).
The 3rd order Fraser-Reid approximation is fast and
accurate up to moderate n, suggesting it is worth pur-
suing the full nuisance parameter case. However, the
approximation fails for one large Z, and is very slow
for the largest n.

Of the ad-hoc corrections for signal uncertainty,
none are reliable; the “corrected” Poisson calculation
is less biased than the un-corrected, but still widely
overestimates signiﬁcance for α > 1, and can’t be used
for serious work. The s/√b + δb isn’t much better
than its “un-corrected” version.

4

PHYSTAT2003, SLAC, Stanford CA, September 8-11, 2003

40

30

20

10

40

30

20

10

2.5

5

7.5

10 12.5 15 17.5 20

2.5

5

7.5

10 12.5 15 17.5 20

FIG. 1: Contours of equal Z, case [18], for ZSB (left) and
ZL (right).

To summarize, most bad formulae overestimate sig-
niﬁcance (the only exceptions are Z5 for α < 1 and
Poisson with b
b + δb). Thus, prudence demands
using a formula with good properties. The Binomial
test seems best for simple Poisson backgrounds. For
backgrounds with several components, compare Bayes
MC with Γ or Normal posteriors.

→

V. CALIBRATION OF ABSOLUTE
SIGNIFICANCE: MONTE CARLO

In the previous section, results of signiﬁcance cal-
culations were compared to a reference calculation,
the UMPU Binomial Test. That method produces
the lowest reported signiﬁcance among the methods
with a sound theoretical basis. This alone could jus-
tify its use (on grounds of conservatism)[3], but would
beg the question of whether the Binomial test is actu-
ally “correct.” This has been studied by Monte Carlo
simulation[24] in [3].

A few observations on MC testing are useful. One
might imagine simply generating instances of Pois-
son variables x, y with means µ, µ/α, and calculating
ZMC from pMC = the fraction of events “more signal-
like” than (Non, Nof f ). Instead, [2, 3] a separate MC
is done for each individual measure, because there is
no unique “correct” Z-value for a given observation.
The best that can be done is to ask that a method
produce a Z value consistent with MC probabilities
when the observation is analyzed by that method.
The problem is that there is no unique deﬁnition of
“more signal-like”. One is essentially trying to ﬁnd a
unique ordering of points on the x, y plane to deﬁne
those which are similarly far from the observed point

Non, Nof f .

Each variable introduces its own metric, and con-
tours of equal Z do not coincide for diﬀerent Z vari-
ables, as seen in Figure 1.

The p-value for an observation (x0, y0) depends on

these contours:

pMC (x0, y0) = RZ>Z0

p(x, y) dx dy

where the integration is over the region beyond the
contour line Z0 passing through the observation:
Z(x, y) > Z0(x0, y0).

For small n, the contours are markedly diﬀerent,
so that two diﬀerent Z-values could both be correct if
each agreed with their respective ZMC . Still, the situ-
ation is not catastrophic, as values of Z are not wildly
diﬀerent, and presumably the ZMC diﬀer somewhat
less than the reported values in Table 1. For larger
n, the contours become straighter and more similar,
and more importantly, the probability becomes more
peaked, so that a smaller region contributes. Thus,
the central limit forces convergence to a unique Z
value for large n.

Although Monte Carlo studies can never explore the
entire parameter space, the general conclusion of [3]
is that ZBi is the best of the alternatives. ZBi is
only slightly conservative for Z > 3. There, pBi is a
bit larger than pMC and thus ZBi < ZMC by 3% or
less on the Z scale when min(Non, Nof f ) < 20, and
ZBi performs even better for larger n. They found
the deviations of other methods from ZMC are typi-
cally larger. They also cite work[8] which ﬁnds larger
fractional deviations[25] for ZBi for smaller Z. Since
Z > 3 is the lower edge of the region where claims
are liable to be made, and the degree of conservatism
is small, this would also justify accepting ZBi as the
reference standard, and as the recommended method
of evaluating signiﬁcance when there is any concern
about the validity of other methods–at least when a
single counting uncertainty dominates the knowledge
of the background.

Acknowledgments

The author wish to thank LANL for hospitality and
ﬁnancial support during his sabbatical, Milagro and
D0 colleagues for information and references, and Tom
Loredo for reference [3]. This work was supported in
part by NSF contract NSF0140106. The calculations
were performed with the assistance (mostly) of Math-
ematica.

[1] Abramowitz & Segun, Handbook of Mathematical

Functions, Dover (1968)

[3] Zhang & Ramsden, Exp. Astro. 1 (1990) 145-163
[4] Babu & Feigelson, Astrostatistics (1996), Chapman

[2] Li & Ma, Astroph. J. 272 (1983) 314-324

& Hall

MOBT001

PHYSTAT2003, SLAC, Stanford CA, September 8-11, 2003

5

Reference
Non = x
Noﬀ = y
α
b = αy
s = Non - b
δb
δb/b
Reported p
Reported Z
Recommended:
ZBi Binomial
ZΓ Bayes Gamma
Reasonable:
ZN Bayes Gauss (HEP) 1.88
Z0 √ + 3/8
1.93
ZL L Ratio (GRA)
Not Recommended:
Z9 = s/pα(Non + Nof f ) 2.24
Z5 = s/pNon + α2Nof f
1.46
2.74
Z5
= s/pα(1 + α)Nof f
Ignore δb:
ZP Poisson: ignore δb
Z3 Fraser-Reid
Zsb = s/√b
Unsuccessful Hacks:
Poisson: Nb
s / √b + δb

2.08
2.07
3.00

1.56
2.49

b + δb

1.95

ZP

→

≈

′

[16]
6

[17]
9

18.78 17.83

[18]
[15]
17
4
5
40.11
0.2 0.0692 0.2132 0.0947
3.8
1.3
1.0
5.2
4.7
3.0
0.45
0.9
0.3
0.447 0.231 0.237
.0030
2.7

.027 2.0E-06
1.9

4.6

RMS

[22]

[22]

[19]
67
15
2.0

[20]
200
10
10.0

[23]
[21]
[19]
167589 498426 2119449
523
50
2327 1864910 493434 23671193
55
0.5
0.167
27.5 30.0 100.0 388.6
134.4
37
22.5
8.1
3.71 7.75
0.158 0.135 0.258 0.316 0.0207 0.000732 0.00142 0.000206

0.0891
0.0891
1.000
166213 493434 2109732
4992
702.4

3.8
13.2
0.6

9717
433.6

1376
121.7

100
31.6

3.0

3.0

5.9

3.2

5.0

6.4

1.66 2.63
1.66 2.63

1.82
1.82

4.46
4.46

2.93 2.89 2.20 5.93
2.93 2.89 2.20 5.93

2.71
2.66

2.81

3.59
1.90
3.99

2.84
2.84
4.12

1.94
1.98

1.99

2.17
1.66
2.42

2.14
2.14
2.67

4.55
4.22

4.57

5.67
3.17
6.47

4.87
4.87
6.77

3.08 3.44
3.00 3.07

3.02 3.04

2.90
2.39

2.38

3.11 2.89 2.18
2.89
2.82 3.28
3.02
3.50 3.90

5.93
5.86
5.93

6.16
5.54
6.31

7.72

3.80 5.76
6.44
3.80 5.76 (8.95) 6.44
6.82
4.29 6.76 10.00

2.46
3.72

1.64
2.40

4.47
6.29

3.04 4.24
4.03 6.02

5.51
8.72

6.01
6.75

3.23
*

3.23
3.23

3.23

3.23
3.22
3.23

3.37
3.37
3.38

3.07
3.37

5.01
*

5.02
5.01

5.01

5.01
5.01
5.03

7.09
6.09
7.11

6.09
7.10

6.40
*

6.40
6.40

6.41

6.41
6.40
6.41

6.69
6.69
6.69

6.39
6.69

0
0

.28
.15

.14

.52
.93
.53

1.9
2.2
2.9

1.1
2.4

TABLE I: : Test Cases and Signiﬁcance Results: Inputs are at top; α deduced from Eq.1 for HEP examples. The test
cases are ordered in data counts; [19]; [20], and [23] have large values of α, troublesome for some methods. Z-values in
bold are nearly equal the Binomial values; Z-values in italics diﬀer by more than .5 . * indicates convergence failure.
The last column gives the un-weighted RMS diﬀerence of the Z-values from to the Binomial values.

[5] Lehman, Testing Statistical Hypotheses, 2nd edition,

(HEP D0 collab.)

Wiley (1986)

tics, Vol 1 & 2

[6] Stuart & Ord, Kendall’s Advanced Theory of Statis-

[7] James & Roos, Nuc Phys B172 (1980) 475-480
[8] D’Agostino et. al, Am. Statistician (1988) 198
[9] Fraser, “Statistical Inference: Likelihood to Signiﬁ-

[19] Two artiﬁcial examples from [3]
[20] An artiﬁcial example with large α
[21] icrr.u-tokyo.ac.jp/can/Symp2002/Presentations/
S08-Rowell.pdf: Cyg. OB2 (GRA: Hegra collab.)
[22] Atkins, et al. (2003), Astroph. J., 595, 803-811: Crab

Pulsar (GRA: Milagro collab)

cance”, JASA 86 (1990) 258-65

[23] Reynolds et. al., Astroph. J. 404 (1993) 206-218: Crab

[10] Fraser, Reid, & Wu,

ftp://utstat.toronto.edu/

Pulsar (GRA: Whipple collab)

pub/reid/research/general/196rev3.ps.Z
[11] Cousins & Highland, NIM A320 (1992) 331
[12] conferences.fnal.gov/cl2k/copies/linnemann1.pdf
[13] Alexandreas et. al., NIM A328 (1993) 570-577
[14] Gelman, Carlin, Stern, & Rubin, Bayesian Data Anal-

ysis, Chapman & Hall (1998)

[15] Artiﬁcial case suggested by an example in [13]
[16] Abe et. al., PRL 74 (1995) 2626-31: Top quark: (HEP

CDF collab.; I chose one of many results)

[17] Abachi et. al., PRL 74 (1995) 2422-6: Top quark:

(HEP D0 collab.)

[18] Abachi et. al., PRL 74 (1995) 2632-7: Top quark:

[24] There may have been typographical errors in the re-
sults for ZBi, identical to Z9, but described as having
diﬀerent deviations from the true MC result. If the
Z’s were, by coincidence, identical, this might be an
instance of the measure-dependence described below.
Alas, the paper was published without the MC com-
parisons ﬁgures.

[25] It is not clear whether these limitations (originally
studied in the purely-binomial setting) are due to dis-
creteness; or whether the conditioning on Non + Nof f
causes the diﬀerences from Monte Carlo.

MOBT001

