0
0
0
2

 
r
a

 

M
8
2

 
 
]
n
a
-
a
t
a
d

.
s
c
i
s
y
h
p
[
 
 

1
v
7
8
0
3
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

XAFS spectroscopy. II. Statistical evaluations in the ﬁtting problems

Moscow State Engineering Physics Institute, 115409 Kashrskoe sh. 31, Moscow, Russia

K. V. Klementev

e-mail: klmn@htsc.mephi.ru

(December 2, 2013)

The problem of error analysis is addressed in stages beginning with the case of uncorrelated
parameters and proceeding to the Bayesian problem that takes into account all possible correla-
tions when a great deal of prior information about the accessible parametr space is available. The
formulas for the standard deviations and deviations with arbitrary conﬁdence levels are derived.
Underestimation of the errors of XAFS-function extraction is shown to be a source of unjustiﬁed
optimistic errors of ﬁtting parameters. The applications of statistical χ2- and F -tests to the ﬁtting
problems are also discussed.

61.10.Ht

I. INTRODUCTION

In the Open Letter to the XAFS Community [1] Young and Dent, the leaders of the UK XAFS User Group,
expressed their concern over the persistence of lingering common opinion that XAFS is a “sporting technique” and it
is possible to obtain the “answer you want”. Some way out they see in a special attention to the publishing XAFS data
(ﬁrst of all, to XAFS spectra) and have formulated several recommendations for editors and referees. Undoubtedly,
in the matter of extraction of the real, not invented, information from XAFS experiments the quality of spectra is
of great importance. We see here another problem as well. Not having some necessary elements of XAFS analysis
(some values and the procedures for their determination), one has a quite natural desire to turn those values to
advantage. Principally we mean the inability of the standard methods to ﬁnd the errors of the atomic-like background
µ0. Traditionally, the noise is assigned to these errors. However, as was shown in Ref. [2], the noise is essentially lower
than the errors of the µ0 construction. Below, we will show that the underestimation of the errors of XAFS-function
extraction is a source of the unreasonable optimistic errors of ﬁtting parameters.

Practically all known programs for XAFS modeling [3] in some way calculate conﬁdence limits of ﬁtting parameters.
However, since there is no standardized technique for that and since most published XAFS works do not contain any
mention of methods for estimation of the errors of ﬁtting parameters, the accuracy of the XAFS results remains to
be ﬁeld for trickery.

In the present article we derive the expressions for the errors of ﬁtting parameters under diﬀerent assumptions on
the degree of their correlation. Besides, the prior information about parameters is possible to take into account in the
framework of Bayesian approach. Moreover one can ﬁnd the most probable weight of the prior information relative
to the experimental information.

We also discuss the grounds and usage of the statistical tests. The special attention was focused on that where and

how one can embellish the results and artiﬁcially facilitate the statistical tests to be passed.

All methods and tests described in the paper are realized in the program viper [6].

II. ERRORS IN DETERMINATION OF FITTING PARAMETERS

Let for the experimental curve d deﬁned on the mesh x1, . . . , xM there exists a model m that depends on N
parameters p. In XAFS ﬁtting problems as d may serve both χ(k) (not weighted by kw) and χ(r). The problem is
to ﬁnd the parameter vector ˆp that gives the best coincidence of the experimental and model curves. Introduce the
ﬁgure of merit, the χ2-statistics (do not confuse with the symbol of XAFS function):

χ2 =

(di − mi)2

ε2
i

,

M

Xi=1

(1)

where εi is the error of di. The variate χ2 obeys the χ2-distribution law with M − N degrees of freedom. Of course, for
the given spectrum d and the given model m the value of χ2 is fully determined; we call it “variate” bearing in mind
its possible dispersion under diﬀerent possible realizations of the noise and the experimental errors of di extraction.

1

Often a preliminary processing (before ﬁtting) is needed: smoothing, ﬁltration etc. Naturally, during the pre-
processing some part of the experimental information is lost, and on the variates ξi = (di − mi)/εi additional
dependencies are imposed (before, they were bound solely by the model m). It is necessary to determine the number
of independent experimental points Nind. For the commonly used in XAFS spectroscopy Fourier ﬁltering technique
the number of independent points is given by [4]:

Nind = 2∆k∆r/π + 2,

(2)

where ∆k = kmax − kmin and ∆r = rmax − rmin are the ranges in k- r-spaces used for the analysis, and rmin > 0. If
rmin = 0 then

Nind = 2∆k∆r/π + 1.

(3)

Instead of keeping in the sum (1) only Nind items which are equidistantly spaced on the grid x1, . . . , xM , it is more
convenient to introduce the scale factor Nind/M :

χ2 =

Nind
M

(di − mi)2

ε2
i

.

M

Xi=1

(4)

Now the variate χ2 follows the χ2-distribution with Nind − N degrees of freedom. It can be easily veriﬁed that with
the use of all available data (rmin = 0 and rmax = π/2dk) the deﬁnition (4) turns into (1).

Let us now derive the expression for the posterior distribution for an arbitrary ﬁtting parameter pj:

where P (p|d) is the joint probability density function for all values p, and the integration is done over all pi6=j.
According to Bayes theorem,

P (pj|d) =Z ··· dpi6=j ··· P (p|d),

(5)

P (p|d) =

P (d|p)P (p)

P (d)

,

(6)

P (p) being the joint prior probability for all pi, P (d) is a normalization constant. Assuming that Nind values in d
are independent and normally distributed with zero expected values and the standard deviations εi, the probability
P (d|t), so-called likelihood function, is given by

where χ2 was deﬁned above by (4). Its expansion in terms of p near the minimum (∇pχ2 = 0) which is reached at
p = ˆp yilds:

P (d|p) ∝ exp(cid:0)−χ2/2(cid:1) ,

(7)

P (d|p) ∝ exp(cid:16)−

1
4

↔

(p − ˆp)T · H

· (p − ˆp)(cid:17) ≡(cid:16)−

1
4

N

Xk,l=1

∂2χ2
∂pk∂pl

∆pk∆pl(cid:17),

(8)

↔

where ∆pk = pk − ˆpk, and the Hessian H
↔
at the minimum of χ2. The suﬃcient conditions for the minimum are H
Hence, the surfaces of constant level of P (d|p) are ellipsoids.

components (the second derivatives) are calculated in the ﬁtting program
2
kl > 0, for any k, l.

↔
kk > 0 and H

↔
kkH

↔

ll − H

A. Simplest cases

Let us consider here two widely used approaches.

If one ignores the prior then the posterior probability density function P (p|d) coincides with the likelihood P (d|p).
(a) Parameters are perfectly uncorrelated. In this case the Hessian is diagonal and

The standard deviation of pj is just

P (pj|d) ∝ exp(cid:16)−

1
4

2

↔
H

jj ∆p2

j(cid:17).

(9)

(b) Parameter pj essentially correlates solely with pi. In this case

↔
δ(a)pj = (2/H

jj )1/2.

P (pj|d) ∝Z dpiP (pipj|d) ∝Z dpi exp(cid:16)−
iii (∆pj)2(cid:17),

∝ exp(cid:16)−

4hH

jj − H

↔
2
ij/H

1
4

↔

↔

1

from where one ﬁnds ¯pj = ˆpj and the mean-square deviation

↔
jj (∆pj)2 −
H

1
2

↔
H
ij∆pj∆pi −

1
4

↔
H

ii(∆pi)2(cid:17)

δ(b)pj = 

↔
H

ii

↔
2H
↔
jjH
ii − H

↔

ij!1/2

2

.

In practice, to ﬁnd the strongly correlated pairs of parameters, one ﬁnds the pair-correlation coeﬃcients:

rij = h∆pi∆pji − h∆piih∆pji

δ(∆pi)δ(∆pj)

taking on the values from -1 to 1. Two parameters are uncorrelated if their correlation coeﬃcient is close to zero. It
is easy to calculate the average values over the distribution (11): h∆p2
ii/Det, h∆pi∆pji =
/2.
−2H
Now the pair-correlation coeﬃcients are given by:

↔
↔
2
ij . Notice, by the way, that these are the elements of the inverse matrix of H

↔
ij/Det, where Det = H

jj /Det, h∆p2

ji = 2H

ii = 2H

ii − H

↔
jjH

↔

↔

↔

Via the correlation coeﬃcient the mean-square deviations, found for the cases (a) and (b), are simply related:

rij = −

.

↔
iiH

jj

↔
H
↔

ij

qH

(10)

(11)

(12)

(13)

(14)

(15)

δ(a)pj = δ(b)pjq1 − r2

ij .

Consider an example of the error analysis. For L3 Pb absorption spectrum1 for BaPbO3 compound the average error
of the XAFS extraction from the measured absorption was εi = 0.007. For the ﬁltered over the range 1.0 < r < 2.1 ˚A
(the signal from the octahedral oxygen environment of lead atom) XAFS (see Fig. 1), the model function was calculated
as follows. For one-dimensional the Hamiltonian of the lead-oxygen atomic pair with potential U = a/2 · (r − r0)2 we
found the energy levels and corresponding to them wave functions. Then, averaging over the Gibbs distribution, the
pair radial distribution function (PRDF) normalized to the coordination number N was found as:

g(r) = NXn

|Ψn(r)|2e−En/kT.Xn

e−En/kT ,

N =Z g(r) dr,

and the XAFS function as:

χ(k) =

1
k

F (k)

g(r) sin[2kr + φ(k)]/r2 dr.

rmax

Zrmin

(16)

(17)

The phase shift φ(k) and the scattering amplitude F (k) were calculated using feff6 program [5]. By variation of
the parameters r0, a, N (where N includes the factor S2
0 ), and E0, the shift of the origin for the wave number k, one
search for the best accordance between the model and experimental curves. Here for the ﬁtting, the viper program
was used which, in particular, calculates the Hessian of χ2 (deﬁnd by (4) with Nind = 11.8) at the minimum. The
correlation coeﬃcients are listed in the Table I.

1The spectrum was recorded at 50 K in transmission mode at D-21 line (XAS-13) of DCI (LURE,Orsay, France) at positron
beam energy 1.85 GeV and the average current ∼ 250 mA. Energy step — 2 eV, counting time — 1 s. Energy resolution
of the double-crystal Si [311] monochromator (detuned to reject 50% of the incident signal in order to minimize harmonic
contamination) with a 0.4 mm slit was about 2–3 eV at 13 keV.

3







 ?








 

 
.














 
 
7
 

&









7 ?







05072039
24/0

 , 







FIG. 1. Experimental and model ﬁltered
XAFS χ(k) · k2 (ﬁrst coordination sphere)
for BaPbO3 (a) and the model potential with
corresponding PRDF and energy levels (b).



?


 
 
7
 






 - 


TABLE I. Pair-correlation coeﬃcients rij for the example ﬁtting.

N
1

−0.286
0.092
0.041

a

−0.286

1

−0.044
0.048

r0
0.092
−0.044

1
0.727

N
a
r0
E0

E0
0.041
0.048
0.727
1

TABLE II. Mean values and mean-square deviations of the ﬁtting parameters. δp are the mean-square deviations calculated:
for perfectly uncorrelated parameters (a), trough the maximum pair correlations (b), from the bayesian technique without prior
information (maximum likelihood) (c), from the posterior probability that considers the most probable contribution of the prior
information. Sp are the sizes of the parameter space accessible for variation (± around the mean value).

p
N
a, K/˚A2
r0, ˚A
E0, eV

ˆp
4.05
2.28·105
2.1456
4.42

δ(a)p
0.090
4.7·104
2.7·10−3
0.23

δ(b)p
0.094
4.9·104
3.9·10−3
0.34

δ(c)p
0.096
4.9·104
4.0·10−3
0.35

Sp
ˆN
ˆa
ˆr0
10

δ(d)p
0.070
6.2·103
3.6·10−3
0.21

We now turn our attention to the errors of ﬁtting parameters. In ignoring the correlations, the errors δ(a)p are rather
small (see Table II). However, we know that the parameters r0 and E0 are highly correlated, and their real errors
must be larger. In the traditional XAFS-analysis two-dimensional contour maps have long been used [7] for estimates
of the correlation score and the error bars. Notice, that to do this requires, ﬁrst, the deﬁnition and determination of
the correct statistical function χ2 (but not a proportionate to it), and, second, a criterion to choose the critical value
of χ2 (depending on the chosen conﬁdence level).

For the most correlated pair, r0 and E0, ﬁnd the joint probability density function P (r0E0|d) using the Hessian

elements found at the minimum of the χ2:

P (r0E0|d) ∝ exp(cid:16)−

1
4

↔
r0r0(∆r0)2 −
H

1
2

↔
r0E0∆r0∆E0 −
H

1
4

↔
H

E0E0(∆E0)2(cid:17)

(18)

4







  

  

  

  
  


/ - 7
/ , 7

FIG. 2. The joint probability density function P (r0E0|d) calculated via the expansion (8) (solid lines) and using the exact
χ2 function (on the right, dashed lines). Also shown the graphical interpretation of the mean-square deviations δ(a)r0 and
δ(b)r0 given by (10) and (12). The ellipse of the standard deviation is drawn by the thick line.

which is depicted in Fig. 2 as a surface graph and as a contour map. The ellipses of the equal probability are described
by:

↔
H

↔
r0r0(∆r0)2 + 2H

↔
r0E0 ∆r0∆E0 + H

E0E0 (∆E0)2 = 4λ.

(19)

In Fig. 2 they limit such areas that the probability for the random vector (r0,E0) to ﬁnd itself in them is equal to
ℓ = 1−e−λ = 0.2, 0.6, 0.8, 0.9 and 0.95. By the thick line is drawn the ellipse corresponding to the standard deviation:
λ = 1/2 and ℓ = 1 − e−1/2 ≈ 0.3935. For this ellipse the point of intersection with the line ∆E0 = 0 and the point
of maximum distance from the line ∆r0 = 0 give the standard mean-square deviations δ(a)r0 and δ(b)r0 that coincide
with the expressions (10) and (12). To ﬁnd the mean-square deviation δ(b) for an arbitrary conﬁdence level ℓ, one

should multiply the standard deviation by p−2 ln(1 − ℓ).

In Table II the errors in the column δ(b)p were found as the largest errors among all those calculated from the pair
correlations. For the parameters N and a all pair correlations are weak, so their δ(a) and δ(b) are hardly diﬀer. For
the parameters r0 and E0 these mean-square deviations diﬀer remarkable.

Finally, we put the question, how much is rightful the expansion (8) for the likelihood function? In Fig. 2, on the
right, the dashed ellipses of equal probability are found for the exact χ2 that was calculated by the viper program
as well. Mainly, just-noticeable diﬀerence is caused by the realization of the ﬁtting algorithm or to be more precise,
by the values of the variations of the ﬁtting parameters which determine the accuracy of the minimum itself and the
accuracy of the derivatives at the minimum. Of course, this diﬀerence can be neglected.

B. General case

Often, a particular ﬁtting parameter signiﬁcantly correlates not with a one, but with several other parameters
(in our example this is not so, but, for instance, the problem of approximation of the atomic-like background by
interpolation spline drawn through the varied knots [8,2] is that very case). Now, the consideration of the two-
dimensional probability density functions is not correct no more, one should search for the total joint posterior
probability P (p|d).
of the variation range of the parameter pk. Then the prior probability can be expressed as:

For that, ﬁrst of all, one is to ﬁnd the prior probability P (p). Let we approximately know in advance the size Sk

P (p|α) ∝ αN/2 exp(cid:16)−

α
2

N

Xk=1

∆p2
k
S2

k (cid:17),

5

(20)

where the regularizer α speciﬁes the relative weight of the prior probability; at α = 0 there is no prior information,
at α → ∞ the ﬁtting procedure gives nothing and the posterior distribution coincides with the prior one. In the
expression (20) α appears as a known value. Later, we apply the rules of probability theory to remove it from the
problem.

So, for the sought probability density functions we have:

P (pj|d, α) ∝Z ··· dpi6=j ··· αN/2 exp(cid:16)−

1
2

N

Xk,l=1

gkl∆pk∆pl(cid:17),

where

gkl =

α
S2
k

δkl +

↔
H
kl
2

.

Since there is no integral over pj, separate it from the other integration variables:

P (pj|d, α) ∝ αN/2 exp(cid:16)−

1
2

gjj∆p2

j(cid:17)Z ··· dpi6=j ··· exp(cid:16)−

1
2

N

Xj

k,l=1

gkl∆pk∆pl − ∆pj

N

Xj

k=1

gkj∆pk(cid:17),

(21)

(22)

(23)

Here, the symbol j near the summation signs denotes the absence of j-th item. Further, ﬁnd the eigenvalues λi
and corresponding eigenvectors ei of the matrix gkl in which the j-th row and column are deleted, and change the
variables:

N

bi =pλi

Xj

k=1

∆pkeik,

∆pk =

N

Xj

i=1

bieik√λi

(i, k 6= j).

Using the properties of eigenvectors:

N

Xj

k=1

glkeik = λieil,

N

Xj

k=1

elkeik = δli

(l, i 6= j),

one obtains:

P (pj|d, α) ∝ αN/2 exp(cid:16)−
∝ αN/2 exp(cid:16)−

where new quantities were introduced:

1
2

1
2

j(cid:17)Z ··· dbl6=j ··· exp(cid:16)−
[gjj − u2]∆p2
j(cid:17),
[gjj − u2]∆p2

1
2

N

Xj

i=1

[bi + ui∆pj]2(cid:17)

ui =

1
√λi

N

Xj

k=1

gkjeik,

u2 =

u2
i .

N

Xj

i=1

(24)

(25)

(26)

(27)

Thus, we have found the explicit expression for the posterior distribution of an arbitrary ﬁtting parameter. This is

a Gaussian distribution with the mean ¯pj = ˆpj and the standard deviation

δ(c)pj = (gjj − u2)−1/2.

(28)

The formulas (26)–(28) require to ﬁnd the eigenvalues and eigenvectors for the matrix of rank N − 1 for each
parameter. Those formulas have merely a methodological value: the explicit expressions for posterior probabilities
enables one to ﬁnd the average of arbitrary function of pj. However, the standard deviations could be calculated
signiﬁcantly easier, having found the eigenvalues and eigenvectors for the matrix of rank N one time.

(δ(c)pj)2 = R ∆p2

j P (pj|d, α)dpj
R P (pj|d, α)dpj

= R ∆p2

j exp(cid:16)− 1
k,l=1 gkl∆pk∆pl(cid:17)dp
2PN
k,l=1 gkl∆pk∆pl(cid:17)dp
R exp(cid:16)− 1
2PN

.

6

(29)

Analogously to what was done above, performing the diagonalization of gkl, one obtains:

(δ(c)pj)2 = R db(cid:16)PN

i=1 bieij/√λi(cid:17)2
exp(cid:16)− 1
2PN
i(cid:17)
R db exp(cid:16)− 1
2PN

i=1 b2

i=1 b2

i(cid:17)

=

e2
ij
λi

,

N

Xi=1

(30)

where the eigenvalues (λi) and eigenvectors (ei) correspond to the full matrix gkl.

↔
One can give another interpretation of the δ(c)p-ﬁnding process. It is easy to verify that H

/2 and the covariance

matrix C of the vector p are mutually inverse. Therefore

↔
(δ(c)pj)2 = Cjj = 2(H

−1)jj ,

(31)

and the variate (p − ˆp)T · C −1 · (p − ˆp) = 1
· (p − ˆp) is χ2-distributed with N degrees of freedom if p is
the N -dimensional normally distributed vector (by Eq. (26) this condition is met). The ellipsoid that determines the
standard deviation is:

2 (p − ˆp)T · H

↔

↔

(p − ˆp)T · H

· (p − ˆp) = N.

(32)

For an arbitrary conﬁdence level ℓ, on the r.h.s. would be (χ2
degrees of freedom. The error δ(c)pk is equal to the half the ellipsoid size along the k-th axis.

N )ℓ, the critical value of the χ2-distribution with N

In our example ﬁtting, the errors found in the absence of any prior information (α = 0) from the formula (30) are
listed in Table II in the column δ(c)p. Due to every one parameter correlates at the most with one other parameter,
all δ(c)p are practically coincide with δ(b)p. Generally, this may be not so.

Finally, let us ﬁnd the most probable value of α. Its posterior distribution is given by:

P (α|d) =Z dpP (α, p|d) =Z dpP (α)P (p|α, d).

Using a Jeﬀreys prior P (α) = 1/α [9], one obtains for the posterior distribution:

P (α|d) ∝Z dpαN/2−1 exp(cid:16)−

1
2

N

Xk,l=1

gkl∆pk∆pl(cid:17) ∝ (λ1 ··· λN )−1/2αN/2−1.

(33)

(34)

In our example we have set the variation range of the parameter pk to be equal to Sk = ±ˆpk (this means that
pk ∈ [0, 2ˆpk]) for all parameters except for E0; since it varies near zero, we have chosen SE0 = ±10 eV. For the
mentioned variation ranges, the distribution P (α|d) has its mode at α = 2.64 · 103 (see Fig. 3). The bayesian errors
found for this regularizer are listed in the column δ(d)p of Table II. As a result, we have got the mean-square errors
that for some parameters are signiﬁcantly lower than even δ(a)p. There is nothing surprising in that: any additional
information narrows the posterior distribution. If we would choose Sk to be less, δ(d)pk would be yet lower. For
instance, XAFS is quite accurate in distance determination, and for many cases one can assume distances to be
known within ±0.2 ˚A. In our case this leads to δ(d)r0 = 3.4 · 10−3 ˚A.

,2



 
/
,
 
!

FIG. 3. The posterior distribution for the regularizer

α found from Eq. (34).







,





7

C. Important note

Having obtained the expressions (10), (12) and (30) for the errors of ﬁtting parameters, we are able now to draw
an important conclusion. If in the deﬁnition (4) one substitutes for εi the values that are smaller by a factor of β
than the real ones, the χ2 and its Hessian’s elements are exaggerated by a factor of β2, and from (10), (12) and (30)
follows that the errors of ﬁtting parameters are understated by a factor of β!

In the preceding paper [2] it was shown that the errors of the atomic-like absorption construction are essentially
larger than the experimental noise, and therefore it is the former that should determine the εi values. However,
these values are traditionally assumed to be equal to the noise, or one uses unjustiﬁed approximations for them, also
understated (like 1/ε2

i = kw [10]). It is here where we see the main source of the groundless optimistic errors.

III. STATISTICAL TESTS IN FITTING PROBLEMS

A. χ2-test

Introducing the statistical function χ2, we assumed that it follows the χ2 distribution with ν = M − N degrees of
freedom. However for this would be really so, one should achieve a suﬃcient ﬁtting quality. This “suﬃcient quality”
could be deﬁned as such that the variate (4) obeys the χ2 distribution law, that is this variate does not fall within
the tail of this distribution. Strictly speaking, the following condition must be met:

χ2 < (χ2

ν )ℓ,

(35)

where the critical value (χ2
mately (for odd ν) using the known formulas [11].

ν)ℓ for the speciﬁed signiﬁcance level ℓ may be calculated exactly (for even ν) or approxi-

Notice, that the choice of the true εi here also plays a cardinal role. However, it is important here that one would
not use the overestimated values which facilitate to meet the requirement (35). As we have shown in [2], one could
obtain the overestimated εi, having assumed the Poisson destribution law for the detectors counts when the actual
association between the probability of a single count event and the radiation intensity is unknown.

Thus, the exaggerated values εi tell about a quality ﬁtting, but give the large errors of ﬁtting parameters. The
understated εi lead to the would-be small errors, but make diﬃcult to pass the χ2-test (i. e. to meet the condition
(35)). We are aware of many works the authors of which do not describe explicitly the evaluation process for the
errors of XAFS-function extraction and do not report their explicit values. However, by implication it is seen that εi
were chosen (not calculated!) as low as possible to scarcely (with ℓ = 0.9 − 0.95) pass the χ2-test; as a result, very
impressive errors of the structural parameters were obtained. In such approach no wander that the diﬀerence of 0.01 ˚A
between the diﬀraction data and the XAFS-result that was found within 0.002 ˚A was attributed to the “suggested
presence of a small systematic error” [10].

Let there is a possibility to choose between two physical models depending on diﬀerent numbers of parameters N1
and N2 (N2 > N1). Which one of them is more statistically important? For instance one wish to decide whether a
single coordination sphere is split into two.

B. F -test

Let for the two models the functions χ2

2 obey the χ2-distribution law with ν1 = Nind−N1 and ν2 = Nind−N2
degrees of freedom, correspondingly. From the linear regression problem (near the minimum of χ2, the likelihood
function is expressed by (8) and is identical in form to that of the linear regression problem) it is known that the
value

1 and χ2

f =

(χ2

1 − χ2
2)/(ν1 − ν2)
χ2
2/ν2

(36)

obeys the Fisher’s F -distribution law with (ν1 − ν2, ν2) degrees of freedom if exactly r = ν1 − ν2 parameters in the
second model are linearly dependent, that is if exist the r × N2 matrix C of rank r and the vector c of the dimension
r such that Cp = c. In order for the linear restrictions on the second model parameters to be absent, the value f
should not follow the F -distribution, that is it should be greater than the critical value (Fν1−ν2,ν2 )ℓ for the speciﬁed
signiﬁcance level ℓ:

8







.









or

FIG. 4. On the choice between two diﬀerent models on

statistical grounds. Cited from Ref. [12].

19070//,9,
24/0
24/0













 ?


f > (Fν1−ν2,ν2 )ℓ

χ2
2 < χ2

1(cid:18)(Fν1−ν2,ν2)ℓ

ν1 − ν2

ν2

+ 1(cid:19)−1

.

(37)

(38)

Notice, that the expression (38) means the absence of exactly r linear restrictions on the second model parameters.
Even if (38) is realized, the less number of linear dependencies are possible. If, for instance, the splitting of a single
coordination sphere into two does not contradict to the F -test (38), some of the parameters of these two spheres may
be dependent, but not all. This justiﬁes the introduction of a new sphere into the model XAFS function.

Thus, having speciﬁed the signiﬁcance level ℓ, one can answer the question “what decrease of χ2 must be achieved
to increase the number of parameters from N1 to N2?” or, inside out, “what is the probability that the model 2 is
better than the model 1 at speciﬁed (N1, χ2

1) and (N2, χ2
1/χ2

2)?”
2 appears, the actual values of εi become not important for

Notice, that since in the deﬁnition for f the ratio χ2

the F -test (only if they all are taken equal to a single value).

Consider an example of the statistical tests in the ﬁtting problem. In Fig. 4 are shown the experimental curve
with Nind = 11.8 and two model curves with N1 = 4 and N2 = 7. The underlying physical models were described in
Ref. [12]; here only the number of parameters is of importance. Let us apply the statistical tests. Through the ﬁtting
procedure for the model 1 we have: ν1 = 11 − 4 = 7, χ2
7)0.95, for the model 2: ν2 = 11 − 7 = 4,
4)0.95. That is the ﬁrst model does not pass the χ2-test. Further, f = 2.89 = (F3,4)0.84, from
1 = 5.3 < 9.5 = (χ2
χ2
where with the probability of 84% we can assert that the model 2 is better than the model 1.

1 = 16.8 > 14.1 = (χ2

In the XAFS analysis the F -test has long been in use [7]. However, the words substantiating the test are often
wrong. The authors of Refs. [10,13], for example, even claimed that the value f (36) must follow the F -distribution,
although then in Ref. [13] there appears a really correct inequality (38).

IV. CONCLUSION

The solution of the main task of the XAFS spectroscopy, determination of the structural parameters, becomes
worthless if the conﬁdence in this solution is unknown. Here we mean not only the conﬁdence in the obtained ﬁtting
parameters that is their mean-square deviations, but also the credence to the very methods of the error analysis. It
is excessive optimistic errors evaluations lead to the suspicious attitude to the XAFS results.

To improve the situation could the development of the reliable and well-grounded techniques that do not allow
one to treat the data in an arbitrary way. First of all, this is a technique for determination of the real errors of the
atomic-like absorption construction. Second, we regard as necessary to standardize the method for the correct taking
into account of all pair correlation between ﬁtting parameters. And third, (we have not raised this question here)
programs for scattering phase and amplitude calculations should report on the conﬁdence limits for the calculated
values, that is report how sensitive the calculated values are to the choice of the parameters of scattering potentials.

9

[1] N. A. Young, A. J. Dent, Open Letter to the XAFS Comunity. Maintaining and improving the quality of published XAFS

data: a view from the UK XAFS user group. J. Synchrotron Rad. 6, 799 (1999), (Proc. of Int. Conf. XAFS X).

[2] K. V. Klementev, XAFS analysis. I. Extracting the ﬁne structure from the absorption spectra. The preceding article ,

(2000).

[3] Catalog of XAFS Analysis Programs, http://ixs.csrri.iit.edu/catalog/XAFS_Programs .
[4] E. A. Stern, Number of relevant independent points in x-ray-absorption ﬁne-structure spectra. Phys. Rev. B 48(13), 9825–

9827 (1993).

[5] J. J. Rehr, J. Mustre de Leon, S. I. Zabinsky, R. C. Albers, Theoretical X-ray Absorption Fine Structure Standards. J. Am.

Chem. Soc. 113, 5135–5140 (1991).

[6] K. V. Klementev, VIPER for Windows (Visual Processing in EXAFS Researches),

freeware, http://www.crosswinds.net/~klmn/viper.html .

[7] R. W. Joyner, K. J. Martin, P. Meehan, Some applications of statistical tests in analysis of EXAFS and SEXAFS data.

J. Phys. C: Solid State Phys. 20, 4005–4012 (1987).

[8] M. Newville, P. L¯ıvi¸nˇs, Y. Yacoby, J. J. Rehr, E. A. Stern, Near-edge x-ray-absorption ﬁne structure of Pb: A comparison

of theory and experiment. Phys. Rev. B 47(21), 14126–14131 (1993).

[9] H. Jeﬀreys, Theory of Probability (Oxford University Press, London, 1939), later editions: 1948, 1961, 1983.

[10] A. Filipponi, A. Di Chicco, X-ray-absorption spectroscopy and n-body distribution functions in condensed matter. II. Data

analysis and applications. Phys. Rev. B 52, 15135–15149 (1995).

[11] Handbook of mathematical functions with formulas, graphs and mathematical tables, edited by M. Abramowitz, I. Stegun

(Applied mathematical series, 55, National bureau of standards, 1964).

[12] A. P. Menushenkov, K. V. Klementev, EXAFS indication of double-well potential for oxygen vibration in Ba1−xKxBiO3.

J. Phys.: Condens. Matter 12, (2000), (accepted).

[13] A. Michalowicz, K. Provost, S. Laruelle, A. Mimouni, F-test in EXAFS ﬁtting of structural models. J. Synchrotron Rad.

6, 233–235 (1999), (Proc. of Int. Conf. XAFS X).

10

