3
0
0
2
 
n
u
J
 
8
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
8
3
1
6
0
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Asymmetric Systematic Errors

MAN/HEP/03/02
3/6/2003

Roger Barlow

Department of Physics
Manchester University
England

Abstract

Asymmetric systematic errors arise when there is a non-linear dependence of a result
on a nuisance parameter. Their combination is traditionally done by adding positive and
negative deviations separately in quadrature. There is no sound justiﬁcation for this, and
it is shown that indeed it is sometimes clearly inappropriate. Consistent techniques are
given for this combination of errors, and also for evaluating χ2, and for forming weighted
sums.

1.

Introduction
Although most errors on physics results are Gaussian, there are occasions where the
Gaussian form no longer holds, and indeed when the distribution is not even symmetric.
This can occur for statistical errors, when the one-σ interval is read oﬀ a log likelihood
curve which is not well described by a parabola [1]. It can also arise in evaluating systematic
errors: if a ‘nuisance parameter’ a which aﬀects the result x has an uncertainty described
by a Gaussian distribution with mean µa and standard deviation σa, then the uncertainty
in a produces an uncertainty in x given to ﬁrst order by the standard combination of errors
formula:

σ2
x =

2

dx
da (cid:19)

(cid:18)

σ2
a.

The uncertainty in a may be frequentist (for example, a Monte Carlo parameter deter-
mined by another experiment) or Bayesian (for example, a Monte Carlo parameter set
by judgement of theorists.) Bayesian probabilities may be admissable even in basically
frequentist analyses if the eﬀects are small [2]. The assumption that a has a Gaussian
probability distribution may be questioned, but that brings in further complications we do
not wish to consider here.

If the diﬀerential is not known analytically a numerical evaluation can be done, most
σa). See [3] for a discussion of the

conveniently by evaluation of x(µa + σa) and x(µa −
procedure and some issues that may arise.

Both x(µa + σa)

σa) give estimates of the uncertainty σx.
x(µa −
If they are diﬀerent then this is a sign that the dependence is non-linear and the symmetric
distribution in a gives an asymmetric distribution in x.

x(µa) and x(µa)

−

−

•
•
•

The questions that can be asked are:
How should asymmetric errors be combined?
How should a χ2 be formed?
How should a weighted mean be formed from results with asymmetric errors?
Current practice is to combine such errors separately, i.e. to add the σ+ values together
in quadrature, and then do the same thing for the σ− values. This is not, to my knowledge,
documented anywhere and, as will be shown, is certainly wrong.

2. Models

σa, x

σ−x ),(a, x) and (a + σa, x + σ+

The analysis gives 3 co-ordinate pairs: (a

x ).
In practice there are errors on these points, and one might be well advised to assume a
straight line dependence and take the error as symmetric, however we will assume that
this is not a case where this is appropriate. Again, faced with a real non-linear dependence
one might well be advised to map out more than three points; we will likewise assume that
this is not done. We consider cases where a non-linear eﬀect is not small enough to be
ignored entirely, but not large enough to justify a long and intensive investigation. Such
cases are common in practice.

−

−

For simplicity we transform a to the variable u described by a unit Gaussian, and
x(0). For future convenience it is useful to deﬁne the mean σ,

work with X(u) = x(u)

−

1

the diﬀerence α, and the asymmetry A:

σ =

σ+ + σ−
2

α =

σ+

σ−

−
2

A =

σ+
σ−
−
σ+ + σ−

There are inﬁnitely many non-linear relationships between a and X that will go

through these three points. We consider two.

Model 1 : Two straight lines

Two straight lines are drawn, meeting at the central value

Model 2 : A quadratic function

The parabola through the three points is

X = σ+u
= σ−u

0

0

.

u

u

≥

≤

X = σu + αu2 = σu + Aσu2.

These forms are shown in Figure 1 for a small asymmetry of 0.1, and a larger asym-

metry of 0.4.

(1)

(2)

(3)

Figure 1: X (vertically) against u (horizontally)

2

1
−

≤

≤

Model 1 (two straight lines) is shown in red, and Model 2 (x as a quadratic function of
u) in green. Both go through the 3 speciﬁed points. The diﬀerences between them within
the range

1 are not large; outside that range they diverge considerably.

u

We have no knowledge of whether either of them is better than the other in a particular
case. Model 1 has kink at u = 0 which is unphysical. Model 2 has a turning point, which
may well be unrealistic (though it only gets into the relevant region if A is fairly large.)
The practitioner may select one of the two - or some other model - on the basis of their
knowledge of the problem, or preference and experience. Working with asymmetric errors
at all involves the assumption of some model for the non-linearity. The ‘correctness’ of
any model may be arguable, but once chosen it must be used consistently.

The distribution in u is a unit Gaussian, G(u), and the distribution in X is obtained
. For Model 1 this gives a dimidated Gaussian - two Gaussians with
. For model 2 with small asymmetries
. For larger
values, the second root also has to be considered. Examples

from P (X) = G(u)
dX/du
|
diﬀerent standard deviation for X > 0 and X < 0
†
the curve is a distorted Gaussian, given by G(u)
σ+2αu
|
asymmetries and/or larger
are shown in Figure 2.

with u = √σ2+4αX

X

2α

−

σ

|

|

|

|

Figure 2: Examples of the distributions from combined asymmetric errors.

†

This is sometimes called a ‘bifurcated Gaussian’, but this is inaccurate. ‘Bifurcated’
means ‘split’ in the sense of forked. ‘Dimidated’ means ‘cut in half’, with the subsidiary
meaning of ‘having one part much smaller than the other’[4].

3

It can be seen that the Model 1 dimidated Gaussian and Model 2 distorted Gaussian
are not dissimilar if the asymmetry is small, but are very diﬀerent if the asymmetry is
large. Again, in a particular case there is no unique reason for choosing one above the
other in the absence of further information.

3. Bias

If a nuisance parameter u is distributed with a Gaussian probability distribution, and

the quantity X(u) is a nonlinear function of u, then the expectation

X

is not X(

u

).

h

i

h

i

For model 1 one has

< X >=

σ−u

0

Z

−∞

u2/2

e−
√2π

du +

∞

σ+u

Z
0

u2/2

e−
√2π

du =

σ+

σ−

−
√2π

For model 2 one has

< X >=

u2e−

u2/2

√2π

∞

α

Z

−∞

du =

σ+

σ−

−
2

= α

Hence in these models, or others, if the result quoted is X(0), it is not the mean. It
is perhaps defensible as a number to quote as the result as it is still the median - there is
a 50% chance that the true value is below it and a 50% chance that it is above.

4. Adding Errors

If a derived quantity z contains parts from two quantities x and y, so that z = x + y,

the distribution in z is given by the convolution:

(4)

(5)

(6)

fz(z) =

dxfx(x)fy(z

x)

−

With Model 1 the function for z

0 can be written:

f (z) =

dxfx

(x)fy+(z

x) +

dxfx+(x)fy+(z

x) +

dxfx+(x)fy

(z

x)

−

∞

Z
z

−

−

−

−

0

Z

−∞

Inserting the appropriate Gaussian functions and using

+ = σ+
σ2
x

2

2

+ σ+
y

2

= σ+
x

2

+ σ−y

σ2
±

= σ−x

2

2

+ σ+
y

σ2
∓

2

= σ−x

+ σ−y

2

,

σ2
−

this gives

√2πf (z) =

e

1
σ

∓

−z2
2σ2

zσ−x
∓ g( −
σ+
y σ

∓

) +

−z2
2σ2
+

1
σ+

e

zσ+
y
σ+
x σ+

)

zσ+
x
g( −
σ+
y σ+

−

g(

(cid:18)

+

)

(cid:19)

−z2
2σ2

e

± g(

1
σ

±

zσ−y
σ+
x σ

±

)

where g(x) is the cumulative Gaussian, equivalent to 1

2 (1 + erf (x)), and g(x) = 1

g(x).

−

4

Z

≥

z

Z

0

For z

0 the limits are diﬀerent and the second region covers the case where x and

y are both negative, giving

≤

√2πf (z) =

1
σ

∓

−z2
2σ2

e

∓ g(

zσ+
y
σ−x σ

∓

) +

−z2
2σ2
−

e

1
σ

−

zσ−x

g( −

(cid:18)

σ−y σ

g(

)

−

−

zσ−y
σ−x σ

−

+

)

(cid:19)

1
σ

±

−z2
2σ2

e

± g( −

zσ+
x
σ−y σ

±

)

Figure 3: Examples of the distributions from combined asymmetric errors.

Figure 3 shows the distributions from some typical cases. The blue line shows the con-
volution, the black line is obtained by adding the positive and negative standard deviations
separately in quadrature (the ‘usual procedure’).

The agreement is not good. It is apparent that the skew of the distribution obtained
from the convolution is smaller than that obtained from the usual procedure. This is
obvious: if two distributions with the same asymmetry are added then the ‘usual procedure’
will give a distribution with the same asymmetry. This violates the Central Limit Theorem,
which says that convoluting identical distributions must result in a combined distribution
which is more Gaussian, and therefore more symmetric, than its components. This shows
that the ‘usual procedure’ for adding asymmetric errors is inconsistent. Even though, as
stated earlier, there is no guarantee that Model 1 or any model is correct, once a model
has been adopted it should be handled in a consistent fashion, and the ‘usual procedure’
fails to do this.

5

5. A consistent addition technique

If a distribution for x is described by some 3 parameter function, f (x; x0, σ+, σ−),
which is a Gaussian transformed according to Model 1 or Model 2 or anything else, then
‘combination of errors’ involves a convolution of two such functions according to Equation
6. This combined function is not necessarily a function of the same form. It is a special
property of the Gaussian that the convolution of two Gaussians gives a third. Figure 3 is
a demonstration of this. The convolution of two dimidated Gaussians is not a dimidated
Gaussian.

Although the form of the function is changed by a convolution, some things are pre-
served. The semi-invariant cumulants of Thi`ele (the coeﬃcients of the power series expan-
sion of the log of the Fourier Transform) add under convolution. The ﬁrst two of these are
the usual mean and variance. The third is the unnormalised skew:

γ =< x3 >

3 < x >< x2 > +2 < x >3

−

Within the context of any model, a rational approach to the combination of errors is
to ﬁnd the mean, variance and skew: µ, V and γ, for each contributing function separately.
Adding these up gives the mean variance and skew of the combined function. Working
within the model one then determines the values of σ
, σ+, and x0 that give this mean,
variance and skew.

−

5.1 Model 1

For Model 1, for which

x3

h

i

= 2
√2π

(σ3

σ3
−

+ −

) we have

µ = x0 +

(σ+

σ−)

1
√2π

V =

(σ+2

+ σ−

2

)

(σ+

σ−)2 = σ2 + α2

1
2

−

−

1
2π

γ =

1
√2π (cid:20)

2(σ+3

σ−

3

)

−

−

σ−)(σ+2

2

+ σ−

) +

(σ+

σ−)3

−

(cid:21)

−
3
2

(σ+

−

1
(cid:18)

−

2
π (cid:19)
1
π

So given a set of error contributions then the equations (8) give the cumulants µ, V and
γ. The ﬁrst three cumulants of the combined distribution are given by adding up the
individual contributions. Then one can ﬁnd the set of parameters σ−, σ+, x0 which give
these values by using Equations (8) in the other sense.

It is convenient to work with ∆, where ∆ is the diﬀerence between the ﬁnal x0 and
the sum of the individual ones. The parameter is needed because of the bias mentioned
earlier. Even though each contribution may have x0 = 0, i.e. it describes a spread about
the quoted result, it has non-zero µi through the bias eﬀect (c.f. Equation 4). The σ+ and
σ− of the combined distribution, obtained from the total V and γ, will in general not give
the right µ unless a location shift ∆ is added. The value of the quoted result will shift.

Recalling section 3, for a dimidated Gaussian one could defend quoting the central
value as it was the median, even though it was not the mean. The convoluted distribution
not only has a non-zero mean, it also (as can be seen in Figure 2) has non-zero median.
Consider two dimidated Gaussians with, say, σ+ > σ− , which are convoluted. There is

(7)

(8)

6

a 25% chance that both will contribute a negative value, a similar 25% chance that both
will be positive, and a 50% chance of getting one positive and one negative contribution -
which will probably be positive overall (as σ+ > σ−). So for two combined distributions
the zero value may lie as far away as the 25th percentile.

If you want to combine asymmetric errors then you have to accept that the quoted
value will shift. To make this correction requires a real belief in the asymmetry of the error
values. At this point the practitioner, unless they are really sure that their errors really
do have a signiﬁcant asymmetry, may be persuaded to revert to quoting symmetric errors.
Solving the Equations (8) for σ−, σ+, x0 given µ, V and γ has to be done numerically.

If we write D = σ+

σ− and S = σ−

2 + σ+2 then the equations

can be solved by repeated substitution (starting with D = 0). Then ∆ is given by

−

S = 2V + D2/π

D =

2
3S (cid:18)

√2πγ

D3(

−

1
π −

1)

(cid:19)

∆ = µ

D
√2π

−

(9)

(10)

A program for this is available on http://www.slac.stanford.edu/
sults are shown in Figure 4 and Table 1.

∼

barlow. Some re-

Figure 4: Examples of combined errors with the correct ﬁrst 3 cumulants using Model 1.

7

x σ−y σ+
σ−x σ+
y
1.0 1.0 0.8 1.2
0.8 1.2 0.8 1.2
0.5 1.5 0.8 1.2
0.5 1.5 0.5 1.5

σ− σ+ ∆
1.32 1.52 0.08
1.22 1.61 0.16
1.09 1.78 0.28
0.97 1.93 0.41

Table 1: The values used in Figure 4

Comparing Figure 4 and Figure 3 (note that the blue curves are the same in both
ﬁgures; the consistent technique is shown in purple), it is apparent that the new technique
does a very much better job than the old. It is not an exact match, but does an acceptable
job given that there are only 3 adjustable parameters in the function.

In terms of the diﬀerence α = (σ+

σ−)/2 and the mean σ = (σ+ + σ−)/2 the

−

< x >= α

< x2 >= σ2 + 3α2

< x3 >= 9ασ2 + 15α3

5.2 Model 2

moments are

Giving

(11)

(12)

µ = x0 + α
V = σ2 + 2α2
γ = 6σ2α + 8α3

α =

6V

4α2

γ

−

As with Method 1, these are used to ﬁnd the cumulants of each contributing distribution,
which are summed to give the three totals, and then Equation 11 is used again to ﬁnd the
parameters of the distorted Gaussian with this mean, variance and skew. There is only
one equation to be solved numerically, again by iteration

after which, σ = √V

2α2 and ∆ = µ

α.

−

−

Some results are shown in Figure 5 and Table 2. The true convolution cannot be done

analytically but can be done by a Monte Carlo calculation.

x σ−y σ+
σ−x σ+
y
1.0 1.0 0.8 1.2
0.8 1.2 0.8 1.2
0.5 1.5 0.8 1.2
0.5 1.5 0.5 1.5

σ− σ+ ∆
1.33 1.54 0.10
1.25 1.64 0.20
1.12 1.88 0.35
1.13 2.07 0.53

8

Table 2: The values used for the curves with correct cumulants in Figure 5.

Figure 5: Examples of combined errors using Model 2.

Again the true curves (blue) are not well reproduced by the ‘usual procedure’ (black)
whereas the curves with the correct cumulants (purple) do a very reasonable job. (The
sharp behaviour at the lower edge of the curves is due to the minimum value of y.)

The web program mentioned earlier will also do the calculations for Model 2.

6. Evaluating χ2

For Model 1 the χ2 contribution from a discrepancy δ is just δ2/σ+2 or δ2/σ−
2 as
appropriate. This is manifestly inelegant, especially for minimisation procedures as the
value goes through zero.
For Model 2 one has

δ = σu + Aσu2

.

This can be considered as a quadratic for u with solution

Squaring gives u2, the χ2 contribution, as

u = q

1 + 4 δ

σ A

1

−

2A

u2 =

2 + 4A δ

σ −

2(1 + 4A δ
σ )
4A2

1
2

9

This is not really exact, in that it only takes one branch of the solution, the one approx-
imating to the straight line, and does not consider the extra possibility that the δ value
could come from an improbable u value the other side of the turning point of the parabola.
Given this imperfection it makes sense to expand the square root as a Taylor series, which,
neglecting correction terms above the second power, leads to

The ﬁrst order approximation to this is

χ2 = (

)2

2A(

) + 5A2(

δ
σ

1

(cid:18)

−

δ
σ

δ
σ

)2

.

(cid:19)

χ2 = (

)2(1

2A(

)).

δ
σ

−

δ
σ

This can be modiﬁed to a form forced to give χ2 = 1 for deviations of +σ+ and

χ2 = δ2(

σ+3 + σ−

3

σ+2σ−

2(σ+ + σ−)

)(1

δ

−

σ+2
σ−
−
σ+3 + σ−

2
3 )

(13).

(14)

σ−.

−

(15)

Figure 6: χ2 approximations

Figure 6 shows these forms. The black line is the simplest χ2 = ( δ

σ )2 form. The
green is the full form involving the square root.
for values beyond the
turning point which in principle can never happen. The blue line is the third order form
of Equation 14 and the red line is the higher order Equation 13. The yellow is Equation
15, the ﬁrst order form constrained to go though unity at +σ+ and
σ−, shown by the

It goes to +

∞

−

10

two crosses. For a 10% asymmetry all the approximations are pretty well equivalent and
a signiﬁcantly better form than the simplest one. For a larger 20% asymmetry the lower
order forms show undesirable behaviour, turning over for a moderate (2σ) deviation.

We therefore suggest that Equation 13 be used. The even power ensures that χ2
does not turn over but increases at large deviations, which is desirable. It does not go to
inﬁnity when δ approaches the turning point, which is probably a good feature. A poor
determination of the parameters of Equation 3 could give an unrealistic minimum value
which could be exceeded by an experimental value, and one would not want this to give
an undeﬁned χ2.

Higher order (5th, 6th...) terms do not signiﬁcantly improve the agreement with the

full (green) curve.

7. Weighted means

Suppose a value x has been measured several times, x1, x2...xN , each measurement
i and σ−i . For the usual symmetric errors the ‘best’ estimate (i.e. unbi-

having its own σ+
assed and with smallest variance) is given by the weighted sum

ˆx =

wixi
wi

P
P

V =

w2
i Vi
wi)2

P
(

P

with wi = 1/σ2

i . We wish to ﬁnd the equivalent for asymmetric errors.

As noted in Section 3, when sampling from an asymmetric distribution the result is
is not the location parameter x.

x

biassed towards the high tail. The expectation value
So for an an unbiassed estimator one has to take
wi(xi −

bi)/

ˆx =

X

h

i

wi

X

where

−
√2π
The variance of this is given by

b =

σ+

σ−

(Model 1)

b = α (Model 2)

(16)

(17)

where Vi is the variance of the ith measurement about its mean.
Diﬀerentiating with respect to wi to ﬁnd the minimum gives

2wiVi

2

(

wj)2 −

P

(

w2
j Vj
wj)3 = 0

i
∀

which is satisﬁed by wi = 1/Vi. This is the equivalent of the familiar weighting by 1/σ2.
The weights are given by (see Equations 8 and 11)

P

P

V = σ2 + (1

)α2

(Model 1)

V = σ2 + 2α2

(Model 2)

(18)

2
π

−

.

Note that this is not the ML estimator - writing down the likelihood in terms of the
χ2 of Equation 13 and diﬀerentiating does not give to a nice form - so in principle there
may be better estimators, but they will not have the simple form of a weighted sum.

11

8. Asymmetric statistical errors

When the estimated value and range are obtained using a maximum likelihood esti-
mate and the shape of the log likelihood is not parabolic, the one standard deviation limits
are taken as the points at which the log likelihood falls by 0.5 from its peak [1].

The treatment of these errors will be given in a subsequent publication. Although
treatment of asymmetric errors involves, for both systematic and statistical errors, the
mapping of the actual distribution onto a Gaussian one, there is a considerable diﬀerence
of interpretation. It is, however, worth pointing out that if two separate statistical eﬀects
are combined - say two backgrounds from diﬀerent sources - then the combined background
is the simple arithmetic sum of the two with no shift to the central value. This is because,
for these statistical errors, the value quoted is the mean.

9. Summary

The treatment of asymmetric systematic errors cannot be based on secure foundations,
and if they cannot be avoided they need careful handling. The practitioner needs to choose
a model for the dependence, which could be one of the two proposed here.

In combining asymmetric errors, the traditional procedure of adding positive and neg-
ative values separately in quadrature is unjustiﬁable. Instead, values should be determined
which, within the limitations of the model, give the correct mean, variance, and skew. A
program is available to do this on http://www.slac.stanford.edu/

barlow.

The χ2 contribution for a value with asymmetric errors can be represented by

∼

where

In forming a weighted sum one should use

χ2 = (

)2

2A(

) + 5A2(

)2

δ
σ

1

(cid:18)

−

δ
σ

δ
σ

(cid:19)

σ =

σ+ + σ−
2

A =

σ+
σ−
−
σ+ + σ−

ˆx =

(xi −
Vi

bi)

/

1
Vi

.

X

X

where the bias b and Variance V are given by Equations 17 and 18 above.

References

1971

[1] W. T. Eadie et al, “Statistical Methods in Experimental Physics”, North Holland,

[2] R. D. Cousins and V. L. Highland, Nucl. Instr & Meth. A320 331 (1992)
[3] R. J. Barlow “Systematic Errors: Facts and Fictions” in Proc. Durham conference
on Advanced Statistical Techniques in Particle Physics, M. R. WHalley and L. Lyons
(Eds). IPPP/02/39. 2002

[4] The Shorter Oxford English Dictionary, Vol I (A-M) p 190 and p 551 of the 3rd

edition (1977).

12

