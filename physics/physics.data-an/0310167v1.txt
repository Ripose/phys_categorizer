PHYSTAT2003, SLAC, Stanford, California, September 8–11, 2003

1

Pitfalls of Goodness-of-Fit from Likelihood

Joel Heinrich
University of Pennsylvania, Philadelphia, PA 19104, USA

3
0
0
2
 
t
c
O
 
1
3
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
7
6
1
0
1
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

The value of the likelihood is occasionally used by high energy physicists as a statistic to measure goodness-
of-ﬁt in unbinned maximum likelihood ﬁts. Simple examples are presented that illustrate why this (seemingly
intuitive) method fails in practice to achieve the desired goal.

1. INTRODUCTION

For every complex problem, there is a so-
lution that is simple, neat, and wrong.
H.L. Mencken

The complex problem considered here is goodness-
of-ﬁt (g.o.f.) for unbinned maximum likelihood ﬁts in
cases when binned g.o.f. methods and Kolmogorov-
Smirnov are not well suited:

A physicist, having ﬁt a complicated model to his
multi dimensional data to obtain estimates of the val-
ues of certain parameters, is also expected to check
how well the data match his model. In the sections
that follow, we discuss a g.o.f. method, still occasion-
ally used in high energy physics (HEP), that is simple,
neat, and wrong.

2. THE SNW1 METHOD

faulty resolution: We approximate this by replac-
ing ~Θ with the parameter estimate obtained
from the ﬁt to the actual data.

This method has a long history of use in high energy
physics.
It’s recommended by several excellent sta-
tistical data analysis texts written by (and for) high
energy particle physicists. Consequently, and because
the method is “obvious”, it’s still being used in (some)
HEP analyses.

Reference [1], written by a statistician and four

physicists, describes the method, but criticizes:

The likelihood of the data would appear to
be a good [g.o.f.] candidate at ﬁrst sight.
Unfortunately, this carries little informa-
tion as a test statistic, as we shall see. . .

Since this was ignored, maybe its warning was not
strong enough. I have found no mention of the method
in texts written (solely) by statisticians.

We start with a brief description of the method. (A
true derivation, for obvious reasons, is not available.)

3. A SIMPLE TEST OF THE METHOD

observation: Maximum likelihood ﬁts are performed
by maximizing the likelihood L(~θ, ~x) with re-
spect to the (unknown) parameters ~θ for ﬁxed
data ~x.

faulty intuition: Thus, the value of the likelihood
provides the g.o.f. between the data and the
probability density function (p.d.f.): The value
of the likelihood at the maximum,

Lmax = L(

~ˆθ, ~x)

corresponds to the best ﬁt—the smaller the like-
lihood, the worse the g.o.f., . . .

Always test your general reasoning against
simple models. John S. Bell

Reference [2], following the above advice, tests the

method against the p.d.f.

−t/τ

1
τ

e

(t

0)

≥

where t (we have in mind the decay-time of a par-
ticle) follows an exponential distribution, and τ (the
mean lifetime) is a parameter whose value, being un-
known, is estimated from data. The likelihood for N
observations ti is given by

N

ln L =

ln τ +

−

ti
τ

obstacle: To calculate this “g.o.f.” P-value, we need
the distribution of Lmax for an ensemble of ran-
dom ~x deviates from the p.d.f. using the true
(but unknown) parameters ~Θ.

i=1 (cid:20)
X
The value (ˆτ ) of τ that maximizes the likelihood, and
the value (Lmax) of the likelihood at its maximum, are
given by

(cid:21)

1Simple, Neat, Wrong.

MOCT001

ˆτ =

1
N

N

ti

i=1
X

ln Lmax = N (1 + ln ˆτ )

−

2

PHYSTAT2003, SLAC, Stanford, California, September 8–11, 2003

3.1. The First Surprise

and the g.o.f. statistic is now calculated as

The value of the likelihood at its maximum (in this
test case) is just a simple function of ˆτ —all samples
with the same mean obtain the same “g.o.f.” value.
This is a disaster for g.o.f. Even if the true value of
—were known in advance, so that we could
τ —call it
calculate the P-value associated with the observed ˆτ ,
merely comparing the ˆτ of the data with
is not
suﬃcient to show that the observed data are modeled
well by the exponential distribution.

T

T

ln L =

ln τ +

−

N

i=1 (cid:20)
X

x2
i
τ −

ln(2xi)
(cid:21)

ˆτ =

1
N

N

i=1
X

x2
i

ln Lmax = N (1 + ln ˆτ )

ln(2xi)

−

= N (1 + ln ˆτ )

ln(2√ti)

N

−

−

i=1
X
N

i=1
X

3.2. The Second Surprise

Since under this method, our P-value ensemble is
actually based on the value of ˆτ computed from the
), we always obtain
data (not knowing the true value
a P-value of about 50%, for any data whatsoever. This
is a second disaster for g.o.f. By construction, the
distribution of Lmax from our ensemble of N -event
pseudo experiments tracks the Lmax observed from
the data.

T

The fact that the method yields “reasonable” P-
values has undoubtedly contributed to its longevity
in practice: P-values very near 0 or 100% would have
triggered further investigation.

That is, the “g.o.f.” statistic is not invariant under
change of variable in the continuous p.d.f. case. (The
value of the m.l.e. is, of course, invariant.)

Under change of variable, the “g.o.f.” statistic picks
up an extra term from the Jacobian—an extra func-
tion of the data. We’re free to choose any transfor-
mation, so we can make the “g.o.f.” statistic more or
less anything at all—a serious pathology.

At this point, experts point out that ratios of like-
lihoods have the desired invariance under change of
variable, but, while the likelihood ratio is a useful test
statistic in certain special cases, it is not at all clear
how to obtain a useful g.o.f. statistic from the likeli-
hood ratio in the general, unbinned, case.

3.3. Lessons Learned

5. A REPLACEMENT MODEL

In this example, g.o.f. is equivalent to testing the
single hypothesis: “The data are from an exponential
distribution of unspeciﬁed mean.” Lmax provided no
information with respect to this hypothesis.

What went wrong? In our test case, the likelihood
could be expressed as a function of just the param-
eter and its maximum likelihood estimator (m.l.e.):
L(τ ; ˆτ ). All data samples with the same m.l.e. gave
the same “g.o.f.”

Exactly the same thing happens in the Gauss-
ian (normal) case—the likelihood can be written us-
ing solely the 2 parameters and their estimators:
L(µ, σ; ˆµ, ˆσ).

Other “textbook” distributions—scaled gamma,
beta, log-normal, geometric—also fail in the same way.
Geometric is a discrete distribution, so the problem is
not restricted to the continuous case.

4. MORE TROUBLE: NON INVARIANCE

Returning to our exponential example, suppose we
make the substitution t = x2. The p.d.f. transforms
as

−t/τ dt =

e

1
τ

2x
τ

e

2

−x

/τ dx

Since we now lack an intuitive understanding, we
need a replacement intuition for what is going on. I
propose this model:

Denote by H0 the hypothesis that the data are from
the p.d.f. in question. Specify an alternative hypoth-
esis H1 that the data are from a uniform p.d.f. (ﬂat
in the variables that we happen to have chosen). At
least, the H1 p.d.f. is ﬂat over the region where we
have data—outside that region it can be cut oﬀ.

Performing a classic Neyman-Pearson hypothesis
test of H0 vs H1, we use the ratio of their likelihoods
as our test statistic:

λ(~x) =

H0)
L(~x
|
H1)
L(~x
|

=

L(~x)
constant

So, the “g.o.f.” statistic can be re-interpreted as suit-
able for a hypothesis test that indicates which of H0
(our p.d.f.) and H1 (a ﬂat p.d.f.) is more favored by
the data—a well established statistical practice.

The beneﬁt of the new interpretation is that it ex-
plains behaviors that were baﬄing under the g.o.f. in-
terpretation: Neyman-Pearson hypothesis tests and
g.o.f. tests behave quite diﬀerently.

For example, a reasonable g.o.f. statistic should
be at least approximately distribution independent,
but λ(~x) is often highly correlated with the m.l.e.’s

MOCT001

PHYSTAT2003, SLAC, Stanford, California, September 8–11, 2003

3

(100% in our exponential case). This high correla-
tion was conﬁrmed in the example contributed by
K. Kinoshita[3] to the 2002 Durham Conference. Not
knowing the true value of the parameters then makes
it diﬃcult, or impossible, to use λ(~x) as g.o.f., since
we don’t know what λ(~x) should be.2 The behav-
ior of these correlations is natural and obvious in
the hypothesis test picture: changing the parameters
changes the “ﬂatness” of the H0 p.d.f., and λ(~x) re-
ﬂects this.

Reference [1] pointed out that, with no unknown pa-
rameters, one can always transform the p.d.f. to a ﬂat
distribution. Then λ(~x) becomes constant indepen-
dent of the data—bad news for g.o.f. In the hypoth-
esis test picture, this becomes a comparison between
two identical hypotheses, and the result is what we
would expect.

6. TEST BIAS

Take the H0 p.d.f. to be

This distribution is fully speciﬁed—no unknown pa-
rameters. Our “g.o.f.” statistic is then

−t

e

(t

0)

≥

ln L = N ˆt

−

ln L

= N , and variance is
whose mean is
i
Var(
ln L) = N , for an ensemble of data sets from
the H0 p.d.f. A data set with ˆt close enough to 1 will
be claimed to be a good ﬁt to the H0 p.d.f.

h−

−

But say, unknown to us, the data are really from a

triangular p.d.f.:

1

t
− |

−

1

|

(0

t

2)

≤

≤

The mean and variance of N ˆt will be N and N/6 re-
spectively, for data from the triangular distribution.
So, although the exponential and triangular p.d.f.’s
are quite diﬀerent, the triangular data will be more
likely to pass the g.o.f. test than exponential data for
which it was intended. Statisticians refer to this situ-
ation as a case of “test bias”.

We conclude that, even with no free parameters, the
“g.o.f.” test is biased: there exist “impostor” p.d.f.’s
that should produce bad ﬁts, but instead pass the
“g.o.f.” test with greater probability then the p.d.f.

2Small correlations are not fatal. For example, if the P-value
of g.o.f. for the observed data in a particular case ranged only
between, say, 20% and 30%, for diﬀerent true values within ±3σ
of the estimated value of a parameter, one would be justiﬁed
in concluding “good ﬁt” (assuming the g.o.f. statistic used had
the right properties in other respects).

MOCT001

for which the test was designed. Reference [4] gives
additional examples of this behavior.

From the hypothesis test point of view, this behav-
ior makes sense. The exponential and triangular data
have the same “distance” from the ﬂat distribution, on
the average, with the triangular data being less sus-
ceptible to ﬂuctuations. The hypothesis test doesn’t
tell us when the data are inconsistent with both H0
and H1.

7. ANOTHER EXAMPLE

Here we try to ﬁnd an example p.d.f. (with a free
parameter) that the method in question can handle
well. We use the insight provided by the hypothe-
sis test picture. We want to keep the correlation be-
tween the free parameter and the g.o.f. statistic Lmax
to a minimum. In the hypothesis test picture, this is
achieved when the “ﬂatness” of the p.d.f. is indepen-
dent of the parameter. A location parameter has this
property. Additionally, we want the p.d.f. to be eas-
ily distinguishable from a ﬂat p.d.f. So we choose the
Gaussian

−0.5(x−µ)

2

2

/σ

1
√2πσ

e

where µ is unknown, but σ is speciﬁed in advance.
The likelihood is given by

ln L =

−

N

i=1 "
X

ln √2π + ln σ +

xi −
σ

1
2

(cid:18)

2

µ

#

(cid:19)

When µ and σ are both unknown, their m.l.e.’s are

ˆµ =

xi

ˆσ2 =

1
N

N

i=1
X

1
N

N

i=1
X

ˆµ)2

(xi −

Using these expressions, we can rewrite the likeli-

hood in the form L(µ, σ; ˆµ, ˆσ):

ln L =

−

N
2

(cid:20)

ln(2π) + ln(σ2) +

ˆσ2 + (ˆµ
σ2

−

µ)2

(cid:21)

When only µ is unspeciﬁed, its m.l.e. is ˆµ as above,
and the value of the maximized likelihood is

ln Lmax =

−

N
2

(cid:20)

ln(2π) + ln(σ2) +

ˆσ2
σ2

(cid:21)

Our victory is that Lmax only depends on ˆσ, which
is an ancillary statistic for µ. That is, we don’t need
to know the true value of µ in order to calculate the
distribution of our g.o.f. statistic in this carefully cho-
sen example. In fact, a convenient form for the g.o.f.
statistic is

N

N

ˆσ2
σ2 =

i=1 (cid:18)
X

xi −
σ

2

ˆµ

(cid:19)

4

PHYSTAT2003, SLAC, Stanford, California, September 8–11, 2003

which is well known to have the distribution (under
the null hypothesis) of a χ2 with N
1 degrees of
freedom.

−

7.1. The Bad News

Before we declare that the method performs well in
this example, there are several ugly facts to consider:

•

•

•

≃

Data that match the null hypothesis well yield
N ˆσ2/σ2
N . Much larger or much smaller val-
ues of the g.o.f. statistic imply poor g.o.f. This is
in contrast to Pearson’s χ2 (binned χ2), for ex-
ample, where smaller χ2 is always better g.o.f.
So we must interpret this statistic diﬀerently
than how we are used to.

The g.o.f. in this example simply reduces to a
comparison between the sample variance and σ2.
Any distribution with variance approximately
equal to σ2 will usually generate data that “pass
the test”, even distributions that look nothing
like a Gaussian. This is the same kind of prob-
lem that we ﬁrst saw in section 3.1.

A construction similar to that of section 6
will produce “impostor” p.d.f.’s that pass the
“g.o.f.” test with greater frequency than the null
hypothesis. So, we have not eliminated the test
bias problem.

of variables. These problems persist when there
are ﬂoating parameters.

•

•

With ﬂoating parameters, the method is often
circular: “g.o.f.” becomes a comparison between
the measured values and the true (but unknown)
values of the parameters. . .

The misbehavior of this “g.o.f.” statistic is un-
derstandable when reinterpreted as the ratio
between the likelihood in question and a uni-
form likelihood, and used to distinguish between
these two speciﬁc hypotheses. Dual-hypothesis
tests are not g.o.f. tests.

Acknowledgments

I would like to thank Louis Lyons for several helpful
discussions of the points raised here, and the organiz-
ers of the PHYSTAT2003 Conference for arranging a
superb program.

References

In this example, the g.o.f. method in question will
be able to ﬂag some, but not all, of data samples
that poorly match the null hypothesis. In answer to
the question “Are the data from a Gaussian with un-
speciﬁed mean, and variance equal to σ2?”, this g.o.f.
method can only answer “No” or “Maybe”: it checks
the variance part of the question, but does nothing to
check the Gaussian part.

8. CONCLUSIONS

•

This “g.o.f.” method is fatally ﬂawed in the un-
binned case. Don’t use it. Complain when you
see it used.

•

With ﬁxed p.d.f.’s, the method suﬀers from test
bias, and is not invariant with respect to change

be

used

[2] J.G. Heinrich,

[1] W.T. Eadie, D. Drijard, F.E. James, M. Roos, and
B. Sadoulet, Statistical Methods in Experimen-
tal Physics, chapter 11, pages 268, 271, (North-
Holland Publishing Co, Amsterdam, 1971).
likelihood
“Can

the
to measure

func-
goodness-of-
tion
(2001).
CDF Internal Note 5639,
ﬁt?”,
www-cdf.fnal.gov/publications/cdf5639_goodnessoffitv2.ps.gz
[3] K. Kinoshita, “Evaluating quality of ﬁt in un-
binned maximum likelihood ﬁtting”, in Proceed-
ings of the Conference on Advanced Techniques
in Particle Physics, edited by M. Whalley and
L. Lyons, p 176, (2002).
www.ippp.dur.ac.uk/Workshops/02/statistics/proceedings/kinoshita.ps

[4] J.G. Heinrich, “Unbinned likelihood as goodness-
of-ﬁt for ﬁxed distributions: A critical review”,
CDF Internal Note 6123, (2002).
www-cdf.fnal.gov/publications/cdf6123_gof_like_fixed.ps

MOCT001

