6
0
0
2
 
r
p
A
 
0
2
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
7
6
1
4
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Precursors of extreme increments

Sarah Hallerberg, Eduardo G. Altmann, Detlef Holstein, Holger Kantz
Max Planck Institute for the Physics of Complex Systems
N¨othnitzer Str. 38, D 01187 Dresden, Germany

(Dated: September 3, 2013)

We investigate precursors and predictability of extreme events in time series, which consist in large
increments within successive time steps. In order to understand the predictability of this class of
extreme events, we study analytically the prediction of extreme increments in AR(1)-processes. The
resulting strategies are then applied to predict sudden increases in wind speed recordings. In both
cases we evaluate the success of predictions via creating receiver operator characteristics (ROC-
plots). Surprisingly, we obtain better ROC-plots for completely uncorrelated Gaussian random
numbers than for AR(1)-correlated data. Furthermore, we observe an increase of predictability
with increasing event size. Both eﬀects can be understood by using a likelihood ratio as a summary
index for smooth ROC-curves.

PACS numbers: 02.50.-r,05.45.Tp
Keywords: time series analysis, extreme events, extreme increments, precursors

I.

INTRODUCTION

Systems with a complex time evolution, which gener-
ate a great impact event from time to time, are ubiqui-
tous. Examples include ﬂuctuations of prices for ﬁnan-
cial assets in economy with rare market crashes, electrical
activity of human brain with rare epileptic seizures, seis-
mic activity of the earth with rare earthquakes, changing
weather conditions with rare disastrous storms, and also
ﬂuctuations of on-line diagnostics of technical machinery
and networks with rare breakdowns or black-outs. Due
to the complexity of these systems mentioned, a com-
plete modeling is usually impossible, either due to the
huge number of degrees of freedom involved, or due to a
lack of precise knowledge about the governing equations.
Considering the great impact of the above mentioned
events, a prediction of their occurrence is nonetheless
highly desirable. Therefore, there have been many at-
tempts to employ time series strategies for this purpose.
These strategies usually investigate a record of historical
data about the phenomenon under study and try to infer
knowledge about the future. In view of extreme events,
one often focuses exactly on the prediction of these. A
standard approach is to search for precursors, i.e., typ-
ical signatures preceeding an extreme event. Such pre-
cursors have been discussed, e.g. in the literature about
earthquakes[1], epileptic seizures [2], and stock market
crashes [3].

Depending on the amount of available data, precursors
are statistically more or less signiﬁcant. The standard
way of ﬁnding precursors is to collect time series seg-
ments preceeding observed events. We shall discuss that
the study of such precursors does not necessarily lead to
optimal predictions.
In this contribution we also show
that the existence of correlation does not necessarily im-
ply any predictability of the event to follow. We will
present analytic results for an auto-regressive process of
order 1 (AR(1)) [4] where quite counter-intuitively the

predictive power of the precursor decreases with increas-
ing correlation between each time step.

The predictability of an event can also depend on the
event size. In Refs. [5] and [6] it is reported that extreme
events are the better predictable, the more extreme they
are. In the case of the AR(1) process, we can understand
this eﬀect, by investigating the predictability of extreme
increments analytically.

The paper is organized as follows. In Sec. II A we dis-
cuss two strategies which can be used to choose precur-
sory structures and in Sec. II B we introduce a method to
evaluate the predictive power of precursors. The extreme
events we dicuss in this contribution are deﬁned in Sec.
II C and we show how to obtain their joint PDFs analyt-
ically in Sec. II D. We apply these procedures to AR(1)-
correlated stochastic processes in Sec. III and to wind
speed measurements in Sec. IV. Conclusions appear in
Sec V.

II. DEFINITIONS AND SET-UP

A. The choice of the precursor

In this contribution we are interested in general sys-
tems with a complex time evolution. They might be
purely deterministic, then high-dimensional and chaotic,
or they might be stochastic. The model class will not be
relevant for the general considerations of this section. In
any case we assume that the time evolution of the system
cannot be easily modeled and hence one tries to extract
information about the future from time series data. This
means that through some experimental observation one
can record a usually univariate time series, i.e., a set of
measurements xn at discrete times tn, where tn = t0+n∆
with a sampling interval ∆. The recording should con-
tain suﬃciently many extreme events so that we are able
to extract statistical information about them from these

data. We also assume that the event of interest can be
identiﬁed on the basis of the observations, e.g., by the
value of the observation function exceeding some thresh-
old, by a sudden increase, or by its variance exceeding
some threshold.

Ideally, a precursor is a typical signature in the data
preceeding every individual event. Unfortunately the
time evolution of most systems is usually too irregular
to demand this, so one would call a precursor a data
structure which is typically preceeding an event, allowing
deviations from the given structure, but also allowing
events without preceeding structure. This interpretation
of a precursor allows to determine the speciﬁc values of
the precursor structure by statistical considerations.

k+1, xn

In order to predict an event occurring at the time
(n + 1) we compare the last k observations ~s(n,k) =
1, xn) with a speciﬁc precursor
(xn
k+2, ..., xn
−
structure ~spre = (xpre
k+1, xpre
n ), which
n
−
is usually chosen according to one of the two following
strategies:

k+2, ..., xpre

1, xpre

−

−

−

−

n

n

(I) The ﬁrst strategy consists in deﬁning the pre-
cursors in a retrospective or a posteori way:
once the extreme event (X) has been identi-
ﬁed one asks for the signals right before it.
Formally, this implies that the precursory struc-
the
ture consists of distinguished values, e.g.,
xn
xn
(
xn
means
)
xni
,
,
1i
k+1i
h
h
h
h
component
in
maxima
or
1, x∗n) of the conditional
(x∗n
k+2, ..., x∗n
−
PDF

the
k+1, x∗n

k+2i

each

, ...,

−

−

−

−

−

ρ(~s(n,k)|

X) =

P (~s(n,k), X)
P (X)

P (X

~s(n,k))ρ(~s(n,k))
|

=

. (1)

P (X)

Using the language of Bayesian Statistics [7]
X) is called the posterior PDF, the con-
ρ(~s(n,k)|
~s(n,k)) is named the like-
ditional probability P (X
|
lihood, the marginal PDF ρ(~s(n,k)) is called prior

2

PDF and the probability P (X) is known as predic-
tive probability.

(II) The second strategy consists in determining the
likelihood, i.e.
the conditional PDF that an ex-
treme event follows a given observation ~s(n,k). Thus
we are interested in those values of each component
xi of the condition ~s(n,k) for which the likelihood

P (X

~s(n,k)) =
|

P (~s(n,k), X)
P (~s(n,k))

ρ(~s(n,k)|

=

X)P (X)

(2)

ρ(~s(n,k))

is maximal.
general not deﬁned, since P (X
malized in ~s(n,k).

In this case the mean values are in
~s(n,k)) is not nor-
|

In summary the possible values of precursors are given
by

~sI ,
~sI i
h
~sII ,



x∗n

: ρ(~s(n,k)|
(cid:0)
i = (n
∀

−

~spre =

of ρ(~s(n,k)|

X),

(3)

~sI :=

k+1, x∗n

k+2, ..., x∗n

1, x∗n

,

with x∗i

~sI i
h

=

−

X) = maxxi

−

k + 1), (n

−
k+1iρ(~s(n,k)|

−

1iρ(~s(n,k)|

−

X),

X),

xn
h
(cid:16)
...,

xn
h
x†n

(cid:1)
k + 2), ..., n;

k+2iρ(~s(n,k)|
,

X)

−

−
xn
h
xniρ(~s(n,k)|
h
,
1, x†n

(cid:17)

(cid:17)

k + 2), ..., n.

and ~sII :=

with x†i

−
(cid:16)
: P (X

k+1, x†n

k+2, ..., x†n

−
~s(n,k)) = maxxi
|
k + 1), (n

i = (n

−

∀

−

−

X), ...,

Once the precursory structure ~spre is determined, we give
an alarm for an extreme event, when we ﬁnd the last k
observations ~s(n,k) in the volume

Vpre(δ) =

xpre
n
−

k+1 −

δ
2

, xpre
n
−

k+1 +

δ
2

xpre
n
−

k+2 −

δ
2

, xpre
n
−

k+2 +

δ
2

...

×

(cid:19)

×

(cid:18)

xpre
n −

δ
2

, xpre

n +

δ
2

.

(cid:19)

×

(cid:19)

(cid:18)

(cid:18)

(4)

B. Testing for predictive power

according to

A common method to verify a hypothesis or test the
quality of a prediction is the receiver operating character-
istic curve (ROC-plot) [8] , [9]. In the 1980s it became
popular for medical diagnostic testing, nowadays there
are many other ﬁelds of applications as well. The idea
of the ROC-plot consists simply in comparing the rate of
correctly predicted events rc with the rate of false alarms
rf by plotting rc vs. rf . These rates can be calculated

and rf (~spre, d, δ) =

d~s(n,k) ¯ρ(~s(n,k)|

X(d)),

(6)

X(d)) denotes the PDF to observe a pre-
where ρ(~s(n,k)|
ceeding structure ~s(n,k) and to observe an extreme event
X(d)) denotes the a pos-
of size d. Analogously ¯ρ(~s(n,k)|
teori PDF to observe a preceeding structure ~s(n,k) and
not to observe an extreme event of size d. Plotting rc vs

rc(~spre, d, δ) =

d~s(n,k) ρ(~s(n,k)|

X(d)),

(5)

ZVpre(δ)

ZVpre(δ)

rf for increasing values of δ one obtains a curve in the
unit-square of the rf -rc plane. The curve approaches the
,
origin for δ
→ ∞
where δ accounts for the size of the precursor volume
Vpre(δ) (see Eq. (4)).

0 and the point (1, 1) in the limit δ

→

The shape of the curve characterizes the signiﬁcance
of the prediction. A curve above the diagonal reveals
that the corresponding strategy of prediction is better
than a random prediction which is characterized by the
diagonal. Furthermore we are interested in curves which
converge as fast as possible to 1, since this scenario tells
us that we reach the highest possible rate of correct pre-
diction without having a large rate of false alarms. There
are various so called summary indices [10] which quan-
tify the behavior of the receiver operating characteris-
tics. The most popular of them consists in measuring the
area under the ROC -plot, but there are other concepts
like the Kolmogorov Smirnov -index, which measures the
largest distance of the ROC-plot from the diagonal. We
introduce the slope m of the ROC-plot in the vicinity of
0) as a new summary index
the origin (which implies δ

m(d) =

∆rc
∆rf

=

→
ρ(~s(n,k)|
¯ρ(~s(n,k)|

X(d))
X(d))

+

(δ). (7)

O

rf

0,δ

0

≈

≈

(cid:12)
(cid:12)
(cid:12)
(cid:12)

This index is characteristic for the region of the plot
which corresponds to low rates of false alarms, i.e., the
vicinity of the origin. Thus we can use it as a summary in-
dex, to determine the quality of the predictions we made.
Note that m(d) is similar to the likelihood ratio, which
is used in many medical applications. However, the deﬁ-
nition of Vpre(δ) and the use as summary index demand
that its interpretation as the slope of the ROC-plot is
restricted to the vicinity of the origin.

By inserting the probabilities to give an alarm or not
to give an alarm according to Eq. (1) into Eq. (7), the
slope reads

m(d) =

1

P

X(d)

−
P

(cid:16)

X(d
(cid:0)

)

(cid:1)(cid:17)

~s(n,k))
P (X(d)
|

1

~s(n,k))
P (X(d)
|

−

. (8)

(cid:17)

(cid:0)

(cid:1)

(cid:16)

(cid:0)

X(d)

~s(n,k)
X(d)
|

This expression allows us to discuss the quality of
the ROC-plot, by knowing the total probability to
observe extreme events P
and the likelihood
. If we assume that the ratio of the like-
P
(cid:1)
(cid:0)
lihoods (the right ratio in Eq. (8) is approximately con-
stant in d, or that it contributes a non-leading term to
m(d), we can conclude that the slope m(d) becomes the
larger, the smaller the probability to observe an extreme
is, i.e., the more rare the event is. In gen-
event P
eral we have to take into account also the inﬂuence of the
ratio of the likelihoods, and hence a more sophisticated
discussion is needed.

X(d)

(cid:0)

(cid:1)

(cid:1)

C. Deﬁnition of Extreme Increments

3

of the observed variable within a few time steps. An
example for this kind of extreme events are the increases
in wind speed in [5], [11], but also stock marked crashes
[3] which consist in sudden decreases.

In this context we deﬁne our extreme event by an in-

crement xn+1 −

xn exceeding a given threshold d

xn+1 −

xn ≥

d,

(9)

xn)

where xn and xn+1 denote the observed values at two
consecutive time steps. We deﬁne also a subspace
Aee :=
of the space of all possible
d
(xn, xn+1 : (xn+1 −
{
}
observations, which contains only those pairs (xn, xn+1)
of data, which form an extreme event. The extreme
Aee can be obtained from the time-series by
events in
calculating the increment and simply ﬁltering out these
events from the rest of the data.

≥

Another common deﬁnition of extreme events is the

exceedance of a given threshold d,

xn ≥

d.

(10)

In this article we concentrate on events deﬁned according
to Eq. (9). In appendix A we show how to relate our
results to extreme events deﬁned via Eq.
(10) for the
class of stochastic processes studied in Sec. III.

D. Θ-ﬁlter

A mathematical expression for a ﬁlter, which selects
the PDF of our extreme events out of the PDFs of the
underlying stochastic process can be obtained through
d). This ﬁlter is
the Heaviside function Θ(xn+1 −
then applied to the joint PDF of a stochastic process.

xn −

Since only the time steps (xn, xn+1) are of relevance for
the ﬁltering, we can neglect all previous time steps and
apply our ﬁlter simply to the joint PDF for (xn, xn+1),
xn)
which has the form ρj(xn, xn+1) = ρn(xn)ρn+1(xn+1|
This implies that we can regard all previous time-steps
1, on which ρn and ρn+1 might depend, as
x0, x1, ..., xn
parameters.

−

The joint PDF of the extreme events ρΘ

j (xn+1, xn, d)
can then be obtained by multiplication with Θ(xn+1 −
d). If the resulting expression is non zero, the con-
xn −
dition of the extreme event (9) is fulﬁlled and for xn+1
and xn the following relation holds:

xn+1 = xn + d + γ

(γ

0)

.

(11)

R, γ

∈

≥

In this contribution we will concentrate on extreme
events which consist in a sudden increase (or decrease)

Hence it is possible to express the joint probability den-
sity in terms of xn or xn+1

4

(12)

(13)

Θ(xn+1 −

xn −

d)ρj (xn, xn+1) =

ρn(xn)ρn+1(xn + d + γ
0
ρn(xn+1|
0

xn+1 −

−

d

=

(cid:26)

(cid:26)

xn),
|

if (xn+1 ≥
otherwise;

xn + d);

γ)ρn+1(xn+1),

if (xn+1 ≥
otherwise,

xn + d);

with the new random variable γ. Both descriptions are
equivalent, but since we are interested in predictions we
will restrict to the notation in Eq.(12) in the following.
We can use the integral representation of the Heaviside
function with appropriate substitutions to obtain:
f Θ
j (xn+1, xn, d) = Θ(xn+1 −

d)ρj (xn, xn+1)

xn −
xn)
ρn+1(xn + (d + γ)
|

∞

0
Z
δ((xn+1 −
(14)
By normalizing with the total probability P Θ(d) to ﬁnd
extreme events of size d or larger

xn −

γ) dγ.

d)

−

= ρn(xn)

P Θ(d) =

∞

dxn

∞

dxn+1 f Θ

j (xn, xn+1, d), (15)

Z
−∞
we obtain the joint PDF ρΘ
xn and xn+1 which are part of an extreme event

j (xn, xn+1, d) of all values of

−∞

Z

ρΘ
j (xn+1, xn, d) =

f Θ
j (xn+1, xn, d)
P Θ(d)

.

(16)

Integrating Eq. (16) we ﬁnd the following expression for
the marginal distribution:

ρΘ
m(xn, d) =

∞

dxn+1 ρΘ

j (xn+1, xn, d)

Z
−∞
ρn(xn)
P Θ(d)

=

∞

0
Z

dγ ρn+1(xn + d + γ

xn).
|

(17)

Each value of the marginal PDF ρΘ
m(xn, d) denotes the
probability to observe the value xn and to ﬁnd an extreme
event of size d of larger. Analogously ¯ρΘ
m(xn, d) denotes
the PDF to observe a value xn and not to observe an
extreme increment of size d or larger.

¯ρΘ
m(xn, d) =

ρn(xn)

(1

P Θ(d))
−
Θ(xn+1 −

−∞

Z
xn −

∞

dxn+1

1

−
(cid:16)
ρn+1(xn+1|

xn).

d)

(cid:17)

Note that ρΘ
m(xn, d) is the posterior PDF according to
Eq. (1) and ¯ρΘ
m(xn, d) is the posterior PDF not to ob-
serve an extreme event, although the notation does not
stress, that they are conditional PDFs, since this is im-
plied by the fact, that they are the results of the ﬁltering
for extreme increments.

If for a given process the joint probability ρj(xn, xn+1)
m(xn, d),

is known, we can hence analytically determine ρΘ
m(xn, d) and P Θ(d), by using the Heaviside function.
¯ρΘ

 0

-5

-10

-15
 2

 0

-2

 1
 0
-1
-2
 2

 0

-2

 10
 0
-10

 

 

 

 

a=0.99

a=0.75

a=0

 

 

 

 

 

 

 

a=-0.99

 

 

 

 

 

 

 

 

 

 

 

 

 

a=-0.75

tn

 10000

 10020

 10040

 10060

 10080

 10100

FIG. 1: (Color online) A part of the time series for diﬀerent
values of a.

III. EXTREME INCREMENTS IN THE AR(1)
MODEL

A. AR(1) model

We assume that the time-series

is generated by
an auto-regressive model of order 1 (AR(1)) (see e.g. [4])

xn}

{

xn+1 = axn + ξn,

(19)

where ξn are uncorrelated Gaussian random numbers and
1 < a < 1 is a constant which represents the coupling
−
strength. The size and the sign of the coupling strength
determine whether successive values of xt are clustered
or a spread, as illustrated in Fig. 1. The joint PDF is in
this case the product of the conditional PDFs to observe
the value xn+1 after xn was observed

ρj(x0, x1, ..., xn+1) = ρ(x0)ρ(x1|

x0)...ρ(xn+1|

xn).

(18)

For a stationary process the conditional PDFs are given
by

ρ(xn|

xn

1) =

−

1
2π

r

exp

1
2

−

xn −
(cid:0)

(cid:18)
The marginal probability for one variable xn of an AR(1)
process reads

(cid:19)

(cid:1)

2

axn

1

−

.

(20)

ρm(xn, a) =

√1

a2

−
√2π

exp

1

a2

−
2

x2
n

.

(cid:19)

−

(cid:18)

(21)

In the case a = 0 the process reduces to uncorrelated
random numbers with mean µ = 0 and variance σ2 = 1.
Since the size of the events is naturally measured in units
of the standard deviation σ(a) we introduce a new scaled
a2)d.
variable
Applying the ﬁlter mechanism developed in Sec. II D
we obtain the following expressions for the marginal PDF
of extreme events and the marginal PDF of non-extreme
events

σ(a) = (√1

d = d

−

e

ρΘ
m(xn, a,

d) =

√1
a2
2√2πP Θ(a,

−

d)

exp

1

a2

−
2

x2
n

(cid:19)

−

(cid:18)

¯ρΘ
m(xn, a,

d) =

e

e

erfc

(1

a)xn
−
e
√2

+

 
√1

a2
−
P Θ(a,

d))

exp

(1

a)xn
e

−
√2

+

2√2π(1

1 + erf

 

−

 

d
√2√1
e

, (22)

a2 !
a2

−
1

−
2

x2
n

(cid:19)

.

−

a2 !!
(23)

−

(cid:18)

d
√2√1
e

B. Determining the precursor value

Because of the Markov-probability of the AR(1) model
the preceeding structure is reduced to a preceeding value
xn. Hence, we give an alarm for an extreme event when
an observed value xn is in an interval

Ipre = [xpre −

δ/2, xpre + δ/2];

(24)

around the precursor value xpre. We compute the precur-
sor values xI ,
and xII deﬁned by Eq. (3) according
to the strategies described in Sec. II A. The posterior
PDF given by Eq. (1)) and the likelihood according to
Eq. (2)) read for the AR(1) model:

xI i
h

(I)

(II)

ρ(xn|

X) = ρΘ

m(xn, a, d)

and P (X

xn) =
|

P Θ(d)ρΘ

m(xn, a, d)
ρ(xn)

.

The maximum xI of ρΘ
d) , obtained by diﬀerenti-
ating Eq. (22) with respect to xn, is given by the solution
of the transcendental equation

m(xn, a,

e

xI =

√2
√π(1 + a)

exp

(1

a)xI +

−

(cid:18)
erfc

(cid:16)
(1

−
a)xI
−
√2

1
2

(cid:16)

√1

a2

d

−
e

2

(cid:19)

.

(cid:17)

+

d
√2√1
e

a2

−

(cid:17)

(25)

)
˜d
,
a
,

n

x
(
 

θ

ρ
 
n

l

 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
 0.5
 0.4
 0.3
 0.2
 0.1
 0

5

˜d=8

˜d=4

˜d=0

˜d=2

a =0.0

a=-0.75
a=-0.99

a=0.75

a=0.99

-30

-25

-20

-10

-5

 0

-15
xn

FIG. 2: (Color online) Marginal PDFs for the AR(1) process
d. The PDFs become asym-
for diﬀerent values of a < 0 and
metric for a
the marginal
−
PDFs is becomes very ﬂat and can hence not be distinguished
from the x-axis in this ﬁgures).

1. (For a =

0.99 and d

→ ∞

→ −

e

Inserting the asymptotic expansion for large arguments
of the complementary error function

erfc(z)

exp(

z2)
√πz  

−

1 +

∼

1)m 1

·

3...(2m
(2z2)m

−

1)

∞

(
−
m=1
X
<

3π
4

(cid:19)

,
→ ∞

argz
|

|

z
(cid:18)

,

!

(26)

which can be found in [12] we obtain:

d

xI ∼ −

2√1

a2

−

1 +
e

O

1
d2

,

d
(

). (27)

→ ∞

e

e

(cid:16)

(cid:16)

d) becomes asymmetric if a

d) according
d. One can see

d) moves towards
e

e
(cid:17)(cid:17)
Fig. 2 shows the marginal PDFs ρΘ
m(xn, a,
to Eq. (22) for diﬀerent values of a and
that the maximum of ρΘ
m(xn, a,
−∞
d and decreasing a. Note that
with increasing size of
e
ρΘ
1 and its vari-
m(xn, a,
1. Although we can al-
ance increases immensely if a
e
ways formally deﬁne the maximum xI and the mean
xI i
h
as precursor values, one can argue that the maximum of
1. Since
the distribution has no predictive power if a
ρΘ
d) becomes very ﬂat in this limit, the value of
m(xn, a,
ρΘ
d) in its maximum does not considerably diﬀer
m(xn, a,
e
from the values in any other point. The analogous dis-
d) is
xI i
cussion holds for the mean
e
h
approximately symmetric for a
xI
→
holds.

, since the ρΘ
1, and hence

m(xn, a,
xI i ∼
h
e

→ −

→

→

e

An analytic expression of the mean can be obtained

using an integral representation from [13]

exp

d2

xni
h

= −

−
(cid:16)
(cid:17)
2√π√1 + a P Θ(a,

4(1
−
e

a)

d)

.

(28)

e

Since we do not know the analytic structure of P Θ(a,
d)
explicitely, we have to use another approach to reveal the
d we
analytic properties of the mean. For large values of
e
can assume that

xI i ≃
h

xI ∼ −

d

2√1

a2

−

1 +
e

O

1
d2

e
),

,

d
(

→ ∞

(cid:16)

(29)
(cid:17)(cid:17)
d) is not too asymmetric (i.e. a

(cid:16)

e

e

provided that ρΘ
is not to small).

m(xn, a,

e

In the following investigations we will use the mean
of the marginal PDF as a precursor for strategy I, since
it can be calculated explicitely by evaluating the cor-
responding integral over ρΘ
d) , and it is a good
d and
approximation of the maximum xI for all sizes of
not too small values of a.

m(xn, a,

e

In order to determine xII , the precursor for strategy

e

II, we have to ﬁnd the maximum in xn of

P Θ(

m(xn,

d)

d)ρΘ
ρn(xn)
e
the

e

erfc

(1

a)xn
−
√2

+

(cid:16)

2

d
√2√1
e

a

−

(cid:17)

=

.(30)

error

complementary

a
Since
monotonously decreasing function of xn we see that
we do not have a well deﬁned maximum xII and that
the interval I
−
−
represents the optimal strategy to raise alarms according
to strategy II.

] with the upper limit x

function

−∞

= [

, x

is

−

C. Testing the Performance of the Precursor

In order to test for the predictive power of xI we create
ROC -plots, as discussed in Sec. II B. In order to deter-
mine the rates analytically we evaluate the integrals (5)
for
and (6) on the corresponding intervals Ipre and I
strategies I and II.

−

(31)

(32)

rc(xpre,

d, δ) =

dxn ρΘ

m(xn,

d),

ZI

rf (xpre,

e
d, δ) =

dxn ¯ρΘ

m(xn,

e
d).

e

ZI
We also generate ROC-plots empirically by predicting
within 107 AR(1)- correlated data. The test consisted in
counting the number of extreme events which could be
predicted by using the mean of ρΘ
d) as a precur-
sor. The empirically determined rates comply with the
rates obtained via the evaluation of (31) and (32).

m(xn, a,

e

e

The resulting ROC-plots display that the prediction
within the strongly correlated random numbers with pos-
itive correlation strength (a=0.99) is not better than
any random prediction which corresponds to the diag-
onal. Hence our precursor does not have any predictive
power in this case. This corresponds to the fact that
ρΘ
d) is very ﬂat for this value of a, as discussed
m(xn, a,
in the previous section.
e

6

a=0
a=0.75

a=0.99
a=-0.75
a=--0.99

a=0
a=0.75

a=-0.75
a=--0.99

d=4

d=8

 0  0.2 0.4 0.6 0.8  1

 0  0.2 0.4 0.6 0.8  1

i

s
n
o
i
t
c
d
e
r
p
 
t
c
e
r
r
o
c
 
f
o
 
e
t
a
r

 1
 0.8
 0.6
 0.4
 0.2
 0

 1
 0.8
 0.6
 0.4
 0.2
 0

 1
 0.8
 0.6
 0.4
 0.2
 0

 1
 0.8
 0.6
 0.4
 0.2
 0

d=0

d=2

 0  0.2 0.4 0.6 0.8  1

 0  0.2 0.4 0.6 0.8  1

rate of false alarms

FIG. 3:
(Color online) The ROC-Plots made for the pre-
cursors of strategy I and II. The lines represent the results
of strategy I, the symbols correspond to predictions made
according to strategy II. In both cases the predictions were
made within 107 AR(1)- correlated data. In the case a = 0.99
the data set contained no extreme events which were signiﬁ-
cantly larger than d = 0. Very large events(d = 8) were only
observed for a=-0.75 and a=-0.99.

Surprisingly we observe a better quality of prediction
for a = 0, although in this case the predictions were
made within completely uncorrelated random numbers.
This is contrary to the intuitive expectation that the
quality of the prediction should increase with increasing
correlation strength. We observe in fact the opposite:
the predictability increases with decreasing correlation
strength a. This eﬀect can be explained by the depen-
dence of m(xpre, a, d) on the likelihood P (X
xpre). The
|
conditional PDF for the step xn+1 of the AR(1)-process
is according to Eq.
(20) a Gaussian, with mean axn.
Suppose now, that the last observation is xn = xpre < 0.
If a > 0, the conditional PDF has its mean in a negative
value, if a < 0, the mean is positive. The shift by the
0 the likelihood to ﬁnd extreme
mean causes that for a
xn + d , after the precursor xpre was
increments xn+1 ≥
observed, is larger than it is for a > 0. A formally expla-
nation of the a-dependence is also given by an asymptotic
expression for the slope m(xpre, a, d), which we derive in
Sec. III D.

≤

In addition to the dependence on the coupling
strength a, the ROC-plots display an increase of the qual-
ity of our prediction with increasing size of the events d.
Explanations for this eﬀect are also provided by the de-
tailed analytic structure of the slope of the ROC-plot in
Sec. III D.

Furthermore Fig. 3 reveals that the predictions ac-
cording to strategy II are better than the predictions ac-
cording to strategy I for all values of a and d. This result
is not surprising since in the limit of xn → −∞
Eq. (30)
0, i.e., the number of
tends to 1. This implies that rf →
false alarms tends to zero. Indeed, due to this untypical
behavior of Eq. (30) one can argue that the choice of the

7

interval I
−
of AR(1) processes.

corresponds to an optimal choice for the case

We can use Eqs. (27) and (28) to obtain an approxima-
tion for the total probability to observe extreme events

D. Analytical investigation of the Precursor
Performance

In the case of the AR(1) process the slope of the ROC-

plot in the vicinity of the origin is given by

m(a,

d, xpre)

∼ (cid:16)

r

xpre,

d

, (33)

(cid:17)

with r

xpre,

=

erfc

(cid:16)
1 + erf

e
d

(cid:1)
e

(cid:0)

1

P Θ(

d)

d)

−
P Θ(
a)xpre
√2
e
a)xpre
√2

−

e
+

(1

−

(1

(cid:16)

(cid:1)
e

(cid:0)
d
√2√1
e

−
d
√2√1
e

+

a2

(cid:17)
a2

−

(cid:17)

√1

a

−
√π

1

d

∼

exp

 −

4(1

a) !

P Θ

1(a,

d)

d

≫

e

e

1 +

·

(cid:18)

O

e
(cid:18)

,

(cid:19)(cid:19)

). (35)

→ ∞

d2

−
e
d
(

e

1
d3

e

.(34)

Inserting this asymptotic form of the probability we ob-
tain

m(a, d, xpre)

∼ 

√1

√π

a

−



e

d exp

4(1

 

d2

−
e

1

a) ! 


1 +

O

1
d3



−





(cid:0)



(cid:17)

(cid:16)

e

(cid:1)
e

e

1

r

xpre,

d

,

d
(

).

→ ∞

(36)

According to the choice of the precursor xpre, we have to
consider two diﬀerent behaviors of the ratio r

d

xpre,

r

xpre,

d

=

lim
d

→∞

(cid:0)

(cid:26)

(cid:1)
e

1,
0,

if xpre =
if xpre >

(cid:0)
;
−∞
.
−∞

(cid:1)
e
(37)

e

The ﬁrst case corresponds to the theoretical precursor
value for strategy II. The slope of the ROC-curves ob-
tained with strategy II can be computed by simply eval-
uating Eq. (33) at the value xII =

mII (a,

d, xpre) =

for xII =

d

= 0. (38)

∞

If we make predictions according to strategy II, with a
e
, we should in the-
size independent precursor xII =

e

−∞

−∞

,
−∞

−∞

ory expect ROC-curves which coincide with the verti-
cal axis of the plot and hence represent an ideal pre-
dictability for all size of events and all possible correla-
tion strengths. However, since in any ﬁnite data set, the
precursor is not
, but the smallest accessible data
point, we ﬁnd also for strategy II ROC-plots which de-
pend on a and
d. For any ﬁnite precursor value, i.e.,
in our example xI and any ﬁnite xII , it is necessary to
discuss, if the contribution of the ratio r
or the
exponential function in Eq. (36) prevails. Inserting the
asymptotic expansion of the complementary error func-
tion in Eq. (26), the slope in the vicinity of the origin
reads

xpre,

(cid:1)
e

e

d

(cid:0)

m(xpre, a,

d)

1
2√1

∼

a e

−

d exp

d2

4(1
−
(cid:18) e

(1

−

a)xpre
√2

+

2

d
√2√1
e

a2

−

a) −
(1

−

(cid:16)
a)xpre
√2

(cid:16)

+

d
√2√1
e

a2

−

(cid:17)

(cid:19)

+

(cid:17)

O  

exp(

d2)
d !
e

e

,

d
(

).

(39)

→ ∞

This expression tends to
→ ∞
argument of the exponential function in Eq. (39)

in the limit

∞

d

, if the

is positive. Hence we can use the zeros of the parabola
in Eq. (40)

f (xpre, a,

d) =

4(1

a) −  

(1

−

a)xpre
√2

+

e

e

d
√2√1
e

2

,

a2 !

−

(40)

(x0

pre)+,

=

−

1 + a

√3a2 + 2a3
a2)3/2

±
2(1

1

−

d,

(41)

−

to discuss the regimes in which a chosen precursor value
d.
leads to an increase of m(xpre, a,

d) with increasing

e

e

e

e

d2

−
e

6
(a)

 3000

 2500

 2000

 1500

 1000

 500

 0

-500

-50

(b)

 4
 3
 2
 1
 0
-1
-2
-3
-4

 0

 50

 100

xpre

 150

 200

3a2-1+2a3
sqrt(3a2-1+2a3)
0))
f(Re(xpre

f(xpre,-0.99,10)
f(xpre,-0.75,10)
f(xpre,0,10)
f(xpre,0.75,10)
f(xpre,0.9,10)

(c)

0)+
(xpre
0)-
(xpre
0)
Re(xpre

 25

 20

 15

 10

 5

 0

-1

-0.5

 0.5

 1

-1

-0.5

 0.5

 1

 0
a

 0
a

(Color online) (a) The parabolae according to Eq.
FIG. 4:
d = 10 and diﬀerent values of a. (b) The determining
(40) for
components of Eq.(41) and f (Re(x0
pre)) according to Eq. (42).
(c) The zeros and the minimum of the parabolae given by Eq.
(40).

e

Figure 4 illustrates the following discussion. For a > 0.5
the zeros according to Eq.(41) are real numbers, for a <
0.5 we ﬁnd two complex conjugated solutions, since in
this case the root in the numerator of Eq. (41) becomes
imaginary. In the case a = 0.5 we ﬁnd one zero on the
real axis.

The two real zeros for a > 0.5 correspond to the two
intersection points of the parabola in Eq. (40) and the
zero axis, whereas the real parts of the complex solutions
coincide with the point in which the parabola has its
minimum (see Fig. 4). Since there are only complex
solutions in the case a < 0.5, there are no intersections
of the parabola and the real axis in this case. By inserting
the expression for the real part of the solutions, i.e. the
value of xpre in which the parabola has a minimum, we
ﬁnd that

f (Re(x0

pre)) =

d2(1
2a)
−
2a + 2a3
e

−

a < 0.5 .

a4)

4(1

−
for

> 0,

(42)

d

as

→ ∞

d) should also be pos-
for all

Hence all larger values of f (xpre, a,
itive. Thus, m(xpre, a,
d) tends to
values of xpre if a < 0.5.
e
For a > 0.5 the slope m(xpre, a,
d if xpre < (x0

∞
e
e
d) increases with in-
and if xpre > (x0
pre)+.
is within the interval
d) tends to 0 in
. If the precursor has the precise value
d.
pre)+, the slope is not dependent on

creasing
In case that
[(x0
pre)
−
the limit
of (x0
pre)
This holds also in the case a = 0.5.

pre)+], the slope m(xpre, a,

pre)
−
the precursor

→ ∞
or (x0
−
e

, (x0
e
d

e

e

One can easily show,that the precursors xI and xII are
e
1 <
= 0. Hence,
d)

always smaller than (x0
a < 1 and the precursors xII ≤
for both strategies of prediction, the slope m(xpre, a,

pre)
−
xI < 0 for

> 0 for
d

, since (x0

pre)

−

−

e

e

8

d according to Eq.

increases as a squared exponential with increasing size
of the events
(39). This indicates
that the behavior of the slope is essentially dominated
P Θ(a, d))/P Θ(a, d), for
by the behavior of the ratio (1
e
any precursor value which is smaller than 0. Hence, the
considerations of Sec. II B hold for our example, i.e., an
event is the better predictable, the more rare it is. How-
ever, the existence of regimes in which the contribution
of the ratio r(xpre,
d) dominates m(d), reveals that the
ratio r(xpre,

d) cannot be neglected in general.

−

e

e

Additionally, Eq.

(39) indicates that the slope in-
creases with decreasing precursor size according to the
asymptotic behavior given by Eq.
(39) and according
to the parabolae given by Eq. (40). Thus the smallest
possible precursor values lead to the best predictions and
strategy II, which chooses the smallest possible value as
a precursor, is the best strategy to choose. However, this
considerations hold in the limit
, in which the
asymptotic expansion in Eq. (26) is valid. For any ﬁnite
d, one has to choose a precursor value, for which
value of
at least xpre >
holds, which implies, that
a)
the argument of the complementary error function in Eq.
(34) is positive, and hence the asymptotic expansion in
Eq. (26) can be used.

d
a2(1
e

→ ∞

√1

−

e

e

d

−

−

The asymptotic expression for the slope of the ROC-
plots in Eq. (45) describes also the dependence on the
variable a. For a > 0 the slope decreases as a squared ex-
ponential with increasing size of a. In the case a < 0 the
slope increases as a squared exponential and additionally
one has to consider the inﬂuence of the singularity that
appears in Eq.(45) for a

1.
The special case of method I can be also discussed, by
studying ﬁrst the asymptotic behavior of the marginal
PDFs ρΘ
d) and then the com-
plete ratio (33). Inserting the asymptotic expression for
P Θ
d), the approximation of xI in Eq. (29) and the
asymptotic expansion of the complementary error func-
tion Eq. (26) into Eqs. (22) and (23), we ﬁnd the follow-
ing asymptotic expression

m(xpre, a,

m(xpre, a,

d) and ¯ρΘ

→ −

1(a,

≫

e

e

e

d

ρΘ
m

xI , a,

d

(cid:16)

(cid:17)
e

√1

−

a2√1 + a
√π

∼

1 +

O
(cid:16)
1 + a +

1
d2

,

(cid:16)
e
O

(cid:17)(cid:17)
1
d2

d
(

).

(cid:0)

(cid:0)

(43)

(cid:1)(cid:1)

→ ∞
Hence the value of the PDF at the precursor approaches
a constant for large
d. Analogously one can ﬁnd the
approximation

e

¯ρΘ
m

xI , a,

d

(cid:16)

(cid:17)
e

e

√1

a2

−
√2π

∼

exp



−


.

d
(

)
→ ∞
d) and ¯ρΘ
e

d2
8
e

1

1 +

O

1
d2

,



(cid:16)

e

(cid:17)(cid:17)


(44)

m(xn, a,

The PDFs ρΘ
d) evaluated at the
precursor values xI and their approximations are com-
pared in Fig 5. The approximations become worse for

m(xn, a,

e

(cid:16)

e

6
9

(b)

a=0

a=-0.99
a=-0.75
a=0.75
a=0.99

→ −

m(xn, a,

1, since in this case ρΘ

a
d) becomes asymmet-
ric and hence the assumption in Eq. (29) does not hold.
Note that the value of the failure PDF at the precursor
value decreases as a squared exponential with increasing
d.

e

e

(a)

 0.75

 0.5

)
˜d
,
a
,

n

x
(

m

ρ

θ

 0.25

 0

-5

)
˜d
,
a
,

n

x
(

-

-ρ
 
n

l

θ

-10

m

-15

-20

 0

 0  2  4  6  8  10
˜d 

 0

 5

 10  15  20

˜d

(Color online) The lines without symbols represent
d) (ﬁgure

FIG. 5:
the approximations of the marginal PDFs ρΘ
(a)) and ¯ρΘ
≤
a < 1. The symbols are the results of the numerical evaluation
of Eqs. (22) and (43). The constant lines represent the limit
for large d according to Eqs. (43) and (44).

d) (ﬁgure (b)) for diﬀerent values of 0

m(xn, a,

m(xn, a,

e

e

a2 , a,

asymptotic

the
d) and ρΘ
m(

expressions
for
Inserting
d
ρΘ
m(
d) one can ﬁnd
2√1
−
the same expression which one obtains by inserting
e
xpre = xI ∼ −

d
2√1
−
e
e
a2) in Eq. (39)

e
d/(2√1

a2 , a,

−

e

m(xI , a,

d)

2(1 + a)

∼

1 + a +
p

e

(cid:16)

1
d2

O

(cid:16)

e

(cid:17)(cid:17)

exp



8

1 +



(cid:16)

d2

O
e

1
d2

(cid:16)

e

+



O  

(cid:17)(cid:17)



exp(

d2)
d2 !
e

e

, (

d

).

→ ∞

e

(45)

i

s
n
o
i
t
c
d
e
r
p
 
t
c
e
r
r
o
c
 
f
o
 
e
t
a
r

 1

 0.8

 0.6

 0.4

 0.2

 0

d=8

a=0
a=0.75

a=-0.75
a=-0.99

a=0

a=0.75
a=-0.75

a=-0.99

 0

 0.00025

 0.0005

rate of false alarms

FIG. 6:
strategy I for
lines indicate the slope according to Eq. (45).

(Color online) The ROC-plots made according to
d = 8 in the vicinity of the origin. The straight

e

The numerical evaluation of this expression leads to the
straight lines in Fig. 6 which indicate the slopes of the
ROC-plots.

In this interpretation the

d-dependence of the slope
can be explained as a decrease of the failure PDF (see
Eq. (43) and Fig. 5). Fig. 7 illustrates this eﬀect for
the case a =
d)
m(xn, a,
remains at the origin, the values of ¯ρΘ
d) which are
e

e
0.75. Since the maximum of ¯ρΘ

m(xn, a,

−

e

.
d) as xn → −∞
e

observed at the precursor value xI decrease according to
the decrease of ¯ρΘ

m(xn, a,

e

m(xn, a,

Since the precursor value obtained by strategy II is
very far away, from the value in which the marginal fail-
ure PDF ¯ρΘ
d) has its maximum, strategy II seems
to focus on the minimization of the failure rate. The fact,
that in this point the corresponding value of the marginal
PDF ρΘ
d) is also far away from the maximum of
ρΘ
d) does apparently not inﬂuence the outcome
m(xn, a,
of the prediction. Since strategy II leads to better pre-
dictions than strategy I, the minimization of the rate of
false alarm seems to be in the example of the AR(1) pro-
cess more relevant for the quality of the predictions, than
maximizing the rate of correct predictions.

m(xn, a,

e

e

IV. APPLICATION: WIND SPEED
MEASUREMENTS

As an illustration of the preceeding considerations and
also in order to demonstrate the usefulness of the bench-
marks derived for AR(1) processes, we study here time
series data of wind speed measurements. The data are
recorded at 30m above ground by a cup anemometer with
a sampling rate of 8 Hz in the Lammefjord site of the
Risø research center[14]. Wind speed data are evidently

 2

 1.5

 1

 0.5

-0.5

-1

-1.5

-2

 0

-0.5

-1

-2

-2.5

-3

k

x

-1.5

10

--ρθ
 (xn,-0.75,d)
ρθ
 (xn,-0.75,d)

A. Determining the precursor value

If we extract from the data set all subsequences of data
where such a jump is present, then we can, in principle,
construct empirically the distribution p(xn|
g), which cor-
In Fig.8 we show
responds to ρ(~s(n,k)|

X) of strategy I.

 
)
d
,
a
,

x
(
 

n

-

θ
-ρ
 
,
)
d
,
a
,

x
(
 

θ

ρ

 1

 0.8

 0.6

 0.2

n

 0.4

 0

-10

-5

 0

xn

 5

 2
 10  1

 10

 9

 8

d

 7

 6

 5

 4

 3

g=0.25
g=0.5  
g=0.75
g=1     
AR(1)

k

x

 0

−

m(xn, a,

m(xn, a,

m(xn, a,

d) and ¯ρΘ

(Color online) ρΘ

FIG. 7:
a =
serve extreme events ρΘ
cursor, moves towards

d) for
0.75. The maximum of the marginal PDF to ob-
d) , which is used as pre-

e
with increasing
∼
a2)). Because the maximum of the marginal
d) remains at the origin, the values of
m(xn, a,
d) which are observed at the precursor value xI de-
.

−
failure PDF ¯ρΘ
p
e
¯ρΘ
m(xn, a,
crease according to the decrease of ¯ρΘ

e
d since xI

d) as xn

m(xn, a,

d/(2

−∞

(1

−

e

e

e

→ −∞

e

e

non-stationary and strongly correlated, so that, e.g., the
principle of persistence yields surprisingly accurate fore-
casts: the very simple prediction scheme ˆxn+1 = xn is
almost as accurate as an AR(20) model ﬁtted on moving
windows (in order to take non-stationarity into account)
or order-10 Markov chains[11]. The amplitude of the
ﬂuctuations around a time local mean value are propor-
tional to this mean value, i.e., there is statistical evidence
that the noise in this process is multiplicative. However,
when subtracting the time local mean (more precisely,
performing a high-pass ﬁltering with a Gaussian kernel
with a standard deviation of 75 time steps), we receive
data for which it is reasonable to ﬁt an AR(1) process.
When doing so, we ﬁnd a coeﬃcient a

0.94.

≈

Turbulent gusts,

i.e., sudden increases of the wind
speed, are relevant events, e.g., for the save operation
of wind turbines, for aircrafts during take-oﬀ and land-
ing, and for all wind-driven sports activities. In previ-
ous work[5] we were therefore concerned with their pre-
diction, where we were studying the performance of a
Markov chain model. Here, we will restrict ourselves
to the simpler (and less appropriate) AR(1)-philosophy:
The current state of the process generating the wind time
series is assumed to be fully speciﬁed by the last obser-
vation xn, and the event is assumed to be characterized
by the upward jump of the wind speed in a single time
step by more than g m/s.

-20

-15

-10

-5

 0

 5

 10

 15

 20

time k [1/8 s]

FIG. 8: The proﬁles obtained from the mean of p(sn+k
g)
|
for gust events of amplitude g. Also shown is the theoretical
proﬁle for an AR(1) process with a = 0.94

g=0.25
g=0.5  
g=0.75
g=1     
AR(1)

-20

-15

-10

 10

 15

 20

-5

 0
time k [1/8 s]

 5

FIG. 9: The proﬁles obtained from the maxima of p(g
xn)
|
for gust events of amplitude g. Also shown is the theoretical
proﬁle for an AR(1) process with a = 0.94.

−

≤

g) for k =

20, . . . , 20,
instead the mean value of p(xn+k|
i.e., we show the mean proﬁle of gusts of strength g. Oth-
erwise said, this is an average of all those time series
x0 > g, so
segments, which (in shifted time) fulﬁll x1 −
that the part of these segments with k
0 is what one
would call naively a precursor of a gust event. This has
to be compared to the values xn+k which we ﬁnd when
xn) which
we focus on the maximum xII in xn of p(g
|
corresponds to the conditional probability P (X
xn) of
|
strategy II. More speciﬁcally, in Fig.9 we show the pro-
xII ) =
xn+ki|xn=xII , where xII is deﬁned by p(g
ﬁles
|
h
In even diﬀerent words, the value plotted at
maxxn .
k = 0 is the value xn for which p(g
xn) is maximal, and at
|
the preceeding and succeeding time steps we show the av-
erage over all time series segments which fulﬁll xn = xII
is some precision. These proﬁles diﬀer from the precur-
sors shown before, as we have to expect for an AR(1)-
model: In a perfect AR(1)-process, the precursors equiv-
alent to those in Fig.8 would show a jump larger than g

x1, and with xk = akx0
from k = 0 to k = 1, with x0 =
for k < 0, and xk = akx1 for k > 1. For the same ideal-
ized process, one expects Fig.9 to show curves given by
xk = a|
|xII for all k. Evidently, the wind data show
a qualitatively very similar behavior, whereas, however,
additional correlations are visible.

−

k

B. Testing for predictive power

The ROC-plots for the two prediction strategies are
shown in Fig.11 and 10. As expected, the minimization
of false alarms (strategy II) is here superior, as strategy
I has no predictive power. The latter is consistent with
the observed value a

0.94.

≈

i

s
n
o
i
t
c
d
e
r
p
 
t
c
e
r
r
o
c
 
f
o
 
e
t
a
r

i

s
n
o
i
t
c
d
e
r
p
 
t
c
e
r
r
o
c
 
f
o
 
e
t
a
r

 1

 0.8

 0.6

 0.4

 0.2

 0

 0

 1

 0.8

 0.6

 0.4

 0.2

 0

 0

 0.2

 0.4

 0.6

 0.8

 1

rate of false alarms

FIG. 10:
exploiting p(xn
the rate of false alarms exceeds the hit rate.

(Color online) The ROC plots using strategy I,
X) and maximizing the hit rate. Evidently,
|

In order to compute the ROC plots we use the follow-
ing numerically expensive but theoretically best justiﬁed

g=0.25

g=0.25
g=0.25
g=1

a=0.94, d =1.13

g=0.25
g=0.25

g=0.25
g=1
a=0.94, d =1.13

 0.2

 0.4

 0.6

 0.8

 1

rate of false alarms

FIG. 11: (Color online) The ROC plots for the prediction of
jumps of amplitude larger than g for the wind data. Strategy
II exploits p(X
xn) which minimizes the false alarm rate and
|
performs the better the larger g.

11

g) exceeds some threshold 0

algorithm: In theory, we want to generate an alarm if
the current observation xn lies in an interval I which is
deﬁned by the subset of the R where either p(g
xn) or
|
1. We assume
p(xn|
that both conditional PDFs are smooth in xn.

pc ≤
xn) by searching all
|
< ǫ and to count the
xn −
similar states xj, with
|
relative number of events in this set of states. When
this number exceeds pc, we give the alarm and can see
whether it is a hit or a false alarm.

We can locally approximate p(g
xj|

≤

In order to evaluate p(xn|

g) we ﬁrst create the set of all
states xe which are preceeding an event, and then com-
pute the fraction of these which is ǫ-close to the current
state xn. Since this fraction evidently depends on the
value of ǫ, we should introduce a normalization. How-
ever, in order to create the ROC statistics we just have
to introduce a threshold which runs from 0 to the largest
value thus found. Both schemes can be straightforwardly
generalized to situations where the current state of the
process is deﬁned by a sequence ~s(n,k) of k past mea-
surements (xn
1, xn). E.g., for an
AR(2) model k = 2, whereas in [5] we were using k = 10
for a Markov chain of order 10.

k+2, . . . , , xn

k+1, xn

−

−

−

V. CONCLUSIONS

We have introduced a formulism to construct the PDFs
of extreme increments from a given joint PDF of a
stochastic process. The resulting PDFs were then used
to determine precursors according to two diﬀerent strate-
gies of prediction. Strategy I, the a posteori approach,
maximizes the rate of correct predictions, while strategy
II focuses in the example of the AR(1) process on the
minimization of the rate of false alarms. In general, it
is not clear which of the two strategies lead to a better
predictability and the choice between them is obtained
through comparison of the respective ROC-plots. For
the example of the AR(1) process, we ﬁnd that the min-
imization of the rate of false alarms (strategy II) is the
optimal strategy to make predictions. The application to
the prediction of wind speeds reveals, that also for this
example better results are obtained by predicting accord-
ing to strategy II.

To measure the quality of the prediction we introduced
the slope of the ROC-plot in the vicinity of the origin as a
new summary index, which characterizes particularly the
behavior in the limit of low false-alarm rates. In order to
compare the conclusions drawn from this summary index
with more common summary indices, e.g., the area under
the curve, or the Kolmogorov-Smirnov- index, further
investigations are needed.

In the ROC-plots for the AR(1) process, we observe
that the correlation of the data is inversely proportional
to the quality of the predictions. The ROC-plots for the
wind data, which we assume to be a strongly correlated
AR(1) process with correlation strength a = 0.94, dis-
play also a bad predictability. This eﬀect is due to the

special deﬁnition of the events, we are predicting and due
to the stochastic process, we choose. For a < 0 the like-
lihood that an extreme increment follows the precursor
increases, for a > 0, the likelihood decreases. The asymp-
totic expression for m(xpre, a, d) in Eq. (39) provides us
also with a formally understanding of the a-dependence.
For the examples of the AR(1) process and the pre-
diction of the wind gusts, we observe an increase of pre-
dictability with increasing size of the events. This phe-
nomenon is also reported for diﬀerent kinds of extreme
events and can be discussed by investigating the asymp-
totic behavior of our summary index. The slope in the
vicinity of the origin of the ROC-plot can be interpreted
in two diﬀerent ways. The ﬁrst interpretation decom-
poses the slope into the product of the ratio of the total
probabilities to observe or not to observe extreme events
of a given size and the ratio of likelihoods, that an ex-
treme event follows or follow not after the precursory
structure was observed (see. Eq. 8). The ratio of total
probabilities indicates, that the predictability increases
the more rare an extreme event is. However, in general,
one has to take into account also the inﬂuence of the ratio
of likelihoods. In the case of the AR(1)-process, we ﬁnd
that the analytical structure of both ratios is asymptot-
ically given by squared exponentials. The ratio of total
probabilities increases, while the ratio of the likelihoods
decreases with increasing size of the events. For the pre-
cursors, chosen according to the strategies I and II, we
showed that the inﬂuence of the ratio of total probabil-
ities prevails and hence the slope increases as a squared
exponential.

the

slope

m(xn, a,

A second decomposition of

into the
marginal PDF ρΘ
d) and the marginal failure PDF
¯ρΘ
d) display, that the increases of m(a, d) is due to
m(xn, a,
minimization of the rate of false alarms, i.e., the marginal
failure PDF. This reasoning is independent of the choice
= 0 and hence of the
of the precursor, provided that xpre 6
choice of the prediction strategy. Further investigation
is needed to discuss, if the result found for the AR(1)
process also hold for other classes of extreme events and
other stochastic processes.

e

e

APPENDIX A: TRANSFORMATION OF
EXTREME INCREMENTS INTO EXTREME
VALUES

We show how to relate the results obtained us-
ing the deﬁnition of extreme events as extreme incre-

12

xn ≥

d, as in Eq. (9)) to the case when
ments (xn+1 −
d,
extreme events are deﬁned as extreme values (yn+1 ≥
as in Eq. (9)), for ARMA(p,q) processes. An ARMA(p,q)
model is deﬁned as [4]

Φ(B)xn = θ(B)ξn,

(A1)

where

correspond to white noise and

ξ

{

}

Φ(B) = 1
−
θ(B) = 1 + θ1B + θ2B2 + ... + θqBq,

Φ1B

...

−

−

−

Φ2B2

ΦpBp,

with Bj xn = xn
a time series
x
}
in the time series

{

j. Searching for extreme increments in
−
is equivalent to search for extreme values
, deﬁned through the transformation

y

{

}

yn+1 = xn+1 −

xn.

(A2)

{

x
}

Assuming that

is described by an ARMA(p,q)
process deﬁned by Eq. (A1), and inserting Eq. (A2)
in Eq. (A1), one obtains that
is described by an
ARMA(p,q+1) model with the following transformed co-
eﬃcients

{

}

y

Φ†i = Φi
θ†i = θi −

θ†q+1 = θq

.

θi

1

−

i = 1, 2, ...p ,

i = 1, 2, ...q

,

(A3)

Due to the transformation (A2) the precursory struc-
ture equivalent to the one used in Sec. III is obtained
choosing[15]

ypre =

yj −

x0 = xn.

(A4)

n

j=0
X

With this choice of precursory structure and the corre-
sponding transformation of the process (Eq.(A2)), the
results obtained for extreme increments can be trans-
fered to the case of extreme values.
In particular, for
the case of AR(1) processes (which corresponds to an
ARMA(1,0)) discussed in Sec. III, all results are also
valid for an ARMA(1,1) process with the precursor given
by (A4) and events deﬁned by Eq.(10). E.g., the alarm
strategies consist in this case in raising an alarm when-
ever ypre falls near the precursor values given in Eq. (3).

[1] David D. Jackson, Hypothesis testing and earthquake
prediction, Proc. Natl. Acad. Sci. USA 93 [3772-3775]
(1996).

[2] P. G. Kapiris, J. Polygiannakis, X. Li, X. Yao, K. A.
Eftaxias, Similarities in precursory features in seismic
shocks and epileptic seizures, Europhys. Lett. 69(4) [657-

663](2005).

[3] N. Vandewalle, M. Ausloos, P. Boveroux, et al. How the
ﬁnancial crash of October 1997 could have been predicted
European Physical Journal B 4 (2): [139-141] (1998)
[4] G. E. P. Box, G. M. Jenkins, G. C. Reinsel, Time Series

Analysis, Prentice-Hall, Inc. (1994).

13

[5] H. Kantz, D. Holstein, M. Ragwitz, N. K. Vitanov
Markov chain model for turbulent wind speed data, Phys-
ica A 342 (2004) 315-321.

[6] M. G¨ober, C. A. Wilson, S.F. Milton, D.B. Stephenson,
Fairplay in the veriﬁcation of operational quantitative
precipitation forecasts Journal of Hydrology 288 (2004)
[225-236].

[7] J.M. Bernado, A.F.M.Smith Bayesian Theory Wiley,

New York, 1994

[8] D. M. Green and J. A. Swets Signal detection theory and

psychophysics. Wiley, New York, 1966.

[9] J. P. Egan Signal detection theory and ROC anal-

ysis Academic Press, New York

[10] M. S. Pepe The Statistical Evaluation of Medi-
cal Tests for Classification and Prediction Ox-

ford University Press, 2003

[11] H. Kantz, D. Holstein, M. Ragwitz, N. K. Vitanov, Pro-

ceedings of the EUROMECH 464b (2005).

[12] M. Abramowitz, and I. A. Stegun Handbook of Math-

ematical Functions (Dover, New York, 1972)

[13] A. P. Prudnikov, Yu. A. Brychkov, O. I. Marichev, Inte-
grals andseries Vol. II. Special functions, Gordon
and Breach Science Publ.New York

[14] The wind-speed

data were

recorded

at

research

Risø
Denmark
http://winddata.com

national

research

laboratory

http://www.risoe.dk/vea;

see

the
in
also

[15] We assume x0 = 0, which is the mean value of
assumption is irrelevant for large values of n.

x

. This

{

}

