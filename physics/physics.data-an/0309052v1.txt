3
0
0
2
 
p
e
S
 
0
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
2
5
0
9
0
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

An Object-Oriented Approach to Partial
Wave Analysis

John P. Cummings ∗

Rensselaer Polytechnic Institute

Dennis P. Weygand

Jeﬀerson Laboratory

Abstract

Partial Wave Analysis has traditionally been carried out using a set of tools hand-
crafted for each experiment. By taking an object-oriented approach, the design
presented in this paper attempts to create a more generally useful, and easily ex-
tensible, environment for analyzing many diﬀerent type of data.

Key words: Partial Wave Analysis
PACS: 11.80.Et, 29.85.+c, 21.10.Hw, 89.80.+h

1 Introduction

Partial Wave Analysis, or PWA, is a technique used in hadron spectroscopy to
extract information about the spin-parity and decay properties of resonances
produced in hadronic interactions. Typically, these resonances are produced
at accelerator experiments via a variety of production mechanisms. The reso-
nances produced by these methods also appear in the decay products of other
well known resonances, such as the J/ψ, and can be studied there. Although
the tools we describe here could be used in an investigation that uses any
of these production mechanisms, perhaps with slight modiﬁcation, they have
been used extensively only in peripheral production experiments, and so we
∗ Corresponding author. Address: Department of Physics, Rensselaer Polytechnic
Institute, 110 8th Street, Troy, NY, 12180-3590 Phone: (518) 276-2542

Email addresses: cummij@rpi.edu (John P. Cummings), weygand@jlab.org

(Dennis P. Weygand).

Preprint submitted to Elsevier Science

9 September 2003

will use this type of production as an illustrative example in this paper. Cur-
rently, new results are being obtained studying baryon resonances produced
in s-channel γp interactions.

The general idea is to parameterize the intensity distribution in terms of vari-
ables that have physical meaning when interpreted as properties of intermedi-
ate states in a particular reaction. In principle, any complete set of functions
which span the appropriate space can be used. Although many parameteriza-
tions are possible, for instance an (almost) purely mathematical description in
terms of the moments, we choose an expansion in terms of intermediate res-
onances and their decays. This has at least two advantages. Firstly, it allows
us to take advantage of physics such as conservation laws to limit the number
of terms we must include in our expansion to get a good description of the
intensity distribution. Secondly, it allows a more direct interpretation of our
results. A moment analysis, for instance, requires a complicated mapping from
moments to physical states to understand the results in all but the simplest
of cases.

The formalism we have used in implementing our system is based on the papers
of Chung [1] and Chung and Trueman. [2] The intensity distribution is written
as a sum of amplitudes, squared appropriately to account for interference:

I(τ ) =

αψβ (τ )

α
X






(cid:12)
(cid:12)
Xβ
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

.






(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(1)

The variable τ represents the set of variables necessary to deﬁne a conﬁgura-
tion of the ﬁnal state being investigated. It typically includes the angles of the
decay products in various reference frames, masses of two body sub-systems,
etc. The subscripts α and β are the parameters that describe the partial wave
decomposition we are using, α specifying properties of the diﬀerent interme-
diate states that do not interfere, such as the spin states of the incoming or
outgoing particles in the detector. The subscript β, on the other hand, repre-
sents the properties whose diﬀering values do interfere, for instance the spin
states of broad resonances produced as intermediate states in a sequential
decay.

In a peripheral production experiment, the amplitudes in the expansion can
be drawn as shown in Fig. 1. Guided by this picture, the amplitude ψαβ (τ ) is
factored into two parts: V , the amplitude to produce the state X, and A, the
amplitude for the state X to decay into the ﬁnal state observed.

These amplitudes are written in the reﬂectivity basis [2], which takes into
account parity conservation in the production process by writing the ampli-
tudes in terms of eigenstates of reﬂection through the production plane. The

2

m 1

m 2
.
.
.

m

n

π

X

exR

N

N

Fig. 1. Diagram representing the amplitude ψαβ (τ ). The intermediate state X is
produced by the exchange of a Reggion Rex between the π beam and the nucleon
target.

reﬂectivity of the amplitude, denoted ǫ, is deﬁned so that in the case of a
pion beam it coincides with the naturality of the exchanged Regge trajectory.
Waves of diﬀering ǫ do not interfere. Also, amplitudes with diﬀerent relative
spin conﬁgurations for the incoming and outgoing baryon will not interfere.
The spin conﬁguration of the amplitudes is labeled by k, and the number of
allowed values, sometimes referred to as the rank of the ﬁt, is typically 2 for
a spin 1

2 recoil baryon.

In the reﬂectivity basis our sum over amplitudes splits into four non-interfering
sets of fully interfering amplitudes, or α = {ǫ, k}. While both the production
and decay amplitudes depend on ǫ, the decay amplitude does not depend on
k, since the decay amplitude for a particular state X cannot depend on what
the proton spin did during the production process. Similarly, the production
amplitude does not depend on τ , the conﬁguration of the ﬁnal state the X
decays into.

The intensity distribution now becomes

I (τ ) =

ǫVkβ

ǫAβ (τ )

(2)

The decay amplitudes ǫAkβ (τ ) can be calculated for each event. By varying

Xǫ,k






(cid:12)
(cid:12)
Xβ
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

.






(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

3

the unknown production amplitudes ǫVkβ the predicted intensity distribution
above is matched as closely as possible by the observed intensity as a func-
tion of all kinematic variables. This is done through an extended maximum
likelihood ﬁt. During the ﬁtting process, the ﬁnite acceptance of the detector
is taken into account on a term by term basis, i.e., each term contains a pair
of of decay amplitudes with a unique shape in τ , and the acceptance for each
term is determined separately.

The likelihood function is deﬁned as a product of probabilities,

L =

¯nn
n!

(cid:20)

e−¯n

n

I(τi)

(τ )η(τ )dτ #

(cid:21)

Yi "

R

(3)





(5)

(6)

The term outside the product is the Poisson probability of observing n events
and reﬂects the fact that we use the extended maximum likelihood method.
The integral in the denominator of the summed term contains the acceptance
η(τ ) and is referred to as the accepted normalization integral.

The function which is actually maximized in the likelihood ﬁt is

ln L =

ln

ǫVkβ

ǫV ∗
kβ′

ǫAβ(τi)ǫA∗

β′(τi)

− n

ǫVkβ

ǫV ∗
kβ′

ǫΨx

ββ′

(4)






Xk,ǫ,β,β′


n

Xi





Xk,ǫ,β,β′

The ﬁrst sum is over data events, where the term being summed over is simply
the intensity I(τi) for each event. The second term contains the accepted
normalization integrals ǫΨx
ββ′ where the superscript x denotes accepted. This
integral is evaluated numerically:

ǫΨx

ββ′ =

ǫAβ(τi)ǫA∗

β′(τi).

1
Mx

Mx

i
X

The sum is over an accepted Monte-Carlo data set of Mx events. A similar
integral is calculated for the raw Monte-Carlo data set, to be used in the
calculation of observables. For instance, the number of acceptance corrected
events the ﬁt predicts is

N =

n
ηx

Xǫkββ′

ǫVkβ

ǫV ∗
kβ′

ǫΨββ′,

where ǫΨββ′ is the raw normalization integral. By varying the range of the
values of {ǫkββ′} included in the sum, the number of events due to diﬀerent
combinations of amplitudes can be determined.

4

(X) J, m, W

(x ), s ,
1
1

λ

1

l , p

(x ), s , λ

2

2

2

Fig. 2. Decay of the resonance X into x1 and x2.

1.1 Decay Amplitudes

Calculation of decay amplitudes for the resonance X is done recursively using
the isobar model, regarding the n-body ﬁnal state as the result of a series of
sequential decays (usually two body) through intermediate states known as
the isobars. The amplitude for X to decay into the ﬁnal state is then simply
the amplitude for X to decay into its immediate children times the amplitude
for each of its children to decay.

The initial decay of the X into its children is evaluated in the Gottfried-
Jackson frame. This frame is a rest frame of the resonance X with the z axis
in the direction of the beam and the y axis perpendicular to the production
plane. The quantities used in deﬁning the amplitude are shown schematically
in Fig. 2

The state X of mass W has spin J with z projection m. It decays into children
xi with spin σi and helicity λi. These children have a breakup momentum ~p
and relative orbital angular momentum ℓ. The decay amplitude can then be
written down [3]

AX = ˜ℓ

DJ∗

Xλ

mλ(Ω)(ℓ0sλ|Jλ)(s1λ1s2 − λ2|sλ)Fℓ(p)aℓsAx1Ax2

(7)

where λ = λ1 − λ2 and ~s = ~s1 + ~s2, i.e. , ~s is the total spin of the two children
and λ is the component of ~s in the direction deﬁned by xi’s momentum. The
Axi are the decay amplitudes of each child.

1
The ˜ℓ = (2ℓ+1)
2 factor, along with the two Clebsch-Gordon coeﬃcients, come
from the fact that we are using helicity states and must relate the helicity

5

(x) s,   , wλ

σ ν
(x ),    ,
1

1

1

l

, p

(x ),    ,σ

ν

2

2

2

Fig. 3. Decay of a child x into x1 and x2.

coupling constant to the ℓs-coupling constant, aℓs, we want to ﬁnd through
the partial wave expansion.[3]

Rotational properties of the helicity states lead to the introduction of D-
function DJ∗
mλ(Ω) where Ω = (θ, φ, 0) are the Euler angles of x1 in the Gottfried-
Jackson frame. The choice of the third angle γ deﬁnes the phase convention.
We choose γ = 0, which is diﬀerent from that of Jacob and Wick [4], who
choose γ = −φ.

Fℓ(p) is an angular momentum barrier factor added to give the amplitude
the correct behavior near threshold. We used the Blatt-Weisskopf centrifugal-
barrier functions as given by von Hippel and Quigg. [5]

Finally, aℓs is the ℓs coupling constant which contains the dynamics of the
decay. This factor is absorbed into the production amplitude for this wave,
which is then determined through the ﬁt. The coupling constant aℓs is in
general a function of the mass W of the state X, and this is usually handled
in the ﬁts by performing them in bins of W which are narrow enough to assume
the aℓs constant over the width of the bin.

The decay amplitudes of the children Axi, and recursively their children, etc.,
are calculated in the helicity frame of the child that is decaying. For instance,
consider one of the xi above, but now we call it simply x since it has become
the parent particle of a new decay, as in Fig. 3

Here the particle decaying, x has mass w, spin s, and helicity λ. Its decay prod-
ucts xi have spins σi and helicities νi, with relative orbital angular momentum
ℓ and breakup momentum p.

The form of the amplitude for this piece of the decay is very similar to what

6

was written above

Ax = ˜ℓ

Ds∗

Xλ

λν(Ω)(ℓ0σν|sν)(σ1ν1σ2 − ν2|sν)Fℓ(p)∆x(w)Ax1Ax2

(8)

where again ν = ν1 − ν2 and ~σ = ~σ1 + ~σ2

The pieces of this decay that look similar to the initial decay in the Gottfried–
Jackson frame do so because they come from the same place. The same
Clebsch–Gordon coeﬃcients and ˜ℓ factor show up from the relationship of
the helicity to ℓs states, the D–function from the rotational properties of the
states, and the angular momentum barrier factor suppresses high-ℓ decays
near threshold where the breakup momentum is small.

The only diﬀerence, in fact, is the appearance of ∆x(w) in place of the coupling
constant aℓs from the initial decay. In the decays of the isobars it is usually
assumed that the dynamics of the decay, which depend on the isobar mass
w, are known and put in explicitly. Often this is done as a simple relativis-
tic Breit-Wigner, although it is sometimes necessary to use a more complex
parameterization, such as coupled-channel Breit-Wigners [6] or a K–matrix
parameterization [7].

Total decay amplitudes are made up as a product of these intermediate decays.
In order to parameterize the spin-density matrix, which is determined by the
ﬁt, in the simplest way, it turns out to be advantageous to transform the states
into the reﬂectivity basis. The reﬂectivity basis is deﬁned by eigenstates of
reﬂection in the production plane, the details of the transformation can be
found in Chung and Trueman. [2]

After determining the design criteria from the considerations in the last sec-
tion, we choose tools to assist in building the system to meet these criteria.

2 Choice of Tools

2.1 The choice of language

Choosing a language was not as diﬃcult as one might hope: the paucity of
object-oriented languages having the support of adequate development tools
led us almost immediately to C++. Java, Eiﬀel and Sather were brieﬂy con-
sidered. Java was decided to still be too slow for numerically intensive calcu-
lations. Eiﬀel and it’s relative Sather are interesting languages that address

7

noweb file

notangle

noweave

.c file

.tex file

Fig. 4. A noweb source ﬁle is pre-processed with either notangle or noweave to
produce either source code or documentation, respectively.

some of the deﬁciencies of C++, but the lack or weakness of development
tools such as a symbolic debugger led us to pass them up.

C++ is a popular language which now has an ANSI/ISO standard. There
are numerous compilers, debuggers, CASE tools and class libraries available.
In particular, we choose the GNU compiler suite and development tools. The
GNU C++ compiler is very close to the ANSI standard, and since most of
our development and analysis is done on a Linux/GNU platform it is also the
native compiler on these systems. Using C++ also gives us the advantages of
an object-oriented language while also providing convenient access to useful
libraries written in C or FORTRAN. For instance the engine of our ﬁtting
program is the CERNLIB package MINUIT.

Attempting to deliver a “turnkey” system that, given a physics data set in a
standard format, would allow users to perform an analysis implies a relatively
sophisticated control language for our tools. Yacc and it’s cousin Lex allowed
easy development of a ﬂexible grammar for driving both the decay amplitude
calculator and the ﬁtter. These development tools interface very well with
C++ and are standard on any *NIX system.

2.2 The choice of documentation system

In our experience, up to date documentation for software written by physicist
is hard to ﬁnd–our own code has not been an exception. We take the view that
self-documenting code is a realizable goal as long as the audience is program-

8

mers. For this project we were striving to reach a much broader audience, and
hence recognized the need for something else. We decided to use noweb [8], a
simple literate programming package.

Literate programming [9] was ﬁrst proposed by Donald Knuth, which he im-
plemented in the form of web. Essentially code and documentation are written
interspersed in the same ﬁles, making it easier to document the code as it is
written, and encourages the documentation to keep pace with program devel-
opment. The pre-processors which make up the web system then weave the
web ﬁle into documentation, usually in latex format, or tangle the web ﬁle
into source code. While some literate programming tools are language spe-
ciﬁc, noweb allows any programming language to be embedded into its ﬁles,
allowing symmetric treatment of C++, yacc, lex, etc.

3 The Design

3.1 The architecture of the suite

The design of the tools is strongly inﬂuenced by the mathematics of the ﬁt-
ting, some of which was described above. In general, we felt that a set of
independent programs each of which which work with the output of the oth-
ers is the best design. We clearly need a program to perform the minimization
of the − ln(L) function of equation 4. The normalization integral, equation 5,
is calculated prior to ﬁt and requires a program of its own. We must have a
program to calculate decay amplitudes as a function of τ . This implies three
basic programs are required for an analysis. During the course of testing and
use, however, several additional utility programs were written. Some of these
turned out to be generally useful and will also be brieﬂy described in this
report.

A picture of the entire procedure is shown in Fig. 5. The decay amplitude
calculator gamp computes the decay amplitude given an event and a particular
“wave”: an assumed spin-parity for the whole system, any isobars with their
spin-parities, and a orbital angular momentum and total spin for each two
body decay. The integrator int, used to compute normalization integrals used
in the ﬁtting process, must read amplitudes calculated by gamp and integrate
over the appropriate space. The production amplitudes are found by fit using
a maximum likelihood ﬁt.

9

data

acc
mc

raw
mc

data
amps

gamp

acc
mc amps

int

raw
mc amps

wave
spec

fit
spec

acc
int

raw
int

fit

fit
log

Fig. 5. Pictorial view of the entire PWA procedure. The three circles represent the
three major computational steps, acting on the rectangular data ﬁles.

3.2 The architecture of gamp

A typical invocation of the program to generate amplitudes might look like:

zcat data.gamp.gz | gamp 1++0+rho pi.key > 1++0+rho pi.amps

Notice that gamp reads and writes from standard input and output, and that
it’s single required argument is the name of a keyﬁle, a program specifying
the amplitude to be calculated for each event read from it’s input. gamp uses
an awk-like processing model: the program in the keyﬁle is run repeatedly on
each event as it is read in. The language of this program is described below.

3.2.1 Event format

The format of the events read from standard input is quite simple. The events
are expected to be in ASCII format. Each event begins with an integer spec-
ifying the number of particles which will follow. Particles are given by their
GEANT id (integer), their charge (integer), and the four components of their
four momentum, px, py, pz, E (ﬂoats). The ﬁrst particle in each event is al-
ways the beam. Presently, the target is not speciﬁed and is assumed to be
a proton (this is likely to change in the near future, and the target will be
required). Following the beam come all ﬁnal state particles from the system
being analyzed, in arbitrary order, and then the next event, etc.

For example, the top of a ﬁle containing events from the reaction π−p →
pηπ+π−π− might look like

5

10

0.0003765 -0.0573188 18.3642158 18.3648357
2.3157212
0.0814732
3.9801270
0.2404482
3.3670651
0.3348054
8.5494852

9 -1
0.4102049
9 -1
0.3578656
9 -1
0.0241324
1
8
17 0 -0.4792622 -0.4030199
5
9 -1 -0.0850012 -0.0702078 18.1182842 18.1191577
1.6662241
9 -1 -0.4165566
...

2.2733631
3.9542443
3.3473827
8.5089292

1.5984030

0.1685560

Notice in this example, from BNL E852, the reaction is assumed to be a t-
channel process. Therefore the system being studied here is ηπππ and the
ﬁnal state proton does not appear in the input. This is optional, the keyﬁle
specifying the amplitude to calculate will refer to particles by name, unmen-
tioned particles are simply ignored. Thus specifying the proton in the event
and ignoring it in the keyﬁle will not create an error. If an s-channel ampli-
tude is being calculated, all ﬁnal state particles would be required in the event
speciﬁcation.

Since gamp reads events from standard input, these ASCII ﬁles can be stored
compressed and then zcatted into a pipe. Or better still, never put to disk,
but created on the ﬂy from the (presumably) more eﬃcient binary data format
of the particular experiment.

3.2.2 The keyﬁle language

The keyﬁle language is fairly simple. The ﬁle is free-format: spaces, tabs, and
newlines may be used to improve readability. Statements are terminated by
semi-colons.

A very simple keyﬁle might look like this:

# debug = 1;
channel = t;
mode = binary;

J = 2 P = +1 M = 2 {
pi+
pi-
l=4

}
;

In this ﬁle we are specifying the decay of a state with J P = 1+ and m = 1
into two pions with two units of angular momentum between them, i.e., an D

11

wave.

A # comments the remainder of the line. Here the debug = 1;, which would
turn on copious debugging information, is commented out. The amplitude
being calculated is for a t-channel process. The only allowed values for channel
are s and t. Amplitudes output can be in either ASCII (default) or binary
format, and can be selected by setting mode to either ascii or binary. Finally
comes the speciﬁcation of the wave itself. A wave is a set of quantum numbers–
J, P and M–followed by a decay. Note: all angular momenta are in units of
¯h/2, i.e., multiplied by 2. This allows particles with half-integer spin to be
represented as integers in the input. In the example above, for instance, the
state being calculated has J P = 1+.

The decay is represented by a pair of child particles followed by the orbital
angular momentum between them, and optionally, their total spin. If the total
spin is not ambiguous, it may be omitted. Only when both particles have non-
zero spin is it necessary to explicitly give the spin, and it must follow the
orbital angular momentum. The orbital angular momentum and spin may be
labeled as above or may be unadorned integers. The ﬁrst integer is always the
orbital angular momentum and the second, if present is the total spin. The
decay speciﬁcation is delimited by the pair of curly brackets. Although it may
be spread out over many lines, the entire wave is a single statement, so don’t
forget the ; at the end.

3.2.3 Combining Waves

Waves may be added to eachother, and this gives us a way to handle sym-
metrizing amplitudes when there are identical particles. If the ﬁnal state con-
tains identical particles, they are identiﬁed in the wave speciﬁcation as if the
identical particles were read into a (1-indexed) array, i.e., pi+[1] is the ﬁrst
positively charged pion read for each event, pi+[2] is the second etc. So to
form a Bose-symmetrized amplitude use something similar to the following:

# debug = 1;
channel = t;
mode = binary;

0.707 * (
J = 4 P = +1 M = 0 {

pi0[1]
pi0[2]
l=4

}
+ J = 4 P = +1 M = 0 {

12

In this case the second wave look the same with the exception of the ﬂipped
indices on the pi0’s: we have exchanged the two identical particles.

Any unstable particle may be followed by a similar decay speciﬁcation, recur-
sively. For example, gamp would not balk at a decay chain as follows:

pi0[2]
pi0[1]
l=4

} )
;

3.2.4 Sequential Decays

# debug = 1;
channel = t;
mode = binary;

J = 2 P = +1 M = 0 {

a2(1320) {

rho(770) {

pi+[1]
pi-[1]
l = 2

}
rho(770) {

}
pi0
l = 4

pi+[2]
pi-[2]
l = 2

}
l = 2
s = 2

} ;

This keyﬁle describes a J P = 1+ particle in an m = 0 state decaying into a2ρ
via a P wave. Notice here that we have included a speciﬁcation of the total
spin of the a2ρ system s = 1, as it is not unique. The a2(1320) decays further
in this example into ρπ in a D wave, and ﬁnally each ρ decays into ππ with
ℓ = 1.

13

3.2.5 Mass Dependencies

Currently, gamp also understands a few diﬀerent mass dependencies for iso-
bars: ﬂat, Breit-Wigner, and two solutions for (ππ)S. Others will be added by
popular demand. The alternate mass dependencies are given by appending,
for instance, the statement massdep = flat after the decay, as in

# debug = 1;
channel = t;
mode = binary;

0.707 * (
J = 4 P = +1 M = 0 {

pi0[1]
pi0[2]
l=4

} massdep=flat
+ J = 4 P = +1 M = 0 {
pi0[2]
pi0[1]
l=4

} massdep=flat )
;

The other appropriate keywords are bw for Breit-Wigner (the default), amp for
Au-Morgan-Pennington (ππ)S parameterization (M-solution) [10], and amp ves
for VES modiﬁcation [11,12] to above.

3.2.6 Helicity Sums

The default action when gamp sees a particle with spin is to sum over the
allowed helicities. This is in general the correct action as particles with spin
are usually intermediate states which interfere and must be summed over at
the amplitude level. Final state particles are typically spinless with the notable
exceptions of protons and neutrons. If these appear in the wave speciﬁcation
the amplitude must not be summed over and the helicity or h keyword
allows for this.

mode=binary;
channel=s;

0.94868 * (
J=3 P=-1 M=1 {

delta(1232)[1] {

p+[1]

h=-1

14

pi+[1]
2

}
pi-[1]
4

}
+ 0.33333 * (
J=3 P=-1 M=1 {

delta(1232)[1] {

h=-1

p+[1]
pi-[1]
2

}
pi+[1]
4

}
));

This keyﬁle describes the decay of a J P = 3
baryon resonance into ∆π in a
2
D wave. The two charge possibilities for the ∆’s are combined with the correct
Clebsch-Gordon coeﬃcients to produce an isospin 1
2 state. This wave is being
calculated for the negative helicity of the ﬁnal state proton; presumably the
positive helicity would be calculated also and added incoherently at ﬁt time.

−

3.3 The architecture of int

The normalization integrals, whose values are needed at the time of the ﬁt,
are calculated using int. Recall that the integrals needed look like

Ψαα′ =

∗
α(τ )ψα′(τ )η(τ )dτ =

ψ

∗
α(τi)ψα′(τi)

ψ

(9)

Z

1
M

i
X

where dτ is an element of phase space, τ is then a point in phase space,
ψα(τ ) is the decay amplitude for the wave α as a function of the kinematic
variables deﬁning phase space τ . This is an accepted integral, used at ﬁtting
time to perform the acceptance correction, and hence the appearance of the
acceptance η(τ ). Unfortunately, the acceptance of a detector is rarely known
analytically, and so this integral is always done numerically. This is shown in
the last term as a sum over Monte-Carlo generated events. The generation is
done uniformly in phase space, i. e. ﬂat in τ . These events are then passed
through a detector simulation program, and subjected to the same analysis
and cuts. Using only these M remaining events in the sum above take into
account the η(τ ) factor in the integral. Similar integrals are needed post-ﬁt

15

to calculate observables from the ﬁt results, as descibed by equation 6. These
“raw” integrals diﬀer from the above “accepted” integrals only by their lack of
the acceptance term η(τ ) in the raw integrals. Numerically this corresponds to
performing the sum over the entire generated phase space Monte-Carlo event
sample.

int assumes all decay amplitudes ψα(τi) are available on disk and a single ﬁle
holds all amplitudes for a single wave α for each event in a particular data set.
All the amplitude ﬁles should correspond to the same data set. The integrals
Ψαα′ are kept internally as matrices. Individual integrals may be accessed by
either integer indices of the matrix, or by a string representing the name of
the wave–a human readable form of α.

3.4 The architecture of ﬁt

In the course of an analysis many ﬁts need to be done. It is important to try
diﬀerent sets of waves in many combinations: two waves may not be important
individually, but their interference may be. In addition, once the best set of
waves is determined, the stability of the ﬁt can be studied by repeating the
ﬁt with varying starting values for the parameters. A completed analysis will
often require hundreds of ﬁts.

The likelihood function maximized varies depending on the type of process be-
ing modeled. A s-channel likelihood function diﬀers from a t-channel function,
and a photon beam requires a diﬀerent function from a pion beam. Diﬀerent
assumptions may also be tested with regard to the “rank” of the ﬁt, relating
to whether or not the amplitudes have diﬀering dependence on spin degrees
of freedom.

The lack of a standard function led to the idea of using an interpreter for the
likelihood function. The input ﬁle for the ﬁt contains the speciﬁcation of the
likelihood function. A simple example ﬁle looks like:

damp 0m0.amps;
damp 1m0.amps;
damp 1p0.amps;
damp 2m0.amps;
damp 2p0.amps;

realpar p0m0;
par p1m0;
par p1p0;
par p2m0;
par p2p0;

16

integral normInt(normInt.new);

event_loop:

fcn = fcn - log(

absSq(p0m0*0m0.amps + p1m0*1m0.amps
+ p1p0*1p0.amps + p2m0*2m0.amps
+ p2p0*2p0.amps)

);

normalization:

fcn = fcn + nevents * (

p0m0*conj(p0m0)*normInt[0m0.amps , 0m0.amps] +
p1m0*conj(p1m0)*normInt[1m0.amps , 1m0.amps] +
p1p0*conj(p1p0)*normInt[1p0.amps , 1p0.amps] +
p2m0*conj(p2m0)*normInt[2m0.amps , 2m0.amps] +
p2p0*conj(p2p0)*normInt[2p0.amps , 2p0.amps] +

2.0*real( p0m0*conj(p1m0)*normInt[0m0.amps , 1m0.amps] +

p0m0*conj(p1p0)*normInt[0m0.amps , 1p0.amps] +
p0m0*conj(p2m0)*normInt[0m0.amps , 2m0.amps] +
p0m0*conj(p2p0)*normInt[0m0.amps , 2p0.amps]) +

2.0*real( p1m0*conj(p0m0)*normInt[1m0.amps , 0m0.amps] +

p1m0*conj(p1p0)*normInt[1m0.amps , 1p0.amps] +
p1m0*conj(p2m0)*normInt[1m0.amps , 2m0.amps] +
p1m0*conj(p2p0)*normInt[1m0.amps , 2p0.amps]) +

2.0*real( p1p0*conj(p0m0)*normInt[1p0.amps , 0m0.amps] +

p1p0*conj(p1m0)*normInt[1p0.amps , 1m0.amps] +
p1p0*conj(p2m0)*normInt[1p0.amps , 2m0.amps] +
p1p0*conj(p2p0)*normInt[1p0.amps , 2p0.amps]) +

2.0*real( p2m0*conj(p0m0)*normInt[2m0.amps , 0m0.amps] +

p2m0*conj(p1m0)*normInt[2m0.amps , 1m0.amps] +
p2m0*conj(p1p0)*normInt[2m0.amps , 1p0.amps] +
p2m0*conj(p2p0)*normInt[2m0.amps , 2p0.amps]) +

2.0*real( p2p0*conj(p0m0)*normInt[2p0.amps , 0m0.amps] +

p2p0*conj(p1m0)*normInt[2p0.amps , 1m0.amps] +
p2p0*conj(p1p0)*normInt[2p0.amps , 1p0.amps] +
p2p0*conj(p2m0)*normInt[2p0.amps , 2m0.amps])

);

This ﬁle shows all the key elements of the ﬁt input ﬁle grammar. The state-

17

ments at the top of the ﬁle declare some variables. damp’s are decay amplitudes,
the string following is both the ﬁlename where the amplitudes for a particular
wave are found and the name of the variable that can be used in the function
to refer to this wave. par’s are the ﬁt parameters, assumed to be complex
unless realpar is speciﬁed. Finally, integral normInt(normInt.new); de-
clares normInt to be a normalization integral found in the ﬁle normInt.new.
The executable statements in the second half of the ﬁle are in two sections.
The event loop section is executed for every event in the dataset, while the
normalization section is done only once, after the loop over events. fcn is a
reserved word that is the value to be minimized by varying the par’s. An astute
reader might recognize fcn as a relic of the CERNLIB minuit minimizer,
which is in fact the package used to perform the actual minimization. Notice
also that the normalization integrals are indexed by the name of the wave, or
more precisely, the name of the ﬁle that contained the decay amplitudes for
that wave at the time of integration.

The interpreter for this ﬁle is based heavily on hoc by Kernighan and Pike [13].
Brieﬂy, the ﬁle is parsed and statements are stored as instructions to a virtual
stack machine which is run at ﬁt time. Decay amplitudes and parameters are
stored in a symbol table and their values are updated appropriately: every
event for the amplitudes and every iteration of the ﬁtter for the parameters.
The code generated for a part of the above event loop, p0m0*0m0.amps +
p1m0*1m0.amps is shown in Table 1.

Most instructions are simply pointers to a corresponding function, therefore
execution of the program means simply marching down this list of function
pointers, executing each one as you go. Any “instruction” which is not a func-
tion pointer should be skipped by the true instruction before it. For instance,
the initial varpush in the program shown above pushes the next “instruction”,
the variable name p0m0, onto the stack and increments the program counter
past the next instruction to the eval that follows it. The eval function pops
the top value oﬀ the stack, looks it up in the symbol table, and pushes its value
back onto the stack. Therefore the ﬁrst three instructions have the eﬀect of
pushing the value of p0m0 onto the stack. The next three instructions similarly
push the value of 0m0.amps onto the stack. The stack now contains these two
complex numbers, and the mul instruction pops both oﬀ the stack, multiplies
them, and pushes the result back on the stack.

This produces an extremely ﬂexible ﬁtting program, with two possible draw-
backs. The ﬁrst drawback is the complexity of the input ﬁle. Even the simple
example given above generates many terms and a realistic ﬁt input using tens
of waves could easily require pages of input containing many similar symbols
such as ﬁle names that diﬀer by one character. To reduce the opportunity for
errors to arise, these input ﬁles are often written by a separate program. We
use a prolog program to generate the fit input ﬁles. This program reads the

18

varpush

p0m0

eval

varpush

0m0.amps

eval

mul

varpush

p1m0

eval

varpush

1m0.amps

eval

mul

add

Table 1
Instructions generated by code fragment explained in text.

states we wish to include in the ﬁt, produces a list of production amplitudes
to be used as ﬁt parameters, and applies any known constraints such as par-
ity conservation to link any amplitudes it can. The resulting list is formatted
appropriately for fit to read and output to a ﬁle.

The second drawback of an interpreted system is performance. While very
ﬂexible, an interpreted system is inherently slower. In recent work where this
has become an issue, the function written by the prolog program was mod-
iﬁed to allow direct compilation by the C++ compiler and was used directly
with minuit for ﬁtting.

3.5 Description of libpp classes

We have gathered into libpp a collection of classes that were of general use in
particle physics, beyond the specialized topic of partial wave analysis. This sec-
tion is not an attempt to fully document this library, but rather just a sampling
of a few of the objects available to give the ﬂavor of what is found in libpp.a.
The complete documentation can be obtained from the source using notangle,
or preformatted from the web at http://ignatz.phys.rpi.edu/~cummij/

19

Three- and four-vectors are deﬁned as threeVec and fourVec, with most
common operations available as member functions. The implementation of
fourVec’s used contains a threeVec and a double, rather than deriving both
from a base vector class. While the implementation details are not assumed
in the interface to the class, one can see reﬂections of the implementation in
some of the methods such as the constructors (fourVec(double t, threeVec
space), for instance)

A particle data table class particleDataTable is a simple database contain-
ing information about known particle states from the Particle Data Groups
Review of Particle Properties. It is essentially a list of particleData objects.
It is initialized to a default set of values from the 2002 edition of the Review of
Particle Properties, but can be modiﬁed by reading a local ﬁle containing “cus-
tom” particles. Lookup in the table is implemented as a linear search, which
is not a performance issue for the typical size tables involved. The particle
class represents a physical instance of a particle, i. e. a particleData with
an associated fourVec. The event class contains the beam, target, and a list
of ﬁnal state particles.

Matrices are implemented as template classes to allow both the matrices of
complex numbers used in partial wave analysis and real matrices such as
Lorentz transformations to share the same code. Lorentz transformations
are derived from the template class matrix<> and can be used to boost
fourVec’s, particle’s or event’s. A particularly useful constructor makes
a lorentzTransform from a fourVec, deﬁning the transformation to boost
into the rest frame of the fourVec, treating it as a four-momentum. This
allows convenient constructs such as:

event e;
// read the event from standard input
std::cin >> e;
lorentzTransform L(e.beam().get4P()+e.target().get4P());
// put the event into the beam + target rest frame
e = L*e;

which puts the entire event into the center of mass system.

4 Example analysis

As a demonstration of the ﬂexibility of this system, lets consider the analysis
of data from Jeﬀerson Laboratory looking for “missing baryon” states. The
experiment collected data from the reaction γp → pπ+π−, with a γ beam
energy of 0.5-2.6 GeV/c. Data were selected which reconstructed all three

20

ﬁnal state particles, leaving a data sample of 750k events for partial wave
analysis. While a complete description of this analysis is beyond the scope of
this paper, A brief description of the analysis should illustrate the pwa2000
well.

This is a particularly diﬃcult region to partial wave analyze, due to the fact
that the dynamics is expected to change drastically within the range of the
analysis. For instance, for beam energies below ρ threshold the data are in
the resonance region and will probably be well described by formation of
isobars in the s-channel. Above ρ threshold the center of mass energy is leaving
the resonance region and the availability of the ρ should result in a large
contribution from diﬀractive (t-channel) ρ production. The transition between
these two kinematic extremes will be diﬃcult to map, and will require many
ﬁts trying not only many diﬀerent sets of waves but also diﬀerent likelihood
functions as we make diﬀerent assumptions about how to describe t-channel
processes in a truncated s-channel basis. It is for exactly this situation that we
designed a ﬂexible analysis system; particularly, in this case, the interpreted
ﬁtting program: many diﬀerent function may be tried easily.

Initial ﬁts, including only waves corresponding to isobar production in the
s-channel, were performed. The production amplitudes obtained from this ﬁt
are then used to calculate an acceptance corrected total cross section. The are
plotted in Fig. 6 as open circles. The points plotted as inverted triangles are
from an earlier bubble chamber experiment at DESY [14]. The discrepancy
above 1.9 GeV/c2 is due to the fact that we are not using a suﬃcient set of
waves to describe our data. It is easy to try including waves corresponding
to t-channel production of ρ’s: gamp generates the amplitudes with a small
change to the keyﬁle, and they can be included into the ﬁt either coherently or
incoherently. The result of such a ﬁt, with an incoherent t-channel ρ production
wave is plotted in Fig. 6 as ﬁlled circles. We can see the agreement with the
DESY experiment is much better, and the statistical errors, even of this partial
data set, are much smaller.

We can verify the ﬁt describes the data better by using the ﬁtted production
amplitudes and the calculated decay amplitudes to weight events (generated
uniformly in phase space) that passed through the detector simulation. This
gives us a Monte-Carlo data set distributed in the kinematic variables as the ﬁt
found. This Monte-Carlo data set can be compared to the real data to measure
the quality of the ﬁt and give clues about what waves need to be added. For
example, Fig. 7 shows the cos(θcm) distributions for the data (solid circles),
and the Monte-Carlo “data” sets generated from the ﬁts mentioned above:
s-channel waves only and s-channel with incoherent t-channel ρ production.
These distributions are for 2.06662 < M(pπ+π−) < 2.08378, where the total
cross section is beginning to show discrepancy. The ﬁt using only s-channel
waves (open squares) cannot create an asymmetry large enough to describe

21

Fig. 6. Results for the total cross section calculated from the partial wave analy-
sis. Inverted triangles: Aachen-Berlin-Bonn-Hamburg-Heidelberg-M¨unchen collabo-
ration. Open circles: PWA using s-channel waves only. Filled Circles: PWA using
s-channel waves and t-channel ρ production.

the backward (in the center of mass system) proton peak; however adding a
simple, incoherent t-channel ρ production wave (open circle) improves the the
description of this kinematic variable quite a bit.

5 Conclusions and Future Directions

The pwa2000 is a ﬂexible suite of tools developed for partial wave analysis
of particle physics data. It has been used to analyze peripheral meson pro-
duction in a pion beam [15], peripheral meson production in a photon beam,
and s-channel baryon resonance production in a photon beam [16]. The ob-
ject deﬁned in the library have been suﬃcient for all these analyses, the usual
extent of the modiﬁcation necessary are to the input ﬁle parser to handle in-
put of information not required in previous analysis. For instance, the library
implements the mass dependence of an isobar decay using an abstract base
class massDep. As additional parameterizations are added for isobar decays,
we add a derived class of massDep that implements the particular parameter-
ization, add an appropriate keyword to the keyﬁle language and modify the
yacc parser to instantiate the new derived class when it sees the new keyword.

22

Fig. 7. Comparison of cos(θcm) distributions of the proton for the data (solid
circles), and the predictions of a ﬁt using only s-channel waves (open squares), and
a ﬁt using s-channel waves with incoherent t-channel ρ production (open circles).

The strategy of separating the intelligence of the program from the compu-
tation proved fruitful. By using a separate program to generate the input ﬁle
for the ﬁtting program, we were able to choose a language well suited to each
particular task. prolog, a language known for its artiﬁcial intelligence appli-
cations, was used to apply the logical constraints to the likelihood function
such as physical conservation laws. C++ routines were then driven by the
input ﬁle prolog writes.

Our experiences with the pwa2000 have shown us possible avenues for future
improvements. The large statistics that will be coming available from newer
experiments will tremendously improve the statistical power of the results.
Unfortunately this comes at a cost of speed: serial ﬁts for a single mass bin
of projected data volumes could take days. We have begun studies of par-
allelization of the maximum-likelihood ﬁts. One approach is to utilize work
being done on Grid Computing [17] or World-Wide Computing [18]. Such an
approach may be fruitful for our problem since the evaluation of the likelihood
function is almost trivially parallelizable being a large sum over ≈ 106 − 108
events.

The authors wish to thank all those who suﬀered through buggy versions of
this code. Their patience and suggestions have produced a robust system. This
work was partially supported by the National Science Foundation.

23

References

[1] S. Chung, Formulas for partial-wave analysis, note, BNL (1988).

[2] S. Chung, T. Trueman, Positivity conditions on the spin density matrix: A

simple parametrization, Physical Review D 11 (3) (1975) 633.

[3] S. Chung, Spin formalisms, CERN Yellow Report 71-8, CERN (March 1971).

[4] M. Jacob, G. C. Wick, On the general theory of collisions for particles with

spin, Ann. Phys. 7 (1959) 404–428.

[5] F. von Hippel, C. Quigg, Centrifugal-barrier eﬀects in resonance partial decay

widths, shapes, and production amplitudes, Physical Review D 5 (1972) 624.

[6] S. Flatt´e, Coupled-channel analysis of the πη and K ¯K systems near K ¯K

threshold, Physics Letters B 63 (1976) 224.

[7] S. U. Chung, et al., Partial wave analysis in K matrix formalism, Annalen Phys.

4 (1995) 404–430.

[8] N. Ramsey, Literate programming simpliﬁed, IEEE software 11(5) (1994) 97.

[9] D. E. Knuth, Literate Programming, Center for the Study of Language and

Information - Lecture Notes, University of Chicago Press, 1992.

[10] K. L. Au, D. Morgan, M. R. Pennington, Meson dynamics beyond the quark
model: Study of ﬁnal-state interactions, Physical Review D 35 (1987) 1633.

[11] D. V. Amelin, et al., Study of resonance production in diﬀractive reaction

π−A → π+π−π−A, Physics Letters B 356 (1995) 595.

[12] S. U. Chung, et al., Exotic and q ¯q resonances in the π+π−π− system produced

in π−p collisions at 18 GeV/c, Phys. Rev. D65 (2002) 072001.

[13] B. W. Kernighan, R. Pike, The UNIX programming environment, Prentice-Hall

Software Series, Prentice-Hall, New Jersey, 1984.

[14] ABBHHM, Photoproduction of meson and baryon resonances at energies up to

5.8-GeV, Phys. Rev. 175 (1968) 1669–1696.

[15] M. Nozar, et al., A study of the reaction π−p → ωπ−p at 18-GeV/c: The D and

S decay amplitudes for b1(1235) → ωπ, Phys. Lett. B541 (2002) 35–44.

[16] M. Bellis, An analysis of γp → pπ+π− using the CLAS detector, in: CIPANP-

2003 proceedings, 2003.

[17] I. Foster, C. Kesselman, Globus: A metacomputing infrastructure toolkit, The
International Journal of Supercomputer Applications and High Performance
Computing 11 (2) (1997) 115–128.

[18] C. Varela, G. Agha, Programming dynamically reconﬁgurable open systems

with SALSA, ACM SIGPLAN Notices 36 (12) (2001) 20–34.

24

