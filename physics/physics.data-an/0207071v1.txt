2
0
0
2
 
l
u
J
 
8
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
1
7
0
7
0
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Wireless communications with diﬀuse waves

S.E. Skipetrov∗
CNRS/Laboratoire de Physique et Mod´elisation des Milieux Condens´es,
38042 Grenoble, France
(Dated: February 2, 2008)

Diﬀuse, multiple-scattered waves can be very eﬃcient for information transfer through disor-
dered media, provided that antenna arrays are used for both transmission and reception of signals.
Information capacity C of a communication channel between two identical linear arrays of n equally-
spaced antennas, placed in a disordered medium with diﬀuse scattering, grows linearly with n and
can attain considerable values, if antenna spacing a >∼ λ/2, where λ is the wavelength. Decrease of
a below λ/2 makes the signals received by diﬀerent antennas partially correlated, thus introducing
redundancy and reducing capacity of the communication system. When the size of antenna arrays
is well below λ/2, the scaling of C with n becomes logarithmic and capacity is low.

Wireless communications in a disordered environment
have recently attracted considerable attention [1, 2, 3].
At ﬁrst glance, scattering from randomly distributed
heterogeneities disturbs the signal carried by the scat-
tered wave (either acoustic or electromagnetic) and is
expected to reduce the eﬃciency of communication. In-
deed, the rate of error-free information transfer per Hertz
of frequency bandwidth for a scalar, narrow-band com-
munication channel between a transmitter and a re-
ceiver is bounded by the channel information capacity
2
= log2[1+|G|
/N ] measured in bits per second per Hertz
(bps/Hz) [4, 5]. Here G = G(ν) is the Fourier transform
of the impulse response function G(t), describing the sig-
nal at the receiver due to an inﬁnitely short pulse emitted
by the transmitter, and N is the power of the Gaussian
white noise at the receiver. Obviously, the decrease of
2
the signal power |G|
due to scattering results in a re-
duction of the channel capacity. However, in addition to
the overall decrease of |G|
, scattering introduces random
ﬂuctuations of G in space. It was recently realized [6] that
one can make use of these ﬂuctuations to overcome the
reduction of C due to the drop of the signal power, pro-
vided that the communication system contains a large
number of antennas [1, 3]. This issue is very promis-
ing for applications in wireless communications (mobile
telephony in cities, indoor wireless local-area networks in
buildings with complex structure, underwater communi-
cations with acoustic waves, etc.).

2

Assuming that the information about the scattering
environment is available at the receivers (but not at the
transmitters) and that uncorrelated noises at diﬀerent
receiving antennas have the same power N , the average
capacity of a communication channel between arrays of n
transmitting and n receiving antennas [13] can be deﬁned
as [1]

C = max

log2 det

In + G Q G+/N

,

(1)

Q

(cid:10)

where In is the n × n unit matrix, G is a Green ma-

(cid:2)

(cid:3)(cid:11)

trix (Giα gives the signal received by the receiver α
due to the transmitter i), and Q is a non-negative def-
inite covariance matrix describing correlations between
the transmitted signals (with the constraint on the max-
imum transmitted power Tr Q ≤ n). Angular brackets
in Eq. (1) denote averaging over realizations of disorder.
A rigorous analysis of the information capacity C in a
disordered medium cannot be based uniquely on the ar-
guments of the information theory [4, 5] and requires the
physical understanding of scattering undergone by the
waves carrying the information from transmitters to re-
ceivers. In the present paper we analyze C in the frame-
work of the model of diﬀuse multiple scattering, result-
ing in a complicated, seemingly random spatial distribu-
tion of scattered wave ﬁelds (so-called “speckles”). For
the extreme cases of (a) a single speckle spot covering
the whole antenna array (G has perfectly correlated en-
tries) and (b) diﬀerent antennas situated inside diﬀerent
speckle spots (entries of G are uncorrelated), we derive
complete analytical expressions for C. We show that C
increases during the continuous transition from the case
(a) to the case (b) upon increasing antenna spacing (or,
equivalently, upon decreasing correlations between the
entries of G) and changes its asymptotic scaling with n
from C ∝ ln n to C ∝ n.

To be speciﬁc, we consider two identical linear arrays
of equally-spaced transmitting/receiving antennas placed
in a disordered medium. The distance L between the ar-
rays is assumed to be much greater than the mean free
path ℓ for waves in the medium, while the array size
d = (n − 1)a ≪ ℓ and d ≪ (λL)1/2 (Fresnel limit),
where a is the spacing between adjacent antennas and
λ is the wavelength. In the majority of practically im-
portant cases λ ≪ ℓ, and hence the propagation of waves
from transmitters to receivers is diﬀusive [7]. Entries Giα
of the matrix G can be then treated as complex Gaussian
random variables with zero mean, equal variances, and
possibly nontrivial correlations [8]

hGiαGjβ i = σ2 sin(k∆rij )

k∆rij

sin(k∆rαβ)
k∆rαβ

,

(2)

∗Sergey.Skipetrov@grenoble.cnrs.fr

where k = 2π/λ, ∆rij = |i − j| a, and ∆rαβ = |α − β| a.

2

(5)

(6)

calculated as

C =

F (x)

= Tr

P−1R

,

d
dx

(cid:0)
where P and R are n × n matrices:

(cid:1)

x=0

(cid:12)
(cid:12)
(cid:12)

Pij = (i + j − 2)! n1−i−j,

Rij =

dµ ln [1 + (S/N )µ] µi+j−2 exp(−nµ). (7)

∞

0
Z

Equations (5)–(7) provide an eﬃcient way for capacity
calculation at arbitrary n and S/N (see the solid line in
Fig. 1) and agree perfectly with the direct Monte Carlo
simulation of capacity using Eq. (1) (symbols in Fig. 1).
Note that the growth of C with n is linear at large n and
hence is much faster than in the case (a).

An alternative way of calculating capacity consists in
performing averaging directly in Eq. (3) using Eq. (4).
This yields

∞

C/n =

dµ log2 [1 + (S/N )µ] fn(µ),

(8)

R

0
Z
∞
where fn(µ1) =
0 dµ2 . . . dµn pn(µ1, . . . , µn) can be
evaluated by a direct integration, at least at moderate
n: f1(µ) = exp(−µ), f2(µ) = 2 exp(−2µ)[1 − 2µ + 2µ2],
f3(µ) = 3 exp(−3µ)[1 − 6µ + 18µ2 − 18µ3 + (27/4)µ4],
etc. The values of capacity obtained then from Eq. (8)
coincide exactly with that following from Eq. (5). An
asymptotic expression for fn(µ) at n ≫ 1 can be found
in the framework of the random matrix theory [10, 12]:
f∞(µ) = (2π)−1(4/µ−1)1/2 for 0 < µ < 4 and f∞(µ) = 0
otherwise. Eq. (8) then yields

C/n = (S/N ) 3F2 (1, 1, 3/2; 2, 3; −4 S/N ) / ln 2, (9)

where 3F2 is the generalized hypergeometric function.
This result is shown in the main plot of Fig. 1 by a dashed
horizontal line. We ﬁnd C/n ≃ log2(S/N ) − log2 e for
S/N ≫ 1 (see also the inset of Fig. 1). It is worthwhile
to note that C/n decreases monotonically with n, while
the diﬀerence between the values of C/n at n = 1 and
n > 1 never exceeds 7%.

We now allow ka to take arbitrary values, thus in-
troducing correlations between the entries of the Green
matrix G. Eq. (1) can again be reduced to Eq. (3) with
µi denoting the squares of the singular values of the ma-
trix Q1/2G+/S1/2, where Q is chosen to maximize the
result. The joint probability density function of µi, anal-
ogous to Eq. (4), is not known in this case, but one can
still calculate C in the large-n limit [1, 11]. The idea is
to represent the moment generating function F (x) of a
random variable c, deﬁned by Eq. (3) without averaging,
as a multiple Gaussian integral (the so-called “replica
trick”) and then to perform the integrations using saddle
point methods in the limit n ≫ 1. The maximization
of C = (d/dx)F (x)|x=0 over Q is then accomplished by
requiring δC ≤ 0 for all allowed small variations δQ of
the optimal matrix Q. This yields a system of nonlinear

FIG. 1: Average information capacity per antenna of a com-
munication channel between two arrays of n antennas in a
disordered medium assuming statistical independence of the
entries of the Green matrix G: results obtained using the ran-
dom matrix theory (solid line) and Monte Carlo simulation
(symbols) are shown for the signal to noise ratio S/N = 100.
Horizontal dashed line shows the asymptotic value of C/n for
n → ∞. Inset: Capacity per antenna as a function of S/N
for single transmitting and single receiving antennas (dashed
line) and an inﬁnitely large number of antennas (solid line).

The simplest cases to consider are (a) kd → 0 and
In the former case,
(b) ka = mπ (m = 1, 2, . . .).
all Giα are perfectly correlated and one ﬁnds C =
exp[1/(n2S/N )]E1[1/(n2S/N )]/ ln 2, where E1 is the ex-
ponential integral function, S = nσ2 is the average sig-
nal power received at each receiver assuming independent
signals from transmitters, and C ∝ ln n for n2S/N ≫ 1.
In the case (b), Q = In in Eq. (1) [9] and the machinery
of the random matrix theory [10] can be employed for
further analysis of the problem. In particular, it is useful
to rewrite Eq. (1) as

C =

log2 [1 + (S/N )µi]

,

(3)

+

n

*

i=1
X

where µi are the squares of the singular values of the ma-
trix G+/S1/2 with the joint probability density function
[10]

pn(µ1, . . . , µn) = An exp

−n

µi

(µi − µj)2, (4)

n

 

i=1
X

!

i<j
Y

where An is a normalization constant. The moment gen-
erating function F (x) of a random variable c, deﬁned
by Eq. (3) without averaging, is obtained by averaging
exp(xc) with help of Eq. (4) [11], and C = hci is then

3

calculation. The results that we obtained for identical
linear arrays of equally-spaced antennas are presented in
Fig. 2. As follows from the ﬁgure, at ka > π correlations
between the entries of G are too weak to aﬀect C signiﬁ-
cantly and the latter remains very close to its maximum
value, given by Eqs. (5) or (8). In contrast, correlations
become important when ka decreases below π, leading to
a signiﬁcant drop of C. The dashed line in Fig. 2 results
from the asymptotic large-n theory [1, 11, 12] with n = 2
and is shown for illustration purposes only. Its closeness
to the Monte Carlo result (solid line for n = 2) testiﬁes
a qualitative validity of the large-n theory even at small
n. As ka increases, the scaling of C with n changes from
C ∝ ln n at ka = 0 to C ∝ n at ka >
∼ π (see the inset of
Fig. 2). We note that even at 0 < ka < π, there is still
a signiﬁcant gain in capacity as compared to the case of
ka = 0: e.g., at n = 100, C/n for ka = π/2 (π/4) is
almost 20 (13) times larger than for ka = 0.

In conclusion, we have studied the information capac-
ity C of a wireless communication channel in a disordered
medium, assuming multiple diﬀuse scattering of waves
that carry information, and taking into account ﬂuctua-
tions of wave ﬁelds in space (speckles). Although multi-
ple scattering reduces the received signal, it allows for a
dramatic increase of capacity in the case of communica-
tion between two antenna arrays, provided that antenna
spacing a >
∼ λ/2, where λ is the wavelength. Namely,
for identical linear arrays of n equally spaced receiv-
ing/transmitting antennas, scaling of C with n changes
from C ∝ ln n for kd ≪ π to C ∝ n for ka >
∼ π, where
d = a(n − 1) is the array size and k = 2π/λ. Even at
0 < ka < π an important gain in capacity is possible as
compared to ka = 0.

The author is indebted to Prof. R. Maynard for helpful

discussions and critical reading of the manuscript.

FIG. 2: Average information capacity per antenna of a com-
munication channel between two identical linear arrays of n
antennas in a disordered medium assuming antenna spacing
a and S/N = 100. Solid lines correspond to n = 1 (exact
result), n = 2 (Monte Carlo simulation) and n = 100 (asymp-
totic large-n result). Dashed line shows the result obtained
using the asymptotic large-n theory at n = 2. Inset: Capacity
per antenna as a function of n for diﬀerent antenna spacings a.
Results for ka = π/2 and π/4 are asymptotic large-n results.

equations for the eigenvalues of Q and some auxiliary
variables that can be solved numerically. We refer the
reader to Refs. 11 and 12 for an exhaustive account of the
theoretical approach and the algorithm of the numerical

[1] A.L. Moustakas, H.U. Baranger, L. Balents, A.M. Sen-

[7] A. Ishimaru, Wave Propagation and Scattering in Ran-

gupta, S.H. Simon, Science 287, 287 (2000).

dom Media (Academic, N.Y., 1978).

[2] M.R. Andrews, P.P. Mitra, and R. deCarvalho, Nature

409, 316 (2001).

[3] S.H. Simon, A.L. Moustakas, M. Stoytchev, and H. Safar,

Phys. Today 54(9), 38 (2001).

[4] C.E. Shannon, Bell Syst. Tech. J. 27, 379 & 623 (1948).
[5] T.M. Cover and J.A. Thomas, Elements of Information

(1999).

[8] B. Shapiro, Phys. Rev. Lett. 57, 2186 (1986).
[9] I.E. Telatar, Eur. Trans. Telecommun. 10, 585 (1999).
[10] M.L. Mehta, Random Matrices (Academic, N.Y., 1991).
[11] A.M. Sengupta and P.P. Mitra, physics/0010081 (2000).
[12] A.M. Sengupta and P.P. Mitra, Phys. Rev. E 60, 3389

[6] G.J. Foschini and M.J. Gans, Wireless Personal Commu-

Theory (Wiley, N.Y., 1991).

nications 6, 311 (1998).

[13] For simplicity, we consider the transmitting and receiving
arrays to consist of the same number n of antennas.

