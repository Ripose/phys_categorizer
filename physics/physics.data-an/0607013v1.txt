6
0
0
2
 
l
u
J
 
3
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
3
1
0
7
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Fast Computation of Voigt Functions via Fourier
Transforms

Marcus H. Mendenhall 1

Vanderbilt University Free Electron Laser Center, P. O. Box 351816 Station B, Nashville,
TN 37235-1816, USA

Abstract

This work presents a method of computing Voigt functions and their derivatives, to high
accuracy, on a uniform grid. It is based on an adaptation of Fourier-transform based convo-
lution. The relative error of the result decreases as the fourth power of the computational ef-
fort. Because of its use of highly vectorizable operations for its core, it can be implemented
very efﬁciently in scripting language environments which provide fast vector libraries. The
availability of the derivatives makes it suitable as a function generator for non-linear ﬁtting
procedures.

Key words:
Voigt function, lineshape, Fourier transform, vector

Introduction

The computation of Voigt line proﬁles is an issue which has been dealt with over a
long time in the literature [1, 2, 3, 4, e.g.]. Nonetheless, it remains a computationally
interesting problem because it is still fairly expensive to compute proﬁles to high
accuracy. This paper presents a method which is fast and very simple to implement.
It is similar to the method of [3], but capable of much higher precision for a given
computational effort. More importantly, the method described here computes not
only the Voigt function itself, but its derivatives with respect to both the Gaussian
and Lorentzian widths, which are helpful for non-linear curve ﬁtting.

Because the method is based on Fourier transforms, and generates a grid of values
for the function in a single operation, it is particularly suitable for (but not restricted
to) use in scripting environments, where Fast Fourier Transforms (FFTs) and other

Email address: marcus.h.mendenhall@vanderbilt.edu (Marcus H. Mendenhall).

1 Supported by grant FA9550-04-1-0045 from the DOD MFEL Program

Preprintsubmitted toJQSRT

3March2008

vector operations are available as part of the language library, and execute at very
high speed. Thus, in Matlab R
, Octave,
(cid:13)
and other similar environments, it may ﬁnd particular applicability.

, Python (with Numeric), Mathematica R
(cid:13)

A method such as this one, which contains no inherent approximations, has advan-
tages over other approximate methods in that it can be adapted very easily to the
desired level of precision of the task at hand. Selecting the density of the computa-
tional grid and the length into the tails to which the computation is carried out sets
the accuracy. The grid density does not affect the accuracy of the values this pro-
duces directly, but does affect the accuracy to which interpolation may be carried
out between the computed points. The distance into the tails to which the proﬁle
is computed does affect the accuracy of the step deﬁned below which corrects for
periodic boundary conditions, and it converges as the fourth power of this distance.

As an aside on notation, most papers working with the Voigt function historically
have deﬁned it in terms of a single parameter, the ratio of the Lorentzian to Gaus-
sian width. This work, presents the results in a slightly different form, which is
more useful for direct computation. The equations below are computed in terms of
the Lorentzian width (which I call a ) and the standard deviation of the Gaussian
distribution s
. The parameter y in Drayson [1] is a /(√2s ) in my notation. In this
form, the transforms produce functions fully scaled and ready for direct interpola-
tion.

The Voigt function is a convolution of a Lorentzian proﬁle and a Gaussian,

Theory

V (a

, s

; x) (cid:181)

t2/2s 2
t)2 + a 2 dt

e−

−

(x

Z
−

and can be easily written down in Fourier transform space using the convolution
theorem:

˜V (a

, s

; k) = exp

s 2k2/2

−

(cid:2)

−

k

|

|
(cid:3)

Also, of great importance to using this in ﬁtting procedures, the derivatives of this
function with respect to its parameters can be computed:

and

˜V
a =

k

˜V

− |

|

˜V
s =

s k2 ˜V

−

2

(1)

(2)

(3)

(4)

¥
¥
a
¶
¶
¶
¶
and since the differentiation in these cases commutes with the transform, these are
the transforms of the appropriate derivatives of the function itself.

Note that, since this transform method generates functions with a ﬁxed area, these
are the derivatives with respect to the widths at ﬁxed area, rather than at ﬁxed
amplitude. This implies that ﬁtting carried out using functions computed this way
is most appropriately done using a

, and area as parameters.

, s

This result is exactly correct in the full Fourier transform space. For practical com-
putation, though, one wishes to reduce this into something which is computed
rapidly on a discrete lattice using Fast Fourier Transform (FFT) techniques, and
then interpolated between the lattice points. The difference between the full contin-
uous transform and the discrete transform is, of course, that the function produced
by a discrete transform is periodic. In effect, by discretely sampling the series in
Fourier space, one is computing, instead of the exact convolution, a closely re-
lated function which has had periodic boundary conditions applied. This affects the
shape of the tails of the distribution, but in a way which is fairly easily ﬁxed.

First, when doing the discrete transforms, it is necessary to decide how far out in
k-space it is necessary to have data. In general, one wants to assure the function
is nicely band-limited, which means no signiﬁcant power exists at the highest k.
Practically speaking, setting the argument of the exponential in eq. 2 to something
25 or about
like –25 at the boundary means the highest frequency component is e−
11 of the DC component. To achieve this, deﬁne the absolute value of the log
10−
of the tolerance to be g
= g .
This is a simple quadratic equation, but because one doesn’t know in advance how
dominant the relative terms are, one should solve it with a bit of care. The stable
quadratic solution presented in Numerical Recipes [5] can be adapted to be

(25 for the example here) and solve s 2k2/2 + a

k

|

|

kmax =

a +

2g
a 2 + 2g

2

p

This is simpler than the full solution in [5] since the signs of both a
known in advance.

and s

are

Now, note that the periodic solution is really an inﬁnite comb of functions shaped
like the desired one, added together. Since, beyond a few s
from the center, the
function is close to Lorentzian, one has really computed the desired function plus
an inﬁnite series of offset simple Lorentzians:

(5)

(6)

V (a

, s

; x) = Vact(a

, s

; x) +

1

(x

=0
n

−

nD )2 + a 2

3

s
a
p
(cid:229)
6
where D
analytically. It is:

is the period of the function. However, the inﬁnite sum can be computed

1
nD )2 + a 2 =

≡

(x

=0
n

−

sinh 2p

cosh 2p

cos 2p x

−

D −

(cid:16)

(cid:17)

1
x2 + a 2

a =

a 2
x2
−
p (a 2 + x2)2 +
(cid:0)

(cid:1)

D 2

(cid:0)
2p cosh
cosh 2p

2a

cos 2p x
(cid:1)

D −
(cid:0)

−

D 2

(cid:1)

(cid:0)

(cid:0)

(cid:1)

2a

2p sinh2
cosh 2p

(cid:0)
D −

cos 2p x
(cid:1)

2

(cid:1)

(7)

(8)

Since the derivative with respect to s
the boundaries, no correction is needed for it.

is very localized, and falls to zero rapidly at

Although these equations look computationally intensive, they are not so at all.
Note that the cosh and sinh terms are of a constant, and not evaluated at each point.
Also, for the usual Fourier-space case, D = 2xmax so the cos term is just an evalu-
to p on the same grid the rest of the function will be
ation of the cosine from
evaluated. If the Voigt function is to be evaluated for many different a
, s pairs (as
is the case in ﬁtting routines), but always on a grid with a ﬁxed number of points,
this cosine only gets evaluated once, too, and can be cached for reuse. Also, the
correction and its derivative with respect to a
share most of their terms in common,
so this correction is really a simple algebraic adjustment to the raw function table.

−

The correction term in eq. 7 is an approximation based on all the other nearby
peaks being entirely Lorentzian, and works well. However, it can be improved by
a scaling argument, which works surprisingly well. The non-Lorentzian nature of
the correction is due to the convolution of the Gaussian with the curvature of the
Lorentzian causing a slight widening even on the tails. Note that convolution of a
function with a Gaussian only affects even derivatives (by symmetry), so the second
derivative term is the lowest order this could affect. Also note that this effect is
getting bigger as one approaches the next peak over (the edge of the boundary).
Thus, one can try a correction of multiplying the right hand side of eq. 7 by 1 + ax2
where a is to be determined. Much of the structure of a can be obtained by scaling,
and it should be a (cid:181)
2/D 4. Empirical testing has shown that a constant of 32
appears optimal, so an improvement on eq. 7 is:

e =

"

sinh 2p

cosh 2p

cos 2p x

−

D −

(cid:16)

(cid:17)

(cid:0)

(cid:1)

1
x2 + a 2

# (cid:18)

1 +

32s 2x2
D 4

(cid:19)

(9)

This improves the original correction by almost an order of magnitude in the peak
error at the bounds of the interval, and the RMS error is reduced by about a factor
of 5 for most test cases.

4

e
a
p
(cid:229)
6
a
D
D
a
D
a
p
¶
e
¶
p
D
a
D
p
D
a
D
p
s
a
D
D
a
D
a
p
The road not taken

There is another way one could consider carrying out this computation, which looks
elegant and easy from the outset, but actually is computationally much more expen-
sive. I will outline it here as a warning to others.

Instead of ﬁxing the periodicity error by adding on the correction of eq. 7 or eq.
9, one might be tempted to ﬁx the problem in advance, before the transforms are
carried out from k-space to real space. The obvious solution is to try to compute
the transform of the difference between the Voigt function and a pure Lorentzian,
and then add the pure Lorentzian back in afterward, not as an inﬁnite sum as in the
correction equations, but just as a single copy. One would compute

˜V0(a

, s

; k) =

exp

s 2k2/2

−
(cid:2)

(cid:0)

1

exp [

]

k
|

|

−

−

(cid:3)

(cid:1)

(10)

and then transform this, and add back on the Lorentzian which was subtracted.
This turns out to be computationally very inefﬁcient, though. When computing the
transforms, one wants a cleanly band-limited function in k-space, with the power in
the highest frequency channels vanishing rapidly. In the case of eq. 2, this is clearly
s 2k2/2 term makes the exponential disappear relatively rapidly
the case, since the
even for fairly modest values of s
and k. In the case of eq. 10, though, ˜V0 only
vanishes as fast as the exp [
] term, which falls off much more slowly. Thus,
k
|
|
one has to carry out the transforms to much higher values of k to get convergence.
This turns out practically to be a huge penalty. Even in the case of s
k, it requires
≈
about a few times more terms, and in the case s
k, it is much worse, since the
extremely rapid falloff of the Gaussian in k-space allows one to sample only quite
small values of k to get very good performance.

≫

−

−

Application

The most probable way the author sees these gridded functions being used is to load
cubic spline interpolation tables to generate values at points which may not lie on
the grid. This way, one can compute the Fourier transforms on grids of sizes con-
venient for FFT algorithms (often, powers of two, but using. e.g. FFTW [6], many
other grid sizes can be conveniently transformed), and then use the interpolator to
ﬁll in the values desired. Because of both the shape of these functions and the wide
dynamic range they typically encompass, it is likely that it will be useful to interpo-
late the logarithm of the function. Especially if s
, so the center looks Gaussian,
log interpolation is extremely beneﬁcial, since the logarithm of the Gaussian part is
just parabolic, and exactly interpolable by a cubic spline interpolator.

≫

5

a
a
a
Error Analysis

4 when s

Figure 1 shows sample functions computed by this method, and the relative er-
rors associated with this computation. These were computed using the extra error
correction of eq. 9. The scaling of the errors is fairly easy to compute from the
underlying equations. In general, the errors scale as D −
are held
constant. For most practical applications, it is likely that the need to compute the
tails far enough from the center that the entire spectrum is covered by the calcula-
tion results in the tails being calculated sufﬁciently far out that the accuracy is not a
concern. In Figure 1, the last curve shows the result when D = 80s
(tails computed
to 40s ), and even in this case the peak relative error is 10−
4 (in a part of the curve
off the graph). Most practical cases are likely to need the tails much farther out than
this, resulting in the accuracy automatically being better than this. As an example,
though, of pushing the computation to very narrow tails, the second-to-last curve
shows the results for the tails being computed to only 10s
. Even in this case, the
relative error only exceeds 10−

3 at the very edge of the domain.

and a

Conclusion

Because of relatively slow convergence, simple FFT-based convolution has not
fared well in the Voigt-function computation arena. Nonetheless, this method has
always had an advantage in simplicity and vectorizability. Also, it is trivial to get
the derivatives of the Voigt function with respect to its width parameters from
transform-based methods.

By combining the traditional transform-based method with a convergence-enhanc-
ing operation, the result is a method which is fast, accurate, and extremely easy
to implement. It should ﬁnd particular application for ﬁtting work carried out in
many widely used scripting languages, in which fast vector operations often make
computation of tables of function values an efﬁcient process. As an example, on
my 1 GHz laptop computer, it takes 8 milliseconds to compute a 2048 point grid
of the function and its two derivatives using this method, in the Python language.
Even in compiled languages, though, this should be highly adaptable to fast work
on any operating system and machine which provides good vector operation and
FFT support.

6

Bibliography

[1] S. R. Drayson. Rapid computation of the Voigt proﬁle. Journal of Quantitative

Spectroscopy and Radiative Transfer, 16(7):611–614, July 1976.

[2] Joseph H. Pierluissi, Peter C. Vanderwood, and Richard B. Gomez. Fast calcu-
lational algorithm for the Voigt proﬁle. Journal of Quantitative Spectroscopy
and Radiative Transfer, 18(5):555–558, November 1977.

[3] Alan H. Karp. Efﬁcient computation of spectral line shapes. Journal of Quan-
titative Spectroscopy and Radiative Transfer, 20(4):379–384, October 1978.
[4] F. Schreier. The Voigt and complex error function: A comparison of computa-
tional methods. Journal of Quantitative Spectroscopy and Radiative Transfer,
48(5-6):743–762, November-December 1992.

[5] William H. Press, Saul A. Teukolsky, William T. Vetterling, and Brian P. Flan-
nery. Numerical Recipes in C, chapter 5.6, page 184. Cambridge University
Press, 2nd edition, 1992. ISBN 0-521-43108-5.

[6] Matteo Frigo and Steven G. Johnson.

The design and implementation
of FFTW3.
URL
http://www.fftw.org. special issue on "Program Generation, Optimization,
and Platform Adaptation".

the IEEE, 93(2):216–231, 2005.

Proceedings of

7

 = 1000

 = 1, D
 = 50, D

Function: s
Function: s
10

3 ·  Relative Error: s
3 ·  Relative Error: s
3 ·  Relative Error: s

10

10

 = 1000
 = 1, D
 = 50, D
 = 50, D

 = 1000

 = 1000

 = 4000

e
d
u
t
i
l

p
m
A

0
10

-1

10

-2

10

-3

10

-4

10

-5

10

-6

10

0

100

200

300

400

500

offset

Fig. 1. Plot of Voigt Functions with a = 1 evaluated by this method, and the relative errors
(as computed by adaptive numerical integration of the convolution at each point).

8

