Objective Bayesian statistics

0.-A. Al-Hujaj and H.L. Harney
MPI f¨ur Kernphysik, Postfach 103980, 69029 Heidelberg, Germany
(February 2, 2008)

Abstract

Bayesian inference — although becoming popular in physics and chemistry —
is hampered up to now by the vagueness of its notion of prior probability.
Some of its supporters argue that this vagueness is the unavoidable conse-
quence of the subjectivity of judgements — even scientiﬁc ones. We argue
that priors can be deﬁned uniquely if the statistical model at hand posses
a symmetry and if the ensuing conﬁdence intervals are subjected to a fre-
quentist criterion. Moreover, it is shown via an example taken from recent
experimental nuclear physics, that this procedure can be extended to models
with broken symmetry.

2.50 Kd, 2.50 Wp, 6.20 Dk

7
9
9
1
 
n
u
J
 
8
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
5
2
0
6
0
7
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Typeset using REVTEX

1

INTRODUCTION

Bayesian inference is becoming popular in the physical sciences. It ﬁnds eloquent and
noteworthy defenders [1,2], it is treated in a growing number of textbooks [3–7], an annual
series of conferences [8] as well as numerous articles report on its applications. Even the
“Guide to the expression of uncertainty in measurement” [9] supported by the International
Organization for Standardization (ISO), the Bureau International des Poids et M´esures
(BIPM) and other international organizations implicitly favors Bayesian statistics — as
D‘Agostini points out (in Secs. 2.2 and 14.2 of [2]). Some authors that have collaborated in
the formulation of the Guide [9] and of the German standard [10], adhere in their publications
to “a Bayesian theory of measurement uncertainty” [11]. The change of paradigm from
frequentist to Bayesian statistics (for this antagonism see e.g. the introduction of [11] and
ch. 7 of [12]) is taking place despite the fact, that the disturbing vagueness of Bayesian prior
probabilities persists up to now. D‘Agostini [2] eloquently holds that the prior probabilities
are the mathematical representation of an unavoidable subjectivity of judgments — even
of scientiﬁc ones. In our opinion, however, a criterion exists that prior probabilities should
meet — at least approximately — and which in many cases does not leave any freedom
in their choice. This criterion is a consequence of the fact that Bayesian inference has
a frequentist interpretation — as will be explained below. This fact has been pointed
out earlier (by Welch, Peers, Stein and Villegas [13–17]) in the literature of mathematical
statistics but it seems rarely known in practice. In the present note, the criterion is described
as well as the circumstances under which it is met. They amount to the existence of a
symmetry of the model that states the relation between event and hypothesis. The Bayesian
prior is then a Haar measure of the symmetry group. By helps of a realistic example taken
from current nuclear physics it is shown that this procedure can be extended to the usual
case of models with broken symmetry. Finally the same example shows that the popular
likelihood method — as described in [18]— yields conﬁdence intervals of lower reliability
than the Bayesian procedure.

BAYESIAN STATISTICS

Bayesian statistics is a very useful tool for statistical inference. Let x denote the con-
tinuous event and ξ the continuous hypotheses. Suppose that the conditional probability
p(x
ξ)dx — the above mentioned model — as well as the event x are given. The problem
|
of statistical inference is: What can we learn from x about ξ? The Bayesian answer [19]
is a conditional probability P for ξ given x which can be expressed in terms of the given
distribution p,

P (ξ

x)dξ =

|

p(x
|
dξ′ p(x
|

ξ)µ(ξ)

dξ.

ξ′)µ(ξ′)

(1)

Here, µ(ξ) is the prior distribution assigned to ξ in the absence of or “prior to” any ex-
perimental evidence. Hence, Bayesian statistics relies on the assumption that µ(ξ) is a
meaningful object.

R

The choice of the prior is the problem of Bayesian theory, because it is not clear what

we can know “prior” about ξ.

2

SUBJECTIVE INTERPRETATION

The view held e.g.

in the recent article by D’Agostini [2] or the recent textbook by
Howson and Urbach [6] is that the choice of µ(ξ) should be left to the good taste and the
experience of the scientist analyzing the event x. They argue that a such a subjective element
should be in any honest theory of inference since it makes explicit the subjectivity of any
judgement — including the scientiﬁc ones: nothing can be known about ξ in an objective
way prior to the event. In subjective interpretation Bayesian probabilities reﬂect personal
conﬁdence in hypotheses. It can be expressed in bets (see [6]).

This view does in principle not preclude objectivity altogether: Objectivity exists as the
limiting consequence of an inﬁnite number of recorded events. Indeed one can show that in
this limit Bayesian inference becomes independent of µ(ξ) in the sense that p(x
ξ) then tends
|
towards a δ-distribution with respect to ξ — centered at the true value ˆξ of the hypothesis.

OBJECTIVE BAYESIAN STATISTICS

The subjective interpretation — taken literally and without appealing to some common
sense — allows anything. This is obvious from eq. (1): if one is free to choose µ(ξ), one can
generate any P (ξ
x) — given a ﬁnite number of events. To avoid this, we prefer to look for
some criterion that would severely restrict the class of allowed priors. Fortunately there is
a very natural one.

|

Consider a Bayesian conﬁdence area

(x, C). It shall satisfy

A

dξ P (ξ

x)

C,

|

≡

ZA(x,C)

A

which is usually stated in the form: “given the event x, the hypothesis lies with conﬁdence
C in the area
”. We want to reformulate this in a way which turns the vague notion of
conﬁdence into probability and by the same token deﬁnes the desired criterion.

Imagine an ensemble X of events x with relative frequencies p(x
|

ˆξ)dx. Let x run over the
ensemble and suppose that from every x the conﬁdence area
(x, C) is derived in a unique
way, e.g. by determing the smallest one. This yields an ensemble of conﬁdence areas. The
criterion then is: The prior must lead to an ensemble of conﬁdence areas such that they
cover the true value ˆξ with probability C.

A

Since this gedanken experiment — which can even be realized via Monte Carlo simula-
tion — equates C with a well deﬁned frequency (to cover ˆξ), the criterion turns conﬁdence
into frequentist probability. In short: We require that Bayesian conﬁdence areas are fre-
quentist conﬁdence areas. It is proven in the mathematical literature [14] that this criterion
ξ)dx be invariant under a Lie group
can be met exactly: Let the conditional probability p(x
|
G represented as transformations of x and ξ, i.e.

Gρ ∈
suppose furthermore that the deﬁnition of the conﬁdence area

ξ)dx = p(Gρx
|

Gρξ)dGρx,

p(x
|

is invariant under G, i.e

G,

A

(Gρx, C) = GρA

A

(x, C),

3

(2)

(3)

(4)

then the right Haar measure of the symmetry group is a suitable prior in the sense of the
criterion. It is necessary for this, that the hypothesis can be identiﬁed with the symmetry
group of the conditional probability, i.e. for every two hypotheses ξ1,ξ2 there must be exactly
G such that ξ1 = Gρξ2. Then the uniqueness of the right Haar
one transformation Gρ ∈
measure implies the uniqueness of the prior and one has

µ(ξ) =

∂Gρξ
∂ρ

"

−1

,

ρ=0#
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(5)

which is the inverse Jacobian of the transformation Gρ taken at the unit element of the
group.

Note that the very interesting case of

to be the smallest area of conﬁdence C, satisﬁes
is determined by help of the measure that is invariant under G,

A

eq. (4), if the volume of
A
i.e. the left Haar measure.

The prior distribution is not independent of the statistical model; rather it is deﬁned
by the structure of the model (see [16,20]). It is prior to the observations. Since the above
symmetry uniquely deﬁnes the prior and since it ensures a frequentist interpretation of
Bayesian conﬁdence intervals and since frequentist probability is often termed “objective”
probability, one may call the present procedure objective Bayesian statistics. However, we
return to the word “Bayesian” implying for the rest of the paper the qualiﬁcation “objective”.
By the following example, we show that this concept can be extended to models that lack
the symmetry (3).

EXAMPLE

The measurement problems encountered in science, often do not have a symmetry (3).
However, Bayesian inference based on a multi-dimensional event can usually be broken down
into a succession of Bayesian arguments on more elementary events until a starting point
that possesses a symmetry has been found. To be deﬁnite let us consider the parity violating
matrix elements measured by the TRIPLE collaboration in resonant p-wave scattering of
polarized neutrons on heavy nuclei [21–24]. For the present purpose it is not necessary to
understand the details of those experiments. It suﬃces to know that the parity violating
matrix elements — the events — have the Gaussian probability

√M 2 + ε2)dx =

g(x
|

dx
2π(M 2 + ε2)

exp

1
2

x2
M 2 + ε2

(cid:19)

−

(cid:18)

(6)

p

where ε is an experimental error — supposed to be given — and M is the root mean
square parity violating matrix element. The latter one is the “hypothesis” to be determined.
There is no symmetry (3) relating x and M. However, the probability of eq. (6) remains
invariant under simultaneous change of the scale of x and ξ = √M 2 + ε2. Hence, Bayesian
inference should be done with respect to ξ rather than M. Afterwards — when the posterior
distribution of ξ has been constructed — one can derive statements about M. E.g. one can
decide whether with suﬃciently high conﬁdence ξ is larger than ε and thus M > 0. The
symmetry considerations require

4

µ(ξ) =

1
ξ

(7)

as prior, which is the Haar measure of the Lie group of scale changes.

The problem of [21–24] is complicated by the fact, that one usually does not know the
total angular momentum of the p-wave resonance. Only p1/2 resonances can show parity
violation. If the event x is gathered in a p3/2 resonance nothing can be learned about M
ε). One knows, however, the probability qp of the
and the distribution of the event is g(x
|
occurrence of p1/2 resonances. Again it is not necessary to discuss here the contents of
nuclear physics that create this complication. It suﬃces to state, that the event x follows
with probability qp the distribution g(x
ε),
|
so that one has

qp the distribution g(x
|

ξ) and with probability 1

−

p(x
|

ξ) = qpg(x
|

ξ) + (1

qp)g(x
|

ε).

−

The presence of the second term on the right hand side precludes any symmetry (3) relating
x and ξ — except in the limit of ε
ξ) recovers the symmetry
under scale changes. The full experiment of [21–24] probes n resonances i = 1, . . . , n under
varying experimental conditions, so that ε = εi becomes a function of the resonance i. This
alone precludes any symmetry of the multidimensional problem.

δ(x) and p(x
|

0 when g(x
|

→

→

ε)

If, however, one knows for one of the resonances that it is a p1/2 case, say for i = 1,
ξ); the symmetry is scale-invariance
then the event measured there has the distribution g(x1|
x1); it
and the prior is (7); one can use the event x1 to construct the Bayesian inverse P1(ξ
can be injected as prior distribution into the analysis of the results at i = 2, . . . , n. This
procedure leads to a posterior distribution P (ξ
x1, . . . , xn). In this way, one ﬁnds a starting
point of the whole analysis which has a well deﬁned symmetry and therefore a well deﬁned
prior. Let us call the whole procedure an approximate Bayesian (AB) one.

|

|

It is not our purpose to reanalyze the data of refs. [21–24]. We only want to demonstrate,
that the AB analysis satisﬁes the criterion described above to a good approximation. For the
purpose of this, the AB analysis has been subjected to a Monte Carlo test with parameters
close to those of the experimental cases [21–24]. The number of resonances was chosen to be
n = 15. The errors εi, i = 1, . . . , 15 have been drawn from an exponential distribution with
mean value r ˆM. This allows one to study (on ﬁg. 1) the result as a function of r = ¯ε/ ˆM —
the mean error relative to the true value ˆM of the r.m.s. parity violating matrix element. In
the experiments [21–24], r ranged from 0.23 up to the order of unity. The coordinates xi of
the event x = (x1, . . . , x15) were generated in two steps. First one decides with probability
qp = 1
3, whether the quantity xi should belong to the p1/2-wave resonances. If yes then xi was
drawn from an ensemble with distribution g(xi|
εi) was
applied. The vector x — without the information from which of the two ensembles anyone
of the xi comes — is equivalent to the experimental “event”.

i ), else the distribution g(xi|

ˆM 2 + ε2

q

The event x was analyzed by assuming that the “resonance” im, where the maximum of
the ratio xi/εi occurs, is a p1/2 resonance and can serve as the starting point of the analysis
in the above sense. By help of the posterior distribution P (ξ
x), the shortest conﬁdence
interval (ξ<, ξ>) was found such that

|

dηP (η

x1, . . . , xn) = 0.68

ξ>

ξ<

Z

|

5

it

p

the

true

ξ2
> −

was
ξ2
< −

recorded
ε2
1), max(0,

whether
was
and
1)). This procedure was applied to 104 vectors
ε2
inside (max(0,
x. On ﬁg. 1, the symbols labeled “Bayes” give the relative frequency of “success”, i.e the
probability to ﬁnd ˆM in the above mentioned range performed for diﬀerent r which controls
the experimental error. In this way, the curve on the ﬁgure was generated. (The full and
dashed lines are 4th order polynomials ﬁt to the points). Because of the lack of symmetry,
the result is not identical but only close to 0.68 (the dotted line). However, in the limit of
0 for all i, the criterion is obeyed exactly — as it should be, since
r
scale invariance is recovered in this limit.

0 which means εi →

value

p

→

ˆM

FIG. 1. Bayesian inference is superior to the likelihood method: The frequency of the true
value of the parity violating matrix element to lie in the 68%-conﬁdence interval is plotted against
the size of the experimental error. Details are explained in the text.

In comparison, a “likelihood” analysis was performed. This type of analysis is very
popular.
It amounts to the Bayesian procedure with the prior distribution set constant.
ˆM in order to
In the present case, we had to cut oﬀ the posterior distribution for M
normalize it very much as in [21–23]. The ﬁgure shows, that the likelihood method is inferior
to even the approximate Bayesian method. For good data, i.e. r
0, the likelihood method
yields conﬁdence intervals that are — in the light of the criterion — too wide. For data of
marginal quality (r
1), it yields no reliable conﬁdence intervals, because the frequency of
successes is considerably lower than the prescribed conﬁdence.

≫

→

≈

We have deﬁned objective Bayesian statistics by supplementing the Bayesian argument
with the requirement that it should yield “objectively correct” conﬁdence intervals. A
theorem by Stein — which can be found in the published mathematical literature [14] but
which seems to be unknown in practice — shows that this requirement can be met provided

SUMMARY

6

ξ)dx does not have an exact symmetry.

ξ)dx posses the symmetry (3) deﬁned by a Lie group.
that the conditional probability p(x
|
By way of an example we have extended objective Bayesian statistics to the common case
in which p(x
In the example, a complex event
|
x = (x1, . . . , xn) is broken down into elementary ones xi among which there is at least
ξ)dx possesses a symmetry (3). It is
one — say x1 — whose conditional probability p(x1|
used to deﬁne the prior µ(ξ). This has been termed approximate Bayesian procedure. We
have shown numerically that the AB procedure is superior to the popular likelihood method
as judged by the objectivity of the deduced conﬁdence intervals.

Note that the arguments presented here amount to a reconciliation of the subjective and
frequentist interpretations of probability. The Bayesian argument attributes a distribution
to an object, i.e. the hypothesis, which is given by Nature once and for all. This is justiﬁed
by interpreting probability distributions as a representation of subjective knowledge on that
object. The frequentist interpretation insists that a probability distribution must be veriﬁ-
able — at least in a gedanken experiment — as a frequency distribution that occurs in some
stochastic process. We have described a gedanken experiment to generate a distribution of
Bayesian conﬁdence intervals from data that are conditioned by a ﬁxed true value of the
hypothesis. The rate of success, i.e. of the true value lying inside the conﬁdence interval,
turns out to be independent of the true value, moreover the rate of success is equal to the
conﬁdence prescribed in the Bayesian procedure — if the conditional distribution possesses
the symmetry (3) and if the prior is chosen to be the right Haar measure. Then the Bayesian
inference is found reasonable from a frequentist’s point of view.

7

REFERENCES

[1] P. W. Anderson, Physics Today Jan., 9 (1992).
[2] G. D’Agostini, Probability and Measurement. Uncertainity in Physics – a Bayesian

Primer, preprint DESY 95-242, ISSN 0418-9833 (1995).

[3] J. O. Berger, Statistical Decision Theory and Bayesian Analysis, Springer Series in

Statistics, zweite ed. (Springer, New York, 1985).

[4] P. M. Lee, Bayesian Statistics: An Introduction (Oxford University Press, Oxford,

[5] J. S. Press, Bayesian Statistics: Principles, Models, and Applications, Wiley Series in

Probability and Mathematical Statistics (Wiley, New York, 1989).

[6] C. Howson and P. Urbach, Scientiﬁc Reasoning: The Bayesian Approach (Open Court,

1989).

Chicago, 1993).

[7] J. Bernado and A. Smith, Bayesian Theory, Wiley Series in Probability and Mathemat-

ical Statistics (Wiley, Chichester, 1993).

[8] See Conference Reports on “Maximum-Entropy and Bayesian Methods”, Dordrecht,

Reidel, annual published.

[9] Guide to the expression of uncertainity in measurement, International Organization for

Standardization (ISO), Geneva, Switzerland, ISBN 92-67-10188-9.

[10] DIN 1319 Teil 4: Grundbegriﬀe der Meßtechnik: Behandlung von Unsicherheiten bei
der Auswertung von Messungen, Beuth Verlag Berlin, 1985, an English translation is
available from the authors of [11].

[11] K. Weise and W. W¨oger, Meas. Sci. Technol. 3, 1 (1992).
[12] R. J. Barlow, Statistics (Wiley, Chichester, 1989).
[13] B. L. Welch and H. W. Peers, J. Royal Statist. Soc. B 25, 318 (1963).
[14] C. M. Stein, in Proc. Int. Research Seminar, Statistical Laboratory, University of Cali-
fornia, Berkley 1963, edited by J. Neyman and L. L. Cam (Springer, New York, 1965),
p. 217.

[15] C. Villegas, J. Amer. Statist. Assoc. 72, 453 (1977).
[16] C. Villegas, Ann. Statist. 9, 768 (1981).
[17] C. Villegas, J. Amer. Statist. Assoc. 85, 1159 (1990).
[18] W. Eadie et al., Statistical Methods in Experimental Physics (North Holland, Amster-

dam, 1971).

[19] T. Bayes, Phil. Trans. 53, 370 (1763), reprinted in Biometrica 45, 296 (1958).
[20] C. Villegas, J. Amer. Statist. Assoc. 72, 651 (1977).
[21] J. D. Bowman et al., Physical Review Letters 65, 1192 (1990).
[22] C. M. Frankle et al., Physical Review C 46, 778 (1992).
[23] X. Zhu et al., Physical Review C 46, 768 (1992).
[24] J. D. Bowman et al., preprint (unpublished).
[25] J. Hartigan, Ann. Math. Statist. 35, 836 (1964).

8

