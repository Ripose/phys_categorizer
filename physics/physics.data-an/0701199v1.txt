7
0
0
2
 
n
a
J
 
7
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
9
9
1
1
0
7
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Treatment of Errors in Eﬃciency Calculations

T. Ullrich and Z. Xu
Brookhaven National Laboratory

February 2, 2008

Abstract

In this report we discuss the treatment of statistical errors in cut ef-
ﬁciencies. The two commonly used methods for the calculation of the
errors, Poissonian and Binomial, are shown to be defective. We derive the
form of the underlying probability density function and characterize its
mean, mode, and variance. A method for the calculation of errors based
on the variance of the distribution is discussed.

1 Introduction

In many areas of experimental particle and nuclear physics the eﬃciencies of the
detectors used to record the particles is evaluated by Monte Carlo simulations.
These simulations usually incorporate a generator that produces particles and
events with known parameters and a detailed simulation of the detectors and
their respective response. The produced Monte Carlo data is then run through
the standard event reconstruction software and the result is compared to the
input from the generator. The ratio of output over input deﬁnes the so called
response function of the detector. This function is then used to correct the result
obtained from the reconstruction of the real data yielding the ﬁnal corrected
spectra. The response function depends in general on many parameters, e.g.,
transverse momentum and rapidity of the particle, event multiplicity and much
more.

From a statistics point of view this procedure can be simpliﬁed to the comparison
of two histograms. In histogram A, one plots the distribution of the quantity of
interest for all the data of the sample; in histogram B one plots the distribution
of the same quantity, but only for those satisfying the selection criteria, i.e.,
those data that pass the cuts.
Intuition leads one to expect that the best
estimate for the (unknown true) eﬃciency of the cut for each bin is just ki/ni ,
where ki is the number of entries in bin i of histogram B and ni is the number
of entries in bin i of histogram A.

But what uncertainty should be assigned to each eﬃciency? For simplicity of

1

notation, from here forward let us consider only a single bin, in which k events
out of a total of n events pass the cuts. To determine the errors in a histogram,
one merely applies the same rule independently to each bin i. Please note that
in the following we consider only statistical errors and ignore all aspects of
systematic errors.

2 Common but incorrect error evaluations

There are two frequently used, but incorrect, approaches to evaluate the errors
of the eﬃciency calculation. They are brieﬂy discussed below, before we turn
to the derivation of the correct treatment of the uncertainties.

2.1 Poissonian errors

Assuming that k and n ﬂuctuate independently, the Poisson distribution in the
large sample limit tells us that the error σk in k, the output sample, is √k, and
that the error σn in n, the input sample, is √n. Then, using standard error
propagation, and given the usual estimator for the real (unknown) eﬃciency

(1)

(2)

(3)

one ﬁnds for the variance:

E(ε) = ˆε =

k
n

.

V(ˆε) = σ2

ˆε = ˆε2

1
k

(cid:18)

+

1
n (cid:19)

This calculation is ﬂawed for various reasons:

•

n is a ﬁxed quantity and not subject to any ﬂuctuation. It’s usually a well
deﬁned and known input quantity. This reduces Eq. 2 to

V(ˆε) =

=

ˆε2
k

k
n2 .

•

•

Furthermore n and k are not independent but highly correlated. Statistics
tells us that k must be distributed according to a Binomial probability
density function.

Another strong argument against this method is the behavior in limiting
1 one ﬁnds ˆε = 0 and σˆε = 0. The
cases. In the case k = 0 and n
calculation is telling us that if we observe one event, and it fails the cut,
we know with complete certainty (zero error) that the eﬃciency is ex-
actly zero. This is a remarkable conclusion, which diﬀers greatly from our
intuition.

≥

Clearly equation 3 (and even more so 2) are in disagreement with our reasonable
expectations and basic statistics laws. We conclude that the Poissonian error
evaluation is incorrect and is not applicable in our case.

2

2.2 Binomial errors

Next let us consider a simple Binomial error calculation. This calculation is
based on the knowledge that the application of a cut (or cuts) can be considered
a Binomial process, with probability of “success” ε, the true eﬃciency. Given
this eﬃciency and the sample size n, the number of events passing the cut is
given by a Binomial distribution

P (k; ε, n) =

n
k(cid:19)

(cid:18)

εk(1

ε)n−k

−

(4)

(5)

with mean k = εn, and variance V(k) = σ2
ε). Using again the usual
estimator for ˆε = k/n, where n in our case is a given input constant we can
write down the variance for ˆε using simple error propagation:

k = nε(1

−

V(ˆε) = σ2

ˆε =

ˆε(1

ˆε)

k(n

k)

−
n

=

−
n3

However, this equation also yields absurd results in limiting cases.

1. In the case k = 0 we obtain an unphysical zero error as is the case in the

Poissonian error calculation (Eq. 3).

2. In the other limit, k = n, the formula again yields zero error.

In each case, this calculation claims perfect certainty for the measured eﬃciency.
Again, this violates our reasonable expectation.

In the next section, we now develop a calculation, based on the use of Bayes’
Theorem, that calculates the statistical uncertainty in the eﬃciency in a manner
that agrees with our intuition, and that exhibits reasonable behavior even in
limiting cases.

3 Correct treatment of errors

We start out again with the Binomial probability. P (k; ε, n) deﬁned in Eq. 4
denotes the probability that k events will pass the cut, given the conditions that
the true eﬃciency is ε, that there are n events in the sample, and that our prior
information tells us this is a Binomial process.

In our problem, we do not know ε; rather, we have our data, which is an
observation of k events out of n passing the cut. What we need to determine is
the probability density function P (ε; k, n), which gives the probability function
of ε for a given n and k. Once known, we can determine easily the mean,
variance, most probable value, and conﬁdence intervals, so that we can make
comparisons with some statistical meaning.

3

3.1 Derivation of the probability density function

In order to calculate we use the Bayesian theorem and make the following ansatz:

P (ε; k, n) =

P (k; ε, n) P (ε; n)
C

where C is a constant to be determined by normalization, and P (ε; n) is the
probability we assign for the true eﬃciency before we consider the data. Given
only n and the fact that we are dealing with a Binomial process says simply
that ε must be in the inclusive range 0
1; we would have no reason to
favor one value of the eﬃciency over another. Therefore it is reasonable to take

≤

≤

ε

P (ε; n) =

1 if 0
≤
0 otherwise

≤

ε

1

(cid:26)

independent of n. Probability theory allows us to include in our calculation the
knowledge that the eﬃciency must be between zero and one; this knowledge
is built into the predata probability distribution describing our knowledge of ε,
which assigns zero probability to those values of ε which we know, with certainty,
to be impossible.

To determine the normalization we must solve

+∞

Z

−∞

P (ε; k, n) dε =

1

1
C (cid:18)

n
k(cid:19) Z

0

εk(1

ε)n−kdε = 1

−

for C. For the calculation of the integral it is useful to recall the deﬁnition of
the Beta function:

B(α + 1, β + 1) =

xα(1

x)βdx =

1

Z
0

−

Γ(α + 1) Γ(β + 1)
Γ(α + β + 2)

.

Note also the trivial relation for integer values Γ(n + 1) = n!. Thus we directly
obtain

and the ﬁnal eﬃciency probability density function thus reads:

C =

n!
(n + 1)!

=

1
n + 1

P (ε; k, n) = (n + 1)

n
k(cid:19)

εk(1

ε)n−k

εk(1

ε)n−k

−

−

(cid:18)
(n + 1)!

k! (n

k)!

−

=

(6)

(7)

(8)

(9)

(10)

(11)

(12)

Figure 1 shows P (ε; k, n) for n = 10 and k = 0, 1, . . . , 10. Note that in all cases,
we assign zero probability that ε is below zero or above one. Note also that we
assign zero probability to ε = 0 unless k = 0; this is necessary, of course, since
if we observe even a single event which passes, we know the eﬃciency cannot be
zero. Similarly, we assign zero probability to ε = 1 unless k = n, since if even a
single event fails our cut, we know that the eﬃciency is not one.

4

n = 10

10

9

1

2

3

4

5

6

8

7

k = 0

)
n

 
,
k
 
;
ε
(
P

10

8

6

4

2

0

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1
ε

Figure 1: The probability density function P (ε; k, n) for n = 10 and k = 0, 1, . . . , 10.

3.2 Features of the probability density function

Given the analytic form we now can calculate the moments of the distribution.
For the mean we obtain, again using Eq. 9 to solve the integral:

1

ε =

ε P (ε; k, n) dε

Z
0
(n + 1)!

1

=

=

−

k! (n
k + 1
n + 2

εk+1(1

ε)n−kdε

k)! Z
0

−

The most probable value (the mode) mode(ε) can be easily calculated by solving
dP/dε = 0. We get:

This is a remarkable result. The common estimator of the real eﬃciency ˆε =
k/n actually is the mode and not the mean, i.e., the expectation value of the
distribution. The mean and the mode only become identical for n = 2k, and of

mode(ε) =

k
n

.

5

(13)

(14)

(15)

(16)

n = 100

100

)
n

 
,
k
 
;
ε
(
P

80

60

40

20

0

0

k = 0

100

10

20

30

40

50

60 70

90

80

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1
ε

Figure 2: The probability density function P (ε; k, n) for n = 100 and k =
0, 10, . . . , 100.

course in the limit of large n. As depicted in Fig. 1 the density functions are
skewed except for k = n/2 = 5.

What to use if only one measurement was made: mean or mode? Statistics
teaches us that an estimator cannot be described as ’right’ or ’wrong’ but only
as ’good’ or ’bad’. A good estimator has to be consistent, unbiased, and eﬃcient.
Clearly ˆε = k/n has these features, while (k + 1)/(n + 2) is biased for small n.
In practice, however, this diﬀerence can be neglected since in most cases n is
reasonably large. This is depicted in Fig. 2 for the case n = 100.

Let’s now turn to the original purpose of this exercise: the error evaluation.
The calculation of the variance V (ε) from P (ε; k, n) yields:

V (ε) = ε2

ε2

−
1
ε2 P (ε; k, n) dε

ε2

Z
0
(k + 1) (k + 2)
(n + 2) (n + 3) −

−
(k + 1)2
(n + 2)2 .

=

=

(17)

(18)

(19)

As expected V (ε) now behaves correctly in the two extreme cases; for k = 0

6

n = 10
k = 8
〈ε〉 = 0.75
εm.p.= 0.8
σ = 0.12

)
n
 
,
k
 
;
ε
(
P

3.5

2.5

4

3

2

1

1.5

0.5

0

0

εm.p.

〈ε〉

〈ε〉-σ 〈ε〉+σ

CL = 67.3%

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1
ε

Figure 3: Eﬃciency probability density function P (ε; 8, 10). The solid vertical line
depicts the mean value, the dashed line the most probable value. The gray shaded
region corresponds to plus/minus one standard deviation (Eq. 19) around the mean.

and k = n one ﬁnds

k=0,n =
V (ε)
|

n + 1
(n + 2)2 (n + 3)

> 0.

(20)

For large n in this case the variance becomes lim
n→∞

V (ε) = 1/n2.

Interestingly the mean and variance for n = 0 is non-zero. One ﬁnds ε = 1/2
n=0 = 1/12, which is simply the mean and variance of a uniform
and V (ε)
|
distribution in the interval from 0 to 1. This is a nice conﬁrmation of the
validity of our calculations. The case n = 0 essentially means that no prior
information on the eﬃciency is available and all we can say beforehand is that
the eﬃciency has to be between 0 and 1. Since no eﬃciency is more likely than
any other, the only assumption one can make is that of a uniform probability
density.

Figure 3 shows the probability density function for the case n = 10 and k = 8.
The vertical dashed and solid lines depict the mode and the mean, respectively.
In this case the region ε
V (ε) from Eq. 19, corresponds to a
conﬁdence level (CL) of 67.3%.

σ where σε =

±

p

7

3.3 Measure for the statistical error

There are many measures of the uncertainty that can be extracted from the
distribution P (ε; k, n): upper and lower limits at various conﬁdence levels; the
variance, or its square root, the standard deviation; the mean absolute devia-
tion; or conﬁdence intervals of various sorts. Whatever choice, the situation is
complicated by the fact that the function is (i) not symmetric and (ii) that the
integral over P (ε; k, n) is not analytic for limits other than 0 and 1.

There is no obvious recipe for cases where n is small and/or the eﬃciency found
is close to 0 or 100%. A reasonable measure is certainly the standard deviation
σε. The advantage of this approach is clearly that σε =
V (ε) can be easily
calculated from Eq. 19. In addition it turns out that the conﬁdence levels for
’common’ data sample sizes n and eﬃciencies are close to the “1σ” probability
content of the Gaussian distribution, i.e., 68.3%. This is of course no accident
but a consequence of the Central Limit Theorem. Note that in the limiting
cases, that is, small k, small n, or k close or equal to n, the conﬁdence level
deviates slightly from this value.

p

4 Acknowledgments

This report is the result of a discussion between the authors in the context of
data analysis for the STAR experiment at the Relativistic Heavy-Ion Collider
(RHIC) at BNL. After ﬁnalizing the calculations we discovered a writeup on this
very subject by Marc Paterno from University of Rochester (D0 Note 2861). In
this paper the author derives the same probability density function but does not
calculate mean, mode, and standard deviation. He concludes that conﬁdence
levels cannot be found analytically and refers to a numerical solution in the
form of a program.

8

