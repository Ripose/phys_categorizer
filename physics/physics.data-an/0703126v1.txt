7
0
0
2
 
r
a

M
 
2
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
6
2
1
3
0
7
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

The Laplace-Jaynes approach to induction

Being part II of

“From ‘plausibilities of plausibilities’ to state-assignment methods”

P. G. L. Porta Mana,∗ A. Månsson, G. Björk
Kungliga Tekniska Högskolan, Isafjordsgatan 22, SE-164 40 Stockholm, Sweden

(Dated: 12 March 2007)

Abstract

An approach to induction is presented, based on the idea of analysing the
context of a given problem into ‘circumstances’. This approach, fully Bayesian
in form and meaning, provides a complement or in some cases an alternative to
that based on de Finetti’s representation theorem and on the notion of inﬁnite
exchangeability. In particular, it gives an alternative interpretation of those for-
mulae that apparently involve ‘unknown probabilities’ or ‘propensities’. Vari-
ous advantages and applications of the presented approach are discussed, espe-
cially in comparison to that based on exchangeability. Generalisations are also
discussed.

PACS numbers: 02.50.Cw,02.50.Tt,01.70.+w
MSC numbers: 03B48,60G09,60A05

Note, to head oﬀ a common misconception, that this is
in no way to introduce a “probability of a probability”.
It is simply convenient to index our hypotheses by
parameters [. . . ] chosen to be numerically equal to the
probabilities assigned by those hypotheses; this avoids
a doubling of our notation. We could easily restate
everything so that the misconception could not arise; it
would only be rather clumsy notationally and tedious
verbally.

E. T. Jaynes, Monkeys, kangaroos, and N [1], p. 12

1 Dramatis personae, notatio, atque philosophia

We continue here our exploration of the notion of ‘circumstance’ and of its applica-
tions in plausibility theory. Through this notion we shall here approach no less than

∗Email: mana@kth.se

1

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

the question of induction, i.e., of the prediction of unobserved evens from knowl-
edge of observed (similar) ones. The study can be read independently of the previous
one [2], although the two elucidate each other.

The following characters appear in this study:
The ‘de Finettian’: a scholar who conceives probability as ‘degree of belief’,
pedantically insisting on the subjective nature of all plausibility assignments, and
through the notion of inﬁnite exchangeability makes sense of the frequentist’s and
propensitor’s voodooistic practises. The views and tools of this scholar [e.g., 3, 4, 5,
6, 7, 8, 9, 10, 11] are supposed known to the reader.

The ‘propensitor’: a scholar who conceives of a ‘physical disposition’ of some
phenomena to occur with deﬁnite relative frequencies, and call this physical charac-
teristic ‘propensity’. This scholar sometimes makes inferences about propensities by
means of probability as degree of belief.

The ‘frequentist’: a scholar who conceives probability as ‘limit relative fre-
quency’ of a series of ‘trials’ (or something like that). Frequentists are often propen-
sitors at heart.

The ‘plausibilist’ or ‘probability logician’, who in this study will be your humble
narrator: a scholar who conceives of probability as a formalisation and schematisa-
tion of the everyday notions of ‘plausibility’ and ‘probability’ — just as truth in for-
mal logic is such a formalisation and schematisation of the everyday notion of ‘truth’
— and does not dwell more than so in its meaning. The views of this scholar are a dis-
tillate of the philosophies and views and/or the works of Laplace [12], Johnson [13],
Jeﬀreys [14, 15, 16], Cox [17, 18], Jaynes [19, 20, 21], Tribus [22], de Finetti [6, 7],
Adams [23, 24], Hailperin [25], and others [e.g., 11, 26, 27, 28, 29, 30, 31, 32, 33,
34, 35, 36, 37, 38, 39].

Plausibilists agree with de Finettians on basically all points. The only diﬀerence
is in emphasis: although they recognise the ‘subjective’ character of initial plausibil-
ity assignments — i.e., that these are matter of convention —, they also think that
it is not such a big deal. It should in any case be no concern of plausibility theory,
which is ‘impersonal in the same sense as in ordinary logic: that diﬀerent people
starting from the same [assignments] would get the same answers if they followed
the rules’ (Jeﬀreys [16], reinterpreted). This will surely be self-evident when plausi-
bility theory will reach its maturity, just as it is self-evident in formal logic today. In
fact, the same subjective, conventional character is present — no more, no less — in
formal logic as regards the initial truth assignments, those which are usually called
‘axioms’ or ‘postulates’. Albeit in formal logic there is perhaps less place for dis-
agreement amongst people about initial truth assignments, the possible choice being
there between ‘true’ and ‘false’, or ‘0’ and ‘1’ only — and not amongst a continuum
of possibilities [0, 1] as in plausibility theory.

The above remark is not meant to diminish the historical importance of de Fi-
netti’s Nietzschean work in plausibility theory. Emphasis on subjectivity may still be
necessary sometimes. In this study we shall also use terms like ‘judgement’ to this
purpose.

The following notation will be used:

2

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

P(A| B) denotes the plausibility of the proposition A conditional on B or, as we
shall also say, in the context B. The proposition B, is supposed to express all knowl-
edge (including beliefs), data, and ‘working hypotheses’ on the grounds of which
we make the plausibility assignment to A. We are intransigent as regards the ne-
cessity and appropriateness of always specifying the context of a plausibility (as
well as that of a truth!),1 a point also stressed by Jeﬀreys [14, 15], Cox [17, 18],
Jaynes [19, 20, 21], Tribus [22], de Finetti [47, § 4], Hájek [48], and apparently
Keynes [26].

The remaining notation follows ISO [49] and ANSI/IEEE [50] standards.

2 General setting of the question

The question that we are going to touch is, in very general terms, that of induction: In
a given situation, given a collection of observations of particular events, assign the
plausibility for another collection of unobserved events. Note that temporal distinc-
tions are not relevant (we did not say ‘past’ or ‘future’ events) and we shall not make
any. Of course, in stating this general question we have in mind ‘similar’ events.2 So
let us call these events ‘instances of the same phenomenon’, following de Finetti’s
appropriate terminology [3, 4, 47]. We also suppose to know that each such instance
can ‘manifest itself’ in a constant (and known) number of mutually exclusive and
exhaustive ‘forms’, and there is a clear similarity between the forms of each instance
(that is one of the reasons we call the events ‘similar’).

All this can be restated and made more concrete using a terminology that is nearer
to physics; but we must keep in mind that the setting has not therefore become less
general. We call the phenomenon a ‘measurement’,3 and its instances ‘measurement
instances’. The forms will be called ‘(measurement) outcomes’. We can ﬁnally
state our question thus: In a given situation, given the observed outcomes of some
instances of a particular measurement, assign the plausibility for the unobserved
outcomes of some other instances of that measurement.

We represent the situation, measurements, etc. by propositions. The situation
by I, the measurement instances by M( j), the outcomes of the jth instance by R( j)
i
(diﬀerent instances of the same outcome are those with diﬀerent j but identical i).
Instances are thus generally denoted by an index ( j) with j = 1, 2, . . . ; its range may
be inﬁnite or ﬁnite, a detail that will be always speciﬁed as it will be very important in
later discussions. Other propositions will be introduced and deﬁned later. With this
representation, our question above simply becomes the assignment of the plausibility

P(R( jN+L)
iN+L

∧ · · · ∧ R( jN+1)
iN+1
for all possible distinct ja, distinct ia, N > 0, and L > 0.

| M( jN+L) ∧ · · · ∧ M( jN+1) ∧ R( jN )

iN

∧ · · · ∧ R( j1)
i1

∧ I)

(1)

1The context may also have a clarifying rôle in formal logic. Cf. e.g. the studies by Adams [23, 24,

40], Lewis [41, 42], Hailperin [25, 43], Barwise [44, 45], and Gaifman [46].

2But ‘similar’ in which sense? The answer to this question cannot be given by plausibility theory,

but can be formalised within it, as shown later.

3Even more appropriate, but too long, would be ‘measurement scheme’.

3

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

If you are wondering what those M( j) are doing in
A more convenient notation.
the context of the plausibility, consider that the plausibility of observing a particu-
lar outcome at the j instance of a measurement is, in general, the plausibility of the
outcome given that the measurement is made, times the plausibility that the mea-
surement is made (if the latter is not made the outcome has nought plausibility by
deﬁnition):

P(R| I) = P(R| M ∧ I) P(M| I) + P(R| ¬M ∧ I) P(¬M| I),

= P(R| M ∧ I) P(M| I).

But of course when we ask for the plausibility of an outcome we implicitly mean:
given that the corresponding measurement is or will be made. We assume that knowl-
edge of an outcome implies knowledge that the corresponding measurement has been
made — symbolically, P(M( j′)| R( j′′) ∧ I) = 1 if j′ = j′′ — hence there is no need
of specify in the context the measurements of those outcomes that are already in the
context. But the necessity remains of explicitly writing in the context the measure-
ments of the outcomes outside the context. This can sometimes be notationally very
cumbersome, and therefore we introduce the symbol M with the following conven-
tion: M, in the context of a plausibility, always stands for the conjunction of all
measurement instances M( j) corresponding to the outcomes on the left of the condi-
tional symbol ‘|’. Thus, e.g.,

P(R(7)
5

∧ R(3)

1 | M ∧ R(2)

8 ∧ I) ≡ P(R(7)

5

∧ R(3)

1 | M(7) ∧ M(3) ∧ R(2)

8 ∧ I).

Note that M has not a constant value (it is in a sense a metavariable); we indicate this
by the use of a diﬀerent typeface (Euler Fraktur).

With the new notational convention the plausibility (1) can be rewritten as

P(R( jN+L)
iN+L

∧ · · · ∧ R( jN+1)
iN+1

| M ∧ R( jN )

iN

∧ · · · ∧ R( j1)
i1

∧ I).

(1)r

3 The approach through inﬁnite exchangeability

The propensitor (and, roughly in the same way, the frequentist as well) approaches
the question of assigning a value to (1) by supposing that the outcome instances (‘tri-
als’) are ‘i.i.d.’: that they are independently ‘produced’ with constant but ‘unknown’
propensities. As N in (1) becomes large, the relative frequencies of the outcomes
must tend to the numerical values of the propensities. These frequencies can then be
used as ‘estimates’ of the propensities, and so the estimated propensity for outcome
Ri at an additional measurement instance can be given. This summary surely appears
laconic to readers that have superﬁcial knowledge of this practise. But this does not
matter: it is the approach of the de Finettian that interests us.4 Recall that for the

4There are authors who apparently keep a foot in both camps; see e.g. Lindley and Phillips’ arti-

cle [51]

4

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

de Finettian, and for the Bayesian in general, ‘probability’ is not a physical concept
like ‘pressure’, but a logical (and subjective) one like ‘truth’. To mark this diﬀerence
in concept we are using the term plausibility, which has a more logical and subjective
sound.

How would a de Finettian approach the problem above? More or less as follows:

[A ﬁctive de Finettian speaking:] ‘Before I know of any measurement outcomes,
I imagine all possible inﬁnite collections of instances of the measurement M. Let
us suppose that I judge two collections that have the same frequencies of outcomes
to have also the same probability. The probability distribution that I assign to the
inﬁnite collections of outcomes is therefore symmetric with respect to exchanges
of collections having the same frequencies. Such a distribution is called inﬁnitely
exchangeable. De Finetti’s representation theorem [4, 5, 6, 7, 8, 9, 10, 11, 52] (see
also [13, 53, 54]) says that any L-outcome marginal of such distribution, where the
outcomes {Ri} appear with relative frequencies ¯L ≡ (Li), can be uniquely written in
the following form:

P(R( jL)
iL
               

∧ · · · ∧ R( j1)
i1
               

| M ∧ I) =

qLi
i

(cid:17)

Z (cid:16)Q

i

R1 appears L1 times, etc.
|
}
{z

Γ( ¯q| I) d ¯q,

(2)

where ¯q ≡ (qi) are just parameters — not probabilities! — satisfying the same posi-
tivity and normalisation conditions (qi > 0,
i qi = 1) as a probability distribution,
and ¯q 7→ Γ( ¯q| I) is a positive and normalised generalised function [55, 56, 57] (see
also [58]), which can be called the generating function of the representation [cf. 52].
Example: I can write the probability of a collection of three measurement instances
with two outcomes R5 and one R8 as

P

P(R( j1)
5

∧ R( j2)
5

∧ R( j3)
8

| M ∧ I) =

q5

2 q8 Γ( ¯q| I) d ¯q.

Z

In particular, the probability for the outcome i in the whatever measurement instance
j can be written as

P(R( j)
i

| M( j) ∧ I) =

qi Γ( ¯q| I) d ¯q.

Z

(3)

A propensitor or a frequentist would say that the right-hand side of eq. (2) represents
the fact that the outcome instances are “independent” (therefore “their probabilities
qi are simply multiplied to give the probability of their conjunction”), “identically
distributed” (therefore “the probability distributions q is the same for all instances”),
and moreover “their probability is unknown” (therefore “the expectation integral over
all possible probability distributions ¯q”). But de Finetti’s theorem shows that all these
mathematical features are simply consequences of inﬁnite exchangeability, and we
do not need any “i.i.d.” terminology.

‘The generating function ¯q 7→ Γ( ¯q| I) is, by de Finetti’s theorem, equal to the

limit

Γ( ¯q| I) d ¯q = lim
L→∞

P

(cid:18)

‘All possible collections of L outcomes with
frequencies in the range ]Lqi, L(qi + dqi)[’

M ∧ I

,

(4)

(cid:19)

(cid:12)(cid:12)(cid:12)

5

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

i.e., Γ( ¯q| I) is equal to the probability — assigned by me — that my imagined inﬁnite
collection of outcomes has limiting relative frequencies equal to (qi). My exchange-
able probability assignment determines thus Γ uniquely. But de Finetti’s theorem
also says the converse, viz., any positive and normalisable Γ uniquely determines
an inﬁnitely exchangeable probability distribution. This allows me to specify my
probability assignment by giving the function Γ instead of the more cumbersome
probability distribution for inﬁnite collections of outcomes.

‘Let us suppose that I am now given a collection of N measurement outcomes,
and in particular their absolute frequencies ¯N ≡ (Ni). Given this evidence, the proba-
bility for a collection of further L unobserved measurement outcomes with frequen-
cies (Li) is provided by the basic rules of probability theory:

P(R( jN+L)
iN+L
                     

∧ · · · ∧ R( jN+1)
iN+1
                     

| M ∧ R( jN )

Ri appears Li times
{z

}

|

∧ I) =

∧ · · · ∧ R( j1)
iN
i1
                
                
Ri appears Ni times
{z
∧ · · · ∧ R( jN+1)
∧ R( jN )
iN+1
iN
∧ · · · ∧ R( j1)
P(R( jN )
i1
iN

}

|
P(R( jN+L)
iN+L

∧ · · · ∧ R( j1)
i1

| M ∧ I)

.

(5)

| M ∧ I)

Using de Finetti’s representation theorem again, this probability can also be written
as

P(R( jN+L)
iN+L

∧ · · · ∧ R( jN+1)

| M ∧ R( jN )

iN+1

iN

∧ I) =

∧ · · · ∧ R( j1)
i1
qLi
i

Z (cid:16)Q
The function ¯q 7→ Γ( ¯q| R( jN )
∧ · · · ∧ R( j1)
∧ I) is diﬀerent from the previous one
i1
¯q 7→ Γ( ¯q| I), but the two can be shown [e.g., 11] to be related by the remarkable
formula

iN

(cid:17)

i

Γ( ¯q| R( jN )

∧ · · · ∧ R( j1)

∧ I) d ¯q.

(6)

iN

i1

Γ( ¯q| R( jN )

iN

∧ · · · ∧ R( j1)
i1

∧ I) =

qN j
j

qN j
j

(cid:17)

j
(cid:16)Q

j
R (cid:16)Q

Γ( ¯q| I)

(cid:17)
Γ( ¯q| I) d ¯q

,

which is formally identical with Bayes’ theorem if we deﬁne

Γ(R( j1)
i1

∧ R( j2)
i2

∧ · · · ∧ R( jL)
iL

| ¯q, I) ≔ qi1 qi2 · · · qiL

for all L, ia, and distinct ja,

(8)

which includes in particular

Γ(R( j)
i

| ¯q, I) ≔ qi

for all j.

(Note that these are only formal deﬁnitions and not probability judgements, since the
various Γs are not probability distributions.) Thus I can not only specify my inﬁnitely

(7)

(9)

6

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

exchangeable distribution by Γ, but also update it by ‘updating’ Γ. Moreover, for N
enough large this function has the limit

∧ I) ≃ δ

as N → ∞.

(10)

Γ( ¯q| R( jN )

∧ · · · ∧ R( j1)
i1
iN
                
                
Ri appears Ni times
{z

}

|

Comparing with eq. (3), this means that

P(R( jN+1)
i

| M( jN+1) ∧ R( jN )

∧ I) ≃

as N → ∞ (with j , ja),

(11)

¯N
N − ¯q
(cid:17)

(cid:16)

Ni
N

∧ · · · ∧ R( j1)
iN
i1
                
                
Ri appears Ni times
{z

}

|

i.e., the probability I assign to an unobserved outcome gets very near to its observed
relative frequency, as observations accumulate. This also means that two persons
having diﬀerent but compatible initial beliefs (i.e., diﬀerent initial exchangeable dis-
tributions having the same support) and sharing the same data, tend to converge to
similar probability assignments.’

The point of view summarised above by the de Finettian is quite powerful. It
allows the de Finettian to make sense, without the need of bringing along ugly or
meaningless metaphysical concepts, of those mathematical expressions very often
used by propensitors (and frequentists as well) that are formally identical to formu-
lae (3) (‘expected propensity’ or ‘estimation of unknown probability’), (4) (‘proba-
bility as limit frequency’), (8) (deﬁnition of ‘propensity’), (11) (‘probability equal to
past frequency’). This point of view and the notion of exchangeability can moreover
be generalised to more complex situations [5, 8, 9, 10, 52, 59, 60, 61][cf. also 62],
leading to other powerful mathematical expressions and techniques.

4 Why a complementary approach?

We shall presently present and discuss another approach, not based on exchangeabil-
ity or representation theorems, that can be used to give an answer to the question
of induction, and to make sense of the propensitors’ and frequentists’ formulae and
practise as well. Why did we seek an approach diﬀerent from that based on inﬁnite
exchangeability? Here are some reasons:

(a) One sometimes feels ‘uncertain’, so to speak, about one’s plausibility as-
signment. One can also say that some plausibility assignments feel sometimes more
‘stable’ than others. This is lively exempliﬁed by Jaynes [21, ch. 18]:

Suppose you have a penny and you are allowed to examine it carefully,
convince yourself that it’s an honest coin; i.e. accurately round, with head
and tail, and a center of gravity where it ought to be. Then, you’re asked to
assign a probability that this coin will come up heads on the ﬁrst toss. I’m
sure you’ll say 1/2. Now, suppose you are asked to assign a probability to
the proposition that there was once life on Mars. Well, I don’t know what

7

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

your opinion is there, but on the basis of all the things that I have read
on the subject, I would again say about 1/2 for the probability. But, even
though I have assigned the same “external” probabilities to them, I have a
very diﬀerent “internal” state of knowledge about those propositions.

To see this, imagine the eﬀect of getting new information. Suppose
we tossed the coin ﬁve times and it comes up tails every time. You ask
me what’s my probability for heads on the next throw; I’ll still say 1/2.
But if you tell me one more fact about Mars, I’m ready to change my
probability assignment completely. There is something which makes my
state of belief very stable in the case of the penny, but very unstable in the
case of Mars.

An example similar to the Martian one is that of a trickster’s coin, which always
comes up heads or always tails (either because the coin is two-headed or two-tailed,
or because of the tosser’s skills). Not knowing which way the tosses are biased, you
assign 1/2 that the coin will come up heads on the ﬁrst observed toss. But as soon
as you see the outcome, your plausibility assignment for the next toss will collapse5
to 1 or 0. The ‘uncertainty’ in the plausibility assignments given to the penny and
to the trickster coin’s toss could be qualitatively pictured as in Fig. 1. We think
that this ‘uncertainty’ in the plausibility assignment — or better, as Jaynes calls it,
this ‘diﬀerence in the internal state of knowledge’ with regard to the propositions
involved, is a familiar and undeniable feeling. There is in fact a rich literature which
tries to take it into account by exploring or even proposing alternative plausibility
theories based on probability intervals or probabilities of probabilities (see e.g. [63,
64][62, esp. § 3.1] and cf. [65, § 2.2][66, 67]).

(b) A plausibility assignment, according to de Finetti’s approach, begins with
a judgement of exchangeability. One is not concerned within the formalism itself
with the motivation of such a judgement (de Finetti recognises that there usually
is a motivation, but it is relegated to the informal meta-theoretical considerations).
Yet such judgements are often grounded, especially in natural philosophy, on very
important6 reasonings and motivations which one would like to analyse by means of
plausibility theory.7

(c) When the maximum number of possible observations (measurements) is ﬁ-
nite and small it does not make sense to make a judgement of inﬁnite exchangeability,
not even as an approximation (cf. [9][11, § 4.7.1]). De Finettians can in this case use
ﬁnite exchangeability [9, 10], but then they cannot make sense of the propensitor’s
formulae like (3) or (8), which the propensitor, however, is still entitled to use even
in this case.

5Just like a quantum-mechanical wave-function.
6And, trivially, subjective.
7In a way there is a point in Good’s statement [65, ch. 3] ‘it seems to me that one would not
accept the [exchangeability assumption] unless one already had the notion of physical probability and
(approximate) statistical independence at the back of one’s mind’, although there is no need to bring
‘physical probabilities’ and ‘statistical independence’ along.

8

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

0

0.2

0.4

0.6

0.8

1

PH‘heads’L

Figure 1: Qualitative illustration of the ‘uncertainty’ in the plausibility assignments
for ‘heads’ in the case of a fair coin-toss (blue dashed curve, with maximum at 1/2)
and the toss of a trickster’s coin (orange continuous curve, with maxima at 0 and 1).
The illustration is made quantitative in § 6.2.

(d) Finally, another important reason is that the generalisation of de Finetti’s the-
orem studied by Caves, Fuchs, and Schack [68, 69, 70, 71] fails for some physical sta-
tistical models, viz. quantum mechanics on real and quaternionic Hilbert space. We
consider this failure not as a sign that complex quantum theory is somehow ‘blessed’,
but rather as a sign that either the theorem can be generalised in some other way that
holds in any physical statistical model, or de Finetti’s approach can be substituted or
complemented by another one whose generalisation applies to any physical statisti-
cal model whatever. The point here is that de Finetti’s theorem — just like the whole
of plausibility theory — belongs to the realm of logic, not physics, and thus should
apply to any conceivable physical theory that be logically consistent, even one that
does not describe actual phenomena.

The alternative point of view to be presented meets all the points raised above:
(a) It allows us to formalise within plausibility theory — i.e., without resorting to
interval-valued plausibilities and the like — the intuitive notion of ‘uncertainty’ of a
plausibility assignment, and even to quantify it. (b) It stems directly from an analysis
of the conditions in which judgements of exchangeability usually originate and apply.
(c) It can be used to interpret the propensitor’s practise when the maximum number
of possible observations is ﬁnite and small. (d) It readily generalises to any logically
consistent physical statistical model, whether it apply to actual phenomena or not;
in particular, within quantum theory it easily applies to such problems as quantum-

9

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

state assignment, quantum-state ‘teleportation’, and others that involve the notion of
‘unknown quantum state’.

This point of view, which we shall call the ‘Laplace-Jaynes approach’, stems
from a re-reading and possibly a re-interpretation of Jaynes [1, esp. pp. 11, 12, 15]
(cf. also [19, lect. 18][20, lect. 5][21, ch. 18]), Laplace [72], and de Finetti [3, § 20]
(cf. also Caves [73]) and is strictly related to the ‘approach through circumstances’
presented in the previous paper [2].

It cannot be too strongly emphasised that this point of view is fully in line with
plausibility theory, Bayesian theory, and de Finetti’s point of view: Some plausibili-
ties with particular properties will be introduced, based on particular judgements; but
the acceptance or not of the latter is, as with judgements of exchangeability, always
up to the individuals and their knowledge.

We now present this ‘Laplace-Jaynes approach’ and show how it can be used
for the question of induction in a manner parallel to the approach through inﬁnite
exchangeability. We shall then discuss how it meets points a, b, c above (not neces-
sarily in that order). The discussion of the fourth point is left to the next study of this
series [74].

5 The Laplace-Jaynes approach

5.1

Introducing a set of circumstances

5 ∧ R(4)

7 | M ∧ I) as equal.

7 | M ∧ I) and P(R(4)

With the notation and the general settings of the introduction, let us recapitulate
how we reason and proceed in the case of exchangeability. The situation I leads
us to assign an inﬁnitely exchangeable plausibility distribution to the collection of
measurement outcomes. In other words, I is such that we consider two plausibilities
5 ∧ R(2)
like e.g. P(R(2)
In § 4, point (b), we remarked that the approach through exchangeability is not
formally concerned about those details of the situation which lead us to see a sort
of analogy ar similarity amongst diﬀerent measurement and outcome instances and
thence make a judgement of exchangeability. Rather, the whole point is that this
similarity is expressed by, or reﬂected in, the exchangeable plausibility assignment.
As de Finetti says, ‘Our reasoning will only bring in the events, that is to say, the
trials, each taken individually; the analogy of the events does not enter into the chain
of reasoning in its own right but only to the degree and in the sense that it can inﬂu-
ence in some way the judgment of an individual on the probabilities in question’ [4,
p. 120]. And also:

What are sometimes called repetitions or trials8 of the same event are for
us distinct events. They have, in general, some common characteristics
or symmetries which make it natural to attribute to them equal proba-
bilities, but we do not admit any a priori reason which prevents us in

8And what we call here instances (Authors’ Note).

10

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

principle from attributing to each of these trials [. . . ] some diﬀerent and
absolutely arbitrary probabilities [. . . ]. In principle there is no diﬀerence
for us between this case and the case of n events which are not analo-
gous to each other; the analogy which suggests the name “trials of the
same event” (we would say “of the same phenomenon”) is not at all es-
sential, but, at the most, valuable because of the inﬂuence it can exert on
our psychological judgment in the sense of making us attribute equal or
very nearly equal probabilities to the diﬀerent events.’ [4, p. 113, foot-
note 1]

But although we agree on this terminology and its motivation, we do not agree
on the unqualiﬁed and indiscriminate diminution of the importance of the similarity
amongst measurement instances. Such similarity, especially in the natural sciences,
often stems from or is traced back to similarities at deeper9 levels of analysis and
observation. It is by this process that natural philosophy proceeds.

So let us suppose that the considerations that lead us to a probability assignment
for various measurement instances can be analysed — and formalised — at a deeper
level.10 More precisely, we suppose to have identiﬁed for each measurement instance
j a set of diverse possible ‘circumstances’ {C( j)
: k = 1, . . . } — all these sets having
k
the same cardinality — with the following properties:

I. The ﬁrst involves the plausibilities we assign to the circumstances:

for all k and all D representing conjunc-
tions of measurements (but not of out-
comes!) from the same or other instances,

(I)

P(C( j)
k

| D ∧ I) = P(C( j)
k

| I)

k′′ | I) = 0

P(C( j)

k′ ∧ C( j)
C( j)
=
k | I

P

k
(cid:0)W

(cid:1)

k
P

if k′ , k′′,

P(C( j)

k | I) = 1,

i.e., we judge the {C( j)
k } to be mutually exclusive and exhaustive, or in other
words we are certain that one of them holds, but we do not know which. More-
over, we judge any knowledge of measurement instances (but not of outcome
instances) as irrelevant for assessing the plausibilities of these circumstances,
or in other words, simply knowing that a measurement is made does not give us
clues as to the exact circumstance in which it is made.11

9We do not mean ‘microscopic’.
10Using, once more, words by de Finetti: ‘we enlarge the analysis to include our state of mind in
relation to other events, from which it might or might not be independent and by which, consequently,
it will or will not be modiﬁed if they occur, or if we learn of their occurrence’ [75, § 28].

11This assumption can be relaxed.

11

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

II. The second involves the plausibility distribution we assign to the outcomes,

conditional on knowledge of a circumstance:

P(R( j)
i

k ∧ I) = P(R( j)

| M( j) ∧ D ∧ C( j)
for all j, i, k, and all D representing a conjunction of measurements,
measurement outcomes, and circumstances of instances diﬀerent
from j,

| M( j) ∧ C( j)

k ∧ I)

i

(II)

which means that if we were certain about any circumstance C( j)
for the in-
k
stance j we should judge knowledge of any data concerning other instances as
irrelevant for the assessment of the plausibility of the outcome of instance j.
(The expression above is undeﬁned if C( j)
k happens to be inconsistent with D,
i.e. if P(D| M ∧ C( j)
∧ I) = 0; but this will not cause problems in the following
k
analysis.)

III. The third property concerns the relationships amongst our plausibility assign-

ments for the outcomes in diﬀerent instances:

i

P(R( j′)
i

for all j′, j′′,

| M( j′) ∧C( j′)

| M( j′′) ∧C( j′′)

k ∧I) = P(R( j′′)
k ∧I) ≕ qik, (III)
which expresses the fact that we see a similarity between outcomes and circum-
stances of diﬀerent instances, like when we say ‘the same outcome’, ‘the same
measurement’, or ‘the same circumstance’.
It is thanks to this property that
we can often drop the instance index ‘( j)’ and make sense of expressions like
‘P(Ri| M ∧ Ck ∧ I)’, which can stand generically for
P(Ri| M ∧ Ck ∧ I) ≔ P(R( j)
| M( j) ∧ C( j)
i

for any j,

k ∧ I)

(12)

≡ qik.

In the following, expressions like ‘P(Ri| M ∧ Ck ∧ I)’ will be understood in the
above sense.

IV. The fourth property strengthen the similarity amongst instances, and is the one

that makes induction possible:
| C( j′′)

P(C( j′)
k′

k′′ ∧ I) = δk′ k′′

for all j′, j′′.

(IV)

This means that we believe that if a particular circumstance holds in a particular
instance, then the ‘same’ circumstance (in the sense of (III) and (IV)) holds in
all other instances. This property implies (and, with the help of (I), is implied
by) the following:

for all j and k,

P(C( j)

k | I) = P(

C(l)
k | I) ≕ γk

l
V

for some γk; and

(13)

(14)

C(l)
kl

| I) =

P(

l
V

γk

0


12

if kl = k for all l,
otherwise,

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

i.e., the plausibility that we assign to the jth instance of the kth circumstance
is equal to that assigned to the collection consisting exclusively of ‘repetitions’
of the kth circumstance. Collections consisting of non-corresponding circum-
stances have nought plausibility. This allows us to deﬁne

P(Ck| I) ≔ P(

k | I),

lC(l)
≡ P(C( j)
V
k | I)
≡ γk,

for any j,

(15)

(16)

and

Ck ≔

C(l)
k .

l
V
Thanks to the deﬁnitions above the expression ‘P(Ck| I)’ can be used to unam-
biguously denote the plausibility that ‘the “same” circumstance ‘Ck’ holds in
all measurement instances’.

Note that in all the properties above the number of instances (i.e., the range of j) can
be either inﬁnite or ﬁnite.

Before further commenting the above properties, let us try to partially answer
the question: what are these ‘circumstances’? The most general and precise answer
is: they are whatever (propositions concerning) facts you like that make you assign
plausibilities satisfying properties (I)–(IV). No more than this would really need be
said. But we can emphatically add that the circumstances need not concern ‘mecha-
nisms’, ‘causes’, ‘microscopic conditions’, or the like; and that they do not12 concern
‘unknown probabilities’.13 They concern details of the context that are unknown, but
that (we judge) would have a great weight in our plausibility assignment for the {R( j)
i }
if we only knew them; so great a weight as to render (practically) unimportant any
knowledge of the details of other measurement instances. As for the choice of such
details, we have complete freedom. A trivial example: the tosses of a coin which we
have not examined, but which we know for sure to be two-headed or two-tailed. In
this case the propositions ‘Coin is two-headed (at toss j)’ and ‘Coin is two-tailed (at
toss j)’ form, for each j, a set of circumstances that satisfy property (I). But we also
know that the coin is the same at all tosses, which implies property (IV); hence we
can omit the speciﬁcation ‘(at toss j)’ without confusion. If we knew that the coin
was two-headed (at toss j) we should assign unit plausibility to heads for all future
or past tosses, i.e.,

P(‘Heads at toss j’| M ∧ ‘Coin is two-headed (at toss j)’ ∧ I) = 1 for all j,

12Cannot, in a logical sense; cf. Remark 2 in [2].
13But the circumstances may concern ‘propensities’, if the latter are intended as sorts of (ugly)
physical concepts. This possibility is due to the generality of plausibility theory which, like classical
logic, does not forbid you to bring along and reason about unreal or even preposterous concepts and
entities, like ‘nagas’ [76], ‘valier’ [77], ‘propensities’, and ‘wave-particles’, provided you do it in a
self-consistent way.

13

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

and we should consider knowledge of the outcomes of other tosses as irrelevant.14 An
analogous discussion holds for the two-tails possibility. Thus properties (II) and (III)
are also satisﬁed.

This was an extreme example, for the plausibilities conditional on the circum-
stances were nought or one. But it needs not be so: other circumstances could lead
to less extreme conditional plausibility judgements. In general, remaining within the
coin toss example, we could ask: By which method is the coin tossed? What are its
physical characteristics (two-headedness, centre-of-mass position, elastic and rigid
properties, etc.)? Upon what is it tossed? Who tosses it?15 Can there be any symme-
tries in my state of knowledge in respect of the situation? What are the consequences
of the toss or of the outcomes? — and a set of circumstances could be distilled from
the possible answers to these and other questions. Note in particular, with regard to
the last two questions, that a circumstance may be a judgement of symmetry or may
also be a consequence, in some sense, of the outcomes. Such kinds of circumstances
are perfectly ﬁne as long as they lead you to make a plausibility assignment on the
outcomes and satisfy the properties (I)–(IV). This emphasises again the fact that a
circumstance needs not be a sort of ‘mechanism’ or ‘cause’ of the measurements or
of the outcomes. Note also that properties (I) and (IV) determine neither the plausi-
k | I) nor the P(R( j)
bilities P(C( j)
k ∧ I). These plausibilities are, a de Finettian
i
would say, ‘fully subjective’.

| M( j) ∧C( j)

By properties (II) and (III) we can interpret and give a meaning to the locution ‘in-
dependent and identically distributed events’. Such locution means only that we are
entertaining some circumstances that, according to our judgement, render the con-
ditional plausibilities of corresponding outcomes of diﬀerent measurement instances
equal, so that we need not specify the particular instance (‘identically distributed’);
and render knowledge of outcomes of other instances irrelevant, so that we can spec-
ify the conditional plausibility for an outcome independently of the knowledge of
other outcomes (‘independent’). The locutions ‘unknown probability’ and ‘probabil-
ity of a probability’ will also be interpreted in a moment (§ 5.3).

5.2 Approaching the problem of induction through a set of

circumstances

How do we face the question of induction with these ‘circumstances’ and the as-
sumptions that accompany them? We answer this question in two steps.

Having introduced sets of circumstances {C( j)

k }, we must assign (subjectively, a

14Because we can but expect all tosses to give heads. Note that if a toss has given or will give tails,
this signals a contradiction in our knowledge. I.e., some of the data we have (about the coin or about
toss outcomes) have to be mendacious. But this is a problem that does not concern plausibility theory.
Like logic, it can give sensible answers only if the premises we put in are not inconsistent.

15See Jaynes’ insightful and entertaining discussion [21, ch. 10] on these kinds of factors.

14

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

de Finettian would say) for all i and k the plausibilities

P(Ri| M ∧ Ck ∧ I) ≡ qik

P(Ck| I) ≡ γk

(≔ P(R( j)
i
(≔ P(

| M( j) ∧ C( j)
k | I) ≡ P(C( j)
lC(l)

k ∧ I) for any j),
k | I) for any j),

(17)

(18)

V
in the sense of eqs. (12) and (15). It is then a simple consequence of the rules of plau-
sibility theory, together with the properties and deﬁnitions of the previous sections,
that the plausibility we assign to any collection of measurement outcomes is given
by

P(R( jL)
iL
               

∧ · · · ∧ R( j1)
i1
               

| M ∧ I) =

R1 appears L1 times, etc.
}
|
{z
i
Xk hQ

P(Ri| M ∧ Ck ∧ I)Li

P(Ck| I) ≡

P(Ck| I).

(19)

i

qLi
ik

(cid:17)

i
Xk (cid:16)Q

Note how this plausibility assignment depends only on the frequencies (Li) of the
outcomes: it is an (inﬁnitely) exchangeable assignment — although exchangeability
was not our starting assumption.

Let us suppose that we are now given a collection of N measurement outcomes,
and in particular their absolute frequencies ¯N ≡ (Ni). Given this evidence, the plausi-
bility for a collection of outcomes, with frequencies (Li), of further L measurements
is also derived by the basic rules of plausibility theory, from our initial plausibility
assignments (17) and (18), using expression (19) and the properties of the circum-
stances:

P(R( jN+L)
iN+L
                     

∧ · · · ∧ R( jN+1)
iN+1
                     

| M ∧ R( jN )

Ri appears Li times
{z

}

|

∧ I) =

∧ · · · ∧ R( j1)
iN
i1
                
                
Ri appears Ni times
{z

|

P(Ri| M ∧ Ck ∧ I)Li

i

i
Xk hQ

}
P(Ck| ∧R( jN )
iN

∧ · · · ∧ R( j1)
i1

∧ I) ≡

qLi
ik

P(Ck| R( jN )
iN

∧ · · · ∧ R( j1)
i1

∧ I),

(20)

i
Xk (cid:16)Q

(cid:17)

with

P(Ck| R( jN )
iN

∧ · · · ∧ R( j1)
i1

i
∧ I) = (cid:16)Q

(21)

qNi
ik

(cid:17)
qNi
ik

P(Ck| I)

.

P(Ck| I)

i
k (cid:16)Q
P

(cid:17)

These formulae present many similarities to the de Finettian’s (6) and (7), and
to the formally similar expressions used by ‘frequentists’ and ‘propensitors’. But it
should be noted that, in the present formulae, qki ≔ P(Ri| M ∧ Ck ∧ I), P(Ck| I), and
P(Ck| R( jN )
∧I) are actual plausibilities, not just parameters or positive and
iN
normalised generating functions. (‘And they are fully subjective!’, the de Finettian
reiterates).

∧· · ·∧R( j1)
i1

15

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

5.3 Coarse-graining the set of circumstances

The marked similarities can in fact be made into identities of form. To achieve this,
we go back to the point where, after having introduced the circumstances {C( j)
}, we
k
made the plausibility assignments

P(Ri| M ∧ Ck ∧ I) ≡ qik

P(Ck| I) ≡ γk

(≔ P(R( j)
i
(≔ P(

| M( j) ∧ C( j)
k | I) ≡ P(C( j)
lC(l)

k ∧ I) for any j),
k | I) for any j),

(17)r

(18)r

V
for all i, k (and j). Instead of proceeding as we did, we now follow the remark by
Jaynes [1, p. 12], cited in the introductory epigraph:

It is simply convenient to index our hypotheses by parameters [ ¯q] cho-
sen to be numerically equal to the probabilities assigned by those hy-
potheses; this avoids a doubling of our notation. We could easily restate
everything so that the misconception could not arise; it would only be
rather clumsy notationally and tedious verbally.

What Jaynes calls ‘hypotheses’ we have here called, more generically, ‘circum-
stances’. Let us now group together those that lead to the same plausibility distri-
bution for the outcomes. That is, ﬁx a j, and form the equivalence classes of the
equivalence relation

k′ ∼ C( j)
C( j)

k′′ ⇐⇒ for all i, P(R( j)

i

| M( j) ∧ C( j)

k′ ∧ I) = P(R( j)

i

| M( j) ∧ C( j)

k′′ ∧ I).

(22)

By the very method these classes are deﬁned, each one can be uniquely identiﬁed by
a particular set of values (qi) ≡ ¯q of the plausibility distribution for the outcomes.
Note that owing to property (III) the value of ¯q does not depend on j. Call therefore
¯q∼ the class identiﬁed by a particular ¯q, and denote membership of C( j)
k by ‘k ∈ ¯q∼’
for short. Now let us take the disjunction of the circumstances in each class ¯q∼ and
uniquely denote this disjunction by S ( j)
¯q :

S ( j)
¯q

≔

C( j)
k .

k∈ ¯q∼
W

(23)

(24)

It is easy to see that, owing again to property (I), each S ( j)
¯q yields a conditional dis-
tribution for the outcomes that is numerically equal to ¯q, i.e. numerically equal to all
those yielded by the C( j)
k

in ¯q∼:

P(R( j)
i

| M( j) ∧ S ( j)

¯q ∧ I) = qi

for any j.

Moreover, the {S ( j)
their plausibilities are easily obtained from those of the latter:

¯q } also satisfy properties (I)–(IV) as the circumstances {C( j)

k }, and

P(S ( j)

¯q | I) =

P(C( j)

k | I),

k∈ ¯q∼
P

P(S ¯q| I) =

P(Ck| I),

(25)

k∈ ¯q∼
P

16

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

where S ¯q ≔

l S (l)

¯q in analogy with the deﬁnition (16).

These S ( j)
V
¯q are thus a sort of ‘coarse-grained’ circumstances. We shall call them
k can then be

thus, or also ‘plausibility-indexed circumstances’ sometimes. The C( j)
called ‘ﬁne-grained’ circumstances when a distinction is necessary.

In general, we have a class ¯q∼ and a disjunction S ( j)

¯q for particular (vector) values
of ¯q only (depending on the initial choice of circumstances and on the initial assign-
ments (17)). But we can formally introduce propositions S ( j)
¯q′ , all equal to the false
proposition (A ∧ ¬A), for the remaining values ¯q′. These propositions hence have
nought plausibilities, P(S ( j)
¯q′ | I) ≡ 0. The plausibilities P(R( j)
¯q′ ∧ I) are un-
deﬁned, but they will appear multiplied by the former in all relevant formulae, and
hence their product will vanish by convention. With this expedient we can consider
the whole, continuous set {S ( j)
| ¯q ∈ ∆} for all possible distributions ¯q which natu-
¯q
rally belong to the simplex ∆ ≔ {(qi) | qi > 0,
i qi = 1}. We can thus substitute
¯q . . . P(S ¯q| . . . ). The density
an integration ∫∆ . . . p(S ¯q| . . . ) d ¯q for the summation
p(S ¯q| . . . ) will be a generalised function.16

| M( j) ∧ S ( j)

P

i

P

k

We can therefore analyse the context I into the ‘coarse-grained’ circumstances
{S ( j)
}. The rationale behind this is that those circumstances C( j)
¯q }, instead of the {C( j)
k
that belong to a given class ¯q∼ have all exactly the same eﬀect on our judgement as
regards the assignment and the update of the plausibilities of the outcomes. It is there-
fore not unreasonable to handle them class-wise. The special notation chosen for the
diﬀerent classes, ‘S ( j)
¯q ’, the index ‘ ¯q’ in particular, is to remind us on the grounds of
what plausibility judgements (the ¯q) we grouped the original circumstances thus in
the ﬁrst place. But it is only a notation, nothing more. Each S ( j)
is a disjunction of
¯q
propositions like, e.g., ‘The coin is two-headed, or the tosses are made by a trickster
with a predilection for heads, or . . . ’ — it is not a statement about the plausibilities
(or the ‘propensities’) qi.

The eﬀect of this ‘bookkeeping’ notation is, however, surprising for the form our
induction formulae (19)–(21) take when expressed in terms of the coarse-grained
circumstances {S ( j)
¯q }. The plausibility we assign to any collection of measurement
outcomes takes now, by eq. (24), the form

P(R(L)
iL
              

∧ · · · ∧ R(1)
i1
              

| M ∧ I) =

R1 appears L1 times, etc.
}
{z
|
Z hQ

i

P(Ri| M ∧ S ¯q ∧ I)Li

p(S ¯q| I) d ¯q ≡

qLi
i

p(S ¯q| I) d ¯q,

(26)

i
with value numerically equal to that of (19), and with the same remarks and conven-
tions about the index j as made in § 5.1. The expression above is formally identical
to the de Finettian’s (2) with the correspondence p(S ¯q| I) ! Γ( ¯q| I). In particular,

(cid:17)

Z (cid:16)Q

i

16We can avoid the expedient above if we like; then the integrals that follow must be understood in
a measure-theoretic sense [78, 79, 80, 81, 82, 83, 84, 85] (cf. also [86, 87, 88]), with ‘p(S ¯q| . . . ) d ¯q’
standing for appropriate singular measures.

17

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

the plausibility for the outcome of any instance takes the form

P(R( j)
i

| M( j) ∧ I) =

qi p(S ¯q| I) d ¯q,

Z

(27)

formally identical to (3).

The plausibility conditional on the observation of N outcomes takes the form

P(R( jN+L)
iN+L
                     

∧ · · · ∧ R( jN+1)
iN+1
                     

| M ∧ R( jN )

Ri appears Li times
{z

}

|

∧ I) =

∧ · · · ∧ R( j1)
iN
i1
                
                
Ri appears Ni times
{z

}

|

P(Ri| M ∧ S ¯q ∧ I)Li

p(S ¯q| R( jN )
iN

∧ · · · ∧ R( j1)

∧ I) d ¯q ≡

i1

Z hQ

i

qLi
i

p(S ¯q| R( jN )
iN

∧ · · · ∧ R( j1)
i1

∧ I) d ¯q (28)

i

Z (cid:16)Q

i

(cid:17)

with

p(S ¯q| R( jN )
iN

∧ · · · ∧ R( j1)

i
∧ I) d ¯q = (cid:16)Q

i1

,

(29)

qNi
i

(cid:17)
qNi
i

p(S ¯q| I) d ¯q

p(S ¯q| I) d ¯q

i
R (cid:16)Q

(cid:17)

again formally identical to the de Finettian’s (6) and (7).

∧ I) or the P(R( j)
i

Apart from the congruence between their mathematical forms, the above formu-
lae and those derived from exchangeability have very diﬀerent meanings. Whereas in
the exchangeability approach the ¯q ≡ (qi) were just parameters, in the Laplace-Jaynes
approach they are (numerical values of) actual plausibilities, viz. the P(R( j)
| M( j) ∧
i
C( j)
¯q ∧ I). Whereas in the exchangeability approach
k
¯q 7→ Γ( ¯q| . . . ) was only a generalised function, in the Laplace-Jaynes approach
¯q 7→ p(S ¯q| . . . ) is (the density of) an actual plausibility distribution — a distribu-
tion, however, not over ‘probabilities’ or ‘propensities’, but rather over propositions
like ‘The coin is two-headed, or the tosses are made by a trickster with a predilection
for heads, or . . . ’.

| M( j) ∧ S ( j)

Equations (28) and (29) (as well as (20) and (21)) show that the observation of
measurement results has a double ‘updating’ eﬀect in the circumstances approach.
Not only are the plausibilities of unobserved results updated, but those of the cir-
cumstances as well; in fact, the former updating happens through the latter. This is
related to what Caves calls ‘learning through a parameter’ [73], although there are no
parameters here, only plausibilities. Also in the exchangeability approach, one could
argue, is the generating function Γ( ¯q| I) updated; but its updating only represents
and reﬂects a change in our uncertainty or degree of belief about the outcomes, no
more than that. In the Laplace-Jaynes approach, the updating of p(S ¯q| I) represents
instead a further change in our uncertainty about events or phenomena other than the
outcomes. We shall return to this in a moment.

We ﬁnally also see how the Laplace-Jaynes approach interprets and makes sense
of the notions of ‘unknown probability (or propensity)’ and ‘probability of a proba-
bility’: what is unknown is not a probability, but which circumstance from a set of

18

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

empirical ones holds; the second probability is therefore not about a probability, but
about an empirical circumstance.

5.4 Limit for large number of observations

Let us suppose that the plausibility distribution p(S ¯q| I) d ¯q does not vanish for any ¯q.
This implies that the set of ﬁne-grained circumstances {Ck} is a continuum, but with
analytical and topological care this case should not present particular diﬃculties.

That assumption being made, from eq. (29) we have that as the number N of
observations increases, the updated distribution for the plausibility-indexed circum-
stances asymptotically becomes

p(S ¯q| M ∧ R( jN )
∧ · · · ∧ R( j1)
iN
i1
                
                
Ri appears Ni times
{z

|

}

∧ I) ≃ δ

as N → ∞,

(30)

¯N
N − ¯q
(cid:17)

(cid:16)

which is formally identical to the de Finettian’s (10). It also follows that

P(R( jN+1)
i

| M( jN+1) ∧ R( jN )

∧ I) ≃

as N → ∞,

(31)

∧ · · · ∧ R( j1)
iN
i1
                
                
Ri appears Ni times
{z

}

|

Ni
N

exactly as in (11). Also in the Laplace-Jaynes approach, then, the plausibilities as-
signed to unobserved outcomes get nearer their observed relative frequencies as the
number of observations gets larger (under the assumptions speciﬁed above). And
persons sharing the same data and having compatible initial plausibility assignments
tend to converge to similar plausibility assignments, as regards their respective sets
of coarse-grained circumstances (as well as unobserved measurement outcomes. Cf.
the discussion is §§ 6.2 and 6.4.

What happens if the distribution p(S ¯q| I) d ¯q vanishes at, or in a neighbourhood
of, the point (qi) = (Ni/N), as may be the case when the number of ﬁne-grained cir-
cumstances {Ck} is ﬁnite? It happens that the updated distribution gets concentrated
at those S ¯q (and those Ck) with ¯q (respectively (qki)) nearest (Ni/N) and for which the
initial plausibility does not vanish. One should make the adjective ‘nearest’ topolog-
ically more precise. There are also interesting results at variance with the asymptotic
expression (11) when (Ni/N) cannot be obtained as a convex combination of those
¯q (respectively (qki)) whose related plausibilities do not vanish. All this is left to
another study.

6 Discussion

approaches

6.1 Relations between the circumstance and exchangeability

The Laplace-Jaynes approach and the inﬁnite-exchangeability one do not exclude
In fact, if in a
each other and may be used simultaneously in many problems.

19

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

given problem we can introduce ‘circumstances’, and the number of measurement
instances is potentially inﬁnite, the resulting distributions for collections of outcomes
are then inﬁnitely exchangeable and all the results and representations based on ex-
changeability also apply, beside those based on the circumstance representation. This
leads to the following powerful proposition:

Proposition. In the Laplace-Jaynes approach, if the number of measurement in-
stances is potentially inﬁnite then

P(R( jL)
iL
               

∧ · · · ∧ R( j1)
i1
               

| M ∧ D ∧ I) =

R1 appears L1 times, etc.
|
}
{z

and in particular

qLi
i

(cid:17)

Z (cid:16)Q

i

qLi
i

(cid:17)

Z (cid:16)Q

i

Γ( ¯q| D ∧ I) d ¯q =

p(S ¯q| D ∧ I) d ¯q,

(32)

Γ( ¯q| D ∧ I) d ¯q = p(S ¯q| D ∧ I) d ¯q,

(33)

for any L, {il}, and any D representing a (possibly empty) conjunction of measurement
outcomes not containing the instances j1, . . . , jL.

The equalities of the above Proposition may be read in two senses, whose mean-
ing is the following: If in a given situation we have introduced circumstances {S ¯q} (or,
equivalently, {Ck}) and assigned or calculated their plausibility density p(S ¯q| D ∧ I),
then we also know, automatically, the generating function Γ( ¯q| D ∧ I) of de Finetti’s
representation theorem, which we should have introduced had we taken an exchange-
ability approach. Vice versa, if we approach the problem through exchangeability
and assign an inﬁnitely exchangeable distribution to the possible inﬁnite collections
of outcomes, we have automatically assigned also the plausibility density p(S ¯q| D∧I)
for whatever set of coarse-grained circumstances {S ¯q} we might be willing to intro-
duce. The density of the Laplace-Jaynes approach and the generating function of the
exchangeability one are, in both cases, numerically equal.

What is remarkable in the second direction of the Proposition is that the plau-
sibilities of the coarse-grained circumstances are completely determined from our
exchangeable plausibility assignment, even when we have not yet speciﬁed what
those propositions are about! Although remarkable, this fact is a consequence of the
particular way the coarse-grained circumstances are formed from the ﬁne-grained
ones. Note, moreover, that the plausibilities of the ﬁne-grained circumstances {Ck}
would not be completely determined in general, even though their values would be
constrained by eq. (25).

Some philosophical importance has the fact that p(S ¯q| . . . ), numerically equal to
Γ( ¯q| . . . ), is an ‘actual’ plausibility distribution, whereas the latter is only a gener-
ating function. It is practically impossible to specify most inﬁnitely exchangeable
plausibility distributions directly, and this is one of the main points and advantages
of de Finetti’s theorem: a de Finettian can specify an inﬁnitely exchangeable distri-
bution by making a (often necessary) detour and specifying Γ instead. It is, however,

20

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

a bit disconcerting the fact that one is almost always forced to specify the ‘as if’ in-
stead of what according to de Finetti is ‘the actual plausibility’. The Laplace-Jaynes
approach gives instead a direct meaning to the generating function Γ as a plausibility
distribution, so that one needs not feel embarrassed to specify it.

Can all situations which can be approached through inﬁnite exchangeability also
be approached from the Laplace-Jaynes point of view? Asking this means asking
whether all situations for which we deem exchangeability to apply can be analysed
into circumstances having the properties (I)–(IV). There is surely much place for
discussion on the answer to this question, if by ‘circumstances’ we really mean, in
some sense, ‘interesting circumstances’. One could also wonder whether on a formal
level the answer could be ‘yes’. The reason is that the Laplace-Jaynes approach
would seem to formally include the inﬁnite-exchangeability one. To see how, make
ﬁrst a judgement of inﬁnite exchangeability, and then introduce and deﬁne a set {C ¯f }
of propositions stating that the limiting relative frequencies of an inﬁnite collection
of outcomes have certain values ¯f . This should be possible since the existence of
this limit under exchangeability is guaranteed by de Finetti’s theorem. Intuitively,
such a set {C ¯f } ≕ {C( j)
} for any j would seem to constitute (under a judgement of
¯f
inﬁnite exchangeability) a set of circumstances that satisfy properties (I)–(IV). If
this were true then, whenever inﬁnite exchangeability applied, the Laplace-Jaynes
approach would be at least formally viable. But intuition is not a reliable guide here
(the deﬁnition of a proposition like C ¯f , e.g., would apparently involve a disjunction
over the set of permutations of natural numbers), and the above reasoning is not
mathematically rigorous. We have not the mathematical knowledge necessary to
rigorously analyse and answer this sort of conjecture, and since we ﬁnd it in any case
uninteresting, let us not discuss it any further. It can be added, however, that any
criticism from de Finettians with regards to the inﬁnities involved in the argument
would be like sawing the branch upon which they are sitting themselves, since we do
not see how one can eﬀectively make a judgement of inﬁnite exchangeability without
ﬁrst considering possibly problematic propositions like {C ¯f }.

6.2

‘Unsure’ and ‘unstable’ plausibiliy assignments

The presence of circumstances in the analysis of the problem, and the consequent
fact that the plausibility of the outcomes can be decomposed as in eq. (27), suggest
an interpretation of those feelings of ‘uncertainty’ and ‘stability’ about a plausibility
assignment mentioned in § 4, point (a). A person might feel ‘sure’ about an assign-
ment 1/2 to heads in the situation Is because of the following, perhaps unconscious,
reasoning: ‘If I knew that the coin was two-headed or the toss method favoured
heads, I’d assign 1 to heads. If on the contrary I knew that the coin was two-tailed
or the toss method favoured tails, I’d assign 0 to heads. If I knew that the coin was
a usual one and the tosser knew nothing about tossing methods, I’d assign 1/2 to
heads. But the coin, although I gave to it a rapid glance only, seems to me quite com-
mon and symmetric; and I know that the tosser, a friend of mine, knows no tossing

21

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

tricks. So I can safely exclude the ﬁrst two possibilities, and I’m practically sure of
the third. Yes, I’ll give 1/2 to heads’. In this reasoning, the person entertains (for
each j) a set of possibilities, like ‘The coin is two-headed’, ‘The toss method favours
tails’, etc. From these a set of three plausibility-indexed circumstances S ¯q, with
¯q ≡ (qheads, qtails),17 is distilled, corresponding to the ¯q values (1, 0), (1/2, 1/2), and
(0, 1). To these circumstances the person assigns, given the background knowledge
Is, the plausibilities

P(S (1,0)| Is) ≈ 0,
P(S (1/2,1/2)| Is) ≈ 1,
P(S (0,1)| Is) ≈ 0.

(34)

(35)

Then, according to the rules of plausibility theory, the total plausibility assigned to
heads is

P(‘heads’| Is) =

P(‘heads’| S ¯q ∧ Is) P(S ¯q| Is),

¯q
P

= 1 × P(S (1,0)| Is) + 1/2 × P(S (1/2,1/2)| Is) + 0 × P(S (0,1)| Is),
≈ 1 × 0 + 1/2 × 1 + 0 × 0 = 1/2.

The fact to notice here is that amongst all the circumstances, those that lead to a con-
ditional plausibility for heads near to the total plausibility, viz. 1/2, have together far
higher plausibility than the others. This fact can be interpreted as the source of the
feelings of sureness and stability associated to that ﬁnal plausibility assignment: the
person has conceived a number of hypotheses, and the total plausibility assigned on
the grounds of these is practically equal to the plausibilities assigned conditionally
on the most plausible hypotheses only. Put it otherwise, the most plausible circum-
stances are not discordant, all point more or less to the same plausibility assignment.
Mathematically this is reﬂected in the fact that the distribution P(S ¯q| Is) is concen-
trated around the median.

The reasoning of a person who feels ‘unsure’ about an assignment 1/2 to heads
in the situation Iu might go instead as follows: ‘Had I known that the coin was a
common one, I’d have assigned 1/2 to heads. But I have heard from reliable sources
that this coin is not a common one, so I can safely exclude that possibility.
If I
knew that the coin was two-headed, I’d assign 1 to heads. If I knew that the it was
two-tailed, I’d assign 0 to heads. But I’m completely unsure about these two possibil-
ities! I have to give 1/2 to heads then’. Also in this reasoning the person introduces a
collection of hypotheses and from these distills a set of three plausibility-indexed cir-
cumstances similar to those introduced by the ‘sure’ person. It is in the assessment of
the plausibilities P(S ¯q| I) that the two persons — owing to their diﬀerent background

17Note, once more, that the S ¯q concern not plausibilities but statements like, in this case, ‘The coin

is a usual one and the tosser knows nothing about tossing methods’, etc.

22

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

(36)

(37)

knowledges Is, Iu — diﬀer. In this case the assessment yields

P(S (1,0)| Iu) ≈ 1/2,

P(S (1/2,1/2)| Iu) ≈ 0,

P(S (0,1)| Iu) ≈ 1/2,

and therefore the unsure person assign to the outcome ‘heads’ the total plausibility

P(‘heads’| Iu) =

P(‘heads’| S ¯q ∧ Iu) P(S ¯q| Iu),

¯q
P

= 1 × P(S (1,0)| Iu) + 1/2 × P(S (1/2,1/2)| Iu) + 0 × P(S (0,1)| Iu),
≈ 1 × 1/2 + 1/2 × 0 + 0 × 1/2 = 1/2.

The ﬁnal assignment is the same as that of the sure person, but the most plausible
circumstances for the unsure person would yield conditional plausibilities not near
to the ﬁnal value 1/2. The unsure person would have given 0 or 1 if a little bit more
knowledge of the situation had been available.18 In other words, the most plausible
circumstances are discordant and point to diﬀerent plausibility assignments, and this
can be interpreted as the source of the feelings of unsureness and instability.
In
mathematical terms, the distribution P(S ¯q| Iu) is not concentrated around the median.
The two examples above are very simple, the number of possible coarse-grained
circumstances being only three. With a deeper analysis this number could be very
large, and the assignments (34) and (36) would be replaced by eﬀective continuous
distributions like e.g.

p(S ¯q| Is) d ¯q ∝ (qheads)20 (qtails)20 δ(1 − qheads − qtails) d ¯q,
p(S ¯q| Iu) d ¯q ∝ (qheads)−39/40 (qtails)−39/40 δ(1 − qheads − qtails) d ¯q,

(38)

(39)

whose graphs are those of Fig. 1, blue dashed curve for the ﬁrst and orange continu-
ous curve for the second. These are Dirichlet (or beta) distributions, known for their
particular properties, for which see e.g. [1, 11, 53, 65, 89] (cf. also [51]).

The degree of ‘sureness’ or ‘stability’ about a plausibility assignment can thus be
apparently captured, formalised, and even quantiﬁed by the plausibility distribution
of a set of circumstances, P(S ¯q| I). Graphs such as those of Fig. 1 have then a legit-
imate and quantitative meaning within (single-valued) plausibility theory: They do
not represent ‘probabilities of probabilities’; they represent plausibility distributions
amongst diﬀerent unknown empirical circumstances, grouped for simplicity accord-
ing to the conditional plausibilities they lead to.

This interpretation is also consonant with the fact that, according to the results
of § 5.4, eq. (30), as the observed data accumulate the distribution P(S ¯q| I) gets more
and more peaked around a particular value which gets also nearer the median, re-
ﬂecting the fact that accumulation of data tends to make us surer of our plausibility
assignments.

For further discussion and references, see [2].

18The assignment will in fact collapse onto one of those two values as soon as one toss is observed,

leading to nought-or-one updated plausibilities for the circumstances S (0,1) and S (1,0).

23

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

6.3 Finite and small number of possible observations

As mentioned in § 4 with regard to point (c), there are situations in which the inﬁnite-
exchangeability approach cannot be adopted: situations where we know that the num-
ber of possible measurement instances is ﬁnite — and, in particular, small. In this
case a de Finettian has three possible options as regards the application of exchange-
ability.

The ﬁrst is to make a judgement of ﬁnite exchangeability and use the related
representation theorem.
It is known that the representation theorem for ﬁnite ex-
changeability has a diﬀerent form from that for inﬁnite exchangeability, eq. (2). The
plausibility for a collection of outcomes takes in the ﬁnite case the form of a mixture
of hypergeometric distributions (‘urn samplings without replacement’). In the case
of a ﬁnite but large number of possible observations this representation converges
to the inﬁnitely exchangeable one [9, 10][see also 90], so the de Finettian can make
sense of the propensitor’s ‘unknown propensity’ reasoning and of the related formu-
lae, which are formally identical with (2)–(7), as approximations. But in the case of
a small maximum number of possible observations the discrepancy between the two
representations is too large, and if the ‘propensitor’ obstinately uses the ‘unknown
propensity’ formulae, the de Finettian will then not be able to ‘make sense’ of them,
as instead was the case with inﬁnite exchangeability.

The second option is to use de Finetti’s theorem as generalised by Jaynes [52], i.e.
extended to generating functions of any sign, but restricting the choice of the latter to
positive ones only. But this restriction would lack meaningful motivation: What kind
of plausibility judgement would the restriction reﬂect? — For we must remember
that the speciﬁcation of the generating function is for the de Finettian only a detour
to specify the plausibility distribution of the outcomes, which is the only ‘actual’ one.
The restriction to positive generating functions would only seem to reﬂect the third
option, to which we now turn.

The third option is to enlarge the ﬁnite collection of measurement instances with
an inﬁnite number of ﬁctive ones, and then make a judgement of inﬁnite exchange-
ability for the enlarged collection. With this artiﬁce the formulae of the propensitor
can be recovered, and seemingly with a meaningful motivation. It seems to us, how-
ever, that the introduction of very many (∞) ﬁctive measurement instances, apart
from being unpleasant, is formally inconsistent. For the fact that one knows that the
number of measurement instances can but be ﬁnite, say at most n, must be included
in the context I; viz., M( j) ∧ I is false for j > n. The plausibility of the outcomes
of the ﬁctive ‘additional’ ( j > n) measurements, which is conditional on I, is then
by deﬁnition nought, or undeﬁned. One cannot even say ‘Let us suppose that ad-
ditional measurements were possible’, because such a proposition conjoined with I
would yield a false context and the plausibilities conditional on it would then be un-
deﬁned. An alternative would be to eliminate from the context I those ‘elements’ that
bound the number of measurement instances, so that the plausibilities of the ﬁctive
additional measurements would neither be nought nor undeﬁned in the new, muti-
lated context. But mutilation of prior knowledge — granted its feasibility — can be

24

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

dangerous.

The Laplace-Jaynes approach, on the other hand, applies unaltered to the case
of a ﬁnite, even small, maximum number of measurement instances. This is clear if
we look again at properties (II)–(IV): they nowhere require the instance index j to
run to inﬁnity, as cursively remarked directly after their enunciation. Hence, through
the Laplace-Jaynes approach we can make straightforward sense of the propensitor’s
procedure also in these ﬁnite situations.

6.4 When is the Laplace-Jaynes approach useful? Making allowance
for the grounds behind exchangeability assignments: some
examples

We have seen in § 6.1 that the two approaches are not mutually exclusive but can
coexist and strongly ‘interact’. But in which sense are the two approaches comple-
mentary? How ought we to decide which approach to choose? Why? There is no
deﬁnite answer: as de Finetti warns [75, § 20]:

in certain enterprises it can be better to evaluate the probability of favour-
able outcomes all in a block, to see at a glance whether the investment
is secure or insecure, and in others it is better to reach this conclusion
starting from an analysis of the individual factors that are in play. There
is no conceptual diﬀerence between the two cases. Someone who wants
to estimate the area of a rectangular ﬁeld can with the same right esti-
mate the area directly in hectares, or estimate the lengths of the sides
and multiply them: reasons of convenience, practicality and custom will
make one method preferable to the other, the one that seems to us more
trustworthy in relation to our capacity to judge, or we can follow both
methods, or try other ones, and consider all of them in ﬁxing our opinion.

In assigning a plausibility to some measurement outcomes we may simply want,
depending on ‘convenience, practicality and custom’, to assign plausibilities to all
possible collections of similar outcomes (indirectly, by specifying the generating
function of de Finetti’s theorem), update the plausibilities according to observations
already made, and then marginalise for the instances of interest, as described in § 3.
Or we may want to analyse the contexts of the measurements into more details and
assign plausibilities to these, obtaining the ﬁnal plausibilities for the outcomes of in-
terest by the theorem on total probability, as described in § 5. Neither approach is
more ‘objective’ than the other, for both must start from some set of (subjective, the
de Finettian says) plausibilities that must be given without further analysis.

In situations such as that of a ‘common’ coin toss or die throw, we (the authors)
usually prefer in general the approach through exchangeability. Although such situ-
ations could be analysed into more details and hypotheses about the way of tossing
etc., we are not really interested in these and prefer to make an initial exchangeable
plausibility assignment for future tosses, that we shall update according to observa-

25

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

tions made — the number of which can be very large (i.e., inﬁnite exchangeability
can be applied, at least as an approximation). One could say that it is the plausibil-
ities ‘P(R( j)
| . . . )’ that are of interest, and we collect measurement data to be put in
i
place of the dots in order to update those plausibilities. But there are examples, espe-
cially in the study of natural phenomena, where it is the details — the circumstances
— that interest us most and that we want to investigate.
In these cases measure-
ment outcomes are collected not only for the sake of prediction of other, unknown
ones, but also in order to modify our uncertainty about the circumstances, i.e., to
change our initial plausibility assignments about them. In other words, the plausibil-
ities ‘P(Ck| . . . )’ interest us as much as the ‘P(R( j)
| . . . )’, and measurement data are
i
collected to update both.

A powerful feature of the approach through plausibility-indexed (i.e. coarse-
grained) circumstances is that you can ‘wait’ to think about and to explicitly deﬁne
the circumstances of interest until you have collected a large amount of observations.
The ‘procedure’ is as follows:

1. Imagine to have introduced numerous circumstances {Ck}, to have assigned the
plausibilities P(Ri| M ∧ Ck ∧ I), and to have performed the ‘coarse-graining’ of
the circumstances into the set {S ¯q}.

2. Assume to have assigned plausibilities P(Ck| I) such that the plausibility den-
sity p(S ¯q| I) over the coarse-grained circumstances is enough smooth and non-
vanishing at every point. How much is ‘enough’ is related to the size of the
collected data as for the next step.

3. Collect a large amount of outcome observations D. What counts as ‘large’
is related to the smoothness assumed in the previous step for the plausibility
density over the coarse-grained circumstances.

4. Update your distributions according to the observations D.

¯f ≡ ( fi) are
the relative frequencies of the observed outcomes, the updated plausibility dis-
tribution over the coarse-grained circumstances would now be concentrated
around the circumstance labelled by ¯f , i.e., p(S ¯q| D ∧ I) d ¯q ≈ δ( ¯q − ¯f ) d ¯q;
cf. § 5.4. This means that you would judge S ¯f to be the most plausible cir-
cumstance given the evidence D. (But remember: the introduction of circum-
stances is up to now only imagined.)

If

5. Now re-examine the context as it was before the observations, and really intro-
duce a set of circumstances of interest, respecting the assumptions in steps 1
and 2. In this process, however, you only need to concentrate on those circum-
stances conditional on which the outcomes of any measurement instance are
near to ¯f , i.e. those for which P(Ri| M ∧Ck ∧ I) ≈ fi. This restriction is sensible
since, as for step 4 above, these are the circumstances that have now become
most plausible in the light of the observed data.

26

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

This process reﬂects e.g. what we do when, having tossed a coin many times and
seen that we nearly always obtain heads, we say ‘there’s something peculiar going
on here, let’s see what it can be’, and begin to look for circumstances (like who
tossed the coin, how the coin was tossed, on which surface it was tossed, how it was
manufactured, etc.) which presumably lead to the observed peculiar behaviour.

Examples in the same spirit, although more complex, abound in the natural sci-
ences. Consider the following example from the study of granular materials [e.g.,
91, 92]. These are made of a very large number of macroscopic (thermal agitation
is unimportant) but small particles, that are hence considered point-like. These ma-
terials can then be studied by the methods of statistical mechanics. Often of interest
is the particle motion resulting from an externally applied force and the particles’
collisions. In the study by Rouyer and Menon [93] (to which we refer for details) we
are interested in the measurement — our M — of the horizontal velocity component
v of any particle. The possible measurement outcomes {Rv} are the possible diﬀer-
ent values of v.19 What is the plausibility distribution that we assign to the diﬀerent
outcomes? Depending on the circumstances, we should make diﬀerent assignments.
For example, if we knew that the particle collisions were elastic, the particle den-
sity enough low, long-range interactions negligible, and a couple more of details
— all of which we represent by CMB —, we should assign a Maxwell-Boltzmann,
Gaussian distribution p(Rv| M ∧ CMB ∧ I) dv ∝ exp(v2/v2
0) dv, with an appropriate
constant v0. (In the present case we know the collisions to be inelastic, so that CMB is
from the beginning known to be false; but let us disregard this to make the example
more interesting.) If we knew [93] that the collisions were inelastic, knew that the
density presented inhomogeneities, judged the particle density very relevant for the
velocity distribution, and knew some other details — denote all them by CP —, we
should then assign a particular non-Gaussian plausibility distribution, according to
the kinetic-theoretical considerations of Puglisi et al. [94]. Finally, if we knew [93]
that the collision were inelastic, that energy was injected in the system homoge-
neously in space, and some other details — call them CNE —, we should then assign
another particular non-Gaussian plausibility distribution, according to the study by
van Noije and Ernst [95]. (In the present case we know that energy is injected from
the boundary, so that CNE is known to be false; again, we disregard this.)

We do not consider other possible circumstances for the moment, but go on to
collect a large amount of observations instead — call these D. The distribution of
frequencies thus observed goes like Nv/N dv = exp(vα/vα
1 ) dv with α ≈ 3/2, a distri-
bution very similar to that assigned on the grounds of CP, and partially similar to that
assigned conditional on CNE. By eq. (11) we are thus led, in both the exchangeability
and the Laplace-Jaynes approach, to assign

p(R(N+1)
v

| M(N+1) ∧ D ∧ I) dv ≈ exp(vα/vα

1 ) dv

(40)

19Hence, the set of outcomes is continuous here but, with appropriate mathematical care, this is not

so important.

27

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

and to say that

Γ(‘exp(vα/vα

1 )’| D ∧ I) = p(S ‘exp(vα/vα

1 )’| D ∧ I)

has a very large value.

(41)

You note that Γ has ‘exp(vα/vα
1 )’ as argument, which is also the index of S . This
is because v is a continuous variable, hence the vectors ¯q ≡ (qi) of our previous
discussions become functions Q(v) here. The function ‘exp(vα/vα
1 )’ thus represents
a particular value of what is denoted by ‘ ¯q’ in §§ 3 and 5.

The analysis has up to now involved both the exchangeability and the Laplace-
Jaynes approaches, and at this point the exchangeability approach basically termi-
nates. But the interesting part of the Laplace-Jaynes approach, instead, begins. In
fact, from eq. (41) we are led to assign a vanishing plausibility to the circumstance
CMB and a small one to CNE (which we already knew to be false, however) and a
non-negligible plausibility to the circumstance CP. This prompts other studies and
experiments in order to update that plausibility so as to possibly decrease our uncer-
tainty. Rouyer and Menon [93] actually do this, and eventually come to a vanishing
plausibility for the circumstance CP. Other circumstances are still to be formulated
and introduced.

In the above typically physical example the ‘circumstances’ are indeed intended
as ‘causes’ or ‘mechanisms’. But as we remarked in § 5.1, this needs not always be
the case. A very interesting and curious example, for which we believe the circum-
stances cannot be interpreted as ‘causes’ or ‘mechanisms’, is provided by the study
of the Newcomb-Benford law [96, 97, 98, 99], here tersely described by Raimi [98,
p. 521]:

It has been known for a long time that if an extensive collection
of numerical data expressed in decimal form is classiﬁed according to
ﬁrst signiﬁcant digit, without regard to position of decimal point, the
nine resulting classes are not usually of equal size. Indeed, [. . . ] for
the occurrence of a given ﬁrst digit i (i = 1, 2, . . . , 9),20 many observed
tables give a frequency approximately equal to log10[(i + 1)/i]. Thus the
initial digit 1 appears about .301 of the time, 2 somewhat less and so on,
with 9 occurring as a ﬁrst digit less than 5 percent of the time. (We do
not admit 0 as a possible ﬁrst digit.)

This particular logarithmic distribution of ﬁrst digits, while not uni-
versal, is so common and yet so surprising at ﬁrst glance that it has
given rise to a varied literature, among the authors of which are mathe-
maticians, statisticians, economists, engineers, physicists and amateurs.

This example can be analysed along the lines of the previous one. The ‘measurement’
M is the observation of the ﬁrst digits in a given collection of numerical data, the pos-
sible ‘outcomes’ being R1, . . . , R9. Having made a judgement of exchangeability as
regards the outcomes of any number of observations,21 after many observations our

20‘p’ in Raimi’s text.
21Since the number of data is ﬁnite, inﬁnite exchangeability can here be used only as an approxi-

mation or an idealisation.

28

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

log10[(i + 1)/i]
(cid:1)
(cid:0)

plausibility assignment will be very near to the observed frequencies, in this case
approximately
. Here the approach through exchangeability stops.
But the Laplace-Jaynes approach does not. According to eq. (30) the circumstances
that have acquired highest plausibility are those which lead us to assign the ‘sur-
prising’ distribution
. The ‘varied literature’ which Raimi mentions
consists almost exclusively in searches and studies of such circumstances. The sig-
niﬁcant point is that many proposed ones concern not ‘causes’ or ‘mechanisms’, but
symmetries.

log10[(i + 1)/i]
(cid:1)
(cid:0)

A general and more thorough discussion of how the Laplace-Jaynes approach ﬁts
into the formalism of statistical physics will be given in our next study [74], together
with an analysis of point (d) of § 4.

7 Generalisations

In the Laplace-Jaynes approach introduced in § 5.1 a set of possible circumstances is
deﬁned for each measurement instance, and there is a mutual correspondence of these
sets, mathematically expressed in particular by eqs. (III) and (IV). These express the
idea that there is a similarity amongst the measurement instances, for they can be
analysed into the ‘same’ set of circumstances; and also the idea that the ‘same’, but
unknown, circumstance holds in all instances. This approach can be generalised in
diﬀerent directions.

A ﬁrst generalisation is to introduce a set of circumstances {Cλ}, not for each
measurement instance, but for all of them en bloc. I.e., each circumstance Cλ con-
cerns all measurement instances. This idea can be easily illustrated if diﬀerent mea-
surement instances are characterised by diﬀerent times: then each Cλ can represent a
possible ‘history’ of the details of the instances.22 Modifying properties (I)–(III) and
the subsequent sections by the formal substitution C(·)
  Cλ, and dropping prop-
k
erty (IV), most part of the analysis and discussion presented in the previous sections
holds unchanged, or with minor adaptations, for this generalisation.

A second generalisation, with similarities with the preceding one, is made by
dropping property (IV) only. This means that we do not assume the ‘same’ circum-
, where the kl
stance to hold at every measurement instance. All conjunctions
can diﬀer for diﬀerent l, can then have non-vanishing plausibilities (these conjunc-
tions are obviously similar to the circumstances Cλ above; cf. footnote 22). With this

l C(l)
kl

V

22Note, however, that diﬀerent measurement instances do not need to be associated to diﬀerent
times in general, so the ‘history interpretation’ is just an example. A more general way to think of
the circumstances {Cλ} is to introduce for each measurement instance j a set of circumstances {C( j)
k },
as in § 5.1, but without assuming any correspondence amongst the sets, not even the same cardinality.
We then consider all possible conjunctions
, and each such conjunction can be taken to be by
deﬁnition one of the Cλ.

j C( j)
k j

V

29

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

generalisation formulae (19)–(21) do not hold; in their place we have

P(R( jL)
iL

∧ · · · ∧ R( j1)
| M ∧ I) =
i1
| M( j1) ∧ C( j1)
P(R( j1)
i1
k j1

Xk1,k2,...

∧ I) · · · P(R( jL)
iL

| M( jL) ∧ C( jL)
k jL

∧ I) P

C(l)
kl

| I

≡

qi1k j1

· · · qiLk jL

P

C(l)
kl

| I

(19′)

Xk1,k2,...

l
(cid:0)V

l
(cid:0)V

(cid:1)
,

(cid:1)

P(R( jN+L)
iN+L

∧ · · · ∧ R( jN+1)

| M ∧ R( jN )

∧ · · · ∧ R( j1)
i1

∧ I) =

iN

iN+1

L

Xk1,k2,..."

l=1
Q

P(R( jl)
il

| M( jl) ∧ C( jl)
kl

∧ I)
#

P

C(l)
k jl

| R( jN )
iN

∧ · · · ∧ R( j1)

∧ I

≡

i1

qi1k j1

· · · qiLk jL

C(l)
kl

| R( jN )
iN

∧ · · · ∧ R( j1)
i1

(20′)

Xk1,k2,...

(cid:1)
∧ I

,

(cid:1)

l
(cid:0)V
P

l
(cid:0)V

and

C(l)
kl

| R( jN )
iN

∧ · · · ∧ R( j1)
i1

∧ I

=

P

l
(cid:0)V

qi1k j1
k1,k2,... qi1k j1

· · · qiN k jN

P

l C(l)
kl
(cid:0)V
· · · qiN k jN
P

| I
(cid:1)
l C(l)
kl

.

| I

(cid:1)

(cid:0)V

(cid:1)

P

(21′)

The plausibility distribution for the collection of outcomes is therefore generally not
exchangeable (the frequentist and the propensitor would say that the events are not
‘identically distributed’, though independent).

The plausibilistic framework of the last generalisation is used in non-equilibrium
statistical mechanics [100, 101, 102, 103, 104]. A generic circumstance C( j)
rep-
k
resents a system’s being in a (‘microscopic’) state k at the time t j; R( j)
represents
i
the obtainment of the ith outcome of a (‘macroscopic’) measurement M( j) performed
at time t j; the plausibilities P(R( j)
k ∧ I) are given by the relevant physi-
i
cal theory for all i, j, k. We initially assign, usually by means of maximum-entropy
| I) for all
or maximum-calibre principles, an initial plausibility distribution P(

| M( j) ∧ C( j)

that the system may follow. Then we update, from
possible state dynamics
the history of the observed measurement outcomes, the plausibilities of the diﬀerent
V
dynamics and thence those of unobserved outcomes.

V

l C(l)
kl

Finally, a third generalisation could be the introduction of multiple kinds of mea-
surements instead of a single one M. The resulting representation, which should be
easy for the reader to derive, would correspond to de Finetti’s theorem for partial
exchangeability [11, 105].

lC(l)
kl

8 Conclusions

Beside exchangeability, there is another point of view from which the de Finettians
and the plausibilists can approach the question of induction and thus also interpret

30

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

and give meaning to the formulae of the propensitors and some of their locutions
like ‘unknown probability’ or ‘i.i.d.’. This point of view, which we have named
the ‘Laplace-Jaynes approach’, is based on an analysis of the particular situation of
interest into possible ‘circumstances’. These ‘circumstances’ are propositions that
concern details of an empirical nature; in particular, they are not and cannot be state-
ments about probabilities. They do not necessarily involve notions of ‘cause’ or
‘mechanism’, but can concern symmetries of the situation under study, or conse-
quences of the observed events. More generally, their choice is fully ‘subjective’, as
are the plausibilities assigned to them. Their main required property is that when they
are known they render irrelevant any observational data for the purpose of assigning
a plausibility to unobserved events.

The Laplace-Jaynes approach can coexist with that based on exchangeability,
and can be a complement or an alternative to the latter. It is particularly suited to
problems in natural philosophy, whose heart is the analysis of natural phenomena
into relevant circumstances (concerning especially, but not exclusively, the notion
of ‘cause’).
It also allows — without resorting to alternative probability theories
— an interpretation, formalisation, and quantiﬁcation of feelings of ‘uncertainty’
or ‘instability’ about some plausibility assignments. Finally, this point of view is
applicable in those situations in which the maximum number of possible observations
is bounded (and, especially, small) and inﬁnite exchangeability cannot therefore be
applied.

The Laplace-Jaynes approach is also straightforwardly generalised to the case
of more generic sets of circumstances, the case of non-exchangeable plausibility as-
signments (with applications in non-equilibrium statistical mechanics), and the case
in which diﬀerent kinds of measurements are present, usually approached by partial
exchangeability.

Acknowledgements

PM non può ringraziare mai abbastanza Louise, Marianna, e Miriam per il loro con-
tinuo sostegno e amore. Aﬀectionate thanks also to the staﬀ of the KTH Biblioteket,
especially the staﬀ of the Forum Library — Elisabeth Hammam, Ingrid Talman,
Tommy Westergren, Elin Ekstedt, Thomas Hedbjörn, Daniel Larsson, Allan Lindqvist,
Lina Lindstein, Yvonne Molin, Min Purroy Pei, Anders Robertsson — for their pa-
tient and indefatigable work. Without them, research would hardly be possible. AM
thanks Anders Karlsson for encouragement and advice.

Bibliography

Note: arxiv eprints are located at http://arxiv.org/.

[1]

T.

E.
http://bayes.wustl.edu/etj/node1.html;

Monkeys,

Jaynes,

kangaroos

and

(1996),
N
revised and corrected

31

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

version of Jaynes [106]. (Errata: in equations (29)–(31), (33), (40), (44), (49)
the commas should be replaced by gamma functions, and on p. 19 the value
0.915 should be replaced by 0.0915).

P. G. L. Porta Mana, A. Månsson, and G. Björk, From “plausibilities of plausi-
bilities” to state-assignment methods: I. “Plausibilities of plausibilities”: an
approach through circumstances (2006), eprint arXiv:quant-ph/0607111.

B. de Finetti, Probabilismo, Logos 14, 163–219 (1931), transl. as [75]; see
also [107].

B. de Finetti, Foresight: Its logical laws, its subjective sources, in Kyburg and
Smokler [108] (1964), pp. 93–158, transl. by Henry E. Kyburg, Jr. of [109].

E. Hewitt and L. J. Savage, Symmetric measures on Cartesian products, Trans.
Am. Math. Soc. 80(2), 470–501 (1955).

B. de Finetti, Theory of Probability: A critical introductory treatment. Vol. 1
(John Wiley & Sons, New York, 1970/1990), transl. by Antonio Machi and
Adrian Smith; ﬁrst publ. in Italian 1970.

B. de Finetti, Theory of Probability: A critical introductory treatment. Vol. 2
(John Wiley & Sons, New York, 1970/1990), transl. by Antonio Machi and
Adrian Smith; ﬁrst publ. in Italian 1970.

D. Heath and W. Sudderth, De Finetti’s theorem on exchangeable variables,
American Statistician 30(4), 188–189 (1976).

P. Diaconis, Finite forms of de Finetti’s theorem on exchangeability, Synthese
36(2), 271–281 (1977).

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

[10] P. Diaconis and D. Freedman, Finite exchangeable sequences, Ann. Prob. 8(4),

745–764 (1980).

[11]

J.-M. Bernardo and A. F. Smith, Bayesian Theory (John Wiley & Sons, Chich-
ester, 1994).

[12] P. S. Laplace, (Marquis de), Théorie analytique des probabilités (M.me
V.e Courcier, Paris, 1812/1820), 3rd ed., ﬁrst publ. 1812; repr. in [110];
http://gallica.bnf.fr/document?O=N077595.

[13] W. E. Johnson, Logic. Part III. The Logical Foundations of Science (Cam-

bridge University Press, Cambridge, 1924).

[14] H. Jeﬀreys, Theory of Probability (Oxford University Press, London,

1939/1998), 3rd ed., ﬁrst publ. 1939.

[15] H. Jeﬀreys, Scientiﬁc Inference (Cambridge University Press, Cambridge,

1931/1957), 2nd ed., ﬁrst publ. 1931.

32

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

[16] H. Jeﬀreys, The present position in probability theory, Brit. J. Phil. Sci. 5(20),

[17] R. T. Cox, Probability, frequency, and reasonable expectation, Am. J. Phys.

[18] R. T. Cox, The Algebra of Probable Inference (The Johns Hopkins Press, Bal-

275–289 (1955).

14(1), 1–13 (1946).

timore, 1961).

[19] E. T.

Jaynes, Probability Theory: With Applications

and Engineering:
A Series
http://bayes.wustl.edu/etj/science.pdf.html;
written 1954–1974; earlier version of [21].

Informal Lectures

of

in Science
(1954–1974),
notes

lecture

[20] E.

T.

Jaynes,

Probability

Science

and

Theory

in
Company,

En-
1959),

gineering
http://bayes.wustl.edu/etj/node1.html; see also [19].

(Socony-Mobil

Oil

Dallas,

[21] E. T. Jaynes, Probability Theory: The Logic of Science (Cambridge Univer-
sity Press, Cambridge, 1994/2003), ed. by G. Larry Bretthorst; ﬁrst publ. 1994
at http://bayes.wustl.edu/etj. (Chapter 30, Maximum entropy: matrix
formulation, of the original version of the book, not included in the printed
is available at http://web.it.kth.se/~mana/work/cc30e.pdf).
one,
Earlier versions in [19, 20].

[22] M. Tribus, Rational Descriptions, Decisions and Designs (Pergamon Press,

New York, 1969).

[23] E. W. Adams, The Logic of Conditionals: An Application of Probability to

Deductive Logic (D. Reidel Publishing Company, Dordrecht, 1975).

[24] E. W. Adams, A Primer of Probability Logic (CSLI Publications, Stanford,

1998).

[25] T. Hailperin, Sentential Probability Logic: Origins, Development, Current
Status, and Technical Applications (Associated University Presses, London,
1996).

[26]

J. M. Keynes, A Treatise on Probability (MacMillan, London, 1921), 5th ed.

[27] F. P. Ramsey, Truth and probability, in Ramsey [28] (London, 1926/1950), pp.

156–198, repr. in [108, pp. 61–92], written 1926.

[28] F. P. Ramsey, The Foundations of Mathematics and other Logical Essays
(Routledge & Kegan Paul, London, 1931/1950), ed. by R. B. Braithwaite, ﬁrst
publ. 1931.

33

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

[29] A. N. Kolmogorov, Foundations of the Theory of Probability (Chelsea Pub-
lishing Company, New York, 1933/1956), second English ed., transl. by
Nathan Morrison, with an added bibliography by A. T. Bharucha-Reid ﬁrst
publ. in Russian 1933.

[30] B. O. Koopman, The bases of probability, Bull. Am. Math. Soc. 46, 763–774

(1940), repr. in [108, pp. 159–172].

[31] B. O. Koopman, The axioms and algebra of intuitive probability, Ann. Math.

[32] B. O. Koopman, Intuitive probabilities and sequences, Ann. Math. 42(1), 169–

41(2), 269–292 (1940).

187 (1941).

[33] G. Pólya, Mathematics and Plausible Reasoning: Vol. I: Induction and Anal-

ogy in Mathematics (Princeton University Press, Princeton, 1954).

[34] G. Pólya, Mathematics and Plausible Reasoning: Vol. II: Patterns of Plausible
Inference (Princeton University Press, Princeton, 1954/1968), 2nd ed., ﬁrst
publ. 1954.

[35] H. Gaifman, Concerning measures in ﬁrst order calculi, Israel J. Math. 2, 1–18

(1964).

[36] D. Scott and P. Krauss, Assigning probabilities to logical formulas, in Hintikka

and Suppes [111] (1966), pp. 219–264.

[37] H. Gaifman and M. Snir, Probabilities over rich languages, testing and ran-

domness, J. Symbolic Logic 47(3), 495–548 (1982).

[38] H. Gaifman, Reasoning with bounded resources and assigning probabil-
ities to arithmetical statements, Synthese 140(1–2), 97–119 (2003/2004),
http://www.columbia.edu/~hg17/; ﬁrst publ. 2003.

[39] P. Gregory, Bayesian Logical Data Analysis for the Physical Sciences: A Com-
parative Approach with Mathematica Support (Cambridge University Press,
Cambridge, 2005).

[40] E. W. Adams, modus tollens revisited, Analysis 48(3), 122–128 (1988).

[41] D. Lewis, Probabilities of conditionals and conditional probabilities, Phil.

Rev. 85(3), 297–315 (1976), see also [42].

[42] D. Lewis, Probabilities of conditionals and conditional probabilities II, Phil.

Rev. 95(4), 581–589 (1986), see also [41].

[43] T. Hailperin, Probability logic, Notre Dame J. Formal Logic 25(3), 198–212

(1984).

34

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

[44]

J. Barwise, The Situation in Logic (CSLI, Stanford, 1989).

[45]

J. Barwise, The situation in logic — II: Conditionals and conditional informa-
tion, Tech. Rep. CSLI-85-21, Center for the Study of Language and Informa-
tion, Stanford (1985).

[46] H. Gaifman,

tolerance
http://www.columbia.edu/~hg17/.

Vagueness,

and

contextual

logic

(2002),

[47] B. de Finetti, Probability and exchangeability from a subjective point of view,

Int. Stat. Rev. 47(2), 129–135 (1979).

[48] A. Hájek, What conditional probability could not be, Synthese 137(3), 273–

323 (2003).

[49]

[50]

ISO, Quantities and units, International Organization for Standardization,
Geneva, 3rd ed. (1993).

IEEE, ANSI/IEEE Std 260.3-1993: American National Standard: Mathemati-
cal signs and symbols for use in physical sciences and technology, Institute of
Electrical and Electronics Engineers, New York (1993).

[51] D. V. Lindley and L. D. Phillips, Inference for a Bernoulli process (a Bayesian

view), American Statistician 30(3), 112–119 (1976).

[52] E. T. Jaynes, Some applications and extensions of

the de Finetti rep-
resentation theorem,
in Bayesian Inference and Decision Techniques
with Applications: Essays in Honor of Bruno de Finetti, edited by
P. K. Goel and A. Zellner (North-Holland, Amsterdam, 1986), p. 31,
http://bayes.wustl.edu/etj/node1.html.

[53] W. E. Johnson, Probability: The deductive and inductive problems, Mind
41(164), 409–423 (1932), with some notes and an appendix by R. B. Braith-
waite.

[54] S. L. Zabell, W. E. Johnson’s “suﬃcientness” postulate, Ann. Stat. 10(4),

1090–1099 (1982).

[55] Y. V. Egorov, A contribution to the theory of generalized functions, Russ.

Math. Surveys (Uspekhi Mat. Nauk) 45(5), 1–49 (1990).

[56] Y. V. Egorov, Generalized functions and their applications, in Exner and Nei-

dhardt [112] (1990), pp. 347–354.

[57] A. S. Demidov, Generalized Functions in Mathematical Physics: Main Ideas
and Concepts (Nova Science Publishers, Huntington, USA, 2001), with an
addition by Yu. V. Egorov.

35

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

[58] M. J. Lighthill, Introduction to Fourier Analysis and Generalised Functions

(Cambridge University Press, London, 1958/1964), ﬁrst publ. 1958.

[59] B. de Finetti, On the condition of partial exchangeability, in Jeﬀrey [113]
(1980), pp. 193–205, transl. by P. Benacerraf and R. Jeﬀrey of [105].

[60] P. Diaconis and D. Freedman, A dozen de Finetti-style results in search of a

theory, Ann. Inst. Henri Poincaré (B) 23(S2), 397–423 (1987).

[61] H. O. Georgii, ed., Canonical Gibbs Measures: Some Extensions of de Fi-
netti’s Representation Theorem for Interacting Particle Systems (Springer-
Verlag, Berlin, 1979).

[62] F. Lad, J. M. Dickey, and M. A. Rahman, The fundamental theorem of previ-

sion, Statistica 50(1), 19–38 (1990).

[63] F. V. Atkinson, J. D. Church, and B. Harris, Decision procedures for ﬁnite
decision problems under complete ignorance, Ann. Math. Stat. 35(4), 1644–
1655 (1964).

[64] E. H. Kyburg, Jr., Bayesian and non-Bayesian evidential updating, Artif. In-

tell. 31(3), 271–293 (1987).

[65]

I. J. Good, The Estimation of Probabilities: An Essay on Modern Bayesian
Methods (The MIT Press, Cambridge, USA, 1965).

[66] D. Jamison, Bayesian information usage,

in Hintikka and Suppes [114]

(1970), pp. 28–57.

[67]

I. Levi, Information and ignorance, Inform. Process. Manag. 20(3), 355–362
(1984).

[68] C. M. Caves, C. A. Fuchs, and R. Schack, Unknown quantum states: the
quantum de Finetti representation, J. Math. Phys. 43(9), 4537–4559 (2002),
eprint arXiv:quant-ph/0104088.

[69] C. M. Caves, C. A. Fuchs, and R. Schack, Quantum probabilities
as Bayesian probabilities, Phys. Rev. A 65, 022305 (2002), eprint
arXiv:quant-ph/0106133.

[70] C. A. Fuchs and R. Schack, Unknown quantum states and operations, a

Bayesian view (2004), eprint arXiv:quant-ph/0404156.

[71] C. A. Fuchs, R. Schack, and P. F. Scudo, De Finetti representation theorem
for quantum-process tomography, Phys. Rev. A 69, 062305 (2004), eprint
arXiv:quant-ph/0307198.

36

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

[72] P. S. Laplace,

(Marquis de), Mémoire sur la probabilité des causes
par les évènemens, Mémoires de mathématique et de physique, pre-
sentés à l’Académie Royale des Sciences, par divers savans et
lûs
in [115], pp. 25–65;
dans ses assemblées 6, 621–656 (1774),
http://gallica.bnf.fr/document?O=N077596; transl. as [116].

repr.

[73] C. M. Caves, Learning and the de Finetti

representation (2000),

http://info.phys.unm.edu/~caves/reports/reports.html.

[74] P. G. L. Porta Mana, A. Månsson, and G. Björk, A general bayesian frame-
work for statistical physics, combining the circumstance approach to induc-
tion and the vector representation for physical theories: (Being part III of
“From ‘plausibilities of plausibilities’ to state-assignment methods”) (2007),
in preparation.

[75] B. de Finetti, Probabilism: A critical essay on the theory of probability and on
the value of science, Erkenntnis 31(2–3), 169–223 (1931/1989), transl. of [3]
by Maria Concetta Di Maio, Maria Carla Galavotti, and Richard C. Jeﬀrey.

[76]

and M. Guerrero, The Book of

J. L. Borges
(Vintage, London,
by Norman Thomas di Giovanni
Borges;
http://www.uiowa.edu/borges/vakalo/zf/home.html.

Imaginary Beings
transl.
in collaboration with Jorge Luis
second Spanish ed. 1967;

revised and enlarged ed.,

in Spanish 1957,

1957/2002),

ﬁrst publ.

[77]

J. R. R. Tolkien, The Silmarillion (Ballantine Books, New York, 1977/1979),
ﬁrst publ. 1977.

[78] A. N. Kolmogorov and S. V. Fomin, Measure, Lebesgue Integrals, and Hilbert
Space (Academic Press, New York, 1960/1962), transl. by Natascha Artin
Brunswick and Alan Jeﬀrey; ﬁrst publ. in Russian 1960.

[79] W. Rudin, Real and Complex Analysis (McGraw-Hill, London, 1970).

[80] C. Swartz, Measure, Integration, and Function Spaces (World Scientiﬁc Pub-

lishing, Singapore, 1994).

[81] D. H.

Fremlin, Measure
Fremlin,

1:
Minimum (Torres
England,
http://www.sx.ac.uk/maths/staff/fremlin/mt.htm;
2000.

Vol.
Colchester,

Theory.

The

Irreducible
2000/2004),
publ.
ﬁrst

Fremlin, Measure
(Torres

2:
[82] D. H.
dations
England,
http://www.sx.ac.uk/maths/staff/fremlin/mt.htm;
2001.

Theory.
Colchester,

Fremlin,

Vol.

Broad

Foun-
2001/2003),
publ.
ﬁrst

37

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

[83] D. H.

Fremlin, Measure
(Torres

3:
gebras
England,
http://www.sx.ac.uk/maths/staff/fremlin/mt.htm;
2002.

Theory.
Colchester,

Fremlin,

Vol.

Measure

Al-
2002/2004),
publ.
ﬁrst

[84] D. H. Fremlin, Measure Theory. Vol. 4:

I

Spaces. Part
http://www.sx.ac.uk/maths/staff/fremlin/mt.htm;
2003.

(Torres Fremlin, Colchester, England,

[85] D. H. Fremlin, Measure Theory. Vol. 4:

II

Spaces. Part
http://www.sx.ac.uk/maths/staff/fremlin/mt.htm;
2003.

(Torres Fremlin, Colchester, England,

Topological Measure
2003/2006),
publ.
ﬁrst

Topological Measure
2003/2006),
publ.
ﬁrst

[86] E. J. McShane, A uniﬁed theory of integration, Am. Math. Monthly 80(4),

349–359 (1973).

[87] A. M. Bruckner, Creating diﬀerentiability and destroying derivatives, Am.

Math. Monthly 85(7), 554–562 (1978).

[88] P.

Zakrzewski,

Some

set-theoretic

aspects

Cubo Matemática

ory,
http://www.mimuw.edu.pl/~piotrzak/publications.html.

Educacional

3(2),

of measure
75–88

the-
(2001),

[89] M. R. Novick, Multiparameter Bayesian indiﬀerence procedures, J. Roy. Stat.

Soc. B 31(1), 29–64 (1969).

[90] S. L. Zabell, The rule of succession, Erkenntnis 31(2–3), 283–321 (1989).

[91] H. M. Jaeger, S. R. Nagel, and R. P. Behringer, Granular solids, liquids, and

gases, Rev. Mod. Phys. 68(4), 1259–1273 (1996).

[92] P. G. de Gennes, Granular matter: a tentative view, Rev. Mod. Phys. 71(2),

S374–S382 (1999).

[93] F. Rouyer and N. Menon, Velocity ﬂuctuations in a homogeneous 2D granular

gas in steady state, Phys. Rev. Lett. 85(17), 3676–3679 (2000).

[94] A. Puglisi, V. Loreto, U. Marini Bettolo Marconi, and A. Vulpiani, Kinetic
approach to granular gases, Phys. Rev. E 59(5), 5582–5595 (1999), eprint
arXiv:cond-mat/9810059.

[95] T. P. C. van Noije and M. H. Ernst, Velocity distributions in homogeneous
granular ﬂuids: the free and the heated case, Granular Matter 1(2), 57–64
(1998), eprint arXiv:cond-mat/9803042.

[96] S. Newcomb, Note on the frequency of use of the diﬀerent digits in natural

numbers, Am. J. Math. 4(1/4), 39–40 (1881), benford.

38

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

[97] F. Benford, The law of anomalous numbers, Proc. Am. Philos. Soc. 78(4),

[98] R. A. Raimi, The ﬁrst digit problem, Am. Math. Monthly 83(7), 521–538

[99] R. A. Raimi, The ﬁrst digit phenomenon again, Proc. Am. Philos. Soc. 129(2),

551–572 (1938).

(1976).

211–219 (1985).

[100] E. T. Jaynes, The minimum entropy production principle, Annu. Rev. Phys.
Chem. 31, 579 (1980), http://bayes.wustl.edu/etj/node1.html.

[101] E. T. Jaynes, Macroscopic prediction, in Complex Systems — Operational
Approaches, edited by H. Haken (Springer-Verlag, Berlin, 1985), p. 254,
http://bayes.wustl.edu/etj/node1.html.

[102] R. C. Dewar,

Information theory explanation of

the ﬂuctuation theo-
rem, maximum entropy production and self-organized criticality in non-
equilibrium stationary states, J. Phys. A 36(3), 631–641 (2003), eprint
arXiv:cond-mat/0005382.

[103] R. C. Dewar, Maximum entropy production and the ﬂuctuation theorem, J.

Phys. A 38(21), L371–L381 (2005).

[104] R. C. Dewar, Maximum entropy production and non-equilibrium statistical

mechanics, in Kleidon and Lorenz [117] (2005), pp. 41–55.

[105] B. de Finetti, Sur la condition d’équivalence partielle (1938), transl. in [59].

[106] E. T. Jaynes, Monkeys, kangaroos and N, in Maximum-Entropy and Bayesian
Methods in Applied Statistics, edited by J. H. Justice (Cambridge University
Press, Cambridge, 1986), p. 26, see also the revised and corrected version [1].

[107] R. Jeﬀrey, Reading Probabilismo, Erkenntnis 31(2–3), 225–237 (1989),

see [3].

[108] H. E. Kyburg, Jr. and H. E. Smokler, eds., Studies in Subjective Probability

(John Wiley & Sons, New York, 1964).

[109] B. de Finetti, La prévision : ses lois logiques, ses sources subjectives, Ann.

Inst. Henri Poincaré 7(1), 1–68 (1937), transl. as [4].

[110] P. S. Laplace, (Marquis de), Œuvres complètes de Laplace. Tome septième :
Théorie analytique des probabilités (Gauthier-Villars, Paris, 1886), “Publiées
sous les auspices de l’Académie des sciences, par MM. les secrétaires perpé-
tuels”; http://gallica.bnf.fr/notice?N=FRBNF30739022.

[111] J. Hintikka and P. Suppes, eds., Aspects of Inductive Logic (North-Holland,

Amsterdam, 1966).

39

Porta Mana, Månsson, Bj¨ork

The Laplace-Jaynes approach to induction

[112] P. Exner and H. Neidhardt, eds., Order, Disorder and Chaos in Quantum Sys-
tems: Proceedings of a conference held at Dubna, USSR on October 17–21,
1989 (Birkhäuser Verlag, Basel, 1990).

[113] R. C. Jeﬀrey, ed., Studies in inductive logic and probability (University of

California Press, Berkeley, 1980).

[114] J. Hintikka and P. Suppes, eds., Information and Inference (D. Reidel Publish-

ing Company, Dordrecht, 1970).

[115] P. S. Laplace, (Marquis de), Œuvres complètes de Laplace. Tome hui-
tième : Mémoires extraits des recueils de l’Académie des sciences
de Paris et de la classe des sciences mathématiques et physiques de
l’Institut de France (Gauthier-Villars, Paris, 1891), “Publiées sous les aus-
pices de l’Académie des sciences, par MM. les secrétaires perpétuels”;
http://gallica.bnf.fr/notice?N=FRBNF30739022.

[116] P. S. Laplace, (Marquis de), Memoir on the probability of the causes of events,
Stat. Sci. 1(3), 364–378 (1986), transl. by S. M. Stigler of [72]; see also the
translator’s introduction [118].

[117] A. Kleidon and R. D. Lorenz, eds., Non-equilibrium Thermodynamics and the
Production of Entropy: Life, Earth, and Beyond (Springer, Berlin, 2005), with
a Foreword by Hartmut Grassl.

[118] S. M. Stigler, Laplace’s 1774 memoir on inverse probability, Stat. Sci. 1(3),

359–363 (1986), introduction to the transl. [116].

40

