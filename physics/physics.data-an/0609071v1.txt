6
0
0
2
 
p
e
S
 
8
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
1
7
0
9
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Fast Spatial Prediction from Inhomogeneously Sampled Data
Based on Generalized Random Fields with Gibbs Energy Functionals

Dionissios T. Hristopulos∗ and Samuel Elogne†
Department of Mineral Resources Engineering
Technical University of Crete
Chania 73100, Greece

An explicit optimal linear spatial predictor is derived. The spatial correlations are imposed by
means of Gibbs energy functionals with explicit coupling coeﬃcients instead of covariance matrices.
The model inference process is based on physically identiﬁable constraints corresponding to distinct
terms of the energy functional. The proposed predictor is compared with the geostatistical linear
optimal ﬁlter (kriging) using simulated data. The agreement between the two methods is excellent.
The proposed framework allows a uniﬁed approach to the problems of parameter inference, spatial
prediction and simulation of spatial random ﬁelds.

PACS numbers: 02.50.Tt,02.50.Fz,05.40.-a,05.10.Ln,89.60.-k,89.70.+c
Keywords: correlations, Hamiltonian, stochastic estimation, interpolation

INTRODUCTION

Spatial prediction of physical variables from samples
that are irregularly distributed in space is a task with
applications in many ﬁelds of science and engineering,
including subsurface hydrology [1, 2], oil reservoir engi-
neering [3, 4], environmental pollutant mapping and risk
assessment [5], mining exploration and reserves estima-
tion [6], environmental health studies [7], image analysis
[8] and neuroscience [9]. Physical quantities of econom-
ical and environmental interest include mineral grades,
concentrations of environmental pollutants, soil and rock
permeability and ﬂow ﬁelds in oil reservoirs. Modeling
the variability of such processes is based on the theory
of spatial random ﬁelds (SRFs) [10]. Knowledge of spa-
tial correlations in SRFs enables (i) generating predic-
tive isolevel maps (ii) estimating prediction uncertainty
and (iii) developing simulations that reconstruct proba-
ble scenarios conditioned on the data. The classical ap-
proach is based on Gaussian SRF’s (GSRF’s) and various
generalizations for non-Gaussian distributions [11, 12].
For GSRF’s the spatial structure is determined from the
covariance matrix, which is estimated from the available
sample(s).
Let Ω

Rd denote the area of interest, and
its vol-
ume. An SRF state (realization) in Ω can be decomposed
into a deterministic trend mx(s), a correlated ﬂuctua-
tion Xλ(s), and an independent random noise term, ǫ(s),
i.e., X(s) = mx(s) + Xλ(s) + ǫ(s). The trend represents
large-scale variations obtained in principle by ensemble
averaging, i.e. mx(s) = E[X(s)]. In practice, the trend
is often determined from a single available realization.
The ﬂuctuation represents ‘fast variations’ describing ﬁne
structure above the resolution limit λ. The random noise
represents non-resolved inherent variability, purely ran-
dom additive noise, or non-systematic measurement er-
rors. The ﬂuctuation typically is a second-order station-
ary SRF, or an intrinsic SRF with second-order station-

Ω
|

∈

|

ary increments [10]. The residual SRF after trend re-
moval is a zero-mean ﬂuctuation: X ∗(s) = Xλ(s) + ǫ(s).
The inference process focuses on determining a model for
Xλ(s) from a set of possibly noisy observations X ∗(s).

H[X(s)]
}

In statistical physics the probability density function
(pdf ) of any ﬂuctuation ﬁeld X(s) governed by an en-
is expressed as fx[X(s)] =
ergy functional H[X(s)]
Z −1 exp
, where Z is the partition function.
{−
In classical geostatistics, the Gaussian joint pdf for a set
of ﬂuctuations X =
is expressed in
terms of H[X] = 1
is
the inverse covariance matrix, and summation is implied
over repeated indices. Instead, Spartan Spatial Random
Fields (SSRF’s) [13] model spatial correlations in terms
of ‘interactions’. This change in viewpoint has important
consequences for model inference and spatial prediction.

}
ij X(sj), where [Cx]−1

{
2 X(si) [Cx]−1

X(si), i = 1 . . . , N

ij

THE FGC MODEL

In [13] the ﬂuctuation-gradient-curvature (FGC) SSRF
model is deﬁned and its properties investigated. The
continuum FGC model involves the following H[X]:

1
2η0ξd Z

,

2

(cid:2)

ds

Hfgc[Xλ] =

2Xλ(s)
(cid:3)

where S0(s) = [Xλ(s)]2, S1(s) = [

S0(s) + η1 ξ2 S1(s) + ξ4 S2(s)
(cid:3)
(1)
Xλ(s)]2, and S2(s) =
∇
. The model is characterized by four param-
∇
eters: the scale coeﬃcient η0, the covariance-shape co-
(cid:2)
eﬃcient η1, the characteristic length ξ, and the cutoﬀ
wavevector kmax. Bochner’s permissibility theorem [5]
for the positive deﬁniteness of the covariance function
In statistical physics
requires η1 >
terminology, ℓ1 = η1 ξ2−d/(2 η0) and ℓ2 = ξ2−d/(2 η0)
represent the coupling strengths of the gradient and cur-
vature terms. A coarse-graining kernel is used to cut

.
2 if kmax → ∞

−

oﬀ the ﬂuctuations at kmax [13, 14], leading to band-
limited covariance spectral density. If kmax is ﬁnite, the
ﬁeld’s conﬁgurations are almost surely diﬀerentiable [14].
If kmax is inﬁnite, generalized gradient and constraints
should be used. The coarse-graining kernel implies that
the SRF Xλ is a generalized SRF [10].

A moment-based method for parameter estimation was
proposed and validated with simulated data [13]. The
inference process is based on matching ensemble con-
straints E[Sj (s)] with their sample counterparts, denoted
j(s), for j = 0, 1, 2. The procedure is extended in
by
S
[15].

s1, . . . sN

}

Assume Sm =

is a set of sampling points
{
on an irregular grid and X ∗(Sm) =
1 , . . . , X ∗
is the
respective vector of measurement. On an irregular grid,
the translation symmetry of the lattice is lost. The con-
tinuum FGC functional is then a more suitable model.
For practical purposed, a tractable approximation of the
continuum model is needed.

N }

X ∗

{

−

1),

Ai,j
h

d = 4d(d + 2), c(1)

d = d, c(2)
i6=j Ai,j Kh(si−sj )

In [15], approximations for the sample averages of
S1(s) and S2(s) are formulated in terms of kernel av-
In the following we use the
erages of the data values.
notation: c(0)
d = 4d2 and
c(3)
, where the
d = 2d(d
summation is over both indices (i, j = 1, . . . , N ) denotes
the average of the quantity Ai,j, weighted by the kernel
Kh(r) with bandwidth parameter h. The pair distance is
denoted by si,j =
is the Euclidean
k
k
norm of the distance vector r, and the ﬁeld increment by
X ∗(sj). Then, the generalized gradient
X ∗(si)
X ∗
constraint is given by

ih ≡ P

Kh(si−sj )

, where

i,j ≡

r
k

sj

si

−

−

i6=j

P

k

S1(s) =

c(1)
d
a2
1 D(cid:0)

2

X ∗
i,j

Eh1

(cid:1)

(2)

(cid:10)

s2
i,j

1 =

h1
(cid:11)

where a2
. Sensible estimates of the spacing
a1 should account for the grid topology. E.g., let B0 be
the set of near-neighbor vectors of all the points in Sm.
If B0 contains N0 vectors and ∆i denote the lengths of
the vectors in B0, then ˆad
1 = 1
i . Similarly, if
N0
s4
a4
, h3 = √2 h2, h4 = 2 h2, the generalized
P
2 =
i,j
h2
(cid:11)
(cid:10)
S2(s) is given by
curvature constraint

N0
i=1 ∆d

S2(s) =

1
a4
2 (cid:26)
c(1)
d

c(2)
d µ1

2

X ∗
i,j

D(cid:0)
2

(cid:1)

,

X ∗
i,j

D(cid:0)

Eh4 (cid:27)

(cid:1)

−

Eh2 −

c(3)
d µ2

2

X ∗
i,j

D(cid:0)

Eh3

(cid:1)

(3)

where µ1 and µ2 are 1 + o(ǫ) constants that depend on
the sampling network topology. The µ1, µ2 are deﬁned so
as to satisfy asymptotic bias and consistency properties
[15]. They introduce explicitly in the problem of model
inference four parameters linked to the topology of the
sampling network: the spacings a1 and a2 that replace

2

the lattice constant, and the bandwidths h1 and h2 that
determine the range of inﬂuence of the averaging kernel.
The latter are determined from the consistency principle
a2p
p =

, where p = 1, 2.

s2p
i,j

D

Ehp

SPATIAL PREDICTION

z1, . . . zK

}

zl

Let Zp =

be a set of prediction points, dis-
{
joint from Sm, Vl = Sm ∪ {
Sm. The
, and V = Zp ∪
}
ˆXλ(zl), l = 1, . . . , K
predictions will be denoted by
}
{
and the respective prediction vector by ˆXλ(Zp). The in-
crements corresponding to Vl will be denoted by αp(Vl),
p = 1, 2. Typically, single-point prediction is applied
sequentially over all points in Zp. Multiple-point predic-
tion is possible in the SSRF framework, but this letter
focuses on single-point prediction.

Optimal Linear Prediction

M

P

In geostatistics, spatial prediction is based on the Best
Linear Unbiased Estimator (BLUE), commonly known
as Kriging [1, 12]. Diﬀerent variants of kriging exist, de-
pending on the hypotheses about the normality of the
data and the behavior of the mean. These methods are
generalizations of the linear minimum mean square er-
ror (LMMSE) estimators, also known as Wiener ﬁlters
[16]. Ordinary kriging (OK) is the most common variety.
It is applied to normally distributed data, with an un-
known mean that can be considered as locally constant.
A single-point prediction is obtained as a superposition
ˆX(zl) =
j=1 λj X(sj), where sj are all the points inside
a local search neighborhood, B(sl), around zl. The pre-
diction error is deﬁned as ε(sl) = ˆX(zl)
X(zl). The op-
timal linear coeﬃcients should minimize the mean square
M
j=1 λj =
error conditional on the zero-bias constraint
1, i.e., the expression E
ε2(sl)
, where
(cid:3)
µ is a Lagrange coeﬃcient. This leads to the linear sys-
tem CX(si
i = 1, . . . , M
j=1 λj = 1, where CX(r) is the centered covari-
and
ance function. OK is an exact interpolator, meaning
. Exactitude is not al-
that
∈
ways desirable, since it ignores measurement errors and
over-constrains the predictions. For a ﬁxed-size search
neighborhood, the numerical complexity of an M -point
OK prediction is O(K M 3).

(cid:2)
sj) λj + µ = CX(si

ˆX(si) = X ∗(si),

M
j=1λj

P
1
(cid:17)

Sm}

si
∀

(cid:16)P

zl),

+µ

P

−

−

−

−

∀

M

{

Spatial Prediction based on FGC Functional

Once the parameters of the FGC model have been de-
termined from the data, prediction of the SRF at zl is
possible by means of at least two diﬀerent approaches.

First, the corresponding covariance function is deter-
mined and spatial predictions are then obtained using the
OK predictor. In this case, the only diﬀerence introduced
by the SSRF functional is the covariance estimator.

|

|

Xλ(Sm) ].

Since fX [ Xλ(zl)

Here we propose a diﬀerent predictor, obtained
by maximizing the conditional probability density
fX [ Xλ(zl)
Xλ(Sm) ] =
fX [ Xλ(Vl) ] /fX [Xλ(Sm)], the prediction is obtained by
maximizing fX [Xλ(Vl)]. In principle, this requires solv-
ing the equation δHfgc/δXλ(zl) = 0, where
δXλ(zl) is the
variational derivative of the functional given by Eq. (1)
with respect to Xλ(zl). In practice, Hfgc is replaced by a
discretized estimator, ˆHfgc. Since ˆHfgc is a bilinear func-
tional, the prediction follows from the solution of the
linear equation:

δ[.]

∂ ˆHfgc [ Xλ(Vl)]
∂Xλ(zl)

ˆXλ(zl)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= 0.

(4)

ˆHfgc is obtained by means of the estimators
0, 1, 2
, using the ergodic hypothesis
Ω
|

}
j(s), which leads to:

| S

R

j(s), j =

{S
ds Sj(s)

≈

Ω
|
2η0ξd

ˆHfgc[ Xλ(Vl)] = |

hS0(s) + η1 ξ2

S2(s)
i
(5)
where the spatial averages involve the sampling points
and the prediction point as well. In light of (2), (3), and
(5), equation (4) leads to the following linear predictor

S1(s) + ξ4

,

(6)

(7)

ˆXλ(zl) =

P

4
l
X ∗
i=1 qi ci(Vl)
hi
i
h
4
i=1 qi ci(Vl)
1 +
X ∗
h

1,

,

P
where q1 = q2 = 1, q3 = q4 =
average of the sample, centered at the prediction point

l
h is the kernel
i

−

X ∗
h

l
h =
i

P

Kh(sl

i

−
Kh(sl

i

si) X ∗
i
si)

,

−
ci, i = 1, 2, 3, 4
and the linear coeﬃcients
}
ci(Vl) = bi(Vl) (N +1) ghi(Vl), b1(Vl) = c(1)
d η1 ˇξ2
c(2)
2, b4(Vl) = c(1)
2 , b3(Vl) = c(3)
d µ1(Vl) ˇξ4
ˇξp = ξ/ap(Vl) and

are given by
1, b2(Vl) =
ˇξ4
2,

d µ2(Vl) ˇξ4

P
{

d

gh(Vl) =

Kh(si
P

j>i

P

si)

Kh(sl
sj) +

−

Kh(si

i

i

−

.

sl)

−

P

The summation in gh(Vl) extends over all the N (N
1)/2
non-identical and non-repeating pairs of sampling points.
Deﬁning the linear weights

−

λi(Vl) =

1)δi>2 ci(Vl)

(
−

,

1 + c1(Vl) + c2(Vl)

c3(Vl)

c4(Vl)

−

−

the prediction is expressed as

ˆXλ(zl) =

4

p=1

X

λp(Vl)

X ∗

l
hp.
i

h

(8)

3

Properties of the FGC Mode Predictor

The present formulation of the FGC mode predictor
(FGC-MP) is closer to simple kriging than OK, since the
mean is assumed to be known. However, unlike simple
kriging the mean does not have to be constant, provided
that it changes slowly so that the energy contributions
due to the square gradient and curvature of the mean can
be ignored compared to the ﬂuctuations. In this respect,
the predictor resembles OK, which allows for slow (but
unknown) variation of the mean. Predictions of the FGC-
MP are independent of η0, while the prediction variance
is linearly proportional to η0.

The FGC-MP is linear and unbiased. Since the joint
FGC pdf is Gaussian, the mode estimate is equivalent to
the minimum mean square estimate. Thus, the FGC-MP
is an optimal linear predictor. The main diﬀerences with
OK result from the use of the energy functional in the
FGC SSRF: (1) The FGC-MP is not an exact interpo-
lator, because it does not use the data at the prediction
point. (2) The single-point FGC-MP provides an explicit
expression for the prediction, while kriging requires solv-
ing a linear system. (3) The FGC-MP does not require
specifying a search neighborhood around the prediction
point; in kriging deﬁnition of a search neighborhood re-
quires an iterative procedure based on cross-validation of
the predictions with the data. (4) The FGC-MP incor-
porates two sets of parameters: the ﬁrst set determines
the spatial dependence of the SRF, while the second set
depends on the topology of the sampling network. The
inﬂuence of the sampling topology is not explicitly ac-
(5) The uncertainty estimate
counted for in kriging.
involves the SSRF covariance function, for which there
are no explicit solutions in d = 2, unlike d = 1, 3 [14].
Obtaining the covariance in d = 2 requires performing
numerically a univariate (for isotropic dependence) inte-
gration of the spectral density. (6) Regarding multiple-
point estimates the FGC-MP has a numerical complexity
O(K 3), derived from solving a linear system of K coupled
equations at the prediction points, while the numerical
complexity of kriging is O(K M 3).

PREDICTION USING SIMULATED SAMPLES

At 400 randomly distributed points on a square do-
main of length L = 100 we generate 100 independent
“samples”. These represent realizations of a Gaussian
random ﬁeld with mx = 50, and an exponential covari-
ance function Cx(r) = σ2
/be), where σx = 10,
x exp(
and be = 10. The Cholesky LU decomposition method
is used for the simulations. We partition the 400 points
into a training set Sm of 100 randomly selected points,
and a prediction set, Zp, including the remaining points.
We use the ﬁrst set to determine the optimal SSRF pa-
rameters, and then predict the values of the ﬁeld at the

r
k

−k

TABLE I: Statistics of OK performance.

Minimum Maximum Mean Median

bias
mae
rmse
mare
rmsre
R2

bias
mae
rmse
mare
rmsre
2
R

−1.90
5.00
6.28
0.10
0.13
0.38

−1.58
5.07
6.40
0.10
0.13
0.37

2.10
6.95
8.98
0.15
0.25
0.76

2.40
7.07
9.04
0.16
0.27
0.76

−0.04
6.03
7.76
0.12
0.17
0.62

−0.03
6.13
7.73
0.13
0.18
0.60

−0.14
6.11
7.81
0.12
0.17
0.63

−0.00
6.10
7.73
0.13
0.17
0.61

TABLE II: Statistics of FGC-Mode performance.

Minimum Maximum Mean Median

locations of the prediction set. The triangular kernel is
used in the FGC-predictor mode. Predictions are also
generated using the Ordinary Kriging method.

The performance of the predictors is evaluated using
the bias, the mean absolute error (mae), the root mean
square error (rmse), the mean absolute relative error
(mare), the root mean square relative error (rmsre) and
the linear correlation coeﬃcient (R2). The means are cal-
culated with respect to the values at the 300 prediction
points. Statistics of these quantities over the 100 sam-
ples are shown in Tables I and II. The kriging predictor
is applied with the a priori parameters of the exponen-
tial covariance (instead of the inferred covariance model
from the data). This choice aims at testing the FGC-
Mode Predictor against the “true” model. The results
show that the two predictors perform very similarly.

CONCLUSIONS

A fast linear optimal predictor, with applications in
the analysis of spatial data, is proposed. The predictor
is based on generalized random ﬁelds which represent the
spatial dependence in terms of interactions. An explicit
expression for single-point prediction is obtained. The re-
duced numerical complexity of the FGC-Mode predictor
may promote the use of cross-validation procedures for
model parameter inference, instead of the commonly used
parametric methods. The SRF representation, which
is based by construction on an objective function, pro-
vides a uniﬁed framework for model parameter estima-
tion, spatial prediction and constrained (respecting the
data) simulation. This is in contrast with classical ap-
proaches that require the introduction of ad hoc objective
functions [4, 6] for simulations (e.g., by means of simu-

4

lated annealing.) Expressions for the prediction uncer-
tainty and a linear system for multiple-point prediction
have also been derived and will be reported elsewhere
[17]. The multiple-point predictor accounts for interac-
tions between the prediction points that may lower the
total “energy”. Such interactions are missed in single-
point prediction. Finally, the FGC focuses on short-range
interactions, but long-range dependence can be incorpo-
rated in the SSRF framework with suitable modiﬁcations
of the energy functional.

Acknowledgments

This research is supported by the Marie Curie TOK
Action of the European Community (project “SPAT-
STAT” MTKD-CT-2004- 014135) and co-funded by
the European Social Fund and National Resources
(EPEAEK II) PYTHAGORAS.

∗ Electronic

address:

dionisi@mred.tuc.gr ;

URL: http://www.mred.tuc.gr/home/hristopoulos/dionisi.html

† Electronic address: elogne@mred.tuc.gr

[1] P. K. Kitanidis, Introduction to Geostatistics: Applica-

tions to Hydrogeology (Cambridge, 1997).

[2] Y. Rubin, Applied Stochastic Hydrogeology (Oxford Uni-

versity Press, New York, 2003).

[3] M. E. Hohn, Geostastistics and Petroleum Geology

(Kluwer, Dordrecht, 1999).

[4] H. Hamzhepour and M. Sahimi, Phys. Rev. E, 73, 056121

(2006).

[5] G. Christakos, Random Field Models in Earth Sciences

(Academic Press, San Diego, 1992).

[6] P. Goovaerts, Geostatistics for Natural Resources Evalu-

ation (Oxford, NY, 1997).

[7] G. Christakos, and D. T. Hristopulos, Spatiotemporal En-
vironmental Health Modelling (Kluwer, Boston, 1998).
[8] G. Winkler, Image Analysis, Random Fields and Dy-
namic Monte Carlo Methods: A Mathematical Introduc-
tion (Springer, New York, 1995).

[9] A. Leow et al., NeuroImage, 24, 910 (2005).
[10] M. Yaglom, Correlation Theory of Stationary and Related
Random Functions I (Springer, New York, 1987).
[11] C. Lantuejoul, Geostatistical Simulation: Models and Al-

gorithms (Springer, Berlin, 2002).

[12] H. Wackernagel, Multivariate Geostatistics (Springer,

Berlin, 2003).

[13] D. T. Hristopulos, SIAM J. Sci. Comput. 24 2125 (2003).
[14] D. T. Hristopulos and S. N. Elogne, submitted to IEEE

Trans. Inform. Theor., cs.IT/0605073.

[15] S. N. Elogne

and D. T. Hristopulos

(2006).

math.ST/0603430.

[16] J. Ruiz-Alzola, C. Alberola-L´opez and C.-F. Westin, Sig-

nal Processing, 85(2), 413 (2005).

[17] D. T. Hristopulos and S. N. Elogne, in preparation.

