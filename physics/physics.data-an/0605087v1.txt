6
0
0
2
 
y
a
M
 
0
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
7
8
0
5
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Finding community structure in networks using the eigenvectors of matrices

M. E. J. Newman

Department of Physics and Center for the Study of Complex Systems, University of Michigan, Ann Arbor,
MI 48109–1040

We consider the problem of detecting communities or modules in networks, groups of vertices with
a higher-than-average density of edges connecting them. Previous work indicates that a robust
approach to this problem is the maximization of the quality function known as “modularity” over
possible divisions of a network. Here we show that this maximization process can be written in
terms of the eigenspectrum of a matrix we call the modularity matrix, which plays a role in com-
munity detection similar to that played by the graph Laplacian in graph partitioning calculations.
This result leads us to a number of possible algorithms for detecting community structure, as
well as several other results, including a spectral measure of bipartite structure in networks and
a new centrality measure that identiﬁes those vertices that occupy central positions within the
communities to which they belong. The algorithms and measures proposed are illustrated with
applications to a variety of real-world complex networks.

I. INTRODUCTION

Networks have attracted considerable recent attention
in physics and other sciences as a foundation for the
mathematical representation of a variety of complex sys-
tems, including biological and social networks, the Inter-
net, the worldwide web, and many others [1, 2, 3, 4]. A
common feature of many networks is “community struc-
ture,” the tendency for vertices to divide into groups of
vertices, with dense connections within groups and only
sparser connections between groups [5, 6]. Social net-
works [5], biochemical networks [7, 8, 9], and informa-
tion networks such as the web [10], have all been shown
to possess strong community structure, a ﬁnding that has
substantial practical implications for our understanding
of the systems these networks describe. Communities are
of interest because they often correspond directly to func-
tional units such as cycles or circuits in a metabolic net-
work [8, 9, 11] or pages on a single topic on the web [10],
but their inﬂuence reaches further than this. A number of
recent results suggest that networks can have properties
at the community level that are quite diﬀerent from their
properties at the level of the entire network, so that anal-
yses that focus on whole networks and ignore community
structure may miss many of the interesting features of a
system.

For instance, in some social networks one ﬁnds individ-
uals with diﬀerent mean numbers of contacts in diﬀerent
groups; the individuals in one group might be gregarious,
having many contacts with others, while the individuals
in another group are more reticent. An example of this
behavior is seen in networks of sexual contacts, where
separate communities of high- and low-activity individ-
uals have been observed [12, 13].
If one were to char-
acterize such a network by quoting only a single ﬁgure
for the average number of contacts an individual has, one
would be missing features of the network directly relevant
to questions of scientiﬁc interest such as epidemiological
dynamics [14].

It has also been shown that vertices’ positions within

communities can aﬀect the role or function they assume.
In social networks, for example, it has long been accepted
that individuals who lie on the boundaries of communi-
ties, bridging gaps between otherwise unconnected peo-
ple, enjoy an unusual level of inﬂuence as the gatekeepers
of information ﬂow between groups [15, 16, 17]. A sur-
prisingly similar result is found in metabolic networks,
where metabolites that straddle the boundaries between
modules are found to show particular persistence across
species [8]. This ﬁnding might indicate that modules in
metabolic networks possess some degree of functional in-
dependence within the cell, allowing vertices central to a
module to change or disappear with relatively little eﬀect
on the rest of the network, while vertices on the borders
of modules are less able to change without aﬀecting other
aspects of the cellular machinery.

One can also consider the communities in a network
themselves to form a higher level meta-network, a coarse-
grained representation of the full network. Such coarse-
grained representations have been used in the past as
tools for visualization and analysis [18] but more recently
have also been investigated as topologically interesting
entities in their own right. In particular, the degree dis-
tributions of networks of modules appear to have inter-
esting similarities to but also some diﬀerences from the
degree distributions of other networks [9], and may also
display so-called preferential attachment in their forma-
tion [19], indicating the possibility of distinct dynamical
processes taking place at the level of the modules.

For all of these reasons and others besides there has
been a concerted eﬀort in recent years within the physics
community and elsewhere to develop mathematical tools
and computer algorithms to detect and quantify com-
munity structure in networks. A huge variety of com-
munity detection techniques have been developed, based
variously on centrality measures, ﬂow models, random
walks, resistor networks, optimization, and many other
approaches [5, 8, 9, 18, 20, 21, 22, 23, 24, 25, 26, 27,
28, 29, 30, 31, 32, 33, 34, 35, 36, 37]. For reviews see
Refs. [6, 38].

In this paper we focus on one approach to community
detection that has proven particularly eﬀective, the opti-
mization of the quality function known as “modularity”
over the possible divisions of a network. Methods based
on this approach have been found to produce excellent
results in standardized tests [33, 38]. Unfortunately, ex-
haustive optimization of the modularity demands an im-
practically large computational eﬀort, but good results
have been obtained with various approximate optimiza-
tion methods, including greedy algorithms [24, 39], simu-
lated annealing [36, 40], and extremal optimization [41].
In this paper we describe a diﬀerent approach, in which
we rewrite the modularity function in matrix terms,
which allows us to express the optimization task as a
spectral problem in linear algebra. This approach leads
to a family of fast new computer algorithms for commu-
nity detection that produce results competitive with the
best previous methods. Perhaps more importantly, our
work also leads to a number of useful insights about net-
work structure via the close relations we will demonstrate
between communities and matrix spectra.

Our work is by no means the ﬁrst to ﬁnd connec-
tions between divisions of networks and matrix spectra.
There is a large literature within computer science on so-
called spectral partitioning, in which network properties
are linked to the spectrum of the graph Laplacian ma-
trix [42, 43, 44]. This method is diﬀerent from the one
introduced here and is not in general well suited to the
problem of community structure detection. The reasons
for this, however, turn out to be interesting and instruc-
tive, so we being our presentation with a brief review
of the traditional spectral partitioning method in Sec-
tion II. A consideration of the deﬁciencies of the method
in Section III leads us in Section IV to introduce and de-
velop at length our own method, which is based on the
characteristic matrix we call the “modularity matrix.”
Sections VII and VIII explore some further ideas arising
from the study of the modularity matrix but not directly
related to the problem of community detection. In Sec-
tion IX we give our conclusions. A brief report of some
of the results described in this paper has appeared pre-
viously as Ref. [34].

II. GRAPH PARTITIONING AND THE LAPLACIAN
MATRIX

There is a long tradition of research in computer sci-
ence on graph partitioning, a problem that arises in a
variety of contexts, but most prominently in the devel-
opment of computer algorithms for parallel or distributed
computation. Suppose a computation requires the per-
formance of some number n of tasks, each to be carried
out by a separate process, program, or thread running
on one of c diﬀerent processors. Typically there is a de-
sired number of tasks or volume of work to be assigned
to each of the processors; if the processors are identical,
for instance, and the tasks are of similar complexity, we

2

may wish to assign the same number of tasks to each
processor so as to share the workload roughly equally. It
is also typically the case that the individual tasks require
for their completion results generated during the perfor-
mance of other tasks, so tasks must communicate with
one another to complete the overall computation. The
pattern of required communications can be thought of as
a network with n vertices representing the tasks and an
edge joining any pair of tasks that need to communicate,
for a total of m edges. (In theory the amount of com-
munication between diﬀerent pairs of tasks could vary,
leading to a weighted network, but we here restrict our
attention to the simplest unweighted case, which already
presents interesting challenges.)

Normally, communications between processors in par-
allel computers are slow compared to data movement
within processors, and hence we would like to keep such
communications to a minimum.
In network terms this
means we would like to divide the vertices of our net-
work (the processes) into groups (the processors) such
that the number of edges between groups is minimized.
This is the graph partitioning problem.

Problems of this type can be solved exactly in polyno-
mial time [45], but unfortunately the polynomial in ques-
tion is of leading order nc2
, which is already prohibitive
for all but the smallest networks even when c takes the
smallest possible value of 2. For practical applications,
therefore, a number of approximate methods have been
developed that appear to give reasonably good solutions.
One of the most widely used is the spectral partitioning
method, due originally to Fiedler [42] and popularized
particularly by Pothen et al. [43]. We here consider the
simplest instance of the method, where c = 2, i.e., where
our network of n vertices is to be divided into just two
non-intersecting subsets such that the number of edges
running between the subsets is minimized.

We begin by deﬁning the adjacency matrix A to be

the matrix with elements

Aij =

(

1
0

if there is an edge joining vertices i, j,
otherwise.

(1)

(We restrict our attention in this paper to undirected
networks, so that A is symmetric.) Then the number of
edges R running between our two groups of vertices, also
called the cut size, is given by

R = 1
2

Aij ,

i, j in
X
diﬀerent
groups

(2)

where the factor of 1
edge twice in the sum.

2 compensates for our counting each

To put this in a more convenient form, we deﬁne an

index vector s with n elements

+1 if vertex i belongs to group 1,
1 if vertex i belongs to group 2.

(3)

si =

(

−

(Note that s satisﬁes the normalization condition sT s =
n.) Then

n
i=1 aivi, where ai = vT

s =
sT s = n implies that

i s and the normalization

1
2 (1

−

sisj) =

(

1
0

if i and j are in diﬀerent groups,
if i and j are in the same group,

which allows us to rewrite Eq. (2) as

R = 1
4

(1

sisj)Aij .

−

ij
X

Noting that the number of edges ki connected to a ver-
tex i—also called the degree of the vertex—is given by

ki =

Aij ,

j
X

the ﬁrst term of the sum in (5) is

Aij =

ki =

s2
i ki =

sisjkiδij ,

(7)

i
X

ij
X

i
X
where we have made use of s2
the values
Thus

±

i = 1 (since si can take only
1), and δij is 1 if i = j and zero otherwise.

ij
X

matrix is zero:

R = 1
4

sisj(kiδij

Aij ).

−

ij
X

We can also write this in matrix form as

R = 1

4 sT Ls,

where L is the real symmetric matrix with elements Lij =
kiδij

Aij, or equivalently1

−

ki

if i = j,

Lij = 


−
0

otherwise.

1 if i

= j and there is an edge (i, j),

(10)



L is called the Laplacian matrix of the graph. The Lapla-
cian matrix appears in many contexts in the theory of
networks, such as in the analysis of diﬀusion and random
walks on networks [46] and the dynamics of coupled oscil-
lators [47, 48]. Its properties are the subject of hundreds
of papers in the mathematics and physics literature and
are by now quite well understood. For our purposes, how-
ever, we will need only a few simple observations about
the matrix to make progress.

Our task is to choose the vector s so as to minimize the
cut size, Eq. (9). Let us write s as a linear combination
of the normalized eigenvectors vi of the Laplacian thus:

1 We assume here that the network is a simple graph, having at
most one edge between any pair of vertices and no self-edges
(edges that connect vertices to themselves).

(4)

(5)

(6)

(8)

(9)

3

(11)

P

Then

a2
i = n.

n

i=1
X

R =

aivT

i L

ajvj =

aiajλj δij =

a2
i λi,

i
X

i
X

j
X

ij
X

(12)
is the eigenvalue of L corresponding to the
where λi
eigenvector vi and we have made use of vT
i vj = δij.
Without loss of generality, we assume that the eigenval-
λn.
λ2 ≤
ues are labeled in increasing order λ1 ≤
The task of minimizing R can then be equated with the
task of choosing the nonnegative quantities a2
i so as to
place as much as possible of the weight in the sum (12) in
the terms corresponding to the lowest eigenvalues, and as
little as possible in the terms corresponding to the high-
est, while respecting the normalization constraint (11).

. . .

≤

The sum of every row (and column) of the Laplacian

Lij =

(kiδij

Aij) = ki

ki = 0,

(13)

−

−

j
X

j
X

where we have made use of (6). Thus the vector
(1, 1, 1, . . .) is always an eigenvector of the Laplacian with
It is less trivial, but still straightfor-
eigenvalue zero.
ward, to demonstrate that all eigenvalues of the Lapla-
cian are nonnegative. (The Laplacian is symmetric and
equal to the square of the edge incidence matrix, and
hence its eigenvalues are all the squares of real num-
bers.) Thus the eigenvalue 0 is always the smallest eigen-
value of the Laplacian and the corresponding eigenvector
is v1 = (1, 1, 1, . . .)/√n, correctly normalized.

Given these observations it is now straightforward to
see how to minimize the cut size R.
If we choose
s = (1, 1, 1, . . .), then all of the weight in the ﬁnal sum
in Eq. (12) is in the term corresponding to the lowest
eigenvalue λ1 = 0 and all other terms are zero, since
(1, 1, 1, . . .) is an eigenvector and the eigenvectors are or-
thogonal. Thus this choice gives us R = 0, which is the
smallest value it can take since it is by deﬁnition a non-
negative quantity.

Unfortunately, when we consider the physical inter-
pretation of this solution, we see that it is trivial and
uninteresting. Given the deﬁnition (3) of s, the choice
s = (1, 1, 1, . . .) is equivalent to placing all the vertices in
group 1 and none of them in group 2. Technically, this
is a valid partition of the network, but it is not a useful
one. Of course the cut size is zero if we put all the ver-
tices in one of the groups and none in the other, but such
a trivial solution tells us nothing about how to solve our
original problem.

We would like to forbid this trivial solution, so as to
force the method to ﬁnd nontrivial ones. A variety of
ways have been explored for achieving this goal, of which

6
the most common is to ﬁx the sizes of the two groups,
which is convenient if, as discussed above, the sizes of the
groups are speciﬁed anyway as a part of the problem. In
the present case, ﬁxing the sizes of the groups ﬁxes the
coeﬃcient a1 of the ﬁrst term in the sum in Eq. (12). For
instance, if the required sizes of the groups are n1 and n2,
then

a1 = vT

1 s =

(n1 −
√n

n2)

.

(14)

Since we cannot vary this coeﬃcient, we shift our at-
tention to the other terms in the sum. If there were no
further constraints on our choice of s, apart from the nor-
malization condition sT s = n, our course would be clear:
R is minimized by choosing s proportional to the second
eigenvector v2 of the Laplacian, also called the Fiedler
vector. This choice places all of the weight in Eq. (12)
in the term involving the second-smallest eigenvalue λ2,
also known as the algebraic connectivity. The other terms
would automatically be zero, since the eigenvectors are
orthogonal.

±

Unfortunately, there is an additional constraint on s
imposed by the condition, Eq. (3), that its elements take
1, which means in most cases that s cannot
the values
be chosen parallel to v2. This makes the optimization
problem much more diﬃcult. Often, however, quite good
approximate solutions can be obtained by choosing s to
be as close to parallel with v2 as possible. This means
maximizing the quantity

vT
1 s

=

v(1)
i si

v(1)
i

,

(15)

≤

i
X

(cid:12)
(cid:12)
(cid:12)
(cid:12)

i
X

(cid:12)
(cid:12)
(cid:12)
(cid:12)

i

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)
where v(1)
is the ith element of v1. Here the second
relation follows via the triangle inequality, and becomes
an equality only when all terms in the ﬁrst sum are posi-
vT
1 s
tive (or negative). In other words, the maximum of
|
|
is achieved when v(1)
0 for all i, or equivalently when
si has the same sign as v(1)
. Thus the maximum is ob-
tained with the choice

i si

≥

i

si =

+1
1

−

(

if v(1)
if v(1)

1,
i ≥
i < 1.

(16)

−

Even this choice however is often forbidden by the con-
1 elements of s be
dition that the number of +1 and
equal to the desired sizes n1 and n2 of the two groups, in
which case the best solution is achieved by assigning ver-
tices to one of the groups in order of the elements in the
Fiedler vector, from most positive to most negative, until
the groups have the required sizes. For groups of diﬀer-
ent sizes there are two distinct ways of doing this, one in
which the smaller group corresponds to the most positive
elements of the vector and one in which the larger group
does. We can choose between them by calculating the
cut size R for both cases and keeping the one that gives
the better result.

(a)

(b)

4

FIG. 1 (a) The mesh network of Bern et al. [49]. (b) The
best division into equal-sized parts found by the spectral par-
titioning algorithm based on the Laplacian matrix.

This then is the spectral partitioning method in its
simplest form.
It is not guaranteed to minimize R,
but, particularly in cases where λ2 is well separated
from the eigenvalues above it, it often does very well.
Figure 1 shows an example application typical of those
found in the literature, to a two-dimensional mesh such
as might be used in parallel ﬁnite-element calculations.
This particular mesh is a small 547-vertex example from
Bern et al. [49] and is shown complete in panel (a) of
the ﬁgure. Panel (b) shows the division of the mesh into
two parts of 273 and 274 vertices respectively using the
spectral partitioning approach, which ﬁnds a cut of size
46 edges in this case.

Although the cut found in this example is certainly a
reasonable one, it does not appear—at least to this au-
thor’s eye—that the vertex groups in Fig. 1b constitute
any kind of natural division of the network into “commu-
nities.” This is typical of the problems to which spectral
in most circumstances
partitioning is usually applied:
the network in question does not divide up easily into
groups of the desired sizes, but one must do the best one
can. For these types of tasks, spectral partitioning is an
eﬀective and appropriate tool. The task of ﬁnding natu-
ral community divisions in a network, however, is quite
diﬀerent, and demands a diﬀerent approach, as we now
discuss.

III. COMMUNITY STRUCTURE AND MODULARITY

Despite its evident success in the graph partitioning
arena, spectral partitioning is a poor approach for de-
tecting natural community structure in real-world net-
works, which is the primary topic of this paper. The is-
sue is with the condition that the sizes of the groups into
which the network is divided be ﬁxed. This condition
is neither appropriate nor realistic for community detec-
tion problems. In most cases we do not know in advance
the sizes of the communities in a network and choosing

arbitrary sizes will usually preclude us from ﬁnding the
best solution to the problem. We would like instead to
let the group sizes be free, but the spectral partitioning
method breaks down if we do this, as we have seen:
if
the group sizes are not ﬁxed, then the minimum cut size
is always achieved by putting all vertices in one group
Indeed, this statement is con-
and none in the other.
siderably broader than the spectral partitioning method
itself, since any method that correctly minimizes the cut
size without constraint on the group sizes is sure to ﬁnd,
in the general case, that the minimum value is achieved
for this same trivial division.

The fundamental problem is that cut size is not the
right thing to optimize because it doesn’t accurately re-
ﬂect our intuitive concept of network communities. A
good division of a network into communities is not merely
one in which the number of edges running between groups
is small. Rather,
it is one in which the number of
edges between groups is smaller than expected. Only if
the number of between-group edges is signiﬁcantly lower
than would be expected purely by chance can we justi-
ﬁably claim to have found signiﬁcant community struc-
ture. Equivalently, we can examine the number of edges
within communities and look for divisions of the network
in which this number is higher than expected—the two
approaches are equivalent since the total number of edges
is ﬁxed and any edges that do not lie between communi-
ties must necessarily lie inside them.

These considerations lead us to shift our attention from
pure cut size to a modiﬁed beneﬁt function Q deﬁned by

Q = (number of edges within communities)
(expected number of such edges).

(17)

−

This beneﬁt function is called modularity [18, 50]. It is
a function of the particular division of the network into
groups, with larger values indicating stronger community
structure. Hence we should, in principle, be able to ﬁnd
good divisions of a network into communities by opti-
mizing the modularity over possible divisions. This ap-
proach, proposed in [24] and since pursued by a number
of authors [8, 34, 39, 40, 41], has proven highly eﬀective
in practice [38] and is the primary focus of this article.

The ﬁrst term in Eq. (17) is straightforward to calcu-
late. The second, however, is rather vague and needs to
be made more precise before we can evaluate the modu-
larity. What exactly do we mean by the “expected num-
ber” of edges within a community? Answering this ques-
tion is essentially equivalent to choosing a “null model”
against which to compare our network. The deﬁnition
of the modularity involves a comparison of the number
of within-group edges in a real network and the number
in some equivalent randomized model network in which
edges are placed without regard to community structure.
It is one of the strengths of the modularity approach
that it makes the role of this null model explicit and clear.
All methods for ﬁnding communities are, in a sense, as-
suming some null model, since any method must make a
value judgment about when a particular density of edges

5

is signiﬁcant enough to deﬁne a community.
In most
cases, this assumption is hidden within the workings of a
computer algorithm and is diﬃcult to disentangle, even
when the algorithm itself is well understood. By bring-
ing its assumptions out into the open, the modularity
method gives us more control over our calculations and
more understanding of their implications.

Our null model must have the same number of ver-
tices n as the original network, so that we can divide
it into the same groups for comparison, but apart from
this we have a good deal of freedom about our choice of
model. We here consider the broad class of randomized
models in which we specify separately the probability Pij
for an edge to fall between every pair of vertices i, j. More
precisely, Pij is the expected number of edges between i
and j, a deﬁnition that allows for the possibility that
there may be more than one edge between a pair of ver-
tices, which happens in certain types of networks. We
will consider some particular choices of Pij in a moment,
but for now let us pursue the developments in general
form.

Given Pij , the modularity can be deﬁned as follows.
The actual number of edges falling between a particular
pair of vertices i and j is Aij , Eq. (1), and the expected
number is, by deﬁnition, Pij . Thus the actual minus
expected number of edges between i and j is Aij
Pij
and the modularity is the sum of this quantity over all
pairs of vertices belonging to the same community. Let us
deﬁne gi to be the community to which vertex i belongs.
Then the modularity can be written

−

Q =

1
2m

ij
X

(cid:2)

−

(cid:3)

Aij

Pij

δ(gi, gj),

(18)

where δ(r, s) = 1 if r = s and 0 otherwise and m is again
the number of edges in the network. The extra factor of
1/2m in Eq. (18) is purely conventional; it is included
for compatibility with previous deﬁnitions of the modu-
larity and plays no part in the maximization of Q since
it is a constant for any given network. A special case
of Eq. (18) was given previously by Clauset et al. [39]
and independently, in slightly diﬀerent form, by White
and Smyth [51]. A number of other expressions for
the modularity have also been presented by various au-
thors [18, 40, 41] and are convenient in particular applica-
tions. Also of interest is the derivation of the modularity
given recently by Reichardt and Bornholdt [36], which is
quite general and provides an interesting alternative to
the development presented here.

Returning to the null model, how should Pij be cho-
sen? The choice is not entirely unconstrained. First, we
consider in this paper only undirected networks, which
implies that Pij = Pji. Second, it is axiomatically the
case that Q = 0 when all vertices are placed in a single
group together: by deﬁnition, the number of edges within
groups and the expected number of such edges are both
equal to m in this case. Setting all gi equal in Eq. (18),

we ﬁnd that

Pij] = 0 or equivalently

ij[Aij

−

P

Pij =

Aij = 2m.

(19)

ij
X

ij
X
This equation says that we are restricted to null models
in which the expected number of edges in the entire net-
work equals the actual number of edges in the original
network—a natural choice if our comparison of numbers
of edges within groups is to have any meaning.

Beyond these basic considerations, there are many pos-
sible choices of null model and several have been consid-
ered previously in the literature [18, 27, 52]. Perhaps
the simplest is the standard (Bernoulli) random graph,
in which edges appear with equal probability Pij = p be-
tween all vertex pairs. With a suitably chosen value of
p this model can be made to satisfy (19) but, as many
authors have pointed out [53, 54, 55], the model is not
a good representation of most real-world networks. A
particularly glaring aspect in which it errs is its degree
distribution. The random graph has a binomial degree
distribution (or Poisson in the limit of large graph size),
which is entirely unlike the right-skewed degree distribu-
tions found in most real-world networks [56, 57]. A much
better null model would be one in which the degree dis-
tribution is approximately the same as that of the real-
world network of interest. To satisfy this demand we will
restrict our attention in this paper to models in which
the expected degree of each vertex within the model is
equal to the actual degree of the corresponding vertex
in the real network. Noting that the expected degree of
j Pij , we can express this condition
vertex i is given by
as

Pij = ki.

(20)

P

j
X

If this constraint is satisﬁed, then (19) is automatically
satisﬁed as well, since

i ki = 2m.
Equation (20) is a considerably more stringent con-
straint than (19)—it excludes for instance the Bernoulli
random graph—but it is one that we believe makes good
sense, and one moreover that has a variety of desirable
consequences for the developments that follow.

P

The simplest null model in this class, and the only one
that has been considered at any length in the past, is
the model in which edges are placed entirely at random,
subject to the constraint (20). That is, the probability
that an end of a randomly chosen edge attaches to a par-
ticular vertex i depends only on the expected degree ki
of that vertex, and the probabilities for the two ends of a
single edge are independent of one another. This implies
that the expected number of edges Pij between vertices i
and j is the product f (ki)f (kj) of separate functions of
the two degrees, where the functions must be the same
since Pij is symmetric. Then Eq. (20) implies

Pij = f (ki)

f (kj) = ki,

(21)

n

j=1
X

n

j=1
X

6

(23)

for all i and hence f (ki) = Cki for some constant C. And
Eq. (19) says that

2m =

Pij = C2

kikj = (2mC)2,

(22)

ij
X

ij
X

and hence C = 1/√2m and

Pij =

kikj
2m

.

This model has been studied in the past in its own right as
a model of a network, for instance by Chung and Lu [58].
It is also closely related to the conﬁguration model, which
has been studied widely in the mathematics and physics
literature [58, 59, 60, 61]. Indeed, essentially all expected
properties of our model and the conﬁguration model are
identical in the limit of large network size, and hence
Eq. (23) can be considered equivalent to the conﬁguration
model in this limit.2

Although many of the developments outlined in this
paper are true for quite general choices of the null model
used to deﬁne the modularity, the choice (23) is the only
one we will pursue here. It is worth keeping mind however
that other choices are possible: Massen and Doye [52], for
instance, have used a variant of the conﬁguration model
in which multiedges and self-edges were excluded. And
further choices could be useful in speciﬁc cases, such as
cases where there are strong correlations between the de-
grees of vertices [62, 63] or where there is a high level of
network transitivity [55].

IV. SPECTRAL OPTIMIZATION OF MODULARITY

Once we have an explicit expression for the modularity
we can determine the community structure by maximiz-
ing it over possible divisions of the network. Unfortu-
nately, exhaustive maximization over all possible divi-
sions is computational intractable because there are sim-
ply too many divisions, but various approximate opti-
mization methods have proven eﬀective [8, 24, 36, 39, 40,
41, 52]. Here, we develop a matrix-based approach anal-
ogous to the spectral partitioning method of Section II,
which leads not only to a whole array of possible opti-
mization algorithms but also to new insights about the

2 The technical diﬀerence between the two models is that the con-
ﬁguration model is a random multigraph conditioned on the ac-
tual degree sequence, while the model used here is a random
multigraph conditioned on the expected degree sequence. This
makes the ensemble of the former considerably smaller than that
of the latter, but the diﬀerence is analogous to the diﬀerence
between canonical and grand canonical ensembles in statistical
mechanics and the two give the same answers in the thermody-
namic limit for roughly the same reason. In particular, we note
that the probability of an edge falling between two vertices i and
j in the conﬁguration model is also given by Eq. (23) in the limit
of large network size; for smaller networks, there are corrections
of order 1/n.

nature and implications of community structure in net-
works.

A. Leading eigenvector method

As before, let us consider initially the division of a
network into just two communities and denote a potential
such division by an index vector s with elements as in
Eq. (3). We notice that the quantity 1
2 (sisj + 1) is 1 if i
and j belong to the same group and 0 if they belong to
diﬀerent groups or, in the notation of Eq. (18),

δ(gi, gj) = 1

2 (sisj + 1).

(24)

Thus we can write (18) in the form

Q =

Aij

Pij

(sisj + 1)

1
4m

1
4m

ij
X

(cid:2)

ij
X

(cid:2)

−

−

(cid:3)
sisj,

(cid:3)

=

Aij

Pij

(25)

where we have in the second line made use of Eq. (19).
This result can conveniently be rewritten in matrix form
as

where B is the real symmetric matrix having elements

Q =

sT Bs,

1
4m

Bij = Aij

Pij .

−

(26)

(27)

We call this matrix the modularity matrix and it plays
a role in the maximization of the modularity equivalent
to that played by the Laplacian in standard spectral par-
titioning: Equation (26) is the equivalent of Eq. (9) for
the cut size and matrix methods can thus be applied to
the modularity that are the direct equivalents of those
developed for spectral partitioning, as we now show.

First, let us point out a few important properties of the
modularity matrix. Equation (20) implies that all rows
(and columns) of the modularity matrix sum to zero:

Bij =

Aij

Pij = ki

ki = 0.

(28)

−

−

j
X

j
X

j
X
This immediately implies that for any network the vec-
tor (1, 1, 1, . . .) is an eigenvector of the modularity matrix
with eigenvalue zero, just as is the case with the Lapla-
cian. Unlike the Laplacian however, the eigenvalues of
the modularity matrix are not necessarily all of one sign
and in practice the matrix usually has both positive and
negative eigenvalues. This observation—and the eigen-
spectrum of the modularity matrix in general—are, as
we will see, closely tied to the community structure of
the network.

Working from Eq. (26) we now proceed by direct anal-
ogy with Section II. We write s as a linear combination of

7

modularity method

spectral partitioning

FIG. 2 The dolphin social network of Lusseau et al. [64]. The
dashed curve represents the division into two equally sized
parts found by a standard spectral partitioning calculation
(Section II). The solid curve represents the division found
by the modularity-based method of this section. And the
squares and circles represent the actual division of the net-
work observed when the dolphin community split into two
as a result of the departure of a keystone individual. (The
individual who departed is represented by the triangle.)

the normalized eigenvectors ui of the modularity matrix,
s =

i s. Then

n
i=1 aiui with ai = uT
1
4m

Q =

P

a2
i βi,

i
X

(29)

where βi is the eigenvalue of B corresponding to the
eigenvector ui. We now assume that the eigenvalues are
labeled in decreasing order β1 ≥
βn and the
task of maximizing Q is one of choosing the quantities a2
i
so as to place as much of the weight in the sum (29) in
the terms corresponding to the largest (most positive)
eigenvalues.

β2 ≥

. . .

≥

As with ordinary spectral partitioning, this would be a
simple task if our choice of s were unconstrained (apart
from normalization): we would just choose s proportional
to the leading eigenvector u1 of the modularity matrix.
But the elements of s are restricted to the values si =
1,
which means that s cannot normally be chosen parallel
to u1. Again as before, however, good approximate so-
lutions can be obtained by choosing s to be as close to
parallel with u1 as possible, which is achieved by setting

±

si =

+1
1

−

(

if u(1)
if u(1)

1,
i ≥
i < 1.

(30)

This then is our ﬁrst and simplest algorithm for com-
munity detection: we ﬁnd the eigenvector corresponding
to the most positive eigenvalue of the modularity matrix
and divide the network into two groups according to the
signs of the elements of this vector.

In practice, this method works nicely, as discussed in
Ref. [34]. Making the choice (23) for our null model, we
have applied it to a variety of standard and less stan-
dard test networks and ﬁnd that it does a good job of

8

FIG. 3 The network of political books compiled by Krebs. Vertex colors range from blue to red to represent the values of the
corresponding elements of the leading eigenvector of the modularity matrix.

ﬁnding community divisions. Figure 2 shows a represen-
tative example, an animal social network assembled and
studied by Lusseau et al. [64]. The vertices in this net-
work represent 62 bottlenose dolphins living in Doubtful
Sound, New Zealand, with social ties between dolphin
pairs established by direct observation over a period of
seven years. This network is of particular interest be-
cause, during the course of the study, the dolphin group
split into two smaller subgroups following the departure
of a key member of the population. The subgroups are
represented by the shapes of the vertices in the ﬁgure.
The dotted line denotes the division of the network into
two equal-sized groups found by the standard spectral
partitioning method. While, as expected, the method
does a creditable job of dividing the network into groups
of these particular sizes, it is clear to the eye that this is
not the natural community division of the network and
neither does it correspond to the division observed in
real life. The spectral partitioning method is hamstrung
by the requirement that we specify the sizes of the two
communities; unless we know what they are in advance,
blind application of the method will not usually ﬁnd the
“right” division of the network.

The method based on the leading eigenvector of the
modularity matrix, however, does much better. Uncon-
strained by the need to ﬁnd groups of any particular size,
this method ﬁnds the division denoted by the solid line
in the ﬁgure, which, as we see, corresponds quite closely
to the split actually observed—all but three of the 62
dolphins are placed in the correct groups.

The magnitudes of the elements of the eigenvector u1
also contain useful information about the network, indi-
cating, as discussed in [34], the “strength” with which
vertices belong to the communities in which they are
placed. As an example of this phenomenon consider
Fig. 3, which depicts the network of political books from
Ref. [34]. This network, compiled by V. Krebs (un-
published), represents recent books on US politics, with
edges connecting pairs of books that are frequently pur-

chased by the same customers of the on-line bookseller
Amazon.com. Applying our method, we ﬁnd that the
network divides as shown in the ﬁgure, with the colors
of the vertices representing the values of the elements of
the eigenvector. The two groups correspond closely to
the apparent alignment of the books according to left-
wing and right-wing points of view [34], and are sugges-
tively colored blue and red in the ﬁgure.3 The most blue
and most red vertices are those that, by our calculation,
belong most strongly to the two groups and are thus, per-
haps, the “most left-wing” and “most right-wing” of the
books under consideration. Those familiar with current
US politics will be unsurprised to learn that the most left-
wing book in this sense was the polemical Bushwacked by
Molly Ivins and Lou Dubose. Perhaps more surprising is
the most right-wing book: A National Party No More by
Zell Miller.4

3 By a ﬂuke of recent history, the colors blue and red have come to
denote liberal and conservative points of view respectively in US
politics, where in most other parts of the world the color-scheme
is the other way around.

4 Miller is a former Democratic (i.e., ostensibly liberal) senator
from the state of Georgia. He became known in the later years
of his career, however, for views that aligned more closely with
the conservative Republicans than with the Democrats. Even
so, Miller was never the most conservative member of the sen-
ate, nor is his book the most conservative in this study. But
our measure is not based on the content of the books; it merely
ﬁnds the vertices in the network that are most central to their
communities. The standing of Miller’s book in this calculation
results from its centrality within the community of conserva-
tive book buying. This book, while not in fact as right-wing
as some, apparently appeals widely and exclusively to conserva-
tives, presumably because of the unusual standing of its author
as a nominal Democrat supporting the Republican cause.

B. Other eigenvectors of the modularity matrix

The algorithm described in the previous section has
two obvious shortcomings. First, it divides networks into
only two communities, while real-world networks can cer-
tainly have more than two. Second, it makes use only
of the leading eigenvector of the modularity matrix and
ignores all the others, which throws away useful infor-
mation contained in those other vectors. Both of these
shortcomings are remedied by the following generaliza-
tion of the method.

Consider the division of a network into c non-
overlapping communities, where c may now be greater
than 2. Following Alpert and Yao [65] and more re-
cently White and Smyth [51],
c
index matrix S with one column for each community:
sc). Each column is an index vector now
S = (s1|
|
of (0, 1) elements (rather than
1 as previously), such
that

let us deﬁne an n

s2|

. . .

±

×

Sij =

1
0

(

if vertex i belongs to community j,
otherwise.

(31)

Note that the columns of S are mutually orthogonal, that
the rows each sum to unity, and that the matrix satisﬁes
the normalization condition Tr(ST S) = n.

Observing that the δ-symbol in Eq. (18) is now given

by

δ(gi, gj) =

SikSjk,

(32)

c

k=1
X

the modularity for this division of the network is

Q =

Bij SikSjk = Tr(ST BS),

(33)

n

c

i,j=1
X

k=1
X

where here and henceforth we suppress the leading mul-
tiplicative constant 1/2m from Eq. (18), which has no
eﬀect on the position of the maximum of the modularity.
Writing B = UDUT , where U = (u1|
. . .) is the
matrix of eigenvectors of B and D is the diagonal matrix
of eigenvalues Dii = βi, we then ﬁnd that

u2|

Q =

βj(uT

j sk)2.

(34)

n

c

j=1
X

k=1
X

Again we wish to maximize this modularity, but now we
have no constraint on the number c of communities; we
can give S as many columns as we like in our eﬀort to
make Q as large as possible.

If the elements of the matrix S were unconstrained
apart from the basic conditions on the rows and columns
mentioned above, a choice of c communities would be
1 independent, mutually or-
equivalent to choosing c
thogonal columns s1 . . . sc−1. (Only c
1 of the columns
are independent, the last being ﬁxed by the condition
that the rows of S sum to unity.) In this case our path

−

−

9

would be clear: Q would be maximized by choosing the
columns proportional to the leading eigenvectors of B.
However, only those eigenvectors corresponding to pos-
itive eigenvalues can give positive contributions to the
modularity, so the optimal modularity would be achieved
by choosing exactly as many independent columns of S as
there are positive eigenvalues, or equivalently by choosing
the number of groups c to be 1 greater than the number
of positive eigenvalues.

Unfortunately, our problem has the additional con-
straint that the index vectors si have only binary (0, 1)
elements, which means it may not be possible to ﬁnd as
many index vectors making positive contributions to the
modularity as the set of positive eigenvalues suggests.
Thus the number of positive eigenvalues, plus 1, is an
upper bound on the number of communities and again
we see that there is an intimate connection between the
properties of the modularity matrix and the community
structure of the network it describes.

C. Vector partitioning algorithm

In Section IV.A we maximized the modularity approx-
imately by focusing solely on the term in Q proportional
to the largest eigenvalue of B. Let us now make the more
general (and often better) approximation of keeping the
leading p eigenvalues, where p may be anywhere between
1 and n. Some of the eigenvalues, however, may be neg-
ative, which will prove inconvenient. To get around this
we rewrite Eq. (33) thus:

Q = nα + Tr[ST U(D

n

c

αI)UT S]
n

−

= nα +

(βj

α)

−

j=1
X

k=1
X

(cid:20)

i=1
X

2

,

(cid:21)

UijSik

(35)

where α is a constant whose value we will choose shortly
and we have made use of Tr(ST S) = n.

Now, employing an argument similar to that used for
ordinary spectral partitioning in [65], let us deﬁne a set
of vertex vectors ri, i = 1 . . . n, of dimension p, such that
the jth component of the ith vector is

ri

j =
(cid:3)

(cid:2)

p

βj

α Uij.

−

(36)

βp, ri is guaranteed real for
Provided we choose α
all i. Then, dropping terms in (35) proportional to the
smallest n

p of the factors βj

α, we have

≤

Q

nα +

βj

α UijSik

−

≃

−

p

c

n

j=1
X
c

k=1(cid:20)
X
p

i=1
X

p

= nα +

= nα +

i∈Gk
j=1(cid:20) X
X
2,
Rk
|
|

k=1
X
c

k=1
X

−

2

ri

(cid:2)

(cid:3)

j

(cid:21)

2

(cid:21)

(37)

where Gk is the set of vertices comprising group k and
the community vectors Rk, k = 1 . . . c, are

Rk =

ri.

(38)

i∈Gk
X
The community structure problem is now equivalent
to choosing a division of the vertices into groups so as to
maximize the magnitudes of the vectors Rk. This means
we need to arrange that the individual vertex vectors ri
going into each group point in approximately the same
direction. Problems of this type are called vector parti-
tioning problems.

The parameter p controls the balance between the com-
plexity of the vector partitioning and the accuracy of
the approximation we make by keeping only some of the
eigenvalues. The calculations will be faster but less accu-
rate for small p and slower but more accurate for larger.
For the special case p = n where we keep all of the eigen-
values, Eq. (37) is exact. In this case, we note that the
vertex vectors have the property

rT
i rj =

n

k=1
X

Uik(βk

α)Ujk = Bij

αδij .

(39)

−

−

n

It’s then simple to see that Eq. (37) is trivially equiv-
alent to the fundamental deﬁnition (18) of the modu-
larity, so in the p = n case our mapping to a vector
partitioning problem gives little insight into the maxi-
mization problem. The real advantage of our approach
comes when p < n, where the method extracts pre-
cisely those factors that make the principal contribu-
tions to the modularity—i.e., those corresponding to the
largest eigenvalues—discarding those that have relatively
little eﬀect. In practice, as we have seen for the single-
eigenvector algorithm, the main features of the commu-
nity structure are often captured by just the ﬁrst eigen-
vector or perhaps the ﬁrst few, which allows us to reduce
the complexity of our optimization problem immensely.
The approach is similar in concept to the standard
technique of principal components analysis (PCA) used
to reduce high-dimensional data sets to manageably
small dimension by focusing on the eigendirections along
which the variance about the mean is greatest and ignor-
ing directions that contribute little.
In fact, this simi-
larity is more than skin-deep: the form of our modular-
ity matrix is closely analogous to the covariance matrix
whose eigenvectors are the basis for PCA. The elements
of the covariance matrix are correlation functions of the
form
, where x and y denote measured vari-
i
ables in the data set. Thus the covariance is the dif-
ference between the actual value of the mean product
expected by
xy
h
chance for that product if the variables were uncorre-
lated. Similarly, the elements Bij = Aij
kikj/2m of
the modularity matrix are equal to the actual number
of edges Aij between a given pair of vertices and the
value kikj/2m expected by chance, expressed in a prod-
uct form. In a sense, therefore, our spectral method for

of two variables and the value

xy
h

y
ih

y
ih

i − h

x
h

−

x

i

i

10

modularity optimization can be regarded as a “principal
components analysis for networks.” This aspect of the
method is clear, for instance, in the study of political
books represented in Fig. 3: the leading eigenvector used
to assign the colors to the vertices in the ﬁgure is playing
a role equivalent to the eigendirections in PCA, deﬁn-
ing a “direction of greatest variation” in the structure
of the network. The vertex vectors of Eq. (36) are sim-
ilarly analogous to the low-dimensional projections used
in PCA.5

Returning to our algorithm, let us consider again the
special case of the division of a network into just two
communities. (Multi-way division is considered in Sec-
tion VI.) Since (1, 1, 1, . . .) is always an eigenvector of
the modularity matrix and the eigenvectors are orthog-
onal, the elements of all other eigenvectors must sum to
zero:

uj

i = uT

1 uj = 0.

(40)

n

i=1
X

(cid:2)

(cid:3)

But Eq. (36) then implies that

ri

j =

βj

α

−

Uij =

βj

α

−

n

i=1
X

p

n

uj

i = 0,
(cid:3)

(41)

i=1
X

(cid:2)

i=1
X
(cid:3)
(cid:2)
and hence

p

ri = 0

n

i=1
X

(42)

for any value of p. This in turn implies that the commu-
nity vectors Rk also sum to zero:

c

c

Rk =

k=1
X

i∈Gk
k=1 X
X

n

i=1
X

ri =

ri = 0.

(43)

And as a special case of this last result, any division of
a network into two communities has community vectors
R1 and R2 that are of equal magnitude and oppositely
directed.

Furthermore,

the modularity,
the maximum of
Eq. (37), is always achieved when each individual ver-
tex vector ri has a positive inner product with the com-
munity vector of the community to which the vertex be-
longs. To see this, observe that removing a vertex i from
ri < 0 produces a change in
a community k where Rk
2 in Eq. (37) of
the corresponding term
|
ri
|

·
Rk
|
2 =
|

ri > 0.

Rk
|

2Rk

(44)

Rk

2
|

2
|

− |

ri

−

−

·

5 This suggests, for instance, that the vertex vectors for p = 2
or 3 could be used to deﬁne graph layouts for visualizing net-
works in 2 or 3 dimensions. Either the endpoints of the vectors
could deﬁne vertex positions themselves or they could be used
as starting positions for a spring embedding visualizer or other
more conventional layout scheme.

11

keep track of the value of R1, and so ﬁnd the maximum
of the modularity within this approximation. Evaluat-
ing the magnitude of R1 involves a constant number of
operations each time we move the line, and hence the
total work involved in ﬁnding the maximum is O(n) for
all n possible positions, which is the same as the O(n)
operations needed to separate the vertices in the p = 1
case.

For p > 2, we do not know of an eﬃcient method to
enumerate exhaustively all topologically distinct bisect-
ing planes in the vertex vector space, and hence we have
to turn to approximate methods for solving the vector
partitioning problem. A number of reasonable heuristics
have been described in the past. We have found accept-
able though not spectacular results, for instance, with the
“MELO” algorithm of [65], which is essentially a greedy
algorithm in which a grouping of vectors is built up by
repeatedly adding to it the vector that makes the largest
contribution to Q.

D. Choice of α

Before implementing any of these methods, a crucial
question we must answer is what value we should choose
for the parameter α. By tuning this value we can improve
the accuracy of our approximation to Q as follows.

−

By dropping the n

p most negative eigenvalues, we are
αI
in eﬀect making an approximation to the matrix B
αI)UT , but an
in which it takes not its full value U(D
αI′)UT , where D′ and I′ are
approximate value U(D′
the matrices D and I with the last n
p diagonal elements
set to zero. We can quantify the error this introduces
by calculating the sum of the squares of the diﬀerence
between the two matrices, which is given by

−

−

−

−

χ2 = Tr[U(D

αI)UT

−

= Tr[(D

αI)

−

−

−

−

U(D′

−
αI′)]2 =

(D′

αI′)UT ]2
n

α)2, (45)

(βi

−

i=p+1
X

where in the second line we have made use of the fact
that U is orthogonal.
Minimizing this
dχ2/dα = 0, we ﬁnd

error by setting the derivative

α =

1

−

n

p

n

βi.

i=p+1
X

(46)

In other words, the minimal mean square error intro-
duced by our approximation is achieved by setting α
equal to the mean of the eigenvalues that have been
dropped. The only exception is when p = n, where the
choice of α makes no diﬀerence since no approximation
is being made anyway. In our calculations we have used
α = βn in this case, but any choice α
βn would work
as well.

≥

FIG. 4 A plot of the vertex vectors ri for a small network
with p = 2. The dotted line represents one of the n possible
topologically distinct cut planes.

·

Similarly adding vertex i to a community for which Rk
·
2. Hence, we can always
Rk
ri > 0 always increases
|
|
increase the modularity by moving vertices until they are
ri > 0.
in groups such that Rk
Taken together, these results imply that possible can-
didates for the optimal division of a network into two
groups are fully speciﬁed by just the direction of the sin-
gle vector R1. Once we have this direction, we know that
the vertices divide according to whether their projection
along this direction is positive or negative. Alternatively,
one can consider the direction of R1 to deﬁne a plane
through the origin in the p-dimensional vector space oc-
cupied by the vertex vectors ri. The vertices then divide
according to which side of this plane their vectors fall
on. Finding the maximum of the modularity is then a
matter of choosing this bisecting plane to maximize the
magnitude of R1.

In general, this still leaves us with a moderately dif-
the number of bisecting
ﬁcult optimization problem:
planes that give distinct partitions of the vertex vectors
is large and diﬃcult to enumerate as the dimension p
of the space becomes large. For the case p = 2, how-
ever, a relatively simple solution exists. Consider Fig. 4,
which shows a typical example of the vertex vectors.6
In this two-dimensional case, there are only n topologi-
cally distinct choices of the bisecting plane (actually just
a line in this case, denoted by the dashed line in the ﬁg-
ure), and furthermore the divisions of the vertices that
these choices represent change by only a single vertex
at a time as we rotate the plane about the origin. This
makes it computationally simple to perform the rotation,

6 In fact, this ﬁgure shows the vectors for the “karate club” network

used previously as an example in Ref. [34].

V. IMPLEMENTATION

Implementation of the methods described in Sec-
tions IV is straightforward. The leading-eigenvector
method of Section IV.A requires us to ﬁnd only the sin-
gle eigenvector of the modularity matrix B corresponding
to the most positive eigenvalue. This is most eﬃciently
achieved by the direct multiplication or power method.
Starting with any trial vector, we repeatedly multiply
by the modularity matrix and the result will converge
to the eigenvector of the matrix having the eigenvalue of
largest magnitude. In some cases this will be the most
positive eigenvalue, in which case our calculation ends at
this point. In other cases the eigenvalue of largest magni-
tude may be negative. If this happens then, denoting this
βnI,
eigenvalue by βn, we calculate the shifted matrix B
which has eigenvalues βi
βn (necessarily all nonnega-
tive) and the same eigenvectors as the modularity matrix
itself. Then we repeat the power-method calculation for
this new matrix and this time the eigenvalue of largest
βn and the corresponding eigen-
magnitude must be β1 −
vector is the one we are looking for.

−

−

For the method of Section IV.B, we require either all
of the eigenvectors of the modularity matrix or a sub-
set corresponding to the p most positive eigenvalues.
These are most conveniently calculated using the Lanc-
zos method [66]. The fundamental matrix operation at
the heart of the Lanczos method is again multiplication
of the matrix B into a trial vector.

Eﬃcient implementation of any of either of these meth-
ods thus rests upon our ability to rapidly multiply an
arbitrary vector x by the modularity matrix B. This
presents a problem because the modularity matrix is
dense, and hence it appears that matrix multiplications
will demand O(n2) time each, where n is, as before, the
number of vertices in the network (which is also the size
of the matrix). By contrast, the equivalent calculation
in standard spectral partitioning is much faster because
the Laplacian matrix is sparse, having only O(n + m)
nonzero elements, where m is the number of edges in the
network.

For the standard choice, Eq. (23), of null model used to
deﬁne the modularity, however, it turns out that we can
multiply by the modularity matrix just as fast as by the
Laplacian by making use of the special structure of the
matrix. In vector notation the modularity matrix can in
this case be written

where A is the adjacency matrix, Eq. (1), and k is the
n-element vector whose elements are the degrees ki of the
vertices. Then

B = A

kkT
2m

,

−

Bx = Ax

kT x
2m

k.

−

(47)

(48)

Since the adjacency matrix is sparse, having only O(m)
elements, the ﬁrst term can be evaluated in O(m) time,

12

while the second requires us to evaluate the inner product
kT x only once and then multiply it into each element of k
in turn, both operations taking O(n) time. Thus the en-
tire matrix multiplication can be completed in O(m + n)
time, just as with the normal Laplacian matrix.
If a
shift of the eigenvalues is required to ﬁnd the most posi-
tive one, as described above, then there is an additional
βnI in the matrix, but this also can be multiplied
term
into an arbitrary vector in O(n) time, so again the entire
operation can be completed in O(m + n) time.

−

Typically O(n) matrix multiplications are required for
either the power method or the Lanczos method to con-
verge to the required eigenvalues, and hence the calcula-
tion takes O((m + n)n) time overall. In the common case
in which the network is sparse and m
n, this simpliﬁes
to O(n2).

∝

While this is, essentially, the end of the calculation for
the power method, the Lanczos method unfortunately
demands more eﬀort to ﬁnd the eigenvectors themselves.
In fact, it takes O(n3) time to ﬁnd all eigenvectors of a
matrix using the Lanczos method, which is quite slow.
There are on the other hand variants of the Lanczos
method (as well as other methods entirely) that can ﬁnd
just a few leading eigenvectors faster than this, which
makes calculations that focus on a ﬁxed small number of
eigenvectors preferable to ones that use all eigenvectors.
In our calculations we have primarily concentrated on al-
gorithms that use only one or two eigenvectors, which
typically run in time O(n2) on a sparse network.

A. Reﬁnement of the modularity

The methods for spectral optimization of the modular-
ity described in Section IV are only approximate. Indeed,
the problem of modularity optimization is formally equiv-
alent to an instance of the NP-hard MAX-CUT problem,
so it is almost certainly the case that no polynomial-time
algorithm exists that will ﬁnd the modularity optimum
in all cases. Given that the algorithms we have described
run in polynomial time, it follows that they must fail to
ﬁnd the optimum in some cases, and hence that there is
room for improvement of the results.

In standard graph partitioning applications it is com-
mon to use a spectral approach based on the graph Lapla-
cian as a ﬁrst pass at the problem of dividing a network.
The spectral method gives a broad picture of the general
shape the division should take, but there is often room
for improvement. Typically another algorithm, such as
the Kernighan–Lin algorithm [67], which swaps vertex
pairs between groups in an eﬀort to reduce the cut size,
is used to reﬁne this ﬁrst pass, and the resulting two-
stage joint strategy gives considerably better results than
either stage on its own.

We have found that a similar joint strategy gives good
results in the present case also:
the divisions found
with our spectral approach can be improved in small
but signiﬁcant ways by adding a reﬁnement step akin

to the Kernighan–Lin algorithm. As described in [34],
we take an initial division into two communities derived,
for instance, from the leading-eigenvector method of Sec-
tion IV.A and move single vertices between the commu-
nities so as to increase the value of the modularity as
much as possible, with the constraint that each vertex
can be moved only once. Repeating the whole process
iteratively until no further improvement is obtained, we
ﬁnd a ﬁnal value of the modularity which can improve
on that derived from the spectral method alone by tens
of percent in some cases, and smaller but still signiﬁcant
amounts in other cases. Although the absolute gains in
modularity are not always large, we ﬁnd that this reﬁne-
ment step is very much worth the eﬀort it entails, raising
the typical level of performance of our methods from the
merely good to the excellent, when compared with other
algorithms. Speciﬁc examples are given in [34].

It is certainly possible that other reﬁnement strategies
might also give good results. For instance, the “extremal
optimization” method explored by Duch and Arenas [41]
for optimizing modularity could also be employed as a
reﬁnement method by using the output of our spectral
division as its starting point, rather than the random
conﬁguration used as a starting point by Duch and Are-
nas.

VI. DIVIDING NETWORKS INTO MORE THAN TWO
COMMUNITIES

So far we have discussed only methods for dividing net-
works into two communities. Many of the networks we
are concerned with, however, have more than two com-
munities. How can we generalize our methods to this
case? The simplest approach is repeated division into
two. That is, we use one of methods described above to
divide our network in two and then divide those parts
in two again, and so forth. This approach was described
brieﬂy in Ref. [34].

It is important to appreciate that upon further sub-
dividing a community within a network into two parts,
the additional contribution ∆Q to the modularity made
by this subdivision is not given correctly if we apply the
algorithms of Section IV to that community alone. That
is, we cannot simply write down the modularity matrix
for the community in question considered as a separate
graph in its own right and examine the leading eigen-
vector or eigenvectors.
Instead we proceed as follows.
Let us denote the set of vertices in the community to
be divided by G and let nG be the number of vertices
within this community. Now let S be an nG
c index
matrix denoting the subdivision of the community into c
subcommunities such that

×

Sij =

1
0

(

if vertex i belongs to subcommunity j,
otherwise.

(49)
Then, following Eq. (33), ∆Q is the diﬀerence between

13

(50)

(51)

the modularities of the network before and after subdi-
vision of the community thus:

∆Q =

BijSikSjk

Bij

−

i,j∈G
X

c

i,j∈G
k=1 X
X
c

=

i,j∈G(cid:20)

k=1 X
X
= Tr(ST B(G)S),

Bij

δij

−

Bil

SikSjk
(cid:21)

l∈G
X

where B(G) is an nG
nG generalized modularity matrix
with elements indexed by the vertex labels i, j of the
vertices within group G and having values

×

B(G)

ij = Bij

δij

−

Bil,

l∈G
X

with Bij deﬁned by Eq. (27).

Equation (50) has the same form as our previous ex-
pression, Eq. (33), for the modularity of the full net-
work, and, following the same argument as for Eqs. (35)
to (38), we can then show that optimization of the ad-
ditional modularity contribution from subdivision of a
community can also be expressed as a vector partition-
ing problem, just as before. We can approximate this
vector partitioning problem using only the leading eigen-
vector as in Section IV.A or using more than one vector
as in Section IV.B. The resulting divisions can also be
optimized using a “reﬁnement” stage as in Section V.A,
to ﬁnd the best possible modularity at each step.

Using this method we can repeatedly subdivide com-
munities to partition networks into smaller and smaller
groups of vertices and in principle this process could con-
tinue until the network is reduced to n communities con-
taining only a single vertex each. Normally, however, we
stop before this point is reached because there is no point
in subdividing a community any further if no subdivision
exists that will increase the modularity of the network as
a whole. Our recommended strategy is to calculate ex-
plicitly the modularity contribution ∆Q at each step in
the subdivision of a network, and to decline to subdivide
any community for which the value of ∆Q is not positive.
Communities with the property of having no subdivision
that gives a positive contribution to the modularity of
the network as a whole we call indivisible; the strategy
described here is equivalent to subdividing communities
repeatedly until every remaining community is indivisi-
ble.

This strategy appears to work very well in practice. It
is, however, not perfect (a conclusion we could draw un-
der any circumstances from the fact that it runs in poly-
nomial time—see above). In particular, it is certain that
repeated subdivision of a network into two parts will in
some cases fail to ﬁnd the optimal modularity conﬁgura-
tion. Consider, for example, the (rather trivial) network
shown in Fig. 5, which consists of eight vertices connected
together in a line. By exhaustive enumeration we can
show that, among possible divisions of this network into

(a)

(b)

FIG. 5 Division by the method of optimal modularity of a
simple network consisting of eight vertices in a line. (a) The
optimal division into just two parts separates the network
symmetrically into two groups of four vertices each. (b) The
optimal division into any number of parts divides the network
into three groups as shown here.

only two parts, the division indicated in Fig. 5a, right
down the middle of the network, is the one that gives
the highest modularity. The optimum modularity over
divisions into any number of parts, however, is achieved
for the three-way division shown in Fig. 5b. It is clear
that if we ﬁrst split the network as shown in Fig. 5a, no
subsequent subdivisions of the network can ever ﬁnd the
conﬁguration of Fig. 5b, and hence our algorithm will fail
in this case to ﬁnd the global optimum. Nonetheless, the
algorithm does appear to ﬁnd divisions that are close to
optimal in most cases we have investigated.

Repeated subdivision is the approach we have taken to
multi-community divisions in our own work, but it is not
the only possible approach. In some respects a more sat-
isfying approach would be to work directly from the ex-
pression (37) for the modularity of the complete network
with a multi-community division. Unfortunately, maxi-
mizing (37) requires us to perform a vector partitioning
into more than two groups, a problem about whose so-
lution rather little is known. Some general observations
are, however, worth making. First, we note that the
community vectors Ri in the optimal solution of a vector
partitioning problem always have directions more than
90◦ apart. To demonstrate this, we note that the change
in the contribution to Eq. (37) if we amalgamate two
communities into one is

R1 + R2

2

−

2

R1

+

R2

2

= 2R1 ·

R2,

(52)

(cid:1)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:0)(cid:12)
(cid:12)

(cid:12)
which is positive if the directions of R1 and R2 are less
(cid:12)
than 90◦ apart. Thus we can always increase the mod-
ularity by amalgamating a pair of communities unless
their vectors are more than 90◦ apart.

But the maximum number of directions more than 90◦
apart that can exist in a p-dimensional space is p + 1,
which means that p + 1 is also the maximum number of
communities we can ﬁnd by optimizing a p-dimensional
spectral approximation to the modularity. Thus if we use
only a single eigenvector we will ﬁnd at most two groups;
if we use two we will ﬁnd at most three groups, and so
forth. So the choice of how many eigenvectors p to work
if
with is determined to some extent by the network:

14

−

the overall optimum modularity is for a division into c
groups, we will certainly fail to ﬁnd that optimum if we
use less than c

1 eigenvectors.

Second, we note that while true multi-way vector par-
titioning may present problems, simple heuristics that
group the vertex vectors together can still produce good
results. For instance, White and Smyth [51] have ap-
plied the standard technique of k-means clustering based
on group centroids to a diﬀerent but related optimization
problem and have found good results. It is possible this
approach would work for our problem also if applied to
the centroids of the end-points of the vertex vectors. It is
also possible that an intrinsically vector-based variant of
k-means clustering could be created to tackle the vector
partitioning problem directly, although we are not aware
of such an algorithm in the current vector partitioning
literature.

VII. NEGATIVE EIGENVALUES AND BIPARTITE
STRUCTURE

It is clear from the developments of the previous sec-
tions that there is useful information about the commu-
nity structure of a network stored in the eigenvectors
corresponding to the most positive eigenvalues of the
modularity matrix.
It is natural to ask whether there
is also useful information in the eigenvectors correspond-
ing to the negative eigenvalues and indeed it turns out
that there is: the negative eigenvalues and their eigen-
vectors contain information about a nontrivial type of
“anti-community structure” that is of substantial inter-
est in some instances.

Consider again the case in which we divide our network
into just two groups and look once more at Eq. (29),
which gives the modularity in this case. Suppose now
that instead of maximizing the terms involving the most
positive eigenvalues, we maximize the terms involving the
most negative ones. As we can easily see from the equa-
tion, this is equivalent to minimizing rather than maxi-
mizing the modularity.

What eﬀect will this have on the divisions of the net-
work that we ﬁnd? Large negative values of the mod-
ularity correspond to divisions in which the number of
edges within groups is much smaller than expected on
the basis of chance, and the number of edges between
groups correspondingly much bigger. Figure 6 shows
a sketch of a network having this property. Such net-
works are said to be bipartite if there are no edges at all
within groups, or approximately bipartite if there are a
few within-group edges as in the ﬁgure. Bipartite or ap-
proximately bipartite graphs have attracted some atten-
tion in the recent literature. For instance, Kleinberg [68]
has suggested that small bipartite subgraphs in the web
graph may be a signature of so-called hub/authority
structure within web communities, while Holme et al. [69]
and Estrada and Rodr´ıguez-Vel´azquez [70] have indepen-
dently devised measures of bipartitivity and used them to

15

(a)

(b)

FIG. 7 (a) The network of commonly occurring English ad-
jectives (circles) and nouns (squares) described in the text.
(b) The same network redrawn with the nodes grouped so as
to minimize the modularity of the grouping. The network is
now revealed to be approximately bipartite, with one group
consisting almost entirely of adjectives and the other of nouns.

algorithm used to draw the network completely fails to
reveal the interesting structure present. Figure 7b shows
what happens when we divide the vertices by minimiz-
ing the modularity using the method described above—a
ﬁrst division according to the elements of the eigenvector
with the most negative eigenvalue, followed by a reﬁne-
ment stage to reduce the modularity still further. It is
now clear that the network is in fact nearly bipartite,
and the two groups found by the algorithm correspond
closely to the known groups of adjectives and nouns, as
indicated by the shapes of the vertices. 83% of the words
are classiﬁed correctly by this simple calculation.

Divisions with large negative modularity are—like
those with large positive modularity—not limited to hav-
ing only two groups. If we are interested purely in min-
imizing the modularity we can in principle use as many
groups as we like to achieve that goal. A division with k
groups is called k-partite. By direct analogy with our ear-
lier calculations of community structure, one can search
for k-partite structure with k > 2 by repeated division in
two using the single-eigenvector method above. Just as
before, Eq. (50) gives the additional change ∆Q in the
modularity upon subdivision of a group in a network,
and the division process ends when the algorithm fails
to ﬁnd any subdivision with ∆Q < 0. Alternatively, one

FIG. 6 A small example of an approximately bipartite net-
work. The network is composed of two groups of vertices and
most edges run between vertices in diﬀerent groups.

quantify bipartitivity in a variety of real-world networks.
The arguments above suggest that we should be able
to detect bipartite or approximately bipartite structure
in networks by looking for divisions of the vertices that
minimize modularity. In the simplest approximation, we
can do this by focusing once more on just a single term in
Eq. (29), that corresponding to the most negative eigen-
value βn, and maximizing the coeﬃcient of this eigen-
value by choosing si = +1 for vertices having a positive
element in the corresponding eigenvector and si =
1 for
all others. In other words, we can achieve an approxima-
tion to the minimum modularity division of the network
by dividing vertices according to the signs of the elements
in the eigenvector un, and this division should correspond
roughly to the most nearly bipartite division of the net-
work. We can also append a “reﬁnement” step to the
calculation, similar to that described in Section V.A, in
which, starting from the division given by the eigenvec-
tor, we move single vertices between groups in an eﬀort
to minimize the modularity further.

−

As an example of this type of calculation, consider
Fig. 7, which shows a network representing juxtaposi-
tions of words in a corpus of English text, in this case
the novel David Copperﬁeld by Charles Dickens. To con-
struct this network, we have taken the 60 most commonly
occurring nouns in the novel and the 60 most commonly
occurring adjectives. (The limit on the number of words
is imposed solely to permit a clear visualization; there
is no reason in principle why the analysis could not be
extended to a much larger network.) The vertices in the
network represent words and an edge connects any two
words that appear adjacent to one another at any point
in the book. Eight of the words never appear adjacent
to any of the others and are excluded from the network,
leaving a total of 112 vertices.

Typically adjectives occur next to nouns in English. It
is possible for adjectives to occur next to other adjectives
(“the big green bus”) or for nouns to occur next to other
nouns (“the big tour bus”), but these juxtapositions are
less common. Thus we would expect our network to
be approximately bipartite in the sense described above:
edges should run primarily between vertices represent-
ing diﬀerent types of words, with fewer edges between
vertices of the same type. One would be hard pressed
to tell this from Fig. 7a, however: the standard layout

can derive the analog of Eq. (37) and thereby map the
minimization of the modularity onto a vector partition-
ing problem. The appropriate deﬁnition of the vertex
vectors turns out to be

α

βn+1−j Ui,n+1−j,

(53)

ri

j =

(cid:2)

(cid:3)

p

−

where α is a constant chosen suﬃciently large as to make
α
0 for all terms in the sum that we keep. Then
the modularity is given by

βj

−

≥

Q = nα

c

−

k=1
X

Rk
|

2,
|

(54)

with the community vectors Rk deﬁned according to
Eq. (38).

Before moving on, we note that one might attempt
to ﬁnd k-partite structure in a network just by looking
for divisions that maximize the number of between-group
edges, but brief reﬂection persuades us that the optimum
solution to this search problem is always to put each ver-
tex in a group on its own, which automatically means
that all edges run between groups. As with the ordinary
community structure problem, the correct way to avoid
this trivial solution is to concentrate not on the total
number of edges between groups but on the diﬀerence
between this number and the expected number of such
edges. Thus, as before, we are led naturally to the con-
sideration of modularity as a measure of the best way to
divide a network.

VIII. OTHER USES OF THE MODULARITY MATRIX

One of the striking properties of the Laplacian matrix
is that, as described in Section II, it arises repeatedly in
various diﬀerent areas of graph theory. It is natural to
ask whether the modularity matrix also crops up in other
areas. In this section we describe brieﬂy two other situa-
tions in which the modularity matrix appears, although
neither has been viewed in terms of this matrix in the
past, as far as we are aware.

A. Network correlations

For our ﬁrst example, suppose we have a quantity xi
deﬁned on the vertices i of a network, such as degrees
of vertices, ages of people in a social network, numbers
of hits on web pages, and so forth. And let x be the
n-component vector whose elements are the xi. Then
consider the quantity

r =

xT Bx,

1
2m

(55)

where here we will take the same deﬁnition (23) for our
null model that we have been using throughout. Observ-

16

(56)

ing that

ij Aij =

i ki = 2m, we can rewrite r as

P

r =

P

1
2m

Aij

kikj
2m

−

ij (cid:20)
X

ij Aij xixj

=

P

ij Aij − " P
P

P

xixj

(cid:21)

2

.

ij Aij xi
ij Aij #

Note that the ratios appearing in the second line are sim-
ply averages over all edges in the network, and hence r
of a correlation function
xj
has the form
measuring the correlation of the values xi over all pairs
of vertices joined by an edge in the network.

xixj
h

i − h

xi

ih

i

Correlation functions of exactly this type have been
considered previously as measures of so-called “assorta-
tive mixing,” the tendency for adjacent vertices in net-
works to have similar properties [50, 63]. For example, if
the quantity xi is just the degree ki of a vertex, r becomes
equal, to within a normalizing factor, to the correlation
coeﬃcient for degrees of adjacent vertices, which takes
positive values if vertices tend to have similar degrees
to their neighbors, high-degree vertices linking to other
high-degree vertices and low to low, and negative values
if high-degree links to low.

Equation (55) is not just a curiosity, but provides some
insight concerning assortativity. If we expand x in terms
of the eigenvectors of the modularity matrix, as we did
for the modularity itself in Eq. (29), we get

r =

1
2m

c2
i βi,

i
X

(57)

where βi is again the ith largest eigenvalue of B and
ci = uT
i x. Thus r will have a large positive value if x has
a large component in the direction of one or more of the
most positive eigenvectors of the modularity matrix, and
similarly for large negative values. Now we recall that the
leading eigenvectors of the modularity matrix also deﬁne
the communities in the network and we see that there
is a close relation between assortativity and community
structure: networks will be assortative according to some
property x if the values of that property divide along the
same lines as the communities in the network. Thus, for
instance, a network will be assortative by degree if the
degrees of the vertices are partitioned such that the high-
degree vertices fall in one community and the low-degree
vertices in another.

This lends additional force to the discussion given in
the introduction, where we mentioned that diﬀerent com-
munities in networks are often found to have diﬀerent av-
erage properties such as degree. In fact, as we now see,
this is probably the case for any property that displays
signiﬁcant assortative mixing, which includes an enor-
mous variety of quantities measured in networks of all
types. Thus, it is not merely an observation that diﬀer-
ent communities have diﬀerent average properties—it is
an expected behavior in a network that has both commu-
nity structure and assortativity.

17

B. Community centrality

and the community vectors Xk and Yk are deﬁned by

For our second example of other uses of the modu-
larity matrix, we consider centrality measures, one of
the abiding interests of the network analysis community
for many decades. In Section IV.A we argued that the
magnitudes of the elements of the leading eigenvector of
the modularity matrix give a measure of the “strength”
with which vertices belong to their assigned communi-
ties. Thus these magnitudes deﬁne a kind of centrality
index that quantiﬁes how central vertices are in commu-
nities. Focusing on just a single eigenvector of the mod-
ularity matrix, however, is limiting. As we have seen, all
the eigenvectors contain useful information about com-
munity structure. It is useful to ask what the appropriate
measure is of strength of community membership when
the information in all eigenvectors is taken into account.
Given Eq. (37), the obvious candidate seems to be the
projection of the vertex vector ri onto the community
vector Rk of the community to which vertex i belongs.
Unfortunately, this projection depends on the arbitrary
parameter α, which we introduced in Eq. (35) to get
around problems caused by the negative eigenvalues of
the modularity matrix. This in turn threatens to intro-
duce arbitrariness into our centrality measure, which we
would prefer to avoid. So for the purposes of deﬁning a
centrality index we propose a slightly diﬀerent formula-
tion of the modularity, which is less appropriate for the
optimization calculations that are the main topic of this
paper, but more satisfactory for present purposes, as we
will see.

Suppose that there are p positive eigenvalues of the
modularity matrix and q negative ones. We deﬁne two
xi
new sets of vertex vectors
, of dimension p
and q, thus:

and

yi

{

}

{

}

βj Uij,

xi

(cid:2)

yi

(cid:2)

j =
j =
(cid:3)
(cid:3)

−

p

p

βn+1−j Ui,n+1−j.

(58)

(59)

(Note that p + q < n since there is always at least one
eigenvalue with value zero.) In terms of these vectors the
modularity, Eq. (33), can be written as

c

p

n

Q =

βj UijSik

k=1
X

j=1(cid:20)
i=1
X
X
q
c

p
n

2

(cid:21)

βn+1−j Ui,n+1−jSik

−

c

k=1
X
p

−

j=1(cid:20)
X

i=1
X

p

2

c

q

=

=

xi

j

(cid:21)

(cid:3)
Yk
|

−

2,
|

k=1
X
c

k=1
X

(cid:2)
c

j=1(cid:20) X
i∈Gk
X
Xk
|

2
|

−

k=1
X

k=1
X

j=1(cid:20) X
i∈Gk
X

(cid:2)

(cid:3)

(60)

2

(cid:21)

yi

2

j

(cid:21)

where Gk is once again the set of vertices in community k

Xk =

xi,

Yk =

yi.

(61)

i∈Gk
X

i∈Gk
X

This reformulation avoids the use of the arbitrary con-
stant α, thereby making the vertex vectors dependent
only on the network structure and not on the way in
which we choose to represent it.

Equation (60) separates out the positive and negative
contributions to the modularity, the positive contribu-
tions coming from vertices that have large corresponding
components in the eigenvectors with positive eigenvalues,
and conversely for the negative contributions. Thus the
two contributions correspond respectively to the tradi-
tional community structure of Sections III and IV, and
to the bipartite or k-partite structure discussed in Sec-
tion VII. It is important to notice that while obviously
the overall modularity can only be either positive or neg-
ative, it is entirely possible for individual vertices to si-
multaneously make both large positive and large negative
contributions to that modularity. Upon reﬂection, this is
clearly reasonable: there is no reason why a single ver-
tex cannot have more connections than expected within
its own community and more connections than expected
to other communities.
In a sense, Eq. (60) may be a
more fundamental representation of the modularity than
Eq. (37) because it makes this separation transparent,
even if it is in practice less suitable as a basis for modu-
larity optimization.

We can now deﬁne precisely the quantity that plays
the role previously played by the elements of the lead-
ing eigenvector in the single-eigenvector approximation:
it is the projection of xi onto the relevant community
vector Xk, as we can see by writing the magnitude
Xk
|
in Eq. (60) as

|

Xk
|

|

=

XT

k Xk
Xk
|

|

XT
k

=

i∈Gk xi
Xk
P
|

|

=

i∈Gk
X

ˆXT

k xi,

(62)

where ˆXk is the unit vector in the direction of Xk. Thus
equal to its pro-
each vertex makes a contribution to
jection onto Xk. In the approximation where we ignore
all but the leading eigenvector, this projection reduces
to the (magnitude of) the appropriate element of that
eigenvector, as in Section IV.A.

Xk
|

|

The projection speciﬁes how central vertex i is in its
own community in the traditional sense of having many
connections within that community. If this quantity is
large then we will lose a large positive contribution to the
modularity if we move the vertex to another community,
which is to say that the vertex is a strong member of its
current community.

But there is now also a second measure for each ver-
tex, the projection of yi onto Yk. This projection corre-
sponds to a more unusual sort of “anti-centrality” which
is high if vertex i has many connections to others out-
side its community. This “outsider” centrality measure

could also be useful in certain circumstances to identify
individuals with strong external connections.

|

xi
|

These two projections, however, do not take precisely
the form that we expect of a centrality measure because
they are functions not only of the vertex itself (via xi
or yi) but also of the community in which it is placed
(via Xk or Yk). Instead, therefore, let us consider the
projection in the form
cos θik, where θik is the angle
between xi and Xk. The two parts of this expression are
both of interest. The ﬁrst, the magnitude
, measures
|
how large a positive contribution vertex i can potentially
make to the modularity. The vertex only actually makes
a contribution this large if the vertex vector is aligned
with the community vector, i.e., if the vertex is, in a
sense, “in the middle” of the community to which it be-
is large may in prac-
longs. Even a vertex for which
tice make a small positive contribution to the modularity
if xi is almost perpendicular to Xk, i.e., if the vertex is
“on the edge” of the community.

xi
|

xi
|

|

The second part of the projection, the cos θik, is a mea-
sure precisely of the vertex’s position in the middle or
on the edge of its community. In the parlance of social
network analysis, the vertex is either in the core of its
community (cos θik near 1) or in the periphery (cos θik
nearer 0). The cosine is a property both of the vertex
and of the community.

Let us concentrate here, however, on the vector mag-
nitudes and deﬁne two centrality measures for vertices
in a network equal to the magnitudes of the vertex vec-
2 instead,
tors xi and yi. (If we prefer, we could use
|
which is slightly easier to calculate. If, as is sometimes
the case with centrality measures, we only care about rel-
ative rankings of vertices, then the two are equivalent.)
These centralities are now properties of the vertices alone
and are independent of the way the network is divided
yi
into communities. We notice, however, that
|
are not independent since

xi
|

xi
|

and

|

|

xi
|

2
|

yi

2 =
|

− |

p

2

βj Uij

j=1
X

(cid:0)p
q

(cid:1)

βn+1−j Ui,n+1−j

2

(cid:1)

ji = Bii.

(63)

−

n

−

j=1
X
(cid:0)p
UijβjU T

=

j=1
X

Almost all networks considered in the literature are sim-
ple graphs, meaning, among other things, that they have
no self-edges (edges that connect vertices to themselves)
and hence Aii = 0 for all i. If the expected number of
self-edges Pii is also zero (as seems sensible), then Bii = 0
and we have
for all i. Thus there is actually
|
only one centrality for simple graphs, not two.

yi
|

xi
|

=

|

In fact, the choice (23) for Pij that we and other au-
thors have mostly used does allow self-edges (and is in
this sense slightly unrealistic—see [52]), but Pii = k2
i /2m
is typically small for most vertices if m is large (and

18

xi
|

.
|

|

yi

→ ∞

and there is only one centrality.

indeed vanishes as m
if degrees are bounded),
and hence it is still true to a good approximation that
xi
|

| ≃ |
In other words, we come to the nontrivial conclusion
that the vertices with the greatest capacity for making
positive contributions to the modularity also have the
greatest capacity for making negative contributions. The
fundamental meaning of this centrality measure is thus
that there are certain vertices that, as a consequence of
their situation within the network, have the power to
make substantial contributions, either positive or nega-
tive, to the overall modularity of the network. For this
reason, we call this centrality measure community cen-
trality. We deﬁne it to be equal to the vector magni-
tude

xi
|

|

An alternative way to view the community centrality is
to consider how a vertex i is situated among the other ver-
tices in its immediate vicinity—its neighborhood in the
network. If we were to artiﬁcially construct a community
from the vertices of this neighborhood, then that commu-
nity would presumably have a community vector Xk with
direction close to xi, and hence the magnitude
would
be a good measure of the actual strength with which ver-
tex i belongs to its neighborhood. Thus vertices with
high community centrality are ones that play a central
role in their local neighborhood—regardless of where the
oﬃcial community boundaries may lie. Conversely, even
when considered as the “center of its world” in this way,
vertex i can never play a central role in its neighborhood
in this sense if

is small.

xi
|

|

As an example, consider Fig. 8, which shows results
for community centrality for a network of coauthorships
between scientists, scientists in this case who are them-
selves publishing on the topic of networks. The net-
work is similar to the one presented in Ref. [18] but is
based on more recent data, including publications up
until early 2006.7 The network has a total of 1589 sci-
entists in it, from a broad variety of ﬁelds, but only the
379 falling in the largest connected component are shown
in the ﬁgure. Diameters of the vertices in the ﬁgure
are proportional to their community centrality (actually
2—see above), and the ten vertices having the high-
to
|
est centralities are highlighted. A couple of remarks are
worth making about the results. Without naming spe-
ciﬁc names, we observe that all of the highlighted authors
are group leaders or senior researchers of groups working
in this area. Thus community centrality appears to live
up to its name in this admittedly anecdotal example: it
highlights those vertices that are central in their local

xi
|

7 The vertices of the network represent all individuals who are
authors of papers cited in the bibliographies of either of two
recent reviews on networks research [1, 2] and edges join every
pair of individuals whose names appear together as authors of
a paper or papers in those bibliographies. A small number of
additional references were added by hand to bring the network
up to date.

19

2.5

1.5

2

1

0.5

y
t
i
l
a
r
t
n
e
c
 

y
t
i
n
u
m
m
o
C

0

0

10

20

30

40

2

r

 = 0.593

Degree

FIG. 8 A network of coauthorships between 379 scientists whose research centers on the properties of networks of one kind or
another. Vertex diameters indicate the community centrality and the ten vertices with highest centrality are highlighted. For
those readers curious about the identities of the vertices, an annotated version of this ﬁgure, names and all, can be downloaded
from http://www.umich.edu/~mejn/centrality. Inset: a scatter plot of community centrality against vertex degrees. Like
most centrality measures, this one is correlated with degree, though only moderately strongly.

communities. Second, while the centrality is correlated
with degree (r2 = 0.59—see the inset to Fig. 8), the two
are not perfectly correlated and in particular some ver-
tices have quite high centrality while having relatively low
degree. This emphasizes the point that high centrality is
an indicator of individuals who have more connections
than expected within their neighborhood (and hence po-
tentially make a large contribution to the modularity),
rather than simply having a lot of connections.

IX. CONCLUSIONS

In this paper, we have studied the problem of detect-
ing community structure in networks. There is already
a substantial body of theory supporting the view that
community structure can be accurately quantiﬁed using
the beneﬁt function known as modularity and hence that
communities can be detected by searching possible divi-
sions of a network for ones that possess high modular-
ity. Here we have demonstrated that the modularity can

be succinctly expressed in terms of the eigenvalues and
eigenvectors of a matrix we call the modularity matrix,
which is a characteristic property of the network and is it-
self independent of any division of the network into com-
munities. Using this expression we have derived a series
of further results including several new and competitive
algorithms for identifying communities, a method for de-
tecting bipartite or k-partite structure in networks, and a
new “community centrality” measure that identiﬁes ver-
tices that play a central role in the communities to which
they belong.

We have demonstrated a variety of diﬀerent applica-
tions of our methods to real-world networks representing
social, technical, and information networks. These, how-
ever, are intended only as illustrations of the potential
of these methods. We hope that readers will feel encour-
aged to apply these or similar methods to other networks
of scientiﬁc interest and we look forward to seeing the re-
sults.

Acknowledgments

The author thanks Luis Amaral, Alex Arenas, Roger
Guimer`a, Edward Ionides, and David Lusseau for useful
and enjoyable conversations, and Valdis Krebs and David
Lusseau for providing network and other data used in the
examples. This work was funded in part by the National
Science Foundation under grant number DMS–0405348
and by the James S. McDonnell Foundation.

References

[1] M. E. J. Newman, The structure and function of complex

networks. SIAM Review 45, 167–256 (2003).

[2] S. Boccaletti, V. Latora, Y. Moreno, M. Chavez, and D.-
U. Hwang, Complex networks: Structure and dynamics.
Physics Reports 424, 175–308 (2006).

[3] S. N. Dorogovtsev and J. F. F. Mendes, Evolution of Net-
works: From Biological Nets to the Internet and WWW.
Oxford University Press, Oxford (2003).

[4] M. E. J. Newman, A.-L. Barab´asi, and D. J. Watts, The
Structure and Dynamics of Networks. Princeton Univer-
sity Press, Princeton (2006).

[5] M. Girvan and M. E. J. Newman, Community structure
in social and biological networks. Proc. Natl. Acad. Sci.
USA 99, 7821–7826 (2002).

[6] M. E. J. Newman, Detecting community structure in net-

works. Eur. Phys. J. B 38, 321–330 (2004).

[7] P. Holme, M. Huss, and H. Jeong, Subnetwork hierar-
chies of biochemical pathways. Bioinformatics 19, 532–
538 (2003).

[8] R. Guimer`a and L. A. N. Amaral, Functional cartogra-
phy of complex metabolic networks. Nature 433, 895–900
(2005).

[9] G. Palla, I. Der´enyi, I. Farkas, and T. Vicsek, Uncover-
ing the overlapping community structure of complex net-
works in nature and society. Nature 435, 814–818 (2005).
[10] G. W. Flake, S. R. Lawrence, C. L. Giles, and F. M. Co-
etzee, Self-organization and identiﬁcation of Web com-
munities. IEEE Computer 35, 66–71 (2002).

[11] M. Huss and P. Holme, Currency and commodity
metabolites: Their identiﬁcation and relation to the mod-
ularity of metabolic networks. Preprint q-bio/0603038
(2006).

[12] G. P. Garnett, J. P. Hughes, R. M. Anderson, B. P.
Stoner, S. O. Aral, W. L. Whittington, H. H. Handsﬁeld,
and K. K. Holmes, Sexual mixing patterns of patients
attending sexually transmitted diseases clinics. Sexually
Transmitted Diseases 23, 248–257 (1996).

[13] S. O. Aral, J. P. Hughes, B. Stoner, W. Whittington,
H. H. Handsﬁeld, R. M. Anderson, and K. K. Holmes,
Sexual mixing patterns in the spread of gonococcal and
chlamydial infections. American Journal of Public Health
89, 825–833 (1999).

[14] S. Gupta, R. M. Anderson, and R. M. May, Networks of
sexual contacts: Implications for the pattern of spread of
HIV. AIDS 3, 807–817 (1989).

[15] M. Granovetter, The strength of weak ties. Am. J. Sociol.

[16] R. S. Burt, Positions in networks. Social Forces 55, 93–

78, 1360–1380 (1973).

122 (1976).

20

[17] L. C. Freeman, A set of measures of centrality based upon

betweenness. Sociometry 40, 35–41 (1977).

[18] M. E. J. Newman and M. Girvan, Finding and evaluat-
ing community structure in networks. Phys. Rev. E 69,
026113 (2004).

[19] P. Pollner, G. Palla, and T. Vicsek, Preferential attach-
ment of communities: The same principle, but a higher
level. Europhys. Lett. 73, 478–484 (2006).

[20] H. Zhou, Distance, dissimilarity index, and network com-
munity structure. Phys. Rev. E 67, 061901 (2003).
[21] A. E. Krause, K. A. Frank, D. M. Mason, R. E. Ulanow-
icz, and W. W. Taylor, Compartments revealed in food-
web structure. Nature 426, 282–285 (2003).

[22] F. Wu and B. A. Huberman, Finding communities in
linear time: A physics approach. Eur. Phys. J. B 38,
331–338 (2004).

[23] F. Radicchi, C. Castellano, F. Cecconi, V. Loreto, and
D. Parisi, Deﬁning and identifying communities in net-
works. Proc. Natl. Acad. Sci. USA 101, 2658–2663
(2004).

[24] M. E. J. Newman, Fast algorithm for detecting com-
munity structure in networks. Phys. Rev. E 69, 066133
(2004).

[25] A. Capocci, V. D. P. Servedio, G. Caldarelli, and
F. Colaiori, Detecting communities in large networks. In
S. Leonardi (ed.), Proceedings of the 3rd Workshop on
Algorithms and Models for the Web Graph, number 3243
in Lecture Notes in Computer Science, Springer, Berlin
(2004).

[26] S. Fortunato, V. Latora, and M. Marchiori, A method to
ﬁnd community structures based on information central-
ity. Phys. Rev. E 70, 056104 (2004).

[27] J. Reichardt and S. Bornholdt, Detecting fuzzy commu-
nity structures in complex networks with a Potts model.
Phys. Rev. Lett. 93, 218701 (2004).

[28] L. Donetti and M. A. Mu˜noz, Detecting network commu-
nities: A new systematic and eﬃcient algorithm. J. Stat.
Mech. p. P10012 (2004).

[29] H. Zhou and R. Lipowsky, Network brownian motion:
A new method to measure vertex-vertex proximity and
to identify communities and subcommunities. In Lecture
Notes in Computer Science, volume 3038, pp. 1062–1069,
Springer, New York (2004).

[30] P. Orponen and S. E. Schaeﬀer, Local clustering of large
graphs by approximate Fiedler vectors. In Proceedings of
the 4th International Workshop on Eﬃcient and Experi-
mental Algorithms, pp. 524–533, Springer, Berlin (2005).
[31] A. Clauset, Finding local community structure in net-

works. Phys. Rev. E 72, 026132 (2005).

[32] P. Pons and M. Latapy, Computing communities in large
networks using random walks. In Proceedings of the 20th
International Symposium on Computer and Information
Sciences, volume 3733 of Lecture Notes in Computer Sci-
ence, pp. 284–293, Springer, New York (2005).

[33] M. Gustafsson, A. Lombardi, and M. Hornquist, Com-
parison and validation of community structures in com-
plex networks. Preprint physics/0601057 (2006).

[34] M. E. J. Newman, Modularity and community structure

in networks. Preprint physics/0602124 (2006).

[35] L. Danon, A. Diaz-Guilera, and A. Arenas, Eﬀect of
size heterogeneity on community identiﬁcation in com-
plex networks. Preprint physics/0601144 (2006).

[36] J. Reichardt and S. Bornholdt, Statistical mechan-
ics of community detection. Preprint cond-mat/0603718

(2006).

[37] M. B. Hastings, Community detection as an inference

problem. Preprint cond-mat/0604429 (2006).

[38] L. Danon, J. Duch, A. Diaz-Guilera, and A. Arenas,
Comparing community structure identiﬁcation. J. Stat.
Mech. p. P09008 (2005).

[39] A. Clauset, M. E. J. Newman, and C. Moore, Finding
community structure in very large networks. Phys. Rev.
E 70, 066111 (2004).

[40] R. Guimer`a, M. Sales-Pardo, and L. A. N. Amaral, Mod-
ularity from ﬂuctuations in random graphs and complex
networks. Phys. Rev. E 70, 025101 (2004).

[41] J. Duch and A. Arenas, Community detection in complex
networks using extremal optimization. Phys. Rev. E 72,
027104 (2005).

[42] M. Fiedler, Algebraic connectivity of graphs. Czech.

Math. J. 23, 298–305 (1973).

[43] A. Pothen, H. Simon, and K.-P. Liou, Partitioning sparse
matrices with eigenvectors of graphs. SIAM J. Matrix
Anal. Appl. 11, 430–452 (1990).

[44] P.-O. Fj¨allstr¨om, Algorithms for graph partitioning: A
survey. Link¨oping Electronic Articles in Computer and
Information Science 3(10) (1998).

[45] O. Goldschmidt and D. S. Hochbaum, Polynomial algo-
rithm for the k-cut problem. In Proceedings of the 29th
Annual IEEE Symposium on the Foundations of Com-
puter Science, pp. 444–451, Institute of Electrical and
Electronics Engineers, New York (1988).

[46] F. R. K. Chung, Spectral Graph Theory. Number 92
in CBMS Regional Conference Series in Mathematics,
American Mathematical Society, Providence, RI (1997).
[47] M. Barahona and L. M. Pecora, Synchronization in small-
world systems. Phys. Rev. Lett. 89, 054101 (2002).
[48] T. Nishikawa, A. E. Motter, Y.-C. Lai, and F. C. Hoppen-
steadt, Heterogeneity in oscillator networks: Are smaller
worlds easier to synchronize? Phys. Rev. Lett. 91, 014101
(2003).

[49] M. Bern, D. Eppstein, and J. Gilbert, Provably good
mesh generation. In Proceedings of the 31st Annual IEEE
Symposium on the Foundations of Computer Science, pp.
231–241, Institute of Electrical and Electronics Engi-
neers, New York (1990).

[50] M. E. J. Newman, Mixing patterns in networks. Phys.

Rev. E 67, 026126 (2003).

[51] S. White and P. Smyth, A spectral clustering approach
to ﬁnding communities in graphs. In H. Kargupta, J. Sri-
vastava, C. Kamath, and A. Goodman (eds.), Proceed-
ings of the 5th SIAM International Conference on Data
Mining, Society for Industrial and Applied Mathematics,
Philadelphia (2005).

[52] C. P. Massen and J. P. K. Doye, Identifying “communi-
ties” within energy landscapes. Phys. Rev. E 71, 046101
(2005).

[53] S. H. Strogatz, Exploring complex networks. Nature 410,

21

268–276 (2001).

[54] S. N. Dorogovtsev and J. F. F. Mendes, Evolution of
networks. Advances in Physics 51, 1079–1187 (2002).
[55] D. J. Watts and S. H. Strogatz, Collective dynamics of
‘small-world’ networks. Nature 393, 440–442 (1998).
[56] A.-L. Barab´asi and R. Albert, Emergence of scaling in

random networks. Science 286, 509–512 (1999).

[57] L. A. N. Amaral, A. Scala, M. Barth´el´emy, and H. E.
Stanley, Classes of small-world networks. Proc. Natl.
Acad. Sci. USA 97, 11149–11152 (2000).

[58] F. Chung and L. Lu, Connected components in random
graphs with given degree sequences. Annals of Combina-
torics 6, 125–145 (2002).

[59] T.  Luczak, Sparse random graphs with a given degree se-
quence. In A. M. Frieze and T.  Luczak (eds.), Proceedings
of the Symposium on Random Graphs, Pozna´n 1989, pp.
165–182, John Wiley, New York (1992).

[60] M. Molloy and B. Reed, A critical point for random
graphs with a given degree sequence. Random Structures
and Algorithms 6, 161–179 (1995).

[61] M. E. J. Newman, S. H. Strogatz, and D. J. Watts, Ran-
dom graphs with arbitrary degree distributions and their
applications. Phys. Rev. E 64, 026118 (2001).

[62] R. Pastor-Satorras, A. V´azquez, and A. Vespignani, Dy-
namical and correlation properties of the Internet. Phys.
Rev. Lett. 87, 258701 (2001).

[63] M. E. J. Newman, Assortative mixing in networks. Phys.

Rev. Lett. 89, 208701 (2002).

[64] D. Lusseau, K. Schneider, O. J. Boisseau, P. Haase,
E. Slooten, and S. M. Dawson, The bottlenose dolphin
community of Doubtful Sound features a large propor-
tion of long-lasting associations. Can geographic isola-
tion explain this unique trait? Behavioral Ecology and
Sociobiology 54, 396–405 (2003).

[65] C. J. Alpert and S.-Z. Yao, Spectral partitioning: The
more eigenvectors, the better. In B. T. Preas, P. G.
Karger, B. S. Nobandegani, and M. Pedram (eds.), Pro-
ceedings of the 32nd ACM/IEEE conference on Design
automation, pp. 195–200, ACM Press, New York, NY
(1995).

[66] C. D. Meyer, Matrix Analysis and Applied Linear Al-
gebra. Society for Industrial and Applied Mathematics,
Philadelphia (2000).

[67] B. W. Kernighan and S. Lin, An eﬃcient heuristic proce-
dure for partitioning graphs. Bell System Technical Jour-
nal 49, 291–307 (1970).

[68] J. M. Kleinberg, Authoritative sources in a hyperlinked

environment. J. ACM 46, 604–632 (1999).

[69] P. Holme, F. Liljeros, C. R. Edling, and B. J. Kim, Net-
work bipartivity. Phys. Rev. E 68, 056107 (2003).
[70] E. Estrada and J. A. Rodr´ıguez-Vel´azquez, Spectral mea-
sures of bipartivity in complex networks. Phys. Rev. E
72, 046105 (2005).

