Log-normal statistics in e-mail communication patterns

Daniel B. Stouffer,∗ R. Dean Malmgren∗, and Lu´is A. N. Amaral†
Department of Chemical and Biological Engineering, Northwestern University, Evanston, IL 60208, USA

(Dated: February 2, 2008)

Abstract

Following up on Barab´asi’s recent letter to Nature [435, 207–211 (2005)], we systematically investigate

the time series of e-mail usage for 3,188 users at a university. We focus on two quantities for each user:

the time interval between consecutively sent e-mails (interevent time), and the time interval between when

a user sends an e-mail and when a recipient sends an e-mail back to the original sender (waiting time). We

perform a standard Bayesian model selection analysis that demonstrates that the interevent times are well-

described by a single log-normal while the waiting times are better described by the superposition of two

log-normals. Our analysis rejects the possibility that either measure could be described by truncated power-

law distributions with exponent α

1. We also critically evaluate the priority queuing model proposed

≃

by Barab´asi to describe the distribution of the waiting times. We show that neither the assumptions nor

the predictions of the model are plausible, and conclude that a theoretical description of human e-mail

communication patterns remains an open problem.

6
0
0
2
 
y
a
M
 
3
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
7
2
0
5
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

∗These two authors contributed equally to this work.
†Electronic address: amaral@northwestern.edu

1

I.

INTRODUCTION

Human beings are extraordinarily complex agents. Remarkably, in spite of that complexity

a number of striking statistical regularities are known to describe individual and societal human

behavior [1, 2, 3, 4, 5, 6]. These regularities are of enormous practical importance because of the

inﬂuence of individual behaviors on social and economic outcomes.

Even though the analysis of social and economic data has a long and illustrious history, from

Smith [7] to Pareto [8] and to Zipf [9], the recent availability of digital records has made it much

easier for researchers to quantitatively investigate various aspects of human behavior. In particular,

the availability and omnipresence of e-mail communication records is attracting much attention

[10, 11, 12, 13, 14].

Recently, Barab´asi studied the e-mail records of users at a university and reported two patterns

in e-mail communication [12]:

the time interval between two consecutive e-mails sent by the

same user, which we will denote as the interevent time τ , and the time interval between when

a user sends an e-mail and when a recipient sends an e-mail back to the original sender, which

we will denote as the waiting time τw, follow power-law distributions which decay in the tail

with exponent α

1. Additionally, Barab´asi proposed a priority queuing model that reportedly

captures the processes by which individuals reply to e-mails, thereby predicting the probability

≃

distribution of τw.

Here, we demonstrate that the empirical results reported in Ref. [13] are an artifact of the

data analysis. We perform a standard Bayesian model selection analysis that demonstrates that

the interevent times are well-described by a single log-normal while the waiting times are better

described by the superposition of two log-normals. Our analysis rejects beyond any doubt the

possibility that the data could be described by truncated power-law distributions.

We also critically evaluate the priority queuing model proposed by Barab´asi to describe the

observed waiting time distributions. We show that neither the assumptions nor the predictions of

the model are plausible. We thus conclude that the description of human e-mail communication

patterns remains an open problem.

The remainder of this paper is organized as follows. In Section II, we describe the preprocessing

of the data. We then analyze the distribution of interevent times (Section III) and the distribution

of waiting times (Section IV). Finally, in Section V we investigate the priority queuing model of

Ref. [13].

2

II. PREPROCESSING OF THE DATA

We consider here the database investigated by Barab´asi [13], which was also the focus of an

earlier paper by Eckmann et al. [12]. This database consists of e-mail records for 3,188 e-mail

accounts at a university covering an 83-day period. Each record comprises a sender identiﬁer, a

recipient identiﬁer, the size of the e-mail, and a time stamp with a precision of one second. Before

describing our analysis of the data, we ﬁrst note some important features of the data which impact

the analysis.

The ﬁrst important fact is that the data were gathered at an e-mail server, not from the e-

mail clients of the individual users. It is quite possible that some users have e-mail clients, like

Microsoft Outlook, which permit users to send multiple e-mails at once regardless of when the

e-mails were composed. Moreover, servers may parse long recipient lists into several shorter lists

[15]. For this reason, e-mails to multiple recipients were occasionally recorded in the server as

multiple e-mails. Each of these duplicate e-mails was then sent in rapid succession to a different

subset of the list of recipients in the actual e-mail. Both the client-side and server-side uncertainties

introduce artifacts in the time series of interevent times for each user as it could appear that a user

is sending several e-mails over a very short time interval.

To minimize these uncertainties, we preprocessed the data in order to focus on actual human

behavior. First, we identify sets of e-mails sent by a user that have the exact same size but whose

time stamp differs by at most ﬁve seconds1. We then remove all but the ﬁrst e-mail from the

time series of e-mails sent, while adjusting the list of recipients to the ﬁrst e-mail to include all

recipients in the removed e-mails 2.

An additional important fact to note is that some of the e-mail accounts do not belong to “typ-

ical” users. For example, User 1962 only sent 5 e-mails while receiving 2,284 e-mails. This

individual’s e-mail use is too infrequent to provide useful information on human dynamics. Mean-

while User 4099 sent 9,431 e-mails while receiving no e-mails. Although it cannot be conﬁrmed

1 Five seconds corresponds with the average minimal bound on humanly possible interevent times based on the

experiment in Fig. 2.

2 A more aggressive preprocessing method would also remove blind-carbon-copied (BCC) e-mails. The basic idea
is that an e-mail with BCC recipients will have its size increased by a few bytes due to the addition of outgoing
headers. E-mails to the BCC recipients would be sent by the server shortly after the e-mail to visible recipients and
would thus increase the number of very small interevent times. We choose to err on the side of caution and not
attempt to remove e-mails with BCC recipients, as their detection is more subjective.

3

0
10

-1

10

-2

10

-3

10

i

n
o
i
t
u
b
i
r
t
s
d
 
e
v
i
t
a
u
m
u
C

l

-4

10

0

A

B

y
t
i
s
n
e
d
 
y
t
i
l
i

b
a
b
o
r
P

0.4

0.3

0.2

0.1

0.0

0
10

1
10

3
10

4
10

-6

-4

2
10
Nsent

-2

0
2
ln(Nreceived / Nsent)

4

6

FIG. 1: Preprocessing of the data. A, The cumulative distribution of the number of e-mails sent by the 3,188
users over 83 days. To avoid characterizing users which use e-mail infrequently, we consider the 1,212 users
which sent at least 11 e-mails over 83 days (shaded region). Note that this removes the 759 users which sent
no e-mails and the 370 users that sent one e-mail. B, The distribution of the ratio of the number of e-mails
received to the number of e-mails sent is well-described by a log-normal (red line). We use this fact to
develop a criteria to identify typical e-mail users that sent at least 11 e-mails over 83 days and differentiate
them from bulk e-mail accounts, listserves, and e-mail accounts that are rarely used by their owners. We
keep the 1,152 users which fall within three standard deviations of the mean (shaded region).

due to the anonymous nature of the data, this e-mail account was in all likelihood used for bulk

e-mails, implying that it cannot provide information on human e-mail usage.

To avoid having our analysis distorted, we ﬁrst restrict our attention to users which sent at least

11 e-mails over the 83-day experiment, yielding a minimum of 10 interevent times. Our reasoning

is that users sending fewer e-mails do not use e-mail regularly enough to allow us to truly infer

patterns of human dynamics. This procedure excludes 1,976 of the 3,188 original e-mail accounts.

Next we examine the ratio of the number of e-mails received to the number of e-mails sent to

determine what constitutes a “typical” user. This ratio is well-described by a log-normal distribu-

tion, and we use this fact to consider only those users in our study who are within three standard

deviations from the mean. This added constraint excludes an additional 46 users. We thus focus

here on the 1,152 users who fulﬁll the above criteria (Fig. 1).

III.

INTEREVENT TIMES

Reference [13] reports that the probability distribution of time intervals τ between consecutive

e-mails sent by an individual follows a power-law P (τ )

τ −α with α

1. A basic examination

≈

≃

of Barab´asi’s results, however, quickly reveals a number of issues.

1. Figure 2a of Ref. [13] features three bins corresponding to interevent times τ

3 seconds,

≤

4

A

]
s
[
 
τ

8

6

4

2

0

2
10

0
10

)
τ
(

P

-2

10

-4

10

10

5
20
Index of sent e-mail

15

25

0

5

10
Index of sent e-mail

15

20

B

C

-6

10

-2

10

0
10

2
10
τ [s]

4
10

6
10

-2

10

0
10

4
10

6
10

2
10
τ [s]

FIG. 2: The statistical analysis presented in Fig. 2a of Ref. [13]. A, Estimation of a lower bound on
interevent times, τ . Two of us sent about twenty e-mails trying to minimize the time interval between con-
secutive e-mails. To be as fast as possible, we sent replies to an e-mail already in our inboxes. Additionally,
we did not even write any text or read the e-mail to which we were responding. We ﬁnd that humans need
at least 3 seconds to send consecutive e-mails. B, Reproduction of Fig.2a of Ref. [13] obtained with Vis-
taMetrix [16] and, C, the same data with the boundaries of the bins clearly marked. We assumed that the
data points in Fig. 2a of Ref. [13] were placed in the middle of the bin. Note that there is a bin recording
data for τ < 1 second, whereas the data have a resolution of one second. The shaded bins indicate values
with τ

3 second, which contain 9% of all events for the unidentiﬁed user.

≤

an unphysical interval (Fig. 2A). The events in those bins in fact account for 9% of all events.

2. Figure 2a of Ref. [13] features at least one bin conﬁned to interevent times τ < 1 second

(Fig. 2B–C) while the data have a precision of one second [12].

We next quantitatively compare the plausibility of our log-normal hypothesis with the plausi-

bility of the power-law hypothesis of Ref. [13] for interevent times. To simplify the analysis, we do

not consider τ , but its logarithm. If a random variable τ is log-normally distributed, then u = ln(τ )

follows a Gaussian distribution, whereas if τ is distributed according to a power-law with exponent

5

A

1.0

n
o
i
t
c
n
u
f
 
y
t
i
l
i

b
a
b
o
r
P

0.5

0.0
1.0

0.5

0.0
0

20

10

10

10

0
10

-10

10

1
10

w
a
l
-
r
e
w
o
p
,
S
K

l

a
m
r
o
n
-
g
o
l
,

S
K

P

 
/
 

P

User 1491

User 564

User 4176

P
o
w
e
r
−
a
w

l

L
o
g
−
n
o
r
m
a

l

5

10

15

0

5

10

15

0

5

10

15

u

u

C

B

0
10

-2

10

-4

10

u

g
n

l

i
t
c
e
e
s
 
f

o

 
y
t
i
l
i

b
a
b
o
r
p
 
r
o
i
r
e
t
s
o
P

 
 
 
l

 

e
d
o
m
w
a
l
-
r
e
w
o
p
 
 
 
 
 
 
 
 
 
 
 

-6

10

0
10

2
10

3
10

Number of messages sent

1
10

2
10

3
10

Number of users considered

FIG. 3: Bayesian model selection protocol for interevent times. A, Cumulative distributions of u = ln(τ )
for three users in the database. The top panels show data and Gaussian model predictions for the entire range
of u, whereas the bottom panels show data and power-law model for intermediate values of u. B, Scatter
plot of PKS,log−normal/PKS,power−law, the ratio of the two PKS values, for all available users depending
on the number of consecutive e-mails sent for each user. The larger circles colored green, yellow, and red
correspond to the data shown in (A). Note that there are 2 users for which the ratio of PKS is greater than
1020. Those users are indicated by the arrows. C, Recursively calculated posterior probability of accepting
the power-law model. We use Bayesian model selection to recursively calculate the posterior probability
law) = 0.95 (solid
of selecting the power-law distribution for two different prior probabilities: P (power
black) and P (power
law) = 0.50 (red dashed). In both cases, the posterior probability of selecting the
power-law model vanishes after considering 932 of the 1,016 users meeting our preprocessing criteria.

−

−

α = 1, then u is uniformly distributed in the interval [ln(τmin), ln(τmax)]. Speciﬁcally, for

the distribution of u = ln(τ ) is



τ −1 , τmin

τ

τmax

P (τ )

∝ 


0 ,

≤
otherwise

≤

P (u) = 


1

umax−umin , umin
0 ,

≤
otherwise

u

≤

umax

(1)

(2)

Barab´asi [13] has argued that the power-law model is meant to describe only “intermediate” τ



values falling between 100 and 10,000 seconds. Since some users have a smaller range of τ values

than that interval, we test the agreement of the predictions of the power-law model only with data

6

in the interval [τmin, τmax], where τmin = inf

τ

τ

100

and τmax = sup

τ

τ

|
properly specify the power-law distribution, we must have at least two data points in [τmin, τmax].

≥

≤

{

{

}

|

10, 000
}

. To

This constraint leads to the exclusion of an additional 136 users.

We then use the Kolmogorov-Smirnov (KS) test [17] as a measure of the plausibility of a model

given the user’s data. Speciﬁcally, we compare the distribution of the logarithm of the interevent

times for a given user to two candidate models: a Gaussian distribution and a uniform distribution.

Importantly, there is absolutely no ﬁtting in our analysis. The parameters of the Gaussian

distribution, µ and σ, are simply the sample average and standard deviation of u, while the uniform

distribution is completely speciﬁed by umin and umax. Figure 3D displays the ratio of the two KS

probabilities versus number of e-mails sent for all users with at least two data points in the interval

[τmin, τmax].

In order to determine which of the two models provides a more accurate description of the

empirical data, we use the results of the KS test as inputs in a Bayesian model selection analy-

sis [17, 18]. Bayes’ rule states that

(3)

i,

E

P (

j

M

|E

i) =

P (
i
E
k P (

j) P (

j)

M
k) P (

,

k)

M

|M
i
E

|M

P

where P (

i) is the posterior probability of selecting model

j

j given an observation

P (

i

E

|M

M

|E
j) = PKS(

i

E

|M

prior probability of selecting model

j. Assuming no prior knowledge about the correctness of

j) is the probability of observing

i given a model

j, and P (

j) is the

E

M

M

M

M

the power-law and log-normal models, one would select P (log-normal) = P (power-law) = 0.5

for each model. However, to eliminate any bias on our part, we perform the Bayesian model selec-

tion analysis for two cases: (i) no prior knowledge, P (log-normal) = P (power-law) = 0.5, and

(ii) the power-law model is far more likely to be correct, P (power-law) = 0.95.

The availability of data for multiple users enables us to perform this analysis recursively to

obtain posterior probabilities of selecting each model given the available data. Concretely, the

analysis of the interevent times

i from user i updates the posterior probabilities of the two models

E

P (

j

M

|E

i) using Eq. (3). These updated posterior probabilities are then used as prior probabilities

for the next user i + 1. When all of the users have been included, this analysis reveals the posterior

probability of the model given all of the available data. The Bayesian model selection analysis

demonstrates that the likelihood of the truncated power-law model being a good description of the

data vanishes to zero when all data is considered (Fig. 3C).

7

IV. WAITING TIMES

Before we present our analysis of the waiting times, we must note that the database collected

by Eckmann et al. [12] and analyzed by Barab´asi [13] is not particularly well-suited for identifying

the waiting times for replying to an e-mail. The data merely records that an e-mail was sent by

user A to user B at time t. The data does not specify whether the e-mail from A to B is, in fact, a

reply to a prior message. Imagine the following scenario: user A sends an e-mail to user B. Three

days later, user B sends an unrelated e-mail to user A. Barab´asi’s approach [13], which we follow,

is to classify this e-mail as a reply to the e-mail sent by user A three days earlier. As this case

illustrates, the analysis of waiting times is signiﬁcantly less reliable than that of interevent times.

Reference [13] reports that the probability distribution of time intervals τw between receiving a

message from a sender and sending another e-mail to that sender follows a power-law distribution

P (τw)

τ −α
w with α

≈

≃

1. A cursory analysis of this result again reveals several problems.

1. Figure 2b of Ref. [13] features three bins corresponding to waiting times τw

6 seconds,

≤

an unphysical interval (Fig. 4A). The events in those bins account for 1% of all events.

2. Figure 2b of Ref. [13] features two bins conﬁned to waiting times τw < 1 second (Fig. 4B–

C) while the data have a precision of one second [12].

We characterize the actual distribution of waiting times τw following the same procedure out-

lined in Section III. After parsing the data, we are left with 724 users which have sent at least 10 re-

sponse e-mails over 83 days and have at least two waiting times in the interval 100

τw

≤

≤

10, 000

seconds. We then perform KS tests and Bayesian model selection to determine whether the wait-

ing times are better described by a power-law or log-normal distribution. The Bayesian model

selection analysis demonstrates that the likelihood of the truncated power-law model being a good

description of the data vanishes to zero when all data is considered (Fig. 5).

A. Double log-normal description

Analysis of the data for the users with the largest number of replies suggests that τw may

actually be better described by a superposition of two log-normal peaks: the ﬁrst peak—which

contains most of the probability mass—typically corresponds with waiting times of an hour, and

the second peak typically corresponds with waiting times of two days. This ﬁnding prompted us

8

10

A

]
s
[
 

w

τ

8

6

4

0

2
10

0
10

)

w

τ
(

P

-2

10

-4

10

5

10

20
Index of reply e-mail

15

25

0

5

10

15

Index of reply e-mail

B

C

-6

10

-2

10

0
10

2
10
w [s]

τ

4
10

6
10

-2

10

0
10

4
10

6
10

2
10
w [s]

τ

FIG. 4: The statistical analysis presented in Fig. 2b of Ref. [13]. A, Estimation of a lower bound on waiting
time, τw. Two of us sent about twenty replies to an e-mail already in our inboxes. To minimize the time
required to do this, we did not read the e-mail to which we were responding but simply wrote “yes” at the
top of our reply and then clicked send. We ﬁnd that 6 seconds is the smallest waiting time feasible for a
human. B, Reproduction of Fig.2a of Ref. [13] obtained with VistaMetrix [16] and, C, the same data but
with the boundaries of the bins clearly marked. We assumed that the data points in (B) are placed in the
middle of the bin. Note that there are two bins recording data for τw < 1 second, while the data have a
resolution of one second. The shaded bins indicate values with τw < 6 seconds consisting of 1% of the
data.

to investigate whether the superposition of two log-normals would provide a better description of

the data than a single log-normal. The probability function in this case has the functional form:

F (uw) = 0.5

1 + f erf
"

 

uw
µ1
−
σ1√2 !

+ (1

f ) erf

−

uw
µ2
σ2√2 !#

−

,

 

(4)

where µ1 and µ2 are the means the two peaks, σ1 and σ2 are the standard deviations of the two

peaks, and f is the probability mass in the ﬁrst peak.

In order to conduct the KS tests and Bayesian model selection, we must ﬁrst estimate the

parameters of the double log-normal distribution, Eq. (4). Unlike the earlier analyses, it is not

possible to estimate the parameters of the distribution without performing a ﬁt of Eq. (4) to the data.

We perform maximum likelihood estimation [17] to determine the best estimate parametrization

9

User 1531

User 2640

User 355

P
o
w
e
r
−
a
w

l

L
o
g
−
n
o
r
m
a

l

l

o
g
−
n
o
r
m
a

l

D
o
u
b
e

l

5

10

15

0

5

10

15

0

5

10

15

u

u

Power−law vs. Log−normal

Power−law vs. Double log−normal

2
10
Number of replies sent

3
10

P

-5

10

1
10

2
10
Number of replies sent

3
10

D

E

A

1.0

n
o
i
t
c
n
u
f
 
y
t
i
l
i

b
a
b
o
r
P

0.5

0.0
1.0

0.5

0.0
1.0

0.5

0.0
0

B

20

10

10

10

0
10

w
a
l
-
r
e
w
o
p
S
K

,

l

a
m
r
o
n
-
g
o

l
,

S
K

P

 
/
 

P

-10

10

1
10

0
10

-2

10

-4

10

l

g
n
i
t
c
e
e
s
 
f
o
 
y
t
i
l
i

b
a
b
o
r
p
 
r
o
i
r
e
t
s
o
P

 

 
 
 
l
e
d
o
m
w
a
l
-
r
e
w
o
p
 
 
 
 
 
 
 
 
 
 
 

-6

10

0
10

1
10

2
10

3
10

Number of users considered

1
10

2
10

3
10

Number of users considered

FIG. 5: Bayesian model selection protocol for waiting times. A, Cumulative distributions of u = ln(τ ) for
three users in the database. The top panels show data and power-law predictions over intermediate values
of u whereas the middle and bottom panels depict Gaussian and double Gaussian model predictions for the
entire range of u. B–C, Scatter plot of the ratio of the two PKS values for all available users depending on
the number of e-mails sent for each user. The larger circles highlighted in green, yellow, and red correspond
to the data shown in (A). Users outside the domain are indicated by the arrows. D–E, Recursively calculated
posterior probability of accepting the power-law model for in comparison with the log-normal and double
log-normal models. We use Bayesian model selection to recursively calculate the posterior probability of
selecting the power-law distribution for two different prior probabilities: P (power
law) = 0.95 (solid
law) = 0.50 (red dashed). The posterior probability of selecting the power-law
black) and P (power
model vanishes after considering 140 and 49 of the 724 users for the log-normal and double log-normal
comparisons, respectively.

−

−

25

10

C

15

10

P

 
/
 

u

w
a
l
-
r
e
w
o
p
S
K

,

l

a
m
r
o
n
-
g
o

l
 

l

e
b
u
o
d
S
K

,

5
10

0
10

-2

10

-4

10

-6

10

0
10

l

g
n
i
t
c
e
e
s
 
f
o
 
y
t
i
l
i

b
a
b
o
r
p
 
r
o
i
r
e
t
s
o
P

 

 
 
 
l
e
d
o
m
w
a
l
-
r
e
w
o
p
 
 
 
 
 
 
 
 
 
 
 
 

10

0
10

-10

10

f
o
 
y
t
i
l
i

b
a
b
o
r
p
 
r
o
i
r
e
t
s
o
P

 
 
 
l
e
d
o
m
 
g
n
i
t
c
e
e
s
 
 
 
 

l

-20

10

0
10

Double log-normal
Log-normal
Power-law

1
10

2
10

3
10

Number of users considered

FIG. 6: Bayesian model selection protocol for comparing the double log-normal, log-normal, and power-
law with exponent α = 1 distributions. After considering all of the 724 available users, the posterior
probability of the power-law and log-normal vanishes.

of Eq. (4); see Appendix A for details.

After determining the parameters of the double log-normal distribution, we conduct KS tests

and Bayesian model selection as before, and we ﬁnd that a double log-normal has a posterior

probability of one when compared with the power-law model (Fig. 5). In fact, if we consider all

three candidate models simultaneously, we still ﬁnd that the posterior probability of the double

log-normal is one (Fig. 6).

B. Alternative deﬁnition of the waiting times

Recently, Barab´asi and co-workers [19, 20] have reinterpreted the deﬁnition of the waiting

times introduced in Ref. [13]. Barab´asi and co-workers note that the actual waiting time should

not be counted from the time the original e-mail was sent, but from the time the original e-mail

was ﬁrst read. This appears perfectly logical, but the database under investigation does not provide

us with information on when the user actually ﬁrst read the e-mail. In fact, as we explained earlier

the database does not even provide information that would enable one to decide whether an e-mail

is a reply to a previous message or whether it is a totally unrelated message.

Nonetheless, it is worthwhile to analyze in greater detail the manner in which the authors of

Refs. [19, 20] measure the waiting time τw since they characterize it as an improvement over the

original method [13]. At time t1 user A sends an e-mail to user B. At time t2 > t1, user B sends an

e-mail. At time t3

t2, user B sends an e-mail to user A. The “real” waiting time is now deﬁned

as τr = t3

t2, instead of τw = t3

t1. Note that t2 still is not the actual time when the user

≥

−

actually ﬁrst read the e-mail.

−

We ﬁnd three major problems with the reported predictive ability of the priority queuing model

11

y
t
i
s
n
e
d
 
y
t
i
l
i

b
a
b
o
r
P

0
10

-3

10

-6

10

-9

10

-12

10

-15

10

n
o
i
t
c
n
u
f
 
y
t
i
l
i

b
a
b
o
r
P

1.0

0.8

0.6

0.4

0.2

0.0

A

B

0
10

2
10

4
10

6
10

τ

w

FIG. 7: Apparent agreement of new waiting time measure with priority queuing model prediction (p =
0.999999,L = 2) in Figs. 1a–b of Ref. [20]. A, Reproduction of the empirical probability density (open
circles) and purported model solution (red line) from Fig. 1a of Ref. [20] using VistaMetrix [16]. To match
the model with the empirical data, the authors of Ref. [20] claim that τr = 0 is actually τr = 1 (arrow).
Moreover, the authors of Ref. [20] do not use the actual model solution from Ref. [21] (blue dashed line)
as claimed. B, Probability function for the empirical waiting times, the purported model prediction, and the
actual model solution. Even if the purported model solution was correct, it is visually apparent that it does
not match the large gap in waiting times between τw = 1 and τw = 60 seconds.

to capture the peak, the power-law regime, and the exponential cut-off of the waiting time distri-

butions. First, we are troubled that the “agreement” for the peak at τr = 1 is obtained by making

the transformation τr = 1 if t3 = t2, instead of τr = 0 as would be expected from the deﬁnition.

In other words, to match the peak at τr = 1, Barab´asi and co-workers state that 0 = 1.

Moreover, we are surprised that Barab´asi and co-workers claim to use the exact model solution

to predict the empirical waiting times. Unlike Fig. 1a of Ref. [20], the exact probability density has

a large, discontinuous drop at τr = 1 [21]. When we compare the data presented in Ref. [20] with

the actual solution, it is clear that the model does not, in fact, match the empirical data (Fig. 7A).

Finally, there are no waiting time values for τw between 1 and 60 seconds whereas the prior-

ity queuing model predicts a smooth continuous decrease of the probability density function in

that region. While the difference between the two functions is difﬁcult to discern in the plot of

Ref. [19], the difference is actually quite marked (Fig. 7B).

12

User 564

Priority queuing model

FIG. 8: Comparison of time series of a typical user versus the time series assumed in the priority queuing
model. The time series of 100 activities for an actual user is quite different than the time series for 100
activities for the priority queuing model. In the priority queuing model, one task is executed at each time
step causing the interevent times to be distributed according to a Dirac-delta function. As demonstrated in
Section III and Ref. [13], the interevent times are distributed with a heavy-tail.

V. THE PRIORITY QUEUING MODEL

We also examined the priority queuing model presented to explain the reported power-law in

e-mail communication [13]. This model is deﬁned as follows. An individual has a priority queue

with L tasks. Each task is assigned a priority x drawn from a uniform distribution ρ(x) = U[0, 1].

At each unit time step, the user executes either the highest-priority task with probability p or

a randomly selected task with probability 1

p. The executed task is then removed from the

−

queue and a new task with priority x, again drawn from ρ(x), is added to the queue. For the sake

of comparison of the model predictions with the empirical data, Barab´asi surmised that a user’s

queue consists of e-mails which require a response. The model thus predicts the time τw that a

message spends in the user’s inbox prior to response.

We ﬁrst address the deﬁciencies in the model’s assumptions. First, humans can only process

a handful of pieces of information at any time [22]. However, many users of e-mail hold tens,

hundreds, or even thousands of e-mails in their inbox which may require action. It is therefore

unrealistic to expect any user to account for each task’s priority or to be able to carefully determine

the absolute (or even the relative) priority of such a large number of tasks.

Secondly, the priority queuing model does not account for the heterogeneities in interevent

times revealed by our analysis in Section III and reported in Ref. [13]. In the priority queuing

model, tasks are executed at each time step which means that the distribution of interevent times

can be described by Dirac’s delta function (Fig. 8).

13

L = 2

L = 100

t

t

t

t

B

D

1

0.8

0.6

0.4

0.2

0

1.0

0.8

0.6

0.4

0.2

n
o
i
t
u
b
i
r
t
s
i
d
 
e
v
i
t
a
l
u
m
u
C

A

C

0.0
10

-8

p
 
=
 
0
.
9
9

p
 
=
 
0
.
9
9
9
9
9

-6

10

-4

10

-2

10

0
10

-8

10

-6

10

-4

10

-2

10

0
10

Priority

FIG. 9: Deducing the steady state behavior of the priority queuing model. A–D The cumulative distribution
of priorities x in queue after 10i tasks have been executed where i = 0, 1, 2,
, 9. The author of Ref. [13],
considers the case of (D) L = 100 and p = 0.99999 after 106 tasks have been executed (red dashed line). In
this case, however, the model has not even reached steady-state. The important thing to notice is that after a
short transient time, the priorities become uniformly distributed in the very small interval [0, 1
p] denoted
with the gray shading. When new tasks are added to the queue from a uniform distribution on the interval
[0, 1], the vast majority of new tasks are executed immediately. This feature of the priority queuing model
is not representative of human behavior.

· · ·

−

The priority queuing model also suffers from several unrealistic predictions. First, the time for

the model to reach steady-state increases as L/(1

p) [21]. This means that for the case considered

−
in Ref. [13] (L = 100, p = 0.99999), the time to reach steady-state is on the order of 107 tasks. If

a user operating according to those parameter values sends 100 e-mails a day (a very large number

of e-mails), it would take him 100,000 days

300 years to reach steady-state. It is also worthwhile

to note that the results for the model in Ref. [13] were not even obtained for steady-state, implying

that the data is actually a mixture of different stages of the relaxation process of the model.

Second, after reaching steady-state, the dynamics of the model become quite anomalous. The

priorities of the tasks in the user’s queue converge to a uniform distribution U[0, 1

p] (Fig. 9),

−

≈

14

L = 2

L = 100

-10

10

B

1
10

2
10

3
10

0
10

2
10

4
10

0
10

-2

10

-4

10

-6

10

-8

10

0
10

-3

10

-6

10

-9

10

p
 
=
 
0
.
9
9

 

 

.

p
=
0
9
9
9
9
9

0
10

-2

10

-4

10

-6

10

-3

10

-6

10

-9

10

A

-8

10

0
10

0
10

y
t
i

s
n
e
d
y
t
i
l
i

 

b
a
b
o
r
P

C

-12

10

0
10

2
10

4
10

6
10

2
10

4
10

6
10

8
10

D

-12

10

-15

10

0
10

Waiting time

FIG. 10: Contrasting the transient and steady-state behavior of the priority queuing model. A–D, We plot
p) (red) and steady-
the distribution of waiting times during the transient period for times t < 0.1 L/(1
state for times t > 10 L/(1
p) (black). Notice that the likelihood that a task is executed after spending
−
more than one unit of time on the queue is vanishingly small.

−

while new tasks arrive with a priority drawn from U[0, 1]. Thus, in the limit p

1, an e-mail user

→

has a queue consisting of extremely low priority tasks and consequently performs new tasks with

probability p

1 immediately upon arrival. This results in a peak at τw = 1 that accounts for

→

nearly all of the probability mass (Fig. 10). Clearly this situation is not representative of e-mail

activity, let alone human behavior as Ref. [13] claims.

More fundamentally, the priority queuing model predicts a distribution of waiting times that

decays as a power-law with an exponent α = 1 [19, 21] whereas the actual data clearly rejects

that description; cf. Section IV. In fact, a superposition of two log-normals, one corresponding

to waiting times of less than a day and another corresponding to a waiting time of several days

provides an excellent description of the empirical data. More importantly, that description agrees

with the common experience of e-mails users: one replies to e-mails within the day, if not, within

the next few days, and if not then, never.

15

VI. CONCLUSIONS

Here, we have quantitatively analyzed human e-mail communication patterns. In particular,

we have found that the interevent times are well-described by a log-normal distribution while the

waiting times are well-described by the superposition of two log-normal distributions. We have

simultaneously rejected the hypothesis that either quantity is adequately described by a truncated

power-law with exponent α

1.

≃

We have also critically examined the priority queuing model proposed by Barab´asi to match

the empirically observed waiting time distributions. After detailed analysis, we conclude that

neither the assumptions nor the predictions of the model are plausible. We note that the model

does not match the empirically observed waiting time distribution, and we therefore contend that

the theoretical description of human dynamics is an open problem.

Barab´asi and coworkers have also examined the dynamics of letter writing [23], web browsing,

library loans, and stock broker transactions [19]. They argue that these processes also follow

power-law distributions and are consequences of similar priority queuing processes. Our analysis

demonstrates that care must be taken when describing data with fat-tails, particularly when the

apparent scaling exponent is close to one and the probability distribution is concave.

APPENDIX A: MAXIMUM LIKELIHOOD ESTIMATION

j given

M

(A1)

In maximum likelihood estimation, the likelihood function

for distribution model

L

uw,i

{

}

L

the data

uw,i
{

}

is

(
M

j

L

| {

}

uw,i

) =

p (uw,k

j) ,

|M

N

Yk=1

where N is the number of data points in the sample, the

are the empirical data points

and p(uw

j) is the probability density function for the candidate model

j evaluated at each

|M

M

empirical data point. We then maximize the likelihood

to ﬁnd the parametrization of the

model distribution p(uw

j) that best approximates the data. For the double log-normal model,

p(uw

double log-normal) = p(uw; f, µ1, σ1, µ2, σ2). To ﬁnd the best estimate of the ﬁve pa-

f, µ1, σ1, µ2, σ2

, we obtain preliminary estimates for µ1 and σ1 from the mean and

double log-normal parameters. In practice, however, one typically performs a minimization of

and subsequently maximize likelihood

to ﬁnd the appropriate

L

|
rameters

{
standard deviation of

|M

}
uw,i

{

}

16

=

ln

−

L

H

[17, 24].

[1] M. H. R. Stanley, L. A. N. Amaral, S. V. Buldyrev, S. Havlin, H. Leschhorn, P. Maass, M. A. Salinger,

and H. E. Stanley, Nature 379, 804 (1996).

[2] L. A. N. Amaral, S. Buldyrev, S. Havlin, H. Leschorn, P. Maass, M. Salinger, and H. E. Stanley, J.

[3] L. A. N. Amaral, S. V. Buldyrev, S. Havlin, M. A. Salinger, and H. E. Stanley, Phys. Rev. Lett. 80,

Phys. I France 7, 635 (1997).

1385 (1998).

[4] V. Plerou, L. A. N. Amaral, P. Gopikrishnan, M. Meyer, and H. E. Stanley, Nature 400, 433 (1999).

[5] L. A. N. Amaral, P. Gopikrishnan, V. Plerou, K. Matia, and H. E. Stanley, Scientometrics 51, 9 (2001).

[6] R. Guimer`a, A. Arenas, A. D´ıaz-Guilera, and F. Giralt, Phys. Rev. E 66, 026704 (2002).

[7] A. Smith, An inquiry into the nature and causes of the wealth of nations (Methuen & Co., London,

1786).

(2003).

[8] V. Pareto, Manuale di economia politica (Milano, Societa Editrice, 1906).

[9] G. K. Zipf, Human behavior and the principle of least effort: an introduction to human ecology

(Addison-Wesley Press, Cambridge, MA, 1949).

[10] H. Ebel, L.-I. Mielsch, and S. Bornholdt, Phys. Rev. E 66, 035103 (2002).

[11] R. Guimer`a, L. Danon, A. D´ıaz-Guilera, F. Giralt, and A. Arenas, Phys. Rev. E 68, art. no. 065103

[12] J.-P. Eckmann, E. Moses, and D. Sergi, Proc. Natl. Acad. Sci. USA 101, 14333 (2004).

[13] A.-L. Barab´asi, Nature 435, 207 (2005).

[14] G. Kossinets and D. Watts, Science 311, 88 (2006).

[15] A. Berson, Client/server architecture (McGraw-Hill, New York, NY, 1992).

[16] SkillCrest, VistaMetrix (2004), http://www.skillcrest.com/.

[17] A. M. Mood, F. A. Graybill, and D. C. Boes, Introduction to the Theory of Statistics (McGraw-Hill

Companies, 1974).

[18] J. M. Bernardo and A. F. M. Smith, Bayesian Theory (John Wiley & Sons, 2000).

[19] A. V´azquez, J. G. Oliveira, Z. Dezs˜o, K.-I. Goh, I. Kondor, and A.-L. Barab´asi, arXiv:physics/050117

17

(2005).

[20] A.-L. Barab´asi, K.-I. Goh, and A. Vazquez, Reply to Comment on ”The origin of bursts and heavy

tails in human dynamics”.

[21] A. V´azquez, Phys. Rev. Lett. 95, 248701 (2005).

[22] G. A. Miller, Psych. Rev. 63, 81 (1956).

[23] J. ao Gama Oliveira and A.-L. Barab´asi, Nature 437, 1251 (2005).

[24] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery, Numerical Recipes in C: The Art of

Scientiﬁc Computing (Cambridge University Press, New York, 2002), 2nd ed.

18

