Document version 1.0
TMVA version 3.6.0
May 15, 2011
http:// tmva.sf.net

7
0
0
2
 
r
a

M
 
4
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
9
3
0
3
0
7
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

TMVA
Toolkit for Multivariate Data Analysis with ROOT

Users Guide

A. H ¨ocker, J. Stelzer, F. Tegenfeldt, H. Voss, K. Voss

With contributions from

A. Christov, S. Henrot-Versill ´e, M. Jachowski, A. Krasznahorkay Jr.,
Y. Mahalalel, X. Prudent, P. Speckmayer

Abstract

Multivariate machine learning techniques for the classiﬁcation of data from high-energy physics
experiments have become a fundamental ingredient to most analyses. The multivariate classiﬁers
themselves have signiﬁcantly evolved in recent years, also driven by developments in other areas
inside and outside science. TMVA is a ROOT-integrated toolkit, which hosts a large variety of
multivariate classiﬁcation algorithms ranging from rectangular cut optimisation (using a genetic
algorithm) and likelihood estimators, over linear and non-linear discriminants (neural networks),
to sophisticated recent developments like boosted decision trees and rule ensemble ﬁtting. TMVA
allows the simultaneous training, testing and performance evaluation of all these classiﬁers with
user-friendly interfaces.

Copyright c
(cid:13)

TMVA 3.6 – Toolkit for Multivariate Data Analysis with ROOT
2005-2007, Regents of CERN (Switzerland), University of Victoria (Canada),

MIP-Kernphysik Heidelberg (Germany), and LAPP (France).
BSD license: http://tmva.sf.net/LICENSE.

Authors:
Andreas H ¨ocker (CERN, Switzerland),
J ¨org Stelzer (CERN, Switzerland)

,
andreas.hoecker@cern.ch
h
i
,
joerg.stelzer@cern.ch
i
h
Fredrik Tegenfeldt (Iowa University, USA)

Helge Voss (MPI f ¨ur Kernphysik Heidelberg, Germany)

Kai Voss (University of Victoria, Canada)

Asen Christov (Universit ¨at Freiburg, Germany)

Sophie Henrot-Versill ´e (LAL Orsay, Francs)
Matthew Jachowski (Stanford University, USA)
Yair Mahalalel (Tel Aviv University, Israel)
Xavier Prudent (LAPP Annecy, Franec)
Peter Speckmayer (CERN, Switzerland)

fredrik.tegenfeldt@cern.ch
i
h

,

,
helge.voss@cern.ch
i
h

,
kai.voss@cern.ch
i
h

,
christov@physik.uni-freiburg.de
i
h

,

i

versille@lal.in2p3.fr
h
,
jachowski@stanford.edu
h
i
,
yair@mahalalel.com
i
h
,
prudent@lapp.in2p3.fr
i
h
,
speckmay@mail.cern.ch
i
h

and valuable contributions from other developers, please see acknowledgments.

CONTENTS

Contents

1 Introduction

2 TMVA Quick Start

Copyrights and credits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.1 How to download and build TMVA . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Version compatibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3 The TMVA namespace . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4 Example jobs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.5 Running the example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.5.1 Displaying the results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 Using TMVA

3.1 The Factory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.1 Specifying training and testing data . . . . . . . . . . . . . . . . . . . . . . .
3.1.2 Selecting variables and variable transformations . . . . . . . . . . . . . . .
3.1.3 Preparation of training and testing data . . . . . . . . . . . . . . . . . . . .
3.1.4 Booking the classiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.5 Training the classiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.6 Testing the classiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.7 Evaluating the classiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.8 Overtraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 ROOT macros for plotting training, testing and evaluation results . . . . . . . . . .
3.3 The Reader . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.1 Specifying input variables . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.2 Booking selected classiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.3 Requesting the classiﬁer output . . . . . . . . . . . . . . . . . . . . . . . . .
3.4 Which classiﬁer should I use for my problem? . . . . . . . . . . . . . . . . . . . . .

4 Data Preprocessing

4.1 Transforming input variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.1.1 Variable decorrelation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.1.2 Principal component decomposition . . . . . . . . . . . . . . . . . . . . . .
4.2 Binary Search Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5 The TMVA Classiﬁers

5.1 Rectangular cut optimisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.1 Booking options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.2 Description of the classiﬁer and its implementation . . . . . . . . . . . . . .
5.1.3 Ranking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.4 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .
5.2.1 Booking options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.2.2 Description of the classiﬁer and its implementation . . . . . . . . . . . . . .
5.2.3 Ranking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.2 Projective likelihood estimator (PDE approach)

i

1
2

3
3
4
4
4
4
5

7
9
9
12
13
14
14
15
16
17
17
18
18
20
20
21

22
22
22
23
24

25
26
26
27
31
31
31
31
32
36

CONTENTS

5.3 Multidimensional likelihood estimator (PDE range-search approach)

5.2.4 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . .
5.3.1 Booking options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3.2 Description of the classiﬁer and its implementation . . . . . . . . . . . . . .
5.3.3 Ranking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3.4 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.4 H-Matrix (χ2) estimator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.4.1 Booking options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.4.2 Description of the classiﬁer and its implementation . . . . . . . . . . . . . .
5.4.3 Ranking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.4.4 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.5 Fisher discriminants (linear discriminant analysis) . . . . . . . . . . . . . . . . . . .
5.5.1 Booking options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.5.2 Description of the classiﬁer and its implementation . . . . . . . . . . . . . .
5.5.3 Ranking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.5.4 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . .
5.6.1 Booking options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.6.2 Description of the classiﬁers and their implementation . . . . . . . . . . . .
5.6.3 Network architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.6.4 Ranking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.6.5 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.7 Boosted Decision Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.7.1 Booking options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.7.2 Description of the classiﬁer and its implementation . . . . . . . . . . . . . .
5.7.3 Ranking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.7.4 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.8 Predictive learning via rule ensembles . . . . . . . . . . . . . . . . . . . . . . . . .
5.8.1 Booking options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.8.2 Description of the classiﬁer and its implementation . . . . . . . . . . . . . .
5.8.3 Ranking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.8.4 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.6 Artiﬁcial Neural Networks (non-linear discriminants)

6 Summary and Plans

Acknowledgments

A Classiﬁer booking

Bibliography

Index

ii

36
37
37
37
40
41
41
41
41
42
42
42
42
43
44
44
44
45
46
48
50
50
50
50
52
56
56
57
57
57
61
62

63

65

65

67

68

1

1 Introduction

The Toolkit for Multivariate Analysis (TMVA) provides a ROOT-integrated environment
for the processing and parallel evaluation of sophisticated multivariate classiﬁcation tech-
niques.1 TMVA is speciﬁcally designed to the needs of high-energy physics (HEP) appli-
cations,2 but should not be restricted to these. The package includes:

Rectangular cut optimisation (binary splits, Sec. 5.1)

Projective likelihood estimator (Sec. 5.2)

Multi-dimensional likelihood estimator (PDE range-search approach, Sec. 5.3)

Linear discriminant analysis (H-Matrix and Fisher discriminants, Secs. 5.4, 5.5)

Artiﬁcial neural networks (three diﬀerent implementations, Sec. 5.6)

Boosted/bagged decision trees (Sec. 5.7)

Predictive learning via rule ensembles (RuleFit, Sec. 5.8)

•

•

•

•

•

•

•

The software package consists of object-oriented implementations in C++/ROOT for each
of these discrimination techniques and provides training, testing and performance evalua-
tion algorithms and visualization scripts. Detailed descriptions of all the TMVA classiﬁers
and their options are given in Sec. 5. Their training and testing is performed with the
use of user-supplied data sets in form of ROOT trees or text ﬁles, where each event can
have an individual weight. The sample composition (event classiﬁcation) in these data
sets must be known. Preselection requirements and transformations can be applied on
this data. TMVA supports the use of variable combinations and formulas, just as they are
available for the Draw command of a ROOT tree.

TMVA works in transparent factory mode to guarantee an unbiased performance com-
parison between the classiﬁers: all classiﬁers see the same training and test data, and
are evaluated following the same prescriptions within the same execution job. A Fac-
tory class organises the interaction between the user and the TMVA analysis steps. It
performs preanalysis and preprocessing of the training data to assess basic properties of
the discriminating variables used as input to the classiﬁers. The linear correlation coef-
ﬁcients of the input variables are calculated and displayed, and a preliminary ranking is
derived (which is later superseded by classiﬁer-speciﬁc variable rankings). The variables
can be linearly transformed (individually for each classiﬁer) into a non-correlated variable

1A classiﬁcation problem corresponds in more general terms to a discretised regression problem. A
regression is the process that estimates the parameter values of a function, which predicts the value of a
response variable in terms of the values of other variables (the input variables).

2TMVA discriminates signal from background in data sets with unknown composition of these two
samples. In frequent use cases the background (sometimes also the signal) consists of a variety of diﬀerent
populations with characteristic properties, which could call for classiﬁers with more than two discrimination
classes. However, in practice it is usually possible to serialize background ﬁghting by training individual
classiﬁers for each background source, and applying consecutive requirements to these.

2

space or projected upon their principle components. To compare the signal-eﬃciency and
background-rejection performance of the classiﬁers, the analysis job prints tabulated re-
sults for some benchmark values (see Sec. 3.1.7), besides other criteria such as a measure
of the separation and the maximum signal signiﬁcance. Smooth eﬃciency versus back-
ground rejection curves are stored in a ROOT output ﬁle, together with other graphical
evaluation information. These results can be displayed using ROOT macros, which are
conveniently executed via a graphical user interface that comes with the TMVA distri-
bution (see Sec. 3.2). The TMVA training job runs alternatively as a ROOT script, as
a standalone executable, where libTMVA.so is linked as a shared library, or as a python
script via the PyROOT interface. Each classiﬁer trained in one of these applications writes
its conﬁguration and training results in result (“weight”) ﬁles, which consists of one text
and one ROOT ﬁle.

A light-weight Reader class is provided, which reads and interprets the weight ﬁles (inter-
faced by the corresponding classiﬁers), and which can be included in any C++ executable,
ROOT macro or python analysis job.

We have put emphasis on the clarity and functionality of the Factory and Reader inter-
faces to the user applications. All classiﬁers run with reasonable default conﬁgurations,
so that for standard applications that do not require particular tuning, the user script for
a full TMVA analysis will hardly exceed a few lines of code. For individual optimisation
the user can (and should) customize the classiﬁers via conﬁguration strings.

This manual introduces the TMVA training Factory and Reader interfaces, and describes
design and implementation of the various multivariate classiﬁers. It is not the goal here
to provide a general introduction to multivariate analysis techniques. Other excellent re-
views exist on this subject (see, e.g., Refs. [1, 2, 3]). The document begins with a quick
TMVA start reference in Sec. 2, and provides a more complete introduction to the TMVA
design and its functionality in Sec. 3. Common tools used by several classiﬁers such as
the transformation of input variables are discussed in Sec. 4. All the TMVA classiﬁers
including their conﬁgurations and tuning options are described in Secs. 5.1-5.8.

Copyrights and credits

TMVA is an open source product. Redistribution and use of TMVA in source and binary
forms, with or without modiﬁcation, are permitted according to the terms listed in the
BSD license.3

Several similar combined multivariate classiﬁcation (“data mining”) eﬀorts exist with ris-
ing importance in most ﬁelds of science and industry. In the HEP community the package
StatPatternRecognition [4] is in use. Other codes exist, which however often treat only
a subset of the most common MVAs [5]. The idea of parallel training and evaluation of
MVA-based classiﬁcation in HEP has been pioneered by the Cornelius package, developed
by the Tagging Group of the BABAR Collaboration [6].

3For the BSD license, see http://tmva.sf.net/LICENSE.

3

2 TMVA Quick Start

To run TMVA it is not necessary to know much about its concepts or to understand the
detailed functionality of the multivariate classiﬁers. Better, just begin with the quick start
tutorial given below. One should note that the TMVA version obtained from the open
source software platform Sourceforge.net (where TMVA is developed), and the one which
is part of ROOT have a diﬀerent directory structure for the example macros used for the
tutorial. Wherever diﬀerences in command lines occur, they are given for both versions.

2.1 How to download and build TMVA

TMVA is maintained at Sourceforge.net (http://tmva.sf.net). The TMVA project is built
upon ROOT (http://root.cern.ch/), so that for TMVA to run ROOT must be installed.
Since ROOT version 5.11/06, TMVA comes as integral part of ROOT and can be used
from the ROOT prompt without further preparation. For older ROOT versions or if
the latest TMVA features are desired, the TMVA source code can be downloaded from
Sourceforge.net. Since we do not provide prebuilt libraries for any platform, the library
must be built by the user (see below). The source code can be either downloaded as a
gzipped tar ﬁle or via CVS anonymous access

~> cvs -z3 -d:pserver:anonymous@tmva.cvs.sourceforge.net:/cvsroot/tmva \

co -r V03-04-00 -P TMVA

Code Example 1: TMVA source code download via CVS. The latest code (CVS HEAD) can be downloaded
by typing the same command without specifying a version: cvs -d...

-z3 co -P TMVA.

While the source code is known to compile with VisualC++ on Windows (which is a
requirement for ROOT), we do not provide project support for this platform yet. For Unix
and most Linux ﬂavours custom Makeﬁles are provided with the TMVA distribution, so
that the library can be built by typing

~> cd TMVA
~/TMVA> source setup.sh # for c-shell family: source setup.csh
~/TMVA> cd src
~/TMVA/src> make

Code Example 2: Building the TMVA library under Linux/Unix using the provided Makeﬁle. The setup.
[c]sh script must be executed to ensure the correct setting of symbolic links and library paths required
by TMVA.

After compilation, the library ∼/TMVA/lib/libTMVA.so should be present.

2.2 Version compatibility

4

2.2 Version compatibility

TMVA can be run with any ROOT version above v4.02. The few occurring conﬂicts due to
ROOT source code evolution after v4.02 are intercepted in TMVA via C++ preprocessor
conditions.

2.3 The TMVA namespace

All TMVA classes are embedded in the namespace TMVA. For interactive access, or use in
macros the classes must thus be preceded by TMVA::, or one may use the command using
namespace TMVA instead.

2.4 Example jobs

TMVA comes with example jobs for the training phase (this phase actually includes train-
ing, testing and evaluation) using the TMVA Factory, as well as the application of the
training results in a classiﬁcation analysis using the TMVA Reader. The ﬁrst task is per-
formed in the program TMVAnalysis, and the second in TMVApplication.

In the ROOT version of TMVA, the macros TMVAnalysis.C and TMVApplication.C are
located in the directory $ROOTSYS/tmva/test/.

In the Sourceforge.net version, the macros TMVAnalysis.C and TMVApplication.C are
located in ∼/TMVA/macros. At Sourceforge.net we also provide these examples in form
of the C++ executables TMVAnalysis.cxx and TMVApplication.cxx, which are located
in ∼/TMVA/examples. To create the executables, type cd ∼/TMVA/example; make, and
then simply execute them by typing ./TMVAnalysis and ./TMVApplication. To illus-
trate how TMVA can be used in a python script via PyROOT we also provide the script
TMVAnalysis.py located in ∼/TMVA/python, which again has the same functionality as
the macro TMVAnalysis.C.

2.5 Running the example

The easiest way to get started with TMVA is to run the TMVAnalysis.C example macro. It
uses an academic toy data set for training and testing, which consists of four linearly cor-
related, Gaussian distributed discriminating input variables, with diﬀerent sample means
for signal and background. All classiﬁers are trained, tested and evaluated using the toy
dataset in the same way the user is expected to proceed for his or her own data. It is a
valuable exercise to look at the example ﬁle in more detail. Most of the command lines
therein should be self explaining, and one will easily ﬁnd how they need to be customized
to run TMVA on a real use case. A detailed description is given in Sec. 3.

The toy data set used by the example is included in the Sourceforge.net download. For
the ROOT distribution, the example macro TMVAnalysis.C automatically fetches the data
ﬁle from the web using the corresponding TFile constructor TFile::Open("http://root.
cern.ch/files/tmva example.root"). The example ROOT macro can be run from any

2.5 Running the example

5

designated test directory ∼/workdir, after adding the macro directory to ROOT’s macro
search path:

~/workdir> echo "Unix.*.Root.MacroPath: ~/TMVA/macros" >> .rootrc
~/workdir> root -l ~/TMVA/macros/TMVAnalysis.C

Code Example 3: Running the example TMVAnalysis.C using the Sourceforge.net version of TMVA.

~/workdir> echo "Unix.*.Root.MacroPath: $ROOTSYS/tmva/test" >> .rootrc
~/workdir> root -l $ROOTSYS/tmva/test/TMVAnalysis.C

Code Example 4: Running the example TMVAnalysis.C using the ROOT version of TMVA.

The training job provides formatted output logging containing analysis information such
as: signal and background linear correlation matrices for the input variables, variable
ranking, summaries of the classiﬁer conﬁgurations, goodness-of-ﬁt evaluation for PDFs
(if requested), signal and background correlations between the various classiﬁers, their
signal/background-likeness decision overlap, signal eﬃciencies at benchmark background
rejection rates as well as other performance estimators, and overtraining validation output.

2.5.1 Displaying the results

Besides so-called “weight” ﬁles containing the classiﬁer-speciﬁc training results, TMVA
also provides a variety of control and performance plots that can be displayed via a set
of ROOT macros available in ∼/TMVA/macros/ or $ROOTSYS/tmva/test/ for the Source-
forge.net and ROOT distributions of TMVA, respectively. The macros are summarized
in Table 1. At the end of the example job a graphical user interface (GUI) is displayed,
which conveniently allows to run these macros (see Fig. 1).

Examples for plots produced by these macros are given in Figs. 3-5. The distributions of
the input variables for signal and background according to our example job are shown in
Fig. 2. It is useful to quantify the correlations between the input variables. These are
drawn in form of a scatter plot with the superimposed proﬁle for two of the input variables
in Fig. 3 (upper left). As will be discussed in Sec. 4, TMVA allows to perform a linear
decorrelation transformation of the input variables prior to the classiﬁer training. The
result of such decorrelation is shown at the upper right hand plot of Fig. 3. The lower
plots display the linear correlation coeﬃcients between all input variables, for the signal
and background training samples.

Figure 4 shows some of the classiﬁer output distributions for signal and background events
from the test sample. By TMVA convention, signal (background) events accumulate at
large (small) classiﬁer output values. Hence, cutting on the output and retaining the

2.5 Running the example

6

Figure 1: Graphical user interface (GUI) to execute macros displaying training, test and evaluation results
(see Table 1). The GUI can be launched manually by executing the scripts ∼/TMVA/macros/TMVAGui.
C (Sourceforge.net version) or $ROOTSYS/tmva/test/TMVAGui.C (ROOT version).
In short, the buttons
behave as follows: (1a) plots the signal and background distributions of the input variables (training
sample), (1b) the same after decorrelation transformation, (1c) the same after PCA decorrelation (these
latter two buttons only display results if the corresponding transformations have been requested by at least
one classiﬁer), (2a–c) scatters (with superimposed proﬁles) of all pairs of input variables for signal and
background for the three transformation types (training sample), (3) linear correlation coeﬃcients between
the input variables for signal and background (training sample), (4a) signal and background distributions
for the trained classiﬁers (test sample), (4b) the corresponding probability distributions, (5a) signal and
background eﬃciencies (and purities assuming an equal number of signal and background events) as a
function of the cut on the classiﬁer outputs, (5b) background rejection versus signal eﬃciency obtained
when cutting on the classiﬁer outputs (ROC curve, from the test sample). The following buttons launch
classiﬁer-speciﬁc macros: (6) reference distributions (PDFs) used for the likelihood classiﬁer compared
to the training data, (7a) architecture of the MLP neural network, (7b) convergence of the MLP error
parameter for the training and test samples (check for overtraining), (8) plots a sketch of the ﬁrst decision
tree in the forest, (9) compares the classiﬁer PDFs to the training data, (10) plots the importance for the
RuleFit classiﬁer, and (11) quits the GUI. Titles in brackets indicate actions that can only be taken if the
corresponding transformations or classiﬁers have been applied/used during the training.

events with yMVA larger than the cut requirement selects signal samples with eﬃciencies
and purities that respectively decrease and increase with the cut value. The resulting
relations between background rejection versus signal eﬃciency are shown in Fig. 5 for all
classiﬁers that were used in the example macro. This plot belongs to the class of Receiver
Operating Characteristic diagrams, which in its standard form shows the true positive rate
versus the false positive rate for the diﬀerent possible cutpoints of a hypothesis test.

More analysis plots are available, in particular those that validate speciﬁc classiﬁers. For
example, the macro likelihoodrefs.C compares the probability density functions used
by the likelihood classiﬁer to the normalised variable distributions of the training sample.
It is also possible to visualize the MLP neural network architecture and to draw decision

TMVA Input Variables: var1+var2

TMVA Input Variables: var1-var2

Signal

Background

7

0
0

-6
-6

-4
-4

-2
-2

0
0

2
2

4
4

6
6

-4
-4

-3
-3

-2
-2

-1
-1

0
0

1
1

2
2

3
3

var1+var2
var1+var2

var1-var2
var1-var2

TMVA Input Variables: var3

TMVA Input Variables: var4

s
s
t
t
n
n
e
e
v
v
E
E

250
250

200
200

150
150

100
100

50
50

0
0

s
s
t
t
n
n
e
e
v
v
E
E

350
350

300
300

250
250

200
200

150
150

100
100

50
50

0
0

350
350

300
300

s
s
t
t
n
n
e
e
v
v
E
E

250
250

200
200

150
150

100
100

50
50

350
350

300
300

s
s
t
t
n
n
e
e
v
v
E
E

250
250

200
200

150
150

100
100

50
50

0
0

-4
-4

-3
-3

-2
-2

-1
-1

0
0

1
1

2
2

3
3

4
4

-4
-4

-3
-3

-2
-2

-1
-1

0
0

1
1

2
2

3
3

4
4

var3
var3

var4
var4

Figure 2: Example plots for input variable distributions.

trees (see Table 1 for a complete summary of the available scripts).

3 Using TMVA

A typical TMVA analysis consists of two independent phases: the training phase, where
the multivariate classiﬁers are trained, tested and evaluated, and an application phase,
where selected classiﬁers are applied to the concrete classiﬁcation problem they have been
trained for. An overview of the code ﬂow for these two phases as implemented in the
examples TMVAnalysis.C and TMVApplication.C (see Sec. 2.4), is sketched in Fig. 6.

In the training phase, the communication of the user with the data sets and the classiﬁers
is performed via a Factory object, created at the beginning of the program. The TMVA
Factory provides member functions to specify the training and testing data sets, to register
the discriminating input variables, and to book the multivariate classiﬁers. After the
conﬁguration the Factory calls for training, testing and the evaluation of the booked
classiﬁers. Classiﬁer-speciﬁc result (“weight”) ﬁles are created after the training phase.

8

100

80

60

40

20

0

-20

-40

-60

-80

-100

4
4
r
r
a
a
v
v

4
4

3
3

2
2

1
1

0
0

-1
-1

-2
-2

-3
-3

-4
-4

100

80

60

40

20

0

-20

-40

-60

-80

-100

var4 versus var3 (background)_NoTransform

var4 versus var3 (background)_DecorrTransform

4
4
r
r
a
a
v
v

4
4

3
3

2
2

1
1

0
0

-1
-1

-2
-2

-3
-3

-4
-4

-4
-4

-3
-3

-2
-2

-1
-1

0
0

1
1

2
2

3
3

4
4

-4
-4

-3
-3

-2
-2

-1
-1

0
0

1
1

2
2

3
3

var3
var3

var3
var3

Correlation Matrix (signal)

Correlation Matrix (background)

linear correlation coefficients in %

linear correlation coefficients in %

var4
var4

67

-20

90

100

var4
var4

71

-19

90

100

var3
var3

60

-20

100

90

var3
var3

64

-18

100

90

var1-var2
var1-var2

-1

100

-20

-20

var1-var2
var1-var2

0

100

-18

-19

var1+var2
var1+var2

100

-1

60

67

var1+var2
var1+var2

100

0

64

71

var1+var2
var1+var2

var1-var2
var1-var2

var3
var3

var4
var4

var1+var2
var1+var2

var1-var2
var1-var2

var3
var3

var4
var4

Figure 3: Correlation between input variables. Upper left: correlations between var3 and var4 for the
background training sample. Upper right: the same after applying a decorrelation transformation (see
Sec. 4.1.1). Lower plots: linear correlation coeﬃcients for the signal and background training samples.

The application of training results to a data set with unknown sample composition is
governed by the Reader object. During initialization, the user registers the input variables4
together with their local memory addresses, and books the classiﬁers that were found to
be the most appropriate ones during the training phase. As booking argument, the bulk
name of the weight ﬁle is given, which provides for each of the classiﬁers full and consistent
conﬁguration according to the training results. Within the event loop, the input variables
are updated for each event, and the selected classiﬁer outputs are computed.

4This somewhat redundant operation is required to verify the correspondence between the Reader

analysis and the weight ﬁles used.

d
d
e
e
z
z
i
i
l
l
a
a
m
m
r
r
o
o
N
N

d
d
e
e
z
z
i
i
l
l
a
a
m
m
r
r
o
o
N
N

3.5
3.5

2.5
2.5

4
4

3
3

2
2

1.5
1.5

0.5
0.5

1
1

0
0

3.5
3.5

2.5
2.5

4
4

3
3

2
2

1.5
1.5

1
1

0.5
0.5

d
d
e
e
z
z
i
i
l
l
a
a
m
m
r
r
o
o
N
N

d
d
e
e
z
z
i
i
l
l
a
a
m
m
r
r
o
o
N
N

30
30

25
25

20
20

15
15

10
10

5
5

0
0

0
0

3.5
3.5

2.5
2.5

3
3

2
2

1
1

0
0

1.5
1.5

0.5
0.5

3.1 The Factory

9

MVA output for method: Likelihood

MVA output for method: PDERS

Signal
Background

Signal
Background

0.2
0.2

0.4
0.4

0.6
0.6

0.8
0.8

1
1

0.1
0.1

0.2
0.2

0.3
0.3

0.4
0.4

0.5
0.5

0.6
0.6

0.7
0.7

0.8
0.8

0.9
0.9

1
1

Likelihood
Likelihood

PDERS
PDERS

MVA output for method: MLP

MVA output for method: BDT

Signal
Background

Signal
Background

0
0

0.2
0.2

0.4
0.4

0.6
0.6

0.8
0.8

1
1

-0.6
-0.6

-0.4
-0.4

-0.2
-0.2

-0
-0

0.2
0.2

0.4
0.4

0.6
0.6

0
0
-0.8
-0.8

MLP
MLP

BDT
BDT

Figure 4: Example plots for classiﬁer output distributions for signal and background events from the
academic test sample. Shown are likelihood (upper left), PDE range search (upper right), MLP (lower
left) and boosted decision trees.

3.1 The Factory

The TMVA training phase begins by instantiating a Factory object

TMVA::Factory* factory

= new TMVA::Factory( "<JobName>", targetFile, "<options>" );

Code Example 5: Instantiating a Factory class object. The ﬁrst argument is the user-deﬁned job name
which will also appear in the name of the weight ﬁles containing the training results. The second argument
is the pointer to a writable TFile target ﬁle created by the user, where control and performance histograms
are stored. Currently the only option that can be speciﬁed for the Factory is “V” for verbose print out.

3.1.1 Specifying training and testing data

The input data sets used for training and testing of the multivariate classiﬁers need to
be handed to the Factory. TMVA supports ROOT TTree and derived TChain objects

3.1 The Factory

10

Background rejection versus Signal efficiency

n
n
o
o
i
i
t
t
c
c
e
e
j
j
e
e
r
r
 
 
d
d
n
n
u
u
o
o
r
r
g
g
k
k
c
c
a
a
B
B

1
1

0.95
0.95

0.9
0.9

0.85
0.85

0.8
0.8

0.75
0.75

0.7
0.7

0.65
0.65

0.6
0.6

0.55
0.55

MVA Method:
Fisher
MLP
LikelihoodD
PDERS
Cuts
RuleFit
HMatrix
BDT
Likelihood

0.5
0.5

0
0

0.1
0.1

0.2
0.2

0.3
0.3

0.4
0.4

0.5
0.5

0.6
0.6

0.7
0.7

0.8
0.8

1
1
Signal efficiency
Signal efficiency

0.9
0.9

Figure 5: Example for the background rejection versus signal eﬃciency obtained for the various classiﬁers
after evaluating the test sample.

as well as text ﬁles. If ROOT trees are used, the signal and background events can be
located in the same or in diﬀerent trees. Overall weights can be speciﬁed for the signal and
background training data (the treatment of event-by-event weights is discussed below).

Specifying training data in ROOT tree format with signal and background events being
located in diﬀerent trees:

TTree* sigTree = (TTree*)sigSource->Get( "<YourSignalTreeName>" );
TTree* bkgTree = (TTree*)bkgSource->Get( "<YourBackgrTreeName>" );

Double_t sigWeight = 1.0; // overall weight for all signal events
Double_t bkgWeight = 1.0; // overall weight for all background events

factory->SetInputTrees( sigTree, bkgTree, sigWeight, bkgWeight );

Code Example 6: Registration of signal and background ROOT trees read from TFile sources. Overall
signal and background weights can also be speciﬁed. The TTree object may be replaced by a TChain.

Specifying training data in ROOT tree format with signal and background events being
located in the same tree:

3.1 The Factory

11

Figure 6: Left: sequence ﬂow (top to bottom) of a typical TMVA training application. The user script can
be a ROOT macro, C++ executable, python script or similar. The user creates a target ROOT TFile,
which is used by the TMVA Factory object to write histograms and trees. The Factory, after creation by
the user, organises the user’s interaction with the TMVA modules. It is the only object directly created
by the user. First the discriminating variables that must be TFormula-compliant functions of branches
in the signal and background training tree are registered. Then, selected classiﬁers are booked through a
type identiﬁer, and conﬁguration options are speciﬁed via an option string. The TMVA analysis proceeds
by consecutively calling the training, testing and performance evaluation methods of the Factory. The
training results for all classiﬁers used are written to custom weight ﬁles and the evaluation histograms are
stored in the target ﬁle. They can be analysed with speciﬁc macros that come with TMVA (cf. Table 1).
Right: sequence ﬂow (top to bottom) of a typical TMVA analysis application. The classiﬁers that have
been selected as appropriate in the preceding training and evaluation step are now used to classify data
of unknown signal and background composition. First, a Reader class object is created, which serves as
interface to the classiﬁers’ response, just as was the Factory for the training and performance evaluation.
The discriminating variables and references to locally declared memory placeholders are registered with
the Reader. The variable names must coincide with those used for the training. The appropriate classiﬁers
are booked through identiﬁcation with their weight ﬁle, which fully conﬁgures the classiﬁer. Only the bulk
part of the name (that is the ﬁle name without extension) is given. The Reader adds the appropriate ﬁle
extensions .txt and .root for the I/O operations. The user then runs the event loop, where for each event
the values of the input variables are copied to the reserved memory addresses, and the MVA response
values are computed. The user is responsible for the further use of the information.

3.1 The Factory

12

TTree* inputTree = (TTree*)source->Get( "<YourTreeName>" );

TCut signalCut = ...; // how to identify signal events in the TTree
TCut backgrCut = ...; // how to identify backgr. events in the TTree

factory->SetInputTrees( inputTree, signalCut, backgrCut );

Code Example 7: Registration of a single ROOT tree containing the input data for signal and background,
read from a TFile source. The TTree object may be replaced by a TChain. The cuts identify the event
species.

Specifying training data in text format:

var1/F:var2/F:var3/F:var4/F
0.21293 -0.49200 -0.58425 -0.70591
...

// Text file format (avaliable types: ’F’ and ’I’)
//
//
//
TString sigFile = "signal.txt";
TString bkgFile = "background.txt"; // text file for background

// text file for signal

Double_t sigWeight = 1.0; // overall weight for all signal events
Double_t bkgWeight = 1.0; // overall weight for all background events

factory->SetInputTrees( sigFile, bkgFile, sigWeight, bkgWeight );

Code Example 8: Registration of signal and background text ﬁles. Names and types of the input variables
are given in the ﬁrst line, followed by the values.

3.1.2 Selecting variables and variable transformations

The variables in input trees that are used to train the classiﬁers are registered with the
Factory using the AddVariable method. It takes the variable name (string) and optionally
its type (’F’ and ’I’ are supported), which can be particularly useful for discrete variables
(use ’I’). If no type is given, ’F’ is used. The name must have a correspondence in the
input ROOT tree or text ﬁle. It is also possible to specify variable expressions, just as for
the TTree::Draw command (the expression is interpreted as a TTreeFormula).5

5There are restrictions in the use of array index speciﬁcations (true vector types in general): expressions

like "var1[0]" are not permitted.

3.1 The Factory

13

’I’ );
factory->AddVariable( "<YourVar1>",
factory->AddVariable( "log(<YourVar2>)",
’F’ );
factory->AddVariable( "<YourVar3>+<YourVar4>", ’F’ );

Code Example 9: Declaration of variables used to train the classiﬁers. Each variable is speciﬁed by its
name in the training tree (or text ﬁle), and optionally a type (’F’ for ﬂoat and ’I’ for integer, ’F’ is
default). Here, YourVar1 has discrete values and is thus declared as an integer. Just as in the TTree::Draw
command, it is also possible to specify expressions of variables.

Individual events can be weighted, with the weights being a column or a function of
columns of the input data sets. To tell TMVA to use these weights in the classiﬁer
training use the following command:

factory->SetWeightExpression( "<YourWeightExpression>" );

Code Example 10: Speciﬁcation of individual weights applied to the training events. The expression must
be a function of variables present in the input data set.

i =
Some of the classiﬁers normalise the input variables so that min/max(xi) = 0/1,
1, . . . , nvar. These are: Fisher discriminant, H-Matrix, the Clermont-Ferrand and MLP
neural networks (customizable). In the present release of TMVA this option cannot be
customized (excepting the MLP where the option Normalize exists), so that the user must
be aware of it when interpreting the training results (weights).

∀

3.1.3 Preparation of training and testing data

The input events that are handed to the Factory are internally copied and split into
one training and one testing ROOT tree. This guarantees a statistically independent
evaluation of the classiﬁers based on the test sample.6 The numbers of events used in
both samples are speciﬁed by the user. They must not exceed the entries of the input
data sets. In case the user has provided a ROOT tree, the event copy is accelerated by
disabling all branches not used by the input variables.

It is possible to apply selection requirements (cuts) to the input events. These requirements
can depend on any variable present in the input data sets, i.e., they are not restricted to
the variables used by the classiﬁers. The full command is as follows:

6A fully unbiased training and evaluation requires at least three statistically independent data sets. See

comments in Footnote 9 on page 17.

3.1 The Factory

14

TCut preselectionCut = "<YourSelectionString>";

factory->PrepareTrainingAndTestTree( preselectionCut,

<NEventsTrain>, <NEventsTest> );

Code Example 11: Preparation of the internal training and testing trees. The signal and background events
are split into hNEventsTraini training events (equal number of both event species), and hNEventsTesti test
events (unequal numbers possible). All selected events satisfy the preselection criteria. If hNEventsTesti
is not speciﬁed, all remaining events are used after splitting oﬀ the training sample. For cases with
very low statistics, the user may force TMVA to reuse the training events for testing with the command
factory->PrepareTrainingAndTestTree(preselectionCut,-1).
In that case the evaluation may over-
state the performance (cf. Sec. 3.1.8).

3.1.4 Booking the classiﬁers

All classiﬁers are booked via the Factory by specifying the classiﬁer’s type, plus a unique
name given by the user, and a set of speciﬁc conﬁguration options encoded in a string
qualiﬁer.7
If the same type of classiﬁer is booked several times with diﬀerent options
(which is useful to optimise the conﬁguration of a classiﬁer), the speciﬁed names should
be diﬀerent, allowing to separate the instances and their weight ﬁles. A booking example
for the likelihood classiﬁer is given in Code Example 12 below. Detailed descriptions of
the conﬁguration options are given in Secs. 4 and 5, and the default booking commands
for all classiﬁers are given in Appendix A. With the classiﬁer booking the initialization of
the Factory is complete and no classiﬁer-speciﬁc actions are left to do. The Factory takes
care of the subsequent training, testing and evaluation of the classiﬁers.

factory->BookMethod( TMVA::Types::kLikelihood, "LikelihoodD",

"!TransformOutput:Spline=2:NSmooth=5:Preprocess=Decorrelate" );

Code Example 12: Example booking of the likelihood classiﬁer. The ﬁrst argument is a unique type
enumerator (the avaliable types can be looked up in src/Types.h), the second is a user-deﬁned name
which must be unique among all booked classiﬁers, and the third a conﬁguration option string that is
speciﬁc to the classiﬁer. For options that are not set in the string default values are used. The syntax of
the options should become clear from the above example. Individual options are separated by a ’:’. Boolean
variables can be set either explicitly as MyBoolVar=True/False, or just via MyBoolVar/!MyBoolVar. All
speciﬁc options are explained in Secs. 4 and 5.

3.1.5 Training the classiﬁers

The training of the booked classiﬁers is invoked by the command

7In the TMVA package, a classiﬁer is termed Method. According to that terminology, the Factory has

a function BookMethod, and all methods are derived from the abstract classes IMethod and MethodBase.

3.1 The Factory

15

factory->TrainAllMethods();

Code Example 13: Executing the classiﬁer training via the Factory.

extension
h

The training results are stored in the weight ﬁles which are saved in the directory weights
(which, if not existing is created). The weight ﬁles are named Jobname ClassifierName.
weights.
, where the job name has been speciﬁed at the instantiation of the
i
Factory, and ClassifierName is the unique classiﬁer name speciﬁed in the booking com-
mand. Each classiﬁer writes two custom weight ﬁles, one in text format (extension is txt)
where the classiﬁer conﬁguration options, controls and training weights are stored, and
another in ROOT format (extension is root) containing TObject-derived objects (such as
reference histograms for the likelihood classiﬁer).

In addition to the classiﬁer’s output value yMVA, which is typically used to place a cut
for the classiﬁcation of an event as either signal or background, or which could be used
in a subsequent likelihood ﬁt, TMVA also provides signal and background PDFs, ˆyS(B).
The PDFs can be used to derive classiﬁcation probabilities for individual events. The
techniques used to estimate the shapes of the PDFs are those developed for the likelihood
classiﬁer (see Sec. 5.2.2 for details) and can be customized individually for each method
(the control options are given in Sec. 5). The probability for event i to be of signal type
is given by,

PMVA(i) =

ˆyS(i)

fS ·
ˆyS(i) + (1

,

fS)

ˆyB(i)

−

·

fS ·

(1)

where fS = NS/(NS + NB) is the expected signal fraction, and NS(B) are the expected
number of signal (background) events (default is fS = 0.5).8

3.1.6 Testing the classiﬁers

The trained classiﬁers are applied to the testing data and provide scalar outputs according
to which an event can be classiﬁed as either signal or background. The classiﬁer outputs
are stored in the test tree to which a column is added for each classiﬁer. The tree is
eventually written to the target ﬁle and can be directly analysed in a ROOT session. The
testing of all booked classiﬁers is invoked by the command

factory->TestAllMethods();

Code Example 14: Executing the validation (testing) of the MVA classiﬁers via the Factory.

8The PMVA distributions may exhibit a somewhat peculiar structure with frequent narrow peaks. They
are generated by regions of classiﬁer output values in which ˆyS ∝ ˆyB for which PMVA becomes a constant.

3.1 The Factory

16

3.1.7 Evaluating the classiﬁers

The Factory and data set classes of TMVA perform a preliminary assessment of the input
variables used by the classiﬁers, such as computing linear correlation coeﬃcients and rank-
ing the variables according to their separation (see bullet below). The results are printed to
standard output. After training and testing, also the linear correlation coeﬃcients among
the classiﬁer outputs are printed. Moreover, overlap matrices are derived (and printed)
for signal and background that determine the fractions of signal and background events
that are equally classiﬁed by each pair of classiﬁers. This is useful when two classiﬁers
have similar performance, but a signiﬁcant fraction of non-overlapping events.
In such
a case a combination of the classiﬁers (e.g., in a Committee classiﬁer) could improve the
performance (this can be extended to any combination of any number of classiﬁers).

The performance evaluation in terms of eﬃciency, background rejection, etc., of the trained
and tested classiﬁers is invoked by the command

factory->EvaluateAllMethods();

Code Example 15: Executing the performance evaluation via the Factory.

The optimal classiﬁer to be used for a speciﬁc analysis strongly depends on the problem
and no general recommendations can be given. To help with the choice TMVA computes
a number of benchmark quantities that assess the performance of the classiﬁers on the
independent test sample. These are

•

•

•

•

The signal eﬃciency at three representative background eﬃciencies (the eﬃciency is
rejection) obtained from a cut on the classiﬁer output. Also given is
equal to 1
the area of the background rejection versus signal eﬃciency function (the larger the
area the better the performance).

−

The separation of a classiﬁer y, deﬁned by the integral [6]

(ˆyS(y)

ˆyB(y))2
−
ˆyS(y) + ˆyB(y)

dy ,

1
2

Z

(2)

where ˆyS and ˆyB are the signal and background PDFs of y, respectively. The sep-
aration is zero for identical signal and background shapes, and it is one for shapes
with no overlap.

The discrimination signiﬁcance of a classiﬁer, deﬁned by the diﬀerence between the
classiﬁer means for signal and background divided by the quadratic sum of their
root-mean-squares.

yµ(ˆyS(y))dy of the signal µ-transform [7]. The µ-transform of a clas-
The average
siﬁer is the transformation that gives a uniform background distribution.
In this
way, the signal distribution of the µ-transform can be directly compared among the

R

3.2 ROOT macros for plotting training, testing and evaluation results

17

various classiﬁers. The stronger the peak towards one, the better is the discrimina-
tion. This quantity has been removed from the standard evaluation output written
by the Factory (for space reasons). It can be retrieved for each method through an
appropriate accessor.

The results of the evaluation are printed to standard output. In addition, smooth back-
ground rejection/eﬃciency versus signal eﬃciency curves (and the signal µ-transform) are
written to the target ROOT ﬁle, and can be plotted using custom macros (see Sec. 3.2).

3.1.8 Overtraining

Overtraining occurs when a data mining problem has too few degrees of freedom, be-
cause too many model parameters of a classiﬁer were adjusted to too few data points.
The sensitivity to overtraining therefore depends on the classiﬁer. For example, a Fisher
discriminant can hardly ever be overtrained, while, without the appropriate counter mea-
sures, boosted decision trees usually suﬀer from at least partial overtraining, owing to
their large number of nodes. Overtraining leads to a seeming increase in the classiﬁcation
performance over the objectively achievable one, if measured on the training sample, and
to an eﬀective performance decrease when measured with an independent test sample. A
convenient way to detect overtraining and to measure its impact is therefore to compare
the classiﬁcation results between training and test samples. Such a test is performed by
TMVA with the results printed to standard output.

Various classiﬁer-speciﬁc solutions to counteract overtraining exist. For example, binned
likelihood reference distributions are smoothed before estimating their shapes, or unbinned
kernel density estimators smear each training event before computing the PDF; neural net-
works steadily monitor the convergence of the error estimator between training and test
samples9 suspending the training when the test sample has passed its minimum; the num-
ber of nodes in boosted decision trees can be reduced by removing insigniﬁcant ones (“tree
pruning”), etc.

3.2 ROOT macros for plotting training, testing and evaluation results

TMVA provides a simple GUI (TMVAGui.C, see Fig. 1), which interfaces ROOT macros that
visualize the various steps of the training analysis. The macros are respectively located in
∼/TMVA/macros/ (Sourceforge.net distribution) and $ROOTSYS/tmva/test/ (ROOT distri-
bution), and can also be executed from the command line. They are described in Table 1.
All plots drawn are saved as png (or optionally eps, gif) ﬁles in the macro subdirectory
plots which, if not existing, is created.

The binning and histogram boundaries for some of the histograms created throughout the

9 Proper training and validation requires three statistically independent data sets: one for the parameter
optimisation, another one for the overtraining detection, and the last one for the performance validation.
In TMVA, the last two samples have been merged to increase statistics. The (usually insigniﬁcant) bias
introduced by this on the evaluation results does not aﬀect the analysis as far as cut eﬃciencies for the
classiﬁers are independently validated with data.

3.3 The Reader

18

training, testing and evaluation phases are controlled via the singleton class TMVA::Config.
They can be modiﬁed as follows:

// To modify settings for the variable plotting, one can use the
// struct TMVA::Config::VariablePlotting
TMVA::gConfig().variablePlotting.timesRMS = 4.0;
TMVA::gConfig().variablePlotting.nbins1D = 60;
TMVA::gConfig().variablePlotting.nbins2D = 300;

Code Example 16: Modifying global parameter settings for the plotting of the discriminating input vari-
ables. The values given are the TMVA defaults.

3.3 The Reader

After training and evaluation, the most performing classiﬁers are selected and used to clas-
sify events in data samples with unknown signal and background composition. An example
of how this application phase is carried out is given in ∼/TMVA/macros/TMVApplication.C
(Sourceforge.net) and $ROOTSYS/tmva/test/TMVApplication.C (ROOT). Analogously to
the Factory, the communication between the user application and the classiﬁers is inter-
faced by the TMVA Reader, which is created by the user:

TMVA::Reader* reader = new TMVA::Reader();

Code Example 17: Instantiating a Reader class object.

3.3.1 Specifying input variables

The user registers the names of the input variables with the Reader. They are required
to be the same (and in the same order) as the names used for training (this requirement
is not actually mandatory, but enforced to ensure the consistency between training and
application). Together with the name is given the address of a local variable, which carries
the updated input values during the event loop.

Float_t localVar1, localVar2, localVar3;

&localVar1 );
reader->AddVariable( "<YourVar1>",
reader->AddVariable( "log(<YourVar2>)",
&localVar2 );
reader->AddVariable( "<YourVar3>+<YourVar4>", &localVar3 );

Code Example 18: Declaration of the variables and references used as input to the classiﬁers. The order
and naming of the variables must be consistent with the ones used for the training. The local variables
are updated during the event loop, and through the references their values are known to the classiﬁers.

3.3 The Reader

19

Macro

Description

variables.C

correlationscatter.C

Plots the signal and background MVA input variables (train-
ing sample). The second argument sets the preprocessing type
(type=0, default, for no preprocessing, and type=1,2 for decor-
related and PCA-transformed variables, cf. Sec. 4.1).

Plots superimposed scatters and proﬁles for all pairs of input
variables used during the training phase (separate plots for signal
and background). As above, the second argument determines
whether the original (type=0, default) or preprocessed (type=
1,2) input variables are plotted.

Plots the linear correlation matrices for the signal and back-
ground training samples.

Plots the classiﬁer response distributions of the test sample for
signal and background. The second argument (HistType=1) al-
lows to plot the probability distributions of the classiﬁers for an
equal number of signal and background events (see Sec. 3.1.5).

Signal and background eﬃciencies, obtained from cutting on the
classiﬁer outputs, versus the cut value. Also shown are the signal
purity and the signal eﬃciency times signal purity assuming an
equal number of signal and background events before cutting.

Background rejection (second argument type=2, default), or
background eﬃciency (type=1), versus signal eﬃciency for the
classiﬁers (test sample). The eﬃciencies are obtained by cutting
on the classiﬁer outputs. This is traditionally the best plot to
assess the overall discrimination performance (ROC curve).

Plots the reference PDFs of all input variables for the likelihood
classiﬁer and compares it to original distributions obtained from
the training sample.

Draws the TMVA-MLP architecture including weights after
training (does not work for the other ANNs).

Plots the MLP error-function convergence versus the training
epoch for training and test events (does not work for the other
ANNs).

Draws the ith decision tree of the trained forest (default is i=1).
The second argument is the weight ﬁle that contains the full
architecture of the forest (default is weights/MVAnalysis BDT.
weights.txt).

Plots the classiﬁer PDFs used to compute the probability re-
sponse, and compares it to the original distributions.

correlations.C

mvas.C

mvaeffs.C

efficiencies.C

likelihoodrefs.C

network.C

annconvergencetest.C

BDT.C(i)

mvarefs.C

Table 1: List of available ROOT macros for the representation of the TMVA training and evaluation
results. All macros take as ﬁrst argument the name of the ROOT ﬁle containing the histograms (default
is TMVA.root). The lower macros concern speciﬁc classiﬁers, and require that these classiﬁers have been
included in the training.

3.3 The Reader

20

3.3.2 Booking selected classiﬁers

The classiﬁer(s) found to be most performing are booked with the Reader, using the weight
ﬁles from the preceeding training job:

reader->BookMVA( "<YourClassifierName>", "<TheWeightFile.weights>" );

Code Example 19: Booking a multivariate classiﬁer. The ﬁrst argument is a user deﬁned name to dis-
tinguish between classiﬁers (it does not need to be the same name as for training, although this could
be a useful choice). The true type of the classiﬁer and its full conﬁguration are read from the weight ﬁle
speciﬁed in the second argument.

3.3.3 Requesting the classiﬁer output

Within the event loop, the response value yMVA of a particular classiﬁer for a given set of
input variables (that are computed by the user) is obtained with the commands:

localVar1 = treeVar1;
localVar2 = TMath::Log(treeVar2);
localVar3 = treeVar3 + treeVar4;

Double_t mvaValue = reader->EvaluateMVA( "<YourClassifierName>" );

Code Example 20: Updating the local variables for an event, and obtaining the corresponding classiﬁer
output.

The classiﬁer output yMVA may then for example be cut on to increase the signal purity of
the sample (the achievable purities can be read oﬀ the evaluation results obtained during
the test phase), or it could enter a maximum-likelihood ﬁt, etc.

The rectangular cut classiﬁer is special since it returns a binary answer for a given set of
input variables and cuts. The user must specify the desired signal eﬃciency to deﬁne the
working point according to which the Reader will choose the cuts.

Bool_t passed = reader->EvaluateMVA( "Cuts", signalEfficiency );

Code Example 21: For the cut classiﬁer, the second parameter gives the desired signal eﬃciency according
to which the cuts are chosen. The return value is 1 for passed and 0 for retained.

Instead of the classiﬁer response values, one may also retrieve the ratio (1) from the Reader,
which, if properly normalised to the expected signal fraction in the sample, corresponds
to a probability. The corresponding command is

3.4 Which classiﬁer should I use for my problem?

CRITERIA

Cuts

Fisher ANN

BDT

Likeli-
hood

PDE-
RS

H-
Matrix

CLASSIFIERS

Perfor-
mance

Speed

None/linear
correlations
Nonlinear
correlations

Training
Response

Robust- Overtraining
ness

Weak variables

Curse of dimensionality

Transparency

⋆

◦

◦
⋆⋆

⋆⋆
⋆⋆

◦
⋆⋆

⋆⋆

◦

⋆⋆
⋆⋆

⋆
⋆

⋆⋆

⋆⋆

⋆⋆

⋆

⋆

◦
⋆

◦

◦
⋆

⋆

◦

⋆⋆
⋆⋆

⋆⋆
⋆⋆

⋆⋆

⋆⋆

⋆⋆

◦

⋆⋆
⋆⋆

⋆⋆
⋆⋆

⋆⋆

⋆⋆

⋆⋆

⋆⋆

⋆
⋆⋆

⋆
⋆

⋆

◦

⋆

⋆⋆

◦
⋆⋆

◦
⋆

⋆

◦

21

Rule-
Fit

⋆⋆

⋆

⋆
⋆

⋆
⋆

⋆

◦

Table 1: Assessment of classiﬁer properties. The symbols stand for the attributes “good” (⋆⋆), “OK”
(⋆) and “bad” (◦). “Curse of dimensionality” defers to the required increase in training statistics and
processing time when adding more input variables. See also comments in text.

Double_t pSig = reader->GetProba( "<YourClassifierName>", sigFraction );

Code Example 22: Requesting the event’s signal probability from a classiﬁer. The signal fraction is the
parameter fS in Eq. (1).

3.4 Which classiﬁer should I use for my problem?

There is obviously no common answer to that question. To guide the user, we have at-
tempted an assessment of some of the most important classiﬁer properties in Table 1.
Simplicity is a virtue, but only if it is not at the expense of discrimination power. Robust-
ness with respect to overtraining could become an issue when the training sample is scarce.
The user is advised to analyse the correlations among the discriminating variables to assess
whether a linear discriminant analysis could be suﬃcient. This would greatly reduces the
number of parameters to be adjusted and hence allow smaller training samples. However,
for problems that require a high degree of optimisation and allow to form a large number
of input variables, complex nonlinear methods like neural networks, boosted decision trees
and RuleFit are more appropriate. For RuleFit we emphasize that the TMVA implemen-
tation diﬀers from Friedman-Popescu’s original code [19], with (yet) better robustness
and out-of-the-box performance for the latter version. In particular, the behaviour of the
original code with respect to nonlinear correlations and the curse of dimensionality would
have merited two stars. We also point out that the excellent performance for by majority
linearly correlated input variables is achieved somewhat artiﬁcially by adding a Fisher-like
term to the RuleFit classiﬁer (this is true for both implementations, cf. Sec. 5.8).

22

4 Data Preprocessing

A certain number of tools are centrally available in TMVA and can be accessed by all
multivariate classiﬁers. For example, it is possible to preprocess the data prior to pre-
senting it to the classiﬁers. Preprocessing can be useful to reduce correlations among the
discriminating variables, to transform their shapes, or to accelerate the response time of
a classiﬁer.

4.1 Transforming input variables

Currently two preprocessing transformations are implemented in TMVA: decorrelation via
the square-root of the covariance matrix and via a principal component decomposition.
Technically, any transformation of the input variables is performed “on the ﬂy” when the
event is requested from the central DataSet class. Each classiﬁer carries a variable transfor-
mation type together with a pointer to the object of its transformation class (all inherited
from VariableTransformBase), which is owned by the DataSet. If no preprocessing is
requested, an identity transform is applied. The DataSet registers the requested transfor-
mations and takes care not to recreate an identical transformation object (if requested)
during the training phase. Hence if two classiﬁers wish to apply the same transformation,
a single object is shared between them. Each classiﬁer writes its transformation into its
weight ﬁle once the training has converged. For testing and application of a classiﬁer, the
transformation is read from the weight ﬁle and a corresponding transformation object is
created. Here each classiﬁer owns its transformation so that no sharing of potentially dif-
ferent transformation objects occurs (they may have been obtained with diﬀerent training
data and/or under diﬀerent conditions). A schematic view of the variable transformation
interface used in TMVA is drawn in Fig. 7.

4.1.1 Variable decorrelation

A drawback of, for example, the projective likelihood classiﬁer (see Sec. 5.2) is that it
ignores correlations among the discriminating input variables. Because in most realistic
use cases this is not an accurate conjecture it leads to performance loss. Also other
classiﬁers, such as rectangular cuts or decision trees, and even multidimensional likelihood
approaches underperform in presence of variable correlations.

Linear correlations, measured in the training sample, can be taken into account in a
straightforward manner through computing the square-root of the covariance matrix. The
square-root of a matrix C is the matrix C ′ that multiplied with itself yields C: C =
(C ′)2. TMVA computes the square-root matrix by means of diagonalising the (symmetric)
covariance matrix

D = ST CS

C ′ = S√DST ,

⇒

(3)

where D is a diagonal matrix, and where the matrix S is symmetric. The linear decorre-
lation of the input variables is then obtained by multiplying the initial variable tuple by
the inverse of the square-root matrix.

4.1 Transforming input variables

23

Figure 7: Schematic view of the variable transformation interface implemented in TMVA. Each concrete
classiﬁer derives from MethodBase (which is interfaced by IMethod), which holds a protected member
object of type VariableTransformBase. The construction of the concrete variable transformation object
proceeds in MethodBase according to the transformation method requested in the option string. The
events used by the classiﬁers for training, testing and ﬁnal classiﬁcation analysis are read via an API of
the VariableTransformBase class, which itself reads the events from the DataSet. The DataSet ﬁlls the
current values into the reserved event addresses (the event content may either stem from the training
or testing trees, or is set by the user’s application via the Reader for the ﬁnal classiﬁcation analysis).
The VariableTransformBase interface class ensures the proper transformation of all events seen by the
classiﬁers.

The transformations are performed separately for signal and background events because
their correlation patterns are usually diﬀerent.10 The decorrelation is complete only for
linearly correlated and Gaussian distributed variables. In real-world use cases this is not
often the case, so that sometimes only little additional information can be recovered by
the decorrelation procedure. For highly non-linear problems the performance may even
become worse with linear decorrelation. Non-linear classiﬁers without prior variable decor-
relation should be used in such cases.

4.1.2 Principal component decomposition

Principal component decomposition or principal component analysis (PCA) as presently
applied in TMVA is not very diﬀerent from the above linear decorrelation. In common
words, PCA is a linear transformation that rotates a sample of data points such that the
maximum variability is visible. It thus identiﬁes the most important gradients. In the
PCA-transformed coordinate system, the largest variance by any projection of the data
comes to lie on the ﬁrst coordinate (denoted the ﬁrst principal component), the second
largest variance on the second coordinate, and so on. PCA can thus be used to reduce the
dimensionality of a problem (initially given by the number of input variables) by removing
dimensions with insigniﬁcant variance. This corresponds to keeping lower-order principal

10Diﬀerent transformations for signal and background events are only useful for methods that explicitly
distinguish signal and background hypotheses. This is the case for the likelihood and PDERS classiﬁers.
For all other methods the user must choose which transformation to use.

4.2 Binary Search Trees

24

(4)

components and ignoring higher-order ones. This latter step however goes beyond straight
variable transformation as performed in the preprocessing steps discussed here (it rather
represents itself a full classiﬁer). Hence all principal components are retained here.

The signal (U = S) and background (U = B) tuples of principal components xPC
(xPC
for the event i of class U , are obtained by the transformation

U (i) =
U,nvar(i)) of a tuple of input variables x(i) = (x1(i), . . . , xnvar(i)), measured

U,1(i), . . . , xPC

xPC
U,k(i) =

(xU,ℓ(i)

−

xU,ℓ) v(k)
U,ℓ ,

k = 1, nvar .

∀

nvar

Xℓ=1

The tuples xU and v(k)
puted by the ROOT class TPrincipal. The matrix of eigenvectors VU = (v(1)
obeys the relation

U are the sample means and eigenvectors, respectively. They are com-
U , . . . , v(nvar)
)

U

VU = DU ·
where C is the covariance matrix of the sample U , and DU is the tuple of eigenvalues.
As for the preprocessing described in Sec. 4.1.1, the transformation (4) eliminates linear
correlations for Gaussian variables.

CU ·

VU ,

(5)

4.2 Binary Search Trees

When frequent iterations over the training sample need to be performed, it is helpful to
sort the sample before using it. Event sorting in binary trees is employed by the classiﬁers
rectangular cut optimisation and PDERS.

Eﬃciently searching for and counting events that lie inside a multidimensional volume
spanned by the discriminating input variables is accomplished with the use of a binary
tree search algorithm [8].11 It is realised in the class BinarySearchTree, which inherits
from BinaryTree, and which is also employed to grow decision trees (cf. Sec. 5.7). The
N
i=1 ln2(i) =
amount of computing time needed to sort N events into the tree is [9]
N ln2 N . Finding the events within the tree which lie in a given volume is
ln2(N !)
done by comparing the bounds of the volume with the coordinates of the events in the
N nvar
tree. Searching the tree once requires a CPU time that is
without prior event sorting.

ln2 N , compared to

P

∝

≃

∝

∝

11The following is extracted from Ref. [9] for a two-dimensional range search example. Consider a random
sequence of signal events ei(x1, x2), i = 1, 2, . . . , which are to be stored in a binary tree. The ﬁrst event in
the sequence becomes by deﬁnition the topmost node of the tree. The second event e2(x1, x2) shall have
a larger x1-coordinate than the ﬁrst event, therefore a new node is created for it and the node is attached
to the ﬁrst node as the right child (if the x1-coordinate had been smaller, the node would have become
the left child). Event e3 shall have a larger x1-coordinate than event e1, it therefore should be attached to
the right branch below e1. Since e2 is already placed at that position, now the x2-coordinates of e2 and
e3 are compared, and, since e3 has a larger x2, e3 becomes the right child of the node with event e2. The
tree is sequentially ﬁlled by taking every event and, while descending the tree, comparing its x1 and x2
coordinates with the events already in place. Whether x1 or x2 are used for the comparison depends on
the level within the tree. On the ﬁrst level, x1 is used, on the second level x2, on the third again x1 and
so on.

25

5 The TMVA Classiﬁers

All TMVA classifying methods inherit from MethodBase, which implements basic func-
tionality like the interpretation of common conﬁguration options, the interaction with the
training and test data sets, I/O operations and common performance evaluation calculus.
The functionality each classiﬁer is required to implement is deﬁned in the abstract inter-
face IMethod.12 Each classiﬁer must provide a function that creates a rank object (of type
Ranking), which is an ordered list of the input variables prioritized according to criteria
speciﬁc to that classiﬁer.

If the option CreateMVAPdfs is set TMVA creates signal and background PDFs from the
corresponding classiﬁer response distributions using the training sample (cf. Sec. 3.1.5).
The binning and smoothing properties of the underlying histograms can be customized via
controls implemented in MethodBase (so that they are common to all classiﬁers). They
are summarised in in Option Table 1.

Option

Values

Description

VarTransform

None*, Decorrelate, PCA

Transformation method for
variables

input

V

H

NbinsMVAPdf

NsmoothMVAPdf

False

False

60

2

Verbose ﬂag

Help ﬂag

Number of bins in histograms used to
build the classiﬁer PDFs

Number of smoothing iterations

Option Table 1: Conﬁguration options common to all classiﬁers (but which can be controlled individually
for each classiﬁer). Values given are defaults. If predeﬁned categories exist, the default category is marked
by a ’*’. The lower options in the table control the PDF ﬁtting of the classiﬁers.

The following sections describe the classiﬁers implemented in TMVA. For each classiﬁer
we proceed according to the following scheme: (i) a brief introduction, (ii) the description
of the booking options required to conﬁgure the classiﬁer, (iii) a description of the the
classiﬁer and TMVA implementation speciﬁcations, (iv) the properties of the variable
ranking, and (v) a few comments on performance, favourable (and disfavoured) use cases,
and comparisons with other classiﬁers.

12Two constructors are implemented for each classiﬁer: one that creates the classiﬁer for a ﬁrst time
for training with a conﬁguration (“option”) string among the arguments, and another that recreates a
classiﬁer from an existing weight ﬁle. The use of the ﬁrst constructor is demonstrated in the example
macro TMVAnalysis.C, while the second one is employed by the Reader in TMVApplication.C. Other
functions implemented by each classiﬁer are: Train (called for training), Write/ReadWeightsToStream (I/O
of speciﬁc training results), WriteMonitoringHistosToFile (additional speciﬁc information for monitoring
purposes) and CreateRanking (variable ranking).

5.1 Rectangular cut optimisation

26

5.1 Rectangular cut optimisation

The simplest and most common classiﬁer for selecting signal events from a mixed sample
of signal and background events is the application of an ensemble of rectangular cuts
on discriminating variables. Unlike all other classiﬁers in TMVA, the cut classiﬁer only
returns a binary response (signal or background). The optimisation of cuts performed by
TMVA maximises the background rejection at given signal eﬃciency, and scans over the
full range of the latter quantity. Dedicated analysis optimisation for which, e.g., the signal
signiﬁcance is maximised requires the expected signal and background yields to be known
before applying the cuts. This is not the case for a multi-purpose discrimination and
hence not used by TMVA. However, the cut ensemble leading to maximum signiﬁcance
corresponds to a particular working point on the eﬃciency curve, and can hence be easily
derived after the cut optimisation scan has converged.13

TMVA implements three methods for cut optimisation: Monte Carlo (MC) sampling, a
Genetic Algorithm (GA), and Simulated Annealing (SA, which is however depreciated for
the present release, since it has not yet been suﬃciently validated).14 Attempts to use
MINUIT (Simplex or Migrad) have not shown satisfactory results, with frequently failing
ﬁts because of the non-unique and non-global solution space. For most applications GA
should be the most performing optimisation method.

The training events are sorted in binary trees prior to the optimisation, which signiﬁcantly
reduces the computing time required to determine the number of events passing a given
cut ensemble (cf. Sec. 4.2).

5.1.1 Booking options

The rectangular cut optimisation is booked through the Factory via the command:

13Assuming a large enough number of events so that Gaussian statistics is applicable, the signiﬁcance for
εSNS + εB(εS )NS, where εS(B) and NS(B) are the signal and background
a signal is given by S = εS NS /
eﬃciencies for a cut ensemble and the event yields before applying the cuts, respectively. The background
eﬃciency εB is expressed as a function of εS using the TMVA evaluation curve obtained form the test data
sample. The maximum signiﬁcance is then found at the root of the derivative

p

dS
dεS

= NS

2εB(εS)NB + εS “NS − dεB (εS )
2 (εSNS + εB(εS)NB )3/2

dεS NB”

= 0 ,

(6)

which depends on the problem.

14We note that cut optimisation is not a genuine multivariate analyser method, because no combination
of the variables is achieved. Neither does a cut on one variable depend on the value of another variable
(like it is the case for Decision Trees), nor can a, say, background-like value of one variable in a signal
event be counterweighed by signal-like values of the other variables (like it is the case for the likelihood
method).

5.1 Rectangular cut optimisation

27

factory->BookMethod( Types::kCuts, "Cuts", "<options>" );

Code Example 23: Booking of the cut optimisation classiﬁer: the ﬁrst argument is a predeﬁned enumerator,
the second argument is a user-deﬁned string identiﬁer, and the third argument is the conﬁguration options
string. See Sec. 3.1.4 for more information on the booking.

The conﬁguration options for the various cut optimisation techniques are given in Option
Table 2.

5.1.2 Description of the classiﬁer and its implementation

The cut optimisation analysis proceeds by ﬁrst building binary search trees for signal and
background. For each variable, statistical properties like mean, root-mean-squared (RMS),
variable ranges are computed to guide the search for optimal cuts. Cut optimisation re-
quires an estimator that quantiﬁes the goodness of a given cut ensemble. Maximising
this estimator minimises (maximises) the background eﬃciency, εB (background rejection,
rB = 1

εB) for each signal eﬃciency εS.

−

All three optimisation methods act on the assumption that one minimum and one max-
imum requirement on each variable is suﬃcient to optimally discriminate signal from
background (i.e., the signal is clustered). If this is not the case, the variables must be
transformed prior to the cut optimisation to make them compliant with this assumption.

For a given cut ensemble the signal and background eﬃciencies are derived by counting the
training events that pass the cuts and dividing the numbers found by the original sample
sizes. The resulting eﬃciencies are therefore rational numbers that may exhibit visible
discontinuities when the number of training events is small and an eﬃciency is either very
small or very large. Another way to compute eﬃciencies is to parametrise the probability
density functions of all input variables and to thus achieve continuous eﬃciencies for any
cut value. Note however that this method expects the input variables to be uncorrelated!
Nonvanishing correlations would lead to incorrect eﬃciency estimates and hence to under-
performing cuts. The two methods are chosen with the option EffMethod set to EffSel
and EffPDF, respectively.

Monte Carlo sampling

The simplest and most straightforward, albeit somewhat ineﬃcient method to solve the
optimisation problem is to randomly sample the minimum and maximum requirements for
all discriminating variables. Each sample corresponds to a point in the (εS, rB) plane. The
εS dimension is (ﬁnely) binned and a cut sample is retained if its rB value is larger than
the value already contained in that bin. This way a reasonably smooth eﬃciency curve
can be obtained if the number of input variables is not too large (the required number of
MC samples grows with powers of 2nvar).

Prior information on the variable distributions can be used to reduce the number of cuts

5.1 Rectangular cut optimisation

28

Values

Description

MC, GA, SA

Optimisation method

EffSel, EffPDF

Selection method

100000

Monte Carlo sample size

AllNotEnforced,
AllF(Max, Min,
Smart)

Variable properties that can be
used to inject prior information on
cut boundaries; this allows to re-
duce the number of sampled cuts

0.0001

see GA nsteps

MC Var[i]Prop

(as above)

Same as above but per variable

Option

Method

EffMethod

MC NRandCuts

MC AllVarProp

GA nsteps

GA convCrit

GA cycles

GA popSize

GA SC steps

GA SC rate

GA SC factor

SA MaxCalls

30

3

100

10

5

0.95

5000000

Max. number of minimisation calls

SA TemperatureGradient

0.7

SA UseAdaptiveTemperature True

SA InitialTemperature

100000

SA MinTemperature

500

SA NFunLoops

SA Eps

SA NEps

1.0e-04

5

4

Option Table 2: Conﬁguration options for cut optimisation. Values given are defaults.
If predeﬁned
categories exist, the default category is marked by a ’*’. The options in Option Table 1 can also be
conﬁgured. The preﬁxes MC (GA, SA) denote options that set properties of the Monte Carlo (Genetic
Algorithm, Simulated Annealing) optimisation procedure (selected by the option Method).

Stop if the ﬁtness did not increase
by at least GA convCrit during the
previous GA nsteps generations

Number of optimisation cycles

Number of individuals in popula-
tion

If an improvement occurred in
GA SC rate steps of a period of
the last GA SC steps steps, a cut-
variation factor is multiplied by
GA SC factor

see GA SC steps

see GA SC steps

Temperature gradient

Use adaptive temperature

Initial temperature

Minimum temperature

Number of function loops

Minimum improvement in previous
step required to continue annealing

Number of
SA Eps

functions to satisfy

5.1 Rectangular cut optimisation

29

that need to be sampled. For example, if a discriminating variable follows Gaussian
distributions for signal and background, with equal width but a larger mean value for the
background distribution, there is no useful minimum requirement (other than
) so that
a single maximum requirement is suﬃcient for this variable. To instruct TMVA to remove
obsolete requirements, the option MC Var[i]Prop must be used, where [i] indicates the
counter of the variable (following the order in which they have been registered with the
Factory, beginning with 0) must be set to either FMax or FMin. TMVA is capable of
automatically detecting which of the requirements should be removed. Use the option
MC Var[i]Prop=FSmart (where again [i] must be replaced by the appropriate variable
counter, beginning with 0). Note that in many realistic use cases the mean values between
signal and background of a variable are indeed distinct, but the background can have large
tails. In such a case, the removal of a requirement is inappropriate, and would lead to
underperforming cuts.

−∞

Genetic Algorithm

Genetic Algorithm is a technique to ﬁnd approximate solutions to optimisation or search
problems. The problem is modeled by a group (population) of abstract representations
(genomes) of possible solutions (individuals). By applying means similar to processes
found in biological evolution the individuals of the population should evolve towards an
optimal solution of the problem. Processes which are usually modeled in evolutionary
algorithms — of which Genetic Algorithms are a subtype — are inheritance, mutation
and “sexual recombination” (also termed crossover).

Apart from the abstract representation of the solution domain, a ﬁtness function must be
deﬁned. Its purpose is the evaluation of the goodness of an individual. The ﬁtness function
is problem dependent. In cut optimisation for instance, the quality of a rectangular cut is
given by good background rejection combined with high signal eﬃciency. It either returns
a value representing the individual’s goodness or it compares two individuals and indicates
which of them performs better.

The Genetic Algorithm proceeds as follows:

•

•

•

Initialization: A starting population is created. Its size depends on the problem to be
solved. Each individual belonging to the population is created by randomly setting
the parameters (cuts) of the abstract representation (variables), thus producing a
point (cut ensemble) in the solution domain of the initial problem.

Evaluation: Each individual is evaluated using the ﬁtness function.

Selection: Individuals are kept or discarded as a function of their ﬁtness. Several
selection procedures are possible. The simplest one is to separate out the worst per-
forming fraction of the population. Another possibility is to decide on the individ-
ual’s survival by assigning probabilities that depend on the individual’s performance
compared to the others.

5.1 Rectangular cut optimisation

30

•

•

Reproduction: The surviving individuals are copied, mutated and crossed-over until
the initial population size is reached again.

Termination: The evaluation, selection and reproduction steps are repeated until a
maximum number of cycles is reached or an individual satisﬁes a maximum-ﬁtness
criterion. The best individual is selected and taken as solution to the problem.

The TMVA Genetic Algorithm implementation provides a certain number of controls that
can be set through the options (cf. Table 2). The parameter GA popSize determines the
number of individuals (cut ensembles) which are created at each generation of the Genetic
Algorithm. At the initialization, all parameters of all individuals are chosen randomly.
The individuals are evaluated in terms of their background rejection and signal eﬃciency.
Each cut ensemble giving an improvement in the background rejection for a speciﬁc signal
eﬃciency bin is immediately stored. Each individual’s ﬁtness is assessed, where the ﬁtness
is largely determined by the diﬀerence of the best found background rejection for a partic-
ular bin of signal eﬃciency and the value produced by the current individual. The same
individual that has at one generation a very good ﬁtness will have only average ﬁtness
at the following generation. This forces the algorithm to focus on the region where the
potential of improvement is the highest.

Individuals with a good ﬁtness are selected to produce the next generation. The new indi-
viduals are created by crossover and mutated afterwards. Mutation changes some values of
some parameters of some individuals randomly following a Gaussian distribution function.
The width of the Gaussian can be altered by the parameter GA SC factor. The current
width is multiplied by this factor when within the last GA SC steps generations more than
GA SC rate improvements have been obtained. If there were GA SC rate improvements
the width remains unchanged. Were there, on the other hand, less than GA SC rate im-
provements, the width is divided by GA SC factor. This allows to inﬂuence the speed of
searching through the solution domain.

The cycle of evaluating the ﬁtness of the individuals of a generation and producing a new
generation is repeated until the improvement within the last GA nsteps has been less than
GA convCrit in terms of background rejection. The minimisation is then considered to
have converged. The whole cycle from initialization over evaluation of ﬁtness, selection,
reproduction and determining the improvement is repeated GA cycles times. The Genetic
Algorithm has ﬁnished.

Simulated Annealing

As the Genetic Algorithm, Simulated Annealing attempts to solve a minimisation problem
with manifold discrete or continuous, local or global solutions. For example, when slowly
cooling down (“annealing”) a metal its atoms move towards a state of lowest energy,
while for fast annealing the atoms tend to freeze in intermediate higher energy states.
For inﬁnitesimal annealing activity the system will always converge in its global energy
minimum [10].

5.2 Projective likelihood estimator (PDE approach)

This physical principle can be simulated to achieve slow, but correct convergence of an
optimisation problem with multiple solutions. Recovery out of local minima is achieved
by assigning the probability [11]

p(∆E)

exp

∝

∆E
T

,

(cid:19)

−

(cid:18)

to a perturbation of the parameters (the cuts) leading to a shift ∆E in the energy of the
system. The probability of such perturbations to occur decreases with the size of a positive
energy coeﬃcient of the perturbation, and with the ambient temperature (T ). The TMVA
implementation of Simulated Annealing uses adaptive adjustment of the perturbation and
temperature gradients.

Although the Simulated Annealing algorithm is technically functional, it has not yet been
optimised so that its use is depreciated until further notice.

31

(7)

The present implementation of Cuts does not provide a ranking of the input variables.

5.1.3 Ranking

5.1.4 Performance

The Genetic Algorithm currently provides the best cut optimisation convergence. How-
ever, it is found that with rising number of discriminating input variables the goodness of
the solution found (and hence the smoothness of the background-rejections versus signal
eﬃciency plot) deteriorates quickly. Rectangular cut optimisation should therefore be re-
duced to the variables that have the largest discriminating power.

If variables with excellent signal from background separation exist, applying cuts can be
quite competitive with more involved classiﬁers. Cuts are known to underperform in pres-
ence of strong non-linear correlations and/or if several weakly discriminating variables
are used. In the latter case, a true multivariate combination of the information will be
rewarding.

5.2 Projective likelihood estimator (PDE approach)

The method of maximum likelihood consists of building a model out of probability density
functions (PDFs) that reproduces the input variables for signal and background. For a
given event, the likelihood for being of signal type is obtained by multiplying the signal
probability densities of all input variables, and normalising this by the sum of the signal
and background likelihoods. Correlations among the variables are ignored.

5.2.1 Booking options

The likelihood classiﬁer is booked via the command:

5.2 Projective likelihood estimator (PDE approach)

32

factory->BookMethod( Types::kLikelihood, "Likelihood", "<options>" );

Code Example 24: Booking of the (projective) likelihood classiﬁer: the ﬁrst argument is the predeﬁned
enumerator, the second argument is a user-deﬁned string identiﬁer, and the third argument is the conﬁg-
uration options string. See Sec. 3.1.4 for more information on the booking.

The likelihood conﬁguration options are given in Option Table 3.

Values

Description

0, 1, 2*, 3, 5

Option

Spline

NSmooth

NAvEvtPerBin

5

25

UseKDE

False

KDEtype

Gauss*

KDEiter

Nonadaptive*, Adaptive

KDEFineFactor

1

KDEborder

None*, Renorm, Mirror

TransformOutput

False

Degree of splines used to interpolate
the reference histograms

Number of smoothing iterations for
the input histograms

Average number of events per bin in
each reference histogram (to allow an
adaptive number of bins)

Use kernel density estimator (KDE)
instead of spline functions

KDE kernel
Gauss)

type (currently only

Nonadaptive or adaptive number of
iterations (see text)

Finetuning factor for the adaptive
KDE

Method
ary/border eﬀects

for

correcting

bound-

Transform likelihood output by in-
verse sigmoid function

Option Table 3: Likelihood conﬁguration options. Values given are defaults. If predeﬁned categories exist,
the default category is marked by a ’*’. The options in Option Table 1 can also be conﬁgured.

5.2.2 Description of the classiﬁer and its implementation

The likelihood ratio yL(i) for event i is deﬁned by
LS(i)
LS(i) +

yL(i) =

,

LB(i)

where

LS(B)(i) =

pS(B),k(xk(i)) ,

nvar

Yk=1

(8)

(9)

33

(10)

5.2 Projective likelihood estimator (PDE approach)

and where pS(B),k is the signal (background) PDF for the kth input variable xk. The
PDFs are normalised

+∞

Z−∞

pS(B),k(xk)dxk = 1 ,

k.

∀

It can be shown that in absence of model inaccuracies (such as correlations between input
variables not removed by the decorrelation procedure, or an inaccurate probability density
model), the ratio (8) provides optimal signal from background separation for the given set
of input variables.

Since the parametric form of the PDFs is generally unknown, the PDF shapes are em-
pirically approximated from the training data by nonparametric functions, which can be
polynomial splines of various degrees ﬁtted to histograms or unbinned kernel density esti-
mators (KDE), as discussed below.

A certain number of primary validations are performed during the PDF creation, the re-
sults of which are printed to standard output. Among these are the computation of a χ2
estimator between all nonzero bins of the original histogram and its PDF, and a compar-
ison of the number of outliers (in sigmas) found in the original histogram with respect to
the (smoothed) PDF shape, with the statistically expected one. The ﬁdelity of the PDF
estimate can be also inspected visually by executing the macro likelihoodrefs.C (cf.
Table 1).

Nonparametric PDF parameterisation using spline functions

Polynomial splines are ﬁtted to binned histograms according to the following procedure.

1. For each input variable, a histogram is ﬁlled with the training data. The upper and
lower bounds of the histogram coincide with the limits found in the data (or they
are equal to [0,1] if the input variables are normalised). The (equidistant) binning
is chosen so that the average number of entries per bin corresponds to the number
(NAvEvtPerBin) deﬁned in the option string.

2. The histogram is smoothed NSmooth times using the method TH1::SmoothArray(.),
which is an implementation of the algorithm 353QH twice [12]. The appropri-
ate number of smoothing iterations depends on the shape of the histogram. Since
smoothing tends to even out all structures from the histogram, narrow structures
(e.g., peaks) support less smoothing than broad ones.

3. The smoothed histogram is used to construct an object of the class PDF, where
it is cloned and the bins are ﬁt to polynomial interpolation functions, (splines –
derivatives of the ROOT class TSpline). The available splines are: degree 0 (the
original histogram is kept), which is useful for discrete variables; degree 1 (linear),
2 (quadratic), 3 (cubic) and degree 5. Splines of degree two or above render the
PDF continuous and diﬀerentiable in all points excluding the interval borders, which
in turn ensures the same property for the likelihood ratio (8). Since cubic (and

5.2 Projective likelihood estimator (PDE approach)

34

higher) splines equalize the ﬁrst and second derivatives at the spline transitions, the
resulting curves, although mathematically smooth, can wiggle in quite unexpected
ways. Furthermore, there is no local control of the spline: moving one control point
(bin) causes the entire curve to change, not just the part near the control point. To
ensure a safe interpolation, quadratic splines are used by default.

4. To speed up the numerical access to the probability densities, the spline functions are
stored into a ﬁnely binned (104 bins) histogram, where adjacent bins are interpolated
by a linear function. Only after this step, the PDF is normalised according to (10).

Nonparametric PDF parameterisation using kernel density estimators

Another type of nonparametric approximation of the PDFs is achieved with kernel density
estimators (KDE). As opposed to splines KDEs are obtained from unbinned data. The
idea of the approach is to estimate the shape of a PDF by the sum over smeared training
events. One then ﬁnds for a PDF p(x) of a variable x [13]

p(x) =

1
N h

N

K

Xi=1

(cid:18)

x

xi

−
h

=

1
N

(cid:19)

N

Xi=1

Kh(x

xi) ,

−

where N is the number of training events, Kh(t) = K(t/h)/h is the kernel function, and
h is the bandwidth of the kernel (also termed the smoothing parameter). Currently, only
a Gaussian form of K is implemented, where the exact form of the kernel function is of
minor relevance for the quality of the shape estimation. More important is the choice of
the bandwidth.

The KDE smoothing can be applied in either nonadaptive (NA) or adaptive form (A),
the choice of which is controlled by the option KDEiter.
In the nonadaptive case the
bandwidth hNA is kept constant for the entire training sample. As optimal bandwidth can
be taken the one that minimizes the asymptotic mean integrated square error (AMISE).
For the case of a Gaussian kernel function this leads to [13]

hNA =

σxN −1/5 ,

1/5

4
3

(cid:18)

(cid:19)

hA(x) =

hNA
p(x)

.

p

where σx is the RMS of the variable x.

The so called sample point adaptive method uses as input the result of the nonadaptive
KDE, but also takes into account the local event density. The adaptive bandwidth hA
then becomes a function of p(x) [13]

The adaptive approach improves the shape estimation in regions with low event density.
On the contrary, in regions with high event density it can give rise to “over-smoothing”

(11)

(12)

(13)

5.2 Projective likelihood estimator (PDE approach)

35

of ﬁne structures such as narrow peaks. The degree of smoothing can be tuned by multi-
plying the bandwidth hA(x) with the user-speciﬁed factor KDEFineFactor.

For practical reasons, the KDE implementation in TMVA diﬀers somewhat form the pro-
cedure described above. Instead of using the unbinned training data, ﬁnely-binned his-
tograms are used as inputs, which allows to speed up the algorithm. In a second step, a
KDEKernel class object is created where the calculation of the bandwidth hNA is performed.
If the algorithm is run in the adaptive mode the nonadaptive step is also performed and
the output is used to compute hA(x) for the adaptive part. In a third step, a smoothed
histogram estimating the PDF shape is ﬁlled by looping over the binned input histogram
and summing up the kernel functions. Here hNA is used for the nonadaptive mode and
hA(x) for the adaptive mode. Finally, the smoothed histogram is used to construct a PDF
class object.

Both the nonadaptive and the adaptive methods can suﬀer from the so-called boundary
problem.
It occurs for instance if the original distribution is nonzero below a physical
boundary value and zero above. This property cannot be reproduced by the KDE proce-
dure. In general, the stronger the discontinuity the more acute is the boundary problem.
TMVA provides three options under the term KDEborder that allow to treat boundary
problems.

•

•

•

KDEborder=None
No boundary treatment is performed. The consequence is that close to the boundary
the KDE result will be inaccurate: below the boundary it will underestimate the PDF
while it will not drop to zero above. In TMVA the PDF resulting from KDE is in fact
a (ﬁnely-binned) histogram, with bounds equal to the minimum and the maximum
values of the original distribution. Hence, the boundary value will be at the edge of
the PDF (histogram), and a drop of the PDF due to the closeness of the boundary
can be observed (while the artiﬁcial enhancement beyond the boundary will fall
outside of the histogram). In other words, for training events that are close to the
boundary some fraction of the probability “ﬂows” outside the histogram (probability
leakage). As a consequence, the integral of the kernel function inside the histogram
borders is smaller than one.

KDEborder=Renorm
The probability leakage is compensated by renormalising of the kernel function so
that the integral inside the histogram borders is equal to one.

KDEborder=Mirror
The original distribution is “mirrored” around the boundary. To the events originat-
ing from this mirror copy the same procedure is applied as for the original ones: each
of them is smeared by a kernel function and its contribution inside the histogram
(PDF) boundaries is added to the PDF. The mirror copy exactly compensates the
probability leakage.

5.2 Projective likelihood estimator (PDE approach)

36

L
R

0.3

0.2

0.1

0

-0.1

-0.2

-0.3

0

0.1 0.2

0.3 0.4

0.5

0.6

0.7

0.8

0.9

1
LR

Figure 8: Transformation (14) of the likelihood output.

Transforming the likelihood output

If a data-mining problem oﬀers a large number of input variables, or variables with excel-
lent separation power, the likelihood response yL is often strongly peaked at 0 (background)
and 1 (signal). Such a response is inconvenient for the use in subsequent analysis steps.
TMVA therefore allows to transform the likelihood output by an inverse sigmoid function
that zooms into the peaks

yL(i)

y′
L(i) =

τ −1 ln

y−1
L −

1

,

−
where τ = 15 is used (hardcoded). Note that y′
L(i) is no longer contained within [0, 1] (see
Fig. 8). The transformation (14) is enabled (disabled) with the likelihood booking option
TransformOutput=True(False).

−→

(cid:1)

(cid:0)

(14)

The present likelihood implementation does not provide a ranking of the input variables.

5.2.3 Ranking

5.2.4 Performance

Both the training and the application of the likelihood classiﬁer are very fast operations
that are suitable for large data sets.

The performance of the classiﬁer relies on the accuracy of the likelihood model. Because
high ﬁdelity PDF estimates are mandatory, suﬃcient training statistics is required to
populate the tails of the distributions. The neglect of correlations between input variables
in the model (9), often leads to a diminution of the discrimination performance. While
linear Gaussian correlations can be rotated away (see Sec. 4.1), such an ideal situation is
0, 1. Correlations can be
rarely given. Positive correlations lead to peaks at both yL →
reduced by categorizing the data samples and building an independent likelihood classiﬁer
for each event category. Such categories could be geometrical regions in the detector,

5.3 Multidimensional likelihood estimator (PDE range-search approach)

37

kinematic properties, etc. In spite of this, realistic applications with a large number of
input variables are often plagued by irreducible correlations, so that projective likelihood
approaches like the one discussed here are underperforming. This ﬁnding lead to the
development of the many alternative classiﬁers that exist in statistical theory today.

5.3 Multidimensional likelihood estimator (PDE range-search approach)

This is a generalization of the projective likelihood classiﬁer described in Sec. 5.2 to nvar
dimensions, where nvar is the number of input variables used. If the multidimensional PDF
for signal and background were known, this classiﬁer would exploit the full information
contained in the input variables, and would hence be optimal. In practice however, huge
training samples are necessary to suﬃciently populate the multidimensional phase space.15
Kernel estimation methods may be used to approximate the shape of the PDF for ﬁnite
training statistics.

A simple probability density estimator denoted PDE range search, or PDERS, has been
suggested in Ref. [9]. The PDE for a given test event (discriminant) is obtained by counting
the (normalised) number of signal and background (training) events that occur in the
”vicinity” of the test event. The classiﬁcation of the test event may then be conducted on
the basis of the majority of the nearest training events. The nvar-dimensional volume that
encloses the ”vicinity” is user-deﬁned and can be adaptive. A search method based on
sorted binary trees is used to reduce the computing time for the range search. To enhance
the sensitivity within the volume, kernel functions are used to weight the reference events
according to their distance from the test event. PDERS is a variant of a K nearest
neighbour algorithm.

5.3.1 Booking options

The PDERS classiﬁer is booked via the command:

factory->BookMethod( Types::kPDERS, "PDERS", "<options>" );

Code Example 25: Booking of PDERS: the ﬁrst argument is a predeﬁned enumerator, the second argument
is a user-deﬁned string identiﬁer, and the third argument is the conﬁguration options string. See Sec. 3.1.4
for more information on the booking.

The conﬁguration options for the PDERS classiﬁer are given in Option Table 4.

5.3.2 Description of the classiﬁer and its implementation

To classify an event as being either of signal or of background type, a local estimate of the
probability density of it belonging to either class is computed. The method of PDERS

15Due to correlations between the input variables, only a sub-space of the full phase space may be

populated.

5.3 Multidimensional likelihood estimator (PDE range-search approach)

38

Option

Values

Description

VolumeRangeMode

Unscaled, RMS, MinMax,
Adaptive*

Deﬁnition of the volume reference

DeltaFrac

NEventsMin

NEventsMax

3.0

100

200

MaxVIterations

50

InitialScale

0.99

KernelEstimator

GaussSigma

0.2

Box*, Sphere, Teepee,
Gauss, Sinc3(5,7,9,11),
Lanczos2(3,5,8)

Volume size: multiplies MinMax or
RMS

Minimum number of events required
in adaptive volume

Maximum number of events required
in adaptive volume

Maximum number of iterations for
the adaptive volume search

Initial size of adaptive volume (com-
pared to full volume spanned by data)

Kernel estimator function

Width (with respect to volume size)
of Gaussian kernel estimator

Option Table 4: PDERS conﬁguration options. Values given are defaults. If predeﬁned categories exist,
the default category is marked by a ’*’. The options in Option Table 1 can also be conﬁgured.

provides such an estimate by deﬁning a volume (V ) around the test event (i), and by
counting the number of signal (nS(i, V )) and background events (nB(i, V )) obtained from
the training sample in that volume. The ratio

yPDERS(i, V ) =

1
1 + r(i, V )

(15)

(NS/nS(i, V )), and NS(B) is
is taken as the estimate, where r(i, V ) = (nB(i, V )/NB)
the total number of signal (background) events in the training sample. The estimator
yPDERS(i, V ) peaks at 1 (0) for signal (background) events. The counting method averages
over the PDF within V , and hence ignores the available shape information inside (and
outside) that volume.

·

Eﬃciently searching for and counting the events that lie inside the volume is accomplished
with the use of a nvar-variable binary tree search algorithm [8] (cf. Sec. 4.2).

Binary tree search

Choosing a volume

The TMVA implementation of PDERS optionally provides four diﬀerent volume deﬁni-
tions:

5.3 Multidimensional likelihood estimator (PDE range-search approach)

39

•

•

•

•

Unscaled
The simplest volume deﬁnition. The user speciﬁes a rigid box of size DeltaFrac in
units of the variables. This method was the one originally used by the developers of
PDERS [9].

MinMax
The volume is deﬁned in each dimension (i.e., input variable) with respect to the
full range of values found for that dimension in the training sample. The fraction of
this volume used for the range search is deﬁned by the option DeltaFrac.

RMS
The volume is deﬁned in each dimension with respect to the RMS of that dimension
(input variable), estimated from the training sample. The fraction of this volume
used for the range search is deﬁned by the option DeltaFrac.

Adaptive
A volume is deﬁned in each dimension with respect to the RMS of that dimension,
estimated from the training sample. The overall scale of the volume is adjusted
individually for each test event such that the total number of events conﬁned in the
volume lies within a user-deﬁned range (options NEventsMin/Max). The adjustment
is performed by the class RootFinder, which is a C++ implementation of Brent’s
algorithm (translated from the CERNLIB function RZERO). The maximum initial
volume (fraction of the RMS) and the maximum number of iterations for the root
ﬁnding is set by the options InitialScale and MaxVIterations, respectively. The
requirement to collect a certain number of events in the volume automatically leads to
small volume sizes in strongly populated phase space regions, and enlarged volumes
in areas where the population is scarce.

Although the adaptive volume adjustment is more ﬂexible and should perform better, it
signiﬁcantly increases the computing time of the PDERS discriminant. If found too slow,
one can reduce the number of necessary iterations by choosing a larger NEventsMin/Max
interval.

Event weighting with kernel functions

One of the shortcomings of the original PDERS implementation is its sensitivity to the
exact location of the sampling volume boundaries: an inﬁnitesimal change in the bound-
ary placement can include or exclude a training event, thus changing r(i, V ) by a ﬁnite
amount.16 In addition, the shape information within the volume is ignored.

Kernel functions mitigate these problems by weighting each event within the volume as a
function of its distance to the test event. The farer it is away, the smaller is its weight.
The following kernel functions are implemented in TMVA, and can be selected with the
option KernelEstimator.

16Such an introduction of artefacts by having sharp boundaries in the sampled space is an example of

Gibbs’s phenomenon, and is commonly referred to as ringing or aliasing.

5.3 Multidimensional likelihood estimator (PDE range-search approach)

40

t
h
g
i
e
w

 
l
e
n
r
e
K

1.2

1

0.8

0.6

0.4

0.2

0
0

t
h
g
i
e
w

 
l
e
n
r
e
K

1

0.8

0.6

0.4

0.2

0
0

0.1 0.2

0.3 0.4

0.5

0.6

0.7

0.8

0.9

1

0.1 0.2

0.3 0.4

0.5

0.6

0.7

0.8

0.9

1

Radial distance from test discriminant

Radial distance from test discriminant

Figure 9: Kernel functions (left: Gaussian, right: Teepee) used to weight the events that are found inside
the reference volume of a test event.

•

•

•

Box
Corresponds to the original rectangular volume element without application of event
weights.

Sphere
A hyperelliptic volume element is used without application of event weights. The
hyperellipsoid corresponds to a sphere of constant fraction in the MinMax or RMS
metrics. The size of the sphere can be chosen adaptive, just as for the rectangular
volume.

Teepee
The simplest linear interpolation that eliminates the discontinuity problem of the
box. The training events are given a weight that decreases linearly with their distance
from the centre of the volume (the position of the test event). In other words: these
events are convolved with the triangle or tent function, becoming a sort of teepee in
multidimensions.

•

Gauss
The simplest well behaved convolution kernel. The width of the Gaussian (fraction
of the volume size) can be set by the option GaussSigma.

Other methods implemented for test purposes are “Sinc” and ”Lanczos” functions
∝
sin x/x of diﬀerent (symmetric) orders. They exhibit strong peaks at zero and oscillating
tails. Their use is depreciated. The Gaussian and Teepee kernel functions are shown in
Fig. 9.

5.3.3 Ranking

The present implementation of Likelihood does not provide a ranking of the input variables.

5.4 H-Matrix (χ2) estimator

41

5.3.4 Performance

As opposed to many of the more sophisticated data-mining approaches, which tend to
present the user with a ”black box”, PDERS is simple enough that the algorithm can
be easily traced and tuned by hand. PDERS can yield competitive performance if the
number of input variables is not to large and the statistics of the training sample is
ample. In particular, it naturally deals with complex nonlinear variable correlations, the
reproduction of which may, for example, require involved neural network architectures.

PDERS is a slowly responding classiﬁer. Only the training, i.e., the fabrication of the
binary tree is fast, which is usually not the critical part. The necessity to store the entire
binary tree in memory to avoid accessing virtual memory limits the number of training
events that can eﬀectively be used to model the multidimensional PDF. This is not the
case for the other classiﬁers implemented in TMVA (with some exception for Boosted
Decision Trees).

5.4 H-Matrix (χ2) estimator

The origins of the H-Matrix approach dates back to works of Fisher and Mahalanobis in
the context of Gaussian classiﬁers [14, 15]. It discriminates one class (signal) of a feature
vector from another (background). The correlated elements of the vector are assumed
to be Gaussian distributed, and the inverse of the covariance matrix is the H-Matrix. A
multivariate χ2 estimator is built that exploits diﬀerences in the mean values of the vector
elements between the two classes for the purpose of discrimination.

The H-Matrix classiﬁer as it is implemented in TMVA is equal or less performing than
the Fisher discriminant (see Sec. 5.5), and has been only included for completeness.

5.4.1 Booking options

The H-Matrix discriminant is booked via the command:

factory->BookMethod( Types::kHMatrix, "HMatrix", "<options>" );

Code Example 26: Booking of the H-Matrix classiﬁer: the ﬁrst argument is a predeﬁned enumerator, the
second argument is a user-deﬁned string identiﬁer, and the third argument is the conﬁguration options
string. See Sec. 3.1.4 for more information on the booking.

No conﬁguration options in addition to those described in Option Table 1 are implemented
for the H-Matrix classiﬁer.

5.4.2 Description of the classiﬁer and its implementation

For an event i, each one χ2 estimator (χ2
S(B)) is computed for signal (S) and background
(B), using estimates for the sample means (xS(B),k) and covariance matrices (CS(B)) ob-

5.5 Fisher discriminants (linear discriminant analysis)

tained from the training data

χ2

U (i) =

(xk(i)

−

xU,k) C −1

U,kℓ (xℓ(i)

xU,ℓ) ,

−

nvar

Xk,ℓ=1

where U = S, B. From this, the discriminant

yH(i) =

χ2
χ2
B(i)
−
χ2
B(i) + χ2

S(i)
S(i)

,

is computed to discriminate between the signal and background classes.

42

(16)

(17)

The present implementation of the H-Matrix discriminant does not provide a ranking of
the input variables.

5.4.3 Ranking

5.4.4 Performance

The TMVA implementation of the H-Matrix classiﬁer has been shown to underperform in
comparison with the corresponding Fisher discriminant (cf. Sec. 5.5), when using similar
assumptions and complexity. It is therefore depreciated.

5.5 Fisher discriminants (linear discriminant analysis)

In the method of Fisher discriminants [14] event selection is performed in a transformed
variable space with zero linear correlations, by distinguishing the mean values of the signal
and background distributions. The linear discriminant analysis determines an axis in the
(correlated) hyperspace of the input variables such that, when projecting the output classes
(signal and background) upon this axis, they are pushed as far as possible away from each
other, while events of a same class are conﬁned in a close vicinity. The linearity property
of this classiﬁer is reﬂected in the metric with which ”far apart” and ”close vicinity” are
determined: the covariance matrix of the discriminating variable space.

5.5.1 Booking options

The Fisher discriminant is booked via the command:

factory->BookMethod( Types::kFisher, "Fisher", "<options>" );

Code Example 27: Booking of the Fisher discriminant: the ﬁrst argument is a predeﬁned enumerator, the
second argument is a user-deﬁned string identiﬁer, and the third argument is the conﬁguration options
string. See Sec. 3.1.4 for more information on the booking.

The conﬁguration options for the Fisher discriminant are given in Option Table 5.

5.5 Fisher discriminants (linear discriminant analysis)

43

Option

Method

Values

Description

Fisher*, Mahalanobis

Variations of Fisher discriminants

Option Table 5: Conﬁguration options for the Fisher discriminant. Values given are defaults. If predeﬁned
categories exist, the default category is marked by a ’*’. The options in Option Table 1 can also be
conﬁgured.

5.5.2 Description of the classiﬁer and its implementation

The classiﬁcation of the events in signal and background classes relies on the following
characteristics: the overall sample means xk for each input variable k = 1, . . . , nvar, the
class-speciﬁc sample means xS(B),k, and total covariance matrix C of the sample. The
covariance matrix can be decomposed into the sum of a within- (W ) and a between-class
matrix (B). They respectively describe the dispersion of events relative to the means of
their own class (within-class matrix), and relative to the overall sample means (between-
class matrix)17.

The Fisher coeﬃcients, Fk, are then given by
nvar

Fk =

√NSNB
NS + NB

W −1

kℓ (xS,ℓ −

xB,ℓ) ,

Xℓ=1

where NS(B) are the number of signal (background) events in the training sample. The
Fisher discriminant yFi(i) for event i is given by
nvar

yFi(i) = F0 +

Fkxk(i) .

Xk=1

The oﬀset F0 centers the sample mean yFi of all NS + NB events at zero.

Instead of using the within-class matrix, the Mahalanobis variant determines the Fisher
coeﬃcients as follows [15]

(18)

(19)

(20)

Fk =

√NSNB
NS + NB

C −1
kℓ (xS,ℓ −

xB,ℓ) ,

nvar

Xℓ=1

17The within-class matrix is given by

Wkℓ =

hxU,k − xU,kihxU,ℓ − xU,ℓi = CS,kℓ + CB,kℓ ,

X
U =S,B

where CS(B) is the covariance matrix of the signal (background) sample. The between-class matrix is
obtained by

Bkℓ =

(xU,k − xk) (xU,ℓ − xℓ) ,

1
2 X
U =S,B

where xS(B),k is the average of variable xk for the signal (background) sample, and xk denotes the average
for the entire sample.

5.6 Artiﬁcial Neural Networks (non-linear discriminants)

44

where Ckℓ = Wkℓ + Bkℓ.

5.5.3 Ranking

The Fisher discriminant analysis aims at simultaneously maximising the between-class
separation while minimising the within-class dispersion. A useful measure of the discrim-
ination power of a variable is therefore given by the diagonal quantity Bkk/Ckk, which is
used for the ranking of the input variables.

5.5.4 Performance

In spite of the simplicity of the classiﬁer, Fisher discriminants can be competitive with
likelihood and non-linear discriminants in certain cases. In particular, Fisher discriminants
are optimal for Gaussian distributed variables with linear correlations (cf. the standard
toy example that comes with TMVA).

On the other hand, no discrimination at all is achieved when a variable has the same
sample mean for signal and background, even if the shapes of the distributions are very
diﬀerent. Thus, Fisher discriminants often beneﬁt from suitable transformations of the
input variables. For example, if a variable x
1, 1] has a a signal distributions of the
form x2, and a uniform background distributions, their mean value is zero in both cases,
leading to no separation. The simple transformation x
renders this variable powerful
for the use in a Fisher discriminant.

[
−

→ |

x
|

∈

5.6 Artiﬁcial Neural Networks (non-linear discriminants)

An Artiﬁcial Neural Network (ANN) is most generally speaking any simulated collection
of interconnected neurons, with each neuron producing a certain response at a given set
of input signals. By applying an external signal to some (input) neurons the network
is put into a deﬁned state that can be measured from the response of one or several
(output) neurons. One can therefore view the neural network as a mapping from a space
of input variables x1, . . . , xnvar onto a, in case of a signal-versus-background discrimination
problem, one-dimensional space of output variables y. The mapping is non-linear if at least
one neuron has a non-linear response to its input.

In TMVA three neural network implementations are available to the user. The ﬁrst was
adapted from a FORTRAN code developed at the Universit´e Blaise Pascal in Clermont-
Ferrand,18 the second is the ANN implementation that comes with ROOT. The third is a
newly developed neural network (denoted MLP) that is faster and more ﬂexible than the
other two and is the recommended neural network to use with TMVA. All three neural
networks are feed-forward multilayer perceptrons.

18The original Clermont-Ferrand neural network has been used for Higgs search analyses in ALEPH,
and background ﬁghting in rare B-decay searches by the BABAR Collaboration. For the use in TMVA
the FORTRAN code has been converted to C++.

5.6 Artiﬁcial Neural Networks (non-linear discriminants)

45

5.6.1 Booking options

The Clermont-Ferrand neural network

The Clermont-Ferrand neural network is booked via the command:

factory->BookMethod( Types::kCFMlpANN, "CF_ANN", "<options>" );

Code Example 28: Booking of the Clermont-Ferrand neural network: the ﬁrst argument is a predeﬁned
enumerator, the second argument is a user-deﬁned string identiﬁer, and the third argument is the options
string. See Sec. 3.1.4 for more information on the booking.

The conﬁguration options for the Clermont-Ferrand neural net are given in Option Table 6.

Option

NCycles

Values

3000

HiddenLayers

"N-1,N-2,..."

Description

Number of training cycles

Speciﬁcation of the network architec-
ture

Option Table 6: Conﬁguration options for the Clermont-Ferrand neural net. Values given are defaults. See
Sec. 5.6.3 for a description of the network architecture conﬁguration. The options in Option Table 1 can
also be conﬁgured.

The ROOT neural network (class TMultiLayerPerceptron)

This neural network interfaces the ROOT class TMultiLayerPerceptron and is booked
through the Factory via the command line:

factory->BookMethod( Types::kTMlpANN, "TMlp_ANN", "<options>" );

Code Example 29: Booking of the ROOT neural network: the ﬁrst argument is a predeﬁned enumerator,
the second argument is a user-deﬁned string identiﬁer, and the third argument is the conﬁguration options
string. See Sec. 3.1.4 for more information on the booking.

The conﬁguration options for the ROOT neural net are given in Option Table 7.

5.6 Artiﬁcial Neural Networks (non-linear discriminants)

46

Option

NCycles

Values

3000

HiddenLayers

"N-1,N-2,..."

Description

Number of training cycles

Speciﬁcation of the network architec-
ture

Option Table 7: Conﬁguration options for the ROOT neural network. Values given are defaults. See
Sec. 5.6.3 for a description of the network architecture conﬁguration. The options in Option Table 1 can
also be conﬁgured.

The MLP neural network

The MLP neural network is booked through the Factory via the command line:

factory->BookMethod( Types::kMLP, "MLP_ANN", "<options>" );

Code Example 30: Booking of the MLP neural network: the ﬁrst argument is a predeﬁned enumerator,
the second argument is a user-deﬁned string identiﬁer, and the third argument is the options string. See
Sec. 3.1.4 for more information on the booking.

The conﬁguration options for the MLP neural net are given in Option Table 8.

HiddenLayers

"N-1,N-2,..."

Option

NCycles

Normalise

NeuronType

Values

3000

True

sigmoid*, linear, tanh,
radial

NeuronInputType

sum, sqsum, abssum

Description

Number of training cycles

Speciﬁcation of the network architec-
ture

Normalised input variables ﬂag

Neuron activation function

Neuron input norm (synapsis func-
tion)

Option Table 8: Conﬁguration options for the MLP neural network. Values given are defaults. If predeﬁned
categories exist, the default category is marked by a ’*’. See Sec. 5.6.3 for a description of the network
architecture conﬁguration. The options in Option Table 1 can also be conﬁgured.

5.6.2 Description of the classiﬁers and their implementation

The behaviour of an artiﬁcial neural network is determined by the layout of the neurons,
the weights of the inter-neuron connections, and by the response of the neurons to the
input, described by neuron response function ρ.

5.6 Artiﬁcial Neural Networks (non-linear discriminants)

47

Input Layer

Hidden Layer

Output Layer

1x

2x

3x

4x

y1
1

y1
2

y1
3

y1
4

11w 1

12w 1

45w 1

05w 1

y2
1

y2
2

y2
3

y2
4

y2
5

11w 2

51w 2

01w 2

Bias

1

Bias

1

y3
1

yANN

Figure 10: Multilayer perceptron with one hidden layer.

Multilayer Perceptron

While in principle a neural network with n neurons can have n2 directional connections,
the complexity can be reduced by organizing the neurons in layers and only allowing
directional connections from one layer to the immediate next one (see Fig. 10). This
kind of neural network is termed multilayer perceptron; all neural net implementations in
TMVA are of this type. The ﬁrst layer of a multilayer perceptron is the input layer, the
last one the output layer, and all others are hidden layers. For a classiﬁcation problem
with nvar input variables and 2 output classes the input layer consists of nvar neurons that
hold the input values, x1, . . . , xnvar, and one neuron in the output layer that holds the
output variable, the neural net estimator yANN.19 Each directional connection between
the output of one neuron and the input of another has an associated weight. The value
of the output neuron is multiplied with the weight to be used as input value for the next
neuron.

Neuron response function

The neuron response function ρ maps the neuron input i1, . . . , in onto the neuron output
n
(Fig. 11). Often it can be separated into a
R
neuron activation function α, so that ρ = α

7→ R
R 7→ R
κ. The functions κ and α can have the

synapsis function κ, and a

◦

19If two output neurons were used in the output layer, one for signal and the other for background, their

output values would be yANN and 1 − yANN, respectively.

5.6 Artiﬁcial Neural Networks (non-linear discriminants)

48

Input
wl−1
1j
wl−1
2j

wl−1
nj

yl−1
1
yl−1
2
.
..
yl−1
n

Output

Σ

yl
j

ρ

w(ℓ)

0j +

i w(ℓ)
y(ℓ)

ij

Sum

n

i=1
n
P

i=1
n
P
i=1 |
P

w(ℓ)

0j +

w(ℓ)

0j +

2

i w(ℓ)
y(ℓ)

ij

(cid:17)

(cid:16)
i w(ℓ)
y(ℓ)
ij |

x

Linear

Sigmoid

1
1 + e−kx
e−x
ex
ex + e−x Tanh
e−x2/2
Radial

−











Figure 11: Single neuron j in layer ℓ with n input connections. The incoming connections carry a weight
of w(l−1)

.

ij

following forms:

κ : (y(ℓ)

1 , .., y(ℓ)
n |

0j , .., w(ℓ)
w(ℓ)
nj )

→

Sum of squares

(21)

Sum of absolutes

α : x

→

(22)

5.6.3 Network architecture

The number of hidden layers in a network and the number of neurons in these layers are
conﬁgurable via the option HiddenLayers. For example the conﬁguration "HiddenLayers=
N-1,N+10:3" creates a network with three hidden layers, the ﬁrst hidden layer with nvar−
1
neurons, the second with nvar + 10 neurons, and the third with 3 neurons.

When building a network two rules should be kept in mind. The ﬁrst is the theorem by
Weierstrass ascertaining that for a multilayer perceptron a single hidden layer is suﬃcient
to approximate a given continuous correlation function to any precision, given an arbitrary
large number of neurons in the hidden layer. If the available computing power and the
size of the training data sample are suﬃcient, one can thus raise the number of neurons
in the hidden layer until the optimal performance is reached.

It is possible that the same performance can be reached with a network with more than
one hidden layer and a potentially much smaller total number of hidden neurons. This
would lead to a shorter training time and a more robust network.

5.6 Artiﬁcial Neural Networks (non-linear discriminants)

49

Training of the neural network

The most common algorithm for adjusting the weights that optimise the classiﬁcation
performance of a neural network is the so-called back propagation. It belongs to the family
of supervised learning methods, where the desired output for every input event is known.
Back propagation is used by all neural networks in TMVA. The output of a network (here
for simplicity assumed to have a single hidden layer with a Tanh activation function, and
a linear activation function in the output layer) is given by

nh

nh

nvar

yANN =

j w(2)
y(2)

j1 =

tanh

 

xiw(1)
ij

w(2)
j1 ,

! ·

(23)

Xj=1

Xj=1
where nvar and nh are the number of neurons in the input layer and in the hidden layer,
respectively, w(1)
is the weight between input-layer neuron i and hidden-layer neuron j,
ij
and w(2)
j1 is the weight between the hidden-layer neuron j and the output neuron. Simple
summation was used in Eq. (23) as synapsis function κ.

Xi=1

During the learning process the network is supplied with N training event tuples xa =
(x1, . . . , xnvar)a, a = 1, . . . , N . For each training event a the neural network output yANN,a
(1 for signal events and 0
is computed and compared to the desired output ˆya ∈ {
for background events). An error function E, measuring the agreement of the network
response with the desired one, is deﬁned by

1, 0
}

E(x1, . . . , xN |

w) =

Ea(xa|

w) =

(yANN,a −

ˆya)2 ,

(24)

N

a=1
X

1
2

N

a=1
X

where w denotes the ensemble of adjustable weights in the network. The set of weights
that minimizes the error function can be found using the method of steepest or gradient
descent, provided that the neuron response function is diﬀerentiable with respect to the
input weights. Starting from a random set of weights w(ρ) the weights are updated by
∇wE where E decreases most
moving a small distance in w-space into the direction
rapidly

−
η∇wE ,

−
where the positive number η is the learning rate.

w(ρ+1) = w(ρ)

The weights connected with the output layer are updated by

N

N

∆w(2)

j1 =

η

−

=

η

−

(yANN,a −

ˆya) y(2)
j,a ,

∂Ea
∂w(2)
j1

a=1
X
and the weights connected with the hidden layers are updated by

a=1
X

(25)

(26)

∆w(1)

ij =

η

−

=

η

−

(yANN,a −

ˆya) y(2)

j,a (1

j,a )w(2)
y(2)

j1 xi,a ,

−

(27)

N

a=1
X

∂Ea
∂w(1)
ij

N

a=1
X

5.7 Boosted Decision Trees

50

where we have used tanh′ x = tanh x(1
tanh x). This method of training the network is
denoted bulk learning, since the sum of errors of all training events is used to update the
weights. An alternative choice is the so-called online learning, where the update of the
weights occurs at each event. The weight updates are obtained from Eqs. (26) and (27)
by removing the event summations. In this case it is important to use a well randomized
training sample. Online learning is the learning method implemented in TMVA.

−

5.6.4 Ranking

The MLP neural network implements a variable ranking based on the sum of the weights-
squared of the connections that leave the variable input neuron. The importance Ii of the
input variable i is given by

nh

Ii = x2
i

w(1)
ij

2

,

Xj=1 (cid:16)

(cid:17)

i = 1, . . . , nvar ,

(28)

where xi is the sample mean of input variable i.

5.6.5 Performance

In the tests we have carried out so far, the MLP and ROOT networks performed equally
well, with however a clear speed advantage for the MLP. The Clermont-Ferrand neural
net exhibited worse classiﬁcation performance in these tests, which is partly due to the
slow convergence of its training (at least 10k training cycles are required to achieve ap-
proximately competitive results).

5.7 Boosted Decision Trees

A decision tree is a binary tree structured classiﬁer like the one sketched in Fig. 12.
Repeated left/right (yes/no) decisions are performed on a single variable at a time until
some stop criterion is reached. Like this the phase space is split into regions that are
eventually classiﬁed as signal or background, depending on the majority of training events
that end up in the ﬁnal leaf nodes. The boosting of a decision tree (BDT) represents an
extension to a single decision tree. Several decision trees (a forest), derived from the same
training sample by reweighting events, are combined to form a classiﬁer which is given by a
(weighted) majority vote of the individual decision trees. Boosting stabilizes the response
of the decision trees with respect to ﬂuctuations in the training sample.

5.7.1 Booking options

The BDT classiﬁer is booked via the command:

5.7 Boosted Decision Trees

51

Figure 12: Schematic view of a decision tree. Starting from the root node, a sequence of binary splits
using the discriminating variables xi is performed. Each split uses the variable that at this node gives the
best separation between signal and background when being cut on. The same variable may thus be used
at several nodes, while others might not be used at all. The leaf nodes at the bottom end of the tree are
labeled “S” for signal and “B” for background depending on the majority of events that end up in the
respective nodes.

factory->BookMethod( Types::kBDT, "BDT", "<options>" );

Code Example 31: Booking of the BDT classiﬁer: the ﬁrst argument is a predeﬁned enumerator, the
second argument is a user-deﬁned string identiﬁer, and the third argument is the conﬁguration options
string. See Sec. 3.1.4 for more information on the booking.

Several conﬁguration options are available to customize the BDT classiﬁer. They are
summarized in Option Table 9 and explained in more detail in Sec. 5.7.2.

5.7 Boosted Decision Trees

52

Option

nTrees

Values

200

BoostType

AdaBoost*, Bagging

SeparationType

GiniIndex*,
MisClassificationError,
CrossEntropy,
SDivSqrtSPlusB

nEventsMin:

nCuts:

10

20

UseYesNoLeaf

True

UseWeightedTrees

True

PruneMethod

CostComplexity*,
ExpectedError

PruneStrength

5

Description

Number of trees in the forest

Boosting type for
building

successive tree

Separation criterion applied for the
node splitting

Minimum number of events in a node
where further splitting is stopped

Number of steps in the scan to opti-
mise the cut at a node

Use simple Yes/No decision from leaf
node or (if Falsex) use the train-
ing leaf purity as a signal/background
weight

Use a weighted (e.g., ln(boost-weight)
from AdaBoost) or unweighted ma-
jority vote of all trees in the forest

Pruning method

A parameter to adjust the amount of
pruning.
It should be large enough
such that overtraining is avoided and
needs to be tuned for each analysis
individually.
If it is set to a nega-
tive value, an algorithm searches for
the optimal prune strength (not nec-
essarily reliable)

Option Table 9: Conﬁguration options for the BDT classiﬁer. Values given are defaults.
If predeﬁned
categories exist, the default category is marked by a ’*’. The common options in Option Table 1 can also
be conﬁgured.

5.7.2 Description of the classiﬁer and its implementation

Decision trees are well known classiﬁers that allow straightforward interpretation as they
can be visualized by a simple two dimensional tree structure. They are in this respect
similar to rectangular cuts. However, whereas a cut-based analysis is able to select only
one hypercube as region of phase space, the decision tree is able to split the phase space
into a large number of hypercubes, each of which is identiﬁed as either “signal-like” or
“background-like”. The path down the tree to each leaf node represents an individual cut
sequence that selects signal or background depending on the type of the leaf node.

5.7 Boosted Decision Trees

53

A shortcoming of decision trees is their instability with respect to statistical ﬂuctuations
in the training sample from which the tree structure is derived. For example, if two input
variables exhibit similar separation power, a ﬂuctuation in the training sample may cause
the tree growing algorithm to decide to split on one variable, while the other variable
could have been selected without that ﬂuctuation. In such a case the whole tree structure
is altered below this node, possibly resulting also in a substantially diﬀerent classiﬁer
response.

This problem is overcome by constructing a forest of decision trees and classifying an
event on a majority vote of the classiﬁcations done by each tree in the forest. All trees in
the forest are derived from the same training sample, with the events being subsequently
subjected to so-called boosting, a procedure which modiﬁes their weights in the sample.
Boosting increases the statistical stability of the classiﬁer and typically also improves the
separation performance compared to a single decision tree. However, the advantage of the
straightforward interpretation of the decision tree is lost. While one can of course still
look at a limited number of trees trying to interprete the training result, one will hardly
be able to do so for hundreds of trees in a forest. Nevertheless, the general structure of the
selection can already be understood by looking at a limited number of individual trees.

Boosting

Boosting is a general procedure whose application is not limited to decision trees. The
same classiﬁer is trained several times using a successively boosted (reweighted) training
event sample. The ﬁnal classiﬁer is then derived from the combination of all the individual
classiﬁers. The most popular boosting algorithm is the so-called AdaBoost [16] (adaptive
boost), where events that were misclassiﬁed during the training of a tree are given a
higher event weight in the training of the next following tree. Starting with the original
event weights when training the ﬁrst decision tree, the subsequent tree is trained using a
modiﬁed event sample where the weights of previously misclassiﬁed events are multiplied
by a common boost weight α. The boost weight is derived from the misclassiﬁcation rate
err of the previous tree,

α =

1

err

−
err

.

The entire event sample is then renormalised to keep the total number of events (sum of
weights) in a tree constant.

With the result of an individual tree h(x) (x being the tuple of input variables) encoded for
signal and background as h(x) = +1 and
1, respectively, the resulting event classiﬁcation
yBDT(x) for the boosted classiﬁer is then given by

−

(29)

(30)

yBDT(x
¯

) =

ln(αi)

hi(x) ,

·

Xi∈forest

where the sum is over all trees in the forest. Small (large) values for yBDT(x) indicate a
background-like (signal-like) event. Equation (30) is the default BDT boosting. It can be
altered using the option UseWeightedTrees=False for which the yBDT(x) is computed as

5.7 Boosted Decision Trees

54

the average of the individual trees without the weighting factors ln(αi).

Another possible modiﬁcation of Eq. (30) is to use the training purity20 in the leaf node as
respectively signal or background weights rather than relying on the binary decision. This
option is chosen by setting the option UseYesNoLeaf=False. Such an approach however
should be adopted with care as the purity in the leaf nodes is sensitive to overtraining and
therefore typically overestimated. Tests performed so far with this option did not show
signiﬁcant performance increase. Further studies together with tree pruning are needed
to better understand the behaviour of the purity-weighted BDTs.

The other boosting technique implemented in TMVA is a resampling technique, sometimes
referred to as bagging. It is selected via the BoostType option. The resampling is done with
replacement, which means that the same event is allowed to be (randomly) picked several
times from the parent sample. This is equivalent to regarding the training sample as being
a representation of the probability density distribution of the parent event ensemble. If
one draws an event out of this ensemble, it is more likely to draw an event from a region
of phase-space that has a high cross section, as the original Monte Carlo sample will have
more events in that region.
If a selected event is kept in the original sample (that is
when the same event can be selected several times), the parent sample remains unchanged
so that the randomly extracted samples will have the same parent distribution, albeit
statistically ﬂuctuated. Training several decision trees with diﬀerent resampled training
data and combining them into a forest results in an averaged classiﬁer that, just as for
boosting, is more stable with respect to statistical ﬂuctuations in the training sample.
Technically the resampling is implemented by applying random weights to each event of
the parent sample.

Training (Building) a decision tree

The training, building or growing of a decision tree is the process that deﬁnes the splitting
criteria for each node. The training starts with the root node, where an initial splitting
criterion for the full training sample is determined. The split results in two subsets of
training events that each go through the same algorithm of determining the next splitting
iteration. This procedure is repeated until the whole tree is built. At each node, the
split is determined by ﬁnding the variable and corresponding cut value that provides the
best separation between signal and background. The node splitting is stopped once it has
reached the minimum number of events which is speciﬁed in the BDT conﬁguration. The
end- or leaf nodes are classiﬁed as signal or background according to the class the majority
of events belongs to.

A variety of separation criteria can be conﬁgured to assess the performance of a variable
and a speciﬁc cut requirement. Because a cut that selects predominantly background is
as valuable as one that selects signal, the criteria are symmetric with respect to the event
classes. All separation criteria have a maximum where the samples are fully mixed, i.e.,

20The purity of a node is given by the ratio of signal events to all events in that node. Hence pure

background nodes have zero purity.

5.7 Boosted Decision Trees

55

at purity p = 0.5, and fall oﬀ to zero when the sample consists of one event class only.
Tests have revealed no signiﬁcant performance disparity between the following separation
criteria:

Gini Index [default], deﬁned by p

(1

p).

Cross entropy, deﬁned by

Misclassiﬁcation error, deﬁned by 1

·
ln(p)

−
(1

p

−

·

p)

ln(1

p).

−
·
max(p, 1

−
p).

−

−

−

Statistical signiﬁcance, deﬁned by S/√S + B.

The splitting criterion being always a cut on a single variable, the training procedure
selects the variable and cut value that optimises the increase in the separation index
between the parent node and the sum of the indices of the two daughter nodes, weighted
by their relative fraction of events. The cut values are optimised by scanning over the
variable range with a granularity that is set via the option nCuts. The default value of
nCuts=20 proved to be a good compromise between computing time and step size. Finer
stepping values did not increase noticeably the performance of the BDTs.

In principle, the splitting could continue until each leaf node contains only signal or only
background events, which could suggest that perfect discrimination is achievable. However,
such a decision tree would be strongly overtrained. To avoid overtraining a decision tree
must be pruned.

Pruning a decision tree

Pruning is the process of cutting back a tree from the bottom up after it has been built
to its maximum size. Its purpose is to remove statistically insigniﬁcant nodes and thus
reduce the overtraining of the tree. It has been found to be beneﬁcial to ﬁrst grow the tree
to its maximum size and then cut back, rather than interrupting the node splitting at an
earlier stage. This is because apparently insigniﬁcant splits can nevertheless lead to good
splits further down the tree. TMVA currently implements two tree pruning algorithms.

For the expected error pruning [17] all leaf nodes for which the statistical error esti-
mates of the parent nodes are smaller than the combined statistical error estimates
of their daughter nodes are recursively deleted. The statistical error estimate of each
p)/N , where N is the number
node is calculated using the binomial error
of training events in the node and p its purity. The amount of pruning is controlled
by multiplying the error estimate by the fudge factor PruneStrength.

p

(1

−

p

·

Cost complexity pruning [18] relates the number of nodes in a subtree below a node
to the gain in terms of misclassiﬁed training events by the subtree compared the the
node itself with no further splitting. The cost estimate R chosen for the misclassiﬁ-
cation of training events is given by the misclassiﬁcation rate 1
p) in a
node. The cost complexity for this node is then deﬁned by

max(p, 1

−

−

ρ =

R(node)
#nodes(subtree below that node)

R(subtree below that node)
1

−

.

−

(31)

•

•

•

•

•

•

5.7 Boosted Decision Trees

56

The node with the smallest ρ value in the tree is recursively pruned away as long as
ρ < PruneStrength.

Note that the pruning is performed after the boosting so that the error fraction used by
AdaBoost is derived from the unpruned tree.

If the PruneStrength option is set to a negative value, an algorithm attempts to auto-
matically detect the optimal strength parameter. The training sample is divided into two
subsamples, of which only one is used for training, while the other one serves for vali-
dation. Starting with a small value, the prune strength is increased until the maximum
performance of the decision tree is reached on the validation sample. This is done for each
tree individually. Because of statistical ﬂuctuations the performance may not appear as a
smooth function of the prune strength, which could lead to inaccurate optimisation if the
validation sample is too small.

5.7.3 Ranking

A ranking of the BDT input variables is derived by counting how often the variables are
used to split decision tree nodes, and by weighting each split occurrence by the separation
gain-squared it has achieved and by the number of events in the node [18]. This measure
of the variable importance can be used for a single decision tree as well as for a forest.

5.7.4 Performance

Only limited experience has been gained so far with boosted decision trees in HEP. In the
literature decision trees are sometimes referred to as the best “out of the box” classiﬁers.
This is because little tuning is required in order to obtain reasonably good results. This is
due to the simplicity of the method where each training step (node splitting) involves only
a one-dimensional cut optimisation. Decision trees are also insensitive to the inclusion of
poorly discriminating input variables. While for artiﬁcial neural networks it is typically
more diﬃcult to deal with such additional variables, the decision tree training algorithm
will basically ignore non discriminating variables as for each node splitting only the best
discriminating variable is used. However, the simplicity of decision trees has the drawback
that their theoretically best performance on a given problem is generally inferior to other
techniques like neural networks. This is seen for example using the academic training sam-
ples included in the TMVA package. For this sample, which has equal RMS but shifted
mean values for signal and background and linear correlations between the variables only,
the Fischer discriminant provides theoretically optimal discrimination results. While the
artiﬁcial neural networks are able to reproduce this optimal selection performance the
BDTs always fall short in doing so. However, in other academic examples with more com-
plex correlations or real life examples, the BDTs often outperform the other techniques.
This is because either there are not enough training events available that would be needed
by the other classiﬁers, or the optimal conﬁguration (i.e. how many hidden layers, which
variables) of the neural network has not been speciﬁed.

5.8 Predictive learning via rule ensembles

57

5.8 Predictive learning via rule ensembles

This classiﬁer is a TMVA implementation of Friedman-Popscus’ RuleFit method described
in [19]. Its idea is to use an ensemble of so-called rules to create a scoring function with
good classiﬁcation power. Each rule ri is deﬁned by a sequence of cuts, such as

r1(x) = I(x2 < 100.0)
r2(x) = I(0.45 < x4 < 1.00)
r3(x) = I(x3 < 11.00) ,

·

·

I(x3 > 35.0) ,

I(x1 > 150.0) ,

where the xi are discriminating input variables, and I(. . . ) returns the truth of its argu-
ment. A rule applied on a given event is non-zero only if all of its cuts are satisﬁed, in
which case the rule returns 1.

The easiest way to create an ensemble of rules is to extract it from a forest of decision trees
(cf. Sec. 5.7). Every node in a tree (except the root node) corresponds to a sequence of
cuts required to reach the node from the root node, and can be regarded as a rule. Hence
for the tree illustrated in Fig. 12 a total of 8 rules can be formed. Linear combinations
of the rules in the ensemble are created with coeﬃcients (rule weights) calculated using
a regularised minimisation procedure [20]. The resulting linear combination of all rules
deﬁnes a score function (see below) which provides the RuleFit response yRF(x).

In some cases a very large rule ensemble is required to obtain a competitive discrimination
between signal and background. A particularly diﬃcult situation is when the true (but
unknown) scoring function is described by a linear combination of the input variables. In
such cases, e.g., a Fischer discriminant would perform well. To ease the rule optimisation
task, a linear combination of the input variables is added to the model. The minimisation
procedure will then select the appropriate coeﬃcients for the rules and the linear terms.
More details are given in Sec. 5.8.2 below.

5.8.1 Booking options

The RuleFit classiﬁer is booked via the command:

factory->BookMethod( Types::kRuleFit, "RuleFit", "<options>" );

Code Example 32: Booking of RuleFit: the ﬁrst argument is a predeﬁned enumerator, the second argument
is a user-deﬁned string identiﬁer, and the third argument is the conﬁguration options string. See Sec. 3.1.4
for more information on the booking.

The RuleFit conﬁguration options are given in Option Table 5.8.1.

5.8.2 Description of the classiﬁer and its implementation

As for all TMVA classiﬁers, the goal of the rule learning is to ﬁnd a classiﬁcation function
yRF(x) that optimally classiﬁes an event according to the tuple of input observations

5.8 Predictive learning via rule ensembles

58

Option

Model

Values

Description

ModRuleLinear*, ModRule,
ModLinear

This option controls whether rules
and/or linear terms are to be included

LinQuantile

0.025

MinImp

0.01

RuleMaxDist

0.001

SampleFraction

-1

nTrees

nCuts

SeparationType

GiniIndex*,
MisClassificationError,
CrossEntropy,
SDivSqrtSPlusB

-1

20

0.1

0.9

0.6

0.0

1.0

1

200

0.01

10000

1.1

EventsMin

EventsMax

GDTau

GDTauMin

GDTauMax

GDNTau

GDTauScan

GDStep

GDNSteps

GDErrScale

Concerns only the linear terms and
deﬁnes a region outside which a vari-
able is regarded as an outlier; a quan-
tile of zero retains all values

Minimum relative importance ac-
cepted in the ﬁnal model

Minimum “rule distance” allowed; re-
moves similar rules; if zero, all rules
are kept

Event fraction used to train each tree;
if < 0, the fraction is calculated using
Eq. (36)

Number of trees in forest; for further
description of this and the following
three options, see Option Table 9

Scan depths of node cut optimisation

Separation criterion for node splitting

Minimum fraction giving the mini-
mum number of events in a node
where further splitting is stopped

Ditto, maximum fraction

Minimisation ﬁt threshold; used only
if the tau scan range is empty; for the
deﬁnition of tau, see Sec. 5.8.2

Minimum tau in scan

Maximum tau in scan

Number of tau; if < 2, GDTau is used

Number of points to scan for best tau
along path

Step size along the path

Maximum number of steps

Threshold for error-rate (always

1)

≥

Option Table 10: Conﬁguration options for RuleFit. Values given are defaults. If predeﬁned categories
exist, the default category is marked by a ’*’. The options in Option Table 1 can also be conﬁgured.

59

(32)

(33)

(34)

5.8 Predictive learning via rule ensembles

(variables) x. The classiﬁcation function is written as

yRF(x) = a0 +

amfm(x) ,

MR

m=1
X

fm(x)
{

where the set
}MR forms an ensemble of base learners with MR elements. A base
learner may be any discriminating function derived from the training data. In our case,
they consist of rules and linear terms as described in the introduction. The complete
model then reads

To protect against outliers, the variables in the linear terms are modiﬁed to

yRF(x) = a0 +

amrm(x) +

bixi .

MR

m=1
X

nvar

Xi=1

i = min(δ+
x′

i , max(δ−

i )) ,

where δ±
i are the lower and upper β quantiles of the variable xi. If the variables are used
“as is”, they may have an unequal a priori inﬂuence relative to the rules. To counter this
eﬀect, the variables are normalised

σr ·
where σr and σi are the estimated standard deviations of an ensemble of rules and the
variable x′

(35)

i, respectively.

x′
i →

x′
i/σi ,

Rule generation

The rules are extracted from a random forest of decision trees. There are several ways
to generate a forest. In the current RuleFit implementation it is generated from random
subsamples of the training data. Each tree in a forest is generated using a given fraction
(SampleFraction) of the training sample.21 If the user gives a fraction
0, the fraction
is calculated from the training sample size N (signal and background) using the empirical
formula [21]

≤

f = min(0.5, (100.0 + 6.0

√N )/N ) .

·

(36)

The topology of each tree is controlled by the conﬁguration parameters EventsMin, EventsMax,
nCuts and SeparationType, the last two of which are described in Sec. 5.7. The ﬁrst two
parameters deﬁne a range of fractions which are used to calculate the minimum number
of events in a node required for further splitting. For each tree, a fraction is drawn from a
uniform distribution within the given range. The obtained fraction is then multiplied with
the number of training events used for the tree, giving the minimum number of events in
a node to allow for splitting. In this way both large trees (small fraction) giving complex

21Since both the number of trees and the sample fractions are free parameters, the subsamples used
per tree will overlap if the number of trees is greater than 1/SampleFraction. By setting nTrees=-1,
the maximum number of trees allowed without overlapping will be selected. In the output, it is printed
whether the subsets are overlapping or not.

5.8 Predictive learning via rule ensembles

rules and small trees (large fraction) for simple rules are created. For a given forest of Nt
trees, where each tree has nℓ leaf nodes, the maximum number of possible rules is

Nt

MR,max =

2(nℓ,i −

1) .

Xi=1
To prune similar rules, a distance is deﬁned between two topologically equal rules. Two
rules are topologically equal if their cut sequences follow the same variables only diﬀering
in their cut values. The rule distance is then deﬁned by

δ2
i,L + δ2
i,U
σ2
i

,

δ2
R =

Xi

where δi,L(U ) is the diﬀerence in lower (upper) limit between the two cuts containing the
variable xi, i = 1, . . . , nvar. The diﬀerence is normalised to the RMS-squared σ2
i of the
variable. Similar rules with a distance smaller than RuleMinDist are removed from the
rule ensemble. The parameter can be tuned to improve speed and to suppress noise.
However, the cut should be used with care since a too large cut value will deplete the rule
ensemble and weaken its classiﬁcation performance.

Fitting

Once the rules are deﬁned, the coeﬃcients in Eq. (33) are ﬁtted using the training data.
For details, the ﬁtting method is described in [20]. A brief description is provided below
to motivate the corresponding RuleFit options.

A loss function L(yRF(x)
ˆy), given by the “squared-error ramp” [20]
|

L(yRF|

ˆy) = (ˆy

−

H(yRF))2 ,

where H(y) = max(
1, min(yRF, 1)), quantiﬁes the “cost” of misclassifying an event of
given true class ˆy. The risk R is deﬁned by the expectation value of L with respect to x
and the true class. Since the true distributions are generally not known, the average of N
training events is used as an estimate

−

R =

1
N

N

Xi=1

L(yRF(xi)
ˆyi) .
|

a(ǫ + δǫ) = a(ǫ) + δǫ

g(ǫ) ,

·

A line element in the parameter space of the rule weights (given by the vector a of all
coeﬃcients) is then deﬁned by

where δǫ is a positive small increment and g(ǫ) is the negative derivative of the estimated
risk R, evaluated at a(ǫ). The estimated risk-gradient is evaluated using a sub-sample
(Eq. 36) of the training events.

60

(37)

(38)

(39)

(40)

(41)

5.8 Predictive learning via rule ensembles

61

a1

Best point

τ(1)

τ(2)

*

τ(3)

a

2

Figure 13: An example of a path scan in two dimensions. Each point represents an ǫ in Eq. (41) and each
step is given by δǫ. The direction along the path at each point is given by the vector g. For the ﬁrst
few points, the paths τ (1, 2, 3) are created with diﬀerent values of τ . After a given number of steps, the
best path is chosen and the search is continued. It stops when the best point is found. That is, when the
estimated error-rate is minimum.

Starting with all weights set to zero, the consecutive application of Eq. (41) creates a path
in the a space. At each step, the procedure selects only the gradients gk with absolute
values greater than a certain fraction (τ ) of the largest gradient. The fraction τ is an
a priori unknown quantity between 0 and 1. The value τ = 0 implies that at each
step on the path all gradients are used, while only the strongest gradient is selected for
It is possible to automatically estimate the appropriate τ by means of a scan.
τ = 1.
To do so, several paths (GDNTau) with diﬀerent fractions (range GDTauMin, GDTauMax)
are initially scanned for a certain number of points (GDTauScan), and the path with the
best performance is selected. The step size and the number of points along the paths are
given by the options GDStep and GDNSteps. After every 100 steps, the performance is
estimated using the area under the curve of background rejection versus signal eﬃciency.
The area is evaluated using the events not used in the calculation of the path (one-fold
cross validation). The stepping along the path is stopped when the error rate e = 1
area
is larger than (GDErrScale
min e) and the point giving the minimum error rate is selected.
A simple example with a few scan points is illustrated in Fig. 13.

−

·

5.8.3 Ranking

Since the input variables are normalised, the ranking of variables follows naturally from the
coeﬃcients of the model. To each rule m (m = 1, . . . , MR) can be assigned an importance
deﬁned by

Im =

am|
|

sm(1.0

sm) ,

−

p

(42)

5.8 Predictive learning via rule ensembles

62

(43)

(44)

(45)

where sm is the support of the rule with the following deﬁnition

sm =

rm(xn) .

N

1
N

n=1
X
The support is thus the average response for a given rule on the data sample. A large
support implies that many events pass the cuts of the rule. Hence, such rules cannot have
strong discriminating power. On the other hand, rules with small support only accept
few events. They may be important for these few events they accept, but they are not in
the overall picture. The deﬁnition (42) for the rule importance suppresses rules with both
large and small support.

For the linear terms, the deﬁnition of importance is

Ii =

bi| ·
|

σi ,

so that variables with small overall variation will be assigned a small importance.

A measure of the variable importance may then be deﬁned by

Ji = Ii +

Im/qm ,

Xm|xi∈rm
where the sum is over all rules containing the variable xi, and qm is the number of variables
used in the rule rm. This is introduced in order to share the importance equally between
all variables in rules with more than one variable.

5.8.4 Performance

Rule ensemble based learning machines are not yet well known within the HEP community,
although they start to receive some attention [22]. Apart from RuleFit [19] other rule
ensemble learners exists, such as SLIPPER [23].

The TMVA implementation of RuleFit follows closely the original design described in
Ref. [19]. Currently the performance is however slightly less robust than the one of the
Friedman-Popescu package. Also, the experience using the method is still scarce at the
time of this writing.

To optimise the performance of RuleFit several strategies can be employed. The training
consists of two steps, rule generation and rule ensemble ﬁtting. One approach is to modify
the complexity of the generated rule ensemble by changing either the number of trees in
the forest, or the complexity of each tree. In general, large tree ensembles with varying
trees sizes perform better than short noncomplex ones. The drawback is of course that
ﬁtting becomes slow. However, if the ﬁtting performs well, it is likely that a large amount
of rules will have small or zero coeﬃcients. These can be removed, thus simplifying the
ensemble. The ﬁtting performance can be improved by increasing the number of steps
along with using a smaller step size. Again, this will be at the cost of speed performance

63

although only at the training stage. The setting for the parameter τ may greatly aﬀect
the result. Testing with extreme values (close to 0 or 1), will give a feeling for what is a
good choice for the given sample. The optimum value will diﬀer with the training sample,
so that initially the user is advised to use the automatic scan option to derive the best
path.

6 Summary and Plans

TMVA is a toolkit that uniﬁes highly customizable multivariate classiﬁcation algorithms
in a single framework thus ensuring convenient use and an objective performance assess-
ment. It is designed for data mining applications in high-energy physics, but not restricted
to these. Source code and library of TMVA-v.3.5.0 and higher versions are part of the
standard ROOT distribution kit (v5.14 and higher). The newest TMVA development ver-
sion can be downloaded from Sourceforge.net at http://tmva.sf.net.

This manual introduced the main steps allowing a user to optimise and perform her/his
own multivariate analysis. Let us recall the main features of the TMVA design and pur-
pose:

TMVA works in transparent factory mode to allow an unbiased performance assess-
ment and comparison: all classiﬁers see the same training and test data, and are
evaluated following the same prescription.

A complete TMVA analysis consists of two steps:

1. Training: the ensemble of available and optimally multivariate customized
classiﬁers are trained and tested on independent signal and background data
samples; the classiﬁers are evaluated and the most performing and concise ones
are selected.

2. Application: selected trained classiﬁers are used for the classiﬁcation of data

samples with unknown signal and background composition.

A Factory class object created by the user organises the customization and interac-
tion with the classiﬁers for the training, testing and evaluation phases of the TMVA
analysis. The training results together with the conﬁguration of the classiﬁers are
written to result (“weight”) ﬁles.

Standardized outputs during the Factory running, and dedicated ROOT macros
allow a reﬁned assessment of each classiﬁer’s behaviour and performance.

Once appropriate classiﬁers have been chosen by the user, they can be applied to
data samples with unknown classiﬁcation. Here, the interaction with the classiﬁers
occurs through a Reader class object created by the user. A classiﬁer is booked
by giving the path to its weight ﬁle resulting from the training stage. Then, inside
the user’s event loop, the MVA response is returned by the Reader for each of the
booked classiﬁers, as a function of the event values of the discriminating variables

•

•

•

•

•

64

used as input for the classiﬁers. Alternatively, the user may request from the Reader
the probability that a given event belongs to the signal hypothesis.

We give below a summary of the TMVA classiﬁers, outlining the current state of their
implementation, their advantages and shortcomings.

•

•

•

•

•

•

•

Rectangular Cut Optimisation
The current implementation is rather advanced. It includes speed-optimised range
searches using binary trees, and three optimisation algorithms: Monte Carlo sam-
pling, a Genetic Algorithm and Simulated Annealing. In spite of these tools, optimis-
ing the cuts for a large number of discriminating variables remains challenging. The
user is advised to reduce the available dimensions to the most signiﬁcant variables
(e.g., using a principal component analysis) prior to optimising the cuts.

Likelihood
Automatic PDF building through histogram smoothing and approximation with
various spline functions and kernel density estimators is implemented.

PDERS
The multidimensional likelihood approach is in an advanced development stage pro-
viding several kernel estimation methods, and speed optimised range search using
event sorting in binary trees.

Fisher and H-Matrix
These are mature algorithms. The Fisher discriminant is linear only in the present
implementation. The addition of higher-order moments is considered.

Artiﬁcial Neural Networks
Signiﬁcant work went into the implementation of fast feed-forward multilayer per-
ceptron algorithms into TMVA. Two external ANNs have been integrated as fully
independent methods, and another one has been newly developed for TMVA, with
emphasis on ﬂexibility and speed. The performance of the latter ANN (MLP) has
been cross checked against the Stuttgart ANN (using as an example τ identiﬁcation
in ATLAS), and was found to achieve competitive performance.

Boosted Decision Trees
The BDT implementation has received constant attention over the full year of its
development. The current version includes additional features like bagging, and
manual or automatic node pruning.

RuleFit
The original libraries written by J. Friedman are publicly available, but not the
source code. We have therefore decided to attempt an independent implementa-
tion of this powerful classiﬁcation approach. The current version achieves almost
equivalent results, with however usually somewhat better robustness for the original
implementation.

65

Although TMVA has reached a mature status and has been well tested by many users,
there exist limitations that will be worked on for future releases. In particular, the present
setup does not allow an unequal number of training events for signal and background. The
reason for this restriction is that not all classiﬁers yet properly handle event weights that
deviate from one (though the majority of the classiﬁers does).

The current emphasis of the TMVA core developments lies on the consolidation and further
improvement of the existing classiﬁers and of the TMVA framework.
In spite of that
new classiﬁers are under development. Among these are: a Support Vector Machine,
Bayesian classiﬁers, and a Committee classiﬁer, building weighted rules out of arbitrary
combinations of TMVA classiﬁers.

Acknowledgments

The fast development of TMVA would not have been possible without the contribution and feedback
from many developers and users to whom we are indebted. We thank in particular the CERN Summer
students Matt Jachowski (Stanford) for the implementation of TMVA’s new MLP neural network, and
Yair Mahalalel (Tel Aviv) for a signiﬁcant improvement of PDERS. We are grateful to Doug Applegate,
Kregg Arms, Ren´e Brun and the ROOT team, Tancredi Carli, Elzbieta Richter-Was, Vincent Tisserand
and Marcin Wolter for helpful conversations.

A Classiﬁer booking

Code Example 33 gives a collection of classiﬁer bookings together with useful default
options. These bookings can also be found in the example training job TMVAnalysis.C.

66

factory->BookMethod( TMVA::Types::kCuts, "Cuts",

"MC:EffSel:MC_NRandCuts=100000:AllFSmart" );

factory->BookMethod( TMVA::Types::kLikelihood, "Likelihood",

"!TransformOutput:Spline=2:NSmooth=5" );

factory->BookMethod( TMVA::Types::kLikelihood, "LikelihoodD",

"!TransformOutput:Spline=2:NSmooth=5:Preprocess=Decorrelate" );

factory->BookMethod( TMVA::Types::kFisher, "Fisher", "!V:Fisher" );

factory->BookMethod( TMVA::Types::kMLP, "MLP",

"!V:NCycles=200:HiddenLayers=N+1,N:TestRate=5" );

factory->BookMethod( TMVA::Types::kPDERS, "PDERS",

"!V:VolumeRangeMode=RMS:KernelEstimator=Teepee:\

MaxVIterations=50:InitialScale=0.99" );

factory->BookMethod( TMVA::Types::kBDT, "BDT",

"!V:NTrees=400:BoostType=AdaBoost:SeparationType=GiniIndex:

nEventsMin=20:nCuts=20:PruneMethod=CostComplexity:
PruneStrength=3.5:Preprocess=Decorrelate" );

factory->BookMethod( TMVA::Types::kRuleFit, "RuleFit",

"!V:NTrees=20:SampleFraction=-1:nEventsMin=60:nCuts=20:

MinImp=0.001:Model=ModLinear:GDTau=0.6:GDStep=0.01:
GDNSteps=100000:SeparationType=GiniIndex:RuleMaxDist=1e-5" );

Code Example 33: Examples for booking classiﬁers in TMVA. The ﬁrst argument is a unique type enu-
merator (the avaliable types can be looked up in src/Types.h), the second is a user-deﬁned name (must
be unique among all booked classiﬁers), and the third a conﬁguration option string that is speciﬁc to the
classiﬁer. For options that are not set in the string default values are used. The syntax of the options
should become clear from the above examples. Individual options are separated by a ’:’. Boolean variables
can be set either explicitly as MyBoolVar=True/False, or just via MyBoolVar/!MyBoolVar. All concrete
option variables are explained in Secs. 4 and 5.

REFERENCES

References

67

[1] J. Friedman, T. Hastie and R. Tibshirani, “The Elements of Statistical Learning”,

Springer Series in Statistics, 2001.

[2] A. Webb, “Statistical Pattern Recognition”, 2nd Edition, J. Wiley & Sons Ltd, 2002.

[3] L.I. Kuncheva, “Combining Pattern Classiﬁers”, J. Wiley & Sons, 2004.

[4] I. Narsky, “StatPatternRecognition: A C++ Package for Statistical Analysis of High

Energy Physics Data”, physics/0507143 (2005).

[5] The following web pages give information on available statistical
science:
HEP and other
http://astrostatistics.psu.edu/statcodes/.

in
https://plone4.fnal.gov:4430/P0/phystat/,

areas

tools

of

[6] The BABAR Physics Book, BABAR Collaboration (P.F. Harrison and H. Quinn
(editors) et al.), SLAC-R-0504 (1998); S. Versill´e, PhD Thesis at LPNHE,
http://lpnhe-babar.in2p3.fr/theses/these SophieVersille.ps.gz (1998).

[7] M. Pivk, “Etude de la violation de CP dans la d´esint´egration B0

h+h−
(h = π, K) aupr`es du d´etecteur BABAR `a SLAC”, PhD thesis (in French),
http://tel.archives-ouvertes.fr/documents/archives0/00/00/29/91/index fr.html (2003).

→

[8] R. Sedgewick, “Algorithms in C++”, Addison Wesley, Chapter 26, Boston, USA

[9] T. Carli and B. Koblitz, Nucl. Instrum. Meth. A501, 576-588 (2003);

[hep-

(1992).

ex/0211019].

[10] P.J.M. Van Laarhoven and E.H.L. Aart, “Simulated Annealing: Theory and Applica-

tion”, D. Reidel Publishing, Dordrecht, Holland, 1987.

[11] N. Metropolis, A.W. Rosenbluth, M.N. Rosenbluth, A.M. Teller and E. Teller, J.

Chem. Phys. 21, 6, 1087 (1953).

[12] 353QH twice smoothing algorithm, presented by J. Friedman in Proc. of the 1974

CERN School of Computing, Norway, Aug 11-24, 1974.

[13] D.W. Scott, “Multivariate Density Estimation, Theory, Practice, and Visualization”,

Wiley-Interscience, New York, 1992.

[14] R.A. Fisher, Annals Eugenics 7, 179 (1936).

[15] P.C. Mahalanobis, Proc. Nat. Inst. Sci. India, Part 2A, 49 (1936); P.C. Mahalanobis,
“On the generalized distance in statistics”, Proceedings of the National Institute of
Science, Calcutta, 12, 49 (1936).

[16] Y. Freund and R.E. Schapire, J. of Computer and System Science 55, 119 (1997).

68

REFERENCES

(1987).

[17] Y.R. Quinlan, “Simplifying Decision Trees”, Int. J. Man-Machine Studies, 28, 221

[18] L. Breiman, J. Friedman, R. Olshen and C. Stone, “Classiﬁcation and Regression

Trees”, Wadsworth (1984).

[19] J. Friedman and B.E. Popescu, “Predictive Learning via Rule Ensembles”, Technical

Report, Statistics Department, Stanford University, 2004.

[20] J. Friedman and B.E. Popescu, “Gradient Directed Regularization for Linear Regres-
sion and Classiﬁcation”, Technical Report, Statistics Department, Stanford Univer-
sity, 2003.

[21] RuleFit web site: http:/www-stat.stanford.edu/∼jhf/r-ruleﬁt/RuleFit help.html.

[22] J. Conrad and F. Tegenfeldt, JHEP 0607, 040 (2006); [hep-ph/0605106].

[23] W. Cohen and Y. Singer, Proceedings of the Sixteenth National Conference on Arti-

ﬁcial Intelligence (AAAI-99), 335, AAAI Press, 1999.

