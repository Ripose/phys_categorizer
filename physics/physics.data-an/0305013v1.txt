Multiscale Trend Analysis

Ilya Zaliapin ∗,
Andrei Gabrielov †, and
Vladimir Keilis-Borok‡

May 04, 2003

3
0
0
2
 
y
a
M
 
5
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
3
1
0
5
0
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

∗Institute of Geophysics and Planetary Physics, University of California, Los Angeles, USA, 90095-
1567, and International Institute of Earthquake Prediction Theory and Mathematical Geophysics, Rus-
sian Academy of Sciences, Moscow, Russia, E-mail: zal@ess.ucla.edu Phone: +10-310-8256115, Fax:
+10-310-2063051, corresponding author.

†Departments of Mathematics and Earth and Atmospheric Sciences, Purdue University, IN, USA.

E-mail: agabriel@math.purdue.edu

‡Institute of Geophysics and Planetary Physics and Department of Earth and Space Sciences, Univer-
sity of California, Los Angeles, USA, and International Institute of Earthquake Prediction Theory and
Mathematical Geophysics, Russian Academy of Sciences, Moscow, Russia, E-mail: vkb@ess.ucla.edu

1

Multiscale Trend Analysis

1

Abstract

We consider the problem of constructing optimal piecewise linear approxima-
tions for time series. An optimality criterion is formulated and on its base a com-
putationally eﬀective algorithm is constructed for decomposition of a time series
into a hierarchy of trends (local linear approximations) at diﬀerent scales. The top
of the hierarchy is the global linear approximation over the whole observational
interval, the bottom is the original time series. Each internal level of the hierarchy
corresponds to a piecewise linear approximation of analyzed series. Possible appli-
cations of the introduced Multiscale Trend Decomposition (MTD) go far beyond
the linear interpolation problem: This paper develops and illustrates methods of
self-aﬃne, hierarchical, and correlation analyses of time series based on the MTD.

1 Introduction and Motivation

The motivation for the Multiscale Trend Analysis (MTA) introduced in this paper
is to describe and analyze time series in terms of their observed trends (local linear
approximations).
Indeed, trends are the most intuitive feature of a time series: One
easily recognizes its upward and downward episodes and it seems natural to use them for
series description and analysis. Such a description is intrinsically multiscale since each
non-trivial process exhibits juxtaposition of trends of diﬀerent duration and steepness
depending on the observational scale.

The proposed analysis is based on piecewise linear approximations of the analyzed
time series. Such approximations unavoidably depend on the characteristic time scale of
the analysis and involve a tradeoﬀ between quality and detail. We formulate (see Section
2.3) an optimality criterion for a local piecewise linear approximation and use it in a
multiscale fashion to detect trends in a time series at all possible scales. Global piecewise
linear approximations can then be constructed from such local trends. A hierarchy formed
by the local trends is used for quantitative analysis.

The problem of piecewise interpolation of time series has been given signiﬁcant at-
tention in the context of image processing (see for example [1, 2, 3]). The focus was
on constructing an optimal piecewise linear approximation Lǫ(t) with minimal number
of segments for given error ǫ (deviation from the original signal). On the contrary, we
concentrate on ﬁnding a whole hierarchy of consecutively more detailed approximations.
MTA is data adaptive: it creates a natural partition of the observational time interval
uniquely linked to the trend structure of the analyzed series. This contrasts with more
conventional methods of self-aﬃne analysis, which commonly use dyadic, ternary, etc.
partition schemes independent of the series analyzed. On one hand, our analysis is deter-
ministic: we work with a single observed realization and look for its unique properties.
On the other hand, the overall statistics resulting from MTA allow one to make decisive
conclusions about the process in general.
Areas for application of MTA include:

Multiscale Trend Analysis

2

• Descriptive and exploratory data analysis. Computationally eﬀective trend decom-
position naturally complements a standard data miner’s toolbox. Conveniently,
MTA does not rely on any assumptions about the analyzed time series (e.g. sta-
tionarity or existence of higher moments).

• Self-aﬃne analysis. Particularly, MTA provides a way to extract local fractal prop-

erties of the processes.

• Hierarchical analysis. The key element of MTA is construction of a hierarchical tree
TX that represents the multiscale trend structure of the analyzed time series X(t).
As a result MTA allows one to analyze time series with methods borrowed from
the theory of hierarchical scaling complexities [8]. Particularly, Horton-Strahler
indexing provides a natural way to consider scaling laws for trends.

• Correlation analysis. MTA allows one to detect non-linear correlations, particularly
those caused by the presence of amplitude modulation and non-linear long-term
trends.

The paper is organized as follows: Section 2 introduces the basic notions and describes
the computational algorithm for Multiscale Trend Decomposition (MTD). Methods of
MTD-based self-aﬃne analysis comprise Section 3. Section 4 introduces hierarchical
analysis of time series. Correlation analysis is described in Section 5. Fractional Brownian
walks and Mandelbrot cascade measures are used to illustrate methods of Section 3 - 5.
Section 6 concludes.

2 Multiscale Trend Decomposition (MTD)

The core of the MTA is construction of a hierarchical tree TX that describes the
trend structure of a given time series X(t) . Trend is deﬁned here as a linear least square
approximation of X(t) at a subinterval of the observational time interval. The tree TX
is formed step-by-step, from the largest to the smallest scales: First, we determine the
longer trends, then look for the shorter and shorter trends against the background of
already established ones, all the way down the hierarchy of scales. The larger the scale at
which the trend is observed, the higher the level of the corresponding vertex within the
tree. The root (top vertex) of the resulting tree TX corresponds to the global linear trend
of X(t); each internal vertex corresponds to a distinct local trend, the leaves (vertices
with no descendants) to the the elementary linear segments of the original time series
X(t): [X(ti), X(ti+1)]. The union of leaves thus coincides with X(t).

A recursive procedure for constructing the tree TX is described below.

2.1 Scheme of the decomposition

Without loss of generality we presume that the time series X(t) is observed at a ﬁnite
number of epochs within the time interval [0, 1]. At the ﬁrst step of MTD the whole

Multiscale Trend Analysis

3

L t0( )

c)

X t( )

a)

0

b)

X t

1( ) = ( ) -

X t

L t
( )0

L t1( )

t1

1

t1

2

t1

3

t1

4

1

1

v0

v1

3

v1

1

v1

2

v1

4

v1

5

Upward trend

Downward trend

Figure 1: Scheme of the Multiscale Trend Decomposition (MTD). a) At zero step X(t) is
approximated by its global linear trend L0(t). b) Detrended series X1(t) = X(t)−L0(t) is
approximated by the piecewise linear function L1(t), the whole analysis is then repeated
at each of subintervals [t1
i+1]. c) Resulting hierarchy of trends. See Section 2 for
details.

i , t1

time series X(t), t ∈ [0, 1] is approximated by a single trend — the linear least square
ﬁt L0(t) (Fig. 1a).

This trend forms the vertex v0 at the level 0 (the root) of the resulting hierarchical
tree TX (Fig. 1c). It is also convenient to say that the root of TX corresponds to the
whole time interval [0, 1], and vice versa. At the next step we determine secondary
trends on the background of the ﬁrst global one. For this we consider the deviation
X1(t) = X(t) − L0(t), t ∈ [0, 1] of X(t) from its linear trend L0(t) and approximate it
by a piecewise linear (discontinuous) function L1(t) (Fig. 1b). The most delicate part of
the analysis — choosing the optimal number n0 of segments for this approximation — is
described below in Section 2.2. The approximation L1(t) results in partition of the time
interval [0, 1] = I 0 into n0 nonoverlapping subintervals I 1
i+1], i = 1, . . . , n0,
i , t1
n0+1 = 1. The linear segments l1
with t1
i (t) that comprise L1(t) are determined
by the least square ﬁt of X(t) within corresponding subintervals. They form n0 vertices
i ⊂ I 0 are reﬂected in the
v1
i , i = 1, . . . , n0 at level 1 of the tree TX. The enclosures I 1
structure of the tree TX by the fact that the vertices corresponding to subintervals I 1
i are
descendants of the root, which corresponds to I 0.

1 = 0, t1

i = [t1

Repeating the above procedure at arbitrary interval I 1

i ternary
linear trends, each determined by the least square ﬁt of X(t) at a subinterval I 2
j ⊂ I 1
i ,
j = 1, . . . , n1
i such trends descending from all the trends of
level 1 form level 2 of the tree TX. To index the vertices (local trends) at level 2 we use
P
the natural ordering induced by the corresponding time partition: v2
i ) denotes the

i from level 1 we form n1

i . The union of N2 =

n0
i=1 n1

i (l2

Multiscale Trend Analysis

4

vertex (trend) that corresponds to the time subinterval I 2

Repeating the same procedure at each time interval of level l, l ≥ 0 we form level

i =

i , t2
t2
h

i+1

i

, i = 1, . . . , N2.

(l + 1). It consists of

Nl−1

Nl =

nl−1
i

Xi=1
subintervals (vertices). By construction, N0 = 1 and Nk < Np for k < p. We depth of
the resulting tree is denoted by L.

Each level l of the tree TX corresponds to a piecewise linear approximation Ll(t)
of the time series X(t) as well as to the induced partition I l =
of
the observational interval I 0. The global piecewise linear approximation Ll(t) at level
l is a union of local linear approximations ll
, i = 1, . . . , Nl, and
I 0 = ∪Nl
i
By rl
its linear ﬁt ll

i=1I l
i we denote the length of subinterval I l

I l
i, i = 1, . . . , Nl
n

i the rms deviation of X(t) from

i, and by el

i(t), t ∈ I l

i, tl
tl
h

i(t) at this subinterval:

i ∀l.

i =

i+1

o

el
i =

X(t) − ll

i(t)

2

.

(cid:17)

Xt∈I l

i (cid:16)

v
u
u
t

The total ﬁtting error El at the level l is given by

Nl

E2

l =

2

=

el
i

Xi=1 (cid:16)

(cid:17)

Xt∈I 0

(cid:16)

X(t) − Ll(t)

2

.

(cid:17)

(1)

(2)

All vertices (subintervals) at a given level of TX result from the same number of
divisions of the initial interval [0, 1]. However, in many applications it is desirable to work
with approximations characterized by a similar scale of observed trends, independently of
the division history. To take this into account we consider the modiﬁed tree MX obtained
from TX by the following procedure. The ﬁrst two levels of MX are the same as that of
TX. Each consecutive level is formed by division of only one of the existing subtrends
and leaving all the other unchanged. A subtrend vl
i to be divided corresponds to the
2
−
, where c runs over the
maximal improvement of the ﬁtting quality ∆ =
indexes of children of the vertex i. We will call TX the topological and MX the metric
tree associated with the series X(t). To avoid excessive notations we will use the same
indexing for both the trees TX and MX stating each time which one is considered.

el+1
c

P (cid:16)

el
i

(cid:16)

(cid:17)

(cid:17)

2

2.2 Optimal piecewise linear approximation

Here we describe a procedure for ﬁnding the optimal piecewise linear approximation
L(t) of a series X(t) at a given time interval. Without loss of generality we suppose that
the interval is [0, 1]. The problem, of course, is in ﬁnding the optimal tradeoﬀ between
the number N of linear segments within L(t) and the corresponding ﬁtting quality E.

Multiscale Trend Analysis

5

(3)

(4)

Clearly, the larger the number N, the better the resulting ﬁt. Our goal is to depict by
linear segments only the most prominent large-scale trends of X(t) leaving the smaller
ﬂuctuations for the later steps of the decomposition. To solve this problem we employ
the function

H(N, E) = −

log(E/E0)
N − 1

,

where E0 is the ﬁtting error of the global linear approximation L0(t) of X(t) on [0, 1].
This function measures the quality of a piecewise linear approximation L(t; N, E) which
consists of N linear segments and has total ﬁtting error E. The optimal approximation
L(t; N ∗, E∗) corresponds to the maximum of H(N, E):

H(N ∗, E∗) = max
N,E

H(N, E).

Geometrically, consider the plane (N, log(E/E0)), N being the number of linear seg-
ments within a piecewise linear approximation of X(t) on [0, 1], and E the total ﬁtting
error. The global linear approximation L0(t) at the whole interval [0, 1] corresponds to
the point p0 = (1, 0). An arbitrary piecewise approximation Li(t) corresponds to the
point pi = (Ni, log(Ei/E0)), Ni ≥ 1, Ei ≤ E0. The slope of the linear segment [p0, pi]
shows the increase of the ﬁtting quality per one additional segment of approximation.
By the criterion (3,4) we chose the approximation with the maximal quality increase.

With the above criterion (3,4) one can ﬁnd the optimal approximation by a full search
over all possible partitions of [0, 1] by epochs of X(t) into N = 2, 3, ... subintervals.
However, the computational complexity of such an approach depends exponentially on
the number of observations so it can hardly be used in practice. In Section 2.3 below we
introduce an optimized search based on the idea that partition epochs should correspond
to the prominent edges of the analyzed series X(t).

2.3 Optimized search

The idea of the optimized search is to reasonably reduce the set of possible partition
epochs by considering only those at which X(t) signiﬁcantly changes its slope — edge
points.

The edge points are determined by the following recursive procedure illustrated in

Fig. 2.

At the ﬁrst step we choose the epochs (t1, t2) corresponding to the maximum and
minimum of the detrended function X1(t) = X(t) − L0(t), where L0(t) is a least-square
linear ﬁt of X(t) in [0, 1]. If one of these epochs coincides with the interval boundary
(say, t1 = 0) only the remaining epoch (t2) is considered. If both these epochs coincide
with the interval boundaries, we redeﬁne L0(t) as the line connecting X(0) and X(1)
and repeat the procedure. As a result we have one or two partition epochs within the
initial interval; they divide it into two or three subintervals respectively. The procedure
is now repeated for each of these subintervals, producing two to six new partition epochs.
Together with already selected ones, they divide the initial interval into, respectively,

Multiscale Trend Analysis

6

1

a)

X t( )

0

b)

0

L t0( )

1

Maximum

X t

( ) = ( )-

X t L t
( )

1

0

t1

t2

X t

( ) = ( )-

X t L t
( )

1

0

t1

t2

Minimum

1

c)

0

Figure 2: Scheme of detection of edge points. a) At zero step X(t) is approximated by
its global linear trend L0(t). b) Epochs (t1, t2) of global maximum and minimum of the
detrended series X1(t) = X(t) − L0(t) are located. c) Analysis is repeated at each of
subintervals [0, t1], [t1, t2], and [t2, 1].

four to nine subintervals, etc. The partition stops when the predeﬁned number (Nh − 1)
of partition epochs is collected; this corresponds to Nh subintervals.
2Nh−1 − 1

ways to divide the
interval into 2, . . . , Nh subintervals. The optimal — according to (3,4) — partition can
be found by

With (Nh − 1) possible partition epochs there are

2Nh−1 − 2

operations.

(cid:16)

(cid:17)

(cid:17)

(cid:16)

To further reduce the computation volume, we ﬁrst choose the optimal one from
(Nh − 1) partitions formed by (Nh − 2) partition epochs. Next, only the (Nh − 2) epochs
that form this partition are used to ﬁnd the optimal partition with (Nh − 3) partition
epochs, etc. Finally, we use criterion (3,4) to choose the optimal from (Nh −1) partitions,
each having a distinct number of subintervals ranging from 2 to Nh. This way we reduce
the number of operations to (N 2

h − Nh − 2)/2.

Clearly, the above optimization may produce a piecewise function which does not co-
incide with the optimal one resulting from applying the criterion (3,4) to the whole variety
of possible partitions. As such, this optimization should be considered as a computation-
ally eﬀective approximation of the result. Extensive numerical experiments show that
it is reasonably good for a wide range of time series including fractional Brownian mo-
tions with diﬀerent Hausdorﬀ measures and self-aﬃne processes coming from geophysical
observations.

2.4 Examples

In this section we show examples of MTD and illustrate diﬀerent ways to visualize

the results of the decomposition.

Fig. 3 shows four levels, l = 0, 1, 2, and 10 of MTD for a fractional Brownian walk
with Hausdorﬀ dimension Ha = 0.7. Panel a) shows the analysed series X(t) and the
piecewise linear approximations Ll(t), l = 0, 1, 2, 10 from the MTD, while panel b) shows
the four corresponding levels of the tree MX.

One can see how the ﬁtting quality improves with the number of linear segments:
each consecutive approximation tries to account for the most prominent variations of
X(t) adding the least possible number of new segments. For example, starting with the
three segments of the decomposition L1(t) at level 1, it is clearly more eﬃcient to improve
the leftmost segment, which exhibits large deviations around t = 0.1, than work with the

Multiscale Trend Analysis

7

a) MTD for Brownian walk

b) The corresponding hierarchy of trends

upward trend
downward trend

Level 0
1 interval

Level 1
3 intervals

Level 2
7 intervals

Level 10
23 intervals

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

TimeTime

TimeTime

Figure 3: Example of MTD for a Fractional Brownian walk with Hausdorﬀ measure
Ha = 0.7. a) Piecewise linear approximations at levels l = 0, 1, 2, 10. b) Corresponding
hierarchical tree.

central or rightmost one. When work is done with the largest deviation (see level 2) we
proceed to the smaller ones.

The function shown in Fig. 4a on the background of its tree MX is a sum of three

sinusoids with diﬀerent frequencies.

The amplitudes are chosen in such a way that the largest ﬂuctuations are carried at
the smallest frequency, intermediate at the second largest, and smallest at the highest
one. This structure is clearly depicted by the decomposition with each separate level
responsible for a distinct frequency (see panels b), c), and d)).

Two more examples are given in Fig. 5 where we show only the signals X(t) and the
upper levels of their trees MX, which is enough to understand the shape of corresponding
piecewise linear approximations. Decomposition for the famous Devil’s Staircase is shown
in Fig. 5a: it gives the exact description of the staircase structure. Figure 5b shows a
decomposition for modulated oscillations with time-dependent frequency. Contrary to
the panel a) here we use color-code to depict slope changes (from downward to upward
or vice versa), not their directions. In this example one can see how the amplitude of
oscillation is reﬂected in the decomposition: the higher the amplitude, the higher the
level at which it is ﬁrst detected.

2.5 On the numerical parameter Nh

The only numerical parameter of our algorithm is the maximal number Nh of
secondary trends (see Section 2.3). Large values of Nh contribute to the computational
complexity, while small values may prevent fast detection of optimal approximation and
create superﬂuous levels of the hierarchy TX. Numerous experiments suggest the value
Nh = 5 as the optimal tradeoﬀ, and we use it for all experiments presented in this paper.

Multiscale Trend Analysis

8

a)

b)

0

c)

d)

1

0.4

0.7

0.45

0.53

Figure 4: Example of MTD for the sum of three sinusoids, X(t) = sin(5πt)+ 1
5 sin(60πt)+
1
10 sin(200πt). a) X(t) on the background of three levels from its MTD decomposition.
b) Piecewise linear approximation corresponding to the top level of MTD shown in panel
a). c) Fragment corresponding to the middle level of a). d) Fragment corresponding to
the bottom level of a).

Multiscale Trend Analysis

9

a)

b)

Figure 5: Examples of MTD. a) Devil’s Staircase (5 upper levels of MTD are shown). b)
Modulated sinusoid with time-dependent frequency (15 levels are shown).

Multiscale Trend Analysis

10

0

E

/
l

E

,
r
o
r
r
e
 
g
n
i
t
t
i
f
 
e
v
i
t
a
l
e
R

100

10-1

10-2

10-3

10-4
1

Saturation points

3

10

30
Level of MTD, l

100

Figure 6: Illustration of a procedure for removing unnecessary levels of MTD (for the
signal shown in Fig. 4). Prominent saturation points correspond to the three levels
shown in Fig. 4

Clearly, with Nh = 5 we are not insured from creating unnecessary levels. For example
the division of Fig. 4b consists of 6 (> Nh = 5) linear segments, so it could not be
obtained by a single division of the original series. In fact this is level 2 of the original
hierarchy MX. Analogously, the intermediate division of Fig. 4a (see also Fig. 4c)
corresponds to level 19, and the bottom one (Fig. 4d) to level 82.

The simple procedure used to remove unnecessary levels is illustrated in Fig. 6 where
we show the ﬁtting error El/E0 for all levels l of the tree MX constructed for the signal
of Fig. 4a. The prominent edge points show the three levels at which saturation of the
ﬁtting quality is reached; only these three levels are left in Fig. 4a.

If the analyzed tree has only less-than-5-fold partitions (which is the case for the
Devil’s Staircase of Fig. 5a) the above procedure is unnecessary. The properties of this
procedure and conditions for its use are beyond the scope of the present paper.

3 Self-aﬃne properties of MTD

In this section we demonstrate how self-aﬃne properties of a time series are reﬂected

Recall [4] that statistical properties of a self-aﬃne time series X(t) remain the same

in its decomposition MX.

under the transformation

t′ = rt,
X ′ = rHaX.

(

(5)

That is, when one changes the observational time scale by a factor of r, the scale of
measurements should be changed by a factor of rHa in order to preserve the characteristic
statistical features of X(t). The parameter Ha is called Hausdorﬀ measure; it is related
to the fractal dimension D of a self-aﬃne time series as Ha = 2 − D [4]. Accordingly, for
one-dimensional time series the Hausdorﬀ measure may take values within the range 0 <

Multiscale Trend Analysis

11

(6)

(7)

Ha < 1. A useful interpretation of Ha comes from the character of correlations between
the time series increments: ∆i = X(ti) − X(ti−1). Negative correlations between ∆i and
∆i+1 lead to high ﬂuctuations of X(t) and as a result to absence of pronounced trends;
this situation corresponds to small values of Hausdorﬀ measure: Ha < 1/2. Positive
correlations — leading to existence of long-term trends — correspond to Ha > 1/2. For
a process with independent increments (e.g. Brownian walk) one has Ha = 1/2.

To estimate the Hausdorﬀ measure of observed time series one typically considers the
dependence of a convenient measure of its variation on the length of a corresponding
observational interval [4]. In our case the appropriate variation measure can be chosen
as the ﬁtting error El (2) of MX at level l. According to (5), for a self-aﬃne series X(t)
we expect to observe a power-law relation

El
E0

= N −Ha
l

= RHa
l

,

where Nl is the number of segments at the level l, Rl = N −1

l

is their mean length.

As a model example we consider fractional Brownian walks (FBWs) with Hausdorﬀ

measures in the range 0 < Ha < 1.

Figure 7a shows trajectories and the corresponding (Nl, El)-scalings for three FBWs
with Ha = 0.1, 0.5, and 0.9. Figure 7b shows the value b(Ha) estimated by the best
linear square ﬁt from the relation

log(El/E0) = −b log(Nl)

based on MTD of 2100 independent FBWs; to remove statistical ﬂuctuations we averaged
b over 100 FBWs for each value of Ha. As seen in Fig. 7b, the scaling (6) clearly holds for
Ha > 0.3; the deviations observed at the smaller values of Ha are due to the fact that the
corresponding FBWs become noisier and hardly display pronounced trends. This eﬀect is
typical for self-aﬃne analysis (e.g., see [5]). To neglect it we consider the integrated signal
s≤t X(s). Estimations of the slope b(Ha) for integrated FBWs are presented
Y (t) =
in Fig. 7c. The linear relation b(Ha) = Ha + 1 is now observed for 0 < Ha < 0.6, the
change of slope compared to Fig. 7b is due to the integration procedure.

P

Another way to estimate Ha is to consider the error-length dependence for all indi-

vidual linear segments comprising MX:

Ha+1/2

el
i
E0

=

rl
i
(cid:16)

(cid:17)

, l = 1, . . . , L, i = 1, . . . , Nl.

(8)

The diﬀerence in the power exponents of relations (6) and (8) is explained by the fact
that the former deals with averaged statistics, while the latter deals with characteristics
of individual intervals. Figure 8 illustrates the error-length dependence (8) for FBWs
with Ha = 0.1 and Ha = 0.9.

Importantly, MTD provides a convenient basis for estimation of local Hausdorﬀ mea-
sures Ha(t). Consider all the intervals from TX that cover epoch t. At each level l of

Multiscale Trend Analysis

12

Ha = 0.1

Ha = 0.5

Ha = 0.9

2

4

5 6 7 8 910

3
Number of linear segments, Nl

20

30 40 50

100

Time

a)

100

10-1/2

10-1

0

l

E

/

E

 
,
r
o
r
r
e
 
g
n
i
t
t
i
F

10-3/2

1

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

)
a
H
(
b

Slope
0.1

0.5

0.9

b)

0.1

0

0.1

0.2

0.3

0.4

0.5

0.7
Hausdorff measure, Ha

0.6

0.8

0.9

1

0

0.1

0.2

0.4

0.3
0.5
Hausdorff measure, Ha

0.6

0.7

0.8

0.9

1

Figure 7: Relation between Hausdorﬀ measure and error scaling of MTD levels for frac-
tional Brownian walks (FBW). a) Trajectories of FBWs with Ha = 0.1, 0.5, 0.9 and
corresponding error scalings. b) Relation b(Ha) for FBWs, 0 ≤ Ha ≤ 1, values of b
averaged over 100 realizations of FBW for each value of Ha. c) The same as b) for
integrated FBWs.

c)

)
a
H
(
b

1.9

1.8

1.7

1.6

1.5

1.4

1.3

1.2

1.1

1.0

Figure 8:

Multiscale Trend Analysis

13

a)

8

7

6

5

4

3

2

1

c)

1

0.8

0.6

0.4

0.2

0

b)

d)

2.4

2.3

2.2

2.1

2

1.9

1.8

1.7

1

0

-1

-2

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
Time

0.5
Time

0.5
Time

0.5
Time

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

Figure 9: Estimation of local Hausdorﬀ measures, Ha(t) for a multifractal (Mandelbrot
cascade measure) (panel a) and monofractal (Brownian walk) (panel b). Corresponding
time series are shown in panels c) (multifractal) and d) (monofractal).

TX there is one and only one such interval; we use the index l
(t) to denote this interval
and all its characteristics. The local Hausdorﬀ measure Ha(t) is estimated now from the
relation

Ha(t)+1/2

, l = 1, . . . , L.

(9)

el
(t)
E0

=

rl
(t)
(cid:16)

(cid:17)

Figures 9a,b show the dynamics of the local Hausdorﬀ measure for multi- and monofrac-
tals. We use a Mandelbrot cascade measure M(0.7, 0.3; 0.3, 0.7) as a model example of
a multifractal (Fig. 9c), and a Brownian walk as that of a monofractal (Fig. 9d). The
deﬁnition of Mandelbrot cascade measure is given in Appendix A. Note that the range
of Ha(t) variation for the monofractal (Fig. 9b) is an order of magnitude less than that
for the multifractal (Fig. 9a).

The points

used in (9) to estimate the local Hausdorﬀ measure are ex-

i, rl
el
i

(cid:17)

tracted from the whole set

of (8). This suggests a method for detecting multi-
i, rl
el
i

(cid:16)
fractality in X(t): the larger the scattering of the points
, the larger the prob-
ability that the observed series is a multifractal. Formal statistical tests can be easily
(cid:17)
constructed from this general principle based on the particular problem at hand. The
character of temporal variations of Ha(t) (Figs. 9a,b) can be also used in such tests. An
is shown in Fig. 10 for mono- and multifractals of Fig.
example of the scattering
9. In this model example the diﬀerence is obvious.
(cid:16)

i, rl
el
i

(cid:17)

(cid:16)

el
(t), rl
(t)
(cid:16)

(cid:17)

Multiscale Trend Analysis

14

Multifractal (Mandelbrot cascade measure)
Monofractal (Brownian walk)

0
10

i

l

e

,
r
o
r
r
e
 
g
n
i
t
t
i
F

-5/2

10

-5

10

10-5

10-4

10-3

10-2

10-1

100

Length of segment, rl

i

Figure 10: Error-length dependence for multi- and monofractals of Fig. 9. Note that the
point scattering is signiﬁcantly larger for the multifractal.

Figure 11: Horton-Strahler indexing.

4 Hierarchical scaling

The appropriate ordering of vertices within a tree TX is very important for meaningful
description and analysis of the series X(t). The problem of such an ordering becomes
not trivial as soon as the tree is not uniform (i.e.
is not formed by applying the same
deterministic division rule to each of its vertices). A beﬁtting way to solve this problem
is given by the Horton-Strahler topological classiﬁcation of ramiﬁed patterns [6, 7, 8]
illustrated in Fig. 11: One assigns orders to the vertices of the tree, starting from k = 1
at leaves (vertices with no descendants).

The order of an internal vertex equals the maximal order m of its descendants, if they
are distinct, and m + 1 if they are all equal. Originally introduced in geomorphology by
Horton [6] and later reﬁned by Strahler [7], this classiﬁcation is shown to be inherent in
various geophysical, biological, and computational applications [8, 9, 10, 11].

As a result of the Horton-Strahler indexing of the tree TX, each of its vertices is
characterized by an order k, length r of the corresponding partition interval, and the
error e of the linear least square ﬁt of X(t) on this interval. The scaling behavior of X(t)
can be described by the exponents of the relations:

N(k) ∼ 10−BN k; R(k) ∼ 10BRk; E(k) ∼ 10BEk.

(10)

Here N(k) is the number of vertices of order k, R(k) and E(k) are the values of r and e

Multiscale Trend Analysis

15

a)

b)

r0

1

r2

3

r1

1

r2

2

r2

1

r1

2

e1

2

r2

4

r2

5

e2

1

e2

3

e2

4

e2

5

e1

1

e2

2

c)

e0

1

Figure 12: Three levels of detail in the description of a time series in terms of its MTD
decomposition. a) Topological. b) r-metric, based on the interval partition. c) e-metric,
based on local linear ﬁt of the series. See details in Section 4.

averaged over the vertices of order k.

The relation between the number N(k) of vertices of order k and their average length

R(k) determines the fractal dimension d of the tree TX [9]:

N(k) = R(k)−d.

(11)

Combining (10) and (11) we ﬁnd:

.

d =

(12)

BN
BR
The structure of the tree TX can be considered at diﬀerent levels of detail: First, one
can consider only the topological structure (Fig. 12a), where the position of each vertex
is uniquely determined by its parent (the nearest vertex placed closer to the root); and
any permutation of siblings (the vertices with the same parent) does not change the tree.
Each vertex is characterized by its Horton-Strahler index, and the only constraint on a
tree resulting from MTD is the maximal possible number Nh of siblings, that is subtrends
within a given trend. Next, one can add the information on interval partition (Fig. 12b):
The siblings become ordered according to the partition of the interval corresponding
to their parent. Each vertex vi is additionally characterized by the length ri and the
following conservation law holds:

where c runs over the indexes of the children of the element i.

X

Finally, (Fig. 12c) one considers error characteristics ei, which describe the quality
of the linear ﬁt of X(t) within the corresponding time interval. In terms of these errors
the system becomes dissipative:

ri =

rc,

ei ≥

ec,

(13)

(14)

with the same meaning of subindexes as in (13).

X

The exponents BN,R,E of (10) reﬂect diﬀerent statistical properties of the tree TX:
BN describes its topological structure while BR and BE relate to the metric structures
based, respectively, on properties of interval partition (r-metric) and piecewise linear ﬁt
(e-metric).

For illustration we again use FBWs with diﬀerent Hausdorﬀ measures.

Multiscale Trend Analysis

16

BE

BR

BN

t
n
e
n
o
p
x
e
 
g
n
i
l
a
c
S

1.8

1.6

1.4

1.2

1

0.8

0.6

0.4

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Hausdorff measure, Ha

Figure 13: Dependence of scaling exponents BE,R,N (Eq. (10)) on the Hausdorﬀ measure
Ha of FBWs. Dashed line is B = 0.7 + Ha.

Figure 13 shows the dependence of the exponents BN,L,E on the Hausdorﬀ measure
0 ≤ Ha ≤ 1. The estimations are averaged over 100 FBWs for each value of Ha. The
exponents BN and BR are nearly constant: BN ≈ 0.52, BR ≈ 0.57, while for the exponent
BE we observe the linear dependence:

BE = 0.7 + Ha ≈ log10(5) + Ha.

(15)

These results have an important interpretation: All FBWs with Hausdorﬀ measure
in the range 0 ≤ Ha ≤ 1 have the same topological and r-metric structures in terms of
MTD tree TX. Particularly, trees TX corresponding to diﬀerent Ha have the same fractal
dimension d = BN /BR ≈ 0.9. The only characteristic that depends on the Hausdorﬀ
measure is the ﬁtting error (e-metric), that is the degree of variation of X(t) within a
given interval.

5 Correlation analysis

One of the important applications of MTA is correlation analysis of time series.
The major drawback of classical correlation analysis is that interpretation of its results
may be completely ruined by the presence of long-term trends and/or modest amplitude
modulations of signals. The MTA can naturally avoid these problems by depicting the
essential local properties of the analyzed series.

We start this section by introducing two MTD-based measures of similarity for time
series. One is based solely on the time interval partition induced by MX; another takes
into account the directions (upward vs. downward) of local trends.

5.1 Distance between partitions

Each level l of the tree MX (Section 2) corresponds to a partition of the time interval
[0, 1] into Nl nonoverlapping subintervals. Since each of these subintervals corresponds

Multiscale Trend Analysis

17

to a distinct observed trend of the series X(t), the problem of comparison of two such
partitions naturally arises. Below we introduce the distance between two partitions.

Consider the space Ω of ﬁnite partitions of the unit interval [0, 1]. Each partition
A is deﬁned by a ﬁnite number nA of points; the boundaries 0 and 1 are included in all
partitions:

A = {0 = a0 < a1 < . . . < anA < anA+1 = 1}.

The trivial partition U consists only of boundary points: U = {0, 1}.

For A, B ∈ Ω we say that B is a subpartition of A (B ⊂ A) if all points from A are
among points from B; this imposes a partial order on Ω. A union A ∪ B is deﬁned as
the partition consisting of the points included in either A or B, without repetitions. An
intersection A ∩ B is deﬁned as the partition consisting of points included in both A and
B.

An asymmetric distance m(A, B) from A to B (A, B ∈ Ω) can be deﬁned as

m(A, B) =

min
0≤j≤nB+1

{|ai − bj|},

(16)

which gives for the trivial partition

m(A, U) ≡ m(A) =

min{ai, 1 − ai}

nA

Xi=1

nA

Xi=1

The distance (16) is interpreted as the minimal correction to A that makes B its subpar-
tition: B ⊂ A′, where A′ stands for the corrected version of A.

The following properties of m(A, B) follow directly from the deﬁnition (16):

1. 0 ≤ m(A, B) < ∞;

2. m(A, B) = 0 iﬀ B ⊂ A;

3. Additivity with respect to A: m(A1 ∪ A2, B) = m(A1, B) + m(A2, B);

4. Monotonicity with respect to B (the triangle inequality): m(A, B1∪B2) ≤ m(A, B1)+

m(A, B2).

It is convenient to consider the symmetric function

µ(A, B) = max{m(A, B), m(B, A)},

(17)

whose small values signal that the partitions A and B are similar. Note that µ is not a
distance since it does not satisfy the triangle inequality. The reciprocal µ−1 may serve
as a measure of partition correlation.

Multiscale Trend Analysis

18

a)

c)

+

-

I1
I2

I

b

a

+

c

b)

P1

P2

P

+

-

+

-

-

+

-

I1

a

I
b

I2

c

Figure 14: Signed partition corresponding to a piecewise linear approximation (panel
a), union of signed partitions (panel b), and triplet (a, b, c) for an interval of a union of
partitions. see Section 5.2.

5.2 Slope sign correlation

Here we introduce the correlation function that describe similarity between two
piecewise linear approximations L1(t) and L2(t) of X(t), t ∈ [0, 1].
(We use upper
indexes in order not to mix these arbitrary approximations with L1(t), and L2(t) at the
ﬁrst and second levels of the decomposition.) This correlation function is based on the
coarse information about trends from Li(t): We take into account only their directions
— upward vs. downward.

First, we introduce the signed partitions P1 and P2 of the interval [0, 1]. They are

formed by the intervals of constant sign of the slope of Li(t), i = 1, 2 (see Fig. 14a).

A subinterval from Pi is assigned the sign ”+” if the corresponding trend of Li(t) is
upward, and ”–” if it is downward. Second, we deﬁne the signed partition P as a union of
Pi, i = 1, 2 with the signs determined by multiplication of the signs of the corresponding
subintervals from Pi (Fig. 14b). As a result, the positive intervals of P correspond to
matching (up to direction) trends of L1 and L2, while negative to unmatching ones.

Each subinterval I of the partition P is formed by intersection of two subintervals
Ii ∈ Pi, i = 1, 2; two general variants of such an intersection are shown in Fig. 14c. A
subinterval I is assigned a triplet (a, b, c) deﬁned as shown in Fig. 14c: b is the length
of the intersection I1 ∩ I2, while a and c are the lengths of those parts of Ii that are not
included in the intersection. The triplet is normalized: a + b + c = 1. It describes how
good is the matching of intervals Ii: the meaning of b is clear; the best matching for a
given b corresponds to the case when the intervals’ ends coincide, that is to a · c = 0.
The matching quality can be reﬂected in the weight

w = −

(1 − b) log(1 − b)
a log(a) + c log(c)

= −

(a + c) log(a + c)
a log(a) + c log(c)

,

(18)

lying within the range 0 ≤ w ≤ 1.

Multiscale Trend Analysis

The correlation function r(L1, L2) is now deﬁned as

r(L1, L2) =

rk · wk.

Xk

19

(19)

Here the summation is taken over all the subintervals of the signed partition P ; rk denotes
the signed length of the kth subinterval, wk is the corresponding weight (18).

The measure (19) is intentionally crude:

it does not distinguish between steepness
of the trends. More elaborate correlations can be easily deﬁned following the scheme
outlined above. Nevertheless, as we show in Section 5.3 below, even the roughest measure
(16) is very eﬀective in detecting non-linear correlations.

5.3 Examples

This section illustrates applications of MTD-based correlation analysis in the presence

of long-term nonlinear trends and amplitude modulations.

5.3.1 Detection of correlation

Figure 15 displays the trajectories of two processes Fi(t), i = 1, 2 coupled by the
common underlying phenomenon which — by and large — makes them change their
intermediate-scale trends synchronically. The most striking similarity between Fi(t) is
observed at the intervals [0, 0.1] and [0.2, 0.55]. Also we note the synchronous peaks
around t = 0.675, 0.775, 0.975 (more pronounced for F1(t).) At the same time, the
coupling phenomenon is not a primary one in shaping the dynamics of Fi(t), so their
overall outlooks are still quite dissimilar. In such situations one is interested in detection
and proper quantiﬁcation of the observed non-linear coupling. The problem of such a
quantiﬁcation constitutes an important part of modern analysis of time series.

MTA suggests an eﬀective way of solving this problem by comparing the trend struc-
tures of observed series at diﬀerent scales. We decompose the observations Fi(t) into trees
Mi and calculate the distance µ (17) between diﬀerent levels of these decompositions.
The reciprocal µ−1 of the distance between the signals Fi(t) is plotted as the function of
the decomposition levels li, i = 1, 2 in Fig. 16a.

The diagonal ridge indicates pairs of levels with similar trend structures. The promi-
nent upwell observed at the medium scales — 15 ≤ l1 ≤ 18, 14 ≤ l2 ≤ 17 — signals
that this range is responsible for the observed coupling. The maximum µ−1 = 4.6 cor-
responds to the levels l1 = 15,
l2 = 14; we will refer to them as levels of maximal
correlation (LMC). The piecewise linear approximations of Fi(t) corresponding to the
LMC are shown in Fig. 17. They clearly accentuate the observed coupling.

A typical shape of µ−1 for uncoupled time series is shown for comparison in Fig.
16b. The diagonal ridge is still observed, though it is more blurred. Existence of such
a ridge is explained by the fact that partitions with a similar number of segments, even
non-matching ones, are closer to each other in the sense of (17) than partitions with
signiﬁcantly diﬀerent number of segments. Comparing Figs. 16a and b we conclude that

Multiscale Trend Analysis

20

0

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
Time

Figure 15: Two signals coupled by an unobserved phenomenon. The signals tend to
change their intermediate trends synchronously, while their overall shapes are diﬀerent.
The striking similarity is observed at intervals [0, 0.1] and [0.2, 0.55]. Note also the
common peaks at t = 0.675, 0.775, 0.975. See details in Section 5.3.1.

Figure 16:

a)

b)

L1

L2

10

5

0

-5

-10

8

4

0

-4

-8

Original signal
MTD approximation

Original signal
MTD approximation

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Time

Figure 17: Piecewise linear approximations Li, i = 1, 2 of the signals Fi(t) from Fig. 15
at the levels of maximal correlation (l1 = 15, l2 = 14). These approximations depict the
intermediate-scale variations responsible for the signals’ coupling.

Multiscale Trend Analysis

21

Figure 18:

the upwell observed in panel a is not a random one and is due to the correlation between
the signals. A formal statistical test for establishing the signiﬁcance of the observed
peaks of µ can be easily constructed.

5.3.2 Quantiﬁcation of detected correlation

As was shown in the previous section, MTA allows one to estimate non-linear correla-
tions between signals; the value µ−1 may be considered as a measure of such correlation.
Here we show how to evaluate the functional form of the coupling phenomenon respon-
sible for the correlation detected.

To pose the problem formally, suppose that the observations Fi(t), i = 1, 2 are formed
by applying amplitude modulations Ai(t) and adding non-linear trends Ti(t) to the same
base signal X(t):

Fi(t) = Ai(t) · X(t) + Ti(t) + ξi(t), i = 1, 2.

(20)

Here ξi(t) are measurement errors. In this model the correlation between signals Fi(t) is
due totally to the X(t). The ﬁrst problem is to reconstruct trends Ti(t) and modulated
signals Ai(t) · X(t) given the observations Fi(t). Clearly, for reliable reconstruction one
has to assume an appropriate rate of variation for the trends as well as a reasonably
small noise-to-signal ratio. In practice, we assume that such conditions are satisﬁed if
signiﬁcant coupling has been detected by the correlation analysis of Section 5.3.1.

The idea of reconstruction is that the correlated parts Ai · X(t) should be described
by the LMC of MTDs Mi (see Section 5.3.1). Accordingly, the trends Ti(t) should be
described by the higher-scale (less detailed) levels.

As a model example we again use the series of Fig. 15; in fact, they are produced by

the model (20) with

X(t) = sin (400πt(t − 0.5)(t − 0.7)(t − 1)) ;

T1(t) = 5 sin

4πt3/2

;

(cid:17)
2πt3/2

(cid:16)
T2(t) = −5 cos
(cid:16)
A1(t) = exp(2t);
A2(t) = 2 exp (−t/3) .

;

(cid:17)

(21)

The measurement errors ξi(t) are modeled by independent Brownian walks so they also
represent random drifts. The series Fi(t) together with their components (21) are shown
in Fig. 18.

The trends Ti(t) + ξi(t) are estimated by the piecewise linear functions ˆTi, formed
by the parents of the vertices at the LMC, l1 = 15, l2 = 14. In other words, each of
the linear segments at the levels li should be formed by a single non-trivial partition
of one of the trends of ˆTi. By single we mean that this is a one-time partition by

Multiscale Trend Analysis

22

Figure 19:

Fi(t) − ˆTi(t)
(cid:16)

the rules described in Section 2; by non-trivial — that each segment is divided into
more than one subsegment. The modulated signals Ai(t) · X(t) are estimated then as
AiXi(t) =

, i = 1, 2.

(cid:17)

The quality of these estimations is illustrated in Fig. 19 where we show real vs.
d
estimated modulated signals AiXi(t). The estimations are almost perfect at the intervals
[0, 0.1] and [0.2, 0.55], (cf. Fig. 15 and its discussion in Section 5.3.1.) Generally, we catch
well the oscillatory structure of the signals; that is their time-dependent frequencies and
directions (upward vs. downward), while the amplitude estimation is less precise.

The estimations of Fig.19 can be further improved by means of various kernel smooth-
ing techniques. The advantage of starting with MTD-based analysis is that its results
can be used for optimization of the time-dependent kernel width.

With additional assumptions about the rate of variation for Ai(t) one may pose the
problem of reconstructing X(t) given two, or more, modulated versions Ai(t)·X(t). Using
the epochs assigned to the summands of (16) (say, ai), one may analyze time-dependent
correlations within Fi(t). Clearly, the entire analysis can be repeated with the correlation
(19) as a measure of trend similarity.

6 Discussion

The methods developed in this paper are based on the computational technique
(see Section 2) for solving the linear interpolation problem for time series. This problem
includes two principal diﬃculties. The ﬁrst is a fundamental one: there is a tradeoﬀ
between the quality of a possible approximation and its detail. The second diﬃculty is
purely computational: There are (n−2)!/(n−1−k)!(k +1)! ways to construct a piecewise
linear approximation with a given number k of segments and n observational epochs.
Clearly, the search for the optimum over all possible approximations is unacceptable for
operational use, and computationally eﬀective algorithms are to be invented. Here we
resolve the ﬁrst diﬃculty by introducing the optimality criterion (3,4) of Section 2.2, and
the second by replacing the original time series with its ”skeleton” that includes only
the edge points deﬁned in Section 2.3. The whole analysis is then done hierarchically,
in a multiscale self-similar fashion. This contributes to computational eﬃciency as well
as to the imprecision of the ﬁnal result, since the errors made in the ﬁrst steps of the
decomposition may aﬀect all the consecutive steps. It would therefore be interesting to
study a) deviations of the MTD approximations from the optimal (in a squared deviation
sense) piecewise linear approximations with the same number of segments, and b) the
history of the ﬁrst-step errors.

The procedure for edge point detection is introduced here (Section 2.3) in its simplest
(not to say most naive) form and is subject to further improvement. Nevertheless, even
in its present form, the MTA has the potential to be an eﬀective tool for solving a

Multiscale Trend Analysis

23

wide specrtrum of applied problems, ranging from exploratory data analysis to studying
hierarchical scaling for time series.

Recently, several techniques based on properties of local linear trends were proposed
and studied. The Detrended Fluctuation Analysis (DFA) [5] was shown to be a powerful
tool for multiscale analysis and interpretation of diverse medical and ﬁnancial data.
Contrary to our analysis, DFA uses a predeﬁned interval partition scheme independent
of the particular series at hand. It is oriented toward analysis of variations, rather than
the trend structure itself. An alternative approach to the problem of detection of local
linear trends is discussed in [12].

The problem considered in this paper naturally extends to higher dimensions. How-
ever, it is not clear how to apply the ideas developed here even to 2D and this issue
deserves special attention. Interestingly, elegant theoretical results on rectiﬁable curves
by P. Jones [13] are tightly related to detection of linear structures in point clouds. Vari-
ous methods of multiscale geometric analysis based on Jones’ theory ([14] and references
therein) use predeﬁned (dyadic) partition schemes. It would be very important to ﬁnd
algorithms for fast linearization in point clouds.

It is worth mentioning that the self-aﬃne analysis of Section 3 may be done equally
eﬀectively by a multitude of techniques, and MTA is by no means claimed to be the most
eﬃcient one. We include this section in order to demonstrate the diversity of possible
applications based on the single decomposition (MTD) of a time series.

Acknowledgments This work was supported by a Collaborative Activity Award
for Studying Complex Systems from the 21st Century Science Initiative of the James S.
McDonnell Foundation.

Multiscale Trend Analysis

24

A Mandelbrot cascade measures

A Mandelbrot cascade measure M(ri, mi), i = 1, . . . , n on the interval [0, 1] is constructed
as follows. At step 0 there is a unit mass distributed uniformly over the whole interval.
n
i=1 ri = 1
At the ﬁrst step we divide the interval [0, 1] into n subintervals of lengths ri,
n
i=1 mi = 1. Within each interval the mass distribution
and assign to them masses mi,
is uniform. Next, we divide each subinterval i into n subsubintervals and assign to them
uniform masses mi · mj, j = 1, . . . , n, and so on. Therefore, at the kth step the interval
[0, 1] is divided into nk subintervals, each carrying the uniform mass mi1 · . . . · mik , with
ik taken from the set 1, . . . , n with possible repetitions.

P

P

Such measures were introduced ﬁrst to model turbulent dissipation, and were studied

by Mandelbrot [15].

Multiscale Trend Analysis

25

Figure captions

Figure 8. Error-length dependence for individual vertices of trees MX corresponding

to FBW with Ha = 0.1, 0.9. The scaling (8) is clearly observed.

Figure 16. Correlation (reciprocal distance) µ (17) between MTD of two signals

shown in Fig. 15 (panel a) and two independent Brownian walks (panel b).

Figure 18. Structure of the signals Fi(t), i = 1, 2 shown in Fig. 15. a),e) Original
signals Fi(t). b),f) Coupling parts Ai(t) · X(t). c),g) Non-linear deterministic trends.
d),h) Random drifts.

Figure 19. Reconstruction (solid lines) of the coupling parts Ai(t) · X(t) (dashed

lines). See Section 5.3.1 for discussion.

Multiscale Trend Analysis

References

26

[1] Sklansky, J., and V. Gonzalez, 1980. Fast polygonal approximation of digital curves,

Pattern Recognition, 12, 327-331.

[2] Roberge J., 1985. A data reduction algorithm for plain curves, Computer Vision,

Graphics and Image Processing, 29, 168-195.

[3] Natarajan, B. K., 1991. On piecewise linear approximations to curves, SIAM Con-

ference on Geometric Design.

[4] Turcotte, D.L., 1997. Fractals and Chaos in Geology and Geophysics. (2nd edition).

Cambridge University Press. 398 pp.

[5] Peng, C.-K., Havlin, S., Stanley, H.E., Goldberger, A.L., 1995. Quantiﬁcation of
scaling exponents and crossover phenomena in nonstationary heartbeat time series.
Chaos, 5, 82-87.

[6] Horton, R.E., 1945. Erosional development of streams and their drainage basins:
Hydrophysical approach to quantitative morphology, Geol. Soc. Am. Bull., 56, 275-
370.

[7] Strahler A. N., 1957. Quantitative analysis of watershed geomorphology. Trans. Am.

Geophys. Un., 38, 913-920.

[8] Badii, R., and Politi, A. 1997. Complexity: Hierarchical Structures and Scaling in

Physics. Cambridge University Press. 318 pp.

[9] Newman, W.I., Turcotte, D.L., and Gabrielov, A. 1997. Fractal trees with side

branching. Fractals, 5, 603-614

[10] Gabrielov, A., Newman, W.I., and Turcotte, D.L. 1990. An exactly soluble hierar-
chical clustering model: inverse cascades, self-similarity, and scaling. Phys. Rev. E,
60, 5293-5300.

[11] Toroczkai, Z. 2001. Topological classiﬁcation of the Horton-Strahler index on binary

trees, Phys. Rev. E, 65, 016130.

[12] Cheung J. T-Y., and Stephanopoulos G. 1990. Representation of process trends.
Part I. A formal representation framework. Computer Chem. Eng., 14, 495-510.

[13] Jones, P.W., 1990. Rectiﬁable sets and traveling salesman problem. Invent. Math.,

102(1):1-15.

[14] Lerman, G., 2003. Quantifying curvelike structures of measures by using L2 Jones

quantities. To appear in Communications on Pure and Applied Math.

Multiscale Trend Analysis

27

[15] Mandelbrot, B. 1977. Fractals: Form, Chance and Dimension. Freeman & Co., San

Francisco.

This figure "figure8.gif" is available in "gif"(cid:10) format from:

http://arxiv.org/ps/physics/0305013v1

This figure "figure16.gif" is available in "gif"(cid:10) format from:

http://arxiv.org/ps/physics/0305013v1

This figure "figure18.gif" is available in "gif"(cid:10) format from:

http://arxiv.org/ps/physics/0305013v1

This figure "figure19.gif" is available in "gif"(cid:10) format from:

http://arxiv.org/ps/physics/0305013v1

