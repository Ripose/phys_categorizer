7
9
9
1
 
c
e
D
 
2
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
2
2
0
2
1
7
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Non-commutative time-frequency tomography

V.I. Man’ko∗and R.Vilela Mendes
Grupo de F´ısica–Matem´atica, Complexo Interdisciplinar
Universidade de Lisboa
Av. Prof. Gama Pinto, 2, 1699 Lisboa Codex, Portugal

Abstract

The characterization of non-stationary signals requires joint time
and frequency information. However, time (t) and frequency (ω) being
non-commuting variables, there cannot be a joint probability density
in the (t, ω) plane and the time-frequency distributions, that have been
proposed, have diﬃcult interpretation problems arising from negative
or complex values and spurious components. As an alternative we pro-
pose to obtain time-frequency information by looking at the marginal
distributions along rotated directions in the (t, ω) plane. The rigor-
ous probability interpretation of the marginal distributions avoids all
interpretation ambiguities. Applications to signal analysis and signal
detection are discussed as well as an extension of the method to other
pairs of non-commuting variables.

1 Introduction

Non-stationary signals have a time-dependent spectral content, therefore, an
adequate characterization of these signals requires joint time and frequency
information. Among the many time-frequency (quasi)distributions[1] [2] that
have been proposed, Wigner-Ville’s (WV)[3] [4]

W (t, ω) =

f

t +

u
2 (cid:19)

f ∗

t
(cid:18)

−

u
2 (cid:19)

e−

iωu du

(cid:18)
∗on leave from the P. N. Lebedev Physical Institute, Moscow, Russia

Z

(1)

1

for an analytic signal f (t), is considered to be optimal in the sense that it
satisﬁes the marginals, it is time-frequency shift invariant and it possesses
the least amount of spread in the time-frequency plane.

However, the WV distribution has, in general, positive and negative val-
ues and may be non-zero in regions of the time-frequency plane where either
the signal or its Fourier transform vanish. Therefore, despite the fact that the
WV distribution is an accurate mathematical characterization of the signal,
in the sense that it can be inverted by

(2)

′

f (t)f ∗(t

) =

1
2π Z

W

′

t + t
2

, ω

eiω(t
−

) dω

′
t

!

 
its interpretation for signal detection and recognition is no easy matter, be-
cause of the negative and ”spurious” components. The origin of this problem
lies in the fact that t and ω being non-commuting variables, they cannot be
simultaneously speciﬁed with absolute accuracy and, as a result, there cannot
be a joint probability density in the time-frequency plane. Therefore no joint
distribution, even if positive[5], may be interpreted as a probability density.
Looking back at the original motivation leading to the construction of the
time-frequency distributions, namely the characterization of non-stationary
signals, we notice that we are asking for more than we really need. To charac-
terize a non-stationary signal what we need is time and frequency-dependent
information, not necessarily a joint probability density, a mathematical im-
possibility for non-commuting variables. The solution is very simple. The
2 projects the signal intensity on the time axis and the spec-
f (t)
time density
|
|
2 projects on the frequency axis. To obtain the required
f (ω)
tral density
|
|
time-frequency information, all we need is a family of time and frequency
functions sξ(t, ω), depending on a parameter ξ, which interpolates between
time and frequency. Projecting the signal intensity on this variable, that is,
computing the density along the sξ−
M(s, ξ) =

axis, one obtains a function

(3)

f (sξ)
|

2
|

that has, for each ξ, a probability interpretation. The simplest choice for sξ
is a linear combination

the parameter ξ being the pair (µ, ν). For deﬁniteness we may choose

(4)

(5)

s = µt + νω

µ = cos θ
T
ν = sin θ
Ω

2

T, Ω being a reference time and a reference frequency adapted to the signal
2
to be studied. The function M(s, θ) interpolates between
|
and, as we will prove below, contains a complete description of the signal.
For each θ the function M(s, θ) is strictly positive and being a bona-ﬁde
probability (in s) causes no interpretation ambiguities. A similar approach
has already been suggested for quantum optics[6] and quantum mechanics[7]
[8] [9], the non-commuting variable pairs being respectively the quadrature
phases (ar, ai) and the position-momentum (q, p).

f (t)
|

2 and

f (ω)

|

|

This approach, in which to reconstruct an object, be it a signal in signal
processing or a wave function in quantum mechanics, one looks at its prob-
ability projections on a family of rotated axis, is similar to the computerized
axial tomography (CAT) method. The basic diﬀerence is that in CAT scans
one deals with a pair (x, y) of commuting position variables and here we deal
with a plane deﬁned by a pair of non-commuting variables. For this reason
we call the present approach non-commutative tomography (NCT).

The paper is organized as follows. In Section 2 we construct the NCT
signal transform and show its positivity and normalization properties. We
also establish the invertibility of the transformation, which shows that it
contains a complete description of the signal and establish its relation to
the WV distribution. Because the NCT transform involves the square of
the absolute value of a linear functional of the signal, it is actually easier to
compute than bilinear transforms like WV.

In Section 3 we work out the analytical form of the NCT transform for
some signals and also display the M(s, θ) in some examples. We also deal with
the problem of using NCT to detect the presence of signals in noise for small
signal to noise ratios (SNR). Here the essential observation is that, for small
SNR, the signal may be diﬃcult to detect along t or ω, however, it is probable
that there are other directions on the (t, ω) plane along which detection might
be easier. It is the consistent occurrence of many such directions that supplies
the detection signature.

Finally in Section 4 we point out that the NCT approach may also be used
for other pairs of non-commuting variables of importance in signal processing.
As an example we work out the relevant formulas for the scale-frequency pair.

3

2 Non-commutative time-frequency tomogra-

phy

Because the Fourier transform of a characteristic function is a probability
density, we compute the marginal distribution for the variable s = µt + νω
using the characteristic function method. Frequency and time are operators
acting in the Hilbert space of analytic signals and, in the time-representation,
i∂/∂t . The characteristic function C(k) is
the frequency operator is ω =

C(k) =

eik(µt+νω)

=

f ∗(t) eik(µt
−

iν∂/∂t) f (t) dt

(6)

−

i

Z

h

where f (t) is a normalized signal

f (t)

2 dt = 1
|

Z |

The Fourier transform of the characteristic function is a probability density

1
2 π Z
After some algebra, one obtains the marginal distribution (7) in terms of the
analytical signal

M (s, µ, ν) =

C(k)e−

iks dk

(7)

M (s, µ, ν) =

with normalization

exp

iµt2
2 ν −

its
ν #

"

2

f (t) dt
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

M (s, µ, ν) ds = 1

1
2 π

ν

|

|

Z

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Z

For the case µ = 1, ν = 0, it gives the distribution of the analytic signal in
the time domain

and for the case µ = 0, ν = 1, the distribution of the analytic signal in the
frequency domain

The family of marginal distributions M(s, µ, ν) contains complete infor-
mation on the analytical signal. This may be shown directly. However it

M (t, 1, 0) =

f (t)

2

|

2

|

|

|

M (ω, 0, 1) =

f (ω)

4

(8)

(9)

(10)

(11)

is more interesting to point out that there is an invertible transformation
connecting M(s, µ, ν) to the Wigner-Ville quasidistribution, namely

M (s, µ, ν) =

exp [

ik(s

µt

νω)] W (t, ω)

(12)

Z

−

−

−

dk dω dt
(2π)2

and

1
2π Z

W (t, ω) =

M (s, µ, ν) exp [

i (µt + νω

s)] dµ dν ds

(13)

−

−

Therefore, because the WV quasidistribution has complete information, in
the sense of Eq.(2), so has M(s, µ, ν).

3 Examples

We compute the NCT transform M(s, µ, ν) for some analytic signals:

(i) A complex Gaussian signal

It has the properties

f (t) =

1/4

α
π (cid:19)

(cid:18)

exp

α
2

"−

t2 + i

β
2

t2 + i ω0t
#

= 0,

t
i

h

= ω0

ω

i

h
2

t2
σ2
t
t =
i − h
i
h
ω2
σ2
ω
ω =
i − h
i
h
r = 2−1
t
tω+ωt
ih
i−h
h
σω σt

2

ω

i

1
2α

=
= α2+β2
=

2α
β
√α2+β2

This signal minimizes the Robertson–Schr¨odinger uncertainty relation

In quantum mechanics, it corresponds to a correlated coherent state [10] [11].

The NCT transform is

M (s, µ, ν) =

1

2 πσ2
s

exp

"−

(s

s)2

−
2 σ2
s

#

(14)

(15)

(16)

(17)

(18)

ωσ2
σ2

t ≥

1
4

1

−

1

r2

q

5

(19)

(20)

(21)

(22)

(23)

(24)

with parameters

s = 1
σ2
2α |
s = ω0ν
T , ν = sin θ
For the case of µ = cos θ
evolves along the θ axis, changing its maximum and width

ν (α

iβ)

iµ

−

−

|

2

Ω , Eq.(19) shows how the initial Gaussian

s = 1
σ2
2α
s = ω0

sin θ
(cid:12)
(cid:12)
Ω
(cid:12)

sin θ
Ω (α

iβ)

−

−

i cos θ
T

2

(cid:12)
(cid:12)
(cid:12)

Thus, we have squeezing in the quadrature components and their correlation.
In the case β = 0, one has a purely squeezed state[12] [13], which minimizes
the Heisenberg uncertainty relation

ωσ2
σ2

t ≥

1
4

(ii) A normalized superposition of two Gaussian signals

f (t) = Ns {

A1f1(t) + A2f2(t)

}

where fi(t) is

and

fi(t) = Ni exp

ait2 + bit
i

,

−
h

i = 1, 2

Ni =

1/4

ai + a∗i
π

(cid:20)

(cid:21)

exp

"−

1
8

(bi + b∗i )2
ai + a∗i #

The superposition coeﬃcients being complex numbers, the normalization
constant Ns reads

Ns =

A1|

(cid:18)|

2 +

A2|

|

2 + 2 Re

A1A∗2
(cid:20)

Z

f1(t) f ∗2 (t) dt

(25)

1/2

−

(cid:21)(cid:19)

Computing the marginal distribution M (s, µ, ν) by Eq.(8) we arrive at a
combination of three Gaussian terms

M (s, µ, ν) = N 2

s {|

A1|

2M1 (s, µ, ν) +

A2|
|
+2 Re[A1A∗2M12 (s, µ, ν)]
}

2M2 (s, µ, ν)

(26)

6

where we have the contribution of two real Gaussian terms

Mi (s, µ, ν) =

i = 1, 2,

(27)

1
2πσ2
i

exp

"−

(s

si)2

−
2σ2
i

,

#

q

and the superposition of two complex Gaussians

M12 (s, µ, ν) =

n12
2πσ2
12

(s

s12)2

exp

"−

−
2σ2
12

#

q

The parameters of the real Gaussians are the dispersion

and mean

The parameters of the complex Gaussian are

iµ
νai −
2
ai + a∗i

2

(cid:12)
(cid:12)
(cid:12)

σ2
i = 2 (cid:12)
(cid:12)
(cid:12)

si = ν

Im (bia∗i ) + Re
Re ai

(cid:16)

µ
2ν bi

(cid:17)

12 = 2ν2
σ2

(cid:16)

a1 −

a∗2 + iµ

2ν

iµ
2ν
(cid:17) (cid:16)
a1 + a∗2

(cid:17)

and

s12 =

a1 −
and the complex amplitude n12 of the complex Gaussian contribution is

a∗2 +

b∗2

b1

(cid:18)

(cid:18)

(32)

iν
a1 + a∗2 (cid:20)

iµ
2ν (cid:19) −

iµ
2ν (cid:19)(cid:21)

n12 =

σ12
√2π

ν

exp

1
4  

"

b2
1
a1 −

2
b∗
2
a∗2 + iµ

2ν !

+

s2
12
2σ2
12 #

+

iµ
2ν

|
(iii) Finite-time signals
Here we consider signals

|

fi(t) = Nie−

ait2+bit ,

t2i ≤

t

≤

t1i

7

(28)

(29)

(30)

(31)

(33)

(34)

which vanish for all other times and compute the NCT for one signal and for
the superposition of two such signals. The parameters ai and bi are complex
numbers. The normalization constant is

Ni =

ai + a∗i exp

(bi + b∗i )2
4 (ai + a∗i ) #

√π
2 "

"−

erfc

ai + a∗i

t2i −

"

bi + b∗i

2 (ai + a∗i ) #!

q

−

erfc

 

q

ai + a∗i

t1i −

"

2 (ai + a∗i ) #!#

(cid:12)
(cid:12)
bi + b∗i
(cid:12)

 

q
1/2

−

(cid:12)
(cid:12)
(cid:12)

where erfc is the function

(35)

(36)

erfc (y) =

2
√π Z

y

∞

x2

e−

dx

Using Eq.(8), we arrive at the following marginal distribution



s

erfc

ai −

t2i −

iµ
2ν "

| (cid:12)
(cid:12)
(cid:12)
erfc

2
i
Mi (s, µ, ν) = N
ν
8
|

is
νbi −
iµ #
2νai −

νbi −
is
2
iµ #
2νai −

In the limit t1i → −∞
, the marginal distributions (37) reduce
In the case ai = 0, bi = iωi,
to the Gaussian distribution given by (27).
the distribution (37) describes a sinusoidal signal of ﬁnite duration. The
normalization constant takes the limit value

, t2i → ∞

iµ
2ν "

t1i −

ai −

(37)

−

s







(cid:12)
(cid:12)
(cid:12)

For a superposition of two ﬁnite-time signals

Ni =

(t2i −

⇒

1/2

t1i)−

(38)

f (t) = Ns {

A1f1(t) + A2f2(t)

}

with the signals f1(t) and f2(t) as in (34), the normalization constant is given
by Eq.(25) with overlap integral

tb

ta

Z

f1(t) f ∗2 (t) dt =

√π
2√a1 + a∗2

exp

"

N1N2

(bi + b∗i )2
4 (ai + a∗i ) #
b1 + b∗2

ta −

"

tb −

"

2 (a1 + a∗2) #!
b1 + b∗2

2 (a1 + a∗2) #!)

(39)

erfc

a1 + a∗2

erfc

a1 + a∗2

(

−

 

q

 

q

8

The marginal distribution for the superposition signal has the same form
as Eq. (26) but with a changed normalization constant, the distributions
M1 (s, µ, ν) and M2 (s, µ, ν) given by Eq. (37), and an interference term
M12 (s, µ, ν)

M12 (s, µ, ν) = N1N2
|

8

ν

|

erfc

a1 −



s

iµ
2ν "

erfc

−

a1 −

s



iµ
2ν "

t11 −


erfc

a2 −



s

iµ
2ν "

t22 −

× 



erfc

−

a2 −



s

iµ
2ν "

t12 −














t21 −

is
νb1 −
iµ #
2νa1 −

is
νb1 −
iµ #
2νa1 −

νb2 −
is

iµ #
2νa2 −

νb2 −
is
iµ #
2νa2 −





∗

The case a2 = 0 corresponds to the combination of a ﬁnite time chirp and a
ﬁnite time sinusoidal signal shown in one of the ﬁgures below.



(iv) Graphical illustrations
We have plotted M (s, µ, ν) for some signals. In all cases we use µ and ν
as in Eq.(5) with T = 1 and Ω = 10. All signals are ﬁnite time signals and
in each case we display a three-dimensional and a contour plot.

# Figs 1a,b. The signal is

e−

i20t + ei10t

f (t) = 


0



(0, 1)

(0, 1)

t

∈
t /
∈






Although the number of periods, during which is signal is on, is relatively
small, the two contributing frequencies are clearly seen in the separating
ridges.

# Figs 2a,b. The signal is

(40)

(41)

(42)

f (t) =

i20t

e−

0

ei10t






9

(0, 1
4)

4, 3
( 1
4)

( 3
4, 1)

t

t

t

∈

∈

∈






Once again the contributions separate as θ grows, but notice the intermediate
interference region which is a signature of the time-sequence of the frequencies
occurrence and of their relative phase.

# Figs 3a,b. The signal is

i(20t+10t2) + ei10t

e−

0

f (t) = 



(0, 1)

(0, 1)

t

∈
t /
∈





(43)

Contrasts the signature shapes of a chirp contribution and a regular sinu-
soidal pulse.

Notice that all M(s, θ) values have a probability interpretation. Therefore
all peaks or oscillations have a direct physical meaning and, as opposed to the
time-frequency quasidistributions, we need not worry about spurious eﬀects.
This is particularly important for the detection of signals in noise, as we will
see in the next example.

(v) Detection of noisy signals by NCT
In Fig.4a and 4b we have plotted a time signal f (t) and its spectral density
2. It is really very hard to decide, from these plots, where this signal
f (ω)
|
|
might have originated from. Now we plot the NCT transform (Fig.4c) and
its contour plot (Fig.4d) with the normalization T = 1 and Ω = 1000. It still
looks quite complex but, among all the peaks, one may clearly see a sequence
of small peaks connecting a time around 0.5 to a frequency around 200.

In fact the signal was generated as a superposition of a normally dis-
tributed random amplitude and random phase noise with a sinusoidal signal
of the same average amplitude but operating only during the time interval
(0.45, 0.55). This means that, during the observation time, the signal to
noise power ratio is 1/10. The signature that the signal leaves on the NCT
transform is a manifestation of the fact that, despite its low SNR, there is
a number of particular directions in the (t, ω) plane along which detection
happens to be more favorable. The reader may convince himself of the sound-
ness of this interpretation by repeating the experiment with diﬀerent noise
samples and noticing that each time the coherent peaks appear at diﬀerent
locations, but the overall geometry of the ridge is the same.

Of course, to rely on a ridge of small peaks for detection purposes only
makes sense because the rigorous probability interpretation of M(s, θ) ren-
ders the method immune to spurious eﬀects.

10

4 NCT for other non-commuting pairs. The

time-scale and frequency–scale cases

The method may also be applied to other pairs of non-commuting variables
for which, as in the time-frequency case, there cannot be a joint probability
density. Consider the pair time-scale, where scale is the operator

In the plane (t, D) we consider the linear combination

D =

(tω + ωt) = ωt +

1
2

i
2

s1 = µt + νD =

t + νD

cos θ
T

The relevant characteristic function is

C (1)

µν (k) =
=

eik(µt+νD)

=
2 t)ei2 µ
ν sinh( kν
E
R

kν

D
f ∗(e−

2 )f (e

kν

2 t)dt

f ∗(t)eik(µt+νD)f (t)dt

and the NCT transform is, as before, the Fourier transform of C (1)

µν (k)

R

M (1) (s1, µ, ν) =

C (1)

µν (k)e−

iks1 dk

1
2 π Z

leading to

M (1) (s1, µ, ν) =

1
2 π

|
1
2 π

ν

ν

|

t>0

t<0

R

R

| (cid:12)
(cid:12)
(cid:12)
(cid:12)
| (cid:12)
(cid:12)
(cid:12)
(cid:12)

−

dt

√t f (t)ei( µ
ν t
f (t)ei( µ
ν t

dt
√
t
|

|

2

s1
ν log t)

s1
ν log

−

(cid:12)
(cid:12)
|)
t
(cid:12)
|
(cid:12)

+
2

(cid:12)
(cid:12)
(cid:12)
(cid:12)

For the pair frequency-scale, (ω, D), we obtain similarly

s2 = µω + νD =

ω + νD

cos θ
Ω

M (2) (s2, µ, ν) =

(44)

(45)

(46)

(47)

(48)

(49)

ω>0

dω
√ω f (ω)e−

i( µ

ν ω

−

s2
ν log ω)

f (ω)e−

i( µ

ν ω

−

s2
ν log

ω<0

dω
√
ω

|

|

2

+
2

(cid:12)
(cid:12)
ω
(cid:12)
|
(cid:12)

|)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
2 π

ν
|
1
2 π

ν
|

| (cid:12)
(cid:12)
R
(cid:12)
(cid:12)
| (cid:12)
(cid:12)
(cid:12)
(cid:12)

R

11

f (ω) being the Fourier transform of the signal f (t).

References

[1] L. Cohen, ”Time-frequency distributions - A review”, Proc. IEEE,

vol.77, pp. 941-981, 1989.

[2] G. Faye Boudreaux-Bartels, ”Mixed time-frequency signal transforma-
tions” in ”The transforms and applications handbook”, A. D. Poularikas
(Ed.), pp. 887-962, CRC Press, Boca Raton 1996.

[3] E. Wigner, ”On the quantum correction for thermodynamic equilibrium”,

Phys. Rev. vol.40, pp. 749-759, 1932.

[4] J. Ville, ”Th´eorie et applications de la notion de signal analytique”,

Cables et Transmission, vol.2A, pp. 61-74, 1948.

[5] L. Cohen and T. Posch, ”Positive time-frequency distribution functions”,
IEEE Trans. Acoust., Speech, Signal Processing, vol. 33, pp. 31-38, 1985.

[6] K. Vogel and H. Risken, ”Determination of quasiprobability distributions
in terms of probability distributions for the rotated quadrature phase”,
Phys. Rev. vol.A40, pp. 2847-2849, 1989.

[7] S. Mancini, V. I. Man’ko, and P. Tombesi, ”Wigner function and proba-
bility distribution for shifted and squeezed quadratures” Quantum Semi-
class. Opt. vol.7, pp. 615-623, 1995.

[8] S. Mancini, V.I. Man’ko, and P. Tombesi, ”Symplectic tomography as
classical approach to quantum systems”, Phys. Lett. vol.A213, pp. 1-6,
1966.

[9] S. Mancini, V.I. Man’ko, and P. Tombesi, ”Classical-like description of
quantum dynamics by means of symplectic tomography”, Found. Phys.
vol.27, pp.801-824, 1997.

[10] V.V. Dodonov, E.V. Kurmyshev, and V.I. Man’ko, ”Generalized uncer-
tainty relations and correlated coherent states” Phys. Lett. vol.A79, pp.
150-152, 1980.

[11] E.C.G. Sudarshan, Charles B. Chiu, and G. Bhamathi, ”Generalized
uncertainty relations and characteristic invariants for the multimode
states” Phys. Rev. vol.A52, pp. 43-54, 1995.

12

[12] H.P. Yuen, ”Two-photon coherent states of the radiation ﬁeld”, Phys.

Rev. vol.A13, pp. 2226-2243, 1976.

[13] D.F. Walls, ”Evidence for the quantum nature of light”, Nature vol.280,

pp. 451-454, 1979.

13

Fig.1A

5

4

3

2

1

0
4

2

0

s

-2

0

0.2

0.6

0.4

sin(teta)

1

0.8

Fig.1B

s

0.5

2.5

1.5

3

2

1

0

-0.5

-1

-1.5

-2

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
sin(teta)

Fig.2A

1.5

0.5

2

1

0
4

2

0

s

-2

0

0.2

0.6

0.4

sin(teta)

1

0.8

Fig.2B

s

0.5

2.5

1.5

3

2

1

0

-0.5

-1

-1.5

-2

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
sin(teta)

Fig.3A

5

4

3

2

1

0
4

2

0

s

-2

0

0.2

0.6

0.4

sin(teta)

1

0.8

Fig.3B

s

0.5

2.5

1.5

3

2

1

0

-0.5

-1

-1.5

-2

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
sin(teta)

Fig.4A

)
t
(
f

3

2

1

0

-1

-2

-3

-4
0

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
t

Fig.4B

2.5

3

2

1

)
a
g
e
m
o
(
F

1.5

0.5

0
0

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
omega

Fig.4C

100

80

60

40

20

0
1

0.5

s

0.2

0

0

0.6

0.4

sin(teta)

1

0.8

Fig.4D

s

0.5

1

0.9

0.8

0.7

0.6

0.4

0.3

0.2

0.1

0

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
sin(teta)

