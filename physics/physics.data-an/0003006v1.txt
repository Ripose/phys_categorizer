0
0
0
2

 
r
a

M
2

 

 
 
]
n
a
-
a
t
a
d

.
s
c
i
s
y
h
p
[
 
 

1
v
6
0
0
3
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

On mixing times for stratiﬁed walks on the d-cube

Nancy Lopes Garcia

Universidade Estadual de Campinas

Campinas, Brasil

and

Jos´e Luis Palacios

Universidad Sim´on Bol´ıvar

Caracas, Venezuela.

February 2, 2008

Abstract

Using the electric and coupling approaches, we derive a series of results concerning the

mixing times for the stratiﬁed random walk on the d-cube, inspired in the results of Chung and

Graham (1997) Stratiﬁed random walks on the n-cube. Random Structures and Algorithms,

11,199-222.

Key Words: eﬀective resistance, coupling, birth and death chains

1991 Mathematics Subject Classiﬁcation. Primary: 60J15; secondary: 60C05.

1

1

Introduction.

The stratiﬁed random walk (SRW) on the d-cube Qd is the Markov chain whose state space is

the set of vertices of the d-cube and whose transition probabilities are deﬁned thus:

Given a set of non-zero probabilities p = (p0, p1, . . . , pd−1), from any vertex with k 1’s,

the process moves either to any neighboring vertex with k + 1 1’s with probability pk
d ; or to
any neighboring vertex with k − 1 1’s with probability pk−1
d ; or to itself with the remaining
probability. The simple random walk on the d-cube corresponds to the choice pk = 1 for all k.

Vaguely speaking, the mixing time of a Markov chain is the time it takes the chain to have

its distribution close to the stationary distribution under some measure of closeness. Chung

and Graham studied the SRW on the d-cube in [5], mainly with algebraic methods, and found

bounds for the mixing times under total variation and relative pointwise distances. Here we

use non-algebraic methods, the electric and coupling approaches, in order to study the same

SRW and get exact results for maximal commute times and bounds for cover times and mixing

times under total variation distance. We take advantage of the fact that there seems to be some

inequality or another linking hitting times, commute times, cover times and any deﬁnition of

mixing time with any other under any measure of closeness (see Aldous and Fill [2] and Lov´asz

and Winkler [8]).

2 The electric approach

On a connected undirected graph G = (V, E) such that the edge between vertices i and j is

given a resistance rij (or equivalently, a conductance Cij = 1/rij), we can deﬁne the random
walk on G as the Markov chain X = {X(n)}n≥0 that from its current vertex v jumps to the
neighboring vertex w with probability pvw = Cvw/C(v), where C(v) =Pw:w∼v Cvw, and w ∼ v

means that w is a neighbor of v. There may be a conductance Czz from a vertex z to itself,

giving rise to a transition probability from z to itself. Some notation: EaTb and EaC denote

the expected value, starting from the vertex a, of respectively, the hitting time Tb of the vertex

2

b and the cover time C, i. e., the number of jumps needed to visit all the states in V ; Rab is the

eﬀective resistance, as computed by means of Ohm’s law, between vertices a and b.

A Markov chain is reversible if πiP(i, j) = πj P(j, i) for all i, j, where {π.} is the stationary
distribution and P(·,·) are the transition probabilities. Such a reversible Markov chain can be
described as a random walk on a graph if we deﬁne conductances thus:

Cij = πiP(i, j).

(2.1)

We will be interested in ﬁnding a closed form expression for the commute time E0Td + EdT0

between the origin, denoted by 0, and its opposite vertex, denoted by d.

Notice ﬁrst that the transition matrix for X = {X(n), n ≥ 0}, the SRW on the d-cube,
If we now collapse

is doubly stochastic and therefore its stationary distribution is uniform.

all vertices in the cube with the same number of 1’s into a single vertex, and we look at the

SRW on this collapsed graph, we obtain a new reversible Markov chain S = {S(n), n ≥ 0}, a
birth-and-death chain in fact, on the state space {0, 1, . . . d}, with transition probabilities

P(k, k + 1) =

P(k, k − 1) =

d

d − k
k
d

pk,

pk−1,

P(k, k) = 1 − P(k, k + 1) − P(k, k − 1).

(2.2)

(2.3)

(2.4)

It is plain to see that the stationary distribution of this new chain is the Binomial with

parameters d and 1

2 . It is also clear that the commute time between vertices 0 and d is the
same for both X and S. For the latter we use the electric machinery described above, namely,

we think of a linear electric circuit from 0 to d with conductances given by (2.1) for 0 ≤ i ≤ d,
j = i − 1, i, i + 1, and where πi =(cid:18)d

i(cid:19) 1
2d .

It is well known (at least since Chandra et al. proved it in [4]) that

where Rab is the eﬀective resistance between vertices a and b.

EaTb + EaTb = RabXz

C(z),

(2.5)

3

If this formula is applied to a reversible chain whose conductances are given as in (2.1), then

it is clear that

C(z) = πz

and therefore the summation in (2.5) equals 1. We get then this compact formula for the

commute time:

EaTb + EaTb = Rab,

(2.6)

where the eﬀective resistance is computed with the individual resistors having resistances

rij =

1
Cij

=

1

πiP(i, j)

.

In our particular case of the collapsed chain, because it is a linear circuit, the eﬀective

resistance R0d equals the sum of all the individual resistances ri,i+1, so that (2.6) yields

E0Td + EdT0 = R0d = 2d

.

(2.7)

d−1

Xk=0

1

pk(cid:0)d−1
k (cid:1)

Because of the particular nature of the chain under consideration, it is clear that E0Td + EdT0

equals the maximal commute time (τ ∗ in the terminology of Aldous [2]) between any two vertices.

(i) For simple random walk, formula (2.7) is simpliﬁed by taking all pk = 1. This particular

formula was obtained in [8] with a more direct argument, and it was argued there that

An application of Matthews’ result (see [9]), linking maximum and minimum expected hitting

= 2 + o(1).

d−1

Xk=0

1

(cid:0)d−1
k (cid:1)

times with expected cover times, yields immediately that the expected cover time is EvC =
Θ(|V | log |V |), which is the asymptotic value of the lower bound for cover times of walks on a
graph G = (V, E) (see [6]). Thus we could say this SRW is a “rapidly covered” walk.

(ii) The so-called Aldous cube (see [5]) corresponds to the choice pk = k

d−1 . This walk takes
place in the “punctured cube” that excludes the origin. Formula (2.7) thus, must exclude k = 0

in this case, for which we still get a closed-form expression for the commute time between vertex

4

d, all of whose coordinates are 1, and vertex s which consists of the collapse of all vertices with

a single 1:

d−1

EsTd + EdTs = 2d

.

(2.8)

Xk=1

1

(cid:0)d−2
k−1(cid:1)

The same argument used in (i) tells us that the summation in (2.8) equals 2 + o(1) and, once

again, Matthews’ result tells us that the walk on the Aldous cube has a cover time of order

|V | log |V |.

(iii) The choice pk = 1
(d−1
k )

would be in the terminology of [5] a “slow walk”: the commute
time is seen to be exactly equal to |V | log2 |V | and thus the expected cover time is O(|V | log2 |V |).
In general, the SRW will be rapidly covered if and only if

for some constant c.

d−1

Xk=0

1

pk(cid:0)d−1
k (cid:1)

= c + o(1),

Remark. A formula as compact as (2.7) could be easily obtained through the commute

time formula (2.6). It does not seem that it could be obtained that easily, by just adding the

individual hitting times EiTi+1. (A procedure that is done, for instance, in [5], [10], [11], and

in the next section).

3 The coupling approach

In order to asess the rate of convergence of the SRW on the cube Qd to the uniform stationary

distribution π, we will bound the mixing time τ deﬁned as

where

τ = min{t : d(t′) ≤

1
2e

, for all t′ > t},

d(t) = max

x∈Qd kPx(X(t) = ·) − π(·)k,

and kθ1 − θ2k is the variation distance between probability distributions θ1 and θ2, one of whose
alternative deﬁnitions is (see Aldous and Fill [2]), chapter 2):

kθ1 − θ2k = min P(V1 6= V2),

5

where the minimum is taken over random pairs (V1, V2) such that Vm has distribution θm, m =

1, 2.

The bound for the mixing time is achieved using a coupling argument that goes as follows:

let {X(t), t ≥ 0} and {Y(t), t ≥ 0} be two versions of the SRW on Qd such that X(0) = x and
Y(0) ∼ π. Then

kPx(X(t) = ·) − π(·)k ≤ P(X(t) 6= Y(t)).

(3.1)

A coupling between the processes X and Y is a bivariate process such that its marginals

have the distributions of the original processes and such that once the bivariate process enters

the diagonal, it stays there forever. If we denote by

the coupling time, i. e., the hitting time of the diagonal, then (3.1) translates as

Tx = inf{t; X(t) = Y(t)}

and therefore,

kPx(X(t) = ·) − π(·)k ≤ P(Tx > t),

d(t) ≤ max

x∈Qd

P(Tx > t).

(3.2)

(3.3)

If we can ﬁnd a coupling such that ETx = O(f (d)), for all x ∈ Qd and for a certain function f
of the dimension d, then we will also have τ = O(f (d)). Indeed, if we take t = 2ef (d), then (3.3)

and Markov’s inequality imply that d(t) ≤ 1/2e and the deﬁnition of τ implies τ = O(f (d)).

x is a coupling time for the birth-and-death process

We will split Tx as Tx = T 1

x +T 2

x, where T 1

S, and T 2

x is another coupling time for the whole process X, once the bivariate S process enters

the diagonal, and we will bound the values of ET 1

x and ET 2
x.

More formally, for any x, y ∈ Qd deﬁne

d

s(x) =

xi

Xi=1
|xi − yi|.

d(x, y) =

d

Xi=1

6

(3.4)

(3.5)

Deﬁne also for the birth-and-death process S(t) = s(X(t)) its own mixing time:

τ (S) = inf{t; dS (t) ≤

1
2e},

where dS(t) = maxi kPi(S(t) = ·) − πS(·)k, and πS is the stationary distribution of S. Notice
that s(Y(0)) ∼ πS since Y(0) ∼ π.

Now we will prove that τ (S) = O(fS(d)), for a certain function fS of the expected hitting

times of the “central states”, and that this bound implies an analogous bound for ET 1

x. Indeed,

as shown by Aldous [1], we can bound τ (S) by a more convenient stopping time

τ (S) ≤ K2τ (3)

1

(3.6)

where τ (3)

1 = minµ maxi minUi

EiUi and the innermost minimum is taken over stopping times

Ui such that Pi(S(Ui) ∈ ·) = µ(·). In particular,

τ (3)
1

Ei U b
i

max

min
U b
EiTb

≤ min
≤ min
= max(E0Td/2, EdTd/2)

max

i

b

b

i

i

(3.7)

(3.8)

(3.9)

where the innermost minimum in (3.7) is taken over stopping times U b

i such that Pi(S(Ui) =

b) = 1. Expression (3.9) follows from (3.8) since we are dealing with birth and death chains.

Therefore, combining (3.6) and (3.9) we have

τ (S) ≤ K2 max(E0Td/2, EdTd/2) := fS(d).

(3.10)

In general, a coupling implies an inequality like (3.2). However, the inequality becomes an

equality for a certain maximal (non-Markovian) coupling, described by Griﬀeath [7]. Let T 1

x be

the coupling time for the maximal coupling between s(X(t)) and s(Y(t)) such that

kPx(S(X(t)) = ·) − πS(·)k = P(T 1

x > t).

Then

dS(t) = max

x∈Qd kPx(S(X(t)) = ·) − πS(·)k = max

x∈Qd

P(T 1

x > t).

7

By the deﬁnition of τ (S) it is clear that P (T 1

x > τ (S)) ≤ 1

2e . Moreover, by the “submultiplica-

tivity” property (see Aldous and Fill [2], chapter 2)

we have that

Thus

d(s + t) ≤ 2d(s)d(t),

s, t ≥ 0,

P (T 1

x > kτ (S)) ≤

1
2ek ,

k ≥ 1.

∞

(3.11)

(3.12)

ET 1

x =

x ≤ kτ (S)))

kP ((k − 1)τ (S) < T 1

x ≤ kτ (S))

∞

∞

E(T 1

Xk=1
≤ τ (S)

x 1((k − 1)τ (S) < T 1
Xk=1
Xk=1
≤ τ (S)
≤ τ (S) 1 +

kP ((k − 1)τ (S) < T 1
x)
Xk=2

1

2ek−1! .

k

∞

Since the series in the right hand side converges we have

ET 1

x = O(fS(d)).

Once the bivariate S process hits the diagonal

d

d

we devise one obvious coupling that forces the bivariate X process to stay in D and such that the

D = {(x, y) ∈ Qd × Qd;

yi},

(3.13)

xi =

Xi=1

Xi=1

distance deﬁned in (3.5) between the marginal processes does not decrease. In words: we select

one coordinate at random; if the marginal processes coincide in that coordinate, we allow them

to evolve together; otherwise we select another coordinate in order to force two new coincidences.

Formally, for each (X(t), Y(t)) ∈ D, let I1, I2 and I3 be the partition of {0, 1, . . . , d} such that

I1 = {i; Xi(t) = Yi(t)}
I2 = {i; Xi(t) = 0, Yi(t) = 1}
I3 = {i; Xi(t) = 1, Yi(t) = 0}

8

Given (X(t), Y(t)) ∈ D, choose i u.a.r. from {0, 1, . . . , d}.

(a) If i ∈ I1;

1. If Xi(t) = 1 then make Xi(t + 1) = Yi(t + 1) = 0 with probability ps(X(t))−1; otherwise

Xi(t + 1) = Yi(t + 1) = 1.

2. If Xi(t) = 0 then make Xi(t + 1) = Yi(t + 1) = 1 with probability ps(X(t)); otherwise

Xi(t + 1) = Yi(t + 1) = 0.

(b) If i ∈ I2;

1. Select j ∈ I3 u.a.r.;
2. Make Xi(t + 1) = Yj(t + 1) = 1 with probability ps(X(t)); otherwise Xi(t + 1) =

Yj(t + 1) = 0.

(c) If i ∈ I3;

1. Select j ∈ I2 u.a.r.;
2. Make Xi(t + 1) = Yj(t + 1) = 0 with probability ps(X(t))−1; otherwise Xi(t + 1) =

Yj(t + 1) = 1.

Then, it is easy to check that (X(t + 1), Y(t + 1)) ∈ D and d(X(t + 1), Y(t + 1)) ≤

d(X(t), Y(t)). Moreover, noticing that |I2| = |I3| = d(X(t), Y(t))/2, we have
P(d(X(t + 1), Y(t + 1)) = d(X(t), Y(t)) − 2 | X(t), Y(t)) =

d(X(t), Y(t))

2d

(ps(X(t)) + ps(X(t))−1)

P(d(X(t + 1), Y(t + 1)) = d(X(t), Y(t)) | X(t), Y(t)) = 1 −

d(X(t), Y(t))

2d

(ps(X(t)) + ps(X(t))−1).

(3.14)

In this case, it is straightforward to compute

m(i, s(X(t))) = i − E[d(X(t + 1), Y(t + 1)) | d(X(t), Y(t)) = i, X(t), Y(t)]

=

(ps(X(t)) + ps(X(t))−1).

i
d

(3.15)

(3.16)

x be the coupling time for the second coupling just described. That is, let T 2

Let T 2
inf{t > T 1
martingales we have the following comparison lemma (cf. Aldous and Fill [2], Chapter 2).

x : d(X(t), Y(t)) = 0}. Then, as a consequence of the optional sampling theorem for

x =

9

Lemma 3.17

E[T 2

x|d(X(T 1

x ), Y(T 1

x )) = L, (X(T 1

x ), Y(T 1

x )) ∈ D, s(X(T 1

x )) = s] ≤

d

i(ps + ps−1)

(3.18)

L

Xi=1

for all s = 0, 1, . . . , d.

Proof. Deﬁne (X′(t), Y′(t)) = (X(t + T 1
and Ft = σ(X′(t), Y′(t)). Then, it follows from (3.16) that

x), Y(t + T 1

x ) for all t ≥ 0. Deﬁne Z(t) = d(X′(t), Y′(t))

m(i, s) = i − E[Z(1)|Z(0) = i, s(X′(0)) = s].

(3.19)

Also, for all s ∈ {1, . . . , d − 1}, 0 < m(1, s) ≤ m(2, s) ≤ . . . ≤ m(d, s). Fix s ∈ {1, . . . , d − 1}
and write

i

h(i) =

Xj=1

1

m(i, s)

(3.20)

and extend h by linear interpolation for all real 0 ≤ x ≤ d. Then h is concave and for all i ≥ 1

E[h(Z(1)) | Z(0) = i, s(X′(0)) = s] ≤ h(i − m(i, s))

≤ h(i) − m(i, s)h′(i)
= h(i) − 1,

where the ﬁrst inequality follows from the concavity of h and h′ is the ﬁrst derivative of h. Now,
deﬁning ˜h such that

h(i) = 1 +Xj

P[h(Z(1)) | Z(0) = i, s(X′(0)) = s]h(j) + ˜h(i)

and

t−1

M (t) = t + h(Z(t)) +

˜h(Z(u))

Xu=0

(3.21)

(3.22)

we have that M is an Ft-martingale and applying the optional sampling theorem to the stopping
time T0 = inf{t; Z(t) = 0} we have

E[M (T0) | Z(0) = i, s(X′(0)) = s] = E[M (0) | Z(0) = i, s(X′(0)) = s] = h(i).

(3.23)

10

Noticing that M (T0) ≥ T0 and T0 = T 2
Since s(X(t)) is distributed as πS, we can write:

x, we obtain the desired result •

E[T 2

x|d(X(T 1

x ), Y(T 1

x )) = L, (X(T 1

x ), Y(T 1

x )) ∈ D] ≤

d

Xs=0

πS(s)

L

Xi=1

d

i(ps + ps−1)

:= g(d).

(3.24)

Putting the pieces together, we have found a coupling time Tx for the whole process such

that

ETx ≤ fS(d) + g(d).

The task now is to ﬁnd explicit bounds for fS(d) and g(d) for particular workable cases.

To avoid unnecessary complications, we will assume d = 2m, and compute only the hitting

times for the S process of the type E0Tm. Hitting times in birth-and-death processes assume

the following closed-form (see [11] for an electrical derivation):

EkTk+1 =

1

πkP (k, k + 1)

and in our case this expression turns into

πi,

k

Xi=0

0 ≤ k ≤ d − 1,

Therefore

.

EkTk+1 = Pk
i=0(cid:0)d
i(cid:1)
(cid:0)d−1
k (cid:1)pk
Xk=0 Pk
i=0(cid:0)2m
i (cid:1)
(cid:0)2m−1
k (cid:1)pk

m−1

E0Tm =

(i) In case all pk = 1, we have the simple random walk on the cube, and it turns out there

.

(3.25)

is an even more compact expression of (3.25), namely:

E0Tm =

m−1

Xk=0 Pk
i=0(cid:0)2m
i (cid:1)
(cid:0)2m−1
k (cid:1)

= m

1

2k + 1

,

m−1

Xk=0

as was proved in [3], and the right hand side of (3.26) equals m[H(2m) −
H(n) = 1 + 1
4 log d + d

n , allowing us to conclude immediately that in this case E0Tm = E0Td/2 ≈

2 +··· + 1

4 log 2.

d

(3.26)

1
2

H(m)], where

11

Also, we have

E[T 2

x|d(X(T 1

x ), Y(T 1

x )) = L, (X(T 1

x ), Y(T 1

x )) ∈ D] ≤

d
2p

L

Xi=1

1
i ≈

d
2p

O(log L).

(3.27)

Thus in this case both fS(d) and g(d), and a fortiori ETx and τ , are O(d log d).

(ii) For the Aldous cube, pk = k

d−1 , and (3.25) becomes (recall this cube excludes the origin):

E1Tm =

m−1

Xk=1 Pk
i=0(cid:0)2m
i (cid:1)
(cid:0)2m−2
k−1 (cid:1)

=

m−2

Xk=0 Pk
i=0(cid:0)2m
i (cid:1)
(cid:0)2m−2
k (cid:1)

+

m−2

Xk=0 (cid:0) 2m
k+1(cid:1)
(cid:0)2m−2
k (cid:1)

.

(3.28)

After some algebra, it can be shown that the second summand in (3.28) equals (2m −
], and the ﬁrst summand can be bounded by twice the expression in (3.26),

k (cid:19) ≤ 2(cid:18)2m − 2

k (cid:19), for 0 ≤ k ≤ m − 1. Therefore, we can

1
m

1)[H(2m − 1) −
on account of the fact that (cid:18)2m − 1

write

E1Td/2 ≤

3
2

d log d + smaller terms,

thus improving by a factor of 1

2 the computation of the same hitting time in [5].

Also, we have

E[T 2

x|d(X(T 1

x ), Y(T 1

x )) = L, (X(T 1

x ), Y(T 1

x )) ∈ D, s(X(T 1

x )) = s] ≤

L

Xi=1

d(d − 1)
i(2s − 1)

(3.29)

Thus, in this case

E[T 2

d

≤

πS(s)

x ), Y(T 1

x)) ∈ D]

x ), Y(T 1
d

x|d(X(T 1
Xs=1
≤ Φ(−
≈ e−d/9d(d − 1) log d + (1 − e−d/9)d log d.

x )) = d, (X(T 1
d(d − 1)
Xi=1
i(2s − 1)
√d/3)
d(d − 1)
Xi=1

+ (1 − Φ(−

i

d

√d/3))

d

Xi=1

d(d − 1)
i(2d/3 − 1)

(3.30)

And so τ = O(d log d) also in this case.

12

(iii) Slower walks. Consider the case when the probability pk grows exponentially in k, more

speciﬁcally

pk =(cid:16) k + 1
n + 1(cid:17)α

(3.31)

with α > 1. In this case, it seems that (3.25) is useless to get a closed expression for E0Td/2.

However, Graham and Chung [5] provide the following bound

EiTd/2 ≤ c0(α)dα,

for all d ≥ d0(α), 0 ≤ i ≤ d

(3.32)

where c0(α) and d0(α) are constants depending only on α. Moreover, (3.24) becomes

g(d) =

d(d + 1)α

i((s + 1)α + sα)

d

d

d

πS(s)

Xs=0

= d(d + 1)α

Xi=1
Xs=0
≈ d(d + 1)α log d

πS(s)

(s + 1)α + sα

1
i

d

Xi=1

(s + 1)α + sα

d

πS(s)

d

Xs=0
Xs=0
≤ d(d + 1)α log d
= d(d + 1)α log dEh
(1 + X)αi,

πS(s)
(s + 1)α

1

(3.33)

where X is a Binomial (d, 1
2 ) random variable. Jensen’s inequality and the same argument that
lead to (3.30) show that E[(1 + X)−α] ∼ O(d−α) and (3.33) can be bound by O(d log d). This
fact together with (3.32) allows us to conclude that τ = O(dα) in this case, thus improving on

the rate of the mixing time provided in [5] by a factor of log d.

Acknowledgments. This paper was initiated when both authors were visiting scholars at the

Statistics Department of the University of California at Berkeley. The authors wish to thank

their hosts, especially Dr. David Aldous with whom they shared many fruitful discussions. This

work was partially supported by FAPESP 99/00260-3.

References

13

[1] Aldous, D.J. (1982) Some inqualities for reversible Markov chains, Journal of the London

Mathematical Society, 2, 25:564–576.

[2] Aldous, D. J. and Fill, J. (2000) Reversible Markov chains and random walks on graphs,

book draft.

[3] Blom, G. (1989) Mean transition times for the Ehrenfest urn, Advances in Applied Proba-

bility, 21, 479-480.

[4] Chandra, A. K., P. Raghavan, W. L. Ruzzo, R. Smolensky and P. Tiwari (1989), The

electrical resistance of a graph captures its commute and cover times, in Proceedings of the

Twenty First Annual ACM Symposium on Theory of Computing, Seattle, Washington, pp.

574-586.

[5] Chung, F. R. K. and Graham, R. L. (1997) Stratiﬁed random walks on the n-cube, Random

Structures and Algorithms, 11, 199-222.

[6] Feige, U. (1995)) A tight lower bound on the cover time for random walks on graphs,

Random Structures and Algorithms, 6, 433-438.

[7] Griﬀeath, D. (1975) A maximal coupling for Markov chains, Z. Wahrscheinlichkeitstheorie

verw. Gebiete, 31, 95-106.

[8] Lov´asz, L. and Winkler, P. (1998) Mixing times, in DIMACS Series in Discrete Mathemat-

ics and Theoretical Computer Science, 41, American Mathematical Society.

[9] Matthews, P. C. (1988) Covering problems for Markov chains, Annals of Probability, 16,

1215-1228.

[10] Palacios, J. L. (1994) Another look at the Ehrenfest urn via electric networks, Advances in

Applied Probability, 26, 820-824.

[11] Palacios, J. L. and Tetali, P. (1996) A note on expected hitting times for birth and death

chains, Statistics & Probability Letters, 30, 119-125.

14

