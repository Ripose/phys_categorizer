4
0
0
2
 
b
e
F
 
7
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
2
4
0
2
0
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Competition of Two Types of Correlations in Coarse-Grained Natural Written Texts

S. S. Melnyk
Department of Physics, Kharkov National University, 4 Svoboda Sq., Kharkov 61077, Ukraine

O. V. Usatenko, V. A. Yampol’skii ∗
A. Ya. Usikov Institute for Radiophysics and Electronics
Ukrainian Academy of Science, 12 Proskura Street, 61085 Kharkov, Ukraine

V. A. Golick
Academic Gymnasium No 45, 46-a Tobolskaya Street, Kharkov, Ukraine

A theory of additive Markov chains with long-range memory is used for a description of correla-
tion properties of literary texts. The coarse-grained naturally written texts are shown to be strongly
correlated sequences that possess antipersistent properties at small distances (in the region of gram-
matical rules action, L <∼ 300) and persistent ones at long distances (in the region of semantic rules
action, L >∼ 300). For some concrete examples of literary texts, a memory function is constructed
and its power-law behavior is revealed at long distances. This behavior is shown to be a cause for
self-similarity of coarse-grained texts with respect to the decimation procedure.

PACS numbers: 05.40.-a, 02.50.Ga, 87.10.+e

The problem of long-range correlated dynamic systems
(LRCS) has been under study for a long time in many
areas of contemporary physics [1, 2, 3, 4, 5, 6], biol-
ogy [7, 8, 9, 10, 11, 12], economics [8, 13, 14], etc. [8, 15].
One of important examples of complex LRCS are nat-
urally written texts [16, 17, 18, 19, 20]. The eﬃcient
method for investigating into such systems consists in the
decomposition of the space of states into a ﬁnite number
of parts labelled by deﬁnite symbols, which are natu-
rally ordered according to the dynamics of the system.
The most frequently decomposition procedure is based
on the introduction of two parts of the phase space. In
other words, the approach supposes mapping two kinds
of states into two symbols, say 0 and 1. This procedure
is often referred to as coarse graining. Thus, the prob-
lem is reduced to investigating the statistical properties
of binary sequences.

It might be thought that the coarse graining procedure
could result in losing, at least, the short-range mem-
ory between symbols in the sequence. However, as in-
dicated out below, this procedure retains, although not
completely, the correlations at all distances. This means
that, for the analysis of correlation properties of the dy-
namic systems, there is no point in coding every symbol
(associating every part of the phase space of the system
with its binary code), as it is done so, for example, in
Ref. [18], but it is suﬃcient to use the coarse graining
procedure.

One of the ways to get a correct insight into the
nature of correlations in a system consists in an abil-
ity of constructing a mathematical object (for example,

∗yam@ire.kharkov.ua

a correlated sequence of symbols) possessing the same
statistical properties as the initial system. There ex-
ist many algorithms for generating long-range correlated
sequences: the inverse Fourier transformation [15], the
expansion-modiﬁcation Li method [21], the Voss pro-
cedure of consequent random additions [22], the corre-
lated Levy walks [23], etc. [15]. We believe that, among
the above-mentioned methods, the use of the many-step
Markov chains is one of the most important. This was
demonstrated in Ref. [24], where the model Markov chain
with the step-like memory function (which allows the an-
alytical treatment) was considered. In the present work,
we continue investigating into symbolic dynamic systems,
examining them as additive Markov chains, but use more
complex memory functions. After ﬁnding the memory
function of the original coarse-grained text on the ba-
sis of the analysis of its statistical properties, we can
construct the corresponding Markov chain, which pos-
sesses the same properties as the initial sequence.
In
this work, we study the character of correlations of the
coarse-grained literary texts by examining their memory
functions.

A sequence of the symbols in a Markov chain can be
thought of as the sequence of states of some particle,
which participates in a correlated Brownian motion. Ev-
ery element of the sequence corresponds to the instant
change of the particle’s coordinate. For example, we
can associate symbol ”1” with an increase of the par-
ticle’s coordinate by 1 (a jump) and symbol ”0” with
the invariability of its coordinate (absence of the jump).
Thus, every L-word (the portion of the length L in the
sequence) can be considered as one of the realizations of
the ensemble of correlated Brownian trajectories in the
”time” interval L. This point of the symbolic sequence
gives an opportunity to use the statistical methods for

investigating the correlation properties of the dynamical
systems.

The sub- and super-linear dependences of the variance
D(L) of the number of deﬁnite symbols (say, unities) in
the L-words that were observed for the coarse-grained lit-
erary texts in Ref. [24] can be interpreted in terms of the
memory function. In the present paper, we have found
that this function is negative at short distances, L <
∼ 300,
and that provides the antipersistent behavior of diﬀusion
trajectories. Indeed, the D(L) function is sub-linear at
these distances. As for long distances, the memory func-
tion is shown to be positive and follows the power-law
decreasing behavior at L >
∼ 300. This fact leads to the
persistent diﬀusion and to super-linear D(L) dependence.
We have also demonstrated that the power-law decrease
of the memory function results in the self-similarity phe-
nomenon in the coarse-grained written texts with respect
to the decimation procedure.

The power-law character of the decrease in long-range
correlations in diﬀerent systems, particularly, in the DNA
and literary texts, was mentioned by a number of au-
thors, but no one has yet associated it with the properties
of the memory function.

Let us consider a homogeneous binary sequence of sym-
bols, ai = {0, 1}. To determine the N -step Markov
chain we have to introduce the conditional probabil-
ity P (ai | ai−N , ai−N +1, . . . , ai−1) of occurring the def-
inite symbol ai (for example, ai = 0) after sym-
bols ai−N , ai−N +1, . . . , ai−1. Thus,
it is necessary to
deﬁne 2N values of the P -function corresponding to
each possible conﬁguration of the symbols in N -word
ai−N , ai−N +1, . . . , ai−1. We suppose that the P -function
has the additive form,

P (ai = 0 | ai−N , ai−N +1, . . . , ai−1)

2

information about correlation properties of the Markov
chain. The suitability of using the additive N -step
Markov chains for a description of the correlation prop-
erties of literary texts was demonstrated in Refs. [20, 24].
Usually, the correlation function and other moments are
employed as the input characteristics for the description
of the correlated random systems. Yet, the correlation
function describes not only the direct interconnection of
the elements ai and ai+r, but also takes into account
their indirect interaction via other elements. Our ap-
proach operates with the “origin” characteristics of the
system, speciﬁcally with the memory function. There-
fore, we believe that this way allows one to disclose the
intrinsic properties of the system which provide the cor-
relations between the elements.

The memory function used in Refs. [20, 24] was char-
acterized by step-like behavior and deﬁned by two pa-
rameters only: the memory depth N and the strength of
symbol’s correlations. Such a memory function allowed
us to describe the coarse persistent properties of the liter-
ary texts, speciﬁcally, the super-linear dependence D(L),
but was not able to reﬂect the antipersistent behavior of
D(L) at short distances L. Obviously, we need in a more
complex memory function for detailed description of the
both short-range and long-range properties of the coarse-
grained literary texts.

The positive values of the MF result in persistent diﬀu-
sion where previous displacements of the Brownian par-
ticle in some direction provoke its consequent displace-
ment in the same direction. The negative values of the
MF correspond to the antipersistent diﬀusion where the
changes in the direction of motion are more probable. In
terms of the Ising model of long-range particles interac-
tions, that could be naturally associated with the Markov
chains, the positive values of the MF correspond to the
attraction of particles and negative ones conform to the
repulsion.

The result of the numerical simulation of the D(L)

=

1
N

N

X
k=1

f (ai−k, k).

(1)

dependence,

Here the value f (ai−k, k)/N is the contribution of the
symbol ai−k to the conditional probability of occurring
the symbol zero at the ith site. Eq. (1) corresponds to
the additive inﬂuence of the previous symbols on the gen-
erated one. The homogeneity of the Markov chain is pro-
vided by the independence of the conditional probability
Eq. (1) of the index i.

Let us rewrite Eq. (1) in an equivalent form,

P (. | .) = 1 − ¯a +

F (r)(¯a − ai−r).

(2)

N

X
r=1

Here ¯a denotes the value of ai averaged over the whole
sequence. We refer F (r) to the memory function (MF).
It describes the inﬂuence of previous symbol ai on gen-
erated ones. The function P (. | .) contains the complete

D = (k − ¯k)2/4¯a(1 − ¯a),

(3)

(k is the number of unities in an L-word), for the coarse-
grained text of the Bible is presented by the solid line
in Fig. 1. The straight dotted line in this ﬁgure de-
scribes the variance D0(L) = L/4, which corresponds
to the non-correlated Brownian diﬀusion. One of the
typical coarse-graining procedure was used for mapping
the letters of the text onto the symbols zero and unity
((a − m) 7→ 0, (n − z) 7→ 1). The dominator 4¯a(1 − ¯a)
D(L) is inserted into the D(L) deﬁnition Eq. (3) in or-
der to take into account the inequality in the average
numbers of zeros and unities in the coarse-grained liter-
ary texts. The deviation of the solid line from the dotted
one testiﬁes to the existence of the correlations in the text
of Bible. It is clearly seen that the diﬀusion is antiper-

sistent at small distances, L <
whereas it is persistent at long distances.

∼ 300, (see inst in Fig. 1)

10

10

10

10

7

6

5

4

3

2

1

0

10

10

10

-1

10

D

10

1

2

3

10

10

10

L

2

1

0

 

/

D
D

L

0

1

2

3

4

5

6

10

10

10

10

10

10

10

FIG. 1: The normalized variance D(L) for the coarse-grained
text of the Bible (solid line) and for the sequence generated
by means of the reconstructed memory function F (r) (dots).
The dotted straight line describes the non-correlated Brow-
nian diﬀusion, D0(L) = L/4. The inset demonstrates the
antipersistent dependence of dimensionless ratio D(L)/D0(L)
on L at short distances.

The minimization of deviation between the variances
D(L) for the generated Markov chain and for the coarse-
grained text was our instrument for ﬁnding text’s mem-
ory function F (r). The obtained MF for the coarse-
grained text of the Bible at r < 300 is presented in
Fig. 2. At long distances r > 300, the memory func-
tion can be nicely approximated by the power function
F (r) = 0.25r−1.1, which is presented by the solid line
in the inset to Fig. 2. Note that the persistent part of
the MF F (r > 300) ≤ 0.0008 is much less than its typ-
ical magnitude 0.02 in the antipersistent region r < 40.
We believe that the sub-linear character of the diﬀusion
at short distances and the antipersistent correlations (re-
pulsion between the symbols, a tendency to change the
diﬀusion direction) are related to the grammatical rules
acting in the languages. The super-linear diﬀusion and
the persistent character of correlations at long distances,
L ≫ 300, can be interpreted as a result of the general
semantic idea of a literary work and the correspondent
repetitions of some words and expressions in a text.

Let us pay attention to the fact that the region r <
∼
40 of negative antipersistent memory function provides
much longer distances L ∼ 300 of antipersistent behavior
of the variance D(L) and antipersistent diﬀusion.

The existence of two characteristic regions with dif-
ferent behavior of the memory function and, correspond-
ingly, of persistent and antipersistent portions in the vari-
ance D(L) dependence appears to be a prominent feature
of all texts of any natural language. The pronounced an-
tipersistent zone in the D(L) plot is very sensitive to a
kind of the coarse graining procedure. On the contrary,

3

0.04

0.00

F

-0.04

-0.08

2

3

4

 

L

10

10

10

-3

10

-4

10

F

-5

10

L

1

10

100

FIG. 2: The memory function F (r) for the coarse-grained
text of the Bible at short distances. In the inset, the power-
law decreasing portions of the F (r) plots for several texts are
presented. The solid and dashed lines correspond to the Bible
in English and Russian, respectively. Dotted line corresponds
to ”Pygmalion” by B. Show.

the long-range persistent zone is practically insensible to
the type of coarse graining and to the translation of the
text from one language into another. The positive per-
sistent portions of the memory functions are presented in
the inset in Fig. 2 for the English- and Russian-worded
Bible (solid and dashed lines). Besides, for comparison,
the memory function of the coarse-grained text of ”Pyg-
malion” by B. Show is shown in the same inset (dotted
line). It is clearly seen that the MF plot for ”Pygmalion”
diﬀers from the plots for the Bible much more essentially
than plots for versions of the Bible in English and Rus-
sian. Closeness of the memory functions for the Bible in
diﬀerent languages reﬂects, perhaps, their semantic iden-
tity.

Two fundamentally diﬀerent portions in the MF plots
result in a peculiar competition of two type of correla-
tions. We would like to note that both portions of MF
are equally important for understanding the correlation
properties of the literary texts. To support this state-
ment we generated two sequences. In both of them, only
one type of the memory function for the coarse-grained
text of the Bible was taken into account, and the mem-
ory function in another region was assumed to be zero.
The variance D(L) for these two sequences is given in
Fig. 3. The lower (dashed) line corresponds to the case
where the negative antipersistent portion, r < 40, of the
memory function was allowed for only. The upper (dash-
dot-dotted) curve corresponds to the sequence, which was
generated by means of the long-range persistent memory,
F (r) = 0.25r−1.1, r > 100. It is evident that the gen-
erated sequence with the antipersistent memory function
displays the sub-diﬀusion only, whereas the sequence that
corresponds to the persistent memory function is charac-
terized by the super-diﬀusion behavior of the variance

D(L). The diﬀerence between the variances for two gen-
erated sequences and for the original coarse-grained text
of the Bible, showen by the solid line in the same ﬁg-
ure, corroborates our supposition about the importance
of both types of the memory function.

8

7

6

5

4

3

2

1

0

10

10

10

10

10

0

D
D

/

10

10

10

10

-1

10

0

1

2

3

4

5

6

10

10

10

10

10

10

10

L

FIG. 3: Normalized variance D(L) for the coarse-grained text
of the Bible (the solid line), and for the sequences constructed
with using the persistent part of the MF (dash-dot-dotted
line) and the antipersistent one (dashed line). The dotted
line describes the non-correlated Brownian diﬀusion, D0(L) =
L/4.

The power-law decrease (without characteristic scale)
of the memory function at long distances leads to quite
an important property of self-similarity of the coarse-
grained texts with respect to the decimation procedure
discussed in Ref. [24]. This procedure implies the de-
terministic or random removal of some part of symbols
from a sequence. The sequence is self-similar if its vari-
ance D(L) does not change after the decimation up to a
deﬁnite value of L (which is dependent on the memory
depth of the original sequence and the decimation pa-
rameter). The model of the additive binary many-step
Markov chain with the step-like MF (which was discussed
in Ref. [24]) possesses the exact property of self-similarity
at the length shorter than the memory depth. The
coarse-grained literary texts possess the self-similarity
property as well. This property is demonstrated by Fig. 4
where three D(L) curves correspond to diﬀerent values
of the parameters of the regular decimation. Note that
the decimation procedure leads to a decrease in the eﬀec-
tive memory length. As a result, the coincidence of the
variance curves takes place up to the eﬀective memory
depth, which decreases proportionally to the decimation
parameter. An analogous phenomenon occurs in the case
of random decimation as well.

A question arises: what property of the memory func-
tion is crucial for the self-similarity of the coarse-grained
literary texts. It is natural to assume that the persistent
long-range scale-free portion of the memory function af-
fords this property because the self-similarity manifests

4

10

10

10

10

D

10

6

5

4

3

2

1

0

10

10

-1

10

1

2

3

4

5

6

10

10

10

10

10

10

L

3

10

 

D

7

10

5

10

1

10

-1

10

L

0

1

2

3

4

5

10

10

10

10

10

10

FIG. 4: Numerically calculated variance D(L) for the coarse-
grained text of the Bible (solid line) and for the sequences
obtained after their regular decimation. Circles, triangles,
and dots correspond to the decimation parameters 2, 4, and
8, respectively. The dotted line describes the non-correlated
Brownian diﬀusion, D0(L) = L/4. The similar curves ob-
tained for the sequence constructed by using the long-range
part of the Bible’s memory function are shown in the inset.

itself speciﬁcally at the long distances. To check this sup-
position we have carried out the decimation procedure
with the Markov chain constructed by using the long-
range part of the Bible’s memory function only and then
plotted the correspondent D(L) dependences. These
curves are shown in the inset to Fig. 4. It is seen that
the property of self-similarity for this sequence appears to
be much more pronounced than for the original coarse-
grained text of the Bible. Moreover, the antipersistent
part of the MF disappears very fast after the decimation
procedure. This is clearly observed as a disappearance of
the antipersistent sub-linear portion of the D(L) curves
in Fig. 4 where the solid line after being decimated trans-
forms into the wholly persistent super-linear line, which
goes above the curve D0 = L/4.

Thus, we have demonstrated the eﬃciency of descrip-
tion of the symbolic sequences with long-range correla-
tions in terms of the memory function. Actually, the
memory function appears to be a suitable informative
”visiting card” of any symbolic stochastic process. As
an example, we have studied the coarse-grained literary
texts and shown the complexity of their organization in
contrast to a previously discussed simple power-law de-
crease of correlations. The suggested approach can be
used for the analysis of other correlated systems in dif-
ferent ﬁelds of science.

We acknowledge to Dr. S. V. Denisov for the helpful

discussions.

[1] U. Balucani, M. H. Lee, V. Tognetti, Phys. Rep. 373,

409 (2003).

[2] I. M. Sokolov, Phys. Rev. Lett. 90, 080601 (2003).
[3] A. Bunde, S. Havlin, E. Koscienly-Bunde, H.-J. Schellen-

huber, Physica A 302, 255 (2001).

[4] H. N. Yang, Y.-P. Zhao, A. Chan, T.-M. Lu, and G. C.

Wang, Phys. Rev. B 56, 4224 (1997).

[5] S. N. Majumdar, A. J. Bray, S. J. Cornell, and C. Sire,

Phys. Rev. Lett. 77, 3704 (1996).

[6] S. Halvin, R. Selinger, M. Schwartz, H. E. Stanley, and

A. Bunde, Phys. Rev. Lett. 61, 1438 (1988).
[7] R. F. Voss, Phys. Rev. Lett. 68, 3805 (1992).
[8] H. E. Stanley et. al., Physica A 224,302 (1996).
[9] S. V. Buldyrev, A. L. Goldberger, S. Havlin, R. N. Man-
tegna, M. E. Matsa, C.-K. Peng, M. Simons, H. E. Stan-
ley, Phys. Rev. E 51, 5084 (1995).

[10] A. Provata and Y. Almirantis, Physica A 247, 482

(1997).

[11] R. M. Yulmetyev, N. Emelyanova, P. H¨anggi, and F. Ga-

farov, A. Prohorov, Phycica A 316, 671 (2002).

[12] B. Hao, J. Qi, Mod. Phys. Lett., 17, 1 (2003).

5

[13] R. N. Mantegna, H. E. Stanley, Nature (London) 376,

46 (1995).

[14] Y. C. Zhang, Europhys. News, 29, 51 (1998).
[15] A. Czirok, R. N. Mantegna, S. Havlin, and H. E. Stanley,

Phys. Rev. E 52, 446 (1995).

[16] A. Schenkel, J. Zhang, and Y. C. Zhang, Fractals 1, 47

[17] I. Kanter and D. F. Kessler, Phys. Rev. Lett. 74, 4559

[18] P. Kokol, V. Podgorelec, Complexity International, 7, 1

(1993).

(1995).

(2000).

[19] W.

Ebeling,

A.

Neiman,

T.

Poschel,

arXiv:cond-mat/0204076.

[20] O. V. Usatenko, V. A. Yampol’skii, S. S. Mel’nyk, and
K. E. Kechedzhy, Phys. Rev. E 68, 061107 (2003).

[21] W. Li, Europhys. Let. 10, 395 (1989).
[22] R. F. Voss, in: Fundamental Algorithms in Computer
Graphics, ed. R. A. Earnshaw (Springer, Berlin, 1985) p.
805.

[23] M. F. Shlesinger, G. M. Zaslavsky, and J. Klafter, Nature

[24] O. V. Usatenko and V. A. Yampol’skii, Phys. Rev. Lett.

(London) 363, 31 (1993).

90, 110601 (2003).

