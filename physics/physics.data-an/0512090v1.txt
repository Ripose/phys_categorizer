5
0
0
2
 
c
e
D
 
0
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
0
9
0
2
1
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Large dimension forecasting models and
random singular value spectra

Jean-Philippe Bouchaud1,2, Laurent Laloux1
M. Augusta Miceli3,1, Marc Potters1

February 2, 2008

1 Science & Finance, Capital Fund Management, 6 Bd Haussmann, 75009 Paris,
France.
2 Service de Physique de l’´Etat Condens´e Orme des Merisiers – CEA Saclay, 91191
Gif sur Yvette Cedex, France
3 Universit`a La Sapienza, Piazzale Aldo Moro, 00185 Roma, Italy

Abstract

We present a general method to detect and extract from a ﬁnite
time sample statistically meaningful correlations between input and
output variables of large dimensionality. Our central result is derived
from the theory of free random matrices, and gives an explicit expres-
sion for the interval where singular values are expected in the absence
of any true correlations between the variables under study. Our re-
sult can be seen as the natural generalization of the Marˇcenko-Pastur
distribution for the case of rectangular correlation matrices. We il-
lustrate the interest of our method on a set of macroeconomic time
series.

1 Introduction

Finding correlations between observables is at the heart of scientiﬁc method-
ology. Once correlations between “causes” and “eﬀects” are empirically es-
tablished, one can start devising theoretical models to understand the mech-
anisms underlying such correlations, and use these models for prediction

1

purposes. In many cases, the number of possible causes and of resulting ef-
fects are both large. For example, one can list an a priori large number of
environmental factors possibly favoring the appearance of several symptoms
or diseases, or of social/educational factors determining choices and tastes
on diﬀerent topics. A vivid example is provided by Amazon.com, where taste
correlations between a huge number of diﬀerent products (books, CDs, etc.)
are sought for. In the context of gene expression networks, the number of
input and output chemicals and proteins, described by their concentration, is
very large. In an industrial setting, one can monitor a large number of char-
acteristics of a device (engine, hardware, etc.) during the production phase
and correlate these with the performances of the ﬁnal product. In economics
and ﬁnance, one aims at understanding the relation between a large number
of possibly relevant factors, such as interest and exchange rates, industrial
production, conﬁdence index, etc. on, say, the evolution of inﬂation in dif-
ferent sectors of activity [1], or on the price of diﬀerent stocks. Nowadays,
the number of macroeconomic time series available to economists is huge (see
below). This has lead Granger [2] and others to suggest that “large models”
should be at the forefront of the econometrics agenda. The theoretical study
of high dimensional factor models is indeed actively pursued [3, 4, 5, 6, 7, 1],
in particular in relation with monetary policy [8, 1].

In the absence of information on the phenomenon under study, a brute
force strategy would consist in listing a large number of possible explanatory
variables and a large number of output variables, and systematically look
for correlations between pairs, in the hope of ﬁnding some signiﬁcant signal.
In an econometric context, this is the point of view advocated long ago by
Sims [9], who suggested to look at large Vector Autoregressive models, and
let the system itself determine the number and the nature of the relevant
variables. However, this procedure is rapidly aﬀected by the “dimensionality
curse”, also called the problem of sunspot variables in the economics litera-
ture [10]. Since the number of observations is always limited, it can happen
that two totally unrelated phenomenon (such as, for example, stock prices
and sunspots) appear to be correlated over a certain time interval T . More
precisely, the correlation coeﬃcient ρ, which would (presumably) be zero if
very long time series could be studied, is in fact of the order of 1/√T and
can be accidentally large. When one tries to correlate systematically N in-
put variables with M output variables, the number of pairs is NM. In the
absence of any true correlation between these variables, the largest of these
NM empirical correlation coeﬃcients will be, for Gaussian variables, of order

2

∼ q

2 ln(NM)/T , which grows with NM. For example, ρmax
0.25
ρmax
for N = M = 25 and T = 200. If the input and output variables are non
Gaussian and have fat-tails, this number can be even larger: if two strongly
ﬂuctuating random variable accidentally take large values simultaneously,
this will contribute a lot to the empirical correlation even though ρ should
be zero for large T .

≈

×

→ ∞

→ ∞

In this paper we want to discuss how recent results in Random Matrix
Theory [11, 12] allow one to alleviate this dimensionality curse and give a
precise procedure to extract signiﬁcant correlations between N input vari-
ables and M output variables, when the number of independent observations
is T . The idea is to compare the singular value spectrum of the empirical
N correlation matrix with a benchmark, obtained by assum-
rectangular M
ing no correlation at all between the variables. For T
at N, M ﬁxed,
all singular values should be zero, but this will not be true if T is ﬁnite.
The singular value spectrum of this benchmark problem can in fact be com-
puted exactly in the limit where N, M, T
, when the ratios m = M/T
and n = N/T ﬁxed. As usual with Random Matrix problems [11, 12], the
singular value spectrum develops sharp edges in the asymptotic limit which
are to a large extent independent of the distribution of the elements of the
matrices. Any singular value observed to be signiﬁcantly outside these edges
can therefore be deemed to carry some relevant information. A similar so-
lution has been known for a long time for standard correlation matrices, for
example the correlations of the N input variables between themselves that
deﬁne an N
N symmetric matrix. In this case, the benchmark is known as
the Wishart ensemble, and the relevant eigenvalue spectrum is given by the
Marˇcenko-Pastur distribution [13, 14, 15]. Applications of this method to ﬁ-
nancial correlation matrices are relatively recent [16] but very active [17, 18].
Comparing the empirical eigenvalues to the correlation matrix to the theo-
retical upper edge of the Marˇcenko-Pastur spectrum allows one to extract
statistically signiﬁcant factors [16] (although some may also be buried below
the band edge, see [17]). Similar ideas are starting to be discussed in the
econometric community, in particular to deal with the problem of identifying
the relevant factors in large dynamical factor models [19], and using them
for prediction purposes (see also [6] for a diﬀerent point of view). Here, we
extend the Marˇcenko-Pastur result to general rectangular, non-equal time
correlation matrices. We will ﬁrst present a precise formulation of our cen-
tral result, which we will then illustrate using an economically relevant data

×

3

set, and ﬁnally discuss some possible extensions of our work.

2 Mathematical formulation of the problem

We will consider N input factors, denoted as Xa, a = 1, ..., N and M output
factors Yα, α = 1, ..., M. There is a total of T observations, where both Xat
and Yαt, t = 1, ..., T are observed. We assume that all N + M time series are
standardized, i.e., both X’s and Y ’s have zero mean and variance unity. The
X and the Y ’s may be completely diﬀerent, or be the same set of observables
but observed at diﬀerent times, as for example N = M and Yαt = Xat+1.
From the set of X’s and Y ’s one can form two correlations matrices, CX and
CY , deﬁned as:

(CX)ab =

XatXbt

(CY )αβ =

YαtYβt.

(1)

1
T

T

Xt=1

1
T

T

Xt=1

In general, the X’s (and the Y ’s) have no reason to be independent of each
other, and the correlation matrices CX and CY will contain information on
their correlations. As alluded to above, one can diagonalize both these ma-
trices; provided T > N, M – which we will assume in the following – all
eigenvalues will, in generic cases, be strictly positive. In certain cases, some
eigenvalues will however lie close to zero, much below the lower edge of the
Marˇcenko-Pastur interval, corresponding to redundant variables which may
need to be taken care of (see below). Disregarding this problem for the mo-
ment, we use the corresponding eigenvectors to deﬁne a set of uncorrelated,
unit variance input variables ˆX and output variables ˆY . For example,
1

ˆXat =

VabXbt,

√T λa Xb
where λa is the ath eigenvalue of CX and Vab the components of the corre-
sponding eigenvector. Now, by construction, C ˆX = ˆX ˆX T and C ˆY = ˆY ˆY T are
exactly identity matrices, of dimension, respectively, N and M. Using general
T matrices D ˆX = ˆX T ˆX
property of diagonalisation, this means that the T
and D ˆY = ˆY T ˆY have exactly N (resp. M) eigenvalues equal to 1 and T
N
(resp. T

M) equal to zero.

−

×

−

Now, consider the M

N cross-correlation matrix G between the ˆX’s

(2)

and the ˆY ’s:

×

(G)αb =

T

Xt=1

ˆYαt ˆXbt ≡

ˆY ˆX T .

4

(3)

The singular value decomposition (SVD) of this matrix answers the follow-
ing question [20]: what is the (normalised) linear combination of ˆX’s on
the one hand, and of ˆY ’s on the other hand, that have the strongest mu-
tual correlation? In other words, what is the best pair of predictor and
predicted variables, given the data? The largest singular value smax and its
corresponding left and right eigenvectors answer precisely this question: the
eigenvectors tell us how to construct these optimal linear combinations, and
the associated singular value gives us the strength of the cross-correlation.
One can now restrict both the input and output spaces to the N
1 and
M
1 dimensional sub-spaces orthogonal to the two eigenvectors, and repeat
the operation. The list of singular values sa gives the prediction power, in
decreasing order, of the corresponding linear combinations.

−

−

3 Singular values from free random matrix

theory

D

×

×

M matrix GGT (or the N

How to get these singular values? If M < N, the trick is to consider the
N matrix GT G if M > N), which
matrix M
is symmetrical and has M positive eigenvalues, each of which being equal to
the square of a singular value of G itself. The second observation is that the
non-zero eigenvalues of GGT = ˆY ˆX T ˆX ˆY T are the same as those of the T
T
×
= D ˆXD ˆY = ˆX T ˆX ˆY T ˆY , obtained by swapping the position of ˆY
matrix
from ﬁrst to last. In the benchmark situation where the ˆX’s and the ˆY ’s are
independent from each other, the two matrices D ˆX and D ˆY are mutually free
[11] and one can use results on the product of free matrices to obtain the
eigenvalue density from that of the two individual matrices, which are known.
The general recipe [14, 11] is to construct ﬁrst the so-called η
transform of
the eigenvalue density ρ(u) of a given T
T non negative matrix A, deﬁned
as:

−

×

ηA(γ) =

duρ(u)

Z

1 + γu ≡

1

1
T

Tr

1
1 + γA

.

From the functional inverse of ηA, one now deﬁnes the Σ-transform of A as:

(4)

(5)

Endowed with these deﬁnitions, one of the fundamental theorems of Free
Matrix Theory [11] states that the Σ-transform of the product of two free

ΣA(x)

1 + x
x

≡ −

η−1
A (1 + x).

5

matrices A and B is equal to the product of the two Σ-transforms. [A similar,
somewhat simpler, theorem exists for sums of free matrices, in terms of “R-
transforms”, see [11]]. Applying this theorem with A = D ˆX and B = D ˆY ,
one ﬁnds:

ηA(γ) = 1

n+

, n =

ηB(γ) = 1

m+

, m =

. (6)

n
1 + γ

−

N
T

;

m
1 + γ

−

M
T

From this, one easily obtains:

ΣD(x) = ΣA(x)ΣB(x) =

(7)

(1 + x)2
(x + n)(x + m)

.

Inverting back this relation allows one to derive the η

transform of

as:

ηD(γ) =

1
2(1 + γ) (cid:20)

1

−

(µ + ν)γ +

(µ

ν)2γ2

q

−

−

−

D

2(µ + ν + 2µν)γ + 1

(cid:21)
(8)
of this quantity gives

−

−

−

1 and ν = n

1. The limit γ

with µ = m
the density of exactly zero eigenvalues, easily found to be equal to max(1
n, 1

−
m), meaning, as expected, that the number of non zero eigenvalues of
is min(N, M). Depending on the value of n + m compared to unity, the
D
pole at γ =
1 corresponding to eigenvalues exactly equal to one has a zero
weight (for n + m < 1) or a non zero weight equal to n + m
1. One can
re-write the above result in terms of the more common Stieltjes transform of

→ ∞

−

−

1/z)/z, which reads:

z + (µ + ν) +

(µ

ν)2 + 2(µ + ν + 2µν)z + z2

. (9)

(cid:21)

q

−

The density of eigenvalues ρD(z) is then obtained from the standard re-

, S(z)

D

≡

SD(z) =

η(

−
1
2z(z

1) (cid:20)

−

lation [11]:

ρD(z) = lim

ǫ→0 ℑ (cid:20)

1
πT

Tr

1
z + iǫ

= lim
ǫ→0

(cid:21)

1
π ℑ

[SD(z + iǫ)] ,

(10)

which leads to the rather simple ﬁnal expression, which is the central result
of this paper, for the density of singular values s of the original correlation
matrix G

ˆY ˆX T :

≡

ρ(s) = max(1

n, 1

m)δ(s)+max(m+n

1, 0)δ(s

−

−

1)+ ℜq

−

(s2

γ−)(γ+
s2)

−
πs(1

s2)

,

−

−

(11)

− D

−

6

 m=0.4, n=0.2
 m=n=0.3
 m=0.7, n=1−m=0.3
 m=n=0.8

0.8

0.6

)
s
(
ρ

 

0.4

0.2

0

0

0.5
 s

7

Figure 1: Continuous part of the theoretical random singular value spectrum ρ(s)
for diﬀerent values of n and m. Note that for n = m the spectrum extends down
s)−1/2 singularity,
to s = 0, whereas for n + m
−
just before the appearance of a δ peak at s = 1 of weight n + m

1, the spectrum develops a (1

→

1.

1

−

where γ± are the two positive roots of the quadratic expression under the
square root in Eq. (9) above, which read explicitely:1

γ± = n + m

2mn

2

mn(1

n)(1

m).

−

±

q

−

−

(12)

This is our main technical result, illustrated in Fig. 1. One can check that
in the limit T
at ﬁxed N, M, all singular values collapse to zero, as
they should since there is no true correlations between X and Y ; the allowed
band in the limit n, m

0 becomes:

→ ∞

→
s

√m

√n

, √m + √n
i

|

.

−

∈ h|

(13)

∈

q

−

→

→

→

[0, 2

m(1

n. When n + m

m, the allowed band becomes s

m)] (plus a δ
When n
−
function at s = 1 when n + m > 1), while when m = 1, the whole band
1−, the inchoate
collapses to a δ function at s = √1
s)−1/2.
δ-peak at s = 1 is announced as a singularity of ρ(s) diverging as (1
Finally, when m
0 at ﬁxed n, one ﬁnds that the whole band collapses
again to a δ function at s = √n. This last result can be checked directly
in the case one has one output variable (M = 1) that one tries to correlate
optimally with a set of N independent times series of length T . The result can
N/T . A plot of the SV density ρ(s)
easily be shown to be a correlation of
for values of m and n which will be used below is shown in Fig 2, together
with a numerical determination of the SVD spectrum of two independent
vector time series X and Y , after suitable diagonalisation of their empirical
correlation matrices to construct their normalised counterparts, ˆX and ˆY .
The agreement with our theoretical prediction is excellent.

−

q

Note that one could have considered a diﬀerent benchmark ensemble,
where the independent vector time series X and Y are not diagonalized and
transformed into ˆX and ˆY before SVD. The direct SVD spectrum in that
case can also be computed as the Σ-convolution of two Marˇcenko-Pastur dis-
tributions with parameters m and n, respectively (noted MP 2 in Fig. 2).
The result, derived in the Appendix, is noticeably diﬀerent from the above
prediction (see Fig. 1). This alternative benchmark ensemble is however not
well suited for our purpose, because it mixes up the possibly non trivial corre-
lation structure of the input variables and of the output variables themselves

1One can check that γ+

1 for all values of n, m < 1. The upper bound is reached
only when n + m = 1, in which case the upper edge of the singular value band touches
s = 1.

≤

8

 Theory (MP2)
 Theory (Standardized)
 Simulation (Random SVD)

0.3

0.2

)
s
(
ρ

 

0.1

0

0

0.2

0.4

0.6

0.8

1

 s

Figure 2: Random Singular Value spectrum ρ(s) for m = 35/265 and n =
76/265. We show two possible theoretical calculations, corresponding either to
bare random vectors X and Y , for which the singular value spectrum is related
to the ‘square’ (in the free convolution sense) of the Marˇcenko-Pastur distribution
M P 2, or standardized vectors ˆX and ˆY , obtained after diagonalizing the empirical
correlation matrices of X and Y . We also show the results of a numerical simulation
of the standardized case with T = 2650.

9

 Gaussian
 (cid:22)X t−1Yt
 XtYt

1000

100

10

)
ρ
(
P

 

1
−0.75

−0.5

−0.25

0.25

0.5

0.75

0
ρ

Figure 3: Histogram of the pair correlation coeﬃcient ρ between X’s and Y ’s,
both at equal times and with one month lag. Note the ‘island’ of correlations
around
0.6 for one-month lagged correlations, which corresponds to correlations
between oil prices and energy related CPI’s one month later. We also show a
Gaussian of variance 1/T , expected in the absence of any correlations.

≈

with the issue at stake here, namely the cross-correlations between input and
output variables.

4 Application: inﬂation vs. economic indica-

tors

We now turn to the analysis of a concrete example. We investigate how dif-
ferent groups of US inﬂation indexes can be explained using combinations of
indicators belonging to diﬀerent economic sectors. As “outputs” Y , we use 34
indicators of inﬂation, the monthly changes of the Composite Price Indexes
(CPIs), concerning diﬀerent sectors of activity including and excluding com-
modities. These indexes were not selected very carefully and some are very
redundant, since the point of our study is to show how the proposed method

10

is able to select itself the relevant variables. As explanatory variables, “in-
puts” X, we use 76 diﬀerent macroeconomic indicators from the following
categories: industrial production, retail sales, new orders and inventory in-
dexes of all available economic activity sectors, the most important consumer
and producer conﬁdence indexes, new payrolls and unemployment diﬀerence,
interest rates (3 month, 2 and 10 years), G7 exchange rates against the Dol-
lar and the WTI oil price itself. The total number of months in the period
June 1983-July 2005 is 265. We want to see whether there is any signiﬁ-
cant correlation between changes of the CPIs and of the economic indexes,
either simultaneous or one month ahead. We also investigated two-month
lag correlations, for which we found very little signal.

×

≈

t and for one-month lagged ˆYt ˆX T

We ﬁrst standardized the time series Y and X and form the rectangular
76 numbers
correlation matrix between these two quantities, containing 34
1, 1]. The distribution of these pair correlations is shown in
in the interval [
−
Fig. 3, both for equal time ˆYt ˆX ′
t−1 correla-
tions, and compared to a Gaussian distribution of variance T −1. We see that
the empirical distributions are signiﬁcantly broader; in particular an ‘island’
0.6 appears for the one-month lagged correlations.
of correlations around
These correspond to correlations between oil prices and energy related CPIs
one month later. The question is whether there are other predictable modes
in the system, in particular, are the correlations in the left and right ﬂanks
of the central peak meaningful or not? This question is a priori non trivial
because the kurtosis of some of the variables is quite high, which is expected
to ‘fatten’ the distribution of ρ compared to the Gaussian. Within the period
of about thirty years covered by our time series, three major rare events hap-
pened: the Gulf War (1991-92), the Asian crisis (1998), and the Twin Towers
Attack (2001). The kurtosis of the CPIs is the trace of the corresponding
outliers, such as the food price index and its ‘negative’, the production price
index excluding food, which are strongly sensitive to war events. Among
economic indicators, the most responsive series to these events appear to be
the inventory-sales ratio, the manufacturing new orders and the motor and
motor parts industrial production indexes.

In order to answer precisely the above question, we ﬁrst turn to the anal-
ysis of the empirical self-correlation matrices CX and CY , which we diagonal-
ize and represent the eigenvalues compared to the corresponding Marˇcenko-
Pastur distributions in Fig. 4, expected if the variables were independent
(see the Appendix for more details). Since the both the input and output
variables are in fact rather strongly correlated at equal times, it is not surpris-

11

≈

≈

ing to ﬁnd that some large eigenvalues λ emerge from the Marˇcenko-Pastur
noise band: for CX, the largest eigenvalue is
15, to be compared to the
theoretical upper edge of the Marˇcenko-Pastur distribution 2.358, whereas
6.2 to be compared with 1.858. But the
for CY the largest eigenvalue is
most important point for our purpose is the rather large number of very small
eigenvectors, much below the lower edge of the Marˇcenko-Pastur distribution
(λmin = 0.215 for CX, see Fig. 4). These correspond to linear combinations of
redundant (strongly correlated) indicators. Since the deﬁnition of ˆX and ˆY
include a factor 1/√λ (see Eq. (2)), the eigenvectors corresponding to these
small eigenvalues have an artiﬁcially enhanced weight. One expects this to
induce some extra noise in the system, as will indeed be clear below. Hav-
ing constructed the set of strictly uncorrelated, unit variance input ˆX and
output ˆY variables, we determine the singular value spectrum of G = ˆY ˆX T .
If we keep all variables, this spectrum is in fact indistinguishable from pure
noise when ˆX precedes ˆY by one month, and only one eigenvalue emerges
0.87 instead of the theoretical value 0.806) when ˆX and ˆY are si-
(smax
≈
multaneous.

≈

≈

≈

If we now remove redundant, noisy factors that correspond to, say, λ

≤
λmin/2
0.1 both in CX and CY , we reduce the number of factors to 50 for
ˆX and 16 for ˆY 2. The cumulative singular value spectrum of this cleaned
problem is shown in Fig. 5 and compared again to the corresponding ran-
dom benchmark. In this case, both for the simultaneous and lagged cases,
the top singular values smax
0.81) are very clearly above
0.73 (resp. smax
0.642, indicating the presence of some true
the theoretical upper edge sue ≈
correlations. The top singular values smax rapidly sticks onto the theoreti-
cal edge as the lag increases. For the one-month lagged case, there might
be a second meaningful singular value at s = 0.66. The structure of the
corresponding eigenvectors allows one to construct a linear combination of
economic indicators explaining a linear combinations of CPIs series. The
combination of economic indicators corresponding to the top singular value
evidences the main economic factors aﬀecting inﬂation indicators: oil prices
obviously correlated to energy production increases and electricity produc-
tion decreases that explain the CPIs indexes including oil and energy. The
second factor includes the next important elements of the economy: employ-
ment (new payrolls) aﬀects directly the “core” indexes and the CPI indexes

2The results we ﬁnd are however weakly dependent on the choice of this lower cut-oﬀ,

provided very small λ’s are removed.

12

30

20

)
λ
(
ρ

 

10

0

0

2

4
 λ

6

8

Figure 4: Eigenvalue spectrum of the N
N correlation matrix of the input
variables CX, compared to the Marˇcenko-Pastur distribution with parameter
n = 76/265. Clearly, the ﬁt is very bad, meaning that the input variables are
strongly correlated; the top eigenvalues λmax
15 is in fact not shown. Note the
large number of very small eigenvectors corresponding to combinations of strongly
correlated indicators, that are pure noise but have a small volatility.

×

≈

excluding oil. New economy production (high tech, media & communica-
tion) is actually a proxy for productivity increases, and therefore exhibits
a negative correlation with the same core indexes. We have also computed
the inverse participation ratio of all left and right eigenvectors with similar
conclusions [16]: all eigenvectors have a participation ratio close to the in-
formationless Porter-Thomas result, except those corresponding to singular
values above the upper edge.

Since Yt−1 may also contain some information to predict Yt, one could
also study, in the spirit of general Vector Autoregressive Models [3, 5, 1], the
case where we consider the full vector of observables Z of size 111, obtained
by merging together X and Y . We again deﬁne the normalised vector ˆZ,
remove all redundant eigenvalues of ˆZ ˆZ ′ smaller than 0.1, and compute the
singular value spectrum of ˆZt ˆZ T
62,

t−1. The size of this cleaned matrix is 62

×

13

1

0.8

0.6

0.4

0.2

)
s
<
’
s
(
P

 

 Data
 Benchmark

0

0.2

0.4

0.6
 s

0.8

1

Figure 5: Cumulative singular value distribution for the “cleaned” problem, i.e.
removing the factors with very small volatilities, leaving 50 factors in ˆX and 16 in
ˆY . The correlations we consider are lagged and correspond to ˆYt ˆX T
t−1. The ﬁlled
circles correspond to the 16 empirical singular values, and the plain line is the
theoretical prediction in the purely random case with n = 50/265 and m = 16/265.
Note that the top singular value smax
0.81 clearly stands out of the noise band,
the edge of which is at sue = 0.642. Finite T corrections are expected to smooth
the edge over a region of size T −2/3

0.025 for T = 265.

≈

≈

14

≈

0.97, and that

0.84. We
and the upper edge of the random singular value spectrum is sue ≈
now ﬁnd that the top singular value is at smax
8 factors
∼
have singular values above the upper edge of the random spectrum. The
top singular value corresponds to sales and inventory/sales ratio, followed by
CPIs that tend to be correlated over time. Further results are less intuitively
simple. This analysis can of course be generalized to larger lags, by studying
ˆZt ˆZ T
t−n. We ﬁnd that even for n = 4, there are still three singular values
above the upper edge. The SVD results are therefore of great help to rank
the importance of autocorrelations of degree n in the system; we will explore
this point further in a future publication.

5 Conclusions and extensions

The conclusions of this illustrative empirical study are twofold: (i) in gen-
eral, both input and output variables have a non trivial correlation structure,
with many redundant factors which add a signiﬁcant amount of noise in the
problem. Therefore, in a ﬁrst step, some data cleaning must be performed by
eliminating these redundant variables; (ii) the singular value spectrum, com-
pared to its purely random counterpart, allows one to answer precisely the
question of the number and relevance of independent predictable factors in
the problem under study. In the case considered, we have seen that although
the number of pairs of apparently correlated factors is large (see Fig. 3), only
a few modes can in fact be considered as containing useful information, in
the sense that their singular value exceeds our analytical upper edge given
in Eq. (11). When studying the full problem where all variables are treated
together, we ﬁnd that the eﬀective dimensionality of the problem drops from
111 to eight or so independent, predictable factors. This compares quite well
with the number seven quoted by Stock and Watson within their dynamical
factor analysis of a similar data set [1]. A more thorough comparison of our
results with those of the econometrics literature will be presented elsewhere.
What we mean by ‘exceed the upper edge’ should of course be speciﬁed
more accurately, beyond the eye-balling procedure that we implicitly rely
on. In order to have a more precise criterion, one should study the statistics
of the top eigenvalue of
, which is, in analogy with the known results for
the Wishart ensemble, most probably given by a Tracy-Widom distribution,
at least for Gaussian random variables (see [21, 22] for recent progress and
references). For ﬁnite T , we expect the top eigenvalue of
to ooze away

D

D

15

≈

≈

from the theoretical edge by a quantity of order T −2/3
0.025 for T =
265. Therefore, the diﬀerence between smax
0.81 and the theoretical edge
sue = 0.642 reported in Fig. 5 can safely be considered as signiﬁcant when
all variables are Gaussian. However, although the density of singular values
is to a large degree independent of the distribution of the matrix entries,
one should expect that the fuzzy region around the theoretical edge expands
signiﬁcantly if the input and output variables have fat tails. In particular,
the Tracy-Widom distribution is expected to breakdown in some way that
would be very interesting to characterize precisely. We leave this problem to
future investigations.

In conclusion, we have presented a general method to extract statistically
meaningful correlations between an arbitrary collection of input and output
variables of which only a ﬁnite time sample is available. Our central result
is derived from the theory of free random matrices, and gives an explicit
expression for the interval where singular values are expected in the absence
of any true correlations between the variables under study. Our result can
be seen as the natural generalization of the Marˇcenko-Pastur distribution
for the case of rectangular correlation matrices. The potential applications
of this method are quite numerous and we hope that our results will prove
useful in diﬀerent ﬁelds where multivariate correlations are relevant.

Acknowledgments: We wish to thank G´erard Ben Arous, Florent Benaych-
Georges and Jack Silverstein for most useful discussions on Random Matrix
Theory.

Appendix: the M P 2 case

As indicated in the main text, one could have chosen as a benchmark the
case where all (standardized) variables X and Y are uncorrelated, meaning
that the ensemble average E(CX) = E(XX T ) and E(CY ) = E(Y Y T ) are
equal to the unit matrix, whereas the ensemble average cross-correlation
E(G) = E(Y X T ) is identically zero. However, for a given ﬁnite size sample,
the eigenvalues of CX and CY will diﬀer from unit, and the singular values
of G will not be zero. The statistics of the eigenvalues of CX and CY is well
known to be given by the Marˇcenko-Pastur distribution with parameters n

16

and m respectively, which reads, for β = n, m < 1:

1

ρM P (λ) =

(λ

λmin)(λmax

λ),

2πβλℜq

−

−

with

λmin = (1

β)2

− q

λmax = (1 +

β)2.

q

The Σ-transform of this density takes a particularly simple form:

Σ(x) =

1
1 + βx

.

Σ(x) =

1
β + x

.

Now, as explained in the main text, the singular values of G are obtained as
the square-root of the eigenvalues of D = X T XY T Y . Since X T X and Y T Y
are mutually free, one can again use the multiplication rule of Σ-transforms,
T matrices X T X and
after having noted that the Σ-transform of the T
Y T Y are now given by:

×

One therefore ﬁnds that the η transform of D is obtained by solving the
following cubic equation for x:

η−1(1 + x) =

1 + x
x(n + x)(m + x)

,

−

which can be done explicitely, leading to the following (lengthy) result. De-
note z = s2, one should ﬁrst compute the following two functions:

f1(z) = 1 + m2 + n2

mn

m

n + 3z

−

−

−

and

Then, form:

f2(z) = 2

3m(1

m)

3n(1

n)

3mn(n+m

−

−

−

−

−

4)+2(m3+n3)+9z(1+m+n).
(20)

−

If ∆ > 0, one introduces a second auxiliary variable Γ:

∆ =

4f1(z)3 + f2(z)2.

−

(14)

(15)

(16)

(17)

(18)

(19)

(21)

(22)

Γ = f2(z)

√∆,

−

17

to compute ρ2(z):

πρ2(z) =

Γ1/3
24/331/2z

−

+

f1(z)
22/331/2Γ1/3z

.

Finally, the density ρ(s) is given by:

ρ(s) = 2sρ2(s2).

(23)

(24)

References

[1] for a review, see: J. H. Stock, and M. W. Watson, Implications of dynamical

factor models for VAR analysis, working paper, June 2005.

[2] C. W. J. Granger, Macroeconometrics, Past and Future, Journal of Econo-

metrics, 100, 17 (2001).

[3] J. Geweke The Dynamic Factor Analysis of Economic Time Series in D.J.
Aigner and A.S. Goldberger eds. Latent Variables in Social Economic Models,
North Holland: Amsterdam (1997).

[4] J. H. Stock, M. W. Watson, Forecasting Inﬂation, Journal of Monetary Eco-
nomics, 44, 293-335 (1999), Macroeconomic forecasting using diﬀusion in-
dexes, Journal of Business and Economic Statistics, 20, 147-162 (2002), Fore-
casting using principal components from a large number of predictors, Journal
of the American Statistical Association, 97, 1167-1179 (2002).

[5] M. Forni, M. Hallin, M. Lippi and L. Reichlin, The Generalized Dynamic
Factor Model: Identiﬁcation and Estimation, The Review of Economic and
Statistics, 82, 540-554 (2000); The Generalized Dynamic Factor Model: Con-
sistency and Rates, Journal of Econometrics, 119, 231-255 (2004), The Gen-
eralized Dynamic Factor Model: One-Sided Estimation and Forecastings,
mimeo (1999).

[6] J. Bai, Inferential theory for factor models of large dimensions, Econometrica,

71, 135-171 (2003).

[7] J. Bai, and S. Ng (2002) Determining the number of factors in approximate

factor model, Econometrica, 70, 191-221 (2002).

[8] B. Bernanke, J. Boivin, Monetary policy in a data rich environment, Journal

of Monetary Economics, 50 525 (2003).

18

[9] C. A. Sims, Macroeconomics and Reality, Econometrica, 48, 1-48 (1980).

[10] see, e.g. M. Woodford, Learning to believe in sunspots, Econometrica, 58,
277-307, (1990); see also M. Wyart, J.P. Bouchaud, Self referential behaviour,
overreaction and conventions in ﬁnancial markets, to appear in JEBO, (2005).

[11] for a recent review, see: A. Tulino, S. Verd`u, Random Matrix Theory and
Wireless Communications, Foundations and Trends in Communication and
Information Theory, 1, 1-182 (2004).

[12] A. Edelman, N. Raj Rao, Random Matrix Theory, Acta Numerica, 1-65

(2005).

[13] V. A. Marˇcenko and L. A. Pastur, Distribution of eigenvalues for some sets

of random matrices, Math. USSR-Sb, 1, 457-483 (1967).

[14] J. W. Silverstein and Z. D. Bai, J On the empirical distribution of eigenval-
ues of a class of large dimensional random matrices, Journal of Multivariate
Analysis, 54 175 (1995).

[15] A. N. Sengupta and P. Mitra, Distributions of singular values for some ran-

dom matrices, Phys. Rev. E 80, 3389 (1999).

[16] L. Laloux, P. Cizeau, J.-P. Bouchaud and M. Potters, Noise dressing of ﬁ-
nancial correlation matrices, Phys. Rev. Lett. 83, 1467 (1999); L. Laloux, P.
Cizeau, J.-P. Bouchaud and M. Potters, Random matrix theory and ﬁnancial
correlations, Int. J. Theor. Appl. Finance 3, 391 (2000): M. Potters, J.-P.
Bouchaud and L. Laloux, Financial Applications of Random Matrix Theory:
Old laces and new pieces, Acta Physica Polonica B, 36 2767 (2005).

[17] Z. Burda, A. G¨orlich, A. Jarosz and J. Jurkiewicz, Signal and Noise in Cor-

relation Matrix, Physica A, 343, 295-310 (2004).

[18] see the proceedings of the conference on Applications of Random Matrix The-

ory, published in Acta Physica Polonica B, 36 2603-2838 (2005).

[19] G. Kapetanios, A new Method for Determining the Number of Factors in

Factor Models with Large Datasets, mimeo Univ. of London (2004).

[20] see, e.g., W. H. Press, B. P. Flannery, S. A. Teukolsky, W. T. Vetterling, Nu-
merical Recipes in C : The Art of Scientiﬁc Computing, Cambridge University
Press (1992).

19

[21] J. Baik, G. Ben Arous,

the
largest eigenv alue for non-null complex sample covariance matrices,
http://xxx.lanl.gov/abs/math.PR/0403022, to appear in Ann. Prob.

and S. Peche, Phase transition of

[22] N. El Karoui, Recent results about the largest eigenvalue of random covariance
matrices and statistical application, Acta Physica Polonica B, 36 2681 (2005).

20

