Maximum Likelihood Estimation of Drift and Diﬀusion Functions

David Kleinhans and Rudolf Friedrich
Westf¨alische Wilhelms-Universit¨at M¨unster, D-48149 M¨unster, Germany
(Dated: September 21, 2013)

The maximum likelihood approach is adapted to the problem of estimation of drift and diﬀusion
functions of stochastic processes from measured time series. We reconcile a previously devised
iterative procedure [1] and put the application of the method on a ﬁrm theoretical basis.

6
0
0
2
 
v
o
N
 
0
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
2
0
1
1
1
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

PACS numbers: 05.10.Gg, 05.45.Tp

I.

INTRODUCTION

Complex systems of physics, chemistry, and biology
are composed of a huge number of microscopic subsys-
tems interacting on a fast time scale. Self organized be-
havior may arise on a macroscopic length and time scale
which can be described by suitably deﬁned order parame-
ters. The microscopic degree’s of freedom, however, show
up in terms of fast temporal variations which eﬀectively
can be treated as random ﬂuctuations [2]. The adequate
description of such systems viewed from a macroscopic
perspective are Langevin equations, which contain a de-
terministic part described by the drift vector and a ﬂuc-
tuating part whose impact on the dynamics is quantiﬁed
by a diﬀusion matrix [3, 4].

Recently, a procedure has been proposed that allows
for a direct estimation of these quantities and, hence, of
the stochastic dynamics from measured data [5]. This
procedure has provided a deeper insight to a broad class
of systems, especially in the ﬁeld of life sciences [5, 6, 7].
Moreover, also turbulence research has greatly beneﬁted
from this procedure [8].

However, the procedure is based on the estimation of
conditional moments in the limit of high sampling fre-
quencies,

D(k)(x) = lim
τ →∞

1
τ D(cid:2)

x(t + τ ) − x(t)
(cid:3)

k

(cid:12)
(cid:12)

x(t) = x

,

E

(1)
for k = 1 and k = 2, respectively. D(1)(x) is the drift
vector, while D(2)(x) exhibits the diﬀusion matrix of the
underlying process at position x. The limiting procedure
(1) can be problematic in case of a ﬁnite time resolution
of measured data. Moreover, any presence of measure-
ment or discretization noise seriously interferes with the
convergence of the limiting procedure [14].

Recently, we proposed an iterative method that cir-
cumvents this limiting procedure [1]. It is based on the
minimization of the Kullback-Leibler distance [9, 10] be-
tween the two time joint probability distribution func-
tions (pdfs) obtained from the data and the simulated
process for a certain set of parameters, respectively. The
starting conﬁguration of this iterative procedure as well
as a suitable parametrization of drift and diﬀusion func-
tions can be obtained by the direct estimates based on
the smallest reliable time increment τ , provided by (1).
The intention of the present note is to derive a

maximum likelihood estimator for parameters of the
parametrized drift vector and diﬀusion matrix. By this
means, the Kullback-Leibler estimator recurs in case of
an ensemble of individual measurements – but now phys-
ically well motivated.

Moreover, a simpliﬁed maximum likelihood estimator
is introduced for the analysis of nonlinear time series,
that satisfy Markov properties. This estimator leads to a
reasonable reduction of the required computational eﬀort
compared to a direct application of the former method
and is proposed for further application in nonlinear time
series analysis. Precise results can be obtained even in
the case of few or sparsely sampled measurement data.
However, the relevance of the results obtained in the case
of data sets involving a few data points carefully has to
be reconsidered in a self consistent manner.

II. MAXIMUM LIKELIHOOD ESTIMATION ON
ENSEMBLES: RECONCILIATION WITH THE
KULLBACK-LEIBLER ESTIMATOR [1]

We consider time series x(t0), . . . , x(tn), ti < ti+1 of
n recordings of a multivariate stochastic variable. Fur-
thermore, we assume that the time lag between consec-
utive observations is τ . Henceforth, the abbreviation
xi := x(t0 + iτ ) will be used.

In this section, the estimation of drift an diﬀusion func-
tions from an ensemble of N independent time series is
considered. Such data sets generally are obtained from
measurements on an ensemble of N independent systems,
that are performed simultaneously. In this vein, the time
evolution of the stochastic properties can be analyzed.
For the present case, we restrict ourselves without loss
of generality to the analysis of the ﬁrst two consecutive
measurements xk

1 with k ∈ [1, N ] .

0 and xk

By means of the direct estimation described in [5], drift
and diﬀusion functions can be estimated from data from
the Kramers-Moyal expansion coeﬃcients (1). On the
basis of this estimate, models for the drift and diﬀusion
function, respectively, can be constructed, depending on
a set of parameters, A. This procedure is described in
greater detail in [1].

The likelihood of the current realization for one speciﬁc
set of parameters, A, can be expressed by means of the

joint pdf,

P (x1

1, x1

0, x2

1, x2

0, . . . , xN

1 , xN

0 |A)

.

(2)

Since the individual N processes are assumed to be sta-
tistically independent of one another, this joint pdf de-
generates into a product of two point joint pdfs,

P (x1

1, x1

0|A)P (x2

1, x2

0|A) × . . . × P (xN

1 , xN

0 |A)

(3)

This expression can be simpliﬁed considerably.

First, we consider the logarithm of (3), usually called

log-likelihood function [11],

N

log

P (xk

1, xk

0|A)
(cid:3)

Xk=1

(cid:2)

(4)

With help of ˆp(x, x′) := 1
1)δ(x′ − xk
1)
N
expression (4) ﬁnally can be evaluated by means of an
integral,

k=1 δ(x − xk

P

N

log

P (x1

(cid:2)
= N

1, x1
dx

0, x2
dx′

1, x2
ˆp(x, x′

0, . . . , xN

1 , xN
0 |A)
(cid:3)
|τ ) log [P (x, x′

|A)]

.

(5)

Z

Z

Since the logarithm is a monotone increasing function,
the maximization of the likelihood function is equivalent
to the maximization of its logarithm. The set A, that
maximizes the latter expression, therefore forms the most
likely set of parameters under the current parametriza-
tion.

In [1], for the present case the minimization of the
Kullback distance ˆK[A] of the joint distributions has
been proposed,

ˆK[A] =

dx′

ˆp(x, x′

) log

=

dx′

ˆp(x, x′

ˆp(x, x′)
P (x, x′|A) (cid:21)

(cid:20)
) log [ˆp(x, x′

)]

(6a)

(6b)

dx′

ˆp(x, x′

) log [P (x, x′

|A)]

.(6c)

dx

dx

Z

Z

Z

Z

−

dx

Z

Z

The term (6b) is independent of the individual set A,
while (6b) is conform to (5). Therefore, minimization of
ˆK[A] evidently is equivalent to the maximization of the
likelihood of the set of parameters A.

III. MAXIMUM LIKELIHOOD ESTIMATION
ON MARKOVIAN TIME SERIES

Henceforth, individual time series x0, . . . , xn are con-
sidered. We assume that the time lag between consecu-
tive observations is τ and that the process is stationary
in a sense, that the statistics are conserved during the
measurement period.

2

Let us further assume, that the data set under consid-
eration features Markov properties. This can be veriﬁed
by means of the Chapman-Kolmogorov equation [3, 4],

P (xi|xi−2) =

dxi−1P (xi|xi−1)P (xi−1|xi−2)

,

Z

(7)
that can be evaluated numerically. Although this con-
dition is not suﬃcient, it has served as a very robust
criterion. A delay embedding of the data may help to
fulﬁll this constraint, if the amount of data is suﬃciently
high for such an procedure [3].

If the process under consideration is ergodic, time av-
erages can be evaluated by means of ensemble averages.
Then, also in this case a reasonable parametrization and
initial condition for the vector A can be obtained by the
direct evaluation of (1), as described in the previous sec-
tion. Let us now iterate the arguments of the previous
section.

The likelihood of the current realization for a speciﬁc

set of parameters, A, is

P (xn, . . . , x0|A)

.

(8)

Since we assume Markov properties, this joint pdf degen-
erates into a product of two point conditional pdfs,

P (xn|xn−1, A) × . . . × P (x1|x0, A)P (x0|A)

.

(9)

This expression can be simpliﬁed by considering the log-
arithm of the likelihood function. With the help of the
deﬁnition

p(x, x′

) :=

δ(x − xi)δ(x′

− xi−1)

(10)

1
n

n

Xi=1

we ﬁnally obtain:

log [P (xn, . . . , x0|A)]
= log [P (x0|A)]

(11)

+n

Z

dx

Z

dx′ p(x, x′

|τ ) log [P (x|x′, A)]

.

Following the maximum likelihood approach, this expres-
sion has to be maximized with respect to A and yields
the most likely set of parameters.

In the previous section we demonstrated the equiva-
lence of the second summand to the accordant Kullback-
Leibler distance function. The latter representation
yields signiﬁcant advantages,
since this distance is
bounded from below by the value 0, which is only reached
for perfect agreement of the two point statistics. There-
fore, the minimization of the expression

K ′

[A] = −

log [P (x0|A)]

1
n

(12)

dx

Z

Z

dx′ p(x, x′

) log

p(x|x′)
P (x|x′, A) (cid:21)

(cid:20)

is a feasible way for optimization of A.

It is obvious, that in the latter expression the ﬁrst sum-
mand is negligible for n ≫ 1. Even in the case of smaller
n, the ﬁrst measurement in some cases may not obey
the stationary distribution due to transient processes of
the measurement. On the other hand, the evaluation of
the expression may be time-consuming since the station-
ary distribution of the process is required. In conclusion,
we propose to drop this ﬁrst summand and perform the
minimization of

K[A] =

dx

Z

Z

dx′ p(x, x′

) log

p(x|x′)
P (x|x′, A) (cid:21)

(cid:20)

. (13)

3

numerical evaluation of the expression P (x|x′, A), equa-
tion (13) can be calculated my means of a ﬁnite sum.

Eventually, the set A, that minimizes (13) has to be
investigated. This can be done by the method of the
steepest descend or more eﬃcient approaches [12]. We
want to emphasize that in the majority of cases a suitable
starting value is obtained from the initial estimates (1).
This is essential for a successful and fast minimization by
any numerical algorithm.

V. CONCLUSION

IV. MINIMIZATION PROCEDURE FOR
DRIFT-/DIFFUSION-PROCESSES

We would like to emphasize, that expression (13) can
be evaluated numerically. It is a feature of drift and diﬀu-
sion processes, that the time evolution of the conditional
pdf can be obtained from the Fokker-Planck equation [3],

∂

∂t P [x(t)|x′(t0)] =

∂
∂xi

D(1)
i

(x)

(14)

−

(cid:26)

Pi
ij (x)

D(2)

(cid:27)

∂2
∂xi∂xj

+

Pi,j

P [x(t)|x′(t0)]

.

This equation can be treated eﬃciently by implicit algo-
rithms at least for the case x ∈ R and x ∈ R2, respec-
tively [12].

The data under consideration can be reduced signiﬁ-
cantly by a suitable discretization of data space in sev-
eral bins. Typically, this grid should coincidence with
the spatial discretization required for numerical solution
of the Fokker-Planck equation. After discretization and

In conclusion, the likelihood functions of stochastic
processes have been derived for two speciﬁc cases. First,
ensembles of measurements on these processes were con-
sidered. In this connection, the iterative procedure pro-
posed in [1] has been approved and physically motivated.
Moreover, the maximum likelihood approach has been
adapted to the needs of non-linear time series analysis.
For the case of Markovian processes, an integral form of
the estimator has been derived. A slight simpliﬁcation
of this estimator, equation (13), is purely based on two
point conditional pdfs, that can be calculated numeri-
cally from the Fokker-Planck equation in case of drift
and diﬀusion processes .

Finally, the meaning of the resulting set of parameters,
A, has been made explicit on the basis of the maximum
likelihood approach: It is the most likely set of param-
eters with respect to the current parametrization. As
a consequence, the proposed procedure can be applied
even to time series that suﬀer from sparse data points
and that could not safely be processed by the former
methods without this knowledge.

[1] D. Kleinhans, R. Friedrich, A. Nawroth, and J. Peinke,

[8] R. Friedrich and J. Peinke, Phys. Rev. Lett. 78, 863

Phys Lett A 346, 42 (2005).

(1997).

[2] H. Haken, Synergetics, Springer Series in Synergetics
(Springer-Verlag, Berlin, 2004), pp. xvi+763, introduc-
tion and advanced topics, Reprint of the third (1983) edi-
tion [Synergetics] and the ﬁrst (1983) edition [Advanced
synergetics].

[3] H. Risken, The Fokker-Planck equation, Vol. 18 of
Springer Series in Synergetics, 2nd ed. (Springer-Verlag,
Berlin, 1989), pp. xiv+472, methods of solution and ap-
plications.

[4] C. W. Gardiner, Handbook of stochastic methods for
physics, chemistry and the natural sciences, Vol. 13 of
Springer Series in Synergetics, 3rd ed. (Springer-Verlag,
Berlin, 2004), pp. xviii+415.

[5] S. Siegert, R. Friedrich, and J. Peinke, Physics Letters A

243, 275 (1998).

[6] S. Kriso, R. Friedrich, J. Peinke, and P. Wagner, Physics

Letters A 299, 287 (2002).

[7] T. Kuusela, Physical Review E 69, 031916 (2004).

[9] H. Haken, Information and self-organization, Springer
Series in Synergetics, 2nd ed. (Springer-Verlag, Berlin,
2000), pp. xiv+222, a macroscopic approach to complex
systems.

[10] S. Kullback, in Information Theory and Statistics, edited
by W. A. Shewhart and S. S. Wilks (Wiley Publications
in Statistics, 1959).

[11] J. D. Kalbﬂeisch, Probability and Statistical Inference II.

Statistical Inference (Springer, Berlin, 1985).

[12] W. H. Press, S. A. Teukolsky, B. P. Flannery, and W. T.
Vetterling, Numerical Recipes in FORTRAN: The Art of
Scientiﬁc Computing (Cambridge University Press, New
York, NY, USA, 1992).

[13] F. B¨ottcher et al., Phys. Rev. Lett. 97, 090603 (2006).
[14] The application of this procedure in presence of measure-
ment noise recently has been investigated, see [13].

