4
0
0
2
 
g
u
A
 
8
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
9
3
0
8
0
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

On Bayesian Treatment of Systematic

Uncertainties in Conﬁdence Interval

Calculation

Fredrik Tegenfeldt a,band Jan Conrad b,
∗

aIowa State University, Ames, IA 5011-3160, USA

bCERN, PH-EP Department, CH-1211 Geneva 23

Abstract

In high energy physics, a widely used method to treat systematic uncertainties in

conﬁdence interval calculations is based on combining a frequentist construction of

conﬁdence belts with a Bayesian treatment of systematic uncertainties. In this note

we present a study of the coverage of this method for the standard Likelihood Ratio

(aka Feldman & Cousins) construction for a Poisson process with known background

and Gaussian or log-Normal distributed uncertainties in the background or signal

eﬃciency. For uncertainties in the signal eﬃciency of upto 40 % we ﬁnd over-coverage

on the level of 2 to 4 % depending on the size of uncertainties and the region in signal

space. Uncertainties in the background generally have smaller eﬀect on the coverage.

A considerable smoothing of the coverage curves is observed. A software package

is presented which allows fast calculation of the conﬁdence intervals for a variety

of assumptions on shape and size of systematic uncertainties for diﬀerent nuisance

parameters. The calculation speed allows experimenters to test the coverage for

their speciﬁc conditions.

Key words: Conﬁdence Intervals, Systematic Uncertainties, Frequentist Methods,

Preprint submitted to Elsevier Science

21 February 2014

Bayesian Methods

PACS: 06.20.Dk, 07.05.Kf

1 Introduction

The calculation of conﬁdence intervals in case of presence of systematic uncer-

tainties is an open problem. Systematic uncertainties are those uncertainties

present in parameters which will aﬀect the calculated conﬁdence interval, but

which are not of prime interest, so called nuisance parameters. Examples for

nuisance parameters are the eﬃciency or the predicted background rate.

In 1992 Cousins & Highland [1] proposed a method which is based on a

Bayesian treatment of the nuisance parameters. They proposed to perform

a frequentist construction (following Neyman [2]) and to replace the probabil-

ity density function (PDF) describing the statistical process of prime interest

with a PDF which is obtained by a convolution the original PDF with the one

describing the uncertainties in the nuisance parameters:

s)

P (n
|

−→ Z

P (n
|

s, ǫ′)P (ǫ′

ǫ)d ǫ′

|

(1)

where ǫ′ is the true value of the nuisance parameter, ǫ denotes its estimate

and s and n symbolize the signal hypothesis and the experimental outcome

respectively.

Highland & Cousins only treated the case of Gaussian uncertainties in the

signal eﬃcency. The method has since been generalized to operate with the

∗ Corresponding author: Jan Conrad, PH-EP Dept, F01910, CH-1211 Geneva 23

Email addresses: Fredrik.Tegenfeldt@cern.ch (Fredrik Tegenfeldt),

Jan.Conrad@cern.ch (Jan Conrad ).

2

modern uniﬁed ordering scheme proposed by Feldman & Cousins [3] and tak-

ing into account several nuisance parameters (eﬃciencies and background) and

correlations [5]. This generalized method has already been used in a number

of particle and astroparticle physics experiments (e.g. [6] [7] [8], [9], [10]).

The most crucial property of methods for conﬁdence interval construction is

the coverage, which states:

A method is said to have coverage (1-α) if, in inﬁnitely many repeated experi-

ments the resulting conﬁdence interval includes the true value with probability

(1-α) irrespective of what the true value is.

100(1-α)% is hereby commonly taken to be 68% 90%, 95% etc. Recently,

the coverage properties of a fully frequentist method, the Proﬁle Likelihood

method, have been studied [11]. The Proﬁle Likelihood method was found to

have surprisingly good coverage properties with a small (mostly negligible)

amount of undercoverage.

In this note we undertake a systematic study of the coverage of the Bayesian

method in order to give more substance to further recommendations on what

method to use to calculate conﬁdence intervals in presence of systematic uncer-

tainties. Previous studies [12] of this method dealt only with certain limiting

cases and were constrained by computational requirements.

The note is organized as follows: in the next section we will review the fre-

quentist construction of conﬁdence intervals, in particular the likelihood ratio

ordering scheme. We will describe the Bayesian method to incorporate sys-

tematics in section 3. The C++ library used to perform the calculations is

described in section 4. Coverage tests and connected subtleties are discussed

in section 5. The ﬁnal section is devoted to discussion and conclusion.

3

2 Frequentist conﬁdence interval construction

Let us consider a Poisson probability density function (PDF), p(n)s+b, for a

ﬁxed but unknown signal, s, in the presence of a known background with mean

b. For every value of s we can ﬁnd two values n1 and n2 such that

n2

Xn′=n1

p(n′)s+b = 1

α

−

where 1

α denotes the conﬁdence level (usually quoted as a 100(1-α)%

−

conﬁdence interval). Since we assume a Poisson distribution, the equality will

generally not be fulﬁlled exactly. A set of intervals [n1(s + b, α), n2(s + b, α)] is

called a conﬁdence belt. Graphically, upon a measurement, no, the conﬁdence

interval [s1, s2] is determined by the intersection of the vertical line drawn

from the measured value no and the boundary of the conﬁdence belt. The

probability that the conﬁdence interval will contain the true value s is 1

α,

−

since this is true for all s per construction. The choice of the n1 and n2 is,

however, not unique to deﬁne the conﬁdence belt. An additional criterion

has to be applied. The currently recommended ordering scheme [3]

[4] of

the elements in the sum in equation (2) is based on likelihood ratios. This

approach automatically provides central conﬁdence intervals when motivated

and upper limits when necessary, therefore it is often denoted as the “uniﬁed

approach”. The following algorithm is applied in solving equation (2):

For each n the sbest is found which maximizes the likelihood

(n)s+b. In case

L

of a simple Poisson distribution with known background, sbest is given by

(2)

(3)

max(0, n

b). Then for a ﬁxed s the ratio

−

R(s, n)L = L

s+b(n)
sbest+b(n)

L

4

is computed for each n, and all n’s are consequently ranked according to the

value of this ratio. Values of n are included in the conﬁdence belt starting

with the n with the highest rank (largest RL) and then decreasing rank until

n2
n=n1

p(n)s+b = 1

−

P
way, the conﬁdence interval [s1, s2] is found as described above.

α. After the conﬁdence belt has been constructed in this

3 Incorporation of systematic uncertainties: the Bayesian way

The ordering schemes are unaﬀected by the way of treating systematic uncer-

tainties considered here. As mentioned earlier, the PDF describing the statisti-

cal process will however be modiﬁed. Two concrete examples are the following:

In the case that the only uncertainty present is a theoretical (assumed Gauss-

shaped) uncertainty of the background process the PDF is modiﬁed to:

q(n)s+b =

1
√2πσb

∞

Z
0

p(n)s+b′ e

− (b−b′
2σ2

)2
b db′

Here b is the estimated background level, and σb is the uncertainty in the

background estimation. If, in addition to the theoretical uncertainty for back-

ground, there is the need to include the uncertainty in the signal detection

eﬃciency the expression for q(n)s+b might be extended to:

(4)

(5)

q(n)s+b = 1

2πσbσǫ ×

∞
0 p(n)b′+ǫ′s e

∞
0
R

R

)2

−(b−b′
2σ2
b

−(1−ǫ′
2σ2ǫ

)2

e

db′dǫ′

where σǫ is the uncertainty in the detection eﬃciency expressed in relative

terms with respect to the nominal eﬃciency 1 . It is important to realize that

1 of course the eﬃciency could be deﬁned in absolute terms as well.

5

the integration variables, here ǫ′ and b′, are the possible “true” (but unknown)

values of nuisance parameter. This indicates that this method is based on

Some examples for conﬁdence intervals computed by this method are shown

Bayesian statistics.

in table 1.

4 pole++

For the coverage studies presented in this paper a reasonably fast and eﬃcient

code is required. Hence, a user-friendly and ﬂexible C++ library of classes

was developed based on the FORTRAN routine presented in [13]. The library

is independent of external libraries and consists of two main classes, Pole and

Coverage. The ﬁrst class takes as input the number of observed events, the ef-

ﬁciency and background with uncertainties and calculates the limits using the

method described in this paper. The integrals are solved analytically. Cov-

erage generates user-deﬁned pseudoexperiments and calculates the coverage

using Pole. Presently the library supports Gauss and log-Normal distributed

PDF for description of the nuisance parameters. Flat and used-deﬁned PDFs

are about to be implemented as well as correlations for the Gauss case. The

class is dynamically optimized depending on if one wishes to calculate sin-

gle (or few) conﬁdence intervals or if one wants to perform a coverage study.

Without these optimisations the calculation of a single interval takes about 1

second (wall clock time) on a 1 GHz Pentium III processor. The duration of

a full coverage study (typically requiring the calculation of

(105) conﬁdence

O

intervals) ranges between a couple of minutes for small uncertainties and small

signal hypotheses to order of 10 hours for large uncertainties and high signal

6

hypotheses. The perfomance of a coverage study thus seems feasable for the

particular set of systematic uncertainties that may appear in real experiments.

The pole++ library can be obtained from http://cern.ch/tegen/statistics.html

5 Coverage Studies

The coverage of the method is studied using MC simulations of pseudo-

experiments with given true value of the prime parameter (signal) or nuisance

parameter (eﬃciency, background). The estimated values of the nuisance pa-

rameters were assumed to be Gaussian or log-Normal distributed around the

given true value. The outcome of one experiment thus consisted of a number

of observed events (following a Poisson distribution with known background

and depending on the true eﬃciency and true background) and the estimate

of the nuisance parameter(s).

Figure 1 shows the coverage 2 as a function of signal hypothesis for two dif-

ferent sizes of uncertainties (5 % and 40 %). The uncertainty considered is in

the signal eﬃciency and assumed to be Gauss-shaped. It can be seen that the

Bayesian method causes over-coverage which is larger for larger systematic

uncertainty. This is also reﬂected in ﬁgure 3 where the mean coverage (mean

taken over all tested signal hypotheses) is shown as a function of assumed

uncertainty. For Gaussian uncertainties in the signal eﬃciency we ﬁnd an in-

crease in mean coverage by

1% in the uncertainty range between 10 % and

∼

40 %.

The see-saw structure which is generally seen in the no-uncertainty case (due

2 we will denote the coverage calculated by the MC simulations as (1

α)ef f to

−

distinguish it from the nominal coverage (1

α)

−

7

to the discrete experimental outcome) is considerably smoothened when sys-

tematic uncertainties are introduced. This is exempliﬁed in ﬁgure 2, which

compares the coverage curve with 5 % uncertainties on the signal eﬃciency

with the zero uncertainties case. To quantify this further we present the rms

of the coverage together with the mean in ﬁgure 3. The smoothing is due to

the fact that we add a continuous variable to the problem, meaning there are

more degrees of freedom to fulﬁl the sum condition of equation 2. The eﬀect

of the smoothing is that whereas for some signal hypothesis the coverage is in-

creased for others it is decreased with respect to the zero uncertainty case. The

mean coverage is therefore only rather weakly dependent on the systematic

uncertainties. For higher signal hypotheses, where the eﬀect of the smoothing

is less pronounced, the eﬀect of the uncertainties is therefore stronger. Taking

the mean over signal hypotheses strue >6 the mean coverage increases from 92

% (at zero uncertainties) to 94 % (at 40 % uncertainties). A side eﬀect is that

the introduction of rather small uncertainties seems to improve the coverage

with respect to the zero uncertainty case for parts of the tested hypothesis

space (see e.g. ﬁgure 2).

Figure 4 shows the coverage for two diﬀerent sizes of Gaussian uncertainty

on the background estimate. Except for the smoothing eﬀect the coverage is

seemingly independent of the size of the uncertainties. An uncertainty in the

background will yield similar results to an uncertainty in the signal eﬃciency

only in the regime were the signal hypotheses are of similar size as the back-

ground expectation. For larger signal hypotheses the coverage curve for the

uncertainty in the background will be approaching the zero uncertainty case,

which is reﬂected in a slight slope of the coverage curve for high uncertainty

in ﬁgure 4. The result is thus that a mean coverage depending on uncertain-

ties in the background will be less aﬀected than the corresponding curve with

8

uncertainties in the signal eﬃciency. We show the mean coverage as well as

the rms in ﬁgure 5.

In ﬁgure 6 the eﬀect of having to consider uncertainties both in signal and

background detection eﬃciency is visible. At large signal hypotheses the cov-

erage plot is dominated by the uncertainty in signal eﬃciency, at low signal

hypotheses coverage beneﬁts from the smoothing eﬀect, since we added yet

another degree of freedom.

It should be noted that for large uncertainties the Gaussian model is not ap-

propriate. The reason is that a Gaussian model will then signiﬁcantly extent to

the unphysical region of the space of experimental outcomes. In the Bayesian

treatment this case is dealt with by truncating the Gauss distribution at zero,

and this is consequently the way it is dealt with during the coverage test.

Considering the coverage test there is an additional subtlety: in order for the

measured eﬃciency to be a maximum likelihood estimate of the true eﬃciency

we would have to renormalize the Gauss distribution to the truncated Gauss

distribution in order to obtain the correct PDF. However, instead of doing this

a posteriori ﬁx, it is more reasonable to use a log-Normal distribution to model

the uncertainty in the eﬃciency. The coverage for the log-Normal distribution

is shown in ﬁgure 7. As can be seen for the highest uncertainties considered

in this note, the Gauss distribution is still a very good approximation to the

log Normal model.

6 Discussion and Conclusions

In this note we presented coverage studies for the Bayesian treatment of sys-

tematic uncertainties. One overall conclusion is that the Bayesian treatment

9

leads some over-coverage. However, introducing a continuous nuisance param-

eter into the discrete Poisson problem results in a smoothing of the coverage

curves. The mean coverage is therefore only weakly aﬀected by the Bayesian

treatment of nuisance parameters and under certain circumstances even im-

proves with respect to the zero uncertainty case.

In a frequentist approach the meaured estimate of a nuisance parameter is

considered to be distributed around a given true value, which is consequently

the way coverage was calculated. The Bayesian method on the other hand

views the true value as distributed around the measured value. The underly-

ing assumption for going from one approach to the other is (at least in case

of a Gauss-distribution) a ﬂat prior probability of hypotheses. The present

study indicates that this assumption does not lead to a serious violation of

the coverage requirement.

The routines used for the presented calculations are reasonably fast and pub-

licly available. A coverage study is therefore feasable for each problem at hand.

The conﬁdence level required for the conﬁdence intervals could then in prin-

ciple be adjusted to recover correct coverage.

The authors thank Robert Cousins for a very useful discussion.

7 Acknowledgements

References

[1] R. D. Cousins and V. L. Highland, Nucl. Instrum. Meth. A320, 331, (1992).

[2] J. Neyman, Phil. Trans. Royal Soc. London A, 333, (1937).

10

[3] G. J. Feldman and R. D. Cousins, Phys. Rev D57, 3873, (1998).

[4] A. Stuart and J. K. Ord: Kendall’s Advanced Theory of Statistics, Vol. 2,

Classical Inference and Relationship, Oxford University Press, New York (1991).

[5] J. Conrad, O. Botner, A. Hallgren and C. Perez de los Heros, Phys. Rev. D 67

(2003) 012002 [arXiv:hep-ex/0202013].

[6] B. Abbott et al. [LIGO Collaboration], Phys. Rev. D 69 (2004) 102001.

[7] Y. Chao et al.

[Belle Collaboration], Phys. Rev. D 69 (2004) 111102

[8] K. Eguchi et al. [KamLAND Collaboration], Phys. Rev. Lett. 92 (2004) 071301

[9]

I. Abt et al. [HERA-B Collaboration], arXiv:hep-ex/0405059.

[10] J. Ahrens [AMANDA Collaboration], Phys. Rev. Lett. 92 (2004) 071102

[arXiv:hep-ex/0311061].

[arXiv:hep-ex/0310047].

[arXiv:astro-ph/0309585].

098301, (2000).

[11] W. A. Rolke, A. M. Lopez, J. Conrad and F. James arXiv:physics/0403059.

[12] J. Conrad, O. Botner, A. Hallgren and C. Perez de los Heros, published in Proc.

of Conference on Advanced Statitical Techniques in Particle Physics, Durham,

England, March 2002

[13] J. Conrad, Computer Physics Communications 158 117-123 (2004)

8 Figures and tables

11

n0

b

rel. signal eﬃciency Likelihood Ratio

uncertainty

interval

2

2

0

4

2

0

0.2

0.4

0.2

0.4

0.2

0.4

0: 3.91

0: 3.89

0: 4.68

0: 6.59

0: 7.16

0: 8.99

1.07:10.09

1.02:13.31

6

2

0

1.08: 9.47

12

Table 1

signal eﬃciency.

Examples of likelihood ratio 90% conﬁdence intervals with Bayesian treatment of

systematic uncertainties. Uncertainties are assumed to be Gauss distributed in the

=N(1,0.05), b=0
=N(1,0.05), b=0

=N(1,0.40), b=0
=N(1,0.40), b=0

f
f
e

-
1

1

0.98

0.96

0.94

0.92

0.9

0
0

was 90%.

2
2

4
4

6
6

8
8

10
10

trues
trues

Fig. 1. Calculated coverage as function of signal hypothesis. Two case are shown: 5

% and 40 % Gaussian uncertainties in the signal eﬃciency. The nominal coverage

13

a
˛
˛
˛
˛
=1.0,       b=0
=1.0,       b=0

=N(1,0.05), b=0
=N(1,0.05), b=0

f
f
e

-
1

1

0.98

0.96

0.94

0.92

0.9

0
0

2
2

4
4

6
6

8
8

10
10

trues
trues

Fig. 2. Calculated coverage with 5 % systematic uncertainties is compared with the

zero uncertainties case. The nominal coverage was 90 %.

14

a
˛
˛
˛
˛
>

f
f
e

-
1
<

0.96

0.95

0.94

0.93

0.92

0.91

0.9

0.89

-0.1
-0.1

Efficiency
Efficiency
Efficiency

Average
Average
Average
Average, s
Average, s
Average, s
RMS
RMS
RMS

>6
>6
>6

true
true
true

0.035

S
M
R

0.03

0.025

0.02

0.015

0.01

0.005

0
0.5
0.5

˛/˛
˛/˛

0
0

0.1
0.1

0.2
0.2

0.3
0.3

0.4
0.4

Fig. 3. Calculated mean coverage and rms as function of Gaussian shape uncertain-

ties in the signal eﬃciency. The mean was calculated over the full range of signal

hypotheses and for signal hypotheses larger than 6, respectively. The rms was cal-

culated over the full range of signal hypotheses. The nominal coverage was 90 %.

15

s
s
a
=1.0, b=N(2.0,0.1)
=1.0, b=N(2.0,0.1)

=1.0, b=N(2.0,0.8)
=1.0, b=N(2.0,0.8)

f
f
e

-
1

1

0.98

0.96

0.94

0.92

0.9

0
0

2
2

4
4

6
6

8
8

10
10

trues
trues

Fig. 4. Calculated coverage as function of signal hypothesis. Two case are shown:

5 % and 40 % Gaussian uncertainties in the background prediction. The nominal

coverage was 90 %.

16

a
˛
˛
˛
˛
>

f
f
e

-
1
<

0.96

0.95

0.94

0.93

0.92

0.91

0.9

0.89

-0.1
-0.1

Background
Background
Background

Average
Average
Average
Average, s
Average, s
Average, s
RMS
RMS
RMS

>6
>6
>6

true
true
true

0.035

S
M
R

0.03

0.025

0.02

0.015

0.01

0.005

0
0.5
0.5
/b
/b

0
0

0.1
0.1

0.2
0.2

0.3
0.3

0.4
0.4

Fig. 5. Calculated mean coverage and rms as function of Gaussian shape uncertain-

ties in the background prediction. The mean was calculated over the full range of

signal hypotheses and for signal hypotheses larger than 6, respectively. The rms was

calculated over the full range of signal hypotheses. The nominal coverage was 90 %

17

s
s
a
f
f
e

-
1

1

0.98

0.96

0.94

0.92

0.9

0
0

%

=N(1.0,0.20), b=N(2.0,0.4)

18

2
2

4
4

6
6

8
8

10
10

trues
trues

Fig. 6. Coverage for the case that uncertainties are present in both the signal de-

tection eﬃciency and in the background prediction. The nominal coverage was 90

a
˛
=LogN(1.0,0.4), b=0.0
=LogN(1.0,0.4), b=0.0

=   N(1.0,0.4), b=0.0
=   N(1.0,0.4), b=0.0

f
f
e

-
1

1

0.98

0.96

0.94

0.92

0.9

0
0

Normal PDF

2
2

4
4

6
6

8
8

10
10

trues
trues

Fig. 7. Coverage as a function of signal hypothesis for a Gaussian PDF and a log

19

a
˛
˛
˛
˛
