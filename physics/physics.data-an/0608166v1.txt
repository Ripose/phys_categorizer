Europhysics Letters

PREPRINT

6
0
0
2
 
g
u
A
 
6
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
6
6
1
8
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Information ﬁltering via Iterative Reﬁnement

P. Laureti 1, L. Moret 1, Y.-C. Zhang 1 and Y.-K. Yu 2
1 D´epartement de Physique, Universit´e de Fribourg - CH-1700 Fribourg, Switzerland.
2 National Center for Biotechnology Information, NIH - 8600 Rockville Pike, Bethesda,
MD 20894.

PACS. 89.20.Hh – World Wide Web, Internet.
PACS. 89.70.+c – Information theory and communication theory.

Abstract. – With the explosive growth of accessible information, expecially on the Internet,
evaluation-based ﬁltering has become a crucial task. Various systems have been devised aiming
to sort through large volumes of information and select what is likely to be more relevant. In
this letter we analyse a new ranking method, where the reputation of information providers is
determined self-consistently.

Introduction. – The study of complex networks and of some dynamical processes taking
place on these structures has recently attracted a great deal of attention in the physics com-
munity [1–4]. The importance of technological networks, such as the Internet, lies mostly in
the increased communication capabilities [5, 6], which make information progressively easier
to produce and distribute. As storage and transmission costs continue to drop, an overabun-
dance of information threatens to overwhelm its recipients. It is, therefore, crucial to process
information in order to present a user only the one that answers best her requests [7].

An important aspect of information ﬁltering regards scoring systems in the World Wide
Web [8, 9]. They collect evaluations and aggregate them into published scores that are mean-
ingful to the ﬁnal user. This embraces many diﬀerent instances, ranging from commercial
websites, where buyers evaluate sellers (Ebay, Amazon, etc.) to new generation search en-
gines (Google, Yahoo, etc.), and opinion websites, where people evaluate objects (Epinions,
Tailrank, etc.) Since the evaluators carry diﬀerent expertise, it is important to estimate how
accurate a given vote may be and to weight it accordingly. This can be done through the use
of raters’ reputations [10]. Reputation summarises one’s past behaviour and has always been
used to bear the risk of interacting with strangers. The Internet, while enhancing such a risk,
brings in the possibility to ﬁnd its antidotes [11]. Since nobody knows a-priori who are the
honest and competent evaluators, in fact, online scoring systems often include some measure
of their past performance. This gives users an indication on how trustworthy a given piece of
information is supposed to be. An expert of the ﬁeld would probably obtain a high reputa-
tion; experts’ votes should then count more when aggregating the scores. While reputation is
usually obtained by asking users supplementary evaluations about other users, the procedure
of Iterative Reﬁnement (IR), which can be shown to outperform naive methods [12], does not
require to explicitly rate the raters.
c(cid:13) EDP Sciences

= µil = Ql + ∆il

µil)2

= σ2

i ,

xili
h
(xil −
(cid:10)

ql =

fixil ;

N

i=1
X

Vi =

1
M

M

Xl=1

(xil −

ql)2 .

ωi = Vi

−β ,

2

EUROPHYSICS LETTERS

The aim of this letter is to study, in a generalised model, the IR method’s dependence
on the relevant parameters, illustrate the subtle issues in its mathematical underpinning and
elaborate on distortions generated by diﬀerent kinds of cheating. Prior to describing the major
focus of this work, we will brieﬂy state the model and deﬁne some notations.

Model and algorithm. – To describe our approach in the simplest manner, let us consider
N raters evaluating M objects, which can be books, movies or even other raters. Each object
l has an intrinsic quality Ql and each rater i has an intrinsic judging power 1/σ2
i . Let xil be
a random variable representing the rating given by rater i to object l. Intrinsic qualities and
judging powers are deﬁned by the ﬁrst two moments of its distribution:

where ∆il is the systematic error of agent i towards object l. Expectation values are taken over
the distribution of xil. They can be regarded as ensemble averages, obtained if the evaluations
were to be performed inﬁnitely many times. Our aim is then to extract the quality of each
of evaluations. We thus estimate the intrinsic quality Ql of
object from a single set
{
object l by a weighted average of the received votes

xil}

(cid:11)

the inverse judging power σ2

i of rater i is estimated by the sample variance Vi

The unnormalised weights ωi take the general form

≥

0 and fi = ωi/

j ωj. As such, ωi decreases when Vi increases because rater i has
with β
a lower judging power and should be given less credit. We will consider scenarios where β
equals 1 or 1/2. The case β = 1/2, in fact, exhibits scale-changing and translational invariance
because ql becomes a sum of dimensionless random variables; the case β = 1 corresponds to
optimal weights, as explained later in the section No systematic errors.

P

The IR algorithm allows to solve eqs. (3-5), thus estimating Ql and σi, via the following
recursive procedure: I) Without additional information, set ωi = 1/N
i = 1, 2, ..., N . II)
III) Estimate Vi with eq. (4) and plug it in eq. (5) to ﬁnd the
Estimate ql with eq. (3).
weights. IV) Repeat from step II. Numerical simulations show that this process converges to

∀

the minimum of the cost function E(
{
conventional methods.

ql}

) =

l(xil −

ql)V −β
i

2

i

i

P

hP

much faster than other

Analytical approach. – Eq. (2) implies that the random variable (xil −
σ2
i and variance m2
if the distribution of votes is itself Gaussian. Let us deﬁne the variable γij = 1
M
Ql)(xjl −
one obtains

µil)2 has mean
i = 3
l(xil −
Ql); provided that xil has ﬁnite moments of, at least, order 4, in the large M limit

i , which is determined by the distribution of xil; in particular, m2

i σ4

P

γij →

σ2
i δij + ∆i∆j +

1
√M

(eij + ∆ihj + ∆jhi) .

(6)

(1)

(2)

(3)

(4)

(5)

P. Laureti, L. Moret, Y.-C. Zhang and Y.-K. Yu: Collaborative filtering

3

i , where m2

ij = 1 + δij(m2

Here the overlined quantities represent averages over the M items, xi = 1
M
Gaussian random variables eij and hi have mean zero and variances var(eij) = m2
P
var(hi) = σ2

l xil. The
i σ2
ijσ2
j and
1). In the following we shall use the notation gi = eii.
Eq. (6) has to be interpreted in probability, as prescribed by the Central Limit Theorem.
In its derivation we have further assumed that raters are independent; in fact, the correlation
among the variables eij of diﬀerent indices diminishes as M increases. If M
1, the random
variables
are eﬀectively independent, with the ﬁrst visible triangular correlation of order
eij}
1/M 2 or smaller. From counting the degrees of freedom associated with random numbers, it
(N + 1)/2. Eq. (6) forms the basis of our analytical pursuit in the
is desirable to have M
later development.

i −

≫

≥

{

The performance of the IR method can be stated by measuring the following mean squared

errors:

(7)

(8)

(9)

dql =

dσi =

Ql)2
i )2
σ2
(cid:11)

(ql −
(cid:10)
(Vi −
(cid:10)

=

(sl + ˜∆l)2

D

= Var(Vi) + Bias2(Vi) ,

E

≡ h

σ2
i . In eq. (7) we have separated the systematic error part, making
Vii −
with Bias(Vi)
use of the variables ˜∆l =
∆il. Eqs. (1,2)
Ql) are independent of index l, therefore
guarantee that the ﬁrst two moments of (yil −
P
s2
l

. This permits us to employ eq. (6) to obtain

Ql)fj, with yil = xil −

(cid:11)
i fi∆il and sl =

j(yjl −

M
l=1

s2
l

P

= 1
M

(cid:10)

(cid:11)

P

(cid:10)

(cid:11)

s2
l

=

σ2
i

f 2
i

+

i
X

i,j (cid:28)
X

fifj

eij
√M (cid:29)

.

(cid:10)

(cid:10)

(cid:11)

(cid:11)
The variable sl becomes Gaussian in the large N limit, as long as the weights fj are ﬁxed and
satisfy the Lindeberg condition [13]. However, such inference can’t be drawn easily because
the weights and the estimated ql are tangled up in eqs. (3-5). The standard deviation of sl can,
nevertheless, be calculated. The general problem of ﬁnding intrinsic values from completely
distorted votes is not solvable. In fact, even if one disposed of an inﬁnite number of raters and
˜∆li
evaluations, the estimator (3) of Ql would always be biased of the amount
. We shall, in
h
the following, focus our attention on three particular cases of special interest.

ωk}

No systematic errors. – When ∆il = 0

i, l, raters are impartial but posses diﬀerent
∀
judging powers. In order to obtain the best quality estimator one can minimise the mean
) of (3) with respect to the ωi’s. This gives the optimal weights [14],
squared error dq(
{
Since the law of large numbers
) = 1/
β = 1 in (5), with minimal dq(
{
guarantees the convergence of dq(
) to zero for large N , the same must obviously be
{
true for optimal weights. Unfortunately, it is not possible to state that the choice β = 1
is optimal if the σ2
Ql for
due to ﬁnite N will propagate to the
N
estimate of σ2
= σ2
. A recursive procedure allows to
calculate the expectation values for

i ’s are not known in advance. Although the convergence of ql →
Ql|

; using eq. (6), it is straightforward to show that

ql −
|
i , even when M

is guaranteed, the small deviation

i and render Vi 6

1/σ2
k}
1/σk}

i σ−2

→ ∞

→ ∞

P

.

i

Vi =

σ2
i +

(cid:20)

gi
√M (cid:21)

(1

2fi) +

−

σ2
j +

gj
√M (cid:19)

+ 2

fjfk

Xj<k

ejk
√M −

2

fj

eij
√M

.

(10)

Xj;j6=i

Now we use ωi = V −β
σi’s and random variables
eij}
{
i σ−b
i m2
us deﬁne G(b)

1
N

i

i

and, after iterative substitutions, we may express ωi in terms of
. One may then compute fi and plug it in eqs. (7-9). Let
and denote by angular brackets a simple average over the

fii
h
f 2
j

(cid:18)

j
X

≡

P

4

EUROPHYSICS LETTERS

dq(~1/σ2
)
dq(~1/σ)
Th. dq(~1/σ2
)
Th. dq(~1/σ)

0,1

dq

0,05

0
10

2
10

4
10

6
10

M

4

10

2

10

dσ

0

10

-2

10

-4

10

)

)

dσ(~1/σ2
Unb. dσ(~1/σ2
dσ(~1/σ)
Unb. dσ(~1/σ)
Th. Unb. dσ(~1/σ)
Th. dσ(~1/σ2
Th. dσ(~1/σ)

)

0

10

2

10

M

4

10

6

10

Fig. 1 – Average squared diﬀerence dσ between given and predicted variance, as a function of M in
log-log scale. Symbols represent simulations of the IR method with β = 1 (triangles) and β = 1/2
(ﬁlled squares) in eq. (5); Diamonds and ﬁlled circles show simulations of dσ, where the estimator of
the variance has been corrected for the bias. The corresponding theoretical predictions, calculated as
explained in the text, ﬁt the data very well. In the inset a similar plot shows the coincidence between
the predicted and simulated plateau reached by dq for large M . Parameters of the simulations:
N = 100, intrinsic values Ql uniformly distributed between 10 and 20 and standard deviations σi
uniformly distributed between 1 and 5; averaged over 103 realizations.

= 1
N

y
h

raters
calculations to obtain the following asymptotic expansions, for M, N
dominating orders:

i yi. Equipped with this formalism, we perform tedious but straightforward
, to the ﬁrst two

→ ∞

P

i

Q)2

(q

−

(cid:10)
Bias(Vi)

(cid:11)

≃

≃

N

1
σ−2β
h

Q)2

(q

−

Var(Vi)

(cid:10)
m2
i

σ4
i
M "

(cid:11)
1 +

≃

(cid:29)

2
i

1
σ4β−2
(cid:20)(cid:28)
2σ2−2β
i
σ−2β
N
−
h
(β + 1)σ−2β
i
σ−2β
h

N

i (cid:20)

,

i #

+

β
C1
N

+

β
C2
M

,

1 +

β
D1
N

+

(cid:21)
β
D2
M

,

(cid:21)

(11)

(12)

(13)

(cid:10)

≃

N

(cid:11)(cid:1)

1/

σ−2

1/(N

with complicated constant coeﬃcients (1). These expressions simplify considerably when
taking the limit β = 1/2 and β = 1. For instance, eq. (12) takes the forms Biasβ=1(Vi)
1/σ
h

≃
2)
. The analytical solution
2σi/
and Biasβ=1/2(Vi)
−
i
−
allows one to ﬁnd an unbiased estimator for σ2
In applications
i –up to
(cid:0)
we may use eq. (4) as an estimator of σ2 to evaluate Bias(Vi) and redeﬁne the weights as
ωi = 1/(Vi −
Bias(Vi)). Since we have here dql = sl, suﬃces to plug eqs. (11 - 13) in eq. (9) to
(1)They are given by: C1 = 4hσ2−6β i
hσ−2β i
1)G(4β − 2) − (β+1)G(2β)hσ2−4β i
(β−1)m2
i
2

σ−1
h
i
(1/N 2, 1/N M ).
(cid:1)

hσ−2β i2 + hσ2−4β ihσ

hσ2−4β iσ
hσ−2β i2 − 2hσ

−4β ihσ2−4β i
hσ−2β i2
−4β i

, C2 = 4hσ2−4β i + (2β −

+ 2 hσ2−4β i2hσ

, D1 =
−2β
i

hσ−2β i
hσ

−2β
2σ
i
hσ−2β i

− (β+1)G(2β)
hσ−2β i

−2(β+2) iσ
hσ−2β i

and D2 =

−2(β+1) i

−2(β+1)i

− 6 hσ

hσ−2β i3

hσ−2β i3

(cid:0)
O

−2
i

+ 2

N

−

.

P. Laureti, L. Moret, Y.-C. Zhang and Y.-K. Yu: Collaborative filtering

5

2

10

0

10

dq

-2

10

-4

10

0
10

)

dq(~1/σ2
dq(~1/σ)
Th. dq(~1/σ2
Th. dq(~1/σ)
Th. dq(1/N)

)

20

dσ

10

)

dσ(~1/σ2
dσ(~1/σ)
Th.  pl. dσ

0
0
10

2
10

4
10

N

2
10

N

4
10

Fig. 2 – Average squared diﬀerence between estimators and intrinsic values, for quality (main) and
variance (inset), plotted in log-log scale as a function of N , with M = 100, for β = 1/2, 1. Symbols
represent simulation results of the IR method, lines are the corresponding theoretical predictions.
The dotted line represents dq when the quality estimator is just the straight average.

ﬁnd theoretical expressions for the mean squared errors. They are shown to match numerical
simulations in ﬁgs. 1 and 2.

P

In ﬁg. 1, the mean squared error of the variance dσ = 1
N

i dσi is plotted against M in
log-log scale. Our theoretical prediction becomes very good as soon as M > 10. Diamonds
and ﬁlled circles show simulation results of the IR method where the biased estimator of the
variance has been corrected by recursive use of eq. (12): the plateau reached by dσ for large
M disappears because the accuracy of the prediction can be thus improved by two orders of
magnitude. The mean squared error of the quality dq = 1
l dql , on the other hand, can
M
never vanish for large M when N is ﬁnite. This is shown in the inset of ﬁg. 1, while the
dependence of dq on N is reported in ﬁg. 2. We have also plotted therein, as a dotted line,
the behaviour of the same quantity when the estimator of ql is just the average unweighted
vote received by item l. This illustrates how IR is able to reduce the error. A comparison
between the two weighting schemes shows that ωi = 1/Vi performs almost always better than
ωi = 1/√Vi. The inset of ﬁg. 2 shows dσ vs. N ; the plateau, which is the same for β = 1/2
when corrected for the bias as before.
and 1, vanishes for M

P

→ ∞

Camouﬂage. – Let us now restart from the general problem of eqs. (1,2). The case
we want to analyse here is that of ratings aﬀected by systematic errors that depend on the
l. Such a ﬁctitious distortion is instructive to study
rater but not on the ratee, ∆il = ∆i ∀
analytically and can be easily generalised to more interesting cases. In fact, as it alters a
rater’s scale of evaluation but not the ranking of her preferences, it can serve as a basis to
study systems where agents are only asked to sort a set of items in order of increasing quality.
proceeding
{
) with respect to
i δij + ∆i∆j. Here we have used a more compact

If one knew the values of ∆i for all i, one could ﬁnd the optimal weights
ωk}

as described in absence of systematic errors. Upon minimisation of dq(
{
the ωi’s one obtains ω∗ = A−11, with Aij = σ2
matrix notation, where 1 is a vector of ones.

ω∗
k}

Whenever the deviations ∆i are small, limited to a minority of the population or randomly
In the general case one can only

distributed around zero, they can be somehow detected.

6

EUROPHYSICS LETTERS

N=100,M=100,σ ε [1, 10], qε[10, 20], σ

ch. = 1, qchd. =20, biasFixedSigmaNoErrorBars.agr, bias.m, 1000 runs

upward push versus result

6

5

4

3

2

1

d
e
c
n
a
v
d
a
 
k
n
a
r
 
q
 
s
’
t
c
e
j
b
O

0
0

analytical evaluation for ω~1/σ
analytical evaluation for ω~1/σ2
ω~1/σ
ω~1/σ2
x=y

5

10

15

20

Cheater’s σ rank worsened

25

Fig. 3 – Increase of object’s quality as a function of the cheater’s rank loss, as the value of ∆ grows from
0 to 30. Simulations have been carried on with N = 100, M = 100 and intrinsic values distributed as
in ﬁg. 1, except for σI = 1 and QL = 20. The theoretical estimations are parametric plots of eq. (14)
for β = 1 and 1/2.

detect, at best, the relative systematic errors.
j fj∆j does not depend on
l in presence of camouﬂage and the relevant quantities only depend on ∆i under the form
2
δi = ∆i −
.
This means that, if we change the ∆i’s while keeping the δi’s unchanged, we end up with the
same result for dq, only translated by the amount ˜∆.

P
˜∆. For instance, the variance can be written as Vi = 1
M

j fj(yjl −

yil) + δi

hP

P

i

l

In fact ˜∆ =

In order to estimate analytically the performance of the IR method, we can posit ˜∆ = 0
i +
j )−β. This way we have a formal solution as a function of δi, which must

and solve eqs. (3-5) as before. Thus we ﬁnd fi(
{
i )−β/
δ2
comply with the constraint

i fiδi = 0 and can eventually be recovered numerically.

), whose term of order zero is (σ2

j + δ2

j(σ2

δi}

P

P

Cheating. – It is interesting to consider the case of one intentional cheater I wanting to
boost the value of object L of an amount ∆, all other raters being honest: ∆il = δiI δlL∆.
Agent I commits no systematic error in evaluating all objects but L. Still, she would loose
credibility and weight as ∆ becomes larger; this would eventually diminish her relative in-
ﬂuence over object L. It is important to evaluate the diﬀerence δql = ql(∆)
ql between
the estimated value of the object with and without the friendly uprating. In fact a small δq,
compared to the lost in credibility of the rater, discourages cheating, and vice-versa.

−

{

{

) = Vi(0,

fi(∆)
}

fi(∆)
}

fi(∆)
}

The variance, as deﬁned in eq. (4), can be written as a function of ∆ and of the normalised
) + δiI ∆2/M , where the formal expression of
weights. Hence Vi(∆,
Vi(0,
) is equal to that of eq. (10). Iterative asymptotic expansions can be performed
the same way we did in absence of systematic errors. In this case the variables yil are equal to
i fi(∆)yil +∆δlLfI (∆),
the xil, except for yIL = xIL −
δqLi ≃
ql ≃
which implies ql(∆)
h
. If the value of ∆ is comparable to √M , on the other hand, the zeroth
∆
order of the correction at the thermodynamic limit amounts to

∆. Therefore eq. (3) becomes ql(∆) =
∆δlLfI . For ∆

√M the average deviation reads

β ∆2
σ2
I M

fIi −

P

≪

−

{

h
(cid:16)

(cid:17)

δqLi →

h

∆

β

σ2
I +

∆2
M

(cid:19)

Xj6=I

· 

(cid:18)



σ−2β
j + 1

−1

.





(14)

P. Laureti, L. Moret, Y.-C. Zhang and Y.-K. Yu: Collaborative filtering

7

In ﬁg. 3 eq. (14) is shown to ﬁt the simulations fairly well in the rank space. We have compared
thereby the scheme β = 1 (circles) with β = 1/2 (stars) in the worst case: the best agent is
trying to raise the worst object. In the region of moderate cheating the ωi = 1/√Vi weighting
scheme is less sensitive to cheating. This is particularly important left to the x = y line, where
the cheater pays less then what she oﬀers to the object and cheating can be advantageous.
However, the relative inﬂuence of the cheater is a growing, although saturating, function of ∆.
Under the ωi = 1/Vi weighting scheme, on the other hand, such an inﬂuence starts decreasing
once passed a crossover value. There the cheater’s reputation is so much damaged by her
misbehaviour that, if she attributed a higher value to object L, its estimated rank would
diminish. Optimal weights are, therefore, much more resilient to severe cheating.

We just remark that, taking averages without reﬁnement, a cheater would indeﬁnitely
increase an object’s rank without undergoing any punishment. The transition to the cheater’s
unfavorable region is the solution of dr(q) = dr(σ) in the ∆ space.

Conclusion. – In this letter we have analyzed a novel scoring system that aggregates the
evaluations of N agents over M objects by use of reputation and weighted averages. Agents,
as a result, are ranked according to their judging capability and objects according to their
quality. The method can be implemented via an iterative algorithm, where the intrinsic bias
of the estimators of the weights can be corrected. We show, with simulations and analytical
results, that the method is eﬀective and robust against abuses. The larger the system, the
better is the ﬁltering precision. This method can be applied in web-related reputation and
scoring systems.

We thank the reviewers for useful remarks. This work was partially supported by the Swiss
National Science Foundation, through project number 2051-67733, and by the Intramural
Research Program of the National Library of Medicine at NIH/DHHS.

∗ ∗ ∗

REFERENCES

[1] Watts D.J. and Strogatz S.H., Nature, 393 (1998) 440.
[2] Albert R. and Barab´asi A., Rev. Mod. Phys., 74 (2002) 47.
[3] Dorogovtsev S. N. and Mendes J. F. F., Advances in Physics, 51 (2002) 1079.
[4] Newman M. E. J., SIAM Review, 45 (2003) 167.
[5] Rosvall M. and Sneppen K., Phys. Rev. Lett., 91 (2003) 178701.
[6] Arenas A., Diaz-Guilera A. and R. Guimera, Phys. Rev. Lett., 86 (2001) 3196.
[7] Varian H., Scientiﬁc American, 9 (1995) 200.
[8] Page L., Brin S., Motwani R. and Winograd T., Technical report, Stanford Univ., (1998)
[9] Kleinberg J.M., Journal of the ACM, 46 (1999) 604
[10] Herlocker J. L., Konstan J. A., Terveen L. G. and Riedl J. T., ACM TIS, 22 (2004) 5.
[11] Resnick P., Kuwabara K., Zeckhauser R. and Friedman E, Comm. ACM, 43 (2000) 45
[12] Yu Y.-K., Zhang Y.-C., Laureti P. and Moret L., to be published in Physica A
[13] Feller W., An Introduction to Probability Theory and Its Applications, Vol. 2 (Wiley, New

York) 1971.

[14] Hoel P. G., Introduction to Mathematical Statistics (Wiley, New York) 1983.

