1
0
0
2
 
v
o
N
 
4
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
6
2
1
1
1
1
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A Matlab Program to Calculate the Maximum
Entropy Distributions

Ali Mohammad-Djafari

Laboratoire des Signaux et Systèmes,
Supélec, Plateau de Moulon, 91192 Gif-sur-Yvette, France

INTRODUCTION

Shannon (1948) indicated how maximum entropy (ME) distributions can be derived by a
straigtforward application of the calculus of variations technique. He deﬁned the entropy
of a probability density function p(x) as

H = −

p(x) ln p(x) dx

(1)

Maximizing H subject to various side conditions is well–known in the literature as a
method for deriving the forms of minimal information prior distributions; e.g. Jaynes
(1968) and Zellner (1977). Jaynes (1982) has extensively analyzed examples in the
discrete case, while in Lisman and Van Znylen (1972), Rao (1973) and Gokhale (1975),
Kagan, Linjik continuous cases are considered. In the last case, the problem, in its
general form, is the following

maximize H = −

p(x) ln p(x) dx

subject to E {φn(x)} =

Z
φn(x) p(x) dx = µn, n = 0, . . . , N

where µ0 = 1 , φ0(x) = 1 and φn(x), n = 0, . . . , N are N known functions, and µn, n =
0, . . . , N are the given expectation data. The classical solution of this problem is given
by

Z

Z

p(x) = exp

−

λn φn(x)

#

N

"

n=0
X

The (N + 1) Lagrangien parameters λ = [λ0, . . . , λn] are obtained by solving the follow-
ing set of (N + 1) nonlinear equations

Gn(λ) =

Z

N

"

n=0
X

#

φn(x) exp

−

λn φn(x)

dx = µn, n = 0, . . . , N

(4)

(2)

(3)

The distributions deﬁned by (3) form a great number of known distributions which are
obtained by choosing the appropriate N and φn(x), n = 0, . . . , N. In general φn(x) are
either the powers of x or the logarithm of x. See Mukhrejee and Hurst (1984), Zellner
(1988), Mohammad–Djafari (1990) for many other examples and discussions. Special
cases have been extensively analyzed and used by many authors. When φn(x) = xn, n =
0, . . . , N then µn, n = 0, . . . , N are the given N moments of the distribution. See, for
example, Zellner (1988) for a numerical implementation in the case N = 4.

In this communication we propose three programs written in MATLAB to solve
the system of equations (4). The ﬁrst is a general program where φn(x) can be any
functions. The second is a special case where φn(x) = xn, n = 0, . . . , N. In this case
the µn are the geometrical moments of p(x). The third is a special case where φn(x) =
exp(−jnωx), n = 0, . . . , N. In this case the µn are the trigonometrical moments (Fourier
components) of p(x). We give also some examples to illustrate the usefullness of these
programs.

PRINCIPLE OF THE METHOD

We have seen that the solution of the standard ME problem is given by (3) in which the
Lagrange multipliers λ are obtained by solving the nonlinear equations (4). In general,
these equations are solved by the standard Newton method which consists of expanding
Gn(λ) in Taylor’s series around trial values of the lambda’s, drop the quadratic and
higher order terms, and solve the resulting linear system iteratively. We give here the
details of the numerical method that we implemented. When developing the Gn(λ)
in equations (4) in ﬁrst order Taylor’s series around the trial λ0, the resulting linear
equations are given by

Gn(λ) ∼= Gn(λ0) + (λ − λ0)t [ grad Gn(λ)]

(λ=λ0

)

= µn, n = 0, . . . , N

(5)

Noting the vectors δ and v by

δ = λ − λ0

and the matrix G by

v =

µ0 − G0(λ0), . . . , µN − GN (λ0)

t

(cid:3)

(cid:2)





G =

gnk

=

n, k = 0, . . . , N





∂Gn(λ)

∂λk 





(λ=λ0

)



then equations (5) become

G δ = v

(6)

(7)

This system is solved for δ from which we drive λ = λ0 + δ, which becomes our new
initial vector λ0 and the iterations continue until δ becomes appropriately small. Note
that the matrix G is a symmetric one and we have

gnk = gkn = −

φn(x) φk(x) exp

−

λn φn(x)

dx n, k = 0, . . . , N

(8)

Z

N

"

n=0
X

#

So in each iteration we have to calculate the N(N − 1)/2 integrals in the equation (8).
The algorithm of the general Maximum Entropy problem is then as follows:

(xmin, xmax,dx).
1. Deﬁne the range and the discretization step of x
(fin_x).
2. Write a function to calculate φn(x), n = 0, . . . , N
3. Start the iterative procedure with an initial estimate λ0
(lambda0).
4. Calculate the (N + 1) integrals in equations (4) and the N(N − 1)/2 distinct

elements gnk of the matrix G by calculating the integrals in the equations(8)

5. Solve the equation (7) to ﬁnd δ
6. Calculate λ = λ0 + δ and go back to step 3 until δ becomes negligible.

(Gn, gnk).
(delta).

The calculus of the integrals in equations (4) and (8) can be made by a univariate
Simpson’s method. We have used a very simpliﬁed version of this method.

Case of geometrical moments

Now consider the special case of moments problem where φn(x) = xn, n =

0, . . . , N. In this case equations (3), (4) and (8) become

p(x) = exp

−

N

λm xm

#

"

m=0
X

(9)

Gn(λ) =

xn exp

−

λm xm

dx = µn, n = 0, . . . , N

(10)

Z

#

N

"

m=0
X

N

gnk = gkn = −

xnxk exp

−

λm xm

dx = −Gn+k(λ) n, k = 0, . . . , N (11)

Z

"

m=0
X

#

This means that the [(N + 1) × (N + 1)] matrix G in equation (7) becomes a symmet-
ric Hankel matrix which is entirely deﬁned by 2N + 1 values Gn(λ), n = 0, . . . , 2N. So
the algorithm in this case is the same as in the precedent one with two simpliﬁcations

1. In step 2 we do not need to write a seperate function to calculate the functions

φn(x) = xn, n = 0, . . . , N.

2. In step 4 the number of integral evaluations is reduced, because the elements gnk
of the matrix G are related to the integrals Gn(λ) in equations (10). This matrix is
deﬁned entirely by only 2N + 1 components.

Case of trigonometrical moments

Another interesting special case is the case where the data are the Fourier components

of p(x)

Z

"

E {exp (−jnω0x)} =

exp (−jnω0x) p(x) dx = µn, n = 0, . . . , N,

(12)

where µn may be complex–valued and has the property µ−n = µn. This means that we
have the following relations

φn(x) = exp (−jnω0x) , n = −N, . . . , 0, . . . N,
N

p(x) = exp

−Real

λn exp (−jnω0x)

,

n=0
X

#

Gn(λ) =

exp (−jnω0x) p(x) dx, n = 0, . . . , N,

gnk =

−Gn−k(λ)
−Gn+k(λ)

for n ≥ k,
for n < k

Z

(cid:26)

n, k = 0, . . . , N,

(13)

(14)

(15)

(16)

so that all the elements of the matrix G are related to the discrete Fourier transforms of
p(x). Note that G is a Hermitian Toeplitz matrix.

EXAMPLES AND NUMERICAL EXPERIMENTS

To illustrate the usefullness of the proposed programs we consider ﬁrst the case of the
Gamma distribution

p(x; α, β) =

xα exp(−βx),

x > 0, α < 1, β > 0.

(17)

β(1−α)
Γ(1 − α)

This distribution can be considered as a ME distribution when the constraints are

p(x; α, β) dx
= 1
= µ1
x p(x; α, β) dx
ln(x) p(x; α, β) dx = µ2

normalization φ0(x) = 1,
= x,
φ1(x)
= ln(x).
φ2(x)

(18)

This is easy to verify because the equation (12) can be written as






R
R
R






(cid:2)

p(x; α, β) = exp

−λ0 − λ1x − λ2 ln(x)

(cid:3)

with λ0 = − ln

, λ1 = β and λ2 = −α.

β(1−α)
Γ(1 − α)

Now consider the following problem

Given µ1 and µ2 determine λ0, λ1 and λ2.

This can be done by the standard ME method. To do this, ﬁrst we must deﬁne the range
of x, (xmin, xmax, dx), and write a function fin_x to calculate the functions
φ0(x) = 1, φ1(x) = x and φ2(x) = ln x (See the function fin1_x in Annex). Then we
must deﬁne an initial estimate λ0 for λ and, ﬁnally, let the program works.

The case of the Gamma distribution is interesting because there is an analytic relation

between (α, β) and the mean m = E {x} and variance σ2 = E {(x − m)2} which is

or inversely

m = (1 − α)/β
σ2 = (1 − α)/β2 ,

α = (σ2 − m2)/σ2
β = m/σ2,

,

(cid:26)

(cid:26)

so that we can use these relations to determine m and σ2. Note also that the corre-
sponding entropy of the ﬁnal result is a byproduct of the function. Table (1) gives some
numerical results obtained by ME_DENS1 program (See Annex).

µ2

µ1

α
0.2156
0.2000 -3.0000
0.2000 -2.0000 -0.4124
0.3000 -1.5000 -0.6969

Table 1.

β
-3.0962
-6.9968
-5.3493

m

σ2
0.2533 0.0818
0.2019 0.0289
0.3172 0.0593

The next example is the case of a quartic distribution

p(x) = exp

−

4

λn xn

.

#

"

n=0
X

This distribution can be considered as a ME distribution when the constraints are

E {xn} =

xn p(x) dx = µn, n = 0, . . . , 4 with µ0 = 1.

(22)

Z

Now consider the following problem : Given µn, n = 1, . . . , 4 calculate λn, n = 0, . . . , 4
. This can be done by the ME_DENS2 program. Table (2) gives some numerical results
obtained by this program:

(19)

(20)

(21)

µ1 µ2
0.2
0
0.3
0
0.3
0

λ0

µ3
µ4
0.05 0.10 0.1992
0.00 0.15 0.9392
0.00 0.15 0.9392

Table 2.
λ1
1.7599
0.000
0.000

λ2
2.2229
-3.3414
-3.3414

λ3

λ4

-3.9375 0.4201
4.6875
0.0000
4.6875
0.0000

These examples show how to use the proposed programs. A third example is also
given in Annex which shows how to use the ME_DENS3 program which considers the
case of trigonometric moments.

CONCLUSIONS

In this paper we addressed ﬁrst the class of ME distributions when the available data are a
ﬁnite set of expectations µn = E {φn(x)} of some known functions φn(x), n = 0, . . . , N.
We proposed then three Matlab programs to solve this problem by a Newton–Raphson
method in general case, in case of geometrical moments data where φn(x) = xn and
in case of trigonometrical moments where φn(x) = exp (−jnω0x). Finally, we gave
some numerical results for some special examples who show how to use the proposed
programs.

REFERENCES

1. A. Zellnerr and R. Highﬁled, “Calculation of Maximum Entropy Distributions and Approximation

of Marginal Posterior Distributions”, Journal of Econometrics 37, 1988, 195–209, North Holland.

2. D. Mukherjee and D.C. Hurst, “Maximum Entropy Revisited”, Statistica Neerlandica 38, 1984, n ˛a

3. Verdugo Lazo and P.N. Rathie, “On the Entropy of Continuous Probability Distributions”, IEEE

1, 1–12.

Trans. , vol. IT–24, n ˛a 1, 1978.

4. Gokhale, “Maximum Entropy Characterizations of some distributions”, Statistical distributions in

5.

Scientiﬁc work , vol. 3, 299–304 (G.P. Patil et al., Eds., Reidel, Dordrecht, Holland, 1975).
Jaynes, “Papers on probability, statistics and statistical physics”, Reidel Publishing Company, Dor-
drecht , Holland, 1983.

6. Matz, “Maximum Likelihood parameter estimation for the quartic exponential distributions”, Tech-

7. Mohammad-Djafari A. et Demoment G., "Estimating Priors in Maximum Entropy Image Process-

nometrics , 20, 475–484, 1978.

ing," Proc. of ICASSP 1990 , pp: 2069-2072

8. Mohammad-Djafari A. et Idier J., "Maximum entropy prior laws of images and estimation of their
parameters," Proc. of The 10th Int. MaxEnt Workshop, Laramie, Wyoming , published in Maximum-
entropy and Bayesian methods, T.W. Grandy ed., 1990.

ANNEX A

% initialize LAMBDA

% This produces a uniform

% fin1_x(x) is an external
% function which provides fin(x).

iter=iter+1;
disp(’---------------’); disp([’iter=’,num2str(iter)]);

% start iterations

[LAMBDA,P,ENTR]=ME_DENS1(MU,X,LAMBDA0)
This program calculates the Lagrange Multipliers of the ME
probability density functions p(x) from the knowledge of the
N contstraints in the form:
E{fin(x)}=MU(n)

with fi0(x)=1, MU(0)=1.

MU
X
LAMBDA0 is a table containing the first estimate of the LAMBDAs.

is a table containing the constraints MU(n),n=1:N.
is a table defining the range of the variation of x.

LAMBDA is a table containing the resulting Lagrange parameters.
P
ENTR

is a table containing the resulting pdf p(x).
is a table containing the entropy values at each
iteration.

n=0:N

: 10-01-1991

% distribution.

lambda=lambda0(:);

(This argument is optional.)

% add mu(0)=1
% x axis

lambda=zeros(size(mu));
lambda(1)=log(xmax-xmin);

Author: A. Mohammad-Djafari
Date

1 function [lambda,p,entr]=me_dens1(mu,x,lambda0)
2 %ME_DENS1
3 %
4 %
5 %
6 %
7 %
8 %
9 %
10 %
11 %
12 %
13 %
14 %
15 %
16 %
17 %
18 %
19 %
20 %
21 mu=mu(:); mu=[1;mu];
22 x=x(:); lx=length(x);
23 xmin=x(1); xmax=x(lx); dx=x(2)-x(1);
24 %
25 if(nargin == 2)
26
27
28 else
29
30 end
31 N=length(lambda);
32 %
33 fin=fin1_x(x);
34 %
35 iter=0;
36 while 1
37
38
39 %
40
41
42 %
43
44
45
46
47 %
48
49
50 %
51
52
53
54
55
56
57
58
59
60
61
62
63 %
64
65
66
67
68
69
70
71
72 end
73 %
74 p=exp(-(fin*lambda));
75 plot(x,p);
76 entr=entr(:);
77 disp(’----- END

v=mu-G;
delta=gnk\v;
lambda=lambda+delta;
eps=1e-6;
if(abs(delta./lambda)<eps),
if(iter>2)

gnk=zeros(N,N);
gnk(1,:)=-G’; gnk(:,1)=-G;
for i=2:N

entr(iter)=lambda’*G(1:N);
disp([’Entropy=’,num2str(entr(iter))])

p=exp(-(fin*lambda));
plot(x,p);

gnk(i,j)=-dx*sum(fin(:,j).*fin(:,i).*p);

G=zeros(N,1);
for n=1:N

G(n)=dx*sum(fin(:,n).*p);

end
for i=2:N

gnk(i,j)=gnk(j,i);

% Calculate Gn

for j=i+1:N

for j=2:i

-------’)

end

end

end

end

end

% Calculate p(x)
% plot it

% Calculate the entropy value

% Calculate gnk
% first line and first column
% lower triangle part of the
% matrix G

% uper triangle part of the
% matrix G

% Calculate v
% Calculate delta
% Calculate lambda
% Stopping rules

break, end

% Calculate the final p(x)
% plot it

if(abs((entr(iter)-entr(iter-1))/entr(iter))<eps),break, end

This script shows how to use the function ME_DENS1
in the case of the Gamma distribution. (see Example 1.)

1 %----------------------------------
2 %ME1
3 %
4 %
5 xmin=0.0001; xmax=1; dx=0.01;
6 x=[xmin:dx:xmax]’;
7 mu=[0.3,-1.5]’;
8 [lambda,p,entr]=me_dens1(mu,x);
9 alpha=-lambda(3);

beta=lambda(2);

% define the x axis

% define the mu values

10 m=(1+alpha)/beta; sigma=m/beta;
11 disp([mu’ alpha beta m sigma entr(length(entr))])
12 %----------------------------------

1 function fin=fin1_x(x);
2 % This is the external function which calculates
3 % the fin(x) in the special case of the Gamma distribution.
4 % This is to be used with ME_dens1.
5
6
7
8
9

M=3;
fin=zeros(length(x),M);
fin(:,1)=ones(size(x));
fin(:,2)=x;
fin(:,3)=log(x);

10 return

% initialize LAMBDA

% This produces a uniform

% Calcul de fin(x)=x.^n
%

[LAMBDA,P,ENTR]=ME_DENS2(MU,X,LAMBDA0)
This program calculates the Lagrange Multipliers of the ME
probability density functions p(x) from the knowledge of the
N moment contstraints in the form:
n=0:N
E{x^n}=mu(n)

with mu(0)=1.

MU
X
LAMBDA0 is a table containing the first estimate of the LAMBDAs.

is a table containing the constraints MU(n),n=1:N.
is a table defining the range of the variation of x.

LAMBDA is a table containing the resulting Lagrange parameters.
P
ENTR

is a table containing the resulting pdf p(x).
is a table containing the entropy values at each
iteration.

: 10-01-1991

% distribution.

lambda=lambda0(:);

fin(:,n)=x.*fin(:,n-1);

(This argument is optional.)

% add mu(0)=1
% x axis

lambda=zeros(size(mu));
lambda(1)=log(xmax-xmin);

Author: A. Mohammad-Djafari
Date

1 function [lambda,p,entr]=me_dens2(mu,x,lambda0)
2 %ME_DENS2
3 %
4 %
5 %
6 %
7 %
8 %
9 %
10 %
11 %
12 %
13 %
14 %
15 %
16 %
17 %
18 %
19 %
20 %
21 mu=mu(:); mu=[1;mu];
22 x=x(:); lx=length(x);
23 xmin=x(1); xmax=x(lx); dx=x(2)-x(1);
24 %
25 if(nargin == 2)
26
27
28 else
29
30 end
31 N=length(lambda);
32 %
33 M=2*N-1;
34 fin=zeros(length(x),M);
35 fin(:,1)=ones(size(x));
36 for n=2:M
37
38 end
39 %
40 iter=0;
41 while 1
42
43
44 %
45
46
47 %
48
49
50
51
52 %
53
54
55 %
56
57
58
59
60 %
61
62
63
64
65
66
67
68
69 end
70 %
71 p=exp(-(fin(:,1:N)*lambda));
72 plot(x,p);
73 entr=entr(:);
74 disp(’----- END
75 end

v=mu-G(1:N);
delta=gnk\v;
lambda=lambda+delta;
eps=1e-6;
if(abs(delta./lambda)<eps),
if(iter>2)

entr(iter)=lambda’*G(1:N);
disp([’Entropy=’,num2str(entr(iter))])

gnk=zeros(N,N);
for i=1:N

G=zeros(M,1);
for n=1:M

p=exp(-(fin(:,1:N)*lambda)); % Calculate p(x)
plot(x,p);

G(n)=dx*sum(fin(:,n).*p);

gnk(:,i)=-G(i:N+i-1);

% Calculate Gn

% plot it

-------’)

% fi0(x)=1

end

end

end

% Calculate the entropy value

% Calculate gnk
% Matrix G is a Hankel matrix

% Calculate v
% Calculate delta
% Calculate lambda
% Stopping rules

break, end

% Calculate the final p(x)
% plot it

iter=iter+1;
disp(’---------------’); disp([’iter=’,num2str(iter)]);

% start iterations

if(abs((entr(iter)-entr(iter-1))/entr(iter))<eps),break, end

This script shows how to use the function ME_DENS2
in the case of the quartic distribution. (see Example 2.)

1 %ME2
2 %
3 %
4 xmin=-1; xmax=1; dx=0.01;
5 x=[xmin:dx:xmax]’;
6 mu=[0.1,.3,0.1,.15]’;
7 [lambda,p,entr]=me_dens2(mu,x);
8 disp([mu;lambda;entr(length(entr))]’)

% define the x axis

% define the mu values

n=0:N

: 10-01-1991

with mu(0)=1.

% distribution.

lambda=lambda0(:);

% start iterations

% initialize LAMBDA

% This produces a uniform

(This argument is optional.)

% add mu(0)=1
% x axis

lambda=zeros(size(mu));
lambda(1)=log(xmax-xmin);

% Calculate fin(x)=exp[-jnw0x]
% fin3_x(x) is an external
% function which provides fin(x).

is a table containing the constraints MU(n),n=1:N.
is a table defining the range of the variation of x.

iter=iter+1;
disp(’---------------’); disp([’iter=’,num2str(iter)]);

is a table containing the resulting pdf p(x).
is a table containing the entropy values at each
iteration.

LAMBDA is a table containing the resulting Lagrange parameters.
P
ENTR

MU
X
LAMBDA0 is a table containing the first estimate of the LAMBDAs.

[LAMBDA,P,ENTR]=ME_DENS3(MU,X,LAMBDA0)
This program calculates the Lagrange Multipliers of the ME
probability density functions p(x) from the knowledge of the
Fourier moments values :
E{exp[-j n w0 x]}=mu(n)

1 function [lambda,p,entr]=me_dens3(mu,x,lambda0)
2 %ME_DENS3
3 %
4 %
5 %
6 %
7 %
8 %
9 %
10 %
11 %
12 %
13 %
14 %
15 %
16 %
17 %
18 % Author: A. Mohammad-Djafari
19 % Date
20 %
21 mu=mu(:);mu=[1;mu];
22 x=x(:); lx=length(x);
23 xmin=x(1); xmax=x(lx); dx=x(2)-x(1);
24 if(nargin == 2)
25
26
27 else
28
29 end
30 N=length(lambda);
31 %
32 M=2*N-1;
33 fin=fin3_x(x,M);
34 %
35 iter=0;
36 while 1
37
38
39 %
40
41
42
43 %
44
45
46
47
48
49 %
50
51
52 %
53
54
55
56
57
58
59
60
61
62
63
64 %
65
66
67
68
69
70
71
72
73 end
74
75 p=exp(-real(fin(:,1:N))*real(lambda)+imag(fin(:,1:N))*imag(lambda));
76 plot(x,p);
77 entr=entr(:);
78 disp(’----- END
79 end

v=mu-G(1:N);
delta=gnk\v;
lambda=lambda+delta;
eps=1e-3;
if(abs(delta)./abs(lambda)<eps),
if(iter>2)

% Calculate gnk
% Matrix gnk is a Hermitian
% Toeplitz matrix.
% Lower triangle part

end
%plot([real(G(1:N)),real(mu),imag(G(1:N)),imag(mu)])

entr(iter)=lambda’*G(1:N);
disp([’Entropy=’,num2str(entr(iter))])

% Calculate v
% Calculate delta
% Calculate lambda
% Stopping rules

if(abs((entr(iter)-entr(iter-1))/entr(iter))<eps),break, end

p=exp(-real(fin(:,1:N))*real(lambda)+imag(fin(:,1:N))*imag(lambda));
plot(x,p);

gnk=zeros(N,N);
for n=1:N

G=zeros(M,1);
for n=1:M

gnk(n,k)=-conj(G(k-n+1));

G(n)=dx*sum(fin(:,n).*p);

% Calculate the entropy

% Upper triangle part

end
for n=1:N

gnk(n,k)=-G(n-k+1);

% Calculate p(x)

% Calculate p(x)

% Calculate Gn

for k=n+1:N

break, end

% plot it

% plot it

for k=1:n

-------’)

end

end

end

end

This scripts shows how to use the function ME_DENS3
in the case of the trigonometric moments.

1 %ME3
2 %
3 %
4 clear;clf
5 xmin=-5; xmax=5; dx=0.5;
6 x=[xmin:dx:xmax]’;lx=length(x);
7 p=(1/sqrt(2*pi))*exp(-.5*(x.*x));% Gaussian distribution
8 plot(x,p);title(’p(x)’)
9 %

% define the x axis

% Calculate mun

% Calculate fin(x)

mu(n)=dx*sum(fin(:,n).*p);

10 M=3;fin=fin3_x(x,M);
11 %
12 mu=zeros(M,1);
13 for n=1:M
14
15 end
16 %
17 w0=2*pi/(xmax-xmin);w=w0*[0:M-1]’; % Define the w axis
18 %
19 mu=mu(2:M);
20
21 [lambda,p,entr]=me_dens3(mu,x);
22 disp([mu;lambda;entr(length(entr))]’)

% Attention : mu(0) is added
% in ME_DENS3

1 function fin=fin3_x(x,M);
2 % This is the external function which calculates
3 % the fin(x) in the special case of the Fourier moments.
4 % This is to be used with ME_DENS3.
5 %
6 x=x(:); lx=length(x);
7 xmin=x(1); xmax=x(lx); dx=x(2)-x(1);
8 %
9 fin=zeros(lx,M);

% x axis

%

10 fin(:,1)=ones(size(x));
11 w0=2*pi/(xmax-xmin);jw0x=(sqrt(-1)*w0)*x;
12 for n=2:M
13
14 end
15 return

fin(:,n)=exp(-(n-1)*jw0x);

% fi0(x)=1

