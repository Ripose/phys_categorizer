1
0
0
2
 
v
o
N
 
2
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
3
0
1
1
1
1
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Eﬀect of nonstationarities on detrended ﬂuctuation analysis

Zhi Chen1, Plamen Ch. Ivanov1,2, Kun Hu1, H. Eugene Stanley1
1 Center for Polymer Studies and Department of Physics, Boston University, Boston, Massachusetts 02215
2 Harvard Medical School, Beth Israel Deaconess Medical Center, Boston, Massachusetts 02215

Detrended ﬂuctuation analysis (DFA) is a scaling analysis method used to quantify long-range
power-law correlations in signals. Many physical and biological signals are “noisy”, heterogeneous
and exhibit diﬀerent types of nonstationarities, which can aﬀect the correlation properties of these
signals. We systematically study the eﬀects of three types of nonstationarities often encountered
in real data. Speciﬁcally, we consider nonstationary sequences formed in three ways: (i) stitching
together segments of data obtained from discontinuous experimental recordings, or removing some
noisy and unreliable parts from continuous recordings and stitching together the remaining parts
— a “cutting” procedure commonly used in preparing data prior to signal analysis; (ii) adding to a
signal with known correlations a tunable concentration of random outliers or spikes with diﬀerent
amplitude, and (iii) generating a signal comprised of segments with diﬀerent properties — e.g.
diﬀerent standard deviations or diﬀerent correlation exponents. We compare the diﬀerence between
the scaling results obtained for stationary correlated signals and correlated signals with these three
types of nonstationarities. We ﬁnd that introducing nonstationarities to stationary correlated signals
leads to the appearance of crossovers in the scaling behavior and we study how the characteristics
of these crossovers depend on: (a) the fraction and size of the parts cut out from the signal; (b) the
concentration of spikes and their amplitudes; (c) the proportion between segments with diﬀerent
standard deviations or diﬀerent correlations; and (d) the correlation properties of the stationary
signal. We show how to develop strategies for pre-processing “raw” data prior to analysis, which
will minimize the eﬀects of nonstationarities on the scaling properties of the data and how to interpret
the results of DFA for complex signals with diﬀerent local characteristics.

I. INTRODUCTION

In recent years, there has been growing evidence indi-
cating that many physical and biological systems have no
characteristic length scale and exhibit long-range power-
law correlations. Traditional approaches such as the
power-spectrum and correlation analysis are suited to
quantify correlations in stationary signals [1]. However,
many signals which are outputs of complex physical and
biological systems are nonstationary — the mean, stan-
dard deviation and higher moments, or the correlation
functions are not invariant under time translation [1].
Nonstationarity, an important aspect of complex variabil-
ity, can often be associated with diﬀerent trends in the
signal or heterogeneous segments (patches) with diﬀerent
local statistical properties. To address this problem, de-
trended ﬂuctuation analysis (DFA) was developed to ac-
curately quantify long-range power-law correlations em-
bedded in a nonstationary time series [2,3]. This method
provides a single quantitative parameter — the scaling
exponent α — to quantify the correlation properties of
a signal. One advantage of the DFA method is that
it allows the detection of long-range power-law correla-
tions in noisy signals with embedded polynomial trends
that can mask the true correlations in the ﬂuctuations
of a signal. The DFA method has been successfully ap-
plied to research ﬁelds such as DNA [2,4–15], cardiac
dynamics [16–36], human gait [37], meteorology [38], cli-
mate temperature ﬂuctuations [39–41], river ﬂow and dis-
charge [42,43], neural receptors in biological systems [44],

and economics [45–57]. The DFA method may also help
identify diﬀerent states of the same system with diﬀerent
scaling behavior — e.g., the scaling exponent α for heart-
beat intervals is diﬀerent for healthy and sick individuals
[26,28] as well as for waking and sleeping states [21,32].
To understand the intrinsic dynamics of a given sys-
tem, it is important to analyze and correctly interpret
its output signals. One of the common challenges is that
the scaling exponent is not always constant (indepen-
dent of scale) and crossovers often exist — i.e., the value
of the scaling exponent α diﬀers for diﬀerent ranges of
scales [16,21,28,58,59]. A crossover is usually due to
a change in the correlation properties of the signal at
diﬀerent time or space scales, though it can also be a
result of nonstationarities in the signal. A recent work
considered diﬀerent types of nonstationarities associated
with diﬀerent trends (e.g., polynomial, sinusoidal and
power-law trends) and systematically studied their eﬀect
on the scaling behavior of long-range correlated signals
[60]. Here we consider the eﬀects of three other types
of nonstationarities which are often encountered in real
data or result from “standard” data pre-processing ap-
proaches.

(i) Signals with segments removed
First we consider a type of nonstationarity caused by dis-
continuities in signals. Discontinuities may arise from the
nature of experimental recordings – e.g., stock exchange
data are not recorded during the nights, weekends and
holidays [45–52]. Alternatively, discontinuities may be
caused by the fact that some noisy and unreliable por-

1

tions of continuous recordings must be discarded, as often
occurs when analyzing physiological signals [16–36]. In
this case, a common pre–processing procedure is to cut
out the noisy, unreliable parts of the recording and stitch
together the remaining informative segments before any
statistical analysis is performed. One immediate prob-
lem is how such cutting procedure will aﬀect the scaling
properties of long-range correlated signals. A careful
consideration should be given when interpreting results
obtained from scaling analysis, so that an accurate es-
timate of the true correlation properties of the original
signal may be obtained.

(ii) Signals with random spikes
A second type of nonstationarity is due to the existence
of spikes in data, which is very common in real life sig-
nals [16–37]. Spikes may arise from external conditions
which have little to do with the intrinsic dynamics of
the system. In this case, we must distinguish the spikes
from normal intrinsic ﬂuctuations in the system’s output
and ﬁlter them out when we attempt to quantify corre-
lations. Alternatively, spikes may arise from the intrinsic
dynamics of the system, rather than being an epiphe-
nomenon of external conditions.
In this second case,
careful considerations should be given as to whether the
spikes should be ﬁltered out when estimating correla-
tions in the signal, since such “intrinsic” spikes may be
related to the properties of the noisy ﬂuctuations. Here,
we consider only the simpler case – namely, when the
spikes are independent of the ﬂuctuations in the signal.
The problem is how spikes aﬀect the scaling behavior
of correlated signals, e.g., what kind of crossovers they
may possibly cause. We also demonstrate to what ex-
tent features of the crossovers depend on the statistical
properties of the spikes. Furthermore, we show how to
recognize if a crossover indeed indicates a transition from
one type of underlying correlations to a diﬀerent type,
or if the crossover is due to spikes without any transition
in the dynamical properties of the ﬂuctuations.

(iii) Signals with diﬀerent local behavior
A third type of nonstationarity is associated with the
presence of segments in a signal which exhibit diﬀerent
local statistical properties, e.g., diﬀerent local standard
deviations or diﬀerent local correlations. Some examples
include: (a) 24 hour records of heart rate ﬂuctuations are
characterized by segments with larger standard deviation
during stress and physical activity and segments with
smaller standard deviation during rest [17]; (b) studies
of DNA show that coding and non-coding regions are
characterized by diﬀerent types of correlations [4,7]; (c)
brain wave analysis of diﬀerent sleep stages (rapid eye
movement [REM] sleep, light sleep and deep sleep) indi-
cates that the signal during each stage may have diﬀerent
correlation properties [61]; (d) heartbeat signals during
diﬀerent sleep stages exhibit diﬀerent scaling properties
[32]. For such complex signals, results from scaling anal-
It is a
ysis often reveal a very complicated structure.

challenge to quantify the correlation properties of these
signals. Here, we take a ﬁrst step toward understanding
the scaling behavior of such signals.

We study these three types of nonstationarities embed-
ded in correlated signals. We apply the DFA method to
stationary correlated signals and identical signals with
artiﬁcially imposed nonstationarities, and compare the
diﬀerence in the scaling results. (i) We ﬁnd that cutting
segments from a signal and stitching together the remain-
ing parts does not aﬀect the scaling for positively corre-
lated signals. However, this cutting procedure strongly
aﬀects anti-correlated signals, leading to a crossover from
an anti-correlated regime (at small scales) to an uncor-
related regime (at large scales). (ii) For the correlated
signals with superposed random spikes, we ﬁnd that the
scaling behavior is a superposition of the scaling of the
signal and the apparent scaling of the spikes. We analyt-
ically prove this superposition relation by introducing a
superposition rule. (iii) For the case of complex signals
comprised of segments with diﬀerent local properties, we
ﬁnd that their scaling behavior is a superposition of the
scaling of the diﬀerent components — each component
containing only the segments exhibiting identical statis-
tical properties. Thus, to obtain the scaling properties
of the signal, we need only to examine the properties of
each component — a much simpler task than analyzing
the original signal.

The layout of the paper is as follows: In Sec. II, we
describe how we generate signals with desired long-range
correlation properties and introduce the DFA method to
quantify these correlations. In Sec. III, we compare the
scaling properties of correlated signals before and after
removing some segments from the signals. In Sec. IV, we
consider the eﬀect of random spikes on correlated signals.
We show that the superposition of spikes and signals can
be explained by a superposition rule derived in Appendix
A.
In Sec. V, we study signals comprised of segments
with diﬀerent local behavior. We systematically examine
all resulting crossovers, their conditions of existence, and
their typical characteristics associated with the diﬀerent
types of nonstationarity. We summarize our ﬁndings in
Sec. VI.

II. METHOD

Using a modiﬁed Fourier ﬁltering method [62], we
generate stationary uncorrelated, correlated, and anti-
correlated signals u(i) (i = 1, 2, 3, ..., Nmax) with a stan-
dard deviation σ = 1. This method consists of the fol-
lowing steps:

(a) First, we generate an uncorrelated and Gaussian
distributed sequence η(i) and calculate the Fourier trans-
form coeﬃcients η(q).

(b) The desired signal u(i) must exhibit correlations,

which are deﬁned by the form of the power spectrum

S(q) =

u(q)u(
h

−

q)

i ∼

q−(1−γ),

(1)

2

where u(q) are the Fourier transform coeﬃcients of u(i)
and γ is the correlation exponent. Thus, we generate
u(q) using the following transformation:

u(q) = [S(q)]1/2η(q),

(2)

where S(q) is the desired power spectrum in Eq. (1).

(c) We calculate the inverse Fourier transform of u(q)

to obtain u(i).

We use the stationary correlated signal u(i) to generate
signals with diﬀerent types of nonstationarity and apply
the DFA method [2] to quantify correlations in these non-
stationary signals.

Next, we brieﬂy introduce the DFA method, which in-

volves the following steps [2]:

(i) Starting with a correlated signal u(i), where i =
1, .., Nmax and Nmax is the length of the signal, we ﬁrst
integrate the signal u(i) and obtain y(k)
u
h

], where
i
(ii) The integrated signal y(k) is divided into boxes of

is the mean.

k
i=1[u(i)

u
h

P

−

≡

i

equal length n.

(iii) In each box of length n, we ﬁt y(k), using a poly-
nomial function of order ℓ which represents the trend in
that box. The y coordinate of the ﬁt line in each box
is denoted by yn(k) (see Fig. 1, where linear ﬁt is used).
Since we use a polynomial ﬁt of order ℓ, we denote the
algorithm as DFA-ℓ.

0

100

200

300

400

500

(a)

(b)

)
i
(
u

)
k
(
y

1.2

1

0.8

0.6

0.4

2

0

−2

−4

−6

i

k

0

100

200

300

400

500

FIG. 1. (a) The correlated signal u(i). (b) The integrated
signal: y(k) =
]. The vertical dotted lines in-
u
i
dicate a box of size n = 100, the solid straight lines segments
are the estimated linear “trend” in each box by least-squares
ﬁt.

k
i=1[u(i)

− h

P

(iv) The integrated signal y(k) is detrended by sub-

tracting the local trend yn(k) in each box of length n.

(v) For a given box size n, the root mean-square
(r.m.s.) ﬂuctuation for this integrated and detrended sig-
nal is calculated:

3

F (n)

1
Nmax

Nmax

Xk=1

≡ v
u
u
t

[y(k)

yn(k)]2.

−

(3)

(vi) The above computation is repeated for a broad range
of scales (box sizes n) to provide a relationship between
F (n) and the box size n.

A power-law relation between the average root-mean-
square ﬂuctuation function F (n) and the box size n in-
nα. The ﬂuctu-
dicates the presence of scaling: F (n)
ations can be characterized by a scaling exponent α, a
self-similarity parameter which represents the long-range
power-law correlation properties of the signal. If α = 0.5,
there is no correlation and the signal is uncorrelated
(white noise); if α < 0.5, the signal is anti-correlated;
if α > 0.5, the signal is correlated [63].

∼

We note that for anti-correlated signals, the scaling
exponent obtained from the DFA method overestimates
the true correlations at small scales [60]. To avoid this
problem, one needs ﬁrst to integrate the original anti-
correlated signal and then apply the DFA method [60].
The correct scaling exponent can thus be obtained from
the relation between n and F (n)/n [instead of F (n)]. In
the following sections, we ﬁrst integrate the signals under
consideration, then apply DFA-2 to remove linear trends
in these integrated signals. In order to provide a more
accurate estimate of F (n), the largest box size n we use
is Nmax/10, where Nmax is the total number of points in
the signal.

We compare the results of the DFA method obtained
from the nonstationary signals with those obtained from
the stationary signal u(i) and examine how the scal-
ing properties of a detrended ﬂuctuation function F (n)
change when introducing diﬀerent types of nonstationar-
ities.

III. SIGNALS WITH SEGMENTS REMOVED

In this section, we study the eﬀect of nonstationar-
ity caused by removing segments of a given length from
a signal and stitching together the remaining parts —
a “cutting” procedure often used in pre-processing data
prior to analysis. To address this question, we ﬁrst gen-
erate a stationary correlated signal u(i) (see Sec. II) of
length Nmax and a scaling exponent α, using the mod-
iﬁed Fourier ﬁltering method [62]. Next, we divide this
signal into Nmax/W non-overlapping segments of size W
and randomly remove some of these segments. Finally,
we stitch together the remaining segments in the signal
u(i) [Fig. 2(a)], thus obtaining a surrogate nonstationary
signal which is characterized by three parameters: the
scaling exponent α, the segment size W and the fraction
of the signal u(i), which is removed.

(a) Signal with cutout segments

(e) Correlated signal: α>0.5, W=20

−6
−6

0
0

cutout

α=0.1

W

500
500
i

1000
1000

(b) Anti−correlated signal: α<0.5

W=20

0% cut
1% cut
5% cut
10% cut
50% cut

0.5

α=0.1

100

102

nx

104

n

(c)  W=20

α=0.1
α=0.2
α=0.3
α=0.4

(d) 10% cut

101

100

101
% cut

102

6
6

0
0

l
a
n
g
i
S

100

n
/
)
n
(
F

10−1

104

103

102

104

103

102

x
n

x
n

101

100

101

W

α=0.1
α=0.2
α=0.3
α=0.4

102

4

103

102

101

100

n
/
)
n
(
F

10−1

10−2

100

α=0.9

0% cut
1% cut
5% cut
10% cut
50% cut

α=0.7

101

102

103

104

105

n

FIG. 2. Eﬀects of the “cutting” procedure on the scaling
behavior of stationary correlated signals. Nmax = 220 is the
number of points in the signals (standard deviation σ = 1)
and W is the size of the cutout segments. (a) A stationary
signal with 10% of the points removed. The removed parts
are presented by shaded segments of size W = 20 and the
remaining parts are stitched together. (b) Scaling behavior
of nonstationary signals obtained from an anti-correlated sta-
tionary signal (scaling exponent α < 0.5) after the cutting
procedure. A crossover from anti-correlated to uncorrelated
(α = 0.5) behavior appears at scale n×. The crossover scale
n× decreases with increasing the fraction of points removed
from the signal. We determine n× based on the diﬀerence ∆
between the logarithm of F (n)/n for the original stationary
anti-correlated signal (α = 0.1) and the nonstationary signal
with cutout segments: n× is the scale at which ∆
0.04.
Dependence of the crossover scale n× on the fraction (c) and
on the size W (d) of the cutout segments for anti-correlated
signals with diﬀerent scaling exponent α. (e) Cutting proce-
dure applied to correlated signals (α > 0.5). In contrast to
(b), no discernible eﬀect on the scaling behavior is observed
for diﬀerent values of the scaling exponent α, even when up
to 50% of the points in the signals are removed.

≥

We ﬁnd that the scaling behavior of such a nonstation-
ary signal strongly depends on the scaling exponent α of
the original stationary correlated signal u(i). As illus-
trated in Fig. 2(b), for a stationary anti-correlated signal
with α = 0.1, the cutting procedure causes a crossover
in the scaling behavior of the resultant nonstationary
signal. This crossover appears even when only 1% of
the segments are cut out. At the scales larger than the
crossover scale n× the r.m.s. ﬂuctuation function behaves
n0.5, which means an uncorrelated random-
as F (n)
ness, i.e., the anti-correlation has been completely de-
stroyed in this regime. For all anti-correlated signals with
exponent α < 0.5, we observe a similar crossover behav-
ior. This result is surprising, since researchers often take
for granted that a cutting procedure before analysis does
not change the scaling properties of the original signal.
Our simulation shows that this assumption is not true,
at least for anti-correlated signals.

∼

Next, we investigate how the two parameters — the

12

0

−12
12

−12
12

0

0

101

100

−12

0

n

/
)
n
(
F

10−1

102

101

100

n
/
)
n
(
F

(a) Signal (α=0.2 σ=1)

(b) Spikes: 5%, Asp=4

l
a
n
g
i

S

(c) Signal + spikes

500
i

1000

(d)

Anti−corr. signal+spikes
Anti−corr. signal Fη(n)/n: α=0.2 
Spikes Fsp(n)/n: 5%, Asp=1
Superposition rule

10−2

100

101

104

105

α

sp=0.5
102

nx
103

n

(e) 

Correlated signal+spikes
Corr. signal Fη(n)/n: α=0.8
Spikes Fsp(n)/n: 5%, Asp=10
Superposition rule

α=0.2

α

sp=0.5

10−1

α=0.8

nx

n

100

101

102

103

104

105

segment size W and the fraction of points cut out from
the signal — control the eﬀect of the cutting procedure
on the scaling behavior of anti-correlated signals. For
the ﬁxed size of the segments (W = 20), we ﬁnd that
the crossover scale n× decreases with increasing the frac-
tion of the cutout segments [Fig. 2(c)]. Furthermore, for
anti-correlated signals with small values of the scaling ex-
ponent α, e.g., α = 0.1 and α = 0.2, we ﬁnd that n× and
the fraction of the cutout segments display an approxi-
mate power-law relationship. For a ﬁxed fraction of the
removed segments, we ﬁnd that the crossover scale n×
increases with increasing the segment size W [Fig. 2(d)].
To minimize the eﬀect of the cutting procedure on the
correlation properties, it is advantageous to cut smaller
number of segments of larger size W . Moreover, if the
segments which need to be removed are too close (e.g.,
at a distance shorter than the size of the segments), it
may be advantageous to cut out both the segments and
a part of the signal between them. This will eﬀectively
increase the size of the segment W without substantially
changing the fraction of the signal which is cut out, lead-
ing to an increase in the crossover scale n×. Such strategy
would minimize the eﬀect of this type of nonstationarity
on the scaling properties of data. For small values of
the scaling exponent α (α < 0.25), we ﬁnd that n× and
W follow power-law relationships [Fig. 2(d)]. The rea-
son we do not observe a power-law relationship between
n× and W and between n× and the fraction of cutout
segments for the values of the scaling exponent α close
to 0.5 may be due to the fact that the crossover regime
becomes broader when it separates scaling regions with
similar exponents, thus leading to uncertainty in deﬁning
n×. For a ﬁxed W and a ﬁxed fraction of the removed
segments [see Figs. 2(c) and (d)], we observe that n× in-
creases with the increasing value of the scaling exponent
α, i.e., the eﬀect of the cutting procedure on the scal-
ing behavior decreases when the anti-correlations in the
signal are weaker (α closer to 0.5).

Finally, we consider the case of correlated signals u(i)
with 1.5 > α > 0.5. Surprisingly, we ﬁnd that the scaling
of correlated signals is not aﬀected by the cutting pro-
cedure. This observation remains true independently of
the segment size W — from very small W = 5 up to very
large W = 5000 segments — even when up to 50% of the
106
segments are removed from a signal with Nmax ∼
points [Fig. 2(e)].

IV. SIGNALS WITH RANDOM SPIKES

In this section, we consider nonstationarity related to
the presence of random spikes in data and we study the
eﬀect of this type of nonstationarity on the scaling prop-
erties of correlated signals. First, we generate surrogate
nonstationary signals by adding random spikes to a sta-
tionary correlated signal u(i) [see Sec. II and Fig. 3(a-c)].

5

FIG. 3. Eﬀects of random spikes on the scaling behav-
ior of stationary correlated signals.
(a) An example of an
anti-correlated signal u(i) with scaling exponent α = 0.2,
Nmax = 220 and standard deviation σ = 1.
(b) A se-
ries of uncorrelated spikes (αsp = 0.5) at 5% randomly
chosen positions (concentration p = 0.05) and with uni-
4, 4].
formly distributed amplitudes Asp in the interval
[
−
(d)
(c) The superposition of the signals in (a) and (b).
Scaling behavior of an anti-correlated signal u(i) (α = 0.2)
with spikes (Asp = 1, p = 0.05, αsp = 0.5).
For
nα, where Fη(n)/n is
n < n×, F (n)/n
≈
For n > n×,
the scaling function of the signal u(i).
nαsp . (e) Scaling behavior of a cor-
F (n)/n
related signal u(i) (α = 0.8) with spikes (Asp = 10, p = 0.05,
nαsp .
αsp = 0.5). For n < n×, F (n)/n
≈
nα. Note that when
For n > n×, F (n)/n
α = αsp = 0.5, there is no crossover.

Fsp(n)/n

Fsp(n)/n

Fη(n)/n

Fη(n)/n

∼

≈

∼

∼

∼

≈

We ﬁnd that the correlation properties of the nonsta-
tionary signal with spikes depend on the scaling exponent
α of the stationary signal and the scaling exponent αsp
of the spikes. When uncorrelated spikes (αsp = 0.5) are
added to a correlated or anti-correlated stationary signal
[Fig 3(d) and (e)], we observe a change in the scaling be-
havior with a crossover at a characteristic scale n×. For
anti-correlated signals (α < 0.5) with random spikes, we
ﬁnd that at scales smaller than n×, the scaling behav-
ior is close to the one observed for the stationary anti-
correlated signal without spikes, while for scales larger
than n×, there is a crossover to random behavior. In the
case of correlated signals (α > 0.5) with random spikes,
we ﬁnd a diﬀerent crossover from uncorrelated behavior
at small scales, to correlated behavior at large scales with
an exponent close to the exponent of the original station-
ary correlated signal. Moreover, we ﬁnd that spikes with
a very small amplitude can cause strong crossovers in
the case of anti-correlated signals, while for correlated
signals, identical concentrations of spikes with a much
larger amplitude do not aﬀect the scaling. Based on
these ﬁndings, we conclude that uncorrelated spikes with
a suﬃciently large amplitude can aﬀect the DFA results
at large scales for signals with α < 0.5 and at small scales
for signals with α > 0.5.

To better understand the origin of this crossover be-
havior, we ﬁrst study the scaling of the spikes only [see
Fig. 3(b)]. By varying the concentration p (0
1)
and the amplitude Asp of the spikes in the signal, we
ﬁnd that for the general case when the spikes may be
correlated, the r.m.s. ﬂuctuation function behaves as

≤

≤

p

Fsp(n)/n = k0√pAspnαsp,

(4)

where k0 is a constant and αsp is the scaling exponent of
the spikes.

Next, we investigate the analytical relation between
the DFA results obtained from the original correlated sig-
nal, the spikes and the superposition of signal and spikes.
Since the original signal and the spikes are not correlated,
we can use a superposition rule (see [60] and Appendix A)

6

to derive the r.m.s. ﬂuctuation function F (n)/n for the
correlated signal with spikes:

[F (n)/n]2 = [Fη(n)/n]2 + [Fsp(n)/n]2,

(5)

where Fη(n)/n and Fsp(n)/n are the r.m.s. ﬂuctua-
tion function for the signal and the spikes, respec-
tively. To conﬁrm this theoretical result, we calculate
[Fη(n)/n]2 + [Fsp(n)/n]2 [see Figs. 3(d), (e)] and ﬁnd
this Eq. (5) is remarkably consistent with our experimen-
p
tal observations.

Using the superposition rule, we can also theoretically
predict the crossover scale n× as the intercept between
Fη(n)/n and Fsp(n)/n, i.e., where Fη(n×) = Fsp(n×).
We ﬁnd that

n× =

√pAsp

(cid:18)

k0
b0 (cid:19)

1/(α−αsp)

,

(6)

since the r.m.s. ﬂuctuation function for the signal and
the spikes are Fη(n)/n = b0nα [60] and Fsp(n)/n =
k0√pAspnαsp [Eq. (4)], respectively. This result predicts
the position of the crossover depending on the parame-
ters deﬁning the signal and the spikes.

Our result derived from the superposition rule can be
useful to distinguish two cases: (i) the correlated station-
ary signal and the spikes are independent (e.g., the case
when a correlated signal results from the intrinsic dy-
namics of the system while the spikes are due to external
perturbations); and (ii) the correlated stationary signal
and the spikes are dependent (e.g., both the signal and
the spikes arise from the intrinsic dynamics of the sys-
tem). In the latter case, the identity in the superposition
rule is not correct (see Appendix A).

V. SIGNALS WITH DIFFERENT LOCAL
BEHAVIOR

Next, we study the eﬀect of nonstationarities on com-
plex patchy signals where diﬀerent segments show diﬀer-
ent local behavior. This type of nonstationarity is very
common in real world data [4,7,17,32,61]. Our discus-
sion of signals composed of only two types of segments is
limited to two simple cases: (A) diﬀerent standard devi-
ations and (B) diﬀerent correlations.

A. Signals with diﬀerent local standard deviations

15
15
15

0
0
0

l
a
n
g
i
S

−15
−15
−15

0

(a) Signal with segments of diff. σ

σ
2=4

σ
1=1

α=0.1

W

500
i

1000

(b) Anti−correlated signal: α<0.5
% of segments with W=20, σ2=4:

0.5

100

n
/
)
n
(
F

0%
5%
30%
95%

10−1

100

103

α=0.1
102

nx
n

104

(c) Anti−correlated signal: α=0.1

95%

x
n

102

5%

0

40

20
80
% of segments with σ=4

60

100

7

103

102

101

100

n
/
)
n
(
F

(d) Correlated signal: α>0.5
% of segments with W=20, σ2=4:

0%
5%
30%
95%

α=0.9

α=0.7

10−1

100

102

n

104

local

standard deviation.

FIG. 4. Scaling behavior of nonstationary correlated
signals with diﬀerent
(a)
Anti-correlated signal (α = 0.1) with standard deviation
σ1 = 1 and ampliﬁed segments with standard deviation
σ2 = 4. The size of each segment is W = 20 and the fraction
of the ampliﬁed segments is p = 0.1 from the total length of
the signal (Nmax = 220). (b) Scaling behavior of the signal
in (a) for a diﬀerent fraction p of the ampliﬁed segments (af-
ter normalization of the globe standard deviation to unity).
A crossover from anti-correlated behavior (α = 0.1) at small
scales to random behavior (α = 0.5) at large scales is ob-
served. (c) Dependence of the crossover scale n× on the frac-
tion p of ampliﬁed segments for the signal in (a). n× is de-
termined from the diﬀerence ∆ of log10[F (n)/n] between the
nonstationary signal with ampliﬁed segments and the origi-
nal stationary signal. Here we choose ∆ = 0.04. (d) Scaling
behavior of nonstationary signals obtained from correlated
stationary signals (1 > α > 0.5) with standard deviation
σ1 = 1, for a diﬀerent fraction of the ampliﬁed segments with
σ2 = 4. No diﬀerence in the scaling is observed, compared to
the original stationary signal.

Here we consider nonstationary signals comprised of
segments with the same local scaling exponent, but dif-
ferent local standard deviations. We ﬁrst generate a sta-
tionary correlated signal u(i) (see Sec. II) with ﬁxed stan-
dard deviation σ1 = 1. Next, we divide the signal u(i)
into non-overlapping segments of size W . We then ran-
domly choose a fraction p of the segments and amplify
the standard deviation of the signal in these segments,
σ2 = 4 [Fig.4(a)]. Finally, we normalize the entire signal
to global standard deviation σ = 1 by dividing the value
of each point of the signal by

p)σ2

(1

1 + pσ2
2.

p

For nonstationary anti-correlated signals (α < 0.5)
with segments characterized by two diﬀerent values of
the standard deviation, we observe a crossover at scale
n× [Fig.4(b)]. For small scales n < n×, the behavior is
anti-correlated with an exponent equal to the scaling ex-
ponent α of the original stationary anti-correlated signal
u(i). For large scales n > n×, we ﬁnd a transition to
random behavior with exponent 0.5, indicating that the
anti-correlations have been destroyed. The dependence

−

of crossover scale n× on the fraction p of segments with
larger standard deviation is shown in Fig. 4(c). The de-
pendence is not monotonic because for p = 0 and p = 1,
the local standard deviation is constant throughout the
signal, i.e., the signal becomes stationary and thus there
is no crossover. Note the asymmetry in the value of n×
— a much smaller value of n× for p = 0.05 compared
to p = 0.95 [see Fig. 4(b-c)]. This result indicates that
very few segments with a large standard deviation (com-
pared to the rest of the signal) can have a strong eﬀect
on the anti-correlations in the signal. Surprisingly, the
same fraction of segments with a small standard devia-
tion (compared to the rest of the signal) does not aﬀect
the anti-correlations up to relatively large scales.

For nonstationary correlated signals (α > 0.5) with
segments characterized by two diﬀerent values of the
standard deviation, we surprisingly ﬁnd no diﬀerence in
the scaling of F (n)/n, compared to the stationary corre-
lated signals with constant standard deviation [Fig. 4(d)].
Moreover, this observation remains valid for diﬀerent
sizes of the segments W and for diﬀerent values of the
fraction p of segments with larger standard deviation.
We note that in the limiting case of very large values
of σ2/σ1, when the values of the signal in the segments
with standard deviation σ1 could be considered close to
“zero”, the results in Fig. 4(d) do not hold and we ob-
serve a scaling behavior similar to that of the signal in
Fig. 5(c) (see following section).

B. Signals with diﬀerent local correlations

Next we consider nonstationary signals which consist
of segments with identical standard deviation (σ = 1)
but diﬀerent correlations. We obtain such signals using
the following procedure: (1) we generate two stationary
signals u1(i) and u2(i) (see Sec. II) of identical length
Nmax and with diﬀerent correlations, characterized by
scaling exponents α1 and α2; (2) we divide the signals
u1(i) and u2(i) into non-overlapping segments of size W ;
(3) we randomly replace a fraction p of the segments in
signal u1(i) with the corresponding segments of u2(i). In
Fig. 5(a), we show an example of such a complex non-
stationary signal with diﬀerent local correlations. In this
Section, we study the behavior of the r.m.s. ﬂuctuation
function F (n)/n. We also investigate F (n)/n separately
for each component of the nonstationary signal (which
consists only of the segments with identical local corre-
lations) and suggest an approach, based on the DFA re-
sults, to recognize such complex structures in real data.

8

(a) Signal with segments of diff. α

α1=0.1

α2=0.9

W

(b) 90% component with α1=0.1

(c) 10% component with α2=0.9

500
500
i

1000
1000

(d) 

Signal with segments of diff. α, W=20
90% component with α1=0.1
10% component with α2=0.9
Superposition rule

α2=0.9

6

0

−6
6

0

−6
6
6

0
0

−6
−6

0
0

102

101

100

l
a
n
g
i
S

n
/
)
n
(
F

10−1

10−2

100

101

102

103

104

105

α1=0.1

n

FIG. 5. Scaling behavior of a nonstationary signal with two
diﬀerent scaling exponents. (a) Nonstationary signal (length
Nmax = 220, standard deviation σ = 1) which is a mixture
of correlated segments with exponent α1 = 0.1 (90% of the
signal) and segments with exponent α2 = 0.9 (10% of the
signal). The segment size is W = 20; (b) the 90% compo-
nent containing all segments with α1 = 0.1 and the remain-
ing segments (with α2 = 0.9) are replaced by zero; (c) the
10% component containing all segments with α2 = 0.9 and
the remaining segments (with α1 = 0.1) are replaced by zero;
(d) DFA results for the mixed signal in (a), for the individual
components in (b) and (c), and our prediction obtained from
the superposition rule.

In Fig. 5(d), we present the DFA result on such a non-
stationary signal, composed of segments with two diﬀer-
ent types of local correlations characterized by exponents
α1 = 0.1 and α2 = 0.9. We ﬁnd that at small scales, the
slope of F (n)/n is close to α1 and at large scales, the
slope approaches α2 with a bump in the intermediate
scale regime. This is not surprising, since α1 < α2 and
thus F (n)/n is bound to have a small slope (α1) at small
scales and a large slope (α2) at large scales. However,
it is surprising that although 90% of the signal consists
of segments with scaling exponent α1, F (n)/n deviates
10) from the behavior expected for
at small scales (n

≈

an anti-correlated signal u(i) with exponent α1 [see, e.g.,
the solid line in Fig. 2(b)]. This suggests that the be-
havior of F (n)/n for a nonstationary signal comprised of
mixed segments with diﬀerent correlations is dominated
by the segments exhibiting higher positive correlations
even in the case when their relative fraction in the signal
is small. This observation is pertinent to real data such
as: (i) heart rate recordings during sleep where diﬀerent
segments corresponding to diﬀerent sleep stages exhibit
diﬀerent types of correlations [32]; (ii) DNA sequences in-
cluding coding and non-coding regions characterized by
diﬀerent correlations [4,7,15] and (iii) brain wave signals
during diﬀerent sleep stages [61].

To better understand the complex behavior of F (n)/n
for such nonstationary signals, we study their compo-
nents separately. Each component is composed only of
those segments in the original signal which are char-
acterized by identical correlations, while the segments
with diﬀerent correlations are substituted with zeros
[see Figs. 5(b) and (c)]. Since the two components of
the nonstationary signal in Fig. 5(a) are independent,
based on the superposition rule [Eq. (5)], we expect that
the r.m.s. ﬂuctuation function F (n)/n will behave as
[F1(n)/n]2 + [F2(n)/n]2, where F1(n)/n and F2(n)/n
are the r.m.s. ﬂuctuation functions of the components in
p
Fig. 5(b) and Fig. 5(c), respectively. We ﬁnd a remark-
able agreement between the superposition rule prediction
and the result of the DFA method obtained directly from
the mixed signal [Fig 5(d)]. This ﬁnding helps us under-
stand the relation between the scaling behavior of the
mixed nonstationary signal and its components.

Information on the eﬀect of such parameters as the
scaling exponents α1 and α2, the size of the segments W
and their relative fraction p on the scaling behavior of the
components provides insight into the scaling behavior of
the original mixed signal. When the original signal comes
from real data, its composition is a priori unknown. A
ﬁrst step is to “guess” the type of correlations (exponents
α1 and α2) present in the signal, based on the scaling be-
havior of F (n)/n at small and large scales [Fig 5(d)]. A
second step is to determine the parameters W and p for
each component by matching the scaling result from the
superposition rule with the original signal. Hence in the
following subsections, we focus on the scaling properties
of the components and how they change with p, α and
W .

1. Dependence on the fraction of segments

First, we study how the correlation properties of the
components depend on the fraction p of the segments
with identical local correlations.

For

components

containing segments with anti-
correlations (0 < α < 0.5) and ﬁxed size W [Fig. 5(b)],
we ﬁnd a crossover to random behavior (α = 0.5) at large
scales, which becomes more pronounced (shift to smaller

9

≤

≤

scales) when the fraction p decreases [Fig. 6(a)]. At small
scales (n
W ), the slope of F (n)/n is identical to that
expected for a stationary signal u(i) (i.e., p = 1) with
the same anti-correlations [solid line in Fig. 6(a)]. More-
over, we observe a vertical shift in F (n)/n to lower values
when the fraction p of non-zero anti-correlated segments
decreases. We ﬁnd that at small scales after rescaling
F (n)/n by √p, all curves collapse on the curve for the
stationary anti-correlated signal u(i) [Fig. 6(a)]. Since
at small scales (n
W ) the behavior of F (n)/n does
not depend on the segment size W , this collapse indi-
cates that the vertical shift in F (n)/n is due only to the
fraction p. Thus, to determine the fraction p of anti-
correlated segments in a nonstationary signal [mixture
of anti-correlated and correlated segments, Fig. 5(a)] we
only need to estimate at small scales the vertical shift in
F (n)/n between the mixed signal [Fig. 5(d)] and a sta-
tionary signal u(i) with identical anti-correlations. This
approach is valid for nonstationary signals where the frac-
tion p of the anti-correlated segments is much larger than
the fraction of the correlated segments in the mixed sig-
nal [Fig. 5(a)], since only under this condition the anti-
correlated segments can dominate F (n)/n of the mixed
signal at small scales [Fig. 5(d)].

101

100

10−1

]

2
/
1
p
*
n
[
/
)
n
(
F

103

102

101

100

]

2
/
1

p
*
n
[
/
)
n
(
F

(a)  Components with

anti−correlated segments
α=0.1, W=20

p=1 (stationary signal)
p=0.9 
p=0.5 
p=0.1 

0.5

100

101

102

103

104

105

α=0.1

n

(b) Components with

correlated segments
α=0.9, W=20

p=1 (stationary signal)
p=0.9 
p=0.5 
p=0.1 

10−1

10−2

100

α=0.9

n

101

102

103

104

105

FIG. 6. Dependence of the scaling behavior of components
on the fraction p of the segments with identical local corre-
lations, emphasizing data collapse at small scales. The seg-
ment size is W = 20 and the length of the components is
Nmax = 220. (a) Components containing anti-correlated seg-
ments (α = 0.1), at small scales (n
W ). The slope of
F (n)/n is identical to that expected for a stationary (p = 1)
signal with the same anti-correlations. After rescaling F (n)/n
by √p, at small scales all curves collapse on the curve for the
stationary anti-correlated signal. (b) Components containing
correlated segments (α = 0.9), at small scales (n
W ). The
slope of F (n)/n is identical to that expected for a stationary
(p = 1) signal with the same correlations. After rescaling
F (n)/n by √p, at small scales all curves collapse on the curve
for the stationary correlated signal.

≤

≤

≤

For components containing segments with positive cor-
relations (0.5 < α < 1) and ﬁxed size W [Fig. 5(c)], we
observe a similar behavior for F (n)/n, with collapse at
small scales (n
W ) after rescaling by √p [Fig. 6(b)]
(For α > 1, there are exceptions with diﬀerent rescaling
factors, see Appendix B). At small scales the values of
F (n)/n for components containing segments with posi-
tive correlations are much larger compared to the values
of F (n)/n for components containing an identical frac-
tion p of anti-correlated segments [Fig. 6(a)]. Thus, for
a mixed signal where the fraction of correlated segments
is not too small (e.g., p
0.2), the contribution at small
scales of the anti-correlated segments to F (n)/n of the
mixed signal [Fig. 5(d)] may not be observed, and the
behavior (values and slope) of F (n)/n will be dominated
by the correlated segments. In this case, we must con-
sider the behavior of F (n)/n of the mixed signal at large
scales only, since the contribution of the anti-correlated
segments at large scales is negligible. Hence, we next
study the scaling behavior of components with correlated
segments at large scales.

≥

For components containing segments with positive cor-
relations and ﬁxed size W [Fig. 5(c)], we ﬁnd that at large
scales the slope of F (n)/n is identical to that expected
for a stationary signal u(i) (i.e., p = 1) with the same
correlations [solid line in Fig. 7(a)]. We also observe a
vertical shift in F (n)/n to lower values when the frac-
tion p of non-zero correlated segments in the component
decreases. We ﬁnd that after rescaling F (n)/n by p, at
large scales all curves collapse on the curve representing
the stationary correlated signal u(i) [Fig. 7(a)]. Since at
large scales (n
W ), the eﬀect of the zero segments
of size W on the r.m.s. ﬂuctuation function F (n)/n for
components with correlated segments is negligible, even
when the zero segments are 50% of the component [see
Fig. 7(a)], the ﬁnding of a collapse at large scales indi-
cates that the vertical shift in F (n)/n is only due to the
fraction p of the correlated segments. Thus, to deter-
mine the fraction p of correlated segments in a nonsta-
tionary signal (which is a mixture of anti-correlated and
correlated segments [Fig. 5(a)]), we only need to estimate
at large scales the vertical shift in F (n)/n between the

≫

mixed signal [Fig. 5(d)] and a stationary signal u(i) with
identical correlations.

(a) Components with

correlated segments
α=0.9, W=20

p=1 (stationary signal)
p=0.9 
p=0.5 
p=0.1 

α=0.9

101

102

103

104

105

n

(b)  Components with

anti−correlated segments
α=0.1, W=20
p=0.96 
p=0.84 
p=0.36 

0.5

)
p
*
n
(
/
)
n
(
F

10−1

10−2

100

103

102

101

100

101

100

]

2
/
1

)
)
p
−
1
(
p
(
*
n
[
/
)
n
(
F

10−1

100

101

102

104

105

106

103
n

FIG. 7. Dependence of scaling behavior of components on
the fraction p of the segments with identical local correlations,
emphasizing data collapse at large scales. The segment size
is W = 20 and the length of the components is Nmax = 220.
(a) Components containing correlated segments (α = 0.9), at
large scales (n
W ). The slope of F (n)/n is identical to that
expected for a stationary (p = 1) signal with the same corre-
lations. After rescaling F (n)/n by p, at large scales all curves
collapse on the curve for the stationary correlated signal. (b)
Components containing anti-correlated segments (α = 0.1),
at large scales (n
W ). There is a crossover to random be-
havior (α = 0.5). After rescaling F (n)/n by
p), all
curves collapse at large scales.

p(1

≫

≫

−

p

For

components

containing segments with anti-
correlations and ﬁxed size W [Fig. 5(b)], we ﬁnd that
at large scales in order to collapse the F (n)/n curves
W ) [Fig. 6(a)] we need to rescale F (n)/n by
(n
p) [see Fig. 7(b)]. Note that there is a diﬀerence
between the rescaling factors for components with anti-
p
correlated and correlated segments at small [Figs. 6(a-
b)] and large [Figs. 7(a-b)] scales. We also note that

≫
p(1

−

10

p(1

for components with correlated segments (α > 0.5) and
suﬃciently small p, there is a diﬀerent rescaling factor
p) in the intermediate scale regime [see Ap-
of
−
pendix B, Fig. 10].

p
For components containing segments of white noise
(α = 0.5), we ﬁnd no change in the scaling exponent as
a function of the fraction p of the segments, i.e., α = 0.5
for the components at both small and large scales. How-
ever, we observe at all scales a vertical shift in F (n)/n
to lower values with decreasing p: F (n)/n

√p.

∼

102

101

100

n

/
)
n
(
F

(b) Components with

correlated segments
α=0.9, p=0.1
W=200
W=20
W=2

10−1

α=0.9

α=0.9

10−2

100

101

102

103

104

105

0.5

n

FIG. 8. Dependence of the scaling behavior of compo-
nents on the segment size W . The fraction p = 0.1 of the
non-zero segments is ﬁxed and the length of the components
is Nmax = 220. (a) Components containing anti-correlated
segments (α = 0.1). At large scales (n
W ), there is a
crossover to random behavior (α = 0.5). An equidistant ver-
tical shift in F (n)/n when W decreases by a factor of ten
suggests a power-law relation between F (n)/n and W . (b)
Components containing correlated segments (α = 0.9). At
intermediate scales, F (n)/n has slope α = 0.5, indicating
random behavior. An equidistant vertical shift in F (n)/n
suggests a power-law relation between F (n)/n and W .

≫

For components containing correlated segments with a
ﬁxed value of the fraction p we ﬁnd that in the intermedi-
ate scale regime, the segment size W plays an important
role in the scaling behavior of F (n)/n [Fig. 8(b)]. We
ﬁrst focus on the intermediate scale regime when both
p = 0.1 and W = 20 are ﬁxed [middle curve in Fig. 8(b)].
We ﬁnd that for a small fraction p of the correlated seg-
ments, F (n)/n has slope α = 0.5, indicating random
behavior [Fig. 8(b)] which shrinks when p increases [see
Appendix B, Fig. 10]. Thus, for components contain-
ing correlated segments, F (n)/n approximates at large
and small scales the behavior of a stationary signal with
identical correlations (α = 0.9), while in the intermediate
scale regime there is a plateau of random behavior due
to the random “jumps” at the borders between the non-
zero and zero segments [Fig. 5(c)]. Next, we consider the
case when the fraction of correlated segments p is ﬁxed
while the segment size W changes. We ﬁnd a vertical
shift with increasing values for F (n)/n when W increases
[Fig. 8(b)], opposite to what we observe for components
with anti-correlated segments [Fig. 8(a)]. Since the verti-
cal shift in F (n)/n is equidistant when W increases by a
factor of ten, our ﬁnding indicates a power-law relation-
ship between F (n)/n and W .

2. Dependence on the size of segments

Next, we study how the scaling behavior of the com-

ponents depends on the size of the segments W .

First, we consider components containing segments
with anti-correlations. For a ﬁxed value of the fraction p
of the segments, we study how F (n)/n changes with W .
At small scales, we observe a behavior with a slope sim-
ilar to the one for a stationary signal u(i) with identical
anti-correlations [Fig. 8(a)]. At large scales, we observe
a crossover to random behavior (exponent α = 0.5) with
an increasing crossover scale when W increases. At large
scales, we also ﬁnd a vertical shift with increasing values
for F (n)/n when W decreases [Fig. 8(a)]. Moreover, we
ﬁnd that there is an equidistant vertical shift in F (n)/n
when W decreases by a factor of ten, suggesting a power-
law relation between F (n)/n and W at large scales.

101

100

n
/
)
n
(
F

10−1

(a) Components with

anti−correlated segments
α=0.1, p=0.1
W=200
W=20
W=2

0.5

10−2

α=0.1

100

101

102

103

104

105

n

11

3. Scaling Expressions

To better understand the complexity in the scaling be-
havior of components with correlated and anti-correlated
segments at diﬀerent scales, we employ the superposition
rule (see [60] and Appendix A). For each component we
have

F (n)/n =

[Fcorr(n)/n]2 + [Frand(n)/n]2,

(7)

p

where Fcorr(n)/n accounts for the contribution of the
correlated or anti-correlated non-zero segments, and
Frand(n)/n accounts for the randomness due to “jumps”
at the borders between non-zero and zero segments in
the component.

Components with correlated segments (α > 0.5)

At small scales n < W , our ﬁndings presented in Fig. 6(b)
suggest that there is no substantial contribution from
Frand(n)/n. Thus from Eq. (7),

F (n)/n

Fcorr(n)/n

b0√pnα,

≈

∼

(8)

where b0nα is the r.m.s. ﬂuctuation function for station-
ary (p = 1) correlated signals [Eq. 6 and [60]].

Similarly, at large scales n

W , we ﬁnd that the con-
tribution of Frand(n)/n is negligible [see Fig. 7(a)], thus
from Eq. (7) we have

≫

F (n)/n

Fcorr(n)/n

≈

b0pnα.

∼

(9)

However, in the intermediate scale regime, the contribu-
tion of Frand(n)/n to F (n)/n is substantial. To conﬁrm
this we use the superposition rule [Eq. (7)] and our esti-
mates for Fcorr(n)/n at small [Eq. (8)] and large [Eq. (9)]
scales [64]. The result we obtain from

Frand(n)/n =

[F (n)/n]2

[b0√pnα]2

[b0pnα]2 (10)

−

−

q

(a) Component: α=0.9, p=0.1, W=20

component: F(n)/n
randomness term: Frand(n)/n)
correlation term: Fcorr(n)/n

α=0.9

0.5

α=0.9

101

102

103

104

105

n

Frand(W1=400) /Frand(W2=20)
Frand(α)/Frand(α=0.5), W=20

p=0.1

102

101

100

10−1

10−2

n
/
)
n
(
F

10−3

100

10

(b) 

1

0

0.5

1

1.5

α

FIG. 9.

(a) Scaling behavior of components contain-
ing correlated segments (α > 0.5). F (n)/n exhibits two
intermedi-
crossovers and three scaling regimes at small,
ate and large scales. From the superposition rule [Eq. (7)]
we ﬁnd that the small and large scale regimes are con-
trolled by the correlations (α = 0.9) in the segments
[Fcorr(n)/n from Eqs. (8) and (9)] while the intermediate
n0.5 from Eq. (10)] is dominated by
regime [Frand(n)/n
the random jumps at the borders between non-zero and zero
segments. (b) The ratio Frand(W1 = 400)/Frand(W2 = 20)
in the intermediate scale regime for ﬁxed p and diﬀerent val-
ues of α, and the ratio Frand(α)/Frand(α = 0.5) for ﬁxed p
and W = W1/W2. Frand(n)/n is obtained from Eq. (10) and
the ratios are estimated for all scales n in the intermediate
regime. The two curves overlap for a broad range of values
for the exponent α, suggesting that Frand(n)/n does not de-
pend on h(α) [see Eqs. (11) and (16)].

∼

overlaps with F (n)/n in the intermediate scale regime,
n0.5 [Fig. 9(a)].
exhibiting a slope of
Thus, Frand(n)/n is indeed a contribution due to the
random jumps between the non-zero correlated segments
and the zero segments in the component [see Fig. 5(c)].

0.5: Frand(n)/n

∼

≈

Further, our results in Fig. 8(b) suggest that in the
W gc(α) for ﬁxed
intermediate scale regime F (n)/n
fraction p [see Sec. V B 2], where the power-law expo-
nent gc(α) may be a function of the scaling exponent α
characterizing the correlations in the non-zero segments.

∼

12

F (n)/n

Since at intermediate scales Frand(n)/n dominates the
scaling [Eq. (10) and Fig. 9(a)], from Eq. (7) we ﬁnd
W gc(α). We also ﬁnd that at in-
Frand(n)/n
≈
p) for ﬁxed segment
termediate scales, F (n)/n
∼
size W (see Appendix B, Fig. 10). Thus from Eq. (7) we
ﬁnd Frand(n)/n
p). Hence we ob-
p(1
≈
tain the following general expression

p
∼

F (n)/n

p(1

−

∼

−

Frand(n)/n

h(α)

p(1

p)W gc(α)n0.5.

(11)

p

−

∼

p

Here we assume that Frand(n)/n also depends directly
on the type of correlations in the segments through some
function h(α).

To determine the form of gc(α) in Eq. (11), we perform

the following steps:
(a) We ﬁx the values of p and α, and from Eq. (10) we
calculate the value of Frand(n)/n for two diﬀerent values
of the segment size W , e.g., we choose W1 = 400 and
W2 = 20.
(b) From the expression in Eq. (11), at the same scale n
in the intermediate scale regime we determine the ratio:

Frand(W1)/Frand(W2) = (W1/W2)gc(α).

(12)

(c) We plot Frand(W1)/Frand(W2) vs. α on a linear-log
scale [Fig. 9(b)]. From the graph and Eq. (12) we obtain
the dependence

gc(α) =

log[Frand(W1)/Frand(W2)]
log(W1/W2)
Cα
C/2, 0.5
0.50, for α > 1,

−

≤

≤

α

1

(13)

where C = 0.87

0.06. Note that gc(0.5) = 0.

To determine if Frand(n)/n depends on h(α) in

Eq. (11), we perform the following steps:
(a) We ﬁx the values of p and W and calculate the value
of Frand(n)/n for two diﬀerent values of the scaling expo-
nent α, e.g., 0.5 and any other value of α from Eq. (10).
(b) From the expression in Eq. (11), at the same scale n
in the intermediate scale regime we determine the ratio:

Frand(α)
Frand(0.5)

=

h(α)
h(0.5)

W gc(α)−gc(0.5) =

W gc(α), (14)

h(α)
h(0.5)

since gc(0.5) = 0 from Eq. (13).
(c) We plot Frand(α)/Frand(0.5) vs. α on a linear-log scale
[Fig. 9(b)] and ﬁnd that when W
W1/W2 [in Eqs. (12)
and (14)] this curve overlaps with Frand(W1)/Frand(W2)
vs. α [Fig. 9(b)] for all values of the scaling exponent
1.5. From this overlap and from Eqs. (12)
0.5
≤
and (14), we obtain

≡

≤

α

W gc(α) =

W gc(α)

h(α)
h(0.5)

(15)

for every value of α, suggesting that h(α) = const and
thus Frand(n)/n can ﬁnally be expressed as:

=

(cid:26)

±

Frand(n)/n

p(1

p)W gc(α)n0.5.

(16)

∼

p

−

Components with anti-correlated segments (α < 0.5)

Our results in Fig. 6(a) suggest that at small scales
n < W there is no substantial contribution of Frand(n)/n
and that:

F (n)/n

Fcorr(n)/n

b0√pnα,

≈

∼

(17)

a behavior similar to the one we ﬁnd for components with
correlated segments [Eq. (8)].

In the intermediate and large scale regimes (n

W ),
from the plots in Fig. 7(b) and Fig. 8(a) we ﬁnd the scal-
ing behavior of F (n)/n is controlled by Frand(n)/n and
thus

≥

F (n)/n

Frand(n)/n

≈

∼

p

−

p(1

p)W ga(α)n0.5,

(18)

where ga(α) = Cα
C/2 for 0 < α < 0.5 [see Fig. 9(b)]
and the relation for Frand(n)/n is obtained using the same
procedure we followed for Eq. (16).

−

VI. CONCLUSIONS

In this paper we studied the eﬀects of three diﬀerent
types of nonstationarities using the DFA correlation anal-
ysis method. Speciﬁcally, we consider sequences formed
in three ways: (i) stitching together segments of signals
obtained from discontinuous experimental recordings, or
removing some noisy and unreliable segments from con-
tinuous recordings and stitching together the remaining
parts; (ii) adding random outliers or spikes to a signal
with known correlations, and (iii) generating a signal
composed of segments with diﬀerent properties — e.g.
diﬀerent standard deviations or diﬀerent correlations.
We compare the diﬀerence between the scaling results
obtained for stationary correlated signals and for corre-
lated signals with artiﬁcially imposed nonstationarities.

≥

(i) We ﬁnd that removing segments from a signal
and stitching together the remaining parts does not af-
fect the scaling behavior of positively correlated signals
α > 0.5), even when up to 50% of the points
(1.5
in these signals are removed. However, such a cutting
procedure strongly aﬀects anti-correlated signals, lead-
ing to a crossover from an anti-correlated regime (at
small scales) to an uncorrelated regime (at large scales).
The crossover scale n× increases with increasing value of
the scaling exponent α for the original stationary anti-
correlated signal. It also depends both on the segment
size and the fraction of the points cut out from the sig-
nal: (1) n× decreases with increasing fraction of cutout
segments, and (2) n× increases with increasing segment
size. Based on our ﬁndings, we propose an approach to

13

minimize the eﬀect of cutting procedure on the correla-
tion properties of a signal: When two segments which
need to be removed are on distances shorter than the
size of the segment, it is advantageous to cut out both
the segments and the part of the signal between them.

(ii) Signals with superposed random spikes. We ﬁnd
that for an anti-correlated signal with superposed spikes
at small scales, the scaling behavior is close to that of the
stationary anti-correlated signal without spikes. At large
scales, there is a crossover to random behavior. For a
correlated signal with spikes, we ﬁnd a diﬀerent crossover
from uncorrelated behavior at small scales to correlated
behavior at large scales with an exponent close to the
exponent of the original stationary signal. We also ﬁnd
that the spikes with identical density and amplitude may
cause strong eﬀect on the scaling of an anti-correlated
signal while they have a much smaller or no eﬀect on
the scaling of a correlated signal — when the two sig-
nals have the same standard deviations. We investigate
the characteristics of the scaling of the spikes only and
ﬁnd that the scaling behavior of the signal with random
spikes is a superposition of the scaling of the signal and
the scaling of the spikes. We analytically prove this su-
perposition relation by introducing a superposition rule.

(iii) Signals composed of segments with diﬀerent local

properties. We ﬁnd that

(a) For nonstationary correlated signals comprised of
segments which are characterized by two diﬀerent values
of the standard deviation, there is no diﬀerence in the
scaling behavior compared to stationary correlated sig-
nals with constant standard deviation. For nonstation-
ary anti-correlated signals, we ﬁnd a crossover at scale
n×. For small scales n < n×, the scaling behavior is sim-
ilar to that of the stationary anti-correlated signals with
constant standard deviation. For large scales n > n×,
there is a transition to random behavior. We also ﬁnd
that very few segments with large standard deviation can
strongly aﬀect the anti-correlations in the signal. In con-
trast, the same fraction of segments with standard devi-
ation smaller than the standard deviation of the rest of
the anti-correlated signal has much weaker eﬀect on the
scaling behavior — n× is shifted to larger scales.

(b) For nonstationary signals consisting of segments
with diﬀerent correlations, the scaling behavior is a su-
perposition of the scaling of the diﬀerent components
— where each component contains only the segments
exhibiting identical correlations and the remaining seg-
ments are replaced by zero. Based on our ﬁndings, we
propose an approach to identify the composition of such
complex signals: A ﬁrst step is to “guess” the type of cor-
relations from the DFA results at small and large scales.
A second step is to determine the parameters deﬁning the
components, such as the segment size and the fraction of
non-zero segments. We studied how the scaling charac-
teristics of the components depend on these parameters
and provide analytic scaling expressions.

ACKNOWLEDGMENTS

We thank NIH/National Center for Research Re-
sources (Grant No. P41RR13622) and NSF for sup-
port. We also thank Jan W. Kantelhardt for reading
the manuscript and for helpful suggestions.

APPENDIX A: SUPERPOSITION RULE

Here we show how the DFA results for any two signals
f and g [denoted as Ff (n) and Fg(n)] relate with the DFA
result for the sum of these two signals f + g [denoted as
Ff +g(n), where n is the box length (scale of analysis)].
Ff + Fg.
Ff −
In the general cases, we ﬁnd
Fg| ≤
|
When the two signals are not correlated, we ﬁnd that the
following superposition rule is valid: F 2
f + F 2
g .
Here we derive these relations.

Ff +g ≤
f +g = F 2

First we summarize again the procedure of the DFA
method [2]. It includes the following steps: starting with
an original signal u(i) of length Nmax, we integrate and

k

i

u

− h

u
h

(u(j)

j=1
P

obtain y(k) =

is the mean of

), where
i
u(i). Next, we divide y(k) into non-overlapping boxes of
equal length n. In each box we ﬁt the signal y(k) using a
polynomial function yn(k) = a0 + a1x(k) + a2x2(k) + ... +
asxs(k), where x(k) is the x coordinate corresponding to
the kth signal point. We calculate the r.m.s. ﬂuctuation
Nmax

function F (n) =

1
Nmax

s

[y(k)

yn(k)]2.

−

k=1
P
To prove the superposition rule, we ﬁrst focus on one
particular box along the signal. In order to ﬁnd the an-
alytic expression of best ﬁt in this box, we write

I(a0, ..., as) =

[y(k)

(a0 + ... + asxs(k))]2,

(A1)

−

where am, m = 0, ..., s are the same for all points in this
box. “Best ﬁt” requires that am, m = 0, ..., s satisfy

= 0, m = 0, ...s

(A2)

n

Xk=1

∂I
∂am

Combining Eq. (A1) with (A2) we obtain s + 1 equations

ym = a0tm0 + a1tm1... + astms, m = 0, ..., s

(A3)

ym =

y(k)xm(k), tmj =

xm+j(k), j = 0, ..., s (A4)

n

Xk=1

From Eqs. (A3) we determine a0, a1, .., as.
For the signals f , g and f + g after the integration, in

each box we have

where

n

Xk=1

14

fm = a0tm0 + a1tm1... + astms, m = 0, ..., s
1tm1... + a′
gm = a′
stms, m = 0, ..., s
(f + g)m = a

0tm0 + a′

′′
1 tm1... + a

′′
0 tm0 + a

′′
s tms, m = 0, ..., s (A5)

where fm, gm and (f +g)m correspond to ym in Eqs. (A3).
Comparing the three groups of equations in Eqs. (A5),
we ﬁnd that, when we add the ﬁrst two groups together,
the left side becomes fm + gm = (f + g)m , which is pre-
cisely the left side of the third group of equations. Thus
we ﬁnd

a′′
m = am + a′

m, m = 0, ..., s

(A6)

and for each point k in every box, the polynomial ﬁts for
the signals f , g and f + g satisfy

(f + g)n(k) = fn(k) + gn(k).

(A7)

This result can be extended to all boxes in the signals.
For the signal f + g we obtain

Nmax

Xk=1
−

F 2

f +g =

1
Nmax

[f (k)

fn(k)]2 + [g(k)

gn(k)]2

−

−

+2[f (k)

fn(k)][g(k)

gn(k)].

(A8)

−

After the substitutions f (k)
gn(k) = Yg(k), we rewrite the above equation as

fn(k) = Yf (k) and g(k)

−

−

F 2

f +g =

1
Nmax

Nmax

Nmax

(Yf (k))2 +

(Yg(k))2

h
Nmax

Xk=1

Xk=1

+2

Xk=1
f + F 2

g +

= F 2

Yf (k)Yg(k)
i
Nmax

2
Nmax

Xk=1

Yf (k)Yg(k).

(A9)

In the general case, we can utilize the Cauchy inequal-

ity

Nmax

Yf (k)Yg(k)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(Yf (k))2
!

Nmax

Xk=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
≤  

Xk=1
and we ﬁnd

1/2

Nmax

1/2

(Yg(k))2

!

 

Xk=1

(A10)

F 2
Fg)2
f +g ≤
≤
Ff +g ≤
Fg| ≤
From Eqs. (A3) for m = 0, in every box we have

(Ff −
Ff −

(Ff + Fg)2

Ff + Fg.

(A11)

⇒ |

=

y(k) =

yn(k). Thus we obtain

Yf (k) =

Nmax

k=1
P

Yg(k) = 0 where Yf (k) and Yg(k) ﬂuctuate around

n

k=1
P

n

k=1
Nmax
P

k=1
P

15

zero. When Yf (k) and Yg(k) are not correlated, the value
of the third term in Eq. (A9) is close to zero and we ob-
tain the following superposition rule
F 2
f +g = F 2

f + F 2
g .

(A12)

APPENDIX B: STRONGLY CORRELATED
SEGMENTS

For components containing segments with stronger
positive correlations (α > 1 ) and ﬁxed W = 20, we
ﬁnd that at small scales (n < W ), the slope of F (n)/n
does not depend on the fraction p and is close to that
expected for a stationary signal u(i) with identical cor-
relations (Fig. 10). Surprisingly we ﬁnd that in order to
collapse the F (n)/n curves obtained for diﬀerent values
p)
of the fraction p, we need to rescale F (n)/n by
instead of √p, which is the rescaling factor at small
scales for components containing segments with corre-
lations α < 1. Thus α = 1 is a threshold indicating
when the rescaling factor changes. Our simulations show
that this threshold increases when the segment size W
increases.

p(1

p

−

For components containing a suﬃciently small fraction
p of correlated segments (α > 0.5), we ﬁnd that in the
intermediate scale regime there is a crossover to random
behavior with slope 0.5. The F (n)/n curves obtained
for diﬀerent values of p collapse in the intermediate scale
regime if we rescale F (n)/n by
p) (Fig. 10). We
note that this random behavior regime at intermediate
scales shrinks with increasing the fraction p of correlated
segments and, as expected, for p close to 1 this regime
disappears (see the p = 0.9 curve in Fig. 10).

p(1

p

−

103

101

Components with
correlated segments
α=1.2, W=20
p=0.9
p=0.5 
p=0.1 

1.2

10−1

]

2
/
1

)
)
p
−
1
(
p
(
*
n
[
/
)
n
(
F

0.5

n

10−3

100

101

102

103

104

105

FIG. 10. Dependence of the scaling behavior of compo-
nents on the fraction p of the segments with strong positive
correlations (α = 1.2). The segment size is W = 20 and
the length of the components is Nmax = 220. After rescal-
ing F (n)/n by
p), all curves collapse at small scales
(n < W ) with slope 1.2 and at intermediate scales with slope
0.5. The intermediate scale regime shrinks when p increases.

p(1

p

−

[1] R.L. Stratonovich, Topics in the Theory of Random

Noise Vol. 1 (Gordon & Breach, New York, 1981).

[2] C.-K. Peng, S.V. Buldyrev, S. Havlin, M. Simons, H.E.
Stanley, and A.L. Goldberger, Phys. Rev. E 49, 1685
(1994).

[3] M.S. Taqqu, V. Teverovsky, and W. Willinger, Fractals

3, 785 (1995).

[4] C.-K. Peng, S.V. Buldyrev, A.L. Goldberger, S. Havlin,
F. Sciortino, M. Simons, and H.E. Stanley, Nature (Lon-
don) 356, 168 (1992).

[5] C.-K. Peng, S.V. Buldyrev, A.L. Goldberger, S. Havlin,
M. Simons, and H.E. Stanley, Phys. Rev. E 47, 3730
(1993).

[6] S.V. Buldyrev, A.L. Goldberger, S. Havlin, C.-K. Peng,
H.E. Stanley, and M. Simons, Biophys. J. 65, 2673
(1993).

[7] S.M. Ossadnik, S.B. Buldyrev, A.L. Goldberger, S.
Havlin, R.N. Mantegna, C.-K. Peng, M. Simons, and
H.E. Stanley, Biophys. J. 67, 64 (1994).

[8] H.E. Stanley, S.V. Buldyrev, A.L. Goldberger, S. Havlin,
R.N. Mantegna, C.-K. Peng, and M. Simons, Nuovo Ci-
mento D 16, 1339 (1994).

[9] R.N. Mantegna, S.V. Buldyrev, A.L. Goldberger, S.
Havlin, C.-K. Peng, M. Simons, and H.E. Stanley, Phys.
Rev. Lett. 73, 3169 (1994).

[10] S. Havlin, S.V. Buldyrev, A.L. Goldberger, S.M. Ossad-
niksm, C.-K. Peng, M. Simons, and H.E. Stanley, Chaos,
Soliton Fractals 6, 171 (1995).

[11] C.-K. Peng, S.V. Buldyrev, A.L. Goldberger, S. Havlin,
R.N. Mantegna, M. Simons, and H.E. Stanley, Physica
A 221, 180 (1995).

[12] S. Havlin, S.V. Buldyrev, A.L. Goldberger, R.N. Man-
tegna, C.-K. Peng, M. Simons, and H.E. Stanley, Fractals
3, 269 (1995).

[13] R.N. Mantegna, S.V. Buldyrev, A.L. Goldberger, S.
Havlin, C.-K. Peng, M. Simons, and H.E. Stanley, Phys.
Rev. Lett. 76, 1979 (1996).

[14] S.V. Buldyrev, N.V. Dokholyan, A.L. Goldberger,
S. Havlin, C.-K. Peng, H.E. Stanley and G.M.
Viswanathan, Physica A 249, 430 (1998).

[15] H.E. Stanley, S.V. Buldyrev, A.L. Goldberger, S. Havlin,
C.-K. Peng and M. Simons, Physica A 273, 1 (1999).
[16] N. Iyengar, C.-K. Peng, R. Morin, A.L. Goldberger, and

L.A. Lipsitz, Am. J. Physiol. 40, R1078 (1996).

[17] P.Ch. Ivanov, M.G. Rosenblum, C.-K. Peng, J.E. Mietus,
S. Havlin, H.E. Stanley, and A.L. Goldberger, Nature
(London) 383, 323 (1996).

[18] K.K.L. Ho, G.B. Moody, C.-K. Peng, J.E. Mietus, M.G.
Larson, D. Levy, and A.L. Goldberger, Circulation 96,
842 (1997).

[19] P.Ch. Ivanov, M.G. Rosenblum, C.-K. Peng, J.E. Mietus,
S. Havlin, H.E. Stanley, and A.L. Goldberger, Physica A
249, 587 (1998).

[20] M. Barbi, S. Chillemi, A. Di Garbo, R. Balocchi, C.
Carpeggiani, M. Emdin, C. Michelassi, and E. Santar-

cangelo, Chaos, Solitions Fractals 9, 507 (1998).

[21] P.Ch. Ivanov, A. Bunde, L.A. Nunes Amaral, S. Havlin,
J. Fritsch-Yelle, R.M. Baevsky, H.E. Stanley, and A.L.
Goldberger, Europhys. Lett. 48, 594 (1999).

[22] S.M. Pikkujamsa, T.H. Makikallio, L.B. Sourander, I.J.
Raiha, P. Puukka, J. Skytta, C.-K. Peng, A.L. Gold-
berger, and H.V. Huikuri, Circulation 100, 393 (1999).

[23] P.Ch. Ivanov, L.A. Nunes Amaral, A.L. Goldberger, S.
Havlin, M.G. Rosenblum, Z.R. Struzik, and H.E. Stanley,
Nature (London) 399, 461 (1999).

[24] S. Havlin, S.V. Buldyrev, A. Bunde, A.L. Goldberger,
P.Ch. Ivanov, C.-K. Peng, and H.E. Stanley, Physica A
273, 46 (1999).

[25] H.E. Stanley, L.A. Nunes Amaral, A.L. Goldberger, S.
Havlin, P.Ch. Ivanov, and C.-K. Peng, Physica A 270,
309 (1999).

[26] Y. Ashkenazy, M. Lewkowicz, J. Levitan, S. Havlin, K.
Saermark, H. Moelgaard, and P.E.B. Thomsen, Fractals
7, 85 (1999).

[27] T.H. Makikallio, J. Koistinen, L. Jordaens, M.P. Tulppo,
N. Wood, B. Golosarsky, C.-K. Peng, A.L. Goldberger,
and H.V. Huikuri, Am. J. Cardiol. 83, 880 (1999).
[28] C.-K. Peng, S. Havlin, H.E. Stanley, and A.L. Gold-

[29] P.A. Absil, R. Sepulchre, A. Bilge, and P. Gerard, Phys-

berger, Chaos 5, 82 (1995).

ica A 272, 235 (1999).

[30] S. Havlin, L.A. Nunes Amaral, A.L. Goldberger, P.Ch.
Ivanov, C.-K. Peng, and H.E. Stanley, Physica A 274,
99 (1999).

[31] D. Toweill, K. Sonnenthal, B. Kimberly, S. Lai, and B.

Goldstein, Crit. Care Med. 28, 2051 (2000).

[32] A. Bunde, S. Havlin, J.W. Kantelhardt, T. Penzel, J.H.

Peter, and K. Voigt, Phys. Rev. Lett. 85, 3736 (2000).

[33] T.T. Laitio, H.V. Huikuri, E.S.H. Kentala, T.H.
Makikallio, J.R. Jalonen, H. Helenius, K. Sariola-
Heinonen, S. Yli-Mayry, and H. Scheinin, Anesthesiology
93, 69 (2000).

[34] Y. Ashkenazy, P.Ch. Ivanov, S. Havlin, C.-K. Peng, Y.
Yamamoto, A.L. Goldberger, and H.E. Stanley, Comput-
ers in Cardiology 27, 139 (2000).

[35] Y. Ashkenazy, P.Ch. Ivanov, S. Havlin, C.-K. Peng, A.L.
Goldberger, and H.E. Stanley, Phys. Rev. Lett. 86, 1900
(2001).

[36] P.Ch. Ivanov, L.A. Nunes Amaral, A.L. Goldberger,
M.G. Rosenblum, H.E. Stanley, and Z.R. Struzik, Chaos
11, 641 (2001).

[37] J.M. Hausdorﬀ, C.-K. Peng, Z. Ladin, J. Wei and A.L.

Goldberger, J. Applied Physiol. 78, 349 (1995).

[38] K. Ivanova and M. Ausloos, Physica A 274, 349 (1999).
[39] E. Koscielny-Bunde, A. Bunde, S. Havlin, H.E. Ro-
man, Y. Goldreich, and H.J. Schellnhuber, Phys. Rev.
Lett. 81, 729 (1998).

[40] E. Koscielny-Bunde, H.E. Roman, A. Bunde, S. Havlin,
and H.J. Schellnhuber, Philos. Mag. B 77, 1331 (1998).
[41] P. Talkner and R.O. Weber, Phys. Rev. E 62, 150

(2000).

[42] A. Montanari, R. Rosso, and M.S. Taqqu, Water Resour.

Res. 36, (5) 1249 (2000).

[43] C. Matsoukas, S.

Islam, and I. Rodriguez-Iturbe, J.

Geophys. Res., [Atmos.] 105, 29165 (2000).

16

[44] S. Bahar, J.W. Kantelhardt, A. Neiman, H.H.A. Rego,
D.F. Russell, L. Wilkens, A. Bunde, and F. Moss, Euro-
phys. Lett. 56, 454 (2001).

(2001).

published) (2001).

[57] M. Ausloos and K. Ivanova, Int. J. Mod. Phys. C (to be

[45] Y. Liu, P. Cizeau, M. Meyer, C.-K. Peng, and H.E. Stan-

[58] P.Ch. Ivanov, L.A. Nunes Amaral, A.L. Goldberger, and

ley, Physica A 245, 437 (1997).

[46] N. Vandewalle and M. Ausloos, Physica A 246, 454

[47] N. Vandewalle and M. Ausloos, Phy. Rev. E 58, 6832

[48] Y. Liu, P. Gopikrishnan, P. Cizeau, M. Meyer, C.-K.

Peng, and H.E. Stanley, Phys. Rev. E 60, 1390 (1999).

[49] I.M. Janosi, B. Janecsko, and I. Kondor, Physica A 269,

(1997).

(1998).

111 (1999).

H.E. Stanley, Europhys. Lett. 43, 363 (1998).

[59] J.W. Kantelhardt, E. Koscielny-Bunde, H.H.A. Rego, S.
Havlin, and A. Bunde, Physica A 294, 441 (2001).
[60] K. Hu, P.Ch. Ivanov, Z. Chen, P. Carpena and H.E. Stan-

ley, Phys. Rev. E 64, 011114 (2001).

[61] M.A. Carskadon and W.C. Dement, Principle and Prac-
tice of Sleep Medicine (WB Saunders Co., Philadelphia,
2000).

[62] H.A. Makse, S. Havlin, M. Schwartz, and H.E. Stanley,

[50] M. Ausloos, N. Vandewalle, P. Boveroux, A. Minguet,

Phys. Rev. E 53, 5445 (1996).

and K. Ivanova, Physica A 274, 229 (1999).

[63] When 0 < γ < 1, α and γ have the following relation:

[51] M. Roberto, E. Scalas, G. Cuniberti, and M. Riani, Phys-

[52] N. Vandewalle, M. Ausloos, and P. Boveroux, Physica A

ica A 269, 148 (1999).

269, 170 (1999).

[53] P. Grau-Carles, Physica A 287, 396 (2000).
[54] M. Ausloos, Physica A 285, 48 (2000).
[55] M. Ausloos and K. Ivanova, Physica A 286, 353 (2000).
[56] M. Ausloos and K. Ivanova, Phys. Rev. E 63, 047201

α = (2

γ)/2.

−

[64] We note that, for components containing strongly cor-
related segments (e.g., α = 1.2 when W = 20, see Ap-
pendix B and Fig. 10), at small scales the contribution
of the correlated non-zero segments [Fcorr(n)/n] is still
substantial, however, we have F (n)/n
A

Fcorr(n)/n

p)nα.

p(1

≈

∼

−

p

17

