4
0
0
2
 
r
a

M
 
5
2
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
1
2
1
3
0
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Inference of stochastic nonlinear oscillators with applications
to physiological problems

Vadim N. Smelyanskiya, Dmitry G. Luchinskyb
a NASA Ames Research Center, Mail Stop 269-2, Moﬀett Field, CA 94035, USA;
b Department of Physics, Lancaster University, Lancaster LA1 4YB, UK.

ABSTRACT

A new method of inferencing of coupled stochastic nonlinear oscillators is described. The technique does not
require extensive global optimization, provides optimal compensation for noise-induced errors and is robust in
a broad range of dynamical models. We illustrate the main ideas of the technique by inferencing a model of
ﬁve globally and locally coupled noisy oscillators. Speciﬁc modiﬁcations of the technique for inferencing hidden
degrees of freedom of coupled nonlinear oscillators is discussed in the context of physiological applications.

Keywords: Inference, time-series analysis, cardio-respiratory interaction, chaotic dynamics

1. INTRODUCTION

Coupled oscillators are ubiquitous in nature. They are used to describe observed phenomena intensively over
the years in many areas of science and technology including e.g. physics,1, 2 chemistry3 and biology.4
In this
approach a complex system is characterized by projecting it onto a speciﬁc dynamical model of coupled nonlinear
oscillators. However, there are no general methods to infer parameters of stochastic nonlinear models from the
measured time-series data. Furthermore, in a great number of important problems the model is not usually
known exactly from “ﬁrst principles” and one is faced with a rather broad range of possible parametric models
to consider. In addition, the experimental data can be extremely skewed, whereby important “hidden” features
of a model such as coupling coeﬃcients between the oscillators can be very diﬃcult to extract due to the intricate
interplay between noise and nonlinearity.

As was pointed out by McSharry and co-authors,5 deterministic inference techniques6 consistently fail to
yield accurate parameter estimates in the presence of noise. The problem becomes even more complicated when
both measurement noise as well as intrinsic dynamical noise are present.7 Various numerical schemes have
been proposed recently to deal with diﬀerent aspects of this inverse problem.5, 7–12 A standard approach to
this problem is often based on optimization of a certain cost function (a likelihood function) at the values of
the model parameters that best reconstruct the measurements. It can be further generalized using a Bayesian
formulation of the problem.7, 9
Existing techniques usually employ numerical Monte Carlo techniques for
complex optimization11 or multidimensional integration9 tasks. Inference results from noisy observations are
shown to be very sensitive to the speciﬁc choice of the likelihood function.5 Consequently, the correct choice of
the likelihood function is one of the central questions in the inference of continuous-time noise-driven dynamical
models considered here.

In this paper, we present an eﬃcient technique of Bayesian inference of nonlinear noise-driven dynamical
models from time-series data that avoids extensive numerical optimization. It also guarantees optimum compen-
sation of noise-induced errors by invoking the likelihood function in the form of a path integral over the random
trajectories of the dynamical system. The technique is veriﬁed on a broad range of dynamical models including
system of ﬁve globally and locally coupled nonlinear oscillators.

A speciﬁc example of inferencing stochastic nonlinear model from skewed time-series data is considered in the
context of physiological research. In particular, we refer to the situation when the variability of the cardiovascular
signals is modelled in terms of coupled nonlinear oscillators.?, 13–15 At present there are no methods available

Further author information: (Send correspondence to V.N.S.)

V.N.S.: E-mail: vadim@email.arc.nasa.gov

to infer parameters of the nonlinear coupling between oscillators directly from experimental time series data.
Furthermore, in many situations it is important to perform such inference using univariate time series. This rises
another important issue in nonlinear time-series analysis related to the inference of hidden dynamical variables.
If a technique of inferencing of coupling parameters from hidden dynamical variables could be found it could
provide new eﬀective tool for estimation of the state of autonomous nervous control16 and risk stratiﬁcation of
cardiovascular diseases.17 The corresponding problem of inference of the coupling parameters of two nonlinear
oscillators perturbed by noise from univariate time-series data will be considered in this paper.

The paper is organized as follows.

In the Sec. 2 the algorithm is introduced and its main features are
compared with the results of earlier work. In the Sec. 3 the convergence of the algorithm is analyzed in the case
of inference of coupled nonlinear stochastic oscillators. A modiﬁcation of the algorithm that allows inference of
hidden dynamical variables of two nonlinear coupled oscillators from univariate time-series data is considered in
Sec. 4.

2. THEORY OF NONLINEAR INFERENCE OF NOISE-DRIVEN DYNAMICAL
SYSTEMS

Consider N -dimensional dynamical system described by set of nonlinear Langevin equations

(1)

(2)

(3)

˙x(t) = f (x) + ε(t) = f (x) + σξ(t),

where ε(t) is an additive stationary white, Gaussian vector noise process

hξ(t)i = 0,

hξ(t) ξT (t′)i = ˆD δ(t − t′),

characterized by diﬀusion matrix ˆD.

We assume that the trajectory x(t) of this system is observed at sequential time instants {tk; k = 0, 1, . . . , K}
and a series Y = {yk ≡ y(tk)} thus obtained is related to the (unknown) “true” system states X = {xk ≡ x(tk)}
through some conditional PDF po (Y|X ).

The most general approach to dynamical model inference is based on Bayesian framework (cf.7).

In the
Bayesian model inference, two distinct PDFs are ascribed to the set of unknown model parameters: the prior
ppr(M) and the posterior ppost(M|Y), respectively representing our state of knowledge about M before and
after processing a block of data Y. The prior acts as a regularizer, concentrating the parameter search to those
regions of the model space favored by our expertise and any available auxiliary information. The two PDFs are
related to each other via Bayes’ theorem:

ppost(M|Y) =

ℓ(Y|M) ppr(M)
ℓ(Y|M) ppr(M) dM

.

R

Here ℓ(Y|M), usually termed the likelihood, is the conditional PDF of the measurements Y for a given choice
M of the dynamical model. In practice, (3) can be applied iteratively using a sequence of data blocks Y, Y ′,
etc. The posterior computed from block Y serves as the prior for the next block Y ′, etc. For a suﬃciently large
number of observations, ppost(M|Y, Y ′, . . .) is sharply peaked at a certain most probable model M = M∗.

The main eﬀorts in the research on stochastic nonlinear dynamical inference are focused on constructing the
likelihood function that compensates noise induced errors and on introducing eﬃcient optimization algorithms
(cf.5, 7, 9, 11).

No closed form expression for the likelihood function that provides optimal compensation of the noise-induced
errors was introduced so far for continuous systems. The ad hoc likelihood function5 and their generalization to
the conditional PDF for stochastic trajectories in maps7, 9 do not compensate the error in continuous systems,
since they are missing the main compensating term (see below). The problem of noise-induced errors in inference
of continuous systems was considered in11 and a general approach to constructing corresponding likelihood was
outlined. However, the closed form expression for the likelihood that takes into account the leading compensating
term was not found and instead an ad hoc expression for the likelihood function was used.

A common draw back of earlier research is the use of extensive numerical optimization. This problem
will become increasingly important when complex systems with the large number (hundred or more) of model
coeﬃcients are investigated.

In the present paper we introduce a closed form of the likelihood function for continuous systems that provides
optimal compensation for the noise-induced errors. We also suggest parametrization of the unknown vector ﬁeld
that reduces the problem of nonlinear dynamical inference to essentially linear one for a broad class of nonlinear
dynamical systems. This allows us to write an eﬃcient algorithm of Bayesian inference of nonlinear noise-
driven dynamical models that avoids extensive numerical optimization and guarantees optimum compensation
of noise-induced errors.

In what follows in this section we describe the likelihood function, the parametrization, and the corresponding

algorithm.

2.1. The likelihood function
It was pointed out in11 the probability density functional for the nonlinear dynamical stochastic systems in
general is not known. Instead one can use the probability density functional for random trajectories in such
systems. We note that the path-integral approach has also proved to be useful in nonlinear ﬁltration of random
signals (see e.g.18)in the situations where standard spectral-correlation methods fail.

Therefore we write the expression for the likelihood in the form of a path integral over the random trajectories

of the system:

ℓ(Y|M) =

po(Y|X ) FM[x(t)] Dx(t),

(4)

x(tf )

Z

x(ti)

which relates the dynamical variables x(t) of the system (1) to the observations y(t). Here we choose ti ≪ t0 <
tK\tf so that ℓ does not depend on the particular initial and ﬁnal states x(ti), x(tf ). The form of the probability
functional FM over the system trajectory x(t) is determined by the properties of the dynamical noise ξ(t).19, 20

In the following we are focusing on the case of additive and stationary Gaussian white noise, as indicated
in (1), (2). We consider a uniform sampling scheme tk = t0 + hk, h ≡ (tK − t0)/K and assume that for each
trajectory component xn(t) the measurement error ǫ is negligible compared with the ﬂuctuations induced by the
K
dynamical noise; that is, ǫ2 ≪ h( ˆD2)n n. Consequently, we use po(Y|X ) →
k=0 δ[yk − x(tk)] in (4). Using
results from19 for FM[x(t)], the logarithm of the likelihood (4) takes the following form for suﬃciently large K
(small time step h):

Q

−

2
K

log ℓ(Y|M) = ln det ˆD +

h
K

K−1

Xk=0 h

tr ˆΦ(yk; c) + ( ˙yk − f (yk; c))T ˆD−1 ˙yk − f (yk; c))
i

+ N ln(2πh),

(5)

here we introduce the “velocity” ˙yk and matrix ˆΦ(x)

˙yk ≡ h−1(yk+1 − yk),

( ˆΦ(x; c))n n′ ≡ ∂fn(x; c)/∂xn′ .

It is the term tr ˆΦ(yk; c) that guarantees optimal compensation of the noise-induced errors in our technique
and that distinguish our likelihood function from those introduced in earlier work. Formally this term appears
in path integral as a Jacobian of transformation21–23 from noise variables to dynamical ones. We emphasize,
however, that this term is not a correction, but a leading term in inference as will be shown in the following
sections.

Note, that the optimization of the log-likelihood function (5) is in general essentially nonlinear problem that
requires extensive numerical optimization. Below we introduce parametrization that allows to avoid this problem
for a broad class of nonlinear dynamical models. In particular, a vast majority of the model examples considered
in the earlier work on the nonlinear dynamical inference can be solved using this technique. Moreover, a large
number of important practical applications can be treated using the same approach.

2.2. Parametrization of the unknown vector ﬁeld

We parameterize this system in the following way. The nonlinear vector ﬁeld f (x) is written in the form

f (x) = ˆU(x) c ≡ f (x; c),

where ˆU(x) is an N × M matrix of suitably chosen basis functions {Unm(x); n = 1 : N, m = 1 : M }, and c is
an M -dimensional coeﬃcient vector.

The choice of the base functions is not restricted to polynomials, φb(x) can be any suitable function.
In
general if we use B diﬀerent base functions φb(x) to model the system (1) the matrix ˆU will have the following
block structure

ˆU =

φ1
0
...
0















0
φ1
...
0

. . . 0
. . . 0
...
. . .
. . . φ1

φ2
0
...
0








. . .








0
φ2
...
0

. . . 0
. . . 0
...
. . .
. . . φ2








. . .








φB 0
0
...
0

. . . 0
φB . . . 0
...
...
. . .
. . . φB
0

,















where we have B diagonal blocks of size N × N and M = B · N .

An important feature of (6) for our subsequent development is that, while possibly highly nonlinear in x,

f (x; c) is strictly linear in c.

Eqs. (5) and (6) are two main ingredients that allow to solve problem of nonlinear stochastic dynamical

inference analytically as shown in the following section.

2.3. The algorithm
The vector elements {cm} and the matrix elements {Dnn′} together constitute a set M = {c, ˆD} of unknown
parameters to be inferred from the measurements Y.

With the use of (6), substitution of the prior ppr(M) and the likelihood ℓ(Y|M) into (3) yields the posterior

ppost(M|Y) = const × exp[−S(M|Y)], where

S(M|Y) ≡ Sy(c, ˆD) =

ρy( ˆD) − cT wy( ˆD) +

cT ˆΞy( ˆD)c.

1
2

1
2

Here, use was made of the deﬁnitions

ρy( ˆD) = h

˙yT
k

ˆD−1 ˙yk + K ln(det ˆD),

K−1

Xk=0

wy( ˆD) = ˆΣ−1

pr cpr + h

ˆUT
k

ˆD−1 ˙yk −

v(yk)
2

,

(cid:21)

ˆΞy( ˆD) = ˆΣ−1

pr + h

ˆUT
k

ˆD−1 ˆUk,

K−1

(cid:20)

Xk=0

K−1

Xk=0

vm(x) =

, m = 1 : M.

N

Xn=1

∂Un m(x)
∂xn

where ˆUk ≡ ˆU(yk) and the components of vector v(x) are:

(6)

(7)

(8)

(9)

(10)

(11)

(12)

The mean values of c and ˆD in the posterior distribution give the best estimates for the model parameters
for a given block of data Y of length K and provide a global minimum to Sy(c, ˆD). We handle this optimization
problem in the following way. Assume for the moment that c is known in (8). Then the posterior distribution

over ˆD has a mean ˆD′
elements are

post = ˆΘy(c) that provides a minimum to Sy(c, ˆD) with respect to ˆD = ˆDT . Its matrix

ˆΘnn′

y (c) ≡

˙yk − ˆU(yk) c

1
K

K−1

Xk=0 h

˙yk − ˆU(yk) c
i

in h

T

n′

.

Alternatively, assume next that ˆD is known, and note from (8) that in this case the posterior distribution over
c is Gaussian. Its covariance is given by ˆΞy( ˆD) and the mean c′

post minimizes Sy(c, ˆD) with respect to c

(13)

(14)

post = ˆΞ−1
c′

y ( ˆD)wy( ˆD).

We repeat this two-step optimization procedure iteratively, starting from some prior values cpr and ˆΣpr.

It can be seen that the second term in the sum on the rhs of eq. (10) originating from tr ˆΦ(yk) does not vanish
ˆD−1 ˙yk corresponding to the generalized
at the dynamical system attractors (1), unlike the term (5) h
least square optimization.24 Therefore both types of terms are required to optimally balance the eﬀect of noise
eﬀect in {yk} (8) and provide the robust convergence. In the following section we analyze relative importance
of both terms for the convergence of our algorithm.

K−1
k=0

ˆUT
k

P

We veriﬁed the convergence and robustness of the algorithm on a broad range of dynamical systems. In this
paper we will be speciﬁcally focused on the applications to the inference of coupled nonlinear oscillators.

3. NUMERICAL EXAMPLES

3.1. Five coupled oscillators

Consider system of ﬁve locally and globally coupled van der Pol oscillators

˙xk = yk,

5

Xj=1
j6=k

˙yk = εk(1 − x2

k)yk − ωkxk +

ηkjxj + γk,k−1xk−1(t) + γk,k+1xk+1(t) +

σkj ξj ,

(15)

5

Xj=1

We assume for simplicity that there is no observational noise and that the observed signal is y = (y1, y2, y3, y4, y5).
We note that for the model of coupled oscillators (15) parameters of the equations ˙xk = yk are known and do not
have to be inferred. An example of a trajectory of (15) is shown in the ﬁgure 1(a) in projection on (x1, x2, x3)
subspace of the conﬁguration space of this system. We chose the following base functions

φ(1) = x1; φ(2) = y1; φ(3) = x2; φ(4) = y2; φ(5) = x3; φ(6) = y3;
φ(7) = x4; φ(8) = y4; φ(9) = x5; φ(10) = y5; φ(11) = x1x2; φ(12) = x2x3;
φ(13) = x3x4; φ(14) = x4x5; φ(15) = x5x1; φ(16) = x2
φ(18) = x2

1y1; φ(17) = x2

3y3; φ(19) = x2

4y4; φ(20) = x2

2y2;

5y5.

Together with the elements of the diﬀusion matrix we have to infer 115 model coeﬃcients. Example of the
convergence of the coeﬃcients of the 5th oscillator to their correct values is shown in the Fig. 1(b). Results of
the corresponding convergence for the 4th oscillator are summarized in the Table 1. It can be seen from the
Table that accuracy of estimation of the model parameters is better then 1%. Of a special interest for us is
the compensation of the noise-induced errors. In the ﬁgure Fig. 2 we compare results of inference of one of the
coeﬃcients of the system (1) ε1 for two diﬀerent diﬀusion matrices D and 2D where matrix D was chosen at
random

0.0621 1.9171 0.4307 0.0356 0.3113
0.5773 1.3597 0.3648 1.7559 0.3259
1.9421 0.1099 0.1535 0.7051 0.6268
1.9010 1.1997 0.0148 1.4443 0.0588
0.4561 0.7863 1.5776 1.9369 0.7153

.









ˆD =









(16)

x

3

4

0

5

−4

(a) 

(b) 

D

5j

8

6

4

ε
5
−ε
5
ω
5
η
η
η
η

53

51

52

54

0

50

100

1.2
a
i
0.8

0.4

0

−0.4

x
2

0

−5

−5

−10

10

0

5

x
1

20

40

60

N

80

Figure 1. (a) A projection of a trajectory of system (15) on (x1, x2, x3) subspace of its conﬁguration space. (b) Conver-
oscillator to the true values as a function of a number of blocks of data. We have 100
gence of the coeﬃcients of the 5
blocks of data with 800 points in each block and the sampling time h = 0.02. a1 = ǫ1, a2 = −ǫ1, a3 = −ω1, a4 = η12,
a5 = η13, a6 = η14, a7 = η15, a8 = γ15. The convergence of the ﬁve components of the diﬀusion matrix is shown in the
insert.

th

Table 1. Convergence of the coeﬃcients of the 4th oscillator of system (15). We have used 200 blocks of data with
5000 points in each block. True values are shown in the ﬁrst row, inferred values are shown in the second row, and
corresponding standard deviations are shown in the last row. The accuracy of inference is within 5%.

coeﬃcients

true value

ε4
0.2

ω4
-0.06

η41
-0.075

η42
0.24

η43
-0.23

η44
-0.2

γ43
0.064

γ45
0.095

D41
1.477

D42
2.316

D43
1.783

inferred value

0.199

-0.062

-0.069

0.246

-0.228

-0.20

0.066

0.096

1.477

2.316

1.782

std

0.005

0.0033

0.0046

0.004

0.0034

0.0042

0.001

0.001

0.001

0.002

0.002

It can be shown that that without compensation term the estimator (14), (14) is reduced to the generalized
least square (GLS) estimator. The Fig. 2 shows that the GLS estimator systematically overestimates the value
of ε1 and the larger is noise intensity the larger is the systematic error of the overestimation (see curves 1’
and 2’ for D and 2D correspondingly). By adding the term tr ˆΦ(yk; c) we obtain optimal compensation of the
noise-induced errors as shown by the curves 1 and 2 obtained for the same noise intensities. To see the eﬀect of
the compensation analytically it is instructive to rewrite the sum in the eq. (10) in the integral form

wy( ˆD) = ˆΣ−1

pr cpr +

ˆU(y(t))T ˆD−1 dy −

v(yk)dt,

(17)

x(T )

Z

x(t0)

T

1
2 Z

t0

It can be seen from eq. (17) that for the attractor localized in the phase space the ﬁrst integral is ﬁnite, since
initial and ﬁnal points of integration belong to the attractor. The second integral is growing when the total time
of inference is growing.

In particular, for a point attractor this integral is identically zero and the whole inference is due to the
compensating term 1
v(yk)dt. This result is intuitively clear, since for the point attractor in the absence of
2
noise the system will stay forever in the same point and no inference can be done. It is only noise that forces
the system to move about in the phase space and makes it possible to perform inference.

T
t0
R

ρ(ε
)
1

2 

80

1 

1’ 

2’ 

40

0
0

0.1

0.2

0.3

0.4

ε
1

0.5

Figure 2. Results of inference of the ε1 that were performed according to eqs. (10) – (14) (curves 1 and 2) are compared
′
with the results of inference without compensating term tr ˆΦ(yk; c) (curves 1
) for diﬀerent noise matrices d: d = D
for (1) and (1’); d = 2 ∗ D for (2) and (2’) where D is given in eq. (16).

′
and 2

4. INFERENCE OF TWO COUPLED OSCILLATORS FROM UNIVARIATE
TIME-SERIES DATA

As we have mentioned in the introduction in many real experimental situations the model is not usually known
exactly from “ﬁrst principles” and in addition, the experimental data can be extremely skewed, whereby impor-
tant “hidden” features of a model such as coupling coeﬃcients can be very diﬃcult to extract due to the intricate
interplay between noise and nonlinearity.

A speciﬁc example of such experimental situation is inference of the strength, directionality and a degree
of randomness of the cardiorespiratory interaction from the blood pressure signal. Such inference can provide
valuable diagnostic information about the responses of the autonomous nervous system.16, 25 However, it is
inherently diﬃcult to dissociate a speciﬁc response from the rest of the cardiovascular interactions and the
mechanical properties of the cardiovascular system in the intact organism.26 Therefore a number of numerical
linear approximations,27 or semi-quantitative
techniques were introduced to address this problem using e.g.
estimations of either the strength of some of the nonlinear terms28 or the directionality of coupling.29, 30 But
the problem remains wide open because of the complexity and nonlinearity of the cardiovascular interactions.

It is important to notice that simultaneous measurements of the cardiovascular signals is performed in diﬀerent
parts of the system (see e.g.14). As a consequence the nonlinear characteristics of the oscillations are substantially
modiﬁed in each signal and inference of nonlinear coupling parameters has to be performed preferably using
univariate data e.g. blood pressure or blood ﬂow signal only. The necessity to use univariate data in general
poses serious limitations on the techniques of reconstruction and the problem become essentially nontrivial even
in quasi-linear noise-free limit.31–33

In this section we investigate the possibility of extending our technique of reconstruction of coupled nonlinear
stochastic oscillators to encompass the case of inference from the univariate time-series data in the context of
physiological research. We note that this is a particular example of inference of hidden dynamical variables,
which will be addressed elsewhere. An example of the actual signal of the central venous blood pressure (record
24 of the MGH/MF Waveform Database available at www.physionet.org). The main features of the blood signal
data is the presence of the two oscillatory components at frequencies approximately fr = 0.2 Hz and fc = 1.7
Hz corresponding to the respiratory and cardiac oscillations. It can also be clearly seen from the spectra that
the nonlinear terms including terms of nonlinear interaction (and cardiorespiratory interaction in particular)
are very strong in this sample. We note that the relative intensity and position of the cardiac and respiratory
components vary strongly from sample to sample with average frequency of the respiration being around 0.3 Hz
and of the heart beat being around 1.1 Hz. To infer coupling parameters from the univariate blood pressure

(a) 

(b) 

x

1.6

0.8

0

−0.8

−1.6

0

10

S

−2

10

−4

10

−6

10

180

t, sec

200

0

1

2

f, Hz

Figure 3. Example of the blood pressure signal (a) and of its spectrum (b) taken from the record 24 of the MGH/MF
Waveform Database available at www.physionet.org.

signal an important simplifying assumption can be used. Namely it is assumed that the blood pressure signal can
be represented as the sum of the oscillatory components with the main contributions coming from the oscillations
of the respiration and heart.14 Accordingly we chose our surrogate data as a sum of coordinates of two coupled
van der Pol oscillators s(t) = x1(t) + x2(t). It can be seen that the spectrum of s(t) (Fig. 4 (c)) reproduces
mentioned above main features of the real blood pressure signal.

˙x1 = y1,

˙y1 = ǫ1(1 − x2

1)y1 − ω2

1x1 + α1x2 +

β1,ijxixj +

γ1,ijxiyj +

σ1j ξj,

(18)

2

2

Xi,j=1

Xi,j=1

2

2

Xi,j=1
j6=i

Xi,j=1
j6=i

2

2

Xj=1

Xj=1

˙x2 = y2,

˙y2 = ǫ2(1 − x2

2)y2 − ω2

2x2 + α2x2 +

β2,ijxixj +

γ2,ijxiyj +

σ2j ξj,

(19)

hξi(t)i = 0,

hξi(t)ξj(t′)i = δij δ(t − t′).

Here noise matrix σ mixes zero-mean white Gaussian noises ξj(t) and is related to the diﬀusion matrix D = σ·σT .
To infer parameters of nonlinear coupling between cardiac and respiratory oscillations we decompose “mea-
sured” signal s(t) on two oscillatory components using a combination of low- and high-pass Butterworth ﬁlters
representing observations of mechanical cardiac and respiratory degrees of freedom on a discrete time grid with
step h = 0.02 sec. Obtained in this way signals s0(t) and s1(t) are shown in the Fig. 4 (a) and (b) respectively.∗
To make this numerical experiment even more realistic the input signal s(t) was ﬁltered before decomposition
(using high-pass Butterworth ﬁlter of the 2nd order with cut-oﬀ frequency 0.0025 Hz) to model standard proce-
dure of de-trending, which is used in time-series analysis of the cardiovascular signals to remove low frequency
non-stationary trends. We now use standard embedding procedure to introduce an auxiliary two-dimensional
dynamical system whose trajectory z(t) = (z0(t), z1(t)) is related to the observations {s(tk)} as follows

zn(tk) =

sn(tk + h) − sn(tk)
h

,

where n = 1, 2. The corresponding simpliﬁed model of the nonlinear interaction between the cardiac and
respiratory limit cycles has the form (cf. with 15)

˙zn = b1,nsn + b2,nsn−1 + b3,nzn + b4,nzn−1 + b5,ns2
+ b9,nsnsn−1 + b10,nsnzn + b11,nsnzn−1 + b12,nsn−1zn + b13,nsn−1zn−1 + b14,nznzn−1
+ b15,ns2

n + ξn(t), n = 0, 1.

n + b16,nsn−1z2

n−1 + b7,nz2

n + b8,nz2

n + b6,ns2

nz2

n−1

(20)

where ξn(t) is a Gaussian white noise with correlation matrix Qn n′ . We emphasize that a number of important
parameters of the decomposition of the original signal (including the bandwidth, the order of the ﬁlters) have to

∗

Note the diﬀerence between actual oscillatory components of the original signal s(t): x1(t) and x2(t) and the compo-

nents obtained using spectral decomposition with Butterworth ﬁlters: s0(t) and s1(t).

(a)

(b)

(c)

0

10

S

−5

10

0

1

2

f, Hz

0

1

2 f, Hz

0

1

2 f, Hz

th

Figure 4. Comparison of the power spectra of the inferred z(t) components of the signal (gray lines) with the original
signal s(t) (black lines): (a) a low-frequency component of the signal s0(t) obtained using low-pass Butterworth ﬁlter of
order with cut-oﬀ frequency 0.55 Hz (black line) is compared with the inferred signal z0(t)(grayline); (b) a high-
the 5
frequency component of the signal s1(t) obtained high-pass Butterworth ﬁlter of the 4
order with cut-oﬀ frequency 0.55
Hz (black line) is compared with the inferred signal z1(t) (gray line); (c) spectrum of the original signal s(t) = x1(t)+x2(t)
(black line) is compared with the spectrum of the inferred signal z(t) = z0(t) + z1(t).

th

be selected to minimize the cost (8) and provide the best ﬁt to the measured time series {s(tk)}. The parameters
of the model (20) can now be inferred directly from the univariate “measured” time series data s(t). The
comparison between the time series of the inferred and actual cardiac oscillations is shown in Fig. 4 and Fig.
5. The comparison of the inferred parameters with their actual values is summarized in the Tables 2. It can

−5

9

t, sec

12

12

y

5
(a)

0

8

y

4

0

−4

0

14

(b)

y

7

0

−7

−14

20

t, sec

40

−4

0

4

x

Figure 5. (a) Comparison of the inferred signal x(t) = x1(t) + x(2) (black solid line) with the original signal (black dotted
line). In the insert fragments of both signals are compared with better resolution in time. (b) Comparison of the inferred
phase space trajectory (x(t), y(t)) (black solid line) with the original one (black dotted line). To facilitate the comparison
we have used the same initial conditions to generate phase space trajectory with exact parameters of the system and with
inferred parameters of the system.

Table 2. Comparison of the non-zero parameters of the second equation of the model (20) inferred from the univariate
time series data s(t) with their actual values. We have used 1 block of data with 120000 points. True values are shown
in the ﬁrst row, inferred values are shown in the second row.

coeﬃcients

true value

b2,1
0.05

b2,2
-45.0

b2,3
-0.19

inferred value

0.014

-44.73

-0.071

-0.081

b2,5
0

b2,4
0.25

0.17

b2,6
2.55

1.25

b2,9
0.2

0.415

b2,14
0.11

0.14

b2,16
-0.25

D1
0.2

-0.251

0.17

be seen from the Table that the inferred parameters give correct order of the magnitude for the actual values.

The inferred values can be further corrected taken into account attenuation of the ﬁlters at diﬀerent frequencies.
We emphasize, however, that the technique of spectral decomposition of the “measured” signal is in principal
non-unique. Moreover, in the actual experimental situation the dynamics of the physiological oscillations is
unknown and can be only very approximately modelled by the system of coupled oscillators. Furthermore, the
only criterion for the goodness of the spectral decomposition is the coincidence of the original and inferred signal
and spectrum. For these reasons the estimation of the model parameters with the accuracy better then the
order of magnitude does not improve the quality of the inferred information as will be discussed in more details
elsewhere.

In conclusion, we suggested new technique of inference of parameters nonlinear stochastic dynamical system.
The technique does not require extensive global optimization, provides optimal compensation for noise-induced
errors and is robust in a broad range of dynamical models. We illustrate the main ideas of the technique by
inferencing 115 model coeﬃcients of ﬁve globally and locally coupled noisy oscillators within accuracy 1%. It
is demonstrated that our technique can be readily extended to solve selected problems of nonlinear stochastic
inference of hidden dynamical variables in the context of the physiological modelling. We show in particular
that the method allows one to estimate correct order of the magnitude of nonlinear coupling of two stochastic
oscillators from univariate time series data. The framework of nonlinear Bayesian inference outlined in this paper
can be further generalized to include errors of measurements and to solve problem of global inference hidden
dynamical variables.

4.1. Acknowledgments

The work was supported by the Engineering and Physical Sciences Research Council (UK), NASA IS IDU project
(USA), the Russian Foundation for Fundamental Science, and INTAS.

REFERENCES

1. H. Haken, Synergetics, An Introduction, Springer, Berlin, 1983.
2. S. H. Strogatz, Nonlinear Dynamics and Chaos, Addison-Wesley, Reading, 1994.
3. Y. Kuramoto, Chemical Oscillations, Waves, and Turbolence, Springer-Verlag, Berlin, 1984.
4. A. T. Winfree, “The geometry of biological time,” in Springer-Verlag, 1980, New York.
5. P. E. McSharry and L. A. Smith, “Better nonlinear models from noisy data: attractors with maximum

likelihood,” Physical Review Letters 83, pp. 4285–4288, 1999.

6. H. Kantz and T. Schreiber, Nonlinear Time Series Analysis, Cambridge University Press, Cambridge, 1997.
7. R. Meyer and N. Christensen, “Fast bayesian reconstruction of chaotic dynamical systems via extended

kalman ﬁltering,” Phys. Rev. E 65, p. 016206, 2001.

8. J. P. M. Heald and J. Stark, “Estimation of noise levels for models of chaotic dynamical systems,” Phys.

9. R. Meyer and N. Christensen, “Bayesian reconstruction of chaotic dynamical systems,” Phys. Rev. E 62,

Rev. Lett. 84(11), pp. 2366–2369, 2000.

pp. 3535–3542, 2000.

Phys. Rev. E 62(3), pp. 3146–3155, 2000.

p. 031107, 2002.

10. J. Gradisek, S. Siegert, R. Friedrich, and I. Grabec, “Analysis of time series from stochastic processes,”

11. J.-M. Fullana and M. Rossi, “Identiﬁcation methods for nonlinear stochastic systems,” Phys. Rev. E 65,

12. M. Siefert, A. Kittel, R. Friedrich, and J. Peinke, “On a quantitative method to analyze dynamical and

measurement noise,” Europhys. Lett. 61(4), pp. 466–472, 2003.

13. I. Javorka, M. ans Zila, K. Javorka, and A. Calkovska, “Do the oscillations of cardiovascular parameters

persist during voluntary apnea in humans?,” Physol. Res. 51, pp. 227–238, 2002.

14. A. Stefanovska and M. Braˇciˇc, “Physics of the human cardiovascular system,” Contemporary Physics 40,

15. A. Stefanovska, M. Braˇciˇc, S. Strle, and H. Haken, “The cardiovascular system as coupled oscillators?,”

pp. 31–55, 1999.

Physiol. Meas. 22, pp. 535–550, 2001.

Springer-Verlag, New York, 1973.

D 28, pp. 1922–1930, 1983.

A 40(7), pp. 4050–4053, 1989.

16. S. C. Malpas, “Neural inﬂuences on cardiovascular variability: possibilities and pitfalls,” Am. J. Physiol.:

Heart. Circ. Physiol. 282, pp. H6–H20, 2002.

17. P. van Leeuwen and H. Bettermann, “The status of nonlinear dynamics,” Herzschr Elektrophys 11, pp. 127–

130, 2000.

18. A. K. Rosov, Nonlinear Filtration of Signals, Politechnika, St. Petersburg, 2002.
19. R. Graham, “Path integral formulation of general diﬀusion processes,” Z. Phys. B 26, pp. 281–290, 1977.
20. M. I. Dykman, “Large ﬂuctuations and ﬂuctuational transitions in systems driven by colored gaussian

noise–a high frequency noise,” Phys. Rev. A 42, pp. 2020–2029, 1990.

21. R. Graham, Tracts in Modern Physics, vol. 66, ch. Quantum Statistics in Optics and Solid-State Physics.

22. G. E., “Functional-integral approach to parisi-wu stochastic quantization: Scalar theory,” Physical Review

23. A. J. McKane, “Noise-induced escape rate over a potential barrier: Results for a general noise,” Phys. Rev.

24. H. Theil, Linear algebra and matrix methods in econometrix, vol. I of Hundhook of Econometrics, ch. 1,

pp. 5–65. North- Holland Publishing Company, 1983.

25. J. Hayano and F. Yasuma, “Hypothesis: respiratory sinus arrhythmia is an intrinsic resting function of

cardiopulmonary system,” Cardiovascular Research 58, pp. 1–9, 2003.

26. D. Jordan, “Central nervous integration of cardiovascular regulation,” in Cardiovascular regulation, D. Jor-

dan and J. Marshall, eds., Portland Press, Cambridge, 1995.

27. J. A. Taylor, C. W. Myers, J. R. Halliwill, H. Seidel, and D. L. Eckberg, “Sympathetic restraint of respiratory
implications for vagal-cardiac tone assessment in humans,” Am J Physiol Heart Circ

sinus arrhythmia:
Physiol 280(6), pp. H2804–2814, 2001.

28. J. Jamˇsek, I. A. Khovanov, P. V. E. McClintock, and A. Stefanovska Phys. Rev. E, submitted , 2003.
29. M. G. Rosenblum, L. Cimponeriu, A. Bezerianos, A. Patzak, and R. Mrowka, “Identiﬁcation of coupling

direction: Application to cardiorespiratory interaction,” Phys. Rev. E. 65, p. 041909, 2002.

30. M. Paluˇs, V. Kom´arek, Z. Hrnˇc´iˇr, and K. ˇStˇebrov´a, “Synchronization as adjustment of information rates:

Detection from bivariate time series,” Phys. Rev. E 63, p. 046211, 2001.

31. N. B. Janson, A. G. Balanov, V. S. Anishchenko, and P. V. E. McClintock, “Phase synchronization between

several interacting processes from univariate data,” Phys. Rev. Lett. 86, pp. 1749–1752, 2001.

32. N. B. Janson, A. G. Balanov, V. S. Anishchenko, and P. V. E. McClintock, “Phase relationships between
two or more interacting processes from one-dimensional time series: I. Basic theory,” Phys. Rev. E 65,
pp. 036211/1–12, 2002.

33. N. B. Janson, A. G. Balanov, V. S. Anishchenko, and P. V. E. McClintock, “Phase relationships between
two or more interacting processes from one-dimensional time series: II. Application to heart-rate-variability
data,” Phys. Rev. E 65, pp. 036212/1–7, 2002.

