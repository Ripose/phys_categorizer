7
0
0
2
 
n
a
J
 
1
3
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
8
4
3
1
0
7
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Deterministic Modularity Optimization

Sune Lehmann∗ and Lars Kai Hansen
Informatics and Mathematical Modeling, Technical University of Denmark, Building 321, DK-2800 Kgs. Lyngby, Denmark.
(Dated: February 21, 2014)

We study community structure of networks. We have developed a scheme for maximizing the modularity Q
[1] based on mean ﬁeld methods. Further, we have deﬁned a simple family of random networks with community
structure; we understand the behavior of these networks analytically. Using these networks, we show how the
mean ﬁeld methods display better performance than previously known deterministic methods for optimization
of Q.

PACS numbers:

I.

INTRODUCTION

A theoretical foundation for understanding complex net-
works has developed rapidly over the course of the past few
years [2, 3, 4]. More recently, the subject of detecting net-
work communities has gained an large amount of attention,
for reviews see Refs [5, 6]. Community structure describes
the property of many networks that nodes divide into modules
with dense connections between the members of each module
and sparser connections between modules.

In spite of a tremendous research effort, the mathematical
tools developed to describe the structure of large complex net-
works are continuously being reﬁned and redeﬁned. Essential
features related to network structure and topology are not nec-
essarily captured by traditional global features such as the av-
erage degree, degree distribution, average path length, cluster-
ing coefﬁcient, etc. In order to understand complex networks,
we need to develop new measures that capture these structural
properties. Understanding community structures is an impor-
tant step towards developing a range of tools that can provide
a deeper and more systematic understanding of complex net-
works. One important reason is that modules in networks can
show quite heterogenic behavior [7], that is, the link struc-
ture of modules can vary signiﬁcantly from module to module.
For such heterogenic systems, global measures can be directly
misleading. Also, in practical applications of network the-
ory, knowledge of the community structure of a given network
is important. Access to the modular structure of the internet
could help search engines supply more relevant responses to
queries on terms that belong to several distinct communities1.
In biological networks, modules can correspond to functional
units of some biological system [8].

II. THE MODULARITY

This section is devoted to an analysis of the modularity Q.
Identifying communities in a graph has a long history in math-

∗Electronic address: slj@imm.dtu.dk
1 Some search engines have begun implementing related ideas, see for exam-
ple Clusty, the Clustering Engine (http://clusty.com/). There is, however,
still considerable room for improvement.

ematics and computer science [5, 9]. One obvious way to
partition a graph into C communities is distribute nodes into
the communities, such that the number of links connecting the
different modules of the network is minimized. The minimal
number of connecting links is called the cut size R of the net-
work.

Consider an unweighted and undirected graph with n nodes
and m links. This network can be represented by an adjacency
matrix A with elements

Ai j =

(cid:26)

1,
0 otherwise.

if there is a link joining nodes i and j;

(1)

This matrix is symmetric with 2m entries. The degree ki of
node i is given by ki = (cid:229)
j Ai j. Let us express the cut-size in
terms of A; we ﬁnd that

R =

Ai j[1 − d (ci, c j)],

(2)

1
2

i, j

and d (a

, b ) = 0 if a

, b ) = 1 if a = b

where ci is the community to which node i belongs and
d (a
. Minimizing
R is an integer programming problem that can be solved ex-
actly in polynomial time [10]. The leading order of the poly-
nomial, however, is nC2
which very expensive for even very
small networks. Due to this fact, most graph partitioning has
been based on spectral methods (more below).

6= b

Newman has argued [5, 7, 11] that R is not the right quan-
tity to minimize in the context of complex networks. There
are several reasons for this: First of all, the notion of cut-size
does not capture the essence of our ‘deﬁnition’ of network as a
tendency for nodes to divide into modules with dense connec-
tions between the members of module and sparser connections
between modules. According to Newman, a good division is
not necessarily one, in which there are few edges between the
modules, it is one where there are fewer edges than expected.
There are other problems with R: If we set the community
sizes free, minimizing R will tend to favor small communi-
ties, thus the use of R forces us to decide on and set the sizes
of the communities in advance.

As a solution to these problems, Girvan and Newman pro-

pose the modularity Q of a network [1], deﬁned as

Q =

1
2m

i j

[Ai j − Pi j]d (ci, c j).

(3)

(cid:229)
(cid:229)
The Pi j, here, are a null model, designed to encapsulate the
‘more edges than expected’ part of the intuitive network def-
inition. It denotes the probability that a link exists between
node i and j. Thus, if we know nothing about the graph, an ob-
vious choice would be to set Pi j = p, where p is some constant
probability. However, we know that the degree distributions of
real networks are often far from random, therefore the choice
of Pi j ∼ kik j is sensible; this model implies that the proba-
bility of a link existing between two nodes is proportional to
the degree of the two nodes in question. We will make ex-
clusive use of this null model in the following; the properly
normalized version is Pi j = (kik j)/(2m). It is axiomatically
demanded that that Q = 0 when all nodes are placed in one
single community. This constrains the Pi j such that

Pi j = 2m,

i j

(4)

we also note that P = (P)T , which follows from the symmetry
of A.

Comparing Eqs. (2) and (3), we notice that there are two
differences between Q and R. The ﬁrst is that Q implies
that we maximize the number of intra-community links in-
stead of minimizing the the number of inter-community links
as is the case for R—this is the difference between multiply-
ing by d (ci, c j) and [1 − d (ci, c j)]. The second difference lies
in the the introduction of the Pi j in Equation (3). The subtrac-
tion of Pi j serves to incorporate information about the inter-
community links into the quantity we are optimizing.

Use of modularity to identify network communities is
not, however, completely unproblematic. Criticism has been
raised by Fortunato and Barth´elemy [12] who point out that
the Q measure has a resolution limit. This stems from the fact
that the null model Pi j ∼ kik j can be misleading. In a large
network, the expected number of links between two small
modules is small and thus, a single link between two such
modules is enough to join them into a single community. A
variation of the same criticism has been raised by Rosvall and
Bergstrom [13]. These authors point out that the normaliza-
tion of Pi j by the total number of links m has the effect that if
one adds a distinct (not connected to the remaining network)
module to the network being analyzed and partition the whole
network again allowing for an additional module, the division
of the original modules can shift substantially due to the in-
crease of m.

In spite of these problems, the modularity is a highly in-
teresting method for detecting communities in complex net-
works when we assume that the communities are similar in
size. What makes the modularity particularly interesting com-
pared to other clustering methods is its ability to inform us of
the optimal number of communities for a given network2.

2 This ability to estimate the number of communities, however, stems from
the introduction of the Pi j term in the Eq. (3) and is therefore directly linked
to the conceptual problems with Q mentioned in the previous paragraph.

2

(5)

(6)

(7)

III. SPECTRAL OPTIMIZATION OF MODULARITY

The question of ﬁnding the optimal Q is a discrete opti-
mization problem. We can estimate the size of the space we
must search to ﬁnd the maximum. The number of ways to di-
vide n vertices into C non-empty sets (communities) is given
by the Stirling number of the second kind S(C)
[14]. Since we
do not know the number of communities that will maximize
Q before we begin dividing the network, we need to examine
a total of (cid:229) n
community divisions [15]. Even for small
networks, this is an enormous space, which renders exhaustive
search out of the question.

C=2 S(C)

n

n

Motivated by the success of spectral methods in graph par-
titioning, Newman suggests a spectral optimization of Q [11].
We deﬁne a matrix, called the modularity matrix B = A − P
and an (n × C) community matrix S. Each column of S corre-
sponds to a community of the graph and each row corresponds
to a node, such that the elements

Sic =

(cid:26)

1,
0 otherwise.

if node i belongs to community c;

Since each node can only belong to one community, the
columns of S are orthogonal and Tr(ST S) = n. The d -symbol
in Equation (3) can be expressed as

d (ci, c j) =

SikS jk,

C

k=1

which allows us to express the modularity compactly as

Q =

1
2m

n

C

i, j=1

k=1

Bi jSikS jk =

Tr(ST BS)
2m

.

This is the quantity that we wish to maximize.

The next step is the ‘spectral relaxation’, where we relax the
discreteness constraints on S, allowing elements of this matrix
to possess real values. We do, however, constrain the length of
the column vectors by ST S = M, where M is a C × C matrix
with the number of nodes in each community n1, n2, . . . , nC
along the diagonal. In order to determine the maximum, we
take

1
2m

¶ S (cid:18)

Tr[ST BS] + Tr[(ST S − M) ˜L

= 0,

]
(cid:19)

(8)

where ˜L
The maximum is given by

is a C × C diagonal matrix of Lagrange multipliers.

BS = SL

,

(9)

where L = −2m ˜L
for cosmetical reasons. Eq. (9) is a standard
matrix eigenvalue problem. Optimizing in the relaxed repre-
sentation, we substitute this solution into Eq. (7), and see that
in order to maximize Q, we must choose the C largest eigen-
values of B and their corresponding eigenvectors. Since all
rows and columns of B sum to zero by deﬁnition, the vector
(1, 1, . . . , 1)T is always an eigenvector of B with the eigen-
value 0. In general the modularity matrix can have both posi-
tive and negative eigenvalues. It is clear from Eq. (7) that the

(cid:229)
(cid:229)
(cid:229)
(cid:229)
¶
eigenvectors corresponding to negative eigenvalues can never
yield a positive contribution to the modularity. Thus, the num-
ber of positive eigenvalues presents an upper bound on the
number of possible communities.

However, we need to convert our problem back to a discrete
one. This is a non-trivial task. There is no standard way to go
from the n continuous entries in each of the C largest eigenvec-
tors of the modularity matrix and back to discrete 0, 1 values
of the community matrix S. One simple way of circumventing
this problem is to use repeated bisection of the network. This
In New-
is the procedure that Newman [11] recommends.
man’s scheme, the only eigenvector utilized is the eigenvector
corresponding to the largest eigenvalue bmax of B (with high-
est contribution to Q). The 0, 1 vector most parallel to this
continuous eigenvector, is one where the positive elements of
the eigenvector are set to one and the negative elements zero.
This is the ﬁrst column of the community matrix S. The sec-
ond column must contain the remaining elements.

We can increase the modularity iteratively by bisecting the
network into smaller and smaller pieces. However, this re-
peated bisection of the network is problematic. There is no
guarantee that that the best division into three groups can be
arrived at by ﬁnding by ﬁrst determine the best division into
two and then dividing one of those two again. It is straight
forward to construct examples where a sub-optimal division
into communities is obtained when using bisection [7, 16].

Spectral optimization is not perfect—especially when only
the eigenvector corresponding to bmax is employed3. There-
fore, Newman suggests that it should only be used as a start-
ing point. In order to improve the modularity, Newman has
devised an algorithm inspired by the classical Kernighan-Lin
(KL) scheme [17]. The procedure is as follows: After each
bisection of the network we go through the nodes and ﬁnd the
one that yields the highest increase in the modularity of the
entire network (or smallest decrease if no increase is possi-
ble) if moved to the other module. This node is now moved
to the other module and becomes inactive. The next step is to
go through the remaining n − 1 nodes and perform the same
action. We continue like this until all nodes have been moved.
Finally, we go through all the intermediate states and pick the
one with the highest value of Q. This is the new starting divi-
sion. We proceed iteratively from this conﬁguration until no
further improvement can be found. Let us call this optimiza-
tion the ‘KLN-algorithm’.

In the spectral optimization, the computational bottleneck
is the calculation of the leading eigenvector(s) of B, which is
non-sparse. Naively, we would expect this to scale like O(n3).
However, B’s structure allows for a faster calculation. We can

3 Newman has proposed a scheme that utilizes two eigenvectors of the mod-
ularity matrix corresponding to the two highest eigenvalues [7] that—
according to our experiments—performs slightly better than the single
eigenvector method described above. However, after the application of
the KLN-algorithm described in this section, we found no difference in the
results found by using one or two eigenvectors.

3

(10)

write the product of B and a vector v [11] as

Bv = Av −

k(kT v)
2m

.

This way we have a divided the multiplication into (i) sparse
matrix product with the adjacency matrix that takes O(m + n),
and (ii) the inner product kT v that takes O(n). Thus the entire
product Bv scales like O(m+ n). The total running for a bisec-
tion determining the eigenvector(s) is therefore O((m + n)n)
rather than the naive guess of O(n3). Using Eq. (10) during the
KLN-algorithm reduces the cost of this step to O((m + n)n)
[11].

IV. MEAN FIELD OPTIMIZATION

Simulated annealing was proposed by Kirkpatrick et
al. [18] who noted the conceptual similarity between global
optimization and ﬁnding the ground state of a physical system.
Formally, simulated annealing maps the global optimization
problem onto a physical system by identifying the cost func-
tion with the energy function and by considering this system
to be in equilibrium with a heat bath of a given temperature
T . By annealing, i.e., slowly lowering the temperature of the
heat bath, the probability of the ground state of the physical
system grows towards unity. This is contingent on whether
or not the temperature can be decreased slowly enough such
that the system stays in equilibrium, i.e., that the probability
is Gibbsian

P(S|T ) =

exp

−

Q(S)

=

exp

−

1
Z

1
T

(cid:18)

1
Z

(cid:19)

Tr(ST BS)
2m

.

(cid:19)

(cid:18)

(11)
Here, Z is a constant ensuring proper normalization. Kirk-
patrick et al. realized the annealing process by Monte Carlo
sampling. The representation of the constrained modularity
optimization problem is equivalent to a C-state Potts model.
Gibbs sampling for the Potts model with the modularity Q as
energy function has been investigated by Reichardt and Born-
holdt, see e.g., [16].

Mean ﬁeld annealing is a deterministic alternative to Monte
Carlo sampling for combinatorial optimization and has been
pioneered by Peterson et al. [19, 20]. Mean ﬁeld anneal-
ing avoids extensive stochastic simulation and equilibration,
which makes the method particularly well suited for optimiza-
tion. There is a close connection between Gibbs sampling and
MF annealing. In Gibbs sampling, every variable is updated
by random draw of a Potts state with a conditional distribu-
tion,

P(Si1, ..., SiC|S{−i}, T ) =

P(S|T )
(cid:229) Si1,...,SiC P(S|T )

,

(12)

where the sum runs over the C values of the i’th Potts variable
and S{−i} denotes the set of Potts variables excluding the i’th
node. As noted by [16], Eq. (12) is local in the sense that the
part of the energy function containing variables not connected
with the i’th cancels out in the fraction. The mean ﬁeld ap-
proximation is obtained by computing the conditional mean

of the set of variables coding for the i’th Potts variable using
Eq. (12) and approximating the Potts variables in the condi-
tional probability by their means [20]. This leads to a simple
self-consistent set of non-linear equations for the means,

µik =

ik/T )

exp(f
k′=1 exp(f
(cid:229) C

ik′ /T )

,

ik = (cid:229)

j

Bi jµ jk.

(13)

For symmetric connectivity matrices with (cid:229)
j Bi j = 0, the set
of mean ﬁeld equations has the unique high-temperature so-
lution µik = 1/C. This solution becomes unstable at the mean
ﬁeld critical temperature, Tc = bmax/C, determined by the
maximal eigenvalue bmax of B.

This mean ﬁeld algorithm is fast. Each synchronous itera-
tion (see Section VI for details on implementation) requires a
multiplication of B by the mean vector µ. As we have seen,
this operation can be performed in O(m + n) time using the
trick in Eq. (10). In these experiments, we have used a ﬁxed
number of iterations of the order of O(n), which gives us a to-
tal of O((m + n)n) similar to the case of by spectral optimiza-
tion. (A forthcoming paper discusses the relationship between
Gibbs sampling, mean ﬁeld methods, and computational com-
plexity.)

V. A SIMPLE NETWORK

We will perform our numerical experiments on a simple
model of networks with communities. This model network
consists of C communities with nc nodes in each, the total
network has n = ncC nodes. Without loss of generality, we
can arrange our nodes according to their community; a sketch
of this type of network is displayed in Figure 1. Communities

p

q

...

q

· · ·

q

nc

(cid:27)

q

p

. . .

p

|

n
{z

}

FIG. 1: A sketch of the simple network model. The ﬁgure displays
the structure of the adjacency matrix with nodes arranged according
to community. Inside each community (the blocks) along the diag-
onal, the probability of a link between two nodes is p and between
communities, the probability of a link is q.

are deﬁned as standard random networks, where the probabil-
ity of a link between two nodes is given by p, with 0 < p ≤ 1.
Between the communities the probability of a link between is

given by 0 ≤ q < p. The networks are unweighted and undi-
rected.

Let us calculate Q for this network in the case where p = 1
and q = 0. In this case, we can calculate everything exactly.
First, we note that all nodes have the same number of links,
and that the degree of node i, ki = nc − 1 (since a node does
not link to itself). Thus the total number of links mc in each
sub-network is

mc =

nc(nc − 1),

(14)

1
2

and since our network consists of C identical communities the
total number of links is m = Cmc. We can now write down the
contribution Qc from each sub-network to the total modularity

Qc =

(Ai j − Pi j)d (c, c)

=

nc(nc − 1) − n2
c

(nc − 1)2

.

2m (cid:21)

1
2m

i j

1
2m (cid:20)

If we insert m and use that Q = CQc, we ﬁnd

Q = CQc = 1 −

1
C

.

We see explicitly that when C → ¥
unity.

the modularity approaches

Now, let us examine at the general case. Since our network
is connected at random, we cannot calculate the number of
links per node exactly, but we know that the network is well-
behaved (Poisson link distribution), thus we can calculate the
average number of links per node. We see that

k = (nc − 1)p + nc(C − 1)q,

(18)

which is equal to the number of expected intra-community
links plus the number of expected number of inter-community
links. The number of links in the entire network is therefore
given by

m =

Cnck =

[(nc − 1)p + nc(C − 1)q].

(19)

1
2

Cnc
2

We write down Q

Q =

nc(nc − 1)p − n2
c

C
2m (cid:20)

{(nc − 1)p + nc(C − 1)q}2
2m

(cid:21)

=

(nc − 1)p
(nc − 1)p + nc(C − 1)q

−

1
C

.

When nc ≫ 1 (which is always the case), we have that

Q =

p
p + q(C − 1)

−

1
C

,

When we write q as some fraction f of p, that is q = f p, with
0 ≤ f ≤ 1, we ﬁnd

Q(C, f ) =

1
1 + (C − 1) f

−

1
C

,

4

(15)

(16)

(17)

(20)

(21)

(22)

f
(cid:229)
Eq. (21) with C = 5
Mean Q of 100 realizations

Q

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

0.2

0.4

0.6

0.8

1

f

FIG. 2: Equation (22) and Qdesign. This ﬁgure displays Q as a func-
tion of f (the relative probability of a link between communities),
with C = 5 for the simple network deﬁned in Figure 1. The blue line
is given by Eq. (22) and the black dots with error-bars are mean val-
ues of Qdesign in realizations of the simple network with p = 1/10
and n = 500; each data-point is the mean of 100 realizations. The
error bars are calculated as the standard deviation divided by square
root of the number of runs.

which is independent of p. Thus, for this simple network,
the only two relevant parameters are the number of commu-
nities and the density of the inter-community links relative to
the intra-community strength. We can also see that our result
from Eq. (17) is valid even in the case p < 1, as long as the
communities are connected and q = 0.

If we design an adjacency matrix according to Figure 1, we
can calculate the value Qdesign = Tr(ST
d BSd)/(2m), where Sd
is a community-matrix that reﬂects the designed communities.
Values of Qdesign should correspond to Eq. (22). We see in
Figure 2 that this expectation is indeed fulﬁlled. The blue
curve is Q as a function of f with C = 5. The black dots
with error-bars are mean values of Qdesign in realizations of
the simple network with p = 1/10 and n = 500; each data-
point is the mean of 100 realizations and the error bars are
calculated as the standard deviation divided by square root of
the number of runs. The correspondence between prediction
and experiment is quite compelling.

We should note, however, that the value of Qdesign may
be lower than the actual modularity found for the network
by a good algorithm: We can imagine that ﬂuctuations of
the inter-community links could result in conﬁgurations that
would yield higher values of Q—especially for high values of
f . We can quantify this quite precisely. Reichardt and Born-
holdt [16] have shown that demonstrated that random net-
works can display signiﬁcantly larger values of Q due to ﬂuc-
tuations; when f = 1, our simple network is precisely a ran-
dom network (see also related work by Guimer`a et al. [21]).
In the case of the network we are experimenting on, (n = 500,
p = 1/10), they predict Q ≈ 0.13.

Thus, we expect that the curve for Q( f ,C) with ﬁxed C will
be deviate from the Qdesign displayed in Figure 2; especially
for values of f that are close to unity. The line will decrease
monotonically from Q(0,C) = 1 − 1/C towards Q(1,C) =
0.11 with the difference becoming maximal as f → 1.

5

VI. NUMERICAL EXPERIMENTS

We know that the running time of mean ﬁeld method scales
like that of the spectral solution. In order to compare the pre-
cision of the mean ﬁeld solutions to the solutions stemming
from spectral optimization, we have created a number of test
networks with adjacency matrices designed according to Fig-
ure 1. We have created 100 test networks using parameters
nc = 100, C = 5, p = 0.1 and f ∈ [0, 1]. Varying f over this
interval allows us to interpolate between a model with C dis-
junct communities and a random network with no community
structure.

We applied the following three algorithms to our test net-

works

1. Spectral optimization,

2. Spectral optimization and the KLN-algorithm, and

3. Mean ﬁeld optimization.

Spectral optimization and the KLN-algorithm were imple-
mented as prescribed in [11]. The nC non-linear mean ﬁeld
annealing equations were solved approximately using a D =
300-step annealing schedule linear in b = 1/T starting at b c
and ending in 3b c at which temperature the majority of the
mean ﬁeld variables are saturated. The mean ﬁeld critical
temperature Tc = bmax/C is determined for each connectivity
matrix. The synchronous update scheme deﬁned as parallel
update of all means at each of the D temperatures

µ(d+1)
ik

=

ik = (cid:229)
f (d)

j

exp(f (d)
ik /T )
k′=1 exp(f (d)
(cid:229) C
Bi jµ(d)
jk

ik′ /T )

(23)

can grow unstable at low temperatures. A slightly more ef-
fective and stable update scheme is obtained by selecting ran-
dom fractions r < 1 of the means for update in 1/r
steps at
each temperature. We use r = 0.2 in the experiments reported
below. A ﬁnal T = 0 iteration, equivalent to making a deci-
sion on the node community assignment, completes the pro-
cedure. We do not assume that actual the number of commu-
nities C < Cmax is known in advance. In these experiments we
use Cmax = 8. This number is determined after convergence
by counting the number of non-empty communities

The results of the numerical runs are displayed in Fig-
ure 3. This ﬁgure shows the point-wise differences between
the value of Qalgorithm found by the algorithm in question and
Qdesign plotted as a function of the inter-community noise f .
The line of Qalgorithm − Qdesign = 0 thus corresponds to the
curve plotted in Figure 2. We see from Figure 3 that the mean
ﬁeld approach uniformly out-performs both spectral optimiza-
tion and spectral optimization with KLN post-processing. We
also ran a Gibbs sampler [16] for with a computational com-
plexity equivalent to the mean ﬁeld approach. This lead to
communities with Q slightly lower than the mean ﬁeld re-
sults, but still better than spectral optimization with KLN post-
processing.

Q

theoretical

Spectral
Spectral + Optimization
Mean Field

Q
−

 

 

i

n
g
s
e
d

m
h
t
i
r
o
g
a

l

Q

0.1

0.05

0

−0.05

−0.1

s
e
i
t
i
n
u
m
m
o
C

 
f
o
 
r
e
b
m
u
N
 
n
a
d
e
M

i

7

6

5

4

3

2

1

0

0

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
f

FIG. 3: Comparing spectral methods with the mean ﬁeld solution.
The networks were created according to the simple model, using pa-
rameters nc = 100, C = 5, p = 0.1 and f ∈ [0, 1]. All data points dis-
play the point-wise differences between the value of Qalgorithm found
by the algorithm in question and Qdesign. The error-bars are calcu-
lated as in Figure 2. The dash-dotted red line shows the results for the
spectral method. The dashed blue line shows the results for the spec-
tral optimization followed by KLN post-processing. The solid black
curve shows the results for the mean ﬁeld optimization. The grey,
horizontal line corresponds to the theoretical prediction (Eq. (22))
for the designed communities.

Spectral
Spectral + Optimization
Mean Field

0

0.1

0.2

0.3

0.4

0.6

0.7

0.8

0.9

1

0.5
f

FIG. 4: The median number of communities found by the various
algorithms. The panel shows the median number of communities as
a function of the relative fraction of inter-community links f . All
optimization schemes consistently pick four or ﬁve communities for
the highest values of f . This ﬁnding is consistent with theoretical
and experimental results by Reichardt and Bornholdt [16]

6

We note that the obtained Qalgorithm for a random network
( f = 1) is consistent with the prediction made by Reichardt
and Bornholdt [16]. We also see that the optimization algo-
rithms can exploit random connections to ﬁnd higher values of
Qalgorithm than expected for the designed communities Qdesign.
In the case of the mean ﬁeld algorithm this effect is visible for
values of f as low as 0.2.

Figure 4 shows the median number of communities found
by the various algorithms as a function of f .
It is evident
from Figs. 3 and 4 that—for this particular set of parameters—
the problem of detecting the designed community structure is
especially difﬁcult around f = 0.3. Spectral clustering with
and without the KLN algorithm ﬁnd values Qalgorithm that are
signiﬁcantly lower than Qdesigm. The mean ﬁeld algorithm
manages to ﬁnd a value of Qalgorithm that is higher than the
designed Q but does so by creating extra communities. As
f → 1 it becomes more and more difﬁcult to recover the de-
signed number of communities.

VII. CONCLUSIONS

We have introduced a deterministic mean ﬁeld annealing
approach to optimization of modularity Q. We have evalu-
ated the performance of the new algorithm within a family
of networks with variable levels of inter-community links, f .
Even with a rather costly post-processing approach, the spec-
tral clustering approach suggested by Newman is consistently
out-performed by the mean ﬁeld approach for higher noise
levels. Spectral clustering without the KLN post-processing
ﬁnds much lower values of Q for all f > 0.

Speed is not the only beneﬁt of the mean ﬁeld approach.
Another advantage is that the implementation of mean ﬁeld
annealing is rather simple and similar to Gibbs sampling. This
method also avoids the inherent problems of repeated bisec-
tion. The deterministic annealing scheme is directed towards
locating optimal conﬁgurations without wasting time at care-
ful thermal equilibration at higher temperatures. As we have
noted above, the modularity measure Q may need modiﬁca-
tion in speciﬁc non-generic networks. In that case, we note
that the mean ﬁeld method is quite general and can be gener-
alized to many other measures.

[1] M.E.J. Newman and M. Girvan. Finding and evaluating com-
munity structure in networks. Physical Review E, 69:026113,
2004, cond-mat/0308217.

[2] R. Albert and A.-L. Barab´asi. Statistical mechanics of complex

networks. Reviews of modern physics, 74:47, 2002.

[3] S. N. Dorogovtsev and J. F. F. Mendes. Evolution of networks.

Advances in Physics, 51:1079, 2002.

[4] M. E. J. Newman. The structure and function of complex net-

works. SIAM Review, 45:167, 2003.

[5] M.E.J. Newman. Detecting community structure in networks.

The European Physical Journal B, 38:321, 2004.

[6] L. Danon, J. Duch, A. Diaz-Guilera, and A. Arenas. Compar-
ing community structure identiﬁcation. Journal of Statistical
Mechanics, page P09008, 2005, cond-mat/0505245.

[7] M. E. J. Newman. Finding community structure in networks us-
ing the eigenvectors of matrices. Physical Review E, 74:036104,
2006.

[8] A.-L. Barab´asi and Z. N. Oltvai. Network biology: Understand-

7

ing the cell’s functional organization. Nature Reviews Genetics,
5:101, 2004.

cond-mat/0309508.

[16] J. Reichardt and S. Bornholdt. Statistical mechanics of commu-

[9] F. K. R. Chung. Spectral Graph Theory. American Mathemat-

nity detection. Physical Review E, 74:016110, 2006.

ical Society, 1997.

[10] O. Goldscmidt and D. S. Hochbaum. Polynomial algorithm for
the k-cut problem.
In Proceedings of the 29th Annual IEEE
Symposium on the Foundations of Computer Science, page 444.
Institute of Electrical and Electronics Engineers, 1988.

[11] M. E. J. Newman. Modularity and community structure in net-
works. Proceedings of the National Academy of Sciences, USA,
103:8577, 2006.

[12] S. Fortunato and M. Barthelemy. Resolution limit in commu-

nity detection. 2006, physics/0607100.

[13] M. Rosvall and C. T. Bergstrom. An information-theoretic
framework for resolving community structure in complex net-
works. 2006, physics/0612035.

[14] Mathworld. http://mathworld.wolfram.com/.
[15] M.E.J. Newman.

Fast algorithm for detecting community
structure in networks. Physical Review E, 69:066133, 2004,

[17] B. M. Kernighan and S. Lin. An efﬁcient heuristic procedure for
partitioning graphs. The Bell System Technical Journal, 49:291,
1970.

[18] S. Kirkpatrick, C.D. Gelatt Jr., , and M.P. Vecchi. Optimization

by simulated annealing. Science, 220:671–680, 1983.

[19] C. Peterson and J.R. Anderson. A mean ﬁeld theory learning
algorithm for neural networks. Complex Systems, 1:995–1019,
1987.

[20] C. Peterson and B. S¨oderberg. A new method for mapping op-
Int J Neural Syst,

timization problems onto neural networks.
1:3–22, 1989.

[21] R. Guimer´a, M. Sales-Pardo, and L. A. N. Amaral. Modular-
ity from ﬂuctuations in random graphs and complex networks.
Physical Review E, 70:025101, 2004, cond-mat/0403660.

