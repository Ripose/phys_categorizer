8
9
9
1
 
c
e
D
 
7
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
0
3
0
2
1
8
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

EUROPEAN LABORATORY FOR PARTICLE PHYSICS (CERN)

December 15, 1998

The Signal Estimator Limit Setting Method

Shan Jina,∗, Peter McNamaraa,∗

aDepartment of Physics, University of Wisconsin–Madison, Madison, WI 53706

Abstract

A new method of background subtraction is presented which uses the concept of
a signal estimator to construct a conﬁdence level which is always conservative and
which is never better than e−s. The new method yields stronger exclusions than
the Bayesian method with a ﬂat prior distribution.

(Submitted to Nuclear Instruments and Methods A.)

Corresponding address: CERN/EP Division, 1211 Geneva 23, Switzerland. Tel: (41 22) 767 7364;

fax: (41 22) 782 8370; email: Peter.McNamara@cern.ch, jin@wisconsin.cern.ch.

1 Introduction

In any search, the presence of standard model background will degrade the sensitivity
of the analysis because it is impossible to unambiguously seperate events originating
from the signal process from the expected background events. Although it is possible,
when setting a limit on a signal hypothesis, to assume that all observed events come
from the signal, a search analyzed in this way will only be able to exclude signals which
are signiﬁcantly larger than the background expectation of the analysis. Background
subtraction is a method of incorporating knowledge of the background expectation into
the interpretation of search results in order to reduce the impact of Standard Model
processes on the sensitivity of the search.

The end result of an unsuccessful search is an exclusion conﬁdence for a given signal
hypothesis based on the experimental observation. This conﬁdence level 1−c is associated
with a signal and background expectation and an observation, and is required to be
conservative. A conservative conﬁdence level is one in which the False Exclusion rate, or
probability that an experiment with signal will be excluded, must be less than or equal
to c, where c is called the conﬁdence coeﬃcient.

The classical frequentist conﬁdence level is deﬁned such that this probability is equal
to c.
In the presence of a suﬃciently large downward ﬂuctuation in the background
observation, however, the classical conﬁdence level can exclude arbitrarily small signals.
Speciﬁcally, for suﬃciently large background expectations, it is possible for an observation
to exclude the background hypothesis, in which case, the classical conﬁdence level will
also exclude a signal to which the search is completely insensitive. In order to prevent
this kind of exclusion, and because there is no ambiguity when zero events are observed,
it is required that all methods must default to a conﬁdence level 1 − e−s in order to be
“deontologically correct.” When no events are observed, one should not perform any
background subtraction, and c, the probability of observing zero signal events should be
just e−s. Further, any observation of one or more candidate events should yield a larger
value of c. This correctness requirement can be easily veriﬁed for any method, and any
method which is not deontologically correct should be considered too optimistic.

2 Bayesian Background Subtraction Method

A common method of background subtraction[1], based on computing a Bayesian upper
limit on the size of an observed signal given a ﬂat prior distribution, calculates the conﬁ-
dence level 1 − c in terms of the probabilities that a random repetition of the experiment
with the same expectations would yield a lower number of candidates than the current
observation, which observes nobs. This method computes the background subtracted con-

1

ﬁdence to be

CL = 1 − c = 1 −

P(ns+b ≤ nobs)
P(nb ≤ nobs)

where P(ns+b ≤ nobs) is the probability that an experiment with signal expectation s and
background expectation b yields an equal or lower number of candidates than the current
observation, and P(nb ≤ nobs) is the probability that an experiment with background
expectation b yields an equal or lower number of candidates than the current observation.
When nobs is zero, this method reduces to e−s, demonstrating that it is deontolog-
ically correct. Further, the probability of observing nobs events or fewer is equal to
P(ns+b ≤ nobs), and the conﬁdence coeﬃcient for that observation is strictly larger than
the probability of observing the result, so this method is conservative.

The method can be extended[2] to incorporate discriminating variables such as the
reconstructed mass or neural network output values by constructing a test-statistic ǫ for
the experiment which is some function of those discriminating variables, and constructing
the conﬁdence level as the ratio of probabilities

(1)

(2)

CL = 1 − c = 1 −

P(ǫs+b ≤ ǫobs)
P(ǫb ≤ ǫobs)

.

where P(ǫs+b ≤ ǫobs) is the probability that an independent experiment with signal ex-
pectation s, background expectation b, and some given distributions of discriminating
variables yields a value of ǫ less than or equal to ǫobs seen in the current experiment, and
P(ǫb ≤ ǫobs) is the probability that an independent experiment with background expec-
tation b and some given distributions of discriminating variables yields a value of ǫ less
than ǫobs seen in the current experiment. If the test-statistic is the number of observed
events, this method reduces to the method described above, though the test-statistic can
be constructed as a likelihood ratio or in some other appropriate way such that larger
values of ǫ are more consistent with the observation of a signal than lower values.

For an observation of zero events the probabilities P(ǫs+b ≤ ǫobs) and P(ǫb ≤ ǫobs) are
simply the Poisson probabilities of observing zero events in the two cases. Because a
correctly deﬁned test-statistic has its smallest value when and only when there are no
events observed, the conﬁdence level for the generalized version of this method then
reduces to the same value as the number counting method when there are no events
observed, and it is deontologically correct. Similarly, the probability of observing a more
signal-like test-statistic value is equal to P(ǫs+b ≤ ǫobs), and as P(ǫb ≤ ǫobs) ≤ 1, c is
always greater than or equal to this value, so the method is conservative.

3 Signal Estimator Method

Though the Bayesian method described in Section 2 satisﬁes the criteria set out in Sec-
tion 1, it is not the only background subtraction method which is both conservative and

2

deontologically correct. The Signal Estimator method satisﬁes both of these criteria using
P(ǫs+b ≤ ǫobs) and a boundary condition to calculate the conﬁdence level. The boundary
condition imposes the correctness requirement on the conﬁdence level, while also making
the result conservative.

We wish to determine if a given signal hypothesis s is excluded. If we could know the
observed test-statistic based on events truly from signal only, which we refer to as the
signal estimator (ǫs)obs, the conﬁdence level would be rigorously deﬁned as

CL ≡ 1 − c ≡ 1 − P(ǫs ≤ (ǫs)obs)

where P(ǫs ≤ (ǫs)obs) is the probability that an experiment with signal expectation s
yields a value of the signal estimator less than or equal to (ǫs)obs.

Unfortunately, we cannot directly know (ǫs)obs from an experiment as it is not possible
to unambiguously determine if an event comes from signal or background. We can only
directly know a test-statistic value based on the total observation

Although it is not possible to know (ǫs)obs directly, it is still possible to produce an estimate
of it, with which we can calculate Eq. 3. This is most straightforward for test-statistics
of the form

where ‘⊕’ represents a sum or product. For example, in simple event counting,

ǫobs = (ǫs+b)obs.

ǫs+b = ǫs ⊕ ǫb

ǫ = n

ns+b = ns + nb.

In this case, we can use a Monte Carlo simulation of the background expectation to remove
the background contribution in the observed test-statistic (ǫs+b)obs, i.e., to estimate (ǫs)obs,
and to calculate Eq. 3. In each Monte Carlo experiment, the estimate of (ǫs)obs is deﬁned
as

(ǫs)obs =

ǫobs ⊖ ǫb
(ǫs)min

(

if ǫobs ⊖ ǫb ≥ (ǫs)min
if ǫobs ⊖ ǫb ≤ (ǫs)min

where ‘⊖’ represents diﬀerence or division, and (ǫs)min is the minimum possible value of
the signal estimator, which corresponds to the physical boundary (zero signal events).

The conﬁdence level can be computed with Monte Carlo methods in the following way
for an observed test-statistic ǫobs. First, generate a set a Monte Carlo experiments with
test-statistic values distributed as for experiments with the expected background but no
signal to determine a distribution of possible signal estimator values for the observation

3

(3)

(4)

(5)

(6)
(7)

(8)

(9)

(10)

(11)

(12)

according to Eq. 8. Next, using a sample of Monte Carlo with test-statistics distributed
as for experiments with signal only, and for each possible signal estimator value, calculate

c(ǫobs, ǫb) = P(ǫs ≤ max[ǫobs ⊖ ǫb, (ǫs)min]).

The value of c(ǫobs, ǫb) averaged over all of the signal estimator values determined with
background Monte Carlo forms an estimate of P(ǫs ≤ (ǫs)obs), or

c ≡ P(ǫs ≤ (ǫs)obs) ≈ c(ǫobs, ǫb).

The Monte Carlo procedure described above is very slow, and without generalization,
it can only be used for the class of test-statistics which satisfy Eq. 5. The method can be
generalized into a much simpler mathematical format which can be used for any kind of
test-statistic. The generalization can best be illustrated with an example. In the case of
simple event counting, the boundary condition for the signal estimator can be understood
intuitively. For an observation of nobs events, the conﬁdence level is computed by allowing
the background to vary freely, and according to Eq. 8, the signal estimator will be

(ns)obs =

nobs − nb
0
(

if nobs − nb ≥ 0
if nobs − nb ≤ 0.

Using Eq. 10, one can easily compute the conﬁdence coeﬃcient to be

c = [P(nb = 0) × P(ns ≤ nobs)

+ P(nb = 1) × P(ns ≤ nobs − 1) + . . .
+ P(nb = m) × P(ns ≤ nobs − m) + . . .
+ P(nb = nobs) × P(ns ≤ 0)]
+ P(nb ≥ nobs) × P(ns ≤ 0)
= P(ns+b ≤ nobs) + [1 − P(nb ≤ nobs)] × e−s.

This probability reduces to e−(s+b) + (1 − e−b)e−s = e−s when one observes no candidates,
so it is deontologically correct, and because the conﬁdence level is always strictly greater
than P(ns+b ≤ nobs), it is conservative.

In order to compare the performances of this method with the Bayesian method,
the conﬁdence levels for a simple experiment are analyzed in Fig. 1. For this example,
the analysis is assumed to expect three events from a possible signal, and three events
from Standard Model background processes. For both methods, when zero events are
observed, the conﬁdence level reduces to e−s while for observations of more events, the
signal estimator method yields a lower conﬁdence coeﬃcient, and thus a better exclusion

4

conﬁdence level. For large numbers of events, P(nb ≤ nobs) approaches one, meaning that
both methods approach the classical conﬁdence level and give very similar results.

This method can then be generalized, as the method described in Section 2 was gen-

eralized, to include discriminating variables. The natural generalization takes the form

c = P(ǫs+b ≤ ǫobs) + [1 − P(ǫb ≤ ǫobs)] × e−s.

(13)

For an observation of zero events, the generalized method continues to give a conﬁdence
level e−s, and the conﬁdence level computed with this method is always conservative, with
c strictly greater than P(ǫs+b ≤ ǫobs).

Generating Monte Carlo experiments based on a simpliﬁed Higgs analysis, one can
compare the performances of the generalized Bayesian method described in Section 2 and
the Signal Estimator method. For the comparison it is assumed that there are three
events expected from background processes, with mass distributed uniformly between 70
and 90 GeV/c2, and that the signal process would yield three events, with mass distributed
according to a single Gaussian whose width is 2.5 GeV/c2 centered at 80 GeV/c2. Using
the test-statistic described in ref. [3], Fig. 2 shows the relative improvement in conﬁdence
level for this experiment. The Signal Estimator method is seen to never a worse conﬁdence
level than the generalized Bayesian method. For an observation of zero candidates, and for
very signal-like observations (as P(ǫb ≤ ǫobs) approaches one) the methods converge. In
the region in between these extremes, the Signal Estimator method gives conﬁdence levels
up to 20% better than the generalized Bayesian method while remaining conservative.

More than one method of calculating background subtraction conﬁdence levels which is
conservative and deontologically correct exist. The Signal Estimator method proposed
here yields less conservative limits than the Bayesian method, which should result in an
increase in search senstitivity, giving better limits in unsuccessful searches.

Conclusion

References

[1] O. Helene, Nucl. Instr. and Meth. 212 (1983) 319.

[2] LEP Higgs working group, CERN/LEPC 97-11 (1997).

[3] J.-F. Grivaz and F. Le Diberder, NIM A333 (1993) 320.

5

1

t
n
e
i
c
i
f
f
e
o
C
 
e
c
n
e
d
i
f
n
o
C

-1

10

-2

10

Bayesian Method

SE Method

0

2

4

6

8

10
Nobs

Figure 1: A comparison of Signal Estimator method performance to the Bayesian method
performance. For an experiment with three signal and three background events expected,
the conﬁdence levels are shown for diﬀerent numbers of observed events. The Signal Esti-
mator method gives either an equal or better conﬁdence level for all possible observations.

6

0.3

0.2

s
e
y
a
B
C

/
)

E
S
C

-

s
e
y
a
B
C

(

0.1

0

0

0.2

0.4

0.6

0.8

1
CBayes

Figure 2: A comparison of Signal Estimator method performance to the Bayesian method
performance when discriminating variables are used. The Monte Carlo experiments as-
sume three signal and three background events are expected, and the single discriminating
variable has a Gaussian distribution with width 2.5 GeV/c2 for signal, ﬂat for background
over a range of 20 GeV/c2. The relative improvement in conﬁdence level using the Signal
Estimator method is shown for diﬀerent conﬁdence level values.

7

