Conﬁdence Intervals with Frequentist Treatment of Statistical

and Systematic Uncertainties

Wolfgang A. Rolke,1 Angel M. L´opez,2 and Jan Conrad3

1Department of Mathematics, University of Puerto Rico - Mayag¨uez,

Mayag¨uez, PR 00681, USA, Postal Address: PO Box 5959, Mayag¨uez,

PR 00681, Tel: (787) 255-1793, Email: wolfgang@puerto-rico.net
2Department of Physics, University of Puerto Rico - Mayag¨uez, Mayag¨uez, PR 00681, USA
3PH-Department, CERN, CH-1211, Geneva 23, Switzerland.

Abstract

We discuss a general methodology called proﬁle likelihood for the treatment of nuisance parame-

ters, especially for the problem of setting limits. The method is fully frequentist and is applied here

to the case of a Poisson signal process in the presence of background and eﬃciency, both of which

can have uncertainties. We show that the method has correct coverage in all cases considered.

Routines performing the necessary calculations are available as stand-alone FORTRAN routines

or within the analysis framework ROOT.

PACS numbers: 06.20.Dk, 02.50.-r,05.10.Ln

Keywords: Maximum likelihood, proﬁle likelihood, conﬁdence regions, coverage, Monte Carlo

4
0
0
2
 
r
a

M
 
9
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
9
5
0
3
0
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

1

I.

INTRODUCTION

The treatment of nuisance parameters has long been an open problem in the statistical

analysis of high energy physics data. It has been felt that it poses a problem especially if one

wants to stay within the framework of Frequentist statistics. In a Bayesian analysis nuisance

parameters are usually dealt with by integration, which provides a consistent methodology

for the treatment of nuisance parameters but, as always with Bayesian statistics, requires the

introduction of prior distributions. In this paper we will argue that nuisance parameters can

be handled just as easily within a frequentist framework. We will use the method of proﬁle

likelihood to deal with nuisance parameters. For the problem of setting conﬁdence limits

for the signal rate in the presence of background, which is estimated from data sidebands or

Monte Carlo, this has previously been shown in Rolke and L´opez [1] to work quite well. The

same problem but with the assumption of a known background rate and therefore without

nuisance parameters was also discussed in Feldman and Cousins [2].

II. PROFILE LIKELIHOOD

In this section we will outline the basic idea of the proﬁle likelihood, using as an example

the problem of setting limits in the case of a rare decay search with an unknown background

rate. We will need the following notation. Assume that we observe x events in a suitably

chosen signal region and a total of y events in the background region. Here the background

region can be chosen fairly freely and need not be contiguous. Furthermore, the probability

that a background event falls into the background region divided by the probability that it

falls into the signal region is denoted by τ . For example, if we use two background regions

of the same size as the signal region and assume the background distribution is ﬂat we get

τ = 2. If the background rate is estimated from Monte Carlo, τ is the size of the Monte

Carlo sample relative to the size of the data sample. Then a probability model for the data

is given by

X ∼ P ois(µ + b),

Y ∼ P ois(τ b)

where µ is the signal rate, b is the background rate and P ois is the usual Poisson distribution.

We will use large caps letters X, Y, .. to denote random variables and small caps letters

x, y, , ..to denote realizations (observed values) of these random variables. We can assume

2

X and Y to be independent and so

Pµ,b(X = x, Y = y) =

(µ + b)x
x!

e−(µ+b) ·

(τ b)y
y!

e−τ b

Conﬁdence intervals are often found by deriving an appropriate hypothesis test, and then

inverting the test. In the situation here the test is

H0 : µ = µ0 vs. HA : µ 6= µ0

for some unspeciﬁed number µ0. A popular test in Statistics for any kind of hypothesis is

the likelihood ratio test, which is based on the likelihood ratio test statistic Λ given in our

problem by:

Λ(µ0; x,y) =

max {L(µ0, b; x, y) : b ≥ 0}
max {L(µ, b; x, y) : µ ≥ 0, b ≥ 0}

Here L(µ, b; x, y) = Pµ,b(X = x, Y = y) is the likelihood function of µ and b given the

observation (x, y). This test statistic can be thought of as the ratio of the best explanation

for the data if H0 is true and the best explanation for the data if no assumption is made

on µ. The denominator is simply the likelihood function evaluated at the usual maximum

likelihood estimator. To ﬁnd the numerator we have to ﬁnd the maximum likelihood esti-

mator of the background rate b assuming that the signal rate is known to be µ0. For this

we will use l(µ0, b; x, y) = 2 log L(µ0, b; x, y). The factor of 2 as usual is used to make the

loglikelihood comparable to the χ2 distribution. By diﬀerentiation we ﬁnd

∂
∂b

l(µ0, b; x, y) =

x
µ0 + b

− 1 +

− τ

.
= 0

y
b

which can be solved to yield

ˆb(µ0) =

x + y − (1 + τ )µ0 + q(x + y − (1 + τ )µ0)2 + 4(1 + τ )yµ0
2(1 + τ )

pl(µ) = l(µ, ˆb(µ); x, y) is called the proﬁle likelihood function of µ. It is not always possible
to ﬁnd ˆb(µ0) analytically, in which case numerical methods need to be used.

For more details on the likelihood ratio test statistic see Casella and Berger [3]. For

information on the proﬁle likelihood see Bartlett [4], Lawley [5] and Murphy and Van Der

Vaart [6].

3

III. EXTRACTING LIMITS

Limits can be derived from the proﬁle likelihood curve in the same manner as from

ordinary likelihoods, namely by observing the drop from the maximum. Figure 1 shows the

proﬁle likelihood function for the case x = 8, y = 15, τ = 5. To ﬁnd a (1 − α) · 100%

conﬁdence interval we start at the maximum, which of course is at the usual maximum

likelihood estimator, and then move to the left and to the right until the function decreases

by the α percentile of a χ2 distribution with 1 degree of freedom.

In the cases where fewer events are observed in the signal region than are expected from

background the proﬁle likelihood curve, just like the regular likelihood, is no longer parabolic.

In the most extreme case, x = 0, it even becomes linear. In Rolke and L´opez [1] we dealt

with this problem by using a hypothesis test based on the null hypothesis H0 : µ = µ0, b = b0,

deriving the corresponding two-dimensional acceptance region and then ﬁnding the values
of µ where the proﬁle likelihood (cid:16)µ, ˆb(µ)(cid:17) enters and leaves the acceptance region. A similar
method could be used in general. However, as we will see in section 5, ignoring the non-

parabolic nature of the proﬁle likelihood curve does not aﬀect the coverage of the method

in any appreciable way and is computationally much faster. We recommend to simply use

the standard method described above.

IV.

INCLUDING EFFICIENCY AND OTHER EXTENSIONS

The general nature of the proﬁle likelihood technique for dealing with nuisance parameters

can be illustrated by considering several modiﬁcations and extensions of the problem as laid

out in the previous paragraphs. For example, say we want to include the eﬃciency e into

our limits. Assume that we are Monte Carlo limited and therefore have to deal with the

error in the eﬃciency estimate. Speciﬁcally, say we run m events through our Monte Carlo

(without background) and ﬁnd z events surviving Then we can model the eﬃciency Z as a

binomial random variable and ﬁnd the complete model to be

X ∼ P ois(eµ + b),

Y ∼ P ois(τ b),

Z ∼ Bin(m, e)

4

where Bin is the binomial distribution. To ﬁnd the proﬁle likelihood we have to diﬀerentiate

the loglikelihood:

∂
∂b

∂
∂e

log l(µ, b, e; x, y, z) =

x
eµ + b

− 1 +

− τ

.
= 0

y
b

log l(µ, b, e; x, y, z) =

x
eµ + b

− µ +

−

z
e

m − z
1 − e

.
= 0

This system of nonlinear equations can not be solved analytically but for each value of µ we

can do so numerically, and again we have the proﬁle likelihood curve as a function of the

signal rate µ alone.

As a second example, suppose that the background and the eﬃciency are better modeled

as Gaussians rather than using the Poisson and the Binomial, for example, to allow the

inclusion of systematic errors. Then we ﬁnd the model

X ∼ P ois(eµ + b),

Y ∼ N(b, σb),

Z ∼ N(e, σe)

where N indicates the Gaussian (or normal) distribution and σb and σe are the standard

deviations or errors on the estimates of b and e, respectively. Now we ﬁnd the derivatives

of the loglikelihood to be

∂
∂b

∂
∂e

log l(µ, b, e; x, y, z) =

− 1 +

x
eµ + b

x
eµ + b

(y − b)
σb

.
= 0

(z − e)
σe

.
= 0

log l(µ, b, e; x, y, z) =

− µ +

This system can actually be solved explicitly:.

t1 = µ2σ2

e + σ2
b

t2 = µ3σ4

e + µσ2

b σ2

e − µ2σ2

e z + µσ2

e y − 2σ2
b z

e yz + σ2

b z2

t3 = µ2σ4

e (y − x) − µσ2
−t2 +

e(µ) =
b
b(µ) =
b

y − σ2

e σ2
b z − µσ2
t2
2 − 4t1t3
p
2t2
b (z −
σ2
e µ

e(µ))
b

5

All combinations of the above models, for example the background modeled as a Poisson

and the eﬃciency modeled as a Gaussian, are equally easily treated.

V. PERFORMANCE OF THIS METHOD

In the case of conﬁdence intervals, performance means ﬁrst of all coverage, that is, a

nominal 90% conﬁdence interval should cover the true value of the parameter 90% of the

time for all parameter values. Coverage studies for the case of a Poisson model for the signal

and a Poisson model for the background have previously been published in Rolke and L´opez

[1]. For the case of an added eﬃciency modeled as a Binomial (discussed above), consider

the following coverage study: In the ﬁrst panel of ﬁgure 2 we vary the signal rate from 0.1

to 10 in steps of 0.1. The background rate is ﬁxed at b = 3.0 with τ = 5.0 and the eﬃciency

is e = 0.9 and m = 100. We show 68%, 90%, 95% and 99% conﬁdence intervals. In the

second panel we vary the background rate from 0 to 10 in steps of 0.1, with τ = 5.0. The

signal rate is ﬁxed at µ = 2.5 and the eﬃciency is e = 0.9 with m = 100. In the last panel

we vary the eﬃciency from 0.2 to 0.8 in steps of 0.006. The signal rate is ﬁxed at µ = 2.5

and background rate is ﬁxed at b = 3.0 with τ = 5.0.

In each case the method has very nearly the exact nominal coverage although it under-

covers by a very small amount. For example, in the 297 coverage studies shown in ﬁgure 2

for each nominal coverage rate the average true coverage at the nominal 68% level is 67.1%

and at the 90% level it is 89.3%. The worst case is a true coverage of 0.662 at the nominal

68% level. This small undercoverage is mostly due to the fact that we are not using the ex-

act two-dimensional hypothesis test in the case of fewer events in the signal region than are

expected from background alone. We see also that these coverage graphs are considerably

smoother with much less overcoverage than those shown in Rolke and L´opez [1] for both

the uniﬁed method by Feldman and Cousins as well as the method described there, which

is because of the higher randomness due to the extra random variable Z for the eﬃciency.

In ﬁgure 3 we have the coverage graphs for the case of a signal rate modeled as a Poisson

and both the background and the eﬃciency modeled as Gaussians. Speciﬁcally we have

µ = 2.5, b = 3.0, τ = 5.0, σb = 0.8, e = 0.9 and σe = 0.03. The graphs have a very similar

appearance to those in ﬁgure 2. Extensive coverage studies involving all combinations of the

models discussed above have shown these results to be quite general.

In ﬁgure 4 we show the behavior of the limits as functions of the uncertainties in back-

ground (left panel) and eﬃciency (right panel). The limits are for the case x = 5, y = 3,

z = 0.5, and we model both the background and the eﬃciency as Gaussians. In the left

6

panel we vary the uncertainty in the background rate from 0.0 to 1.0 with the uncertainty in

the eﬃciency ﬁxed at 0.1. In the right panel we vary the uncertainty in the eﬃciency from

0.0 to 0.15 with the uncertainty in the background rate ﬁxed at 0.75. As we can see the

behavior of the limits here is what one expects: the larger the uncertainty the higher the

limit.

VI. COMPARISON WITH OTHER METHODS

In ﬁgure 4 we have also included the corresponding limit from Feldman and Cousins’

uniﬁed method which ignores any uncertainties. Clearly those limits and limits found by

the proﬁle likelihood method are somewhat diﬀerent. It would of course be desirable if the

two methods yielded similar limits in similar situations, that is, when the errors on the

observed background rate and the eﬃciency are very small. Unfortunately this is not the

case; the limits can diﬀer by as much as 20%. Although counterintuitive at ﬁrst, this is

in fact not surprising. There are many examples in Statistics of methods for conﬁdence

intervals for the exact same problem that yield slightly diﬀerent limits although all have

correct coverage. As an example, consider the case of estimating the rate of a Poisson

distribution without any complicating factors such as background. Casella and Berger [3]

discuss several conﬁdence intervals for the Poisson mean, among them a method based on an

identity linking the Poisson and the gamma distributions as well as a large sample method

based on the central limit theorem. A discussion of several other methods is given in Dobson

et al [7]. Intervals which are robust against departures from the Poisson assumption can be

based on the statistical bootstrap as described in Efron and Tibshirani [8].

The fact that the intervals can be diﬀerent is not a surprise since the only requirement

for conﬁdence intervals is coverage. Thus, if using method A we ﬁnd an interval which is

shorter than the one found by method B in one physical condition, it will be the reverse

in another physical condition. Obviously, a method A can not yield shorter intervals than

method B in all physical conditions, since this would violate the requirement that both have

correct coverage.

If an experimenter has a choice between several methods for computing limits, he can

take other considerations into account. For example he might prefer a method that always

yields limits within the physical region. Or he might prefer a method that on average yields

7

shortest intervals for the range of parameter values that he expects. He might use a method

because it yields strictly increasing limits for higher values of the data.

It is, of course,

important to remember that the experimenter has to decide what method to use before

seeing the data and not based on his speciﬁc observations.

Thus even methods designed for the exact same problem yield diﬀerent results. The

question at hand however is quite diﬀerent: the methods are designed for diﬀerent physical

problems, depending on whether it is known a priori what the background rate is, or whether

it was estimated. It is therefore not surprising that they yield slightly diﬀerent limits. The

correct way to proceed is to use the method designed for the situation at hand:

if the

background rate and the eﬃciency are known a priori, use Feldman and Cousins’ uniﬁed

method. If the background rate has been estimated from the data (or via Monte Carlo) but

the eﬃciency is known a priori, use the method described in Rolke and L´opez [1]. If both

the background rate and the eﬃciency have been estimated, use the method described here.

It is the only one currently known that has been shown to have correct coverage in all these

situations.

VII. CONCLUSION

We have discussed the method of proﬁle likelihood as a general treatment of nuisance pa-

rameters within a frequentist framework. The computations are reasonably straightforward

and lead to conﬁdence intervals whose coverage diﬀers negligibly from the nominal.

A

FORTRAN

routine

for

computing

these

limits

is

available

at

http://charma.uprm.edu/˜rolke/publications.htm. It is also available as part of ROOT [9].

VIII. ACKNOWLEDGEMENTS

J.C. would like to thank R. Brun for support with ROOT and G. Stefanini for his patience.

This work was supported by the Division of High Energy Physics (Grant DE-FG-97ER41045)

8

of the US Department of Energy and the University of Puerto Rico.

[1] W.A. Rolke, A.M. L´opez, “Conﬁdence Intervals and Upper Bounds for Small Signals in the

Presence of Background Noise”, Nucl. Inst. and Methods A458 (2001) 745-758.

[2] R.D. Cousins, G.J. Feldman, “A Uniﬁed Approach to the Classical Statistical Analysis of Small

Signals”, Phys. Rev, D57, (1998) 3873.

[3] G. Casella, R.L. Berger, Statistical Inference, Duxburry Press, (1990) 346.

[4] M.S. Bartlett, “Approximate Conﬁdence Intervals, Part II: More than one Unknown Parame-

ter”, Biometrica Vol. 40, (1953) 306-317.

[5] D.N. Lawley, “A General Method For Approximating To The Distribution Of The Likelihood

Ratio Criteria”, Biometrica Vol. 43, (1956) 295-303.

[6] S.A. Murphy, A.W. Van Der Vaart, “On Proﬁle Likelihood”, Journal of the American Statistical

Association, Vol. 95, (2000), 449-485.

[7] A.J. Dobson, K. Kuulasmaa, E. Eberle, J. Sherer, “Conﬁdence Intervals for Weighted Sums of

Poisson Parameters”, Stat. Med. Vol 10(3) (1991) 457-462

[8] B. Efron, R.J. Tibshirani, An Introduction to the Bootstrap, Chapman & Hall, (1993)

[9] R. Brun and F. Rademakers, “ROOT - An Object Oriented Data Analysis Framework”, Pro-

ceedings AIHENP’96 Workshop, Lausanne, Sep. 1996, Nucl. Inst. & Meth. in Phys. Res. A 389

(1997) 81-86. See also http://root.cern.ch/

IX. APPENDIX

9

d
o
o
h

i
l

i

e
k
L
 
e

l
i
f
o
r
P

9
-

0
1
-

1
1
-

2
1
-

3
1
-

4
1
-

0

2

4

6

8

10

12

14

Signal Rate

FIG. 1: Example of the log proﬁle likelihood curve, for x = 8, y = 15 and τ = 5.0. Using

the standard method we ﬁnd the 95% conﬁdence interval (0.28, 12.02)

10

9
.
0

7
.
0

5
.
0

9
0

.

7
0

.

5
0

.

0

2

8

10

2

4

6

8

10

6
4
Signal Rate

Background Rate

0.2

0.3

0.4

0.6

0.7

0.8

0.5
Efficiency

FIG. 2: 68%, 90%, 95% and 99% coverage graphs when the signal and the background are

modeled as Poisson and the eﬃciency is modeled as a Binomial

9
.
0

7
.
0

5
.
0

11

9
.
0

7
.
0

5
.
0

9
0

.

7
0

.

5
0

.

0

2

8

10

2

4

6

8

10

6
4
Signal Rate

Background Rate

0.2

0.3

0.4

0.6

0.7

0.8

0.5
Efficiency

FIG. 3: 68%, 90%, 95% and 99% coverage graphs when the signal is modeled as a Poisson

and the background and the eﬃciency are modeled as Gaussians.

9
.
0

7
.
0

5
.
0

12

t
i

i

m
L
 
r
e
p
p
U

6
1

5
1

4
1

3
1

Feldman and Cousins Unified Method
Profile Likelihood Method

t
i

i

m
L
 
r
e
p
p
U

6
1

5
1

4
1

3
1

13

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.05

0.10

0.15

Uncertainty in Background

Uncertainty in Efficiency

FIG. 4: Upper limits as a function of the uncertainties. In both graphs the background

and the eﬃciency are modeled as Gaussians. In the left panel we have the case x=5, y=3,

z=0.5, σe=0.1 and the uncertainty in the background goes from 0.0 to 1.0. In the right

panel we have the case x=5, y=3, z=0.5, σb=0.75 and the uncertainty in the eﬃciency

goes from 0.0 to 0.15. We have added the limits derived from Feldman and Cousins uniﬁed

method where we ignore the uncertainties.

