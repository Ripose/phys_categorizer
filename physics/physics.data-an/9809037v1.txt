8
9
9
1
 
p
e
S
 
5
2
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
7
3
0
9
0
8
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

STATE RESEARCH CENTER OF RUSSIA
INSTITUTE FOR HIGH ENERGY PHYSICS

IHEP 98-48

ON OBSERVABILITY OF SIGNAL OVER
BACKGROUND

S.I. Bityukov1 (IHEP, Protvino RU-142284, Russia),
N.V. Krasnikov2 (INR, Moscow 117312, Russia)

Abstract

Several statistics used by physicists to declare the signal observ-
ability over the background are compared. It is shown that the fre-
quentist method of testing a precise hypothesis allows one to estimate
the power value of criteria with speciﬁed level of signiﬁcance for the
considered statistics by Monte Carlo calculations. The application of
this approach for the analysis of discovery potential of experiments is
discussed.

1E-mails: bityukov@mx.ihep.su, Serguei.Bitioukov@cern.ch
2E-mails: krasniko@ms2.inr.ac.ru, Nikolai.Krasnikov@cern.ch

Protvino 1998

Introduction

One of the common tasks for searching experiments is the detection of a
predicted new Phenomenon. As a rule the estimations of an expected mean
Ns for the signal events of new Phenomenon and Nb for the background
events are known. Then we want to know is the given experiment able to
detect new Phenomenon or not. To check the statement about the observa-
tion of Phenomenon a researcher uses some function of the observed number
of events – a statistic. The value of this statistic for detected x events allows
one to ﬁnd the degree of conﬁdence of the discovery statement. After having
drawn a conclusion on the observation of Phenomenon, two possibilities for
mistake are available: to state that Phenomenon is absent but in real life
it exists (Type I error), or to state that Phenomenon exists but it is absent
(Type II error).

In this paper we compare the “signal signiﬁcances” used by the re-
searchers for the hypothesis testing about the observation of Phenomenon:

(a) “signiﬁcance” S1 =

Ns
√Nb

[1],

Ns
√Ns + Nb

(b) “signiﬁcance” S2 =

[2, 3],

(c) “signiﬁcance” S12 = pNs + Nb

pNb [4],

−

(d) likelihood ratio as is deﬁned in references [5, 6].

For this purpose we formulate the null and alternative hypotheses, con-
struct the statistical test, determine the rejection region by Monte Carlo
calculations, make the decision and ﬁnd the power of test for the criteria
with a speciﬁed level of signiﬁcance. We also use an equal-tailed test to
study the behaviour of Type I and Type II errors versus Ns and Nb for
speciﬁed values of S1 and S2. The hypotheses testing results obtained by
Monte Carlo calculations are compared with result obtained by the direct
calculations of probability density functions.

1 Notations

Let us study a physical process during a ﬁxed time. The estimations of
the average number of signal events which indicate new Phenomenon (Ns)

1

and of the average number of background events (Nb) in the experiment are
given. We suppose that the events have the Poisson distributions with the
parameters Ns and Nb, i.e. the random variable ξ
P ois(Ns) describes
P ois(Nb) describes the back-
the signal events and the random variable η
ground events. Say we observed x events – the realization of the studying
process X = ξ+η (x is the sum of signal and background events in the exper-
iment). Here Ns, Nb are reals and x is an integer. The classical frequentist
methods of testing a precise hypothesis allow one to construct a rejection re-
gion and determine associated error probabilities for the following “simple”
hypotheses:
H0 : X

P ois(Ns + Nb) versus H1 : X

P ois(Nb), where P ois(Ns +

∼

∼

∼
(Ns + Nb)x
x!

Nb) and P ois(Nb) have the probability density functions (p.d.f.’s)
e−(Ns+Nb) for the case of presence and f1(x) =
f0(x) =
for the case of absence of signal events in the universe population.

∼

(Nb)x
x!

e−(Nb)

In Fig.1 the p.d.f.’s f0(x) (a) and f1(x) (b) for the case Ns + Nb = 104
and Nb = 53 ([3], Table.13, cut 6) are shown. As is seen the intersection of
these p.d.f.’s takes place. Let us denote the threshold (critical value) that
divides the abscissa in Fig.1 into the rejection region and the area of accepted
hypothesis H0 via Nev. The incorrect rejection of the null hypothesis H0, the
Type I error (the statement that Phenomenon is absent, but it is present),

Nev

X
x=0

∞

has the probability α =

f0(x), and the incorrect acceptance of H0, the

Type II error (the statement that Phenomenon exists, but it is absent), has

the probability β =

X
x=Nev+1
of Nev for above example is presented in Fig.2.

f1(x). The dependence of α and β on the value

2 Hypothesis testing

In this Section we show the procedure of the rejection region construction
for the likelihood ratio [5].

f0(x)
f1(x)

We denote by B(x) =

the likelihood ratio of H0 to H1 in the area

of existing B(X). The decision to either reject or accept H0 will depend on
the observed value of B(x), where small values of B(x) correspond to the
rejection of H0. For the traditional frequentist the classical most powerful
test of the simple hypothesis is determined by some critical value c such that

2

if B(x)
c, reject H0,
if B(x) > c, accept H0.

≤

−

≡

≤

In compliance with this test, the frequentist reports Type I and Type II
c)
error probabilities as α = P0(B(X)
≡
F1(c), where F0 and F1 are cumulative density functions of B(X) under
1
H0 and H1, respectively. For a conventional equal-tailed test with α = β,
the critical value c satisﬁes F0(c)
1

F0(c) and β = P1(B(X) > c)

values c1, c2 and c12, the probabilities α and β for the statistics s1 =

−
In the same way we can construct the rejection region, ﬁnd the critical
x
Nb
−
√Nb
(for “signiﬁcance” S2) and s12 = √x

(for “signiﬁcance” S1), s2 =

−
pNb (for “signiﬁcance” S12). Here, the value of x
Nb is the estimation
of the number of signal events. Note that “signiﬁcance” S12 depends on S1
and S2, namely, S12 =

F1(c).

−
√x

[4].

Nb

≡

−

x

S2
S1 ·
S1 + S2

3 Determination of probability density functions

for statistics

The probability density functions of statistics under consideration can be
is the
obtained in an analytical form. Another way to obtain the p.d.f.
calculations by a Monte Carlo simulation of the results of a large number
of experiments (see as an example [7, 6, 8]) for the given values Ns and Nb.
In this study we use the latter approach. The p.d.f.’s for Ns + Nb = 104
and Nb = 53 obtained by this way are shown in Fig.3 (these distributions
are the result of 105 simulation experiments for random variables ξ and
η). The diﬀerence between these p.d.f.’s and p.d.f.’s resulting from direct
calculations of the probabilities (Fig.1) is extremely small.

In Fig.4 the p.d.f.’s of statistic s2 for the case of Ns = 51, Nb = 53 (a) and
the case of Ns = 0, Nb = 53 (b) are shown. The behaviour of probabilities
α and β versus the critical value c2 for the statistic s2 is also presented in
Fig.4 (c).

It is worth to stress that this approach allows one to construct the p.d.f.’s,
the acceptance and the rejection regions for complicated statistics with ac-
count for the systematic errors and the uncertainties in Nb and Ns estima-
tions.

3

4 Comparison of diﬀerent statistics

−

We compare the statistic s1, the statistic s2, the statistic s12 and the like-
Nb) in our case). The reason for the comparison is the
lihood ratio (B(x
existence of a opinion that the value of such type statistic (s1, s2, s12) char-
acterizes the diﬀerence between the samples with and without signal events
in terms of “standard deviations” (1 σ, 2 σ, . . . , 5 σ) 1. To anticipate a
little, the values of α and β corresponding to these “standard deviations”
depend on the value of the sample and for S1, for example, α and β have a
perceptible value even if Ns and Nb satisfy the condition S1 = 5.

The Type I error α is also called a signiﬁcance level of the test. The
value for β is meaningful only when it is related to an alternative hypothesis
β is referred to as a power function that allows
H1. The dependence 1
one to choose a preferable statistic for the hypothesis testing.
It means
that for the speciﬁed signiﬁcance level we can determine the critical value
c (correspondingly, c1, c2, c12) and ﬁnd the power 1
β of this criterion.
β, the better statistic separates hypotheses for the
The greater the value 1
speciﬁed value of α.

−

−

−

In Table 1 the comparison result is shown. For several values of Ns and
Nb (signiﬁcance level α = 0.01) 2
the critical values c1, c2, c12, c and the
β of these criteria for the statistics s1, s2,
corresponding values of power 1
s12 and the likelihood ratio are presented. As is seen from Table I there is
no visible diﬀerence in the power values for the considered statistics, i.e. we
can use in an equivalent manner either of these statistics for the hypotheses
testing.

−

5 Equal-tailed test

Of concern to us is the question: What is meant by the statement that

S1 =

= 5 or S2 =

Ns
√Nb

Ns
√Ns + Nb

= 5 ?

Tables 2 and 3 give the answer to this question. In Tables 2 and 3 the
values Ns and Nb corresponding to the above condition, the values α and β
determined by applying equal-tailed test (in this study we use the conditions
1If f1(x) is the standard normal distribution, then the 1 σ deviation from 0 corresponds
the area of tail that is equal to 0.1587, 2 σ – 0.0228, 3 σ – 0.00135, 4 σ – 0.000032 and
5 σ – 0.000003.

2The conditions min(0.01 − α) and α ≤ 0.01 are performed.

4

Table 1: The comparison of power of criteria for diﬀerent statistics. The
values c1, c2, c12 and c are the critical values of statistics s1, s2, s12 and like-
β are the power for corresponding
lihood ratio for α = 0.01. The values 1
critical values.

−

statistic:

5

15

10

Ns Nb
10
15
20
25
15
20
25
30
15
20
25
30
20
25
30
35
40
45
50

55

s1
β
1
−
0.762
0.968
0.999
1.000
0.864
0.986
0.999
1.000
0.750
0.947
0.994
0.999
0.535
0.733
0.873
0.963
0.989
0.997
1.000

s2
β
1
−
0.762
0.968
0.999
1.000
0.866
0.986
0.999
1.000
0.747
0.947
0.994
1.000
0.479
0.733
0.874
0.962
0.988
0.998
1.000

s12
β
1
−
0.762
0.968
0.999
1.000
0.865
0.985
0.999
1.000
0.750
0.948
0.994
1.000
0.483
0.735
0.843
0.950
0.988
0.998
1.000

likelihood
c
0.035
0.078
2.563
110.0
0.045
0.269
3.939
307.0
0.040
0.117
0.667
7.795
0.052
0.049
0.074
0.231
0.512
2.894
9.957

ratio
β
1
−
0.760
0.968
0.999
1.000
0.864
0.986
0.999
1.000
0.749
0.947
0.994
1.000
0.536
0.731
0.873
0.962
0.989
0.998
1.000

c12
0.3
0.8
1.4
1.9
0.4
0.9
1.4
1.8
0.2
0.7
1.1
1.5
-0.1
0.2
0.4
0.7
1.0
1.3
1.5

c2
0.75
1.58
2.40
3.06
1.06
1.88
2.55
3.13
0.70
1.49
2.15
2.73
0.00
0.64
1.12
1.68
2.10
2.60
2.98

c1
0.89
2.23
4.02
5.81
1.26
2.52
3.79
5.05
0.77
1.80
2.84
3.87
0.13
0.67
1.21
1.88
2.42
2.96
3.64

−

≤

α) and α

min(β
β) are presented. One can see the dependence of α (or
β) on the value of sample. The case of Ns = 5 and Nb = 1 for S1 (Fig.5) is
perhaps the most dramatic example. We have 5σ deviation, however, if we
reject the hypothesis H0, we are mistaken in 6.2% of cases and if we accept
the hypothesis H0 we are mistaken in 8.0% of cases.

−

One can point out that for a good deal of events the values of α for S1
and S2 approach each other. A simple argument explains such dependence.
Nb has the variation equal to √Ns + Nb for nonzero signal events,
The x
and to √Nb if signal events are absent. Correspondingly, if Nb
Ns,
the contribution of Ns to the variation is very small. Therefore, the stan-
dard deviation tends to unity both for the distribution of s1 (Fig.6) and for
the distribution of s2. It means that for the suﬃciently large Nb, the val-

≫

5

Table 2: The dependence of α and β determined by using equal-tailed test
on Ns and Nb for S1 = 5. The κ is the area of intersection of probability
density functions f0(x) and f1(x).

Ns
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90
95
100
150
500
5000

Nb
1
4
9
16
25
36
49
64
81
100
121
144
169
196
225
256
289
324
361
400
900
104
106

α
0.0620
0.0316
0.0198
0.0141
0.0162
0.0125
0.0139
0.0114
0.0124
0.0106
0.0114
0.0100
0.0106
0.0095
0.0101
0.0091
0.0096
0.0088
0.0081
0.0086
0.0078
0.0068
0.0062

β
0.0803
0.0511
0.0415
0.0367
0.0225
0.0225
0.0164
0.0171
0.0136
0.0143
0.0120
0.0126
0.0109
0.0115
0.0102
0.0107
0.0097
0.0101
0.0106
0.0097
0.0084
0.0068
0.0065

κ
0.1423
0.0828
0.0564
0.0448
0.0383
0.0333
0.0303
0.0278
0.0260
0.0245
0.0234
0.0224
0.0216
0.0209
0.0203
0.0198
0.0193
0.0189
0.0185
0.0182
0.0162
0.0136
0.0125

N

(0, 1) 3 for the pure background and Gaussian

ues of α and β obtained by equal-tailed test have a constant value close to
0.0062. These distributions also can be approximated by a standard Gaus-
(5, 1) for the signal
sian
mixed with the background. Therefore, the equal-tailed test for the normal
distributions gives c1 = 2.5 and α = β = 0.0062. These are the limiting
values of α and β for the requirement S1 = 5 or S2 = 5 (by the way S12
equals 2.5 in this case).

N

In a similar way we can determine the behaviour of the Type I and Type
II errors depending on Ns and Nb for a small number of events and we can

3It is a conventional notation for normal distribution N (mean,variance).

6

Table 3: The dependence of α and β determined by using equal-tailed test
5. The κ is the area of intersection of probability
on Ns and Nb for S2 ≈
density functions f0(x) and f1(x).

Ns Nb
26
29
33
37
41
45
50
55
100
150

1
4
9
16
25
36
49
64
300
750

α
0.519
0.661
0.127
0.426
0.648
0.929
0.133
0.178
0.317
0.445

10−5
10−4
10−3
10−3
10−3
10−2
10−2
10−2
10−2
10−2

·
·
·
·
·
·
·
·
·
·

β
0.102
0.764
0.439
0.567
0.118
0.193
0.185
0.179
0.428
0.450

10−4
10−4
10−3
10−3
10−2
10−2
10−2
10−2
10−2
10−2

·
·
·
·
·
·
·
·
·
·

κ
0.154
0.142
0.440
0.993
0.172
0.262
0.314
0.357
0.735
0.894

10−4
10−3
10−3
10−3
10−2
10−2
10−2
10−2
10−2
10−2

·
·
·
·
·
·
·
·
·
·

predict the limiting values of α and β for a large number of events in case
of other statements about statistic s1 (Table 4) or any other estimator.

Right column in Tables 2, 3 and 4 contains the value of probability κ [4].
The κ is a characteristic of the observability of Phenomenon for the given
Ns and Nb. In particular, it is the fraction of p.d.f. f0(x) for statistic x that
can be described by the ﬂuctuation of background in case of the absence of
Phenomenon. The value of κ equals the area of intersection of probability
density functions f0(x) and f1(x) (Fig.1). Clearly, if we superimpose the
p.d.f.’s f0(x) and f1(x) and choose the intersection point of curves (point
]) as a critical value for the hypotheses testing 4, we have

Nev = [

Ns
ln(1 + Ns
Nb )

α + β. As is seen from Tables 2, 3 and 4 the value of κ is also close to

κ
the sum α + β determined by using the equal-tailed test.

≡

The accuracy of determination of the critical value by Monte Carlo cal-
culations depends on the number of Monte Carlo trials and on the level
of signiﬁcance deﬁned by the critical value. To illustrate, Fig.7 shows the
4Notice that in this point f0(Nev) = f1(Nev) (in our case conditions min(f0(Nev) −
f1(Nev)) and f1(Nev) ≤ f0(Nev) are performed). By this is meant that this checking can
be named as the equal probability test. Of course, if we use the hypotheses testing we
can also determine Nev having found the minimum of the sum of α and β or having found
the minimum of the sum of weighted α and β or having exploited any other condition in
accordance with the requirements of experiment. The κ may be thought of as independing
of these requirements.

7

α + β
2

for the case Ns = 100,
distribution of the estimations of the value
Nb = 500 and for the 105 Monte Carlo trials in each estimation (equal-tailed
test is used). The result obtained via the direct calculations of p.d.f.’s is also
shown in this Figure. Thus, this method is accurate enough to give reliable
results for estimation of the discovery potential of the experiment.

The approach to the determination of the critical region in the hypothe-
ses testing by Monte Carlo calculation of p.d.f.’s can be used to estimate the
integrated luminosity which is necessary for detection the predicted eﬀects
with suﬃcient accuracy. In Fig.8 (a) the dependence of Nev on integrated
luminosity ([3], Table.12, cut.5, mχ1 = 85 GeV, Ns = 45, Nb = 45) is
shown. The corresponding values of α and β are presented in Fig.8 (b). As
104pb−1 is suﬃcient
evident from Figure the integrated luminosity L = 8
to detect sleptons under the requirement that the probability κ
α + β less
than 1%.

≈

·

Conclusion

In this paper the discussion on the observation of new Phenomenon is
restricted to the testing of simple hypotheses in case of the predicted val-
ues Ns and Nb and the observed value x. As is stressed in [5], the precise
hypothesis testing should not be done by forming a traditional conﬁdence
interval and simply checking whether or not the precise hypothesis is com-
patible with the conﬁdence interval. A conﬁdence interval [8] is usually of
considerable importance in determining where the unknown parameter is
likely to be, given that the alternative hypothesis is true, but it is not useful
in determining whether or not a precise null hypothesis is true.

To compare several statistics used for the hypotheses testing, we employ
the method that allows one to construct the rejection regions via the deter-
mination the probability density functions of these statistics by Monte Carlo
calculations. As is shown, the considered statistics have close values of power
for the speciﬁed signiﬁcance level and can be used for the hypotheses testing.
Also it has been shown that the estimations of Type I and Type II errors
obtained by this method have a reasonable accuracy. The method was used
to make the inferences on the observability of some predicted phenomena.

We are indebted to M.Dittmar for useful discussions which were one of
the motivations to perform this study. We are grateful to V.A.Matveev,

Acknowledgments

8

V.F.Obraztsov and V.L.Solovianov for the interest and valuable comments.
We would like to thank E.N.Gorina for the help in preparing the article.

References

[1] as an example,

V.Tisserand, The Higgs to Two Photon Decay in the ATLAS Detector,
Talk given at the VI International Conference on Calorimetry in High
Energy Physics, Frascati (Italy), June 8-14, 1996.

S.I.Bityukov and N.V.Krasnikov, The Search for New Physics by the
Measurement of the Four-jet Cross Section at LHC and TEVATRON,
Modern Physics Letter A12(1997)2011, also hep-ph/9705338.
M.Dittmar and H.Dreiner, LHC Higgs Search with l+νl− ¯ν ﬁnal states,
CMS Note 97/083, October 1997.

[2] as an example,

D.Denegri, L.Rurua and N.Stepanov, Detection of Sleptons in CMS,
Mass Reach, CMS Note CMS TN/96-059, October 1996.

F.Charles, Inclusive Search for Light Gravitino with the CMS Detector,
CMS Note 97/079, September 1997.

S.Abdullin, Search for SUSY at LHC: Discovery and Inclusive Stud-
ies, Presented at International Europhysics Conference on High En-
ergy Physics, Jerusalem, Israel, August 19-26, 1997, CMS Conference
Report 97/019, November 1997.

[3] S.I.Bityukov and N.V.Krasnikov, The Search for Sleptons and Flavour
Lepton Number Violation at LHC (CMS), Preprint IHEP 97-67,
Protvino, 1997, also hep-ph/9712358.

[4] S.I.Bityukov and N.V.Krasnikov, Towards the Observation of Sig-
nal over Background in Future Experiments, Preprint INR 0945a/98,
Moscow, 1998, also physics/9808016.

[5] J.O.Berger, B.Boukai and Y.Wang, Uniﬁed Frequentist and Bayesian

Testing of a Precise Hypothesis, Statistical Science 12(1997)133.

[6] A.L.Read, Optimal Statistical Analysis of Search Results based on the
Likelihood Ratio and its Application to the Search for the MSM Higgs

9

Boson at √s = 161 and 172 GeV, DELPHI 97-158 PHYS 737, 29
October, 1997.

[7] M.A.Stephens, EDF statistics for goodness-of-ﬁt and some compar-

isons, J.Amer.Statist.Assoc., 1974, 69, N 347, p.730.

T.E.Dielman and E.L.Rose, A bootstrap approach to hypothesis testing
in least absolute value regression, Computational Statistics and Data
Analysis, 20, p.119, 1995.

S.I.Bityukov et al., On Production Control of CMS Electromagnetic
Calorimeter, Preprint IHEP 96-77, Protvino, 1996.

[8] G.J.Feldman and R.D.Cousins, A Uniﬁed Approach to the Classical Sta-
tistical Analysis of Small Signals, Preprint HUTP-97/A096, November,
1997, also physics/9711021.

10

Figure 1: The probability density functions f0(x) (a) and f1(x) (b) for
the case of 51 signal events and 53 background events obtained by direct
calculations of the probabilities.

11

Figure 2: The dependence of Type I α and Type II β errors on Nev for the
case of 51 signal events and 53 background events.

12

Figure 3: The probability density functions f0(x) (a) and f1(x) (b) for the
case of 51 signal events and 53 background events obtained by Monte Carlo
simulation.

13

Figure 4: The probability density functions f0(x) (a) and f1(x) (b) of statis-
tic s2. The dependence of Type I and Type II errors on critical value c2 (c)
for the case of 51 signal events and 53 background events.

14

Figure 5: The probability density functions f0(x) (a) and f1(x) (b) of statis-
tic s1. The dependence of Type I and Type II errors on critical value c1 (c)
for the case of 5 signal events and 1 background events.

15

Figure 6: The probability density functions f0(x) (a) and f1(x) (b) of statis-
tic s1. The dependence of Type I and Type II errors on critical value c1 (c)
for the case of 5000 signal events and 106 background events.

16

Table 4: The dependence of α and β determined by using equal-tailed test
on Ns and Nb for S1 = 2, S1 = 3, S1 = 4, S1 = 6 and S1 = 8. The κ is the
area of intersection of probability density functions f0(x) and f1(x).

β
0.265
0.216
0.199
0.188
0.1587
0.263
0.216
0.123
0.131
0.0668
0.263
0.110
0.0735
0.0572
0.0228
0.0806
0.0217
0.0224
0.0132
0.00135
0.0822
0.0081
0.0052
0.00237
0.000032

κ
0.4634
0.4061
0.3817
0.3680
0.3174
0.3184
0.2408
0.2159
0.1952
0.1336
0.2050
0.1406
0.1130
0.0977
0.0456
0.1008
0.0434
0.0271
0.0198
0.0027
0.0402
0.0131
0.00567
0.00331
0.000064

S1 Ns Nb α
2

3

4

6

8

2
4
6
8

1
4
9
16

∞ ∞
1
3
4
6
9
9
16
12

∞ ∞
1
4
4
8
9
12
16
16

∞ ∞
1
6
4
12
9
18
16
24

∞ ∞
1
8
4
16
9
24
16
32

∞ ∞

0.199
0.192
0.184
0.179
0.1587
0.0906
0.0687
0.0917
0.0722
0.0668
0.0400
0.0459
0.0424
0.0407
0.0228
0.0301
0.0217
0.0089
0.00751
0.00135
0.0061
0.0049
0.0016
0.00128
0.000032

17

in the equal-tailed hypotheses testing
Figure 7: The variation of
(Ns = 100, Nb = 500 and Ns = 0, Nb = 500 in 40 Monte Carlo simulations
of probability density functions).

α + β
2

18

Figure 8: The dependence of the critical value Nev (a), Type I and Type II
errors (b) on integrated luminosity L for the case Ns = Nb and Ns = 45 for
L = 105pb−1 (equal-tailed test).

19

