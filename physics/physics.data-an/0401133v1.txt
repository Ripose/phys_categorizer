PHYSTAT2003, SLAC, Stanford, California, September 8-11,2003

1

A Measure of the Goodness of Fit in Unbinned Likelihood Fits; End of
Bayesianism?

Rajendran Raja
Fermilab, Batavia, IL 60510, USA

4
0
0
2
 
n
a
J
 
6
2
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
3
3
1
1
0
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Maximum likelihood ﬁts to data can be done using binned data (histograms) and unbinned data. With binned
data, one gets not only the ﬁtted parameters but also a measure of the goodness of ﬁt. With unbinned data,
currently, the ﬁtted parameters are obtained but no measure of goodness of ﬁt is available. This remains, to
date, an unsolved problem in statistics. Using Bayes’ theorem and likelihood ratios, we provide a method by
which both the ﬁtted quantities and a measure of the goodness of ﬁt are obtained for unbinned likelihood ﬁts,
as well as errors in the ﬁtted quantities. The quantity, conventionally interpreted as a Bayesian prior, is seen in
this scheme to be a number not a distribution, that is determined from data.

1. Introduction

2. Likelihood ratios

As of the Durham conference [1], the problem of
obtaining a goodness of ﬁt in unbinned likelihood ﬁts
was an unsolved one.
In what follows, we will de-
note by the vector s, the theoretical parameters (s for
“signal”) and the vector c, the experimentally mea-
sured quantities or “conﬁgurations”. For simplicity,
we will illustrate the method where both s and c are
one dimensional, though either or both can be multi-
dimensional in practice. We thus deﬁne the theo-
retical model by the conditional probability density
s). Then an unbinned maximum likelihood ﬁt to
P (c
|
data is obtained by maximizing the likelihood [2],

=

L

P (ci|

s)

i=n

Yi=1

(1)

L

where the likelihood is evaluated at the n observed
data points ci, i = 1, n. Such a ﬁt will determine
the maximum likelihood value s∗ of the theoretical
parameters, but will not tell us how good the ﬁt is.
The value of the likelihood
at the maximum like-
lihood point does not furnish a goodness of ﬁt, since
the likelihood is not invariant under change of vari-
able. This can be seen by observing that one can
transform the variable set c to a variable set c′ such
that P (c′
s∗) is uniformly distributed between 0 and
|
1. Such a transformation is known as a hypercube
transformation, in multi-dimensions. Other datasets
will yield diﬀerent values of likelihood in the variable
space c when the likelihood is computed with the orig-
s∗). However, in the original hyper-
inal function P (c
|
cube space, the value of the likelihood is unity regard-
less of the dataset c′
L
cannot furnish a goodness of ﬁt by itself, since neither
the likelihood, nor ratios of likelihoods computed us-
s∗) is invariant under
ing the same distribution P (c
|
variable transformations. The fundamental reason for
this non-invariance is that only a single distribution,
s∗) is being used to compute the goodness
namely, P (c
|
of ﬁt.

i, i = 1, n, thus the likelihood

MOCT003

→ ∞

In binned likelihood cases, where one is comparing
s) with a binned his-
a theoretical distribution P (c
|
togram, there are two distributions involved, the theo-
retical distribution and the data distribution. The pdf
of the data is approximated by the bin contents of the
histogram normalized to unity. If the data consists of
n events, the pdf of the data P data(c) is deﬁned in the
frequentist sense as the normalized density distribu-
. In the binned
tion in c space of n events as n
case, we can bin in ﬁner and ﬁner bins as n
and
obtain a smooth function, which we deﬁne as the pdf
of the data P data(c). In practice, one is always lim-
ited by statistics and the binned function will be an
approximation to the true pdf . We can now deﬁne a
likelihood ratio

LR such that
i=1 P (ci|
s)
Q
i=n
i=1 P data(ci) ≡
where we have used the notation cn to denote the
event set ci, i = 1, n. Let us now note that
LR is
c′,
invariant under the variable transformation c
→
since

P (cn
s)
|
P data(cn)

LR =

→ ∞

(2)

i=n

Q

P (c′

s) =
|

dc
dc′ |

P (c

s)
|

P data(c′) =

P data(c)

|
dc
dc′ |

|

′
R =
L

LR

(3)

(4)

(5)

dc
dc′

|

|

cancels
and the Jacobian of the transformation
in the numerator and denominator in the ratio. This
is an extremely important property of the likelihood
ratio
LR that qualiﬁes it to be a goodness of ﬁt vari-
able. Since the denominator P data(cn) is independent
of the theoretical parameters s, both the likelihood ra-
tio and the likelihood maximize at the same point s∗.
One can also show [3] that the maximum value of the
likelihood ratio occurs when the theoretical likelihood
s) and the data likelihood P data(ci) are equal for
P (ci|
all ci.

2

PHYSTAT2003, SLAC, Stanford, California, September 8-11,2003

3. Binned Goodness of Fit

5. An illustrative example

−

2log

In the case where the pdf P data(c) is estimated by
binned histograms and the statistics are Gaussian, it
is readily shown [3] that the commonly used goodness
of ﬁt variable χ2 =
LR. It is worth emphasizing
that the likelihood ratio as deﬁned above is needed
and not just the negative log of theoretical likelihood
P (cn
s) to derive this result. The popular conception
|
that χ2 is -2 log P (cn
s) is simply incorrect!. It can
|
also be shown that the likelihood ratio deﬁned above
can describe the binned cases where the statistics are
Poissonian [4]. In order to solve our problem of good-
ness of ﬁt in unbinned likelihood cases, one needs to
arrive at a method of estimating the data pdf P data(c)
without the use of bins.

4. Unbinned Goodness of Fit

One of the better known methods of estimating the
probability density of a distribution in an unbinned
case is by the use of Probability Density Estimators
(P DE′s), also known as Kernel Density Estimators [5]
(KDE′s). The pdf P data(c) is approximated by

P data(c)

P DE(c) =

≈

(c

ci)

−

(6)

1
n

i=n

G

Xi=1

1

p

−

where a Kernel function
ci) is centered around
(c
G
each data point ci, is so deﬁned that it normalizes to
unity and for large n approaches a Dirac delta func-
tion [3]. The choice of the Kernel function can vary
depending on the problem. A popular kernel is the
Gaussian deﬁned in the multi-dimensional case as

(c) =

G

(√2πh)d

(det(E))

exp( −

H αβcαcβ
2h2

)

(7)

where E is the error matrix of the data deﬁned as

(8)

Eα,β =< cαcβ >

< cα >< cβ >

−
and the <> implies average over the n events, and
d is the number of dimensions. The Hessian matrix
H is deﬁned as the inverse of E and the repeated
indices imply summing over. The parameter h is a
“smoothing parameter”, which has[6] a suggested op-
n−1/(d+4), that satisﬁes the asymp-
timal value h
totic condition

∝

G∞(c

−

ci)

lim
n→∞ G

(c

−

≡

ci) = δ(c

ci)

(9)

−

The parameter h will depend on the local number den-
sity and will have to be adjusted as a function of the
local density to obtain good representation of the data
by the P DE. Our proposal for the goodness of ﬁt in
unbinned likelihood ﬁts is thus the likelihood ratio
P (cn
s)
|
P data(cn) ≈
evaluated at the maximum likelihood point s∗.

P (cn
s)
|
P P DE(cn)

LR =

(10)

We consider a simple one-dimensional case where
the data is an exponential distribution, say decay
times of a radioactive isotope. The theoretical pre-
diction is given by

P (c

s) =
|

1
s

exp(

c
s

)

−

(11)

We have chosen an exponential with s = 1.0 for this
example. The Gaussian Kernel for the P DE would
be given by

(c) =

G

1
(√2πσh)

exp(

c2
2σ2h2 )

−

(12)

where the variance σ of the exponential is numerically
equal to s. To begin with, we chose a constant value
for the smoothing parameter, which for 1000 events
generated is calculated to be 0.125. Figure 1 shows
the generated events, the theoretical curve P (c
s) and
|
the P DE curve P (c) normalized to the number of
events. The P DE fails to reproduce the data near
the origin due to the boundary eﬀect, whereby the
Gaussian probabilities for events close to the origin
spill over to negative values of c. This lost probability
would be compensated by events on the exponential
In our
distribution with negative c if they existed.
case, this presents a drawback for the P DE method,
which we will remedy later in the paper using P DE
deﬁnitions on the hypercube and periodic boundary
conditions. For the time being, we will conﬁne our
example to values of c > 1.0 to avoid the boundary
eﬀect.

In order to test the goodness of ﬁt capabilities of
the likelihood ratio
LR, we superimpose a Gaussian
on the exponential and try and ﬁt the data by a
simple exponential. Figure 2 shows the “data” with
1000 events generated as an exponential in the ﬁducial
range 1.0 < c < 5.0. Superimposed on it is a Gaus-
sian of 500 events. More events in the exponential
are generated in the interval 0.0 < c < 1.0 to avoid
the boundary eﬀect at the ﬁducial boundary at c=1.0.
Since the number density varies signiﬁcantly, we have
had to introduce a method of iteratively determining
the smoothing factor as a function of c as described
in [3]. With this modiﬁcation in the P DE, one gets
a good description of the behavior of the data by the
P DE as shown in Figure 2. We now vary the num-
ber of events in the Gaussian and obtain the value of
the negative log likelihood ratio
as a function
of the strength of the Gaussian. Table I summarizes
the results. The number of standard deviations the
unbinned likelihood ﬁt is from what is expected is de-
termined empirically by plotting the value of
N LLR
for a large number of ﬁts where no Gaussian is super-
imposed (i.e. the null hypothesis) and determining the
mean and RM S of this distribution and using these

N LLR

MOCT003

PHYSTAT2003, SLAC, Stanford, California, September 8-11,2003

3

Table I Goodness of ﬁt results from unbinned likelihood
and binned likelihood ﬁts for various data samples. The
negative values for the number of standard deviations in
some of the examples is due to statistical ﬂuctuation.

Number of

Gaussian events N LLR

Unbinned ﬁt Unbinned ﬁt Binned ﬁt χ2
N σ

500
250
100
85
75
50
0

189.
58.6
11.6
8.2
6.3
2.55
0.44

103
31
4.9
3.0
1.9
-0.14
-1.33

39 d.o.f.
304
125
48
42
38
30
24

It can be seen that -log P (cn
s) and -log P P DE(cn)
|
are correlated with each other and the diﬀerence be-
tween the two (-log
) is a much narrower dis-
tribution than either and provides the goodness of ﬁt
discrimination.

N LLR

Figure 1: Figure shows the histogram (with errors) of
generated events. Superimposed is the theoretical curve
P (c|s) and the P DE estimator (solid) histogram with no
errors.

Figure 2: Figure shows the histogram (with errors) of
1000 events in the ﬁducial interval 1.0 < c < 5.0
generated as an exponential with decay constant s=1.0
with a superimposed Gaussian of 500 events centered at
c=2.0 and width=0.2. The P DE estimator is the (solid)
histogram with no errors.

N LLR

to estimate the number of σ’s the observed
is
from the null case. Table I also gives the results of
a binned ﬁt on the same “data”. It can be seen that
the unbinned ﬁt gives a 3σ discrimination when the
number of Gaussian events is 85, where as the binned
ﬁt gives a χ2/ndf of 42/39 for the same case. We in-
tend to make these tests more sophisticated in future
work.

Figure 3 shows the variation of -log P (cn

s) and -log
|
P P DE(cn) for an ensemble of 500 experiments each
with the number of events n = 1000 in the exponen-
tial and no events in the Gaussian (null hypothesis).

MOCT003

Figure 3: (a) shows the distribution of the negative
log-likelihood -loge(P (cn|s)) for an ensemble of
experiments where data and experiment are expected to
ﬁt. (b) Shows the negative log P DE likelihood
-loge(P (cn)) for the same data (c) Shows the correlation
between the two and (d) Shows the negative
log-likelihood ratio N LLR that is obtained by
subtracting (b) from (a) on an event by event basis.

5.1. Improving the P DE

The P DE technique we have used so far suﬀers from
two drawbacks; ﬁrstly, the smoothing parameter has
to be iteratively adjusted signiﬁcantly over the full
s)
range of the variable c, since the distribution P (c
|
changes signiﬁcantly over that range; and secondly,
there are boundary eﬀects at c=0 as shown in ﬁg-
ure 1. Both these ﬂaws are remedied if we deﬁne the

4

PHYSTAT2003, SLAC, Stanford, California, September 8-11,2003

P DE in hypercube space. After we ﬁnd the maxi-
mum likelihood point s∗, for which the P DE is not
c′, such that
needed, we transform the variable c
→
the distribution P (c′
s∗) is ﬂat and 0 < c′ < 1. The
|
hypercube transformation can be made even if c is
multi-dimensional by initially going to a set of vari-
ables that are uncorrelated and then making the hy-
percube transformation. The transformation can be
such that any interval in c space maps on to the inter-
val (0, 1) in hypercube space. We solve the boundary
problem by imposing periodicity in the hypercube. In
the one dimensional case, we imagine three “hyper-
cubes”, each identical to the other on the real axis
in the intervals (
1, 0), (0, 1) and (1, 2). The hyper-
cube of interest is the one in the interval (0, 1). When
the probability from an event kernel leaks outside the
boundary (0, 1), we continue the kernel to the next hy-
percube. Since the hypercubes are identical, this im-
plies the kernel re-appearing in the middle hypercube
but from the opposite boundary. Put mathematically,
the kernel is deﬁned such that

−

(c′
(c′

G
G

−
−

c′
i) =
c′
i) =

(c′
(c′

G
G

−
−

c′
1); c′ > 1
i −
i + 1); c′ < 0
c′

Although a Gaussian Kernel will work on the hyper-
cube, the natural kernel to use considering the shape
of the hypercube would be the function

(c′)

G

;

(c′) =

1
h
(c′) = 0;

G

G

<

>

c′
|
c′
|

|

|

h
2
h
2

(13)
(14)

(15)

(16)

This kernel would be subject to the periodic boundary
conditions given above, which further ensure that ev-
ery event in hypercube space is treated exactly as ev-
ery other event irrespective of their co-ordinates. The
parameter h is a smoothing parameter which needs to
be chosen with some care. However, since the theory
distribution is ﬂat in hypercube space, the smoothing
parameter may not need to be iteratively determined
over hypercube space to the extent that data distri-
bution is similar to the theory distribution. Even if
iteration is used, the variation in h in hypercube space
is likely to be much smaller.

N LLR

Figure 4 shows the distribution of the

for
the null hypothesis for an ensemble of 500 experiments
each with 1000 events as a function of the smoothing
factor h. It can be seen that the distribution narrows
considerably as the smoothing factor increases. We
choose an operating value of 0.2 for h and study the
dependence of the
as a function of the number
of events ranging from 100 to 1000 events, as shown in
ﬁgure 5. The dependence on the number of events is
seen to be weak, indicating good behavior. The P DE
thus arrived computed with h=0.2 can be transformed
from the hypercube space to c space and will repro-
duce data smoothly and with no edge eﬀects. We note

N LLR

MOCT003

Figure 4: The distribution of the negative log likelihood
ratio N LLR for the null hypothesis for an ensemble of
500 experiments each with 1000 events, as a function of
the smoothing factor h=0.1, 0.2 and 0.3

that it is also easier to arrive at an analytic theory of
with the choice of this simple kernel.

N LLR

Figure 5: The distribution of the negative log likelihood
ratio N LLR for the null hypothesis for an ensemble of
500 experiments each with the smoothing factor h=0.2,
as a function of the number of events

6. End of Bayesianism?

By Bayesianism, we mean the practice of “guess-
ing” a prior distribution and introducing it into the
calculations. In what follows we will show that what
is conventionally thought of as a Bayesian prior dis-
tribution is in reality a number that can be calculated
from the data. We are able to do this since we use
two pdf ’s, one for theory and one for data. In what

PHYSTAT2003, SLAC, Stanford, California, September 8-11,2003

5

follows, we will interpret the probability distribution
of the parameter s in a strictly frequentist sense. The
pdf of s is the distribution of the best estimator of the
true value sT of s from an ensemble of an inﬁnite num-
ber of identical experiments with the same statistical
power n.

6.1. Calculation of ﬁtted errors

After the ﬁtting is done and the goodness of ﬁt is
evaluated, one needs to work out the errors on the
ﬁtted quantities. One needs to calculate the posterior
cn), which carries information not only
density P (s
|
about the maximum likelihood point s∗, from a single
experiment, but how such a measurement is likely to
ﬂuctuate if we repeat the experiment. The joint prob-
ability density P (s, cn) of observing the parameter s
and the data cn is given by

P data(s, cn) = P (s

cn)P data(cn)
|

(17)

where we use the superscript data to distinguish the
joint probability P data(s, cn) as having come from us-
ing the data pdf . If we now integrate the above equa-
tion over all possible datasets cn, we get the expres-
sion for the pdf of s.

Pn(s) =

Z

P data(s, cn)dcn =

P (s

cn)P data(cn)dcn
|

Z

P

(18)
where we have used the symbol
to distinguish the
fact that it is the true pdf of s obtained from an in-
ﬁnite ensemble. We use the subscript n in
Pn(s) to
denote that the pdf is obtained from an ensemble of
experiments with n events each. Later on we will
Pn(s) is indeed dependent on n. Equa-
show that
tion 18 states that in order to obtain the pdf of the
parameter s, one needs to add together the conditional
cn) over an ensemble of events, each
probabilities P (s
|
such distribution weighted by the “data likelihood”
P data(cn). At this stage of the discussion, the func-
cn) are unknown functions. We have
tions P data(s
|
however worked out
LR(s) as a function of s and have
evaluated the maximum likelihood value s∗ of s. We
can choose an arbitrary value of s and evaluate the
goodness of ﬁt at that value using the likelihood ra-
tio. When we choose an arbitrary value of s, we are
in fact hypothesizing that the true value sT is at this
value of s. LR(s) then gives us a way of evaluating the
relative goodness of ﬁt of the hypothesis as we change
s. Let us now take an arbitrary value of s and hy-
pothesize that that is the true value. Then the joint
probability of observing cn and sT being at this value
of s is given from the data end by equation 17.

Similarly, from the theoretical end, one can calcu-
late the joint probability of observing the dataset cn,
with the true value being at s. The true value sT is

MOCT003

taken to be the maximum likelihood point of the pdf
It may coincide with the mean value of the
Pn(s).
Pn(s). These statements are assertions of the un-
pdf
biased nature of the data from the experiment. At this
point, there is no information available on where the
true value sT lies. One can make the hypothesis that
a particular value of s is the true value and the prob-
ability of this being so is
Pn(sT ). The actual value of
this number is a function of the experimental resolu-
tion and the statistics n of the experiment. The joint
probability P theory(s, cn) from the theoretical end is
given by the product of the probability density of the
pdf of s at the true value of s, namely
Pn(sT ), and
s) evaluated at the true
the theoretical likelihood P (cn|
value, which by our hypothesis is s.

P theor(s, cn) = P theor(cn

s)
|

Pn(sT )

(19)

For the null hypothesis, we assume that the data is
described by the theory adequately everywhere. So
ﬁtting the data with the theory that agrees with it, is
equivalent to equating P data(s, cn) and P theor(s, cn).
This gives the equation

P (s

cn)P data(cn) = P theor(cn
|

s)
|

Pn(sT )

(20)

which is a form of Bayes’ theorem, but with two pdf ′s
(theory and data). Let us note that the above equa-
tion can be immediately re-written as a likelihood ra-
tio

LR =

cn)
P (s
|
Pn(sT )

=

P theor(cn
s)
|
P data(cn)

(21)

which is what is used to obtain the goodness of ﬁt.
In order to get the ﬁtted errors, we need to evaluate
cn) which necessitates a better understanding of
P (s
|
Pn(sT ) is in equation 20. Rearranging equa-
what
tion 20, one gets

P (s

cn) =
|

LR(s)

Pn(sT ) =

P theor(cn
s)
P data(cn) Pn(sT )
|

(22)

6.1.1. To show that Pn(sT ) depends on n

In practice, in both the binned and unbinned cases,

cn)
|

one only has an approximation to P data(cn). As n

→
, in the absence of experimental bias, one expects
∞
to determine the parameter set s to inﬁnite accuracy;
sT ), where sT is the true value
and P (s
of s. However, for the null hypothesis, as n
,
→ ∞
the statistical error introduced by our use of P DE in
the unbinned case or by binning in the binned case
becomes negligible with the result that the theory pdf
describes the data for all c at the true value sT . i.e.

δ(s

→

−

P theor(c

sT )
|
P data(c) →

1 as n

→ ∞

(23)

6

PHYSTAT2003, SLAC, Stanford, California, September 8-11,2003

When one evaluates the likelihood ratio
LR over n
events, with n
, the likelihood ratio does not
necessarily remain unity. This is due to ﬂuctuations
in the data which grow as
(n). For the binned likeli-
,
hood case with nb bins, one can show that as n
→ ∞

→ ∞

p

LR →

e−

P

i=nb
2
i /2
i=1 χ

e−nb/2

→

(24)

.
→ ∞

This is just an example of the likelihood ratio theo-
rem. If one uses a binned χ2 ﬁt, which can also be
thought of as maximizing a likelihood ratio, one gets
the same limit as when using binned likelihood ﬁts.
The point is that
In the
LR is ﬁnite as n
unbinned case, we have currently no analytic theory
available. However, one can argue that the binned
and nb << n
case with the number of bins nb → ∞
should approach the unbinned limit. In this case, the
LR also is ﬁnite for inﬁnite statistics. This
unbinned
implies that
Pn(sT )
as n
depends on n. This puts an end to the notion of a
Pn(s).
monolithic Bayesian prior interpretation for
6.1.2. To show that Pn(sT ) is constant with respect to s

Pn(sT )

.
→ ∞

→ ∞

i.e

When one varies the likelihood ratio in equation 22
as a function of s, for each value of s, one is mak-
ing a hypothesis that s = sT . As one changes s, a
new hypothesis is being tested that is mutually exclu-
sive from the previous one, since the true value can
only be at one location. So as one changes s, one is
Pn(s) so that sT is at
free to move the distribution
the value of s being tested. This implies that
Pn(sT )
does not change as one changes s and is a constant
wrt s, which we can now write as αn. Figure 6 illus-
trates these points graphically. Thus
Pn(sT ) in our
equations is a number, not a function. The distri-
bution
Pn(s) should not be thought of as a “prior”
but as an “unknown concomitant”, which depends on
the statistics and the measurement capabilities of the
apparatus. For a given apparatus, there are a denu-
merable inﬁnity of such distributions, one for each n.
These distributions become narrower as n increases
and

as n

Pn(sT )

→ ∞

.
→ ∞

6.2. New form of equations

Equation 22 can now be re-written

P (s

cn) =
|

P (cn
s)αn
|
P data(cn)

(25)

Since P (s
αn,

cn) must normalize to unity, one gets for
|

Figure 6: Comparison of the usage of Bayesian priors
with the new method. In the upper ﬁgure, illustrating the
Bayesian method, an unknown distribution is guessed at
by the user based on “degrees of belief” and the value of
the Bayesian prior changes as the variable s changes. In
the lower ﬁgure, an “unknown concomitant” distribution
is used whose shape depends on the statistics. In the
case of no bias, this distribution peaks at the true value
of s. As we change s, we change our hypothesis as to
where the true value of s lies, and the distribution shifts
with s as explained in the text. The value of the
distribution at the true value is thus independent of s.

data set cn. This is our measurement of αn and dif-
ferent datasets will give diﬀerent values of αn, in other
words αn will have a sampling distribution with an ex-
, the
pected value and standard deviation. As n
likelihood ratio
LR will tend to a ﬁnite value at the
true value and zero for all other values, and αn → ∞
as a result.
Note that it is only possible to write down an ex-
pression for αn dimensionally when a likelihood ratio
LR is available. This leads to

→ ∞

P (s

cn) = LR
|

R LR ds

=

R

P (cn
P (cn

s)
|
s)ds
|

(27)

The last equality in equation 27 is the same expres-
sion that “frequentists” use for calculating their errors
after ﬁtting, namely the likelihood curve normalized
to unity gives the parameter errors. If the likelihood
curve is Gaussian shaped, then this justiﬁes a change
of negative log-likelihood of 1
2 from the optimum point
to get the 1σ errors. Even if it is not Gaussian, as we
show in section (8), we may use the expression for
cn) as a pdf of the parameter s to evaluate the
P (s
|
errors.

αn =

P data(cn)
P (cn
s)ds
|

=

R

1

R LR(s) ds

(26)

The normalization condition

We have thus determined αn, the value of the “un-
known concomitant” at the true value sT using our

P (cn) =

P theory(s, cn)ds =

Z

P (cn|

s)

Z

Pn(sT )ds
(28)

MOCT003

PHYSTAT2003, SLAC, Stanford, California, September 8-11,2003

7

is obeyed by our solution, since

P (cn

Z

s)
|

Pn(sT ) ds =

Z

αnP (cn

s) ds
|

≡

P data(cn)

R

αnP (cn

(29)
The expression
s) ds in the above equation
|
may be thought of as being due to an “unknown con-
comitant” whose peak value is distributed uniformly
in s space. The likelihoods of the theoretical predic-
tion P (cn
s) contribute with equal probability each
|
with a weight αn, to sum up to form the data like-
lihood P data(cn).
i.e. the data, due to its statistical
inaccuracy will entertain a range of theoretical param-
eters. However, equation 29 does not give us any fur-
ther information, since it is obeyed identically. Fitting
for the maximum likelihood value s∗ of s is attained
LR = P (cn|s)
by maximizing the likelihood ratio
P data(cn) .
The goodness of ﬁt is obtained using the value of
LR
at the maximum likelihood point. The best theoret-
s∗), and this prediction is used
ical prediction is P (c
|
to compare to the data pdf P data(c). Note that the
maximum likelihood value s is also the same point at
which the posterior density P (s
c) peaks. This is true
|
only in our method. When an arbitrary Bayesian prior
is used, the maximum likelihood value is not the same
point at which the posterior density will peak. Note
also that the normalization equation
still valid. The integral

R Pn(s) ds=1 is

αn ds

= 1

Z

(30)

Pn(s)
since αn is our measurement of the value of
It is a measure of the statistcal
at the true value.
accuracy of the experiment. The larger the value of
αn, the narrower the distribution
Pn(s) and the more
accurate the experiment.

7. Combining Results of Experiments

Each experiment should publish a likelihood curve
for its ﬁt as well as a number for the data likelihood
P data(cn). Combining the results of two experiments
with m and n experiments each, involves multiplying
the likelihood ratios.

LRm(s)

LRm+n(s) =

P (cn
s)
|
P data(cn)
(31)
Posterior densities and goodness of ﬁt can be deduced
from the combined likelihood ratio.

P (cm
s)
|
P data(cm) ×

×LRn(s) =

8. Interpreting the results of one
experiment

After performing a single experiment with n events,
cn), using equation 27.
|

we now can calculate P (s

MOCT003

Equation 18 gives the prescription for arriving at
Pn(s), given an ensemble of such experiments, the
contribution from each experiment being weighted
by the “data likelihood” P data(cn) for that experi-
ment. The “data likelihoods” integrate to unity, i.e
P data(cn)dcn = 1. In the case of only a single ex-
periment, with the observed cn being denoted by cobs
R
n ,

P data(cn) = δ(cn

cn

obs)

(32)

−

Equation 18, for a single experiment, then reduces to

Pn(s) =

Z

P (s

cn)P data(cn)dcn = P (s
|

cn
|

obs) (33)

i.e. given a single experiment, the best estimator for
cnobs) and thus the best
Pn(s), the pdf of s, is P (s
|
estimator for the true value sT is s∗obs deduced from
cnobs) as though
the experiment. We can thus use P (s
|
it is the pdf of s and deduce limits and errors from it.
The proviso is of course that these limits and errors
as well as s∗obs come from a single experiment of ﬁ-
nite statistics and as such are subject to statistical
ﬂuctuations.

9. Comparison with the Bayesian
approach

In the Bayesian approach, an unknown Bayesian
prior P (s) is assumed for the distribution of the pa-
rameter s in the absence of any data. The shape of
the prior is guessed at, based on subjective criteria or
using other objective pieces of information. However,
such a shape is not invariant under transformation of
variables. For example, if we assume that the prior
P (s) is ﬂat in s, then if we analyze the problem in s2,
we cannot assume it is ﬂat in s2. This feature of the
Bayesian approach has caused controversy. Also, the
notion of a pdf of the data does not exist and P (c)
is taken to be a normalization constant. As such, no
goodness of ﬁt criteria exist. In the method outlined
here, we have used Bayes’ theorem to calculate poste-
rior densities of the ﬁtted parameters while being able
to compute the goodness of ﬁt. The formalism devel-
oped here shows that what is conventionally thought
of as a Bayesian prior distribution is in fact a nor-
malization constant and what Bayesians think of as a
normalization constant is in fact the pdf of the data.
Table II outlines the major diﬀerences between the
Bayesian approach and the new one.

6
8

PHYSTAT2003, SLAC, Stanford, California, September 8-11,2003

Table II The key points of diﬀerence between the
Bayesian method and the new method.

Item
Goodness Absent
of ﬁt

Bayesian Method

Used in evaluating
theory pdf
at data points

New Method
Now available
in both binned
and unbinned ﬁts
Used in evaluating
theory pdf
at data points
as well as evaluating
data pdf at data points
Is a distribution
No prior needed.
that is guessed based One calculates a
on “degrees of belief” constant from data
Independent of data, αn =

P data

(cn)
P (cn|s)ds

Data

Prior

monolithic

Posterior Depends on Prior.
density
P (s|cn)

P (cn|s)P (s)
P (cn|s)P (s) ds

R

R

→ ∞ as n → ∞
Independent of prior.
same as frequentists use

P (cn|s)
P (cn|s) ds

R

10. Further work to be done

This scheme involves the usage of two pdf ’s, namely
data and theory. In the process of computing the ﬁt-
ted errors, we have demonstrated that the quantity
in the joint probability equations that has been inter-
preted as the “Bayesian prior” is in reality a number
and not a distribution. This number is the value of
the pdf of the parameter, which we call the “unknown
concomitant” at the true value of the parameter. This
number is calculated from a combination of data and
theory and is seen to be an irrelevant parameter. If
this viewpoint is accepted, the controversial practice
of guessing distributions for the “Bayesian Prior” can
now be abandoned, as can be the terms “Bayesian”
and “frequentist”. We show how to use the posterior
density to rigorously calculate ﬁtted errors.

Acknowledgments

This work is supported by Department of Energy.
The author wishes to thank Jim Linnemann and Igor
Volobouev for useful comments.

Equation 18 can be used to show that the expecta-

tion value of E(s) of the parameter s is given by

References

E(s) =

s

Pn(s)ds =

Z

Z

dcnP (cn)

sP (s

cn)ds(34)
|

Z

¯s(cn)P (cn)dcn(35)

=

Z

where ¯s(cn) is the average of s for individual experi-
ments. Equation 35 states E(s) is the weighted aver-
age of ¯s(cn) obtained from individual measurements,
the weight for each experiment being the “data like-
lihood” P (cn) for that experiment. In the absence of
experimental bias, E(s) would be identical to the true
value sT . It remains to be shown that the weighted av-
erage of maximum likelihood values s∗ from indiviual
experiments also converge to the maximum likelihood
point of

Also one needs to develop an analytic theory of the
goodness of ﬁt for unbinned likelihood ﬁts. Finally,
one needs to investigate a bit more closely the trans-
formation properties of
Pn(s) under change of vari-
able.

Pn(s).

11. Conclusions

To conclude, we have proposed a scheme for ob-
taining the goodness of ﬁt in unbinned likelihood ﬁts.

[1] K. Kinoshita, “Evaluating Quality of Fit

in
Unbinned Maximum Likelihood ﬁtting”, Proceed-
ings of the Conference on Advanced Statistical
Techniques in Particle Physics, Durham, March
2002 IPPP/02/39, DCPT/02/78.
B. Yabsley,“Statistical Practice at the BELLE
Experiment,
questions”,ibid.
R. D. Cousins,“Conference Summary”, ibid.

some

and

[2] R. A. Fisher,“On the mathematical foundations of
theoretical statistics”, Philos. Trans. R. Soc. Lon-
don Ser. A 222, 309-368(1922);
R. A. Fisher,“Theory of statistical estimation”,
Proc. Cambridge Philos. Soc. 22, 700-725 (1925).
[3] “A measure of the goodness of ﬁt in unbinned

likelihood ﬁts”, R .Raja, long write-up,
http://www-conf.slac.stanford.edu/phystat2003/talks
/raja/Raja bayes maxlike.pdf

[4] “End

of

Bayesianism?”,

R.Raja,

[5] E. Parzen, “On estimation of a probability density
function and mode” Ann.Math.Statis. 32, 1065-
1072 (1962).

[6] D. Scott. Multivariate Density Estimation. John

Wiley & Sons, 1992.
M. Wand and M. Jones, Kernel Smoothing. Chap-
man & Hall, 1995.

MOCT003

http://www-conf.slac.stanford.edu/phystat2003/talks/raja/raja-end

