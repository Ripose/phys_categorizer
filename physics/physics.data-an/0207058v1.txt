Conﬁdence Limits and their Robustness

FNAL-CONF-02/047-E

Rajendran Raja∗

Fermi National Accelerator laboratory

Batavia, IL 60510

(Dated: February 2, 2008)

Abstract

Conﬁdence limits are common place in physics analysis. Great care must be taken in their

calculation and use, especially in cases of limited statistics when often one-sided limits are quoted.

In order to estimate the stability of the conﬁdence levels to addition of more data and/or change

of cuts, we argue that the variance of their sampling distributions be calculated in addition to the

limit itself. The square root of the variance of their sampling distribution can be thought of as

a statistical error on the limit. We thus introduce the concept of statistical errors of conﬁdence

limits and argue that not only should limits be calculated but also their errors in order to represent

the results of the analysis to the fullest. We show that comparison of two diﬀerent limits from two

diﬀerent experiments becomes easier when their errors are also quoted. Use of errors of conﬁdence

limits will lead to abatement of the debate on which method is best suited to calculate conﬁdence

limits.

PACS numbers: 00.02.50.Cw, 10.11

2
0
0
2
 
l
u
J
 
5
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
8
5
0
7
0
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

∗Electronic address: raja@fnal.gov

1

I.

INTRODUCTION

Conﬁdence limits are used to express the results of experiments that are not yet sensitive

to discover the object of their searches. In such cases, often a one-sided limit is used to delimit

the quantity of interest. Limits from diﬀerent experiments are compared and attempts are

made to combine them. These limits can ﬂuctuate up or down with the addition of more data

or the changing of the analysis parameters. A measure of the robustness of the limits is given

by the width of the sampling distribution of these limits, where the sampling distribution is

obtained over an ensemble of similar experiments simulated by Monte Carlo. The standard

deviation of the sampling distribution of such limits can be thought of as an error on the

limit.

We introduce the concept of error of conﬁdence limits by a simple Gaussian example.

Consider a sample of n events, where n = 10, characterised by the variable x distributed as

a unit Gaussian, with a mean value µ = 0 and standard deviation σ = 1. Then the average

value ¯x of the n events will be distributed as a Gaussian of mean value zero and standard

error σ/p(n). The unbiased estimate of σ, the variance of the distribution is given by s
where,

s2 =

1
n − 1

i=n

X
i=1

(x2
i

− ¯x2)

(1)

Figure 1 shows the distribution ¯x of our sample of 10 events for a large number of samples.

The expected value ¯x is zero and its standard deviation is 0.32 which is consistent with

the theoretical value of σ/p(n)=0.316. Figure 2 shows a histogram of s deduced from a
sample of 10 events for a large number of such samples. The average value of s is ≈ 1.0,

showing that s is an unbiased estimator of σ. The important point to note is that s also has

a variance and that its standard deviation is 0.23. This is as expected from theory where
the error on the standard deviation of a Gaussian sample [1] is ≈ σ/p(2n)=0.223. Having
got the value of ¯x and s for our sample, one can proceed to work out conﬁdence limits for

our observation. The two-sided 68% CL limits for our observation of ¯x will be given by the

standard error σ(¯x) of ¯x and we would write the observation of ¯x from our sample as

¯x ± σ(¯x) = ¯x ± s/p(n) = −0.188 ± 0.408

(2)

where the numbers correspond to our sample of 10 events. Note that the standard error

2

FIG. 1: The distribution of the sample average ¯x over a large sample of events.

σ(¯x) = 0.408 derived from our sample of 10 events is quite diﬀerent from the theoretical

value of 0.32, but this is merely due to statistical ﬂuctuation.

One can also work out the two-sided 90% CL limits for our observation of ¯x which would
correspond to ±1.64 σ(¯x) and quote the 90% CL limits as −0.188 ± 0.669, which is the value

observed for our sample of 10 events.

Figure 3 shows the distribution of the 90% CL two-sided errors on the sample average,

over a large number of samples. The mean value of the distribution is 0.505 which is close to

the theoretical value of 1.64 σ(¯x)=0.519. Note that the standard deviation of the 90% CL

errors in Figure 3 is 0.12. We can also calculate the standard deviation of the 90% CL error

from our sample as 1.64 σ(¯x)/p(2n) and this is plotted in ﬁgure 4. The mean value of the
standard deviation of the 90% CL error in ﬁgure 4 is 0.113, in line with the theoretical value

of 0.116. When the mean value is of interest, we quote the mean value and the standard

error on the mean value as in equation 2. This enables us to gauge the ﬂuctuations in the

mean value from sample to sample. When the conﬁdence limit is of interest, we propose

that we quote the conﬁdence limit along with its standard error. This would enable us to

3

FIG. 2: Unbiased estimate s of the standard deviation of the σ of the Gaussian distribution deduced

from a sample of n = 10 events. The average value of s is ≈ 1.0 and its standard deviation is 0.23.

gauge the signiﬁcance and stability of the conﬁdence level. In our example we would write

this as

be given by

¯x − 1.64σ(¯x) ± σ90 < µ < ¯x + 1.64σ(¯x) ± σ90 at 90% CL

where µ is the expectation value of ¯x and the standard error σ90 on the 90% CL limit would

σ90 ≈ σ(¯x)p(1 + (1.64)2/(2n)

In our sample of 10 events, this would lead to

−0.857 ± 0.434 < µ < 0.481 ± 0.434 at 90% CL

(3)

(4)

(5)

Note that the error on the lower and upper 90% CL limits are correlated by the error on ¯x

which they have in common. Half the diﬀerence between the lower and uper 90 % CL limits

is 1.64σ(¯x) and its error is 1.64σ(¯x)/p(2n). These two errors added in quadrature yield the

4

FIG. 3: The distribution of the calculated two-sided 90% CL errors of the mean value of the sample.

formula in equation 4. The error in the 90% CL limit indicates to the reader the stability

of the limit and the statistical signiﬁcance of the result.

Very often, we are not interested in the mean value of our observations but are more

interested in the conﬁdence limits, due to the low statistics of the observation. We may only

be interested in an upper (one-sided) bound. So we would quote a 95% CL upper bound on

µ as

A second sample of 10 events from the same distribution may yield a result

µ < 0.481 ± 0.434 at 95% CL

µ < 0.354 ± 0.335 at 95% CL

(6)

(7)

but we do not fall into the trap of declaring the second result a better limit than the ﬁrst,

because both the limits are the same within errors. If we did not quote the errors on the

limits, we would be tempted to declare the second limit superior to the ﬁrst.

5

FIG. 4: The distribution of the calculated error on the two-sided 90% CL error of the mean value

of the sample.

Similarly, as analyses proceed in discovery searches, events can go in and out of samples,

as cuts are reﬁned and more data is accumulated. Appearance of a single event in a sample

can change the conﬁdence limit drastically, as was the case in the search for the top quark.

These changes can be understood as ﬂuctuations of the conﬁdence limit within errors, if we

were to quote not only the conﬁdence limit but also its error.

II. RECONCILIATION WITH THE NEYMAN DEFINITION OF CONFIDENCE

LIMITS

The construction of conﬁdence levels as written down by Neyman [2] may be understood

within the context of our current example as follows. Using our ﬁrst sample of 10 events
drawn from a unit Gaussian, we calculate a mean value ¯x = −0.188. Let us assume, for

the sake of argument, that we know the variance of the mean value to be 1.0/p(10). In
this case, we can construct the Neyman conﬁdence level for µ, the expectation value of ¯x,

6

as illustrated in Fig. 5. The parameter µ is plotted on the ordinate and ¯x is plotted on the

abscissa. For each value of µ, the 90% CL limits of ¯x are delineated by horizontal lines that

are delimited by the curves ¯x1(µ) and ¯x2(µ), assuming ¯x is distributed about µ with variance

1.0/p(10). If the true value of µ is µ0, then ¯x1(µ0) < ¯x < ¯x2(µ0) with 90% probability. If
we now measure a value of ¯x = −0.188, then we can construct the interval AB which will

contain the true value of µ0 if and only if ¯x1(µ0) < ¯x < ¯x2(µ0). In other words the interval

AB has a probability of 90% (also called “coverage”) of containing the true value µ0. The

interval AB is thus deﬁned to be the 90% CL interval of µ.

If we were however to repeat our measurement of ¯x by creating other samples of 10 events

each, we would get diﬀerent lines AB, each of which would have a 90% chance of containing

the true value µ0. Most of the time, one is interested in a central value of ¯x and an interval

such as AB to denote the statistical errors (robustness) of the measurement of ¯x. However,

in experiments with poor statistics, the central value ¯x is often not of interest and the one-

sided limit (either point A or B) is often quoted. At this stage, the points A or B become

point measurements in their own right, and it is informative to quote their statistical errors

in order to evaluate their robustness.

This is illustrated further in Fig. 6, where we now no longer assume we know the variance

of ¯x. This is computed from the data and will ﬂuctuate from sample to sample. These

so-called “nuisance variables” are integrated over to yield a ﬁnal conﬁdence limit in usual

practice, which would be appropriate if one were interested in the central value of ¯x.

If

however, one is interested in the one-sided limit B, it would be appropriate to use them

to estimate the robustness of the point B due to statistical ﬂuctuations. We use the error

bands shown for ¯x and σ(¯x) in the ﬁgure to compute the sampling error band on the point

B.

III. AN ILLUSTRATIVE EXAMPLE

We can illustrate the need for conﬁdence limits errors using the following example. In

1995, the DØ collaboration published limits on the top quark mass and cross section [3].

Figure 7 shows [3] the 95% CL upper limit on top quark production as a function of top
quark mass using 13.5 pb−1 of data. The conﬁdence limit curve is used to derive a lower
limit of 128 GeV/c2 for the top quark mass at 95% CL. In the same paper, another ﬁgure,

7

FIG. 5: The Neyman construction of the conﬁdence level for our example

reproduced here as Figure 8 shows the top quark production cross section as a function

of the top quark mass. This curve has a 1 σ error band around it. But the top quark

production cross section may be thought of as the 50% CL upper/lower bound on the cross

section. Surely, if the 50% CL limit has an error band around it, the 95% CL limit should

also have its own error band.

In what follows, we show how to calculate errors in conﬁdence

levels in general and use the method to calculate the error in the 95% CL curve shown in

Figure 7.

LIMITS

IV. A GENERAL ALGORITHM TO CALCULATE ERRORS IN CONFIDENCE

Most experiments have elaborate algorithms to calculate conﬁdence limits for their re-

sults. Such algorithms will include detailed calculations and parametrizations of eﬃciencies

and acceptances.

In addition, they will have several other input parameters such as the

number of events observed, total integrated luminosity and the error on the luminosity. Let

us denote the input parameters as ai, i = 1, n. The output of such a program will be the

8

FIG. 6: The Neyman construction modiﬁed to illustrate ﬂuctuations in ¯x and σ(¯x) for our example.

The error band due to σ(¯x) and band due the error in σ(¯x) are shown. These are added in

quadrature to produce the sampling error band of point B.

conﬁdence limits Cα, α = 1, k. Figure 9 illustrates this general case. Then, for small changes

in the input parameters, the following equations hold.

δCα =

δCα
δai

δai

< δCαδCβ >=

< δaiδaj >

δCα
δai

δCβ
δaj

where the repeated indices i, j are meant to be summed over and the symbols <> indicates

the average over the enclosed quantities. The quantity on the left hand side of the equation

is the error matrix in the conﬁdence limits Cα, denoted ECC. The above equation can be

re-written in matrix form as

where Eaa is the error matrix of the input parameters ai, i = 1, n and T is the transfer matrix,
such that Tα,i = δCα

δai . T can be determined numerically by varying the input parameters to

ECC = ˜T EaaT

9

(8)

(9)

(10)

FIG. 7: The 95% conﬁdence level [3] on σt¯t as a function of top quark mass. Also shown are central

(dotted line) and low (dashed line) theoretical cross section curves [4].

Theory

30

20

10

)
b
p
(
 
n
o
i
t
c
e
S
 
s
s
o
r
C

DØ

0
120

140

160
Top Mass (GeV/c2)

180

200

FIG. 8: Measured t¯t production cross section (solid line, shaded band = one standard deviation

error) as a function of top mass [3]. Also shown are central (dotted line), high and low (dashed

lines) theoretical cross section curves [4].

the limits algorithm. The error matrix Eaa should be known to the experimenter, yielding

the required error matrix ECC.

10

FIG. 9: Schematic “black box” representation of a general conﬁdence limit calculating algorithm,

that has input parameters a1, a2..a4 and outputs a conﬁdence level C in a single variable.

A. An Example

Let us consider the calculation of C, the 95% CL upper limit to the top quark cross

section as published in reference [3]. The output of the limits algorithm is C. The input

parameters can be taken as three, namely a1, the total number of top quark events observed,
a2, the luminosity×eﬃciency×branching ratio of the channels under consideration, summed

over the channels and a3, the error in the luminosity. We have used a single parameter a2

summed over the channels to simplify the calculation.

In principle, all channels may be

varied independently, but since they are uncorrelated, and the dominant error is due to the

common luminosity factor, the above simpliﬁcation will result. We use this example for

illustrative purposes to show how such a calculation may proceed.

The error matrix of the parameters Eaa is a 3×3 diagonal matrix, since the parameters

are uncorrelated. The variance of a1 is the number of events observed, the variance of a2 is

calculated using the error in luminosity, and the variance of a3 is calculated assuming that

there is a 50% uncertainty in the error in the luminosity. The transfer matrix T is calculated

by numerical diﬀerentiation.

Figure 10 shows the contribution to σC, the error in the 95% CL upper limit to the cross

section, due to the three parameters a1, a2 and a3 as a function of the top quark mass. The

overall error σC, obtained by adding the component errors in quadrature, is also shown as

a function of the top quark mass. It can be seen that the contribution due to uncertainties

in a1, is negligible. So we are not sensitive to errors in our guess of 50% uncertainty to the

11

error in the luminosity. The overall error is dominated by the ﬂuctuation in the total number

of events. This example thus graphically illustrates why conﬁdence limits ﬂuctuate up and

down as events fall in and out of the selected sample as the analysis proceeds and more data

is accumulated. The 95% CL upper limit to the cross section is merely ﬂuctuating within

its error as all statistical quantities do. When we are interested in a conﬁdence limit, it thus

behooves us to compute not only that limit but also its error. We may superimpose these

FIG. 10: The components of σC, the error in the 95% CL top quark cross section upper limit,

due to uncertainties in (a) error in luminosity (b) Luminosity×eﬃciency×branching ratio (c) The

overall number of events observed as a function of top quark mass. (d) shows the overall error σC.

errors on Figure 7 yielding Figure 11. The 95% CL lower limit to the top quark mass can
then be quoted as 128+14
−18 GeV/c2, the error bars indicating the range of ﬂuctuation for the

mass limit. This implies that if one were to repeat the DØ experiment numerous times with
an integrated luminosity of 13.5 pb−1 ﬂuctuating within its errors, one would expect to get

a top quark lower mass limit that ﬂuctuates within the errors quoted.

12

FIG. 11: The DØ 95% CL upper limit to the top quark cross section [3] with its accompanying

error band, as calculated by the method in the text.

V. COMBINING LIMITS

Combining limits from two diﬀerent experiments is diﬃcult at best. We remark here

that in simple Gaussian cases, quoting the limit and its error provides us with enough

information to make a combined result, as may be seen by examining equations 3 and 4.

Using the value of the limit and its error, we may deduce ¯x and σ(¯x), if the number of events

n in the sample is known. Having the mean and its variance in each case, we can combine

the Gaussians, leading to a new variance for the combined data. The combined mean of

the two distributions can be found as usual by the weighted average of the two means, the

weights being the inverse variances. It must be emphasized that the combined limit is not

simply the weighted average of the two limits as in the case of the means.

One can further ask if the two limits are consistent with each other, if the errors on the

limits are quoted, as shown below.

13

VI. COMPARING LIMITS FROM TWO DIFFERENT ALGORITHMS

When two diﬀerent algorithms are used on the same data, two diﬀerent limits will result

that are correlated. The correlations will be due to the common input into the two algo-

rithms. We can think of the “black box” in Fig. 9 as consisting of two diﬀerent algorithms

producing as output C1 and C2, the two conﬁdence levels in question, using the same com-

mon input ai, i = 1, n. We can then use equation 10 to work out ECC, the error matrix of

the two conﬁdence level algorithms and use this matrix to decide whether the two conﬁdence

levels are signiﬁcantly diﬀerent from each other as per,

var(C1 − C2) = var(C1) + var(C2) − 2cov(C1, C2) = E11 + E22 − 2E12

(11)

VII. CONCLUSIONS

We have motivated the concept of statistical error for a conﬁdence limit, as the standard

deviation of the sampling distribution of such limits over an ensemble of similar experi-

ments.

In cases of limited statistics, our estimates of the conﬁdence limits can ﬂuctuate

signiﬁcantly. Comparing conﬁdence limits becomes more meaningful when these errors are

quoted. Diﬀerent methods exist (e.g Bayesian, Frequentist) for calculating these limits. The

diﬀerences between limits computed in the same experiment using diﬀerent methods will

lose their signiﬁcance if the limits are shown to be the same within their sampling error.

Often in analyses with limited statistics, the appearance of a new event can make signiﬁcant

diﬀerences to the limit calculation. An error analysis of the limit will show that the limit is

exhibiting statistical ﬂuctuation as it is entitled to. We propose that experimenters publish

conﬁdence limits to their data accompanied by the error on the limits.

14

VIII. ACKNOWLEDGEMENTS

The author wishes to thank Roger Barlow, Bob Cousins, Louis Lyons, Harrison Prosper,

Byron Roe, and Tom Trippe for helpful comments.

[1] C.E. Weatherburn, “A ﬁrst course in Mathematical Statistics”, Cambridge University press,

Page 137.

[2] J.Neyman, Phil. Trans. Royal Soc. London, Series A, 236, 333 (1937), reprinted in A Selection

of Early Statistical Papers on J. Neyman (University of California Press, Berkeley, 1967).

[3] “Top quark search with the DØ 1992-1993 data sample”, Phys.Rev.D52:4877(1995)

[4] E.Laenen, J.Smith, W. van Neerven, Phys. Lett. 321B, 254 (1994); Nucl. Phys. B368, 543(1992).

15

