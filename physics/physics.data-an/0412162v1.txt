Late comment on Astumian’s paradox

L. Pal
KFKI Atomic Energy Research Institute H-1525 Budapest 114, POB 49 Hungary

In 2001 Astumian [1] published a very simple game which can be described by a Markov chain
with absorbing initial and ﬁnal states. In August 2004 Piotrowski and Sladowski [2] asserted that
Astumian’s analysis was ﬂawed. However, as was shown by Astumian [3], this statement was wrong.
In this comment the properties of Markov chains corresponding to games that are more general than
that studied by Astumian, are investigated.

Keywords: Astumian’s paradox, Markov chains, transition matrix

I.

INTRODUCTION

The present note was initiated by the revisited Astumian’s paradox. In August 2004 Piotrowski and Sladowski [2]
asserted that Astumian’s analysis was ﬂawed. However, as shown by Astumian [3], this statement was wrong. Since
the analysis of the problem in a slightly more general frame than it was done earlier could be a good exercise for
graduate students, we came to the conclusion that it might be useful to publish our elementary considerations about
the properties of Markov chains corresponding to Astumian type games.

For entirely didactic reasons, in Sections II and III we present a brief summary of deﬁnitions and statements which
are needed for the analysis of the Astumian type Markov chains. In Section IV we analyze the properties of such
chains and determine the probabilities of losing and winning. Conclusions are made in Section V.

II. PRELIMINARIES

Let N = {1, 2, . . . , N } be a ﬁnite set of positive integers, and Z = {0, 1, . . .} be a set of non-negative integers.
Denote by ξn, n ∈ Z the random variable which assumes the elements of N . We say that the sequence {ξn} forms a
Markov chain if for all n ∈ Z and for all possible values of random variables the equation

P{ξn = j|ξ0 = i0, ξ1 = i1, . . . , ξn−1 = in−1} = P{ξn = j|ξn−1 = in−1}

(1)

is fulﬁlled. If ξn = j then the process is said to be in state Sj at the nth (discrete time instant) step. The states
S1, S2, . . . , SN deﬁne the space of states of the process. The probability distribution P{ξ0 = i}, i ∈ N of the random
variable ξ0 is called the initial distribution and the conditional probabilities P{ξn = j|ξn−1 = i} are called transition
probabilities. If ξn−1 = i and ξn = j, then we say that the process made a transition Si → Sj at the nth step. The
Markov chain is homogeneous if the transition probabilities are independent of n ∈ Z. In this case we may write

and it obviously holds that

P{ξn = j|ξn−1 = i} = wij (1) = wij ,

In what follows we shall consider only homogeneous Markov chains. We would like to emphasize that the transition
probability matrix

4
0
0
2
 
c
e
D
 
4
2
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
2
6
1
2
1
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

wij = 1,

∀ i ∈ N .

N

j=1
X

w11 w12
· · · w1N
w21 w22
· · · w2N
...
...
...
. . .
wN 1 wN 2 · · · wN N



,






w = 





P{ξm+n = j|ξm = i} = wij (n)

(2)

(3)

(4)

which is a stochastic matrix, and the initial distribution pi = P{ξ0 = i}, i ∈ N determine the random process
uniquely. For the sake of simplicity, we assume that the process is a random walk of an abstract object, called particle
on the space of states S1, S2, . . . , SN . The nth step transition probability

satisﬁes the following equation:

wij (n) =

wik(r) wkj (s),

N

Xk=1

r + s = n.

It is to note that wij (n) is the probability that at the nth step the particle is in the state Sj provided that at n = 0
it was in the state Si. From Eq. (5) we obtain that

and by using the rules of matrix multiplication we arrive at

wij (n) =

wik wkj (n − 1) =

wik(n − 1) wkj ,

N

Xk=1

N

Xk=1

w(n) = w w(n − 1) = w(n − 1) w = wn,

w11(n) w12(n) · · · w1N (n)
w21(n) w22(n) · · · w2N (n)

...

...

. . .

...

wN 1(n) wN 2(n) · · · wN N (n)



,






w(n) = 





1 0 · · · 0
0 1 · · · 0
...
...
. . .
0 0 · · · 1

...








w(0) = 





pj(n) =

pi wij (n),

j ∈ N ,

N

i=1
X

~p = {p1, p2, . . . , pN }

~p(n) = ~p w(n) = w(T )(n) ~p(T ),

~p = {01, 02, . . . , 1i, . . . , 0N },

~pi(n) = {wi1(n), wi2(n), . . . , wiN (n)}.

is the N × N unit matrix.

Making use of the total probability theorem we can determine the absolute probabilities pj(n) as follows:

where pi = P{ξ0 = i} is the initial probability. Clearly, pj(n) is the probability that the particle is in the state Sj at
the nth step. Introducing the row vector

Eq. (8) can be rewritten in the form:

where the upper index T indicates the transpose of matrix w(n) and vector ~p deﬁned by (7) and (9), respectively. If
the process starts from the state Si, then

where

where

and

and

2

(5)

(6)

(7)

(8)

(9)

(10)

III. TYPES OF STATES AND ASYMPTOTIC BEHAVIOR

A. Basic deﬁnitions

In order to use clear notions, we introduce several well-known deﬁnitions. If there is an integer n ≥ 0 such that
wjk(n) > 0, then we say the state Sk can be reached from the state Sj. If Sk can be reached from Sj and Sj can
be reached from Sk, then Sj and Sk are connected states. Obviously, if Sj and Sk are not connected, then either
wjk(n) = 0, or wkj (n) = 0. The set of states which are connected forms a class of equivalence. A Markov chain is
called irreducible if every state can be reached from every state i.e., the entire state space consists of only one class
of equivalence. In other words, the Markov chain is irreducible when all of the states are connected.

The probability fij (n) of passage from Si to Sj in exactly n steps, that is, without passing through Sj before the

nth step, is given by

There exists an important relationship between the probabilities wij (n) and fij (n) which is easy to prove. The
relationship is given by

fij (n) =

wij1 wj1j2 · · · wjn−1j.

j16=j, j26=j, ... ,jn−16=j
X

wij (n) =

fij(k) wjj (n − k),

∀ n ∈ Z.

n

Xk=1

One has to note that the expressions wjj (0) = 1 are the diagonal elements of the unit matrix w(0).

The proof of (12) is immediate upon applying the total probability rule. The particle passes from Si to Sj in n
steps if, and only if, it passes from Si to Sj for the ﬁrst time in exactly k steps, k = 1, 2, . . . , n, and then passes
from Sj to Sj in the remaining n − k steps. These “paths” are disjoint events, and their probabilities are given by
fij(k) wjj (n − k). Summing over k one obtains the equation (12).

Let us introduce the generating functions

ϕij (z) =

fij(n) zn

and

ωij(z) =

wij (n) zn.

∞

n=1
X

∞

n=1
X

Taking into account that wjj (0) = 1, from Eq. (12) we obtain

and from this

so we have

and in particular

ωij(z) = ϕij (z) [1 + ωjj(z)] ,

ϕij (z) =

ωij(z)
1 + ωjj (z)

,

Fij =

fij(n) =

∞

n=1
X

∞
n=1 wij(n)

∞
n=1 wjj (n)

,

1 +
P

P

wjj (n) =

∞

n=1
X

n=1 fjj (n)

∞
n=1 fjj(n)

.

1 −
P

P

Fij deﬁned by (16) is the probability that a particle starting its walk from Si passes through the state Sj at least

once. Clearly, Fii = Fi is the probability of returning to Si at least once.

More generally, the probability Fij(k) that a particle starting its walk from Si passes through Sj at least k times

is given by

Fij(k) =

fij(n)

Fjj (k − 1) = Fij Fjj (k − 1).

∞

"

n=1
X

#

3

(11)

(12)

(13)

(14)

(15)

(16)

(17)

In particular, the probability of returning to Si at least k times is given by Fii(k) = (Fii)k. Its limit

4

is the probability of returning to Si inﬁnitely often. It follows from the previous relationship that the probability that
a particle starting its walk from Si passes through Sj inﬁnitely many times is



so that

Rii = lim
k→∞

(Fii)k =

0,

if Fii < 1,




1,

if Fii = 1

Rij = lim
k→∞

Fij (k) = Fij Rjj,

0,

if Fii < 1,

Fij ,

if Fii = 1.

Rij =




We say that Si is a return state or a nonreturn state according as Fi > 0 or Fi = 0. As a further deﬁnition, we say
that Si is a recurrent state or a nonrecurrent state according as Fi = 1 or 0 ≤ Fi < 1. A nonrecurrent state is often
called a transient state.



The state Si is called periodic with period ℓ if a return to Si can occur only at steps ℓ, 2ℓ, 3ℓ, . . . and ℓ > 1 is the
greatest integer with this property. If n is not divisible by ℓ, then wij (n) = 0. If the period of each state is equal to
1, i.e., if ℓ = 1, then the Markov chain is called aperiodic. In the sequel we are dealing with aperiodic Markov chains.
A set C of states in a Markov chain is closed if it is impossible to move out from any state of C to any state outside
C by one-step transitions, i.e., wij (1) = wij = 0 if Si ∈ C and Sj 6∈ C. In this case wij (n) = 0 obviously holds for every
n ∈ Z. If a single state Si forms a closed set, then we call this an absorbing state, and we have wii = 1.

The states of a closed set C are recurrent states since the return probability Fi for any state Si ∈ C is equal to 1.
1 The set of states having return probabilities Fi < 1 is the
Therefore, the set of recurrent states is denoted by C.
set of transient states and it is denoted by T . Obviously, if Si ∈ T and Sj ∈ C, i.e., if Sj is an absorbing state, then
Fij is the probability that a particle starting at Si is ﬁnally absorbed at Sj .

Let νij be the passage time of a particle from the state Si to the state Sj, taking values m = 1, 2, . . . , with

probabilities fij(m). If

then the expected passage time τij = E{νij} from Si to Sj is deﬁned by

fij (m) = Fi,j = 1,

∞

m=1
X

∞

m=1
X

τij =

m fij(m) =

dϕij (z)
dz

(cid:20)

,

(cid:21)z=1

while if Fij < 1, one says that νij = ∞ with probability 1 − Fij , i.e., if Fij < 1, then the expected passage time
τij = ∞. If the state Sj = Si and it is recurrent, i.e., if Fii = Fi = 1, then the expectation

E{νii} =

m fii(m) =

dϕii(z)
dz

(cid:20)

(cid:21)z=1

= τii = µi

∞

m=1
X

(18)

is called mean recurrent time. If µi = ∞, then we say that Si is a recurrent null-state, whereas if µi < ∞, then we
say that Si is a recurrent non-null-state. If Fi < 1, i.e., the state Si is transient, then 1 − Fi is the probability that
the recurrence time is inﬁnitely long, and so µi = ∞.

We say that the recurrent state Si is ergodic, if it is not a null-state and is aperiodic, that is, if Fi = 1, µi < ∞ and

ℓ = 1.

1 The set C can be decomposed into mutually disjoint closed sets C1, C2, . . . , Cr such that from any state of a given set all states of that

set and no others can be reached . States C1, C2, . . . , Cr can be reached from T , but not conversely.

The ﬁrst statement is very simple, hence it is given without proof. If Sj is a transient or a recurrent null-state,

then for any arbitrary Si

holds.

If Si and Sj are recurrent aperiodic states due to the same closed set, then

irrespective of Si. 2

If i = j, then we have from Eq. (14) the formula

B. Asymptotic behavior

lim
n→∞

wij (n) = 0

lim
n→∞

wij (n) =

1
µj

,

ωjj (z) =

ϕjj (z)
1 − ϕjj (z)

.

Substituting this into (14) we obtain the following expression:

By using Tauber’s Theorem we can state that

ωij(z) = ϕij (z)

1 +

ϕjj (z)
1 − ϕjj (z)

=

ϕij (z)
1 − ϕjj (z)

.

(cid:19)

(cid:18)

(1 − z)

lim
z↑1

ϕij (z)
1 − ϕjj (z)

= lim
n→∞

wij (n).

Since Si and Sj are aperiodic recurrent states due to the same closed set,

i.e., the limit value we have to determine

Applying L’Hospital’s rule we ﬁnd that

lim
z↑1

ϕij (z) = lim
z↑1

ϕjj (z) = 1,

lim
z↑1

1 − z
1 − ϕjj (z)

.

lim
z↑1

1 − z
1 − ϕjj (z)

=

1
ϕ′(1)

=

1
µj

,

lim
n→∞

wij (n) =

Fij
µj

,

Fij = wij +

wikFkj ,

∀ Si ∈ T .

Sk∈T
X

and thus we obtain (20). This completes the proof.

As a generalization we would like to consider the case when Si is a transient state (Si ∈ T ) and Sj is an aperiodic

recurrent state due to the closed set C. It can be shown that

where Fij is the probability that a particle starting from Si will ultimately reach and stay in the state Sj ∈ C. In
other words, Fij is the absorption probability that satisﬁes the following system of equations:

2 In order to prove the limit relationship (20) Tauber’s Theorem is used instead of the lemma by Erd˝os-Feller-Kac.

5

(19)

(20)

(21)

(22)

(23)

(24)

(25)

Clearly, if T ∪ C contains all of the possible states of the particle, then

Sj ∈C
X
The proof of (24) follows immediately from (22). Since

Fij = 1.

∞

n=1
X

lim
z↑1

ϕij (z)

1 − z
1 − ϕjj (z)

=

fij(n)

=

1
µj

Fij
µj

,

we obtain the limit relationship (24).

Finally, we would like to present a brief classiﬁcation of Markov chains.

• A Markov chain is called irreducible if and only if all its states form a closed set and there is no other closed set

contained in it.

• A Markov chain is called ergodic if the probability distributions

pj(n) =

pk(0) wkj (n),

j ∈ N

N

Xk=1

always converge to a limiting distribution pj which is independent of the initial distribution pj(0), that is, when
limn→∞ pj(n) = pj, ∀ j ∈ N . All states of a ﬁnite, aperiodic irreducible Markov chain are ergodic.

• The probability distribution p(st)

i

initial distribution all the distributions pi(n) will coincide with p(st)
chain satisﬁes the following system of linear equations:

i

is a stationary distribution of a Markov chain if, when we choose it as an
. Every stationary distribution of a Markov

p(st)
j =

p(st)
i wij

and

p(st)
j = 1,

i
X

j
X

and conversely, each solution p(st)
probability distribution.

j

of this system is a stationary distribution of the Markov chain, if it is a

It is to mention that some parts of this short summary is based on the small but excellent book by Tak´acs [4].

IV. MARKOV CHAINS WITH ABSORBING STATES

In this section we are going to deal with Markov chains containing two absorbing states S1 and SN , and N − 2
transient states. In this case, the Markov chain is reducible and aperiodic. The set of its states is the union of two
closed sets C1 = {S1} and C2 = {SN }, and of the set of transient states T = {S2, S3, . . . , SN −1} The states S1 and
SN can be reached from each state of T but the converse doesn’t hold, no state of T can be reached from the states
S1 and SN . The states of T are non-recurrent since the particle leaves the set never to return to it. In contrary, the
states of C1 and C2 are ergodic.

Let us assume that the transition matrix w has the following form:

A. Chains of ﬁve states

1
0
0
0
0
w21 w22 w23
0 w31 w33 w34
0
0

0
0
0
0 w43 w44 w45
1
0

0

0



,






w = 





wij = 1.

j
X

where

6

(26)

(27)

The particle, which starts his walk from one of the states Si;
(i = 2, 3, 4), is captured when it enters the states S1
or S5. By using the foregoing formulae for Fi1 and Fi5, we can immediately obtain the capture probabilities by the
absorbing states S1 and S5, respectively. In order to have a direct insight into the nature of the process, we derive
the backward equations for the probabilities wij (n). Clearly,

and by introducing the generating function

we obtain the following system of equations:

w1j (n) = δ1j,
w2j (n) = w21 w1j (n − 1) + w22 w2j(n − 1) + w23 w3j(n − 1),
w3j (n) = w32 w2j (n − 1) + w33 w3j(n − 1) + w34 w4j(n − 1),
w4j (n) = w43 w3j (n − 1) + w44 w4j(n − 1) + w45 w5j(n − 1),
w5j (n) = δ5j,

gij(z) = δij +

wij (n) zn = δij + ωij (z),

|z| < 1,

∞

n=1
X

g2j(z) = δ2j + zw21 g1j(z) + zw22 g2j(z) + zw23 g3j(z),
g3j(z) = δ3j + zw32 g2j(z) + zw33 g3j(z) + zw34 g4j(z),
g4j(z) = δ4j + w43 g3j(z) + zw44 g4j(z) + zw45 g5j(z),

g1j(z) = δ1j

1
1 − z

,

g5j(z) = δ5j

1
1 − z

.

This can be simpliﬁed and rewritten in the form:

(1 − zw22) g2j(z) − zw23 g3j(z) = δ2j + w21

δ1j,

−zw32 g2j(z) + (1 − zw33) g3j(z) − zw34 g4j(z) = δ3j,

−zw43 g3j(z) + (1 − w44) g4j(z) = δ4j + w45

δ5j.

z
1 − z

z
1 − z

After elementary algebra, we can determine all the generating functions gij(z),
(i, j = 1, 2, 3, 4, 5), nevertheless we
are now interested only in those functions which correspond to processes starting from the state S3. In this case we
have

g31(z) =

g32(z) =

g33(z) =

g34(z) =

g35(z) =

z2
w32w21(1 − w44z)
1 − z
D(z)
w32z(1 − w44(z)z)
D(z)

,

,

(1 − w22z)(1 − w44z)
D(z)
w43(1 − w22z)
D(z)

,

,

z2
1 − z

w34w45(1 − w22z)
D(z)

,

where

D(z) = (1 − w44z)

(1 − w22z)(1 − w33z) − w23w32z2

− (1 − w22z)w34w43z2.

Applying Tauber’s Theorem we obtain that

(cid:2)

(cid:3)

lim
n→∞

w31(n) = lim
z↑1

(1 − z) g31(z) =

w32w21(1 − w44)
D(1)

,

7

(28)
(29)
(30)
(31)
(32)

(33)

(34)

(35)

(36)

(37)

(38)

(39)

(40)

(41)

(42)

(43)

and

we have

and

and

Since

we have

where

lim
n→∞

w3j(n) = lim
z↑1

(1 − z) g3j(z) = 0,

j = 2, 3, 4,

lim
n→∞

w35(n) = lim
z↑1

(1 − z) g35(z) =

w34w45(1 − w22)
D(1)

.

Performing the substitutions

w22 = 1 − w21 − w23, w33 = 1 − w32 − w34 w44 = 1 − w43 − w45,

w31(∞) =

w32w21(w43 + w45)
w34w45(w21 + w23) + w32w21(w43 + w45)

,

w35(∞) =

w34w45(w21 + w23)
w34w45(w21 + w23) + w32w21(w43 + w45)

.

It is elementary to show that

In order to prove these equations, let us take into account relationship (15) and write

F31 = ϕ31(1) = w31(∞)

and

F35 = ϕ35(1) = w35(∞).

ϕ31(z) =

ω31(z)
1 + ω11(z)

=

g31(z)
g11(z)

,

ϕ35(z) =

ω35(z)
1 + ω55(z)

=

g35(z)
g55(z)

.

g11(z) = g55(z) =

1
1 − z

,

F31 =

1
1 + r

,

and

F35 =

r
1 + r

,

r =

w34w45(w21 + w23)
w32w21(w43 + w45)

ϕ31(z) = (1 − z)g31(z)

and

ϕ35(z) = (1 − z)g35(z).

Comparing (43) and (45) with (49) we see that Eqs. (48) are true.

It is convenient to write the absorption probabilities F31 and F35 in the form:

and we see immediately that F31 + F35 = 1, as expected.

It seems to be worthwhile to study the history of a particle starting its random walk from the state S3. Let us
consider a trap containing a special ladder with 5 rungs. Each rung corresponds to a given state of the Markov chain
under investigation. The process starts when a particle enters (say,) on the third rung of the ladder, i.e., in the state
S3. Once the particle has entered, it is free to move up and down the rungs randomly . Fig. 1 illustrates this random
walk. If the particle reaches the states either S1 or S5, it is absorbed. (If the random walk is considered as a game,

8

(44)

(45)

(46)

(47)

(48)

(49)

(50)

(51)

9

(52)

S5

S4

S3

S2

S1

✻

❄

✻

❄

✻

❄

w31HnL

w33HnL

w35HnL

FIG. 1:

Illustration of the random walk on a ladder of ﬁve rungs

0.8

0.6

0.4

0.2

y
t
i
l
i

b
a
b
o
r
p

0

0

20

40

60

80

100

number of steps

FIG. 2: Dependencies of the probabilities w31(n), w33(n) and w35(n) on the number of steps n

then the absorption state with probability smaller than 1/2 is the “winning” state.) Having chosen the transition
matrix

1

0
4/36 24/36 8/36

0

0
0

5/36 29/36 2/36

0
0

4/36 24/36 8/36
0

1

0

0
0
0



,






w = 





0
0
0

we calculated the dependencies of probabilities w31(n), w33(n) and w35(n) on the number of steps n. The results of
calculation are shown in Fig. 2. We see that the probability to ﬁnd the particle after n ≈ 100 steps in the transient
state S3 is practically zero. The same holds for the transient states S2 and S4. After n ≈ 100 steps the particle is
absorbed either in S1 with probability w31(100) ≈ F31 = 5/9 or in S5 with probability w35(100) ≈ F35 = 4/9.

It is instructive to determine also the probabilities F32, F33 and F34. As a reminder, we note that F3j is the
(j = 2, 3, 4) at least once. By using the transition
probability that a particle starting from S3 passes through Sj ,
matrix (52) we obtain the following values: F32 = 15/19, F33 = 11/12 and F34 = 6/11. Fig. 3 shows the histogram of
these probabilities. It is evident that passing through either S1 or S5 at least once means that the particle is absorbed.

10

(53)

(54)

probability

0.8

0.6

0.4

0.2

FIG. 3: Probabilities that a particle passes through the state Sj, (j = 1, 2, 3, 4, 5) at least once provided that it started from S3

3®1

3®2

3®3

3®4

3®5

As expected in the present case, the probability F33 that the particle starting from S3 returns to S3 at least once, is
nearly 1. It is to mention that the two absorbing states S1 and S5 are recurrent since F11 = F55 = 1.

In what follows we would like to deal with the determination of the absorption time probability. Denote by τi the
number of steps leading to the absorption of a particle starting its random walk from the state Si. By deﬁnition,
fi1(n) and fi5(n) are the probabilities that the particle starting from the state Si, (i = 2, 3, 4) is absorbed exactly at
the nth step in S1 or in S5, respectively. Hence we can write that

P{τi = n} = Ti(n) = fi1(n) + fi5(n),

i = 2, 3, 4.

It is easy to prove that

From (12) one obtains

Ti(n) = wi1(n) − wi1(n − 1) + wi5(n) − wi5(n − 1),

∀ n ≥ 1.

wi1(n) =

fi1(k) w11(n − k),

wi5(n) =

fi5(k) w55(n − k),

n

Xk=1
n

Xk=1

w11(ℓ) = w55(ℓ) = 1,

∀ ℓ ≥ 0,

and by taking into account that

one has

wi1(n) =

fi1(k)

and

wi5(n) =

fi5(k).

n

Xk=1

n

Xk=1

It follows immediately from these equations that

fi1(n) = wi1(n) − wi1(n − 1)

and

fi5(n) = wi5(n) − wi5(n − 1),

and this completes the proof. The absorption time probabilities Ti(n),
“forward” equations:

(i = 2, 3, 4) can be determined by the

fi1(n) =

wiℓ(n − 1) wℓ1

4

Xℓ=2

11

(55)

(56)

(57)

and

By using these expressions one can write

fi5(n) =

wiℓ(n − 1) wℓ5.

4

Xℓ=2

4

Xℓ=2

Ti(n) =

wiℓ(n − 1) [ wℓ1 + wℓ5] ,

which in the case of w deﬁned by (27) has the following form:

For the sake of completeness, we would like to show that

Ti(n) = wi2(n − 1) w21 + wi4(n − 1) w45.

In the case of Eq. (53) we see that

Ti(n) = 1.

∞

n=1
X

Ti(n) = Fi1 + Fi5,

∞

n=1
X

and by using the expression (26) we ﬁnd (57). In the case of Eq. (55)

∞

n=1
X

4

∞

Xℓ=2 "

n=1
X

Ti(n) =

wiℓ(n − 1)

[ wℓ1 + wℓ5] =

#

[δiℓ + ωiℓ(1)] [ wℓ1 + wℓ5] =

giℓ(1) [ wℓ1 + wℓ5] = Fi1 + Fi5 = 1.

4

Xℓ=2

4

Xℓ=2

T2HnL

T3HnL

T4HnL

<Τ2>=15.7

<Τ3>=19.0

<Τ4>=9.3

y
t
i
l
i

b
a
b
o
r
p

e
m

i
t

n
o
i
t
b
r
o
s
b
a

0.2

0.15

0.1

0.05

0

0

10

20

30

40

50

number of steps

FIG. 4: Absorption time probabilities of a particle starting its random walk from the state Si, (i = 2, 3, 4)

Using the transition matrix w given by (52), we calculated the dependence of the probability Ti(n) on the number
of steps n. The results are seen in Fig. 4. As expected, if the starting state is S3, then the probability T3(n) varies

diﬀerently with the step number as the probabilities T2(n) and T4(n). It is characteristic the probabilities have a
rather long tail. Since Ti(n) is the probability that a particle starting from Si is absorbed exactly in the nth step,
the expectation and the standard deviation of the absorption time τi are given by

E{τi} =

n Ti(n) =< τi >,

∞

n=1
X

D{τi} =

(n− < τi >)2 Ti(n)
#

∞

"

n=1
X

1/2

.

and

E{τi}
D{τi}

For a transition matrix of the form (52) these values are presented in the Table I.

TABLE I: Expectations and the standard deviations of the absorption time

S2
15.7
16.3

S3
19.0
16.4

12

(58)

(59)

S4
9.3
13.3

B. Properties of the absorption probability F31

As it has been shown, F31 is the probability that a particle starting its random walk from the state S3 is ﬁnally
absorbed in the state S1. 3 If F31 > 1/2, then S1 is called a “losing” state, while if F31 < 1/2, then it is a “winning”
state. The game is “fair” when F31 = 1/2, i.e. when the equation

w32w21 (w43 + w45) = w34w45 (w21 + w23)

(60)

is fulﬁlled as it follows from Eq. (51).

Astumian [1] proposed two transition matrices, namely

1

0
4/36 24/36 8/36

0

0
0

1

0
4/36 24/36 8/36

0

0
0

w1 =

5/36 29/36 2/36

w2 =

5/36 29/36 2/36

0
0

4/36 24/36 8/36
0

0

1

0
0

4/36 24/36 8/36
0

0

1










0
0
0










0
0
0

0
0
0










resulting in the absorption probability F31 = 5/9 > 1/2 and showed that the arithmetic mean of these two matrices

0
0
0










1
2

w =

(w1 + w1) =

1

0
9/72 53/72 10/72

0

0
0

=

9/72 53/72 10/72

0
0
0

0
0

9/72 53/36 10/72
0

1

0










0
0
0










3 There is no need to deal separately with the absorption probability F35 since F31 + F35 = 1.

13

(61)

(62)

brings about the probability F31 = 9/19 < 1/2, i.e., in this case the state S1 becomes “winning” state. This property
of the transition matrix (27) is general if the diagonal entries of the matrix are diﬀerent from zero. By using a simple
example we would like to demonstrate this statement.

Let us choose the transition matrix in the following form:

0 < a < 1,

0 < b < 1,

0 < a + b < 1

and

− a < x < min(b, 1 − a − b).

If x = 0 or x = b − a, then the game is “fair”, i.e., F31 = 1/2. The function H(x) assumes its minimal value at

0

1
a 1 − a − b
0
0
0

b
0
0

0
b
1 − a − b − x
a + x
0

0
0
a + x

0

1 − a − b b − x

0
0
0

1

.










w =










F31 = H(x) =

ab
ab + (a + x)(b − x)

,

One obtains immediately that

where

and this value is

x = xmin =

(b − a),

1
2

1/2,

if a = b,

H(xmin) = 


4ab

4ab+(a+b)2 < 1/2,

if a 6= b.

H(xmin + y) = J(y) =

4ab
4ab + (a + b)2 − 4y2 .

Introducing the notation x = xmin + y one has



Choosing y according to the inequalities

i.e., y > |xmin| and a 6= b one ﬁnds that

x1 = xmin + y > 0

and

x2 = xmin − y < b − a,

H(x1) = H(x2) >

and H

1
2

x1 + x2
2

<

1
2

.

(cid:19)

(cid:18)

Evidently, there are inﬁnitely many pairs of transition matrices which result in probabilities of losing in the state S1
but the arithmetic means of corresponding pairs bring about probabilities of winning in the state S1.

For the sake of illustration in Fig. 5 the probability F31 = H(x) vs. x curve is plotted by the values a = 1/4 and

b = 1/8. The black points c1, c2 and c correspond to the probabilities

H(x1 = 1/16) = H(x2 = −3/16) = 8/13

and H

(x1 + x2) = −1/16

= 8/17,

respectively. It seems to be not superﬂuous to write down the corresponding transition matrices:

1

0
4/16 10/16 2/16

0

0
0

1

0
4/16 10/16 2/16

0

w1 =

2/16 9/16 5/16

w2 =

2/16 13/16 1/16

(63)

0
0

5/16 10/16 1/16
0

0

1

0
0

1/16 10/16 5/16
0

0

1

0
0
0

,



















0
0
0

(cid:21)

0
0

0
0
0

,










1
2

(cid:20)










0
0
0

14

(64)

a=1(cid:144)4, b=1(cid:144)8

HHxminL=8(cid:144)17»0.47
xmin=-1(cid:144)16

c2

c1

L
x
H
H
=
1
3
F

y
t
i
l
i

b
a
b
o
r
p

0.75

0.7

0.65

0.6

0.55

0.5

0.6

L
n
H
1
3
w

0.5

0.4

s
e
i
t
i
l
i

b
a
b
o
r
p

0.3

0.2

0.1

0

0

-0.2 -0.15 -0.1 -0.05

0

0.05

0.1

c

x values

FIG. 5: Dependence of F31 = H(x) on the parameter x of the transition matrix (61) when a = 1/4 and b = 1/8

and

properties.

w =

(w1 + w2) =

1
2

1

0
4/16 10/16 2/16

0

0
0

2/16 11/16 3/16

0
0
0

0
0

3/16 10/16 3/16
0

0

1










0
0
0

.










By choosing y values in the allowed interval, we can construct inﬁnitely many transition matrices with just described

p=1(cid:144)2
w1
w2
w

10

20

30

40

50

number of steps

FIG. 6: Dependence of w31(n) on the number of steps n in the case of p = 1/2

Let us now deﬁne a Markov chain with transition matrix w randomly chosen from w1 and w2 deﬁned by (63). In

15

1
3
F

y
t
i
l
i

b
a
b
o
r
p

0.6

0.58

0.56

0.54

0.52

0.5

0.48

losing

winning

0

0.2

0.4

0.6

0.8

1

probability of choosing the game w1

FIG. 7: Dependence of the absorption probabilities F31(n) on the chance p moving the particle at a given step according to the transition
matrix w1

this case

i.e.,

w(n) = [pw1 + (1 − p)w2] × w(n − 1),

w(n) = [pw1 + (1 − p)w2]n .

(65)

In Fig. 6 the dependencies of the absorption probabilities w31(n) 4 on the number of steps n are shown when the
transition matrices are w1, w2 and w, respectively. The last one corresponds to the random selection of the entries
from w1 and w2 with probability p = 1/2. Obviously, not all values of p ∈ [0, 1] bring about a “winning” game, i.e.,
an absorption probability less than 1/2.

Taking into account the transition matrices w1 and w2 deﬁned by (63), we determined the dependence of F31 on p.
As seen in Fig. 7, there is a well deﬁned subinterval [p1, p2] ∈ [0, 1] containing the p values which result in absorption
probabilities F31 smaller than 1/2. In the present case we obtained that p1 = 0.25 and p2 = 0.75.

V. CONCLUSIONS

It has been shown that the random walk of a particle deﬁned by the stochastic transition matrix of a Markov chain
is equivalent to an Astumian type game if the diagonal entries of the matrix are diﬀerent from zero and the ﬁrst
(w11) as well as the last (wN N ) entries are equal to 1. By using a simple example, we have proved that there are
inﬁnitely many pairs of transition matrices which result in absorption probabilities in the state S1 larger than 1/2
but the arithmetic means of the corresponding pairs lead to probabilities smaller than 1/2.

[1] R.D. Astumian, Sci. Am, 285(7), 56 (2001)
[2] E.W. Piotrowski and J. Sladowski, LANL e-print server physics/0408122 (2004)
[3] R.D. Astumian, LANL e-print server physics/0409029 (2004)
[4] L. Tak´acs, Stochastic Processes, Problems and Solutions, John Wiley & Sons Inc., New York (1960)

4 As seen before, w31(n) is the ﬁrst entry of the third row of the matrix w(n).

