Preprint typeset in JHEP style - HYPER VERSION

The probability of making a correct decision in
hypotheses testing as estimator of quality of planned
experiments

Institute for high energy physics, 142281 Protvino, Russia
E-mail: Serguei.Bitioukov@cern.ch, bityukov@mx.ihep.su

Sergei I. Bityukov

Nikolai V. Krasnikov

Institute for nuclear research RAS, Prospect 60-letiya Octyabrya, 117312 Moscow,
Russia
E-mail: Nikolai.Krasnikov@cern.ch,

Abstract: In the report the approach to estimation of quality of planned experiments is
considered. This approach is based on the analysis of uncertainty, which will take place
under the future hypotheses testing about the existence of a new phenomenon in Nature.
The probability of making a correct decision in hypotheses testing is proposed as estimator
of quality of planned experiments. This estimator allows to take into account systematics
and statistical uncertainties in determination of signal and background rates.

Keywords: Uncertainty, Hypotheses testing, Probability.

3
0
0
2
 
p
e
S
 
4
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
1
3
0
9
0
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

2. What is meant by the probability of making a correct decision in hy-

4. How to take into account the statistical uncertainty in the determination

5. A possible way to take into account the systematics

Contents

1.

Introduction

potheses testing?

3. The choice of critical area

of ns and nb?

6. Conclusions

1. Introduction

1

2

3

4

8

8

One of the common goals in the forthcoming experiments is the search for new phenomena.
In estimation of the discovery potential of the planned experiments the background cross
section (for example, the Standard Model cross section) is calculated and, for the given
integrated luminosity L, the average number of background events is nb = σb · L. Suppose
the existence of new physics leads to additional nonzero signal cross section σs with the
same signature as for the background cross section that results in the prediction of the
additional average number of signal events ns = σs · L for the integrated luminosity L. The
total average number of the events is < n >= ns + nb = (σs + σb) · L. So, as a result of new
physics existence, we expect an excess of the average number of events. Let us suppose the
probability of the realization of n events in the experiment is described by function f (n; λ)
with parameter λ.

In the report the approach to estimation of quality of planned experiments is consid-
ered. This approach is based on the analysis of uncertainty, which will take place under the
future hypotheses testing about the existence of a new phenomenon in Nature. We con-
sider a simple statistical hypothesis H0: new physics is present in Nature (i.e. λ = ns + nb)
against a simple alternative hypothesis H1: new physics is absent (λ = nb). The value of
uncertainty is deﬁned by the values of the probability to reject the hypothesis H0 when it is
true (Type I error α) and the probability to accept the hypothesis H0 when the hypothesis
H1 is true (Type II error β).

This uncertainty characterises the distinguishability of the hypotheses under the given
choice of critical area. The probability of making a correct decision in hypotheses testing
is [1]

– 1 –

1 − ˜κ = 1 −

α + β
2 − (α + β)

.

(1.1)

The 1 − ˜κ is the estimator of quality of planned experiments. This estimator allows to
take into account systematics and statistical uncertainties [2] in determination of signal
and background rates. Application of given approach in high energy physics is considered.

2. What is meant by the probability of making a correct decision in hy-

potheses testing?

Let us determine what we mean by the probability of making a correct decision under the
future hypotheses testing about the presence or absence of the new phenomenon in Nature
in case of carrying out the planned experiment. Let us use the frequentist approach, i.e.
consider all the possible results of the experiment in cases when both the hypothesis H0
is true or the hypothesis H1 is true, deﬁne the criterion for the hypothesis choice and
calculate the probability of making a correct decision. It is possible, as we suppose that
the hypotheses H0 and H1 have equal rights. In opposite case some subjectivism appears
in making the decision and there is no possibility to use the statistical methods directly.
So, we will consider 2 conditional distributions of probabilities (see, Fig.1)

f0(n) = f (n; ns + nb),
f1(n) = f (n; nb)

(cid:26)

(2.1)

making numerical calculations 1.

Figure 1: The probability distributions f0(n) (II) and f1(n) (I) for the case of 5 signal events and
1 background event.

Under the hypotheses testing we can estimate the distinguishability of the hypotheses

H0 and H1. There are 3 possibilities.

• Distributions f0(n) and f1(n) have no overlapping, hence, the distributions are com-
pletely distinguishable and any result of the experiment will give the correct choice
between hypotheses.

1The authors suppose that any prior suppositions about H0 and H1 can be included to f0(n) and f1(n).

– 2 –

• Distributions f0(n) and f1(n) coincide completely. It means, that it is impossible to

get a correct answer, i.e. f0(n) and f1(n) are not distinguishable.

• Distributions f0(n) and f1(n) do not coincide, but they have an overlapping. In this
case after choosing a critical value (or a critical area) same way, it is possible to count
up Type I error (α) and Type II error (β). Their combination

˜κ =

α + β
2 − (α + β)

(2.2)

is the probability of making incorrect choice in favour of one of the hypothesis. Ac-
cordingly, 1 − ˜κ is the probability to make a correct choice under the given critical
value.

3. The choice of critical area

Let the probability of the realization of n events in the experiment be described by Poisson
distribution with parameter λ, i.e.

λn
n!
In this case the errors of Type I and II, which will take place in testing of hypothesis

f (n; λ) =

e−λ.

(3.1)

H0 versus hypothesis H1, can be written as follows:

α =

f (i; ns + nb) =

f0(i),

nc

Xi=0

nc

nc

Xi=0

nc

β = 1 −

f (i; nb) = 1 −

f1(i),

Xi=0

Xi=0






nc = [

ns
ln(ns + nb) − ln(nb)

],

where nc is a critical value. Correspondingly, the magnitude κ = α + β, and, hence, the
magnitude ˜κ =

will have minimal value [3] under

κ
2 − κ

where square brackets mean the integer part of a number. This formula is the consequence
of the equation

κ = α + β = 1 −

(f1(i) − f0(i))

nc

Xi=0
under the choice of nc from the condition f0(i) ≤ f1(i). As soon as f0(i) > f1(i) the value
of κ (and, correspondingly, ˜κ) increases. Let us note, that following the given discourse,
we can choose critical values so that ˜κ could be minimal and the probability of correct
decision 1 − ˜κ - maximum for any pair of distributions. As a result it is possible to say,
that the value 1 − ˜κ under the optimum choice of critical value characterises the quality of

(3.2)

(3.3)

(3.4)

– 3 –

planned experiment. Let us name this value the Probability of Making a Correct Decision
(PMCD).

Notice, that such approach works for arbitrary distributions (see, Fig.2), including

multidimentional ones.

f(x)

f  (x)
0

f  (x)
1

f  (x)1

x

Figure 2: The estimation of uncertainty in hypotheses testing for arbitrary distributions.

In the Fig.3 the behaviour of the probability PMCD, depending on the time of making

the experiment under diﬀerent ratio of rates of signal and background events is shown.

Figure 3: The dependence of PMCD versus time of measurements for diﬀerent rates of appearance
of signal and background events.

4. How to take into account the statistical uncertainty in the determina-

tion of ns and nb?

Let the values ns = ˆns and nb = ˆnb be known from Monte Carlo calculations.
In this
case they are random variables. These values can be considered as estimators of unknown

– 4 –

parameters. Consequently, the values nc, α and β are also random variables. It means that
ˆ1 − ˜κ is the estimator of the probability of making a correct decision in hypotheses testing.
Let us consider how the uncertainties in the knowledge of ns and nb inﬂuence the value of
magnitude PMCD 1 − ˜κ. Suppose, as before, that the streams of signal and background
events are Poisson’s.

Let us write down the density of Gamma distribution Γa,n+1 as

where a is a scale parameter, n + 1 > 0 is a shape parameter, λ > 0 is a random variable,
and Γ(n + 1) = n ! is a Gamma function.

Let us set a = 1, then for each n a continuous function

gn(a, λ) =

an+1
Γ(n + 1)

e−aλλn,

gn(λ) =

e−λ, λ > 0, n > −1

λn
n!

(4.1)

(4.2)

is the density of Gamma distribution Γ1,n+1 with the scale parameter a = 1 (see Fig.4).
The mean, mode, and variance of this distribution are given by n + 1, n, and n + 1,
respectively.

As it follows from the article [4] (see, also [5]) and is clearly seen from the identity [6]

(Fig.5)

f (n; λ1) +

gˆn(λ)dλ +

f (n; λ2) = 1 ,

i.e.

(4.3)

λ2

Z

λ1

ˆn

Xn=0

∞

Xn=ˆn+1

∞

1 e−λ1
λn
n!

λ2

λˆne−λ
ˆn!

+

Z

λ1

dλ +

ˆn

Xn=0

2 e−λ2
λn
n!

= 1

Xn=ˆn+1

for any λ1 ≥ 0 and λ2 ≥ 0, the probability of true value of parameter of Poisson distribution
to be equal to the value of λ in the case of one observation ˆn has probability density of
Gamma distribution Γ1,1+ˆn. The Eq.(4.3) shows that we can mix Bayesian and frequentist
probabilities in the given approach.

It allows to transform the probability distributions f (i; ns+nb) and f (i; nb) accordingly

to calculate the probability of making a correct decision (PMCD)

β = 1 −

gnb(λ)

f (i; λ)dλ = 1 −

(4.4)

gns+nb(λ)

f (i; λ)dλ =

∞

α =

Z
0

∞

Z

0

nc

Xi=0
nc

1 − ˜κ = 1 −

Xi=0

α + β
2 − (α + β)

.






nc

Xi=0

C i
ns+nb+i
2ns+nb+i+1

,

nc

Xi=0

C i
nb+i
2nb+i+1

,

Here the critical value nc under the future hypotheses testing about the observability is
chosen in accordance with test of equal probability [1] and C i

. Also we

N is

N !
i!(N − i)!

– 5 –

Figure 4: The behaviour of the probability density of the true value of parameter λ for the Poisson

distribution in case of n observed events versus λ and n. Here f (n; λ) = gn(λ) =
is both
the Poisson distribution with the parameter λ along the axis n and the Gamma distribution with
a shape parameter n + 1 and a scale parameter 1 along the axis λ.

λn
n!

e−λ

suppose that the Monte Carlo luminosity is exactly the same as the data luminosity later
in the experiment.

The Poisson distributed random values have a property: if ξi ∼ P ois(λi), i = 1, 2, . . . , m

then

ξi ∼ P ois(

λi). It means that if we have m observations ˆn1, ˆn2, . . ., ˆnm of the

m

Xi=1

m

Xi=1

same random value ξ ∼ P ois(λ), we can consider these observations as one observation
m

ˆni of the Poisson distributed random value with parameter m · λ. According to Eq.(4.3)

Xi=1
the probability of true value of parameter of this Poisson distribution has probability den-
i=1 ˆni. Using the scale parameter m one can show that
sity of Gamma distribution Γ1,1+
the probability of true value of parameter of Poisson distribution in the case of m obser-
vations of the random value ξ ∼ P ois(λ) has probability density of Gamma distribution
Γm,1+

i=1 ˆni, i.e. (see Eq.(4.1))

P

m

m

P

G(

ˆni, m, λ) = g(

m

i=1 ˆni)(m, λ) =

X

P

m
i=1 ˆni)
m(1+
P
m
i=1 ˆni)!
(
P

e−mλλ(

m

i=1 ˆni).

P

(4.5)

– 6 –

Figure 5: The Poisson distributions f (n, λ) for λ’s determined by the conﬁdence limits ˆλ1 = 1.51
and ˆλ2 = 8.36 in case of the observed number of events ˆn = 4 are shown. The probability density
of Gamma distribution with a scale parameter a = 1 and a shape parameter n + 1 = ˆn + 1 = 5 is
shown within this conﬁdence interval.

Let us assume that the integrated luminosity of planned experiment is L and the
integrated luminosity of Monte Carlo data is m · L. For instance, we can divide the
Monte Carlo data into m parts with luminosity corresponding to the planned experiment.
The result of Monte Carlo experiment in this case looks as set of m pairs of numbers
( (nb)i, (nb)i + (ns)i ), where (nb)i and (ns)i are the numbers of background and signal

events observed in each part of Monte Carlo data. Let us denote Nb =

(nb)i and

m

Xi=1

Ns+b =

((ns)i + (nb)i). Correspondingly (see page 98, [5]),

G(Nb+s, m, λ)

f (i; λ)dλ =

nc

Xi=0
nc

Xi=0

nc

Xi=0

C i

Ns+b+i

m1+Ns+b
(m + 1)1+Ns+b+i ,

nc

Xi=0

C i

Nb+i

m1+Nb
(m + 1)1+Nb+i .

β = 1 −

G(Nb, m, λ)

f (i; λ)dλ = 1 −

(4.6)

As a result, we have a generalized system of equations for the case of diﬀerent luminosity in

m

Xi=1

∞

α =

Z

0






∞

Z
0

– 7 –

planned data and Monte Carlo data to calculate the PMCD 1 − ˜κ = 1 −

set of values C i

N +i

m1+N
(m + 1)N +i+1

, i = 0, 1, . . . is a negative binomial (Pascal) distribution

with real parameters N + 1 and

, mean value

and variance

1
m + 1

1 + N
m

(1 + m)(1 + N )
m2

.

α + β
2 − (α + β)

. The

5. A possible way to take into account the systematics

We consider here forthcoming experiments to search for new physics.
In this case we
must take into account the systematic uncertainty which have theoretical origin without
any statistical properties. For example, two loop corrections for most reactions at present
are not known. It means that we can only estimate the scale of inﬂuence of background
uncertainty on the observability of signal, i.e. we can point the admissible level of uncertaity
in theoretical calculations for given experiment proposal.

Suppose uncertainty in the calculation of exact background cross section is determined
by parameter δ, i.e. the exact cross section lies in the interval (σb, σb(1 + δ)) and the exact
value of average number of background events lies in the interval (nb, nb(1 + δ)). Let us
suppose nb ≫ ns.
In this instance the discovery potential is the most sensitive to the
systematic uncertainties. As we know nothing about possible values of average number of
background events, we consider the worst case [3]. Taking into account Eqs.(3.2) we have
the formulae 2

nc

α =

f (i; nb + ns)

Xi=0

nc

β = 1 −

Xi=0
1 − ˜κ = 1 −

f (i; nb(1 + δ))

α + β
2 − (α + β)

,






nc = [

ns − nb · δ
ln(ns + nb) − ln(nb · (1 + δ))

].

(5.1)

(5.2)

where nc is

6. Conclusions

In this paper we have considered the probability of making a correct decision in hypotheses
testing to estimate the quality of planned experiments. This estimator allows to measure
the distinguishability of models. We estimate the inﬂuence of statistical uncertainty in
determination of mean numbers of signal and background events and propose a possible
way to take into account eﬀects of one-sided systematic errors.

2Eqs.(5.1) realize the worst case when the background cross section σb(1 + δ) is the maximal one, but
we think that both the signal and the background cross sections are minimal. Also, we suppose that
nb(1 + δ) < ns + nb.

– 8 –

The author is grateful to V.A. Matveev and V.F. Obraztsov for the interest and useful
comments, S.S. Bityukov, Yu.P. Gouz, G. Kahrimanis, V.V. Smirnova, V.A. Taperechkina
for fruitful discussions and E.A. Medvedeva for help in preparing the paper. This work has
been supported by grant RFBR 03-02-16933.

Acknowledgments

References

[1] S.I.Bityukov and N.V.Krasnikov, On the observability of a signal above background,

Nucl.Instr.&Meth. A452 (2000) 518.

[2] S.I.Bityukov, On the Signal Signiﬁcance in the Presence of Systematic and Statistical

Uncertainties, JHEP 09 (2002) 060,
http://www.iop.org/EJ/abstract/1126-6708/2002/09/060;
e-Print: hep-ph/0207130, http://xxx.lanl.gov/abs/hep-ph/0207130

[3] S.I. Bityukov and N.V. Krasnikov, New physics discovery potential in future experiments,

Modern Physics Letters A13 (1998) 3235.

[4] E.T. Jaynes: Papers on probability, statistics and statistical physics, Ed. by R.D.
Rosenkrantz, D.Reidel Publishing Company, Dordrecht, Holland, 1983, p.165.

[5] A.G.Frodesen, O.Skjeggestad, H.Toft, Probability and Statistics in Particle Physics,

UNIVERSITETSFORLAGET, Bergen-Oslo-Tromso, 1979, p.408.

[6] S.I. Bityukov, N.V. Krasnikov, V.A. Taperechkina, Conﬁdence intervals for Poisson

distribution parameter, Preprint IFVE 2000-61, Protvino, 2000; also, e-Print:
hep-ex/0108020, 2001.

– 9 –

