Spatial Random Field Models Inspired from Statistical Physics

APS/123-QED

with Applications in the Geosciences

Dionissios T. Hristopulos∗

Department of Mineral Resources Engineering

Technical University of Crete

Chania 73100, Greece†

Abstract

The spatial structure of ﬂuctuations in spatially inhomogeneous processes can be modeled in

terms of Gibbs random ﬁelds. A local low energy estimator (LLEE) is proposed for the interpo-

lation (prediction) of such processes at points where observations are not available. The LLEE

approximates the spatial dependence of the data and the unknown values at the estimation points

by low-lying excitations of a suitable energy functional. It is shown that the LLEE is a linear,

unbiased, non-exact estimator. In addition, an expression for the uncertainty (standard deviation)

of the estimate is derived.

PACS numbers: 02.50.Ga,02.50.Fz,05.40.-a,05.10.Ln,89.60.-k

Keywords:

spatial correlation, excitations, hamiltonian, stochastic estimation

5
0
0
2
 
t
c
O
 
5
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
5
3
0
0
1
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

∗Electronic address: dionisi@mred.tuc.gr ; URL: http://www.mred.tuc.gr/dionisi.htm
†This work is partially supported by the EPEAEK Program: Environment Pithagoras II.

1

I.

INTRODUCTION

Spatial random ﬁelds (SRF’s) have applications in hydrology [9, 11], oil reservoir engi-

neering [4], environmental pollutant mapping and risk assessment [1], mining exploration

and reserves estimation [3], as well as environmental health studies [2]. SRF’s model spatial

correlations in variables such as mineral concentrations, dispersion of environmental pol-

lutants, soil and rock permeability, and ﬂow ﬁelds in oil reservoirs. Knowledge of spatial

correlations enables (i) generating predictive iso-level contour maps (ii) estimating the uncer-

tainty of predictions and (iii) developing simulations that partially reconstruct the process of

interest. Geostatistics provides mathematical tools for these tasks. The classical approach

is based on Gaussian SRF’s (GSRF’s) and various generalizations for non-Gaussian distri-

butions [10, 13]. For GSRF’s the spatial structure is determined from the covariance matrix,

which is estimated from the distribution of the data in space.

An SRF state (realization) can be decomposed into a deterministic trend mx(s), a cor-
related ﬂuctuation X ′(s), and an independent random noise term, ǫ(s) so that X(s) =

mx(s) + X ′

λ(s) + ǫ(s). The trend represents large-scale variations of the ﬁeld, which can be
obtained in principle by ensemble averaging, i.e. mx(s) = E[X(s)]. In practice, the trend

is often determined from a single available realization. The ﬂuctuation term corresponds

to ‘fast variations’ that reveal structure at small scales, which nonetheless exceed a cut-oﬀ

λ. The random noise represents non-resolved inherent variability due to resolution limits,

purely random additive noise, or non-systematic measurement errors. It is typically assumed

that the ﬂuctuation is a second-order stationary SRF, or an intrinsic SRF with second-order

stationary increments [15]. The observed SRF after detrending is a zero-mean ﬂuctuation:

X ∗(s) = Xλ(s) + ǫ(s).

In statistical physics the probability density function (pdf) of a ﬂuctuation ﬁeld x(s)

governed by an energy functional H[x(s)] is expressed as fx[x(s)] = Z −1 exp

}
where Z is the partition function. Using this representation, the Gaussian joint pdf in

H[x(s)]

{−

,

classical geostatistics is expressed in terms of the functional:

H[x(s)] =

ds

ds′x(s) [Gx]−1(s

s′) x(s′).

(1)

In Eq. (1), [Gx]−1(s

s′) is the inverse of the covariance function Gx(s

s′), which determines

−

the spatial disorder. While statistical physics plays an increasingly important role in under-

−

−

1
2

Z

Z

2

standing the behavior of complex geophysical systems [12], its applications in geostatistical

analysis have not yet been explored.

Spartan Spatial Random Fields (SSRF’s) model spatial correlations in terms of ‘inter-

actions’, in the spirit of Markov SRF’s [14].

In [6] general properties and permissibility

conditions were derived for the ﬂuctuation-gradient-curvature (FGC) SSRF model, with the

following energy functional:

Hfgc[Xλ] =

1
2η0ξd

Z

n

ds

[Xλ(s)]2 + η1 ξ2 [

Xλ(s)]2 + ξ4

2Xλ(s)

2

.

(2)

∇

∇

(cid:2)

o

(cid:3)

For this model, a moment-based method for parameter estimation was proposed and

tested with simulated data; methods for SSRF non-constrained simulation were presented

in [7]; systematic reduction of anisotropic disorder, based on the covariance tensor identity,

was investigated in [5, 8]. The FGC model [6] has three main parameters: the scale coeﬃcient

η0, the covariance-shape coeﬃcient η1, and the correlation length ξ. Bochner’s theorem [1]

for the covariance function requires η1 >

2. A coarse-graining kernel is used to cut oﬀ

the ﬂuctuations at kc

λ−1 [6, 7], leading to band-limited covariance spectral density and

−

∝

diﬀerentiable ﬁeld conﬁgurations (in the mean square sense) [7].

II. OPERATOR NOTATION

Let Ω

Rd denote the area of interest and A(Ω) its boundary. Assume an SSRF over this

∈

area with parameters η0, η1, ξ, with a ﬁnite variance σ2

x. It is then possible to normalize the

SSRF to unit variance by simply dividing the states with the standard deviation. Next, it is

possible to express the pseudo-energy functional in terms of an operator notation notation

as follows:

where

H

H[Xλ]

Xλ(s)

Xλ(s)

+ S(A)

≡ h

| H |

i

≡

H

ds Xλ(s)

[Xλ(s)] + S(A),

(3)

ZΩ
is a ‘pseudo-hamiltonian’ operator and S(A) is a surface term. Assuming that the

surface term is negligible, the eigenvalue equation becomes:

where ψE(s; b) is an eigenfunction, E is the corresponding energy and b a degeneracy

ψE(s; b)

= E ψE(s; b),

H |

(4)

i

3

vector index, which may include both discrete and continuous components. Since the SSRF

has been normalized to unit variance, the eigenfunctions ψE(s; b) can also be assumed

normalized, i.e.,

E(s; b) = 1, and then H[Xλ] = E.

Ω ds ψ2
R

If Eq. (4) admits solutions for non-zero E, one can construct eigenfunctions that cor-

respond to positive excitation energies E. The realization probability that corresponds to

low-lying excitations is high. Hence, the main idea is to consider the observed state (exclud-

ing the random noise) or the union of the observations and the predictions as being locally

represented by an excited state. This approach can be used for both parameter estimation

and prediction (spatial estimation)

A. Eigenfunctions for FGC case

For the FGC functional of Eq. (2), integrating the square-gradient term by parts leads

to the following equation:

ds [

ψE(s; b)]2 =

ds

2ψE(s; b) +

da

ψE(s; b) ψE(s; b).

(5)

∇

ZΩ

−

ZΩ

∇

ZA(Ω)

· ∇

In Eq. (5)

A(Ω) da denotes the surface integral on the boundary of the area of interest.
R

Secondly, using Green’s theorem on the square-curvature term one obtains

ds

2ψE(s; b)

2

=

ds ψE(s; b)

4ψE(s; b) +

da

ψE(s; b)

2ψE(s; b)

∇

· ∇

∇

ZΩ

∇

(cid:2)

ZΩ

(cid:3)

ZA(Ω)
ψE(s; b).

da

2ψE(s; b)

−

ZA(Ω)

· ∇

∇
(cid:2)

(cid:3)

Hence, in the operator notation the FGC functional is expressed as follows:

Hfgc =
and the surface term is given by:

1
2η0ξd

1

−

(cid:2)

η1 ξ2

2 + ξ4

4

,

∇

∇

(cid:3)

S(Ω) =

1
2 η0 ξd

η1 ξ2
(cid:20)

+ ξ4

ξ4

−

da

da

ZA(Ω)

ZA(Ω)

da

ψE(s; b) ψE(s; b)

ZA(Ω)
ψE(s; b)

· ∇

∇

· ∇

2ψE(s; b)

2ψE(s; b)

ψE(s; b)

.

(cid:3)

(cid:21)

· ∇

∇

(cid:2)
4

(6)

(7)

(8)

(9)

(10)

(11)

(12)

(13)

(14)

(15)

If the units are chosen so that 2η0ξd = 1 and the surface term is ignored, the eigenvalue

equation is given by the following partial diﬀerential equation (pde):

ψE(s; b)

η1 ξ2

2 ψE(s; b) + ξ4

4 ψE(s; b) = E ψE(s; b).

−

∇

∇

The eigenfunctions ψE(s; b) of Eq. (9) are given by the following four plane waves:

ψE(s; b) = ekj·s, kj = kj ˆθ,

where ˆθ represents the unit direction vector, and kj the magnitude of the characteristic

wave-vectors that are given by the roots of the fourth-order characteristic polynomial:

Πfgc(kξ) = (1

E)

η1 ξ2 k2 + ξ4 k4 = 0.

−

−

Thus, the characteristic wavevectors are given by the following expressions:

k1(η1, ξ, E) =

k2(η1, ξ, E) =

k3(η1, ξ, E) =

k4(η1, ξ, E) =

−

1
√2ξ r
1
√2ξ r
1
√2ξ r
1
√2ξ r

−

η1 +

η2
1 −

4(1

E)

−

q

η1 +

η2
1 −

4(1

E)

−

q
η2
1 −

η1 −

4(1

E)

−

q
η1 −

q

η2
1 −

4(1

E).

−

Note that only the magnitude of the wave-vectors is determined from the pde (9). This is

due to the fact that isotropic spatial dependence was assumed in the SSRF model.

(a) If η1 > 0

1

∧

−

η2
1/4 < E < 1 all the roots are real. (b) If η1 > 0

E > 1, then

∧

k1, k2 are real, while k3, k4 are purely imaginary. (c) If η1 > 0

1

−
η2
1/4 < E < 1, then k1, k2 are real while k3, k4 are

∧

η2
1/4 > E, then all the

roots are complex. (d) If η1 < 0

1

∧

−

imaginary. (e) If η1 < 0

E > 1, then k1, k2 are imaginary, while k3, k4 are complex. (f) If

η1 < 0

0 < E < 1

∧

−

∧
η2
1/4 all the roots are complex.

In general, an excited state formed by the linear superposition of degenerate eigenstates

of energy E is given by the expression:

ZE(s; cb) =

u (kc

kj

)

k

− k

Z

d ˆθ cj( ˆθ) exp

kj ˆθ
(cid:16)

·

s

,

(cid:17)

4

j=1
X

(16)

5

where cj( ˆθ) is a direction-dependent (possibly complex-valued) function,

is the modulus

kj

k

k

of the characteristic wavevector, and u(.) is the unit step function, used to guarantee that the

ﬂuctuations in the excited state do not exceed the cutoﬀ ‘frequency’. For the estimation of
real-valued processes, the coeﬃcients cj( ˆθ) are constrained to give real values for the excited
state ZE(s; cb). If cj( ˆθ) = cj, an isotropic excited state is obtained, which can be expressed

as ZE(s; c1, . . . , c4) =

4
j=1 cj u (kc

kj

) ψE(s; j), where ψE(s; j) =

d ˆθ exp

− k

k

kj ˆθ
(cid:16)

·

s

.

(cid:17)

R

P

B. Eigenstates in d = 1

Based on Eq. (10), in d = 1 the real-valued eigenstates are trigonometric or hyperbolic

functions. We examine these cases in more detail for the domain [0, L]

R.

∈

1. Exponential Eigenstates

For characteristic wave-vectors k that are real numbers, the normalized eigenfunctions

and the corresponding energies of Eq. (9) are given by

However, if the exponential function is inserted in Eq. (2), the resulting energy is given by

X(s) = e−k s

E = 1

−

2 k
e−2k L ,

1

r
η1(k ξ)2 + (k ξ)4.

−

H[X(s)] = 1 + η1(k ξ)2 + (k ξ)4.

(17)

(18)

(19)

The diﬀerence between the energy given by Eq. (17) and the correct energy, given by Eq. (19)

is due to the fact that the boundary term can not be ignored for the localized exponential

excitation.

2. Trigonometric Eigenstates

If k is an imaginary number, the eigenfunctions are trigonometric functions. A normalized

cosine eigenfunction and the corresponding energy are given by:

6

X(s) = cos(k s)

2
L [1 + sinc(2k L)]

,

s

E = 1 + η1(k ξ)2 1

sinc(2k L)
1 + sinc(2k L)

−

+ (k ξ)4.

(20)

(21)

For large domains, k L >> 1, Eq. (21) is practically equivalent to Eq. (19). As expected, in

the case of an extended eigenstate (as the cosine) the boundary term can be ignored.

III. SPATIAL ESTIMATION WITH SSRF’S

Assume Sm = (s1, . . . sN ) is a set of data points with the respective vector of measure-
Sm be the estimation point and ˆXλ(s0) the
B(s0; rc) of all

ments denoted by X∗ = (X ∗
estimate (spatial prediction). The local neighborhood of s0 is the set S0 ≡
the data points sj, j = 1, ..., M inside a ‘sphere’ of radius equal to one correlation range
from s0. In geostatistics, ˆX(s0) is determined by optimal linear ﬁlters (kriging estimators)

N ); let s0 /
∈

1 , . . . , X ∗

[9, 13], which form the estimate as a superposition of the data values inside the local neigh-

borhood, and there is no explicit resolution scale. The coeﬃcients of the superposition are

selected to make the estimate unbiased and to minimize the mean square error. Kriging
Sm, ˆX(si) = X ∗(si). Exactitude is not

is an exact interpolator, meaning that for any si

∈

always desirable, since it ignores measurement errors and leads to excessive smoothing of

the ﬂuctuations. Hence, diﬀerent estimation methods are useful. The SSRF models can be

used in kriging algorithms to provide new, diﬀerentiable covariance functions. In addition,

within the SSRF framework it is possible to deﬁne a new type of estimator.

A. Low Local Energy Estimators

The central idea is that a ‘good’ estimate should correspond to a state with signiﬁ-

cant probability of realization. If the energy functional is non-negative, as in Eq. (2), the

highest probability is associated with the uniform state Xλ(s) = 0, which is not phys-

ically interesting. Other states with high probability correspond to low-energy excita-

tions. Let us superimpose the degenerate eigenstates with energy E to form a mixed state
i=1 ci ψE(s; bi); c = (c1, . . . , cD) is a D-dimensional vector of linear coeﬃcients

ZE(s; c) =

D

P

7

that correspond to the degeneracy indices. In principle D can be inﬁnite since the direc-

tional dependence given by Eq. (16) is continuous. However, in practice it may be simplest

to restrict the search to one ‘optimal’ direction. The energy H[ZE(s; cb)] of the mixed state

is not necessarily equal to E. In fact, for orthonormal eigenstates H[ZE(s; c)] = µ E, where

µ =

D
i=1 ci. This reﬂects the fact that the ‘energy level’ of the observed process is set by
the measurements (i.e., the coeﬃcients ci). Since the scale coeﬃcient η0 is inversely propor-
tional to the magnitude of the ﬂuctuations, µ−1

η0. It should also be noted that if two

P

∝

mixed states (c1, E1) and (c2, E2) are energetically equivalent, i.e., µ1 E1 = µ2 E2, they are

not in general linearly related, since according to Eqs. (10) and (12)-(15) the dependence of

ZE(s; c) on E is nonlinear.

We propose that the observations for sj

B(s0; rc) be expressed as X ∗(sj) = ZE(sj; c0) +

∈

ε(sj), where ZE(s; c0) is a ‘local’ excitation and ε(sj) is the local excitation residual. Local

dependence stems from the fact that the coeﬃcients c0 depend on s0, in contrast with the

solution of Eq. (16), in which the coeﬃcient vector is global. The LLEE estimator is then
given by ˆXλ(s0) = ZE(s0; c0). Since ZE(s; c0) is an estimate of the underlying process Xλ(s),
the excitation residual ε(sj) is not in general the same as the noise ǫ(s). The coeﬃcients c0,

follow from minimizing the mean square excitation residual inside B(s0; rc) , i.e.,

c0 = arg min

[X ∗(sj)

ZE(sj; c)]2 .

−

c

j=1
X

The above is a typical problem of multiple linear regression, where the regressors are the

| {z }
functions ψE(si; bj). If we deﬁne the M

and the LLEE are given by:

D matrix ψE,ij

ψE(si; bj), the solutions for c0,i

≡

M

×

M

j=1
X
D

k=1
X

8

αik =

ψE,ji ψE,jk

c0,i =

[α]−1
ik

ψE,lk X ∗
l .

M

l=1
X

ˆXλ(s0) = w0 ·

X∗,

(22)

(23)

(24)

(25)

where w0 is a weight vector given by:

D

D

w0,i =

ψE,0k

[α]−1

kj ψE,ij.

(26)

j=1
X
The uncertainty of the LLEE estimate is determined from the ensemble variance of the

k=1
X

local excitation residual σ2

ε (s0) = E

ˆX(s0)

2

, i.e.:

X ∗(s0)
h
M

−

M

i=1
X

j=1
X

i

2

−

M

i=1
X

ε (s0) = σ2
σ2

x∗ +

w0,i w0,j Gx∗,ij

w0,i Gx∗,0i

,

(27)

X ∗

i X ∗
j

is the covariance matrix of the observations, Gx∗,0i = E [X ∗
where Gx∗,ij = E
is the covariance vector of the ﬂuctuations between s0 and the estimation point, and σ2
E [X ∗

i ] is the variance of the observed process.

i X ∗

i X ∗
0 ],
x∗ =

(cid:3)

(cid:2)

B. Properties of the LLEE

It follows from Eqs. (25) and (26) that the LLEE is linear in the ﬂuctuations. Hence,

the estimates are unbiased and follow the Gaussian law (if the observations are normally

distributed). Kriging methods are based on minimization of the (ensemble) mean square

error, which is a global optimality criterion. In contrast, the LLEE criterion is local (i.e.,

minimum of the average squared excitation residual in the neighborhood of the estimation

point). Another diﬀerence with kriging is that low local energy estimates do not match

exactly the measurements at observation points. Finally, unlike kriging predictions, the

LLEE provides multiple estimates, since diﬀerent energy levels lead to diﬀerent excited

states. In this respect the LLEE is similar to a simulation method. However, simulations

involve the generation of random numbers, in contrast with the LLEE method. It should also

be noted that the energy of local excitations is not necessarily the energy of the estimated

state, since the coeﬃcient vector c0 is local, meaning that the operators

and

2 contribute

∇

∇

to the overall energy when they act on the coeﬃcients of the mixed state in Eq. (2).

IV. CONCLUSIONS

A spatial estimation method for applications in the geosciences is presented. The method

is based on the use of ‘pseudo-energy’ functionals, motivated by explicit constraints or

9

heuristic physical arguments, to capture the spatial heterogeneity of the observed process.

Estimates of the process at unmeasured points (predictions) are based on local interpolating

functions that represent low-energy excitations of the pseudo-energy. Multiple estimates of

the process can be generated by considering local interpolating functions that correspond to

diﬀerent excitation energies.

[1] G. Christakos, Random Field Models in Earth Sciences, (Academic Press, San Diego, 1992).

[2] G. Christakos, and D. T. Hristopulos, Spatiotemporal Environmental Health Modelling,

(Kluwer, Boston, 1998).

[3] P. Goovaerts, Geostatistics for Natural Resources Evaluation, (Oxford, NY, 1997).

[4] M. E. Hohn, Geostastistics and Petroleum Geology, (Kluwer, Dordrecht, 1999).

[5] D. T. Hristopulos, Stoch. Environ. Res. Risk Assessment, 16, 43 (2002).

[6] D. T. Hristopulos, SIAM J. Sci. Comput. 24 2125 (2003).

[7] D. T. Hristopulos, In: Proceedings of the International Conference of Computational Methods

in Sciences and Engineering (Editor: T. E. Simos), World Scientiﬁc, London, UK, pp. 242-247

(2003); Hristopulos, D. T., J. Comput. Methods Sci. Eng., 5(2) (2005) in print.

[8] D. T. Hristopulos, In: Proceedings of the 1st International Conference on Advances in Mineral

Resources Management and Environmental Geotechnology (Editors: Z. Agioutantis and K.

Komnitsas), Heliotopos Conferences, pp. 127-132, (2004); M. Galetakis and D. T. Hristopu-

[9] P. K. Kitanidis, Introduction to Geostatistics: Applications to Hydrogeology, (Cambridge,

los,ibid., pp. 133-138.

1997).

[10] C. Lantuejoul, Geostatistical Simulation: Models and Algorithms, (Springer, Berlin, 2002).

[11] Y. Rubin, Applied Stochastic Hydrogeology, (Oxford University Press, New York, 2003).

[12] D. Sornette, Critical Phenomena in Natural Sciences, (Springer, Berlin, 2004).

[13] H. Wackernagel, Multivariate Geostatistics, (Springer, Berlin, 2003).

[14] G. Winkler, Image Analysis, Random Fields and Dynamic Monte Carlo Methods: A Mathe-

matical Introduction, (Springer, New York, 1995).

[15] M. Yaglom, Correlation Theory of Stationary and Related Random Functions I, (Springer,

New York, 1987).

10

