0
0
0
2
 
v
o
N
 
1
2
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
9
4
0
1
1
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A Variational Formulation of Optimal Nonlinear Estimation

Gregory L. Eyink∗

CCS-3 MS-B256

Los Alamos National Laboratory

Los Alamos, NM 87545

Abstract

We propose a variational method to solve all three estimation problems for nonlinear

stochastic dynamical systems: prediction, ﬁltering, and smoothing. Our new approach is

based upon a proper choice of cost function, termed the eﬀective action. We show that this

functional of time-histories is the unique statistically well-founded cost function to determine

most probable histories within empirical ensembles. The ensemble dispersion about the

sample mean history can also be obtained from the Hessian of the cost function. We show

that the eﬀective action can be calculated by a variational prescription, which generalizes the

“sweep method” used in optimal linear estimation. An iterative numerical scheme results

which converges globally to the variational estimator. This scheme involves integrating

forward in time a “perturbed” Fokker-Planck equation, very closely related to the Kushner-

Stratonovich equation for optimal ﬁltering, and an adjoint equation backward in time,

similarly related to the Pardoux-Kushner equation for optimal smoothing. The variational

estimator enjoys a somewhat weaker property, which we call “mean optimality”. However,

the variational scheme has the principal advantage—crucial for practical applications—that

it admits a wide variety of ﬁnite-dimensional moment-closure approximations. The moment

approximations are derived reductively from the Euler-Lagrange variational formulation and

preserve the good structural properties of the optimal estimator.

∗Permanent address: Department of Mathematics, University of Arizona, Tucson, AZ 85721

1

0

Introduction

The three classical problems of stochastic estimation are prediction, ﬁltering, and smoothing

of time series; e.g. see [1]. These correspond to estimating the future, present, and past states,

respectively, based upon current available information. In more detail, the nonlinear estima-

tion problem may be described as follows: assume as known some nonlinear (Ito) stochastic

diﬀerential equation for a time-series X(t):

dX = f (X, t)dt + (2D)1/2(X, t)dW(t).

(0.1)

Here f is a (drift) dynamical vector, D is a nonnegative diﬀusion matrix, and W(t) is a vector

Wiener process. Suppose also that some imperfect observations r(t) are taken of a function

Z(X(t), t) of the basic process, including some measurement errors ρ(t) with covariance R(t):

r(t) = Z(X(t), t) + ρ(t).

(0.2)

It will generally be assumed that the distribution of the measurement errors is known as well.

For example, the errors may be assumed to be proportional to a white noise: ρ(t) = R1/2(t)η(t).

Then the problem is, given the data

(tf ) =

R

r(t) : t < tf }
{

up to ﬁnal measurement time tf ,

to obtain the best estimate of X(t) at times t > tf , t = tf and t < tf .

The optimal ﬁltering problem in the above general setting has been exactly solved by

Stratonovich [2] and Kushner [3, 4] within a Bayesian formulation. Those authors have shown

that the conditional probability density

(t)), given the current data

(t), obeys a

(x, t

P

|R

R

stochastic partial diﬀerential equations, nowadays called the Kushner-Stratonovich equation.

Explicitly, denoting

P∗(x, t) =

P

(x, t

|R

(t)), the KS equation is of the form

∂tP∗(x, t) = ˆL(t)

P∗(x, t) + h⊤(t)[Z(x, t)

− h

Z(t)

i∗t]

P∗(x, t).

where

(0.3)

(0.4)

ˆL(t) =

)] + ∇x·[D(x, t)·∇x(
∇x·[f (x, t)(
)]
·
·

−

2

is the standard Fokker-Planck linear operator, and

h(t) = R−1(t)[r(t)

Z(t)

i∗t]

− h

(0.5)

is a random forcing term constructed from the particular realization of the observation r(t)

obtained in a given sample run of the system. Note that

average, i.e. the average with respect to the distribution

h·i∗t = E(
(x, t

(t)) denotes conditional

·|R
(t)) itself. Hence, the KS

P

|R

equation is nonlinear. The integration of this equation forward in time, with sequential input of

the fresh observations r(t) as they become available, solves, in principle, the ﬁltering problem.

The prediction problem is then solved in theory, by integrating the standard Fokker-Planck

equation with

(x, tf |R

P

(tf )) as initial data to obtain

(x, t

(tf )) for t > tf .

P

|R

The optimal smoothing problem has also been solved, in principle, by Kushner [5] and

Pardoux [6]. They have shown that

(tf )) for t < tf can be written as

(x, t

P

|R

(x, t

(tf )) =

P

|R

A∗(x, t)

P∗(x, t),

(0.6)

where

P∗(x, t) is as above and
∂tA∗(x, t) + ˆL∗(t)

A∗(x, t) solves the adjoint equation
A∗(x, t) + h⊤(t)[Z(x, t)

Z(t)

− h

i∗t]

A∗(x, t) = 0.

(0.7)

This equation, with the random forcing h(t), must be interpreted as a “backward stochastic

equation”. It is solved subject to the ﬁnal condition

(x, tf ) = 1.

A

In certain cases, these estimators reduce exactly to solving a ﬁnite number of ODE’s. For

example, in the linear case, where f (x, t) = A(t)x, D(x, t) = D(t), and Z(x, t) = B(t)x, the

KS optimal ﬁlter reduces exactly to the ﬁnite-dimensional Kalman-Bucy optimal linear ﬁlter

[7]. This reduction occurs in the linear case because the conditional PDF is known rigorously

to be multivariate Gaussian, uniquely speciﬁed by its mean and covariance. The conditional

mean E[X(t)

(t)] coincides with the Kalman-Bucy ﬁlter estimate ξ(t) of the current state

|R

X(t), which is determined by the solution of a stochastic ODE with sequential input of the

observations. The covariance matrix C(t) = E[X(t)X⊤(t)

(t)]

ξ(t)ξ⊤(t) is obtained as well

|R

−

from a linear Ricatti equation integrated forward in time.

3

The Pardoux-Kushner smoother is also ﬁnite-dimensional for linear systems.

In fact, it

coincides there with an alternative variational formulation of the linear estimation problem.

The latter can be motivated most naively from the idea of least-square-error estimation. That

is, one may introduce a weighted square-error functional for the dynamics,

ΓX[x] =

dt [ ˙x

A(t)x]⊤D−1(t)[ ˙x

A(t)x],

−

−

tf

1
4

ti

Z

(0.8)

which measures the “cost” for a history x(t) to depart from the solution of the linear, deter-

ministic dynamics ˙x = A(t)x. The integral is weighted by the “error covariance” D(t) which

arises from the random noise. A similar cost function may be introduced for the observation

error of the data:

ΓR[ρ] =

dt ρ(t)⊤R−1(t)ρ(t).

(0.9)

tf

1
2

ti

Z

In that case, the solution to the estimation problem may be obtained by minimizing with respect

to x the combined cost function

ΓX,R[x, r] := ΓX[x] + ΓR[r

Bx]

−

(0.10)

when the set of observations

is input into the second term. The minimizer

r(t) : ti < t < tf }
{

x∗ = x∗[r] is then the optimal history, which solves simultaneously all three estimation problems.

It may be shown that x∗(t) = ξ(t) for t

tf , so that the variational estimator coincides with

≥

the Kalman-Bucy ﬁlter and predictor. Furthermore, it may be shown that, for t < tf , the

variational estimator is given by the Ansatz

x∗(t) = ξ(t) + C(t)α(t).

(0.11)

Here, α(t) is the solution of a linear adjoint equation integrated backward in time with the ﬁnal

condition α(tf ) = 0 and thus vanishes identically for t

tf . However, it makes a contribution

≥

for t < tf to the smoother, proportional to C(t). This adjoint algorithm to calculate the mini-

mizer is called the “sweep method” [8], and it gives the same result x∗(t) = E [X(t)

(tf )] as

|R

calculated by the Pardoux-Kushner equation. Hence, it provides a ﬁnite-dimensional represen-

tation of the optimal smoother for linear systems.

4

In general, however, the optimal estimators are inﬁnite-dimensional, i.e. they require the

solution of (stochastic) PDE’s. For many of the spatially-extended, continuum systems of

greatest interest in geophysics and in engineering, this is, in fact, a functional PDE. Even

discretization for numerical solution results in a (stochastic) PDE on a phase space of dimension

literally a billion or more. It has therefore been clear since their original formulation that, for

such spatially-extended or distributed systems, the exact calculation of the optimal nonlinear

estimator will be numerically unfeasible. Kushner himself wrote an early paper [9], in which he

stressed this point and set up a formalism for approximating the optimal ﬁlter. As he observed

there, the problem is formally the same as the “closure problem” in turbulence theory. The

approximation scheme he proposed was also the same as that traditionally adopted in turbulence

theory: namely, a moment closure of the full KS equation. Such a scheme results in a set

of equations with a number of variables comparable to that in the starting equation (0.1),

which may still be large but tractable. Constructing ﬁnite-dimensional approximate estimators

continues to be a pressing research problem up to the present day, e.g. see [10]. Indeed, general

approximation schemes for the full estimation problem (prediction, ﬁltering and smoothing)

that are at once computationally practicable and faithful to the optimal solution remain to be

developed. The fact that the problem of estimation for extended systems is formally equivalent

to the turbulence problem—a notoriously diﬃcult one—suggests that the solution here, too,

will be nontrivial. Not only must the formal properties of the optimal estimator be retained by

any approximation, but also the physical properties of the underlying dynamical system must

be suﬃciently represented. The problem of approximating the optimal estimator is not, in our

opinion, just one of mathematics but also of physics.

The aim of this paper is to formulate a new approach to the problem of optimal nonlinear

estimation, based upon a variational formulation. The crux of the method is to identify an

action functional, analogous to (0.8), which is statistically justiﬁed to use as a cost function

for estimation of nonlinear dynamics. This is the quantity which we have called the eﬀective

action in previous works [11]-[13]. This functional of state histories is uniquely characterized as

5

that which selects the most probable value under arbitrary conditions on the empirical sample

averages.

In fact, the cost function (0.8) appropriate for linear systems has been motivated

only rather crudely but it has a more fundamental probabilistic justiﬁcation. It was apparently

ﬁrst observed by the chemist Lars Onsager that the dynamical cost function (0.8) is the unique

functional whose minimum determines the statistically most probable time-history of a linear

dynamics of form (0.1), subject to an arbitrary sets of constraints. In the statistical physics

literature, the functional (0.8) is known as the Onsager-Machlup action [14]. The cost function

(0.9) for the current observation error can be similarly shown to give the most probable error in

the case of a Gaussian white-noise distribution. The combined cost function (0.10)—under the

assumption that dynamical noise and observation error are independent random functions—

then indeed gives by minimization the most probable time-history subject to currently available

information. Thus, the minimizer x∗[r] is the unequivocal optimal estimator in the linear case.

Previous attempts to develop variational methods for optimal nonlinear estimation have not

paid suﬃcient attention to the statistical requirements on the cost function. For example, a

functional has often been employed similar to (0.8) for the linear case,

ΓX[x] =

dt [ ˙x

f (x, t)]⊤D−1(t)[ ˙x

f (x, t)],

−

−

tf

1
4

ti

Z

(0.12)

naively based upon least-square-error philosophy. However, the use of this cost function has no

statistical justiﬁcation, except in the weak-noise limit D

0. In that case, (0.12) is known as

→

the “nonlinear Onsager-Machlup action” and it is proved to give the leading-order asymptotics

of probabilities of time histories for small noise [15, 16]. However, except for the weak-noise

limit or for linear dynamics, the Onsager-Machlup action has no probabilistic signiﬁcance. Only

the eﬀective action—and no other cost function, such as (0.12) above—will even have as its

minimum the correct mean value. The eﬀective action thus plays the role of a “ﬂuctuation

potential” in the theory of empirical ensemble averages constructed from independent samples,

analogous to the Onsager-Machlup action for weak-noise or for linear systems.

In fact, the

eﬀective action is known to coincide with the Onsager-Machlup action for weak-noise or for

6

linear systems [15]. Thus, the optimal estimator proposed in this work coincides with the

standard ones for those special cases.

Unlike (0.8), the eﬀective action cannot generally be written as an explicit function of

the state histories. However, it has been shown in [11]-[13] that it may be calculated by a

constrained variational method. The Euler-Lagrange equations that result are a pair of forward

and backward equations, very similar to the Kushner-Stratonovich-Pardoux (KSP) equations.

Despite this, the variational estimator is not quite equivalent to the optimal estimator which

follows from the KSP equations. It possesses instead a property that we call mean-optimality.

Although somewhat weaker than the optimality enjoyed by KSP, mean-optimality distinguishes

it from other “suboptimal” estimators which have in fact no optimality whatsoever. However,

the main advance of the variational approach is in the problem of constructing ﬁnite-dimensional

approximations. Because the variational estimator is based upon an Euler-Lagrange variational

principle, it is very easy to develop consistent approximations by a Rayleigh-Ritz scheme. In

this method, parameterized trial functions are selected to represent the solutions of the forward-

backward equations. Inserted into the variational functional and varying over parameters, one

obtains approximations to the exact forward-backward equations and thereby to the eﬀective

action. A straightforward use of this scheme in fact leads to a moment-closure approximation

for the forward ﬁltering equation, much like that originally proposed by Kushner [9]. However,

now also backward equations are obtained for the smoothing problem. Necessary consistency

properties with the forward equations are guaranteed by the fact that these arise together as

the Euler-Lagrange system of an approximate action functional.

This paper is organized as follows:

in Part I, we present our variational formulation of

optimal estimation. We ﬁrst explain the unique statistical signiﬁcance of the eﬀective action,

which makes it appropriate for variational estimation. We review there also the deﬁnition

and properties of the eﬀective action, including the notions of joint and conditional eﬀective

actions. The optimality property will be established for the variational estimator and compared

with that of the KSP estimator. We next discuss how to calculate the eﬀective action based

7

upon its variational characterization. An iterative numerical scheme is outlined to numerically

calculate the variational estimator, which reduces to solving KSP-type equations. Some matters

important for practical applications will ﬁnally be discussed: the case when measurements are

taken, not continuously, but at a discrete set of times, and the evaluation of the ensemble

dispersion around the most probable value of the sample mean. In Part II the very important

issue is addressed of constructing ﬁnite-dimensional approximations to the variational estimator,

crucial for application of the methods to spatially-extended (or distributed) systems with many

degrees of freedom. A Rayleigh-Ritz moment-closure scheme is developed, based upon the ﬁnite-

dimensional reduction of the nonequilibrium action. The use of this approximation scheme for

solution of practical estimation problems is ﬁnally discussed.

I Variational Formulation of Optimal Estimation

I.1. Ensemble Theory of Estimation

There are intrinsic limits to our ability to estimate, which can be understood most simply from

an ensemble point of view. If the stochastic dynamics (0.1) is run many times with diﬀerent

realizations of the noise or, even in the deterministic case D(t)

0, if the initial data are

selected randomly from some starting distribution

(0), then the solutions will be generally

≡

P

quite distinct. Thus, in N diﬀerent trials there will be N diﬀerent outcomes X1(t), ..., XN (t).

It is therefore not obviously very meaningful to give a single value x∗(t) as an estimate of the

state given some partial information

(unless, of course, that information included the exact

R

initial data or realization of the random noise!) It is true that the average over samples will

converge to the mean in the ensemble conditioned on the available information:

lim
N→∞

1
N

N

Xn=1

Xn(t) = E[X(t)

].

|R

(I.1)

However, the individual sample points will show a scatter, possibly quite large, about this mean

8

value. A useful measure of this scatter is the covariance matrix

CR(t) := E[δX(t)δX⊤(t)

]
|R

(I.2)

in the ensemble conditioned on

, where δX(t) := X(t)

E[X(t)

]. In particular, TrCR(t) :=

R
] gives the mean square radius σ2

−

|R

R(t) of scatter of the sample points around the

2
δX(t)
E[
k
k

|R

mean. The ensemble mean has the one virtue that it minimizes this rms radius of scatter. In

other words, if one took δX(t) := X(t)

x∗(t) for any other non-random estimator x∗(t)

=

−

E[X(t)

], one would increase σ2

R(t). This is an elementary fact of probability theory: for any

|R

random variable, the expectation value is the unique deterministic estimator for which the mean-

square error is a minimum. This important property of the mean value as a predictor—that it

minimizes rms forecast error—has been emphasized before by Leith in the ﬁeld of climatology

[21]. Of course, the above considerations show that one should have not only an estimate of

the state of a system, but also an estimate of the reliability or certainty of that state. The

covariance matrix CR(t) is a good such measure. Any state within a few standard deviations

σR(t) of the mean must be regarded as having a good degree of probability to occur.

Such considerations are precisely those which justify the standard Bayesian approach of

Kushner-Stratonovich-Pardoux. Granted the limitations implied above, one cannot do better

than to give the probability density

) of the state variable conditioned on the available

(x, t

P

|R

information. The minimal requirement on a variational approach to estimation is thus that it

should give at least the mean and covariance of such conditioned ensembles. This has motivated

us to consider a cost function, the “eﬀective action”, which has a proper foundation in the theory

of empirical ensembles. A brief review of its deﬁnition and basic properties is here required.

I.2. Basic Theory of the Eﬀective Action

The quantity which we have termed the eﬀective action [11]-[13] has appeared, in various

guises and by various names, in quantum ﬁeld theory, in theory of stochastic processes, and in

dynamical systems theory. We shall here just brieﬂy recapitulate its deﬁnition and properties.

One interpretation of the eﬀective action is as a generating functional for multi-time cor-

9

6
relations. This is the way in which the functional is generally introduced in ﬁeld theory [17].

Consider any vector-valued random process Z(t). Then, the cumulant generating functional

WZ [h] is deﬁned as

(cid:18)Z
The nth-order multi-time cumulants of Z(t) are obtained from WZ [h] by functional diﬀerenti-

WZ[h] = log

exp
h

tf

ti

dt h⊤(t)Z(t)

.
(cid:19)i

ation with respect to the “test history” h(t):

Ci1···in(t1, ..., tn) =

δnWZ [h]

δhi1 (t1)

· · ·

δhin (tn) (cid:12)
(cid:12)
(cid:12)
(cid:12)

.

h=0

It is not hard to check from its deﬁnition (I.3) that WZ [h] is a convex functional of h. The

Legendre dual of this functional is deﬁned to be the eﬀective action of Z(t):

ΓZ[z] = max
h {

< h, z >

WZ [h]
,
}

−

with < h, z >:=

dt h⊤(t)z(t). It is a generating functional of so-called irreducible correlation

R
functions of Z(t):

Γi1···in(t1, ..., tn) =

δzi1 (t1)

δnΓZ [z]

.

· · ·

δzin (tn) (cid:12)
z=z
(cid:12)
(cid:12)
(cid:12)

The functional derivatives here are evaluated at the mean history z(t) :=

Z(t)
. It is not hard
i
h

to check from the deﬁnition (I.5) that ΓZ[z] is a convex, nonnegative functional with a unique

global minimum (equal to zero) at the mean history z = z.

The eﬀective action has another important interpretation as the rate function in the theory

of large deviations of empirical ensemble averages for time-series. See [18] for the original, so-

called Cram´er theory of single real variables and [19] for the extension to general vector spaces.

This theory involves the empirical or sample mean:

(I.3)

(I.4)

(I.5)

(I.6)

(I.7)

where Zn(t) for n = 1, ..., N are independent, identically distributed realizations of the random

process Z(t). The law of large numbers states that, in the limit of number of samples N going

to inﬁnity, ZN (t)

z(t). However, for ﬁnite N , ZN (t) is itself a random process with some

→

ZN (t) :=

Zn(t),

1
N

N

Xn=1

10

probability of achieving a ﬂuctuation value z(t) diﬀerent from the ensemble mean z(t). The

basic result of the Cram´er theory is that this probability decreases exponentially in the limit

as N

:

→ ∞

Thus, ΓZ[z] for z

P

ZN (t)

z(t) : ti < t < tf

≈

exp (

N

ΓZ[z]) .

∼

−

·

(cid:16)

(cid:17)
= z gives the rate of decay of the probability to observe ZN ≈

(I.8)

z. Since

ΓZ[z] = 0 only for z = z, the probability to observe the empirical N -sample mean ZN equal to

anything other than the ensemble mean z must go to zero as N

. Thus, the large deviation

→ ∞

result (I.8) includes, and generalizes, the usual law of large numbers. Furthermore, the ensemble

mean is now also seen to be characterized by a variational principle of least eﬀective action.

That is, the most probable value of the sample mean for large N , or z = z, is just that which

minimizes the eﬀective action ΓZ [z]. It is worth emphasizing that the eﬀective action is the

unique function possessing all of these properties. This is a consequence of a general theorem

on uniqueness of rate functions for large deviations [20].

There is one other general theorem of large deviation theory which will prove important to

us in the sequel. This is the so-called Contraction Principle. Suppose that WN (t) is a random

process which is deﬁned as a continuous functional W of an empirical mean ZN (t):

Then, WN (t) also satisﬁes a large deviations principle with rate function given by

WN (t) := W[t; ZN ].

˜ΓW [w] = min

ΓZ [z].

{z:W[z]=w}

(I.9)

(I.10)

See [20]. When the functional W is linear, then obviously ˜ΓW [w] = ΓW [w].

The joint eﬀective action ΓX,Y [x, y] of a pair of random time series X(t) and Y(t) can be

deﬁned most simply as the eﬀective action ΓZ [z] of the composite vector Z(t) := (X(t), Y(t)).

Of course, this notion may be extended to a joint eﬀective action ΓX1···Xn[x1, ..., xn] of an

arbitrary number n of variables Xi(t), i = 1, ..., n. It is a simple application of the Contraction

Principle to see that elimination of one of the variables is accomplished by minimizing over its

11

6
(I.11)

(I.12)

(I.13)

(I.14)

.

→ ∞

possible values. For example,

recovers the eﬀective action ΓX[x] of X(t) alone.

ΓX[x] = min

ΓX,Y [x, y]

y

from the deﬁnition to be given just by the sum:

ΓX,Y [x, y] = ΓX[x] + ΓY [y].

The joint eﬀective action of a pair of independent time series X(t) and Y(t) is easily shown

In general, for dependent time series, one may deﬁne the notion of a conditional eﬀective action

y] := ΓX,Y [x, y]
ΓX|Y [x
|

−

ΓY [y].

y] = ΓX[x]. The term “conditional action”
Thus, when X(t) and Y(t) are independent, ΓX|Y [x
|

is justiﬁed by the relation to large-N asymptotics of conditional probabilities for empirical

by means of

averages:

P

XN ≈

YN = y
x
|

(cid:16)

exp

∼

(cid:17)

−

(cid:16)

N

y]
ΓX|Y [x
|

·

.

(cid:17)

Using the deﬁnition of the conditional probability, (I.14) is a simple consequence of the ba-

sic large deviation estimate (I.8). The conditional action is also a generating functional for

irreducible multi-time correlation functions in the conditioned ensemble, in the limit N

I.3. Proposal for the Variational Estimator

These considerations motivate our following proposal: we propose to take as optimal estima-

r] of the history x given the
tor x∗[r] the minimizer of the conditional eﬀective action ΓX|R[x
|

current observation history

r(t) : t
{

. From our discussion of the eﬀective action in
[ti, tf ]
}

∈

the previous section, we can infer the crucial property of this estimator: it is the mean value

within the subensemble in which the empirical N -sample average takes on the value r, that is,

the sub-ensemble in which

rN (t) = r(t), t

[ti, tf ].

∈

(I.15)

In fact, as discussed above, the conditional eﬀective action is a variational functional whose

minimum coincides with the subensemble mean history for an arbitrary set of constraints on

12

the empirical sample average. Thus, the estimator x∗[r] is exactly of the form E[X(t)

]
|R
speciﬁed by (I.15). It is also possible to obtain from the conditional

discussed above, with

R

eﬀective action the error covariance C∗[t

r], essentially by evaluating its Hessian matrix (see
|

Section I.6). This is precisely the ensemble dispersion that would be observed via the spread

of sample histories in an ensemble forecasting scheme [21], if the ensemble considered were the

one speciﬁed by the condition (I.15) for the limit of large N .

Our proposal is clearly similar in spirit to the Bayesian formulation of Kushner-Stratonovich-

Pardoux. However, they are distinct. The diﬀerence can best be understood by considering the

problem from an experimental point of view. Suppose that a very large number N of samples

of the system (1) are run, drawing initial conditions randomly from the same distribution

P0. Then the conditional distribution
|R
very small sub-ensemble in which that particular realization r (non-random) of the observation

(tf )) considered by KSP corresponds to the

P

(x, t

history occurred.

It obviously diﬃcult to prepare such sub-ensembles, since one must wait

patiently for the particular observation r to spontaneously occur and, each time it does, add it

as a member to the sub-ensemble. This makes it very diﬃcult to directly test the predictions

of the KSP-equations. More to the point, it is very diﬃcult to carry out an ensemble or

Monte Carlo approach to calculate directly the conditional average. The variational estimation

method proposed above corresponds to a diﬀerent—and somewhat larger—sub-ensemble. As

noted above, it corresponds to considering the sub-ensemble speciﬁed by the condition

rN (t) =
{

r(t), t

. It is clear that the sub-ensemble described by the KSP-equations is, also, a
[ti, tf ]
}

∈

subset of the new, larger one. In fact, if it is true as in the KSP sub-ensemble that rn = r in

every realization, n = 1, ..., N then it is a fortiori true that rN = r. However, there will clearly

be many members of the new ensemble in which rN = r but for which not every term rn of

the N -sample average is equal to r. Thus, the new sub-ensemble is clearly much larger than

that considered by Kushner-Stratonovich-Pardoux, but, still, too small a subset of the whole

ensemble to be reproducible by direct methods.

Despite the diﬃculty of directly testing the KSP-equations, they are truly the optimal

13

method for the ﬁltering and smoothing problems. While it is diﬃcult to prepare the conditional

ensemble corresponding to a given observation r, there is no diﬃculty in preparing one member

of such an ensemble. After all, just running the system once and collecting one observation

r provides one realization in which that particular observation occurs!

In fact, it is exactly

this type of situation which occurs in practical prediction problems, such a meteorology. One

has no control over which particular weather pattern will be observed up to today, but, given

the one that has occurred, one would like to predict tomorrow’s weather. The best predictor

will be that corresponding to the conditional ensemble in which all of the available information

is used. The variational predictor we have proposed corresponds to a larger sub-ensemble,

which means that somewhat less detailed information about the system is used in making the

prediction. Therefore, the variational predictor is optimal, but in a somewhat weaker sense than

the KSP one. The variational estimator x∗[r] is optimal given the data just on empirical sample

averages, which is somewhat less than the information one actually possesses. We shall refer

to the weaker optimality property possessed by the variational estimator as mean-optimality.

In the language of statistical physics, the variational estimator could be termed a “mean-ﬁeld

approximation” to the optimal one, since it exploits conditions deﬁned only through the sample

mean. How diﬀerent as predictors are the variational and KSP optimal estimators will depend

upon how much variation occurs with the larger sub-ensemble. If all the terms rn ≈
sample average whenever rN = r for a given r, then there will be little diﬀerence between the

r in the

two subensembles. This may be expected to occur whenever there are “preferred paths” in the

dynamical evolution.

In the linear case, the variational method proposed above coincides with the standard one

described in the Introduction. To see this is true it is enough to point out the well-known

fact that, for a linear dynamics, the eﬀective action ΓX [x] coincides with the Onsager-Machlup

action [15]. Hence, in the linear case, the variational estimator coincides with the optimal

estimator of Kushner-Stratonovich-Pardoux, so far as the problems of prediction and ﬁltering

are concerned. This will not be true in general for nonlinear systems. As we shall see in the

14

next subsection, there is nevertheless a close formal connection between the Bayesian approach

of Kushner-Stratonovich-Pardoux and the variational approach.

I.4 Calculation of Eﬀective Action & Variational Estimator

It remains to consider how the eﬀective action and its minimizer, the variational estimator, may

actually be calculated. It was shown in [11, 13] that the eﬀective action may be obtained from

a constrained variational formulation. We shall here brieﬂy review the results of those works

and then explain how to obtain the minimizing history x∗[r] itself.

Consider any Markov times series X(t) and Z(t) := Z(X(t), t) given by a continuous func-

tion Z(x, t). In this general context there is a useful variational characterization of the eﬀective

action ΓZ [z]. To explain this result, we must introduce a few notations. Because the process

X(t) is Markov, its distribution

(x, t) at time t is governed by the forward Kolmogorov equation

P

∂tP

(x, t) = ˆL(t)

(x, t),

P

with ˆL(t) the instantaneous Markov generator. The diﬀusion process governed by the stochastic

equation (0.1) is a particular example, for which the generator is the Fokker-Planck operator

deﬁned in (0.4). Observables, or random variables,

(x, t) evolve under the corresponding

A

backward Kolmogorov equation

∂tA

(x, t) =

ˆL∗(t)

(x, t),

−

A

in which ˆL∗(t) is the adjoint operator of ˆL(t) with respect to the canonical bilinear form on

L∞

L1, i.e. <

×

,

A

P

A

P

R

>:=

dx

(x)

(x). The backward and forward Kolmogorov equations

may be simultaneously obtained as Euler-Lagrange equations for stationarity of the action

functional

when varied over

P ∈

(tf )

1.

≡

A

Γ[

,

] :=

A

P

dt <

(t), (∂t −

A

ˆL(t))

(t) >

P

tf

ti

Z
L1 with initial condition

(ti) =

P

P0 and

A ∈

L∞ with ﬁnal condition

(I.16)

(I.17)

(I.18)

15

(I.19)

(I.20)

(I.21)

(I.22)

ΓZ [z] = st.pt.A,P Γ[

,

]

A

P

<

(t),

(t) >= 1

A

P

<

(t), ˆZ(t)

(t) >= z(t)

A

P

For the above situation, the eﬀective action of Z(t) := Z(X(t), t) has been shown [11, 13]

to be obtained by a constrained variation of the action Γ[

,

]. In fact,

A

P

when varied over the same classes as above, but subject to constraints of ﬁxed overlap

and ﬁxed expectation

for all t

[ti, tf ]. Note that ˆZ(t) is used to denote the operator (in both L1 and L∞ ) of

∈

multiplication by Z(x, t). The Euler-Lagrange equations for this constrained variation may be

obtained by incorporating the expectation constraint (I.21) with a Lagrange multiplier h(t).

The overlap constraint could also be imposed with a Lagrange multiplier w(t). However, it

turns out to be preferable to impose it through the deﬁnitions

(t) = 1 + [

A

(t)

it]

− hB

(t)

B
(t),

C

:= 1 +

P
(t). Like

with the ﬁnal conditions

C
tion with respect to the distribution

B

(tf ) =

(tf )

0. Note that

≡
(t). Hence, the overlap constraint (I.20) is satisﬁed when

hB

P

B

(t),

(t) > is the expecta-

(t)

it :=<

(t) is varied independently of

B
A
but must satisfy the orthogonality condition <

P

(t), the variable

(t) is not independent of

(t),

C

P

(t),

(t) >= 0. We shall mostly make use here

C

P

of the original variable

(t) rather than

(t), but the latter will play an important role in our

C
formulation of moment-closures in Part II.

A

Although obtained by varying over

(t),

(t), the Euler-Lagrange equations are most use-

B

P

fully written instead in terms of the original variables

(t),

(t):

A

P

∂tP

(t) = ˆL(t)

(t) + h⊤(t)[Z(t)

Z(t)

− h

(t)

it]
P

P

(I.23)

16

and

(t) + ˆL∗(t)

(t) + h⊤(t)[Z(t)

∂tA
(t) has allowed the Lagrange multiplier to be evaluated explicitly, as

(t) = 0.

it]
A

(I.24)

Z(t)

− h

A

The calculation via

Z(t)
w(t) = h⊤(t)
h

B
it. The eﬀective action ΓZ [z] evaluated at a speciﬁc history z(t) is now
obtained from the solutions of (I.23),(I.24) by substituting them back into the action functional

Γ[

,

] in (I.18), when the “control ﬁeld” h(t) is chosen so that (I.21) reproduces the considered

A

P
history z(t).

It is not accidental that the same notation h(t) was chosen above as for the

argument of the cumulant generating functional WZ [h]. In fact, it can be shown that also

WZ [h] =

Z(t)
dt h⊤(t)
h

it,

tf

ti

Z

(I.25)

using just the solution

(t) of the forward equation (I.23) for the control history h(t) which

P

appears as the argument of WZ . For more details, see [11, 13]. It should not have escaped

the attention of the reader that the forward equation (I.23) is very similar to the Kushner-

Stratonovich equation (0.3) for the conditional distribution

P∗(t) =

P

|R

(t

(t)) and that the

backward equation (I.24) is likewise similar to the Kushner-Pardoux equation (0.7) for

A∗(t) =

(t

P

(t

(tf ))/

(t)). This observation will be developed below. (See also Appendix 1.)

|R
Having completed our review of established results, we now consider how to calculate the

|R

P

variational estimator.

r] over x
It is helpful to observe that the minimizer x∗[r] of ΓX|R[x
|

with r ﬁxed is the same as of ΓX,R[x, r], the joint action of x and r. For simplicity, the

observation errors will be assumed to be white-noise in time and independent of the dynamical

noise. Another important simplifying assumption we shall make here is that the function of the

process which is observed is linear:

Z(x, t) = B(t)x.

(I.26)

We postpone to later the consideration of the general case, which is somewhat more complicated

but no diﬀerent in principle. By our assumptions, the joint action is given as

ΓX,R[x, r] = ΓX[x] +

dt [r(t)

B(t)x(t)]⊤R−1(t)[r(t)

B(t)x(t)].

(I.27)

−

tf

1
2

ti

Z

−

17

The second term is ΓR[ρ] given in (0.9). We abbreviate Γ∗[x] := ΓX,R[x, r] and its functional

derivative as k∗[t; x] = δΓ∗

δx(t) [x]. It is an easy calculation, using the expression (I.27), to show

that

k∗[t; x] = k[t; x] + B⊤(t)R−1(t) [B(t)x(t)

r(t)] ,

(I.28)

−

with k[t; x] := δΓX

δx(t) [x]. Observe that we are using here the notation k(t) for the control

associated to X(t), whereas we reserve h(t) for the control ﬁeld associated to Z(t). What

makes ﬁnding the minimizer x∗[r] less trivial is the fact that ΓX[x] and k[t; x] are not calculable

directly, but only as the result of another optimization problem, like that in Eq.(I.5): ΓX[x] =

maxk

< x, k >

{

WX[k]
}

−

. Thus, the problem to be solved is really of minimax type:

Γ∗[x∗[r]] = min

max

ΓR[r

Bx]+ < x, k >

x

k {

−

WX[k]
}

.

−

(I.29)

Numerical schemes to obtain the minimizer x∗[r] must thus address this minimax problem.

The simplest approach conceptually is to reformulate it as a double minimization, i.e.

Γ∗[x∗[r]] = min

ΓR[r

Bx]

WX[k]

< x, k >

.

min

k {

−

−

x

(cid:26)

−

}(cid:27)

(I.30)

In this case, each of the minimizations may be carried out in nested fashion, via any of the

common iterative methods. For example, a conjugate gradient (CG) algorithm applied to the

outer problem will produce a sequence x(n) converging as n

to, at least, a local minimum

→ ∞

x∗ of Γ∗[x]. We mention conjugate gradient only as an example of an iterative scheme to

ﬁnd the minimum of a convex function, which requires as its input at each step the gradient

k(n)
∗ (t) = δΓ∗

δx(t) [x(n)]. Any such scheme requiring the gradient might be used instead. From
(I.28) such algorithms require knowing k[x(n)]. Conveniently, this is exactly what is obtained

from the solution of the inner problem, since k[x(n)] is the unique minimizer k(n) of the convex

functional W (n)[k] := WX[k]

< k, x(n) > . This inner minimization problem may also be

−
attacked by a CG-type method, noting that the gradient is

δW (n)
δk(t)

[k] = x[t; k]

x(n)(t).

−

(I.31)

18

This gradient is now directly calculable via formula (I.21) above for a given k(t). Each evaluation

of x[k] by (I.21) requires one forward and one backward integration over the time interval [ti, tf ].

A CG-type method applied to W (n)[k] will then produce a sequence k(n,m) which converges to

k(n) = k[x(n)] as m

. This inner minimization thus provides the gradient k(n) required for

→ ∞

the nth CG step of the ﬁrst minimization. To initiate the algorithm, one must specify x(0) and

k(0,0). For this purpose, one may, for example, set

1 as a ﬁrst approximation in (I.21).

This gives

A ≡

x(0)(t) =

X(t)
it
h

and, from the equation k∗[t; x(0)] = 0, the ﬁrst guess

k(0,0)(t) = B⊤(t)R−1(t) [r(t)

B(t)x(t)]

−

(I.32)

(I.33)

If (I.33) is substituted into the forward equation (I.23), the latter may be integrated with

sequential input of the observations r(t). Thence, both x(0) and k(0,0) are determined. At

each successive stage one may take k(n+1,0) = k(n) to ﬁnd the gradient k(n+1) for the (n + 1)st

CG step. This entire procedure can be regarded as a nonlinear generalization of the “sweep

method” [8] used to ﬁnd the minimizer of the Onsager-Machup action (0.8).

While this method has the advantage of conceptual simplicity, it suﬀers numerically from

loss of precision and computational ineﬃciency.

It is well-known in numerical optimization

that minimizers are in general obtained to only half the precision of the minimum values them-

selves. As it is the outside minimizer which is of direct interest here, the double minimization

algorithm requires working in a precision quadruple to that desired for the optimizing history.

Furthermore, the nested algorithm requires the square of the number of iterations as for a single

minimization. It is thus advantageous to reformulate the minimax problem in terms of a single

numerical minimization. This can be easily accomplished by rewriting it as

Γ∗[x∗[r]] = min

ΓR[r

Bx[k])]+ < x[k], k >

k {

−

WX[k]
}

.

−

(I.34)

(We thank M. Anitescu for this observation.) Note again that x[t; k] is given directly by (I.21)

via one integration each of the forward and backward Kolmogorov equations over the time

19

interval [ti, tf ]. The result of this single minimization is a control ﬁeld k∗[r], which then yields

the desired optimal history x∗[r] as x[k∗[r]]. The only disadvantage of this formulation is that

the gradient of the functional in brackets in (I.34),

GX [k, r] := ΓR[r

Bx[k]]+ < x[k], k >

WX[k],

(I.35)

−

−

is

δGX
δk(t)

[k, r] =

tf

dt′

δx
δk(t)

ti

Z

[t′; k]

k(t′) + R−1(t′)

B(t′)x[t′; k]

r(t′)

.

(I.36)

h

(cid:0)

−

(cid:1)i

This expression involves

δx
δk(t)

[t′; k] =

δ2WX
δk(t)δk(t′)

[k],

(I.37)

the Hessian of the dual functional WX [k]. Thus, this 2nd-derivative must be evaluated and

stored for use. The storage issue is nontrivial for spatially-extended or distributed systems,

because the Hessian then involves a number of elements of the order of the spacetime grid

squared. However, these problems can be overcome. First, there are eﬃcient direct and adjoint

algorithms for calculating higher-order derivatives, such as Hessians, in addition to those for

ﬁrst derivatives. For example, see [23], Chapter 7, and also [13]. Second, it is not really the

Hessian itself which must be stored but only its matrix products with certain vectors, those

in (I.36). Hence, storage requirements can be reduced in intelligent schemes to vectors of the

same order as required for the double minimization algorithm. We give further details of such

algorithms elsewhere, which we regard as the most promising numerical implementations of our

estimation method.

Whichever of these iterative optimization methods is employed, Γ∗[x] is a convex functional,

and the iterates will therefore converge to the global minimizer x∗[r]. Observe that the zeroth-

order of the double iteration scheme coincides formally with the KSP equations (0.3)-(0.7). In

fact, it is then easy to see that equation (I.33) for k(t) at zeroth-order reduces to

k(t) = B⊤(t)h(t),

(I.38)

20

with h(t) given precisely by (0.5). Substituting this value, the forward-backward equations

in our iterative scheme reduce in form to the KSP equations (0.3),(0.7). In general, there is

no reason to believe (except for linear dynamics), that the variational ﬁlter and KS ﬁlter will

coincide. However, one may hope that the variational estimator, acting as a ﬁlter, is not too far

from the optimal KS ﬁlter. The formal coincidence of these two in the case of linear observations

at the start of the iterative construction provides possibly a convenient algorithmic approach

to assess the diﬀerences. We emphasize, however, the word “formal” in this context, because

the variational equations (I.23), (I.24), while appearing in form identical to the KSP equations

(0.3),(0.7), have a quite diﬀerent mathematical interpretation. Whereas the control ﬁeld h(t) in

the variational equations is non-random, the KSP equations are stochastic PDE’s. In particular,

the numerical discretization schemes appropriate to the two mathematical interpretations are

quite diﬀerent and lead to quantitatively distinct results. This will be discussed in more detail

below for the case of discrete-time measurements.

When the measured function Z(x, t) is nonlinear in x, then our approach must be slightly

generalized. In this case, we consider the joint action ΓX,Z,R[x, z, r], whose minimum over x, z

with r ﬁxed yields the optimum state estimate x∗[r] and also the optimum value of the measured

variable z∗[r]. The advantage to considering this joint action is that it is simply expressed in

terms of the eﬀective action ΓR[ρ] of the observation error, which is still assumed independent

but not necessarily Gaussian. Indeed, a simple calculation in this case gives

ΓX,Z,R[x, z, r] = ΓX,Z[x, z] + ΓR[r

z].

−

(I.39)

In contrast, the joint action ΓX,R[x, r] does not have such a simple expression, but instead must

be calculated via the Contraction Principle as ΓX,R[x, r] = minz ΓX,Z,R[x, z, r]. In the case of a

linear observed variable, Z(x, t) = B(t)x, the joint action ΓX,Z[x, z] is found to be

Hence ΓX,R[x, r] = ΓX[x] + ΓR[r

Bx] and the estimation strategy we have proposed for a

ΓX,Z[x, z] = 


ΓX[x]

if z = Bx

otherwise

−

+

∞



21

(I.40)

nonlinear measurement function reduces to the earlier one in the linear case.

The minimization of ΓX,Z,R[x, z, r] over x, z may be done in two steps, which can be carried

out independently. These are, ﬁrst, to minimize

ΓZ,R[z, r] = ΓZ[z] + ΓR[r

z].

−

(I.41)

over all z at ﬁxed r, and, second, to minimize ΓX,Z [x, z] over all x with z ﬁxed. From the

solutions of these two problems, z∗[r] and x∗[z], respectively, the ﬁnal variational estimator of

the state of the system is then the obtained as the composition x∗[r] = x∗[z∗[r]]. The equivalence

of this two-step formulation with the direct one is an application of the Contraction Principle.

Clearly, minimizing ΓX,R[x, r] over all x can be achieved by minimizing ﬁrst ΓX,Z,R[x, z, r]

over all x with z ﬁxed, and then by minimizing over all z. The minimization over x yields

the joint eﬀective action of z and r, since ΓZ,R[z, r] = minx ΓX,Z,R[x, z, r] by the Contraction

Principle. The minimum is achieved here for some x∗[z], the optimal state history x for a given

z-history. There is no dependence upon r. To see this, observe that the minimization may be

directly carried out in equation (I.39), with the result that ΓZ,R[z, r] is given by (I.41). The

Contraction Principle has been employed again to infer ΓZ [z] = minx ΓX,Z[x, z]. It is from this

minimization that x∗[z] is determined, which therefore cannot involve r. All of the dependence

upon measurements is now isolated in (I.41), whose minimization over z yields z∗[r].

This ﬁrst minimization of ΓZ,R[z, r] over z is a problem of the same type as for the case of

linear measurement functions discussed in the text. As there, a CG-type method applied to

Γ∗[z] := ΓZ,R[z, r] may be employed to calculate z∗[r], based upon the Legendre dual relations

h[t; z] =

[z], z[t; h] =

δΓZ
δz(t)

δWZ
δh(t)

[h].

(I.42)

Any of the algorithms discussed in the text may be employed. For example, in the double

minimization scheme, the gradient for the outer minimization,

h∗[t; z(n)]

:=

δΓ∗
δz(t)

[z(n)]

22

= h[t; z(n)] + R−1(t)[z(n)(t)

r(t)],

(I.43)

−

would be obtained from an inner one. The iteration could be initiated by

and

z(0)(t) =

Z(t)
it
h

h(0,0)(t) = R−1(t) [r(t)

Z(t)

it] .

− h

(I.44)

(I.45)

Just as before—but now quite in general—the zeroth-order control h(0,0)(t), when substituted

into the forward-backward equations (I.23), (I.24) recovers formally the KSP equations.

The second minimization of ΓX,Z [x, z] over x is similar. Note that

ΓX,Z[x, z] = max

< k, x > + < h, z >

k,h {

WX,Z[k, h]
}

.

−

(I.46)

Hence, the problem

ΓX,Z[x∗[z], z] = min

max
k,h {

x

< k, x > + < h, z >

WX,Z[k, h]
}

−

(I.47)

is again of minimax type. A doubly iterative scheme would therefore carry out the maximization

over k, h at ﬁxed x, z to obtain not only ΓX,Z[x, z] but also the gradients

k[t; x, z] =

[x, z], h[t; x, z] =

(I.48)

δΓX,Z
δx(t)

δΓX,Z
δz(t)

[x, z]

that are used in the next minimization over x (at ﬁxed z). Alternatively, one may solve this

problem as before via a single minimization over k, h of a functional

GX,Z [k, h] :=< k, x[k, h] > + < h, z[k, h] >

WX,Z[k, h]

(I.49)

−

but with the diﬀerence that this minimization is now subject to a nonlinear constraint that

z[t; k, h] = z(t),

[ti, tf ].

t

∈

(I.50)

This may be addressed using algorithms from nonlinear programming or stochastic/ quasi-

random methods.

23

I.5. Estimation with Discrete-Time Data

So far, we have considered the case where the measurements employed in our estimation are

taken continuously in time. However, this can only be an idealization of a situation where

the data are obtained at a discrete series of times. In many practical examples, the instants

of measurement will be so widely separated that the idealization of continuous acquisition is

far from valid. It is thus a very practical concern to address the issue of state estimation of

continuous in time, stochastic dynamical systems such as (0.1) based upon discrete-time data.

In addition, we shall ﬁnd that some fundamental new concepts are required that are important

in other contexts. For example, the calculation of ensemble dispersions at an instant of time

will turn out to be closely related to the problem of estimation with discrete-time data.

The only change in the statement of the problem in the Introduction is that now the mea-

surements are of the form

rk = Z(x(tk), tk) + ρk, k = 1, ..., n

(I.51)

where ρk represents a measurement error with covariance Rk. If the measurement error is taken

to be an independent Gaussian at each time tk, then the cost function for the observations is

Xk=1
where the sum includes all of the observation times t1, ..., tn up to the present time. The

ΓR[ρ] =

k R−1
ρ⊤

k ρk,

n

1
2

(I.52)

combined cost function Γ∗[z] := ΓZ,R[z, r] for the estimation is then, analogous to (I.41),

Γ∗[z] = ΓZ [z] +

[rk −

z(tk)]⊤R−1

k [rk −

z(tk)].

(I.53)

1
2

n

Xk=1

For simplicity, we shall only consider here the problem of estimating the optimal z-history.

As discussed in the previous section, there remains the problem of estimating the optimal

state or x-history, given the z-history. This can be handled in the same way as discussed

there. Alternatively, we might formulate the problem as a direct estimation of x. The changes

necessary to our discussion below should be obvious to the reader. If we seek the minimizer of

24

(I.53), we must satisfy

0 =

[z] = h[t; z] +

δΓ∗
δz(t)

n

R−1

k [z(tk)

rk]δ(t

tk).

−

−

(I.54)

Xk=1
Thus, we see that h[t; z∗] for the optimal z∗[r] must be a sum of delta functions at the obser-

vation times. This suggests that we consider only the estimation of z at the observation times.

In fact, we will see that this suﬃces.

The cost function H∗(z1, ..., zn) := HZ,R(z1, ..., zn; r1, ...rn) for estimating zk := z(tk), k =

1, ..., n is obtained in the following way. First, we deﬁne a cumulant generating function

FZ (λ1, ..., λn) := log

exp[
h

λ⊤

k Z(tk)]
.
i

n

Xk=1

This is entirely analogous to the cumulant generating functional WZ[h] deﬁned in subsection

2.1. In fact, they are equal with

h(t) =

λkδ(t

tk).

−

n

Xk=1

n

The Legendre transform of FZ is the dynamical part of the cost function:

HZ (z1, ..., zn) = max

λ1,...,λn (

z⊤
k λk −

FZ (λ1, ..., λn)

.

)

Xk=1
This quantity is called the multitime (relative) entropy. It may also be obtained via the Con-

traction Principle directly from the eﬀective action through a constrained minimization:

HZ(z1, ..., zn) =

min
{z:z(tk)=zk,k=1,...,n}

ΓZ [z].

The combined cost function is then

H∗(z1, ..., zn) = HZ(z1, ..., zn) +

[rk −

zk]⊤R−1

k [rk −

zk].

1
2

n

Xk=1

Its minimization yields the optimal values of z(t1), ..., z(tn). The condition for the minimum is

(I.55)

(I.56)

(I.57)

(I.58)

(I.59)

(I.60)

which can already be inferred from (I.54),(I.56). We may regard (I.60) as a nonlinear equation

for either the λ’s or the z’s.

λk = R−1

k [rk −

zk],

25

To calculate numerically the cost function HZ (z1, ..., zn) we see that we must integrate

the forward and backward equations (I.23),(I.24) with a control ﬁeld h(t) consisting of delta-

function spikes, as in (I.56).

It is easiest to formulate this integration in terms of suitable

jump conditions at the observation times. That is, we may integrate the ordinary forward and

backward Kolmogorov equations (I.16),(I.17) with h = 0 between the observation times but

make discrete jumps at those times. We shall show that the proper jump conditions are simply

(x, tk+) =

P

eλ⊤

k Z(x,tk)
(tk−

W

) P

(x, tk−

),

(x, tk−

A

) =

eλ⊤

k Z (x,tk)
(tk−

W

) A

(x, tk+).

and

Here we deﬁned

(tk−

W

) :=

Z

dx eλ⊤

k Z (x,tk)

(x, tk−

P

) =

k Z (tk)

eλ⊤
h

itk−,

so that division by that factor guarantees proper normalization of the results after the jump.

We prove now the validity of these jump conditions. For the ﬁrst, it is useful to make a

reformulation of the forward equation (I.23). The same solution found for that equation may

be obtained by solving instead

∂tQ

(t) = ˆL(t)

(t) + h⊤(t)Z(t)

Q

(t)

· Q

and then renormalizing subsequently

with

It is not hard, by diﬀerentiating (I.65) with respect to time, to show that

(t) so-deﬁned

P

satisﬁes (I.23). This is actually a standard device to solve the Kushner-Stratonovich equation.

P

(x, t) := Q
N

(x, t)
(t)

(t) :=

dx

(x, t).

N

Q

Z

26

(I.61)

(I.62)

(I.63)

(I.64)

(I.65)

(I.66)

In that context, the analogue of equation (I.64) is called the Zakai equation [26]. With the

delta-function control ﬁeld, we obtain

ˆL(t)

(t)

n

∂t ln

(t) =

Q

Q
(t)

Q

+

λkZ(tk)δ(t

tk).

−

Xk=1
ǫ, tk + ǫ) and take the limit as ǫ

We then integrate in time over the range (tk −
term on the righthand side is continuous and does not contribute. From the delta function

0. The ﬁrst

→

contribution we easily obtain

(x, tk+)
Q
(x, tk−
)
Q
(x, tk+), we recover (I.61), as claimed.

= eλ⊤

k Z(x,tk).

Renormalizing

Q

The second jump condition can be similarly obtained. The backward equation (I.24) must

likewise be rewritten so that the source terms stand alone before integration.

In fact, by

integrating (I.64) over x, one ﬁnds that

d
dt

ln

Z(t)
(t) = h⊤(t)
h

it.

N

Using this result, one easily derives from (I.24) that

∂t ln

(t)
(t) (cid:19)

A
N

(cid:18)

+

ˆL∗(t)

(t)

A
(t)

A

+ h⊤(t)Z(t) = 0.

(I.70)

Let us now consider the case where h(t) is given by (I.56), as a sum of delta-functions. Inte-

grating (I.70) over the range (tk −

ǫ, tk + ǫ) and taking the limit as ǫ

0, then yields

→

Of course,

(t) itself experiences a jump across the observation time tk, changing as we have

N

seen by the ratio

immediately follows.

(x, tk+)/
(x, tk−
)/

N
N

(tk+)
)
(tk−

A
A

= e−λ⊤

k Z (x,tk).

(tk+)
)
(tk−

N
N

k Z (tk)

=

eλ⊤
h

itk− =

).

(tk−

W

27

This is a direct consequence of (I.68). From (I.71) and (I.72), the second jump condition

(I.67)

(I.68)

(I.69)

(I.71)

(I.72)

Using the jump conditions (I.61) and (I.62) to replace the controlled forward and backward

equations (I.23),(I.24), the calculation of the cost function proceeds as follows.

Integrating

(I.69) over the time-interval [ti, tf ] and comparing with (I.25), we see that

FZ (λ1, ..., λn) = log

(tf ).

N

By writing

(tf ) =

N

n
k=1

N (tk+)
N (tk−) (where

(t1−

N

sum of contributions for each time tk

Q

) = 1 was used), we can decompose this into a

with

FZ (λ1, ..., λn) =

(∆F )k(λ1, ..., λk)

n

Xk=1

(∆F )k(λ1, ..., λk) := log

k Z (tk)

eλ⊤
h

itk− = log

).

(tk−

W

Whereas the dependence upon λk is explicit, note that the dependence upon the remaining

variables λ1, ..., λk−1 is only implicit through

). Having determined FZ (λ1, ..., λn), the

P
entropy HZ(z1, ..., zn) can then be obtained by the Legendre transform formula (I.57). In that

(x, tk−

formula zk := z(tk), k = 1, ..., n, with z(t) given for all times t by

z(t) =

dx Z(x, t)

(x, t)

(x, t).

A

P

Z

It is worth emphasizing that the history z(t) is a continuous function of time. This will be true

even though the solutions

(x, t),

(x, t) have jump discontinuities at the observation times

P

A

t = tk, k = 1, ..., n. In fact, it is easy to see by a direct diﬀerentiation that

dz
dt

(t) =<

∂t ˆZ + [ ˆL∗, ˆZ]
{

}A

(t),

(t) > .

P

In particular, all of the delta-function sources cancel from this equation. Hence, z(t) is contin-

uous but will generally have a time-derivative with jump-discontinuities.

The rest of the estimation protocols outlined in sections I.4 are the same. For example, the

double minimization algorithm may be carried out using the Legendre dual pair HZ(z1, ..., zn),

FZ (λ1, ..., λn). The iteration may be initiated by taking

(I.73)

(I.74)

(I.75)

(I.76)

(I.77)

(I.78)

z(0)
k =

Z(tk)
h

itk +

28

λ(0,0)
k = R−1

k [rk − h

Z(tk)

itk −].

(I.79)

∗(t),

∗(t)

P

A

k, z∗

k obtained as

The ﬁnal result will be an optimal estimated history z∗(t) given by (I.76), where

therein are the solutions of the forward and backward equations for the λ∗

convergents of the minimization algorithm.

It is worthwhile to compare this procedure for calculating the variational estimator with

discrete data to that for calculating the optimal KSP estimator in the same circumstances.

It is shown in Appendix 1 that the optimal estimator may be obtained as well by integrat-

ing the forward and backward Kolmogorov equations (I.16),(I.17) for

A∗(t) between the
observation times and by making discrete jumps at those times. The proper jump conditions

P∗(t),

(cid:20)

(cid:20)

P∗(x, tk+) =

1
W∗(tk−

)

exp

λ⊤
k

Z(x, tk)

1
2

−

δZ ⊤(x, tk−

)R−1

k δZ(x, tk−

)

(cid:21) P∗(x, tk−

),

(I.80)

A∗(x, tk−

) =

1
W∗(tk−

)

In these equations

exp

λ⊤
k

Z(x, tk)

1
2

−

δZ ⊤(x, tk−

)R−1

k δZ(x, tk−

)

(cid:21) A∗(x, tk+).

(I.81)

the same as the zeroeth-order (I.79) above,

λk = R−1

k [rk − h

Z(tk)

itk −],

δZ(x, tk−

) := Z(x, tk)

Z(tk)

itk−,

− h

(I.82)

(I.83)

and

are

and

and

W∗(tk−

) :=

Z

dx exp

λ⊤
k

Z(x, tk)

(cid:20)

1
2

−

δZ ⊤(x, tk−

)R−1

k δZ(x, tk−

)
(cid:21) P

(x, tk−

)

(I.84)

is the factor to keep the density

P∗(x, t) normalized. The solutions of these equations after a
single forward and backward integration then yield the conditional probability density, via the

formula

(x, t

(tf )) =

P

|R

A∗(x, t)

P∗(x, t). See Appendix 1.

29

It is now clear that the zeroeth-order variational estimator, calculated after one forward-

backward sweep initialized with (I.78),(I.79), does not coincide with the optimal KSP estimator,

for the case of discrete-time measurements. The main diﬀerence, one can easily see, lies in the
extra term in the exponent quadratic in δZ(x, tk−
estimate after the jump from being too far from the prior estimate

itk−. The absence
of this term in the zeroeth-order variational equations helps to make clear in what sense it is

). This term has the eﬀect of preventing the

Z(tk)
h

a “mean-ﬁeld” approximation of the optimal estimator, obtained by neglect of “ﬂuctuations”.

In fact, if we estimate not the variable Z(t) itself, but rather its sample mean ZN (t), then

heuristically λ remains unchanged but δZN (t) = O(N −1/2). Hence, the quadratic term in

the exponent is O(1/N ) and may be neglected. Of course, it must be realized that we are

here comparing the optimal KSP estimator with only a zeroeth-order approximation to the

variational estimator, not to the variational estimator itself for the converged values of λ∗

k, k =

1, ..., n. We hope that, in general, the value of the variational estimator, calculated with the

“mean-ﬁeld” jump rules (I.61),(I.62) for the minimizing values λ∗

k, will not be too far from the

optimal KSP estimator given by the jump rules (I.80),(I.81).

The diﬀerence between the zeroeth-order variational estimator and the optimal KSP esti-

mator which we have illustrated above for the case of discrete-time measurements, of course

also holds in the case of continuous-time measurements. In that case it is a consequences of

the diﬀerence in mathematical interpretation of the zeroeth-order variational equations and the

KSP stochastic equations, despite their formal identity. Of course, at this point one might

question the utility of the variational formulation compared with the straightforward Bayesian

approach based upon the KSP equations. Whether in the discrete- or continuous-time formu-

lations, it is essentially just as diﬃcult to solve the KSP equations as to make one “sweep” in

the iterative solution of the variational problem. However, the latter requires in most cases a

large number of “sweeps” and furthermore provides a suboptimal estimate compared with the

KSP approach! The advantage of the variational approach will become apparent in Part II,

when we consider making ﬁnite-dimensional approximations.

30

I.6. Calculation of the Ensemble Dispersion

As discussed in section I.1, one would like to have not just the mean state x∗(t) but also the

covariance matrix C∗(t) in the conditioned ensemble at each time t. As we shall show now,

the covariance may be readily calculated from the cost function itself. For simplicity, we shall

conﬁne our discussion to the calculation of the covariance of the measured variable Z(t). The

changes required for the determination of the state covariance will be obvious.

Let us discuss ﬁrst the case with discrete-time data. The entropy function H∗(z1, ..., zn) :=

HZ,R(z1, ..., zn; r1, ..., rn) that we introduced in (I.59) of the last subsection has also an in-

terpretation as a generating function for (irreducible) multitime correlations in the ensemble

conditioned on rN (tj) = rj, j = 1, ..., n. Thus, one may calculate the 2-time irreducible corre-

lator

This irreducible correlator is related to the multitime covariance matrix by matrix inversion:

Γ∗(tk, tj) =

∂2H∗
∂zk∂zj

.

z=z

(z1, ..., zn)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

C∗(tk, tj) = [Γ∗(tk, tj)]−1.

The same quantity could also be obtained from F∗(λ∗

1, ..., λ∗

n) := FZ,R(λ∗

1, ..., λ∗

n; r1, ..., rn), the

Legendre dual of H∗(z1, ..., zn), as

C∗(tk, tj) =

∂2F∗
k∂λ∗
j

∂λ∗

(λ∗

.

λ∗

=0

1, ..., λ∗
n)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

From this one may obtain the single-time covariance at any of the times tk by considering the

diagonal C∗(tk) = C∗(tk, tk). Without loss of generality, one may include any time of interest

as one of the “measurement times” by simply taking the corresponding value of its observation

error as inﬁnite, or R−1

k = 0.

While this procedure gives the correct result, it is not so practical because the quantity

of interest, the diagonal C∗(tk), is obtained only through the intermediary of the full 2-time

covariance C∗(tk, tj). A more useful approach is based upon the single-time generating function

(I.85)

(I.86)

(I.87)

31

obtained from the Contraction Principle

H∗(z; tk) := min
˜z:˜zk=z

H∗(˜z1, .., ˜zn).

This is just the (conditional) relative entropy at time tk. We have chosen here to make the

time-dependence explicit in the instantaneous entropy. One can calculate the Hessian of this

function

and then obtain

the condition

Γ∗(tk) =

∂2H∗
∂z∂z

.

z=zk

(z; tk)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

C∗(tk) = [Γ∗(tk)]−1.

To employ this method, one must carry out the minimization in (I.88). This leads as before to

∂H∗
∂zj

(˜z1, ..., ˜zn)

:= λ∗

j (˜z1, ..., ˜zn)

= λj(˜z1, ..., ˜zn) + R−1

j (˜zj −

rj)

= 0,

for j

= k with ˜zk = z ﬁxed. This minimization problem can be solved computationally with

the same methods used to ﬁnd the global minimum, e.g. the double CG-type algorithm, but

now with ˜zk = z held invariant and H∗ minimized only over the remaining variables ˜zj, j

= k.

The result will be the constrained minimizers z∗

j (z; tk) that, substituted into λ∗

j (˜z1, ..., ˜zn) with

˜zk = z, give 0 for all j

= k. However,

λ∗(z; tk) := λ∗

k(˜z1, ..., ˜zn)

|˜zk=z; ˜zj=z∗

j (z;tk), j6=k

will not be zero. In fact, it is not hard to see that

Then, from (I.89),

λ∗(z; tk) =

(z; tk).

∂H∗
∂z

Γ∗(tk) =

∂λ∗
∂z

32

.

z=zk

(z; tk)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(I.88)

(I.89)

(I.90)

(I.91)

(I.92)

(I.93)

(I.94)

6
6
6
This gives rise to a simple, practical algorithm to calculate the covariance, by means of a

ﬁnite-diﬀerence approximation for some small δ

Γ∗

αβ(tk)

α(z+β; tk)
λ∗

α(z−β; tk)
λ∗

λα(z+β; tk)

λα(z−β; tk)

−
2δ

−
2δ

≈

=

+ [R−1

k ]αβ,

z±β := zk ±

δ

·

ˆeβ,

and ˆeβ a unit vector in the β-direction. We have set λ(z; tk) = λk(˜z1, ..., ˜zn)

j (z;tk), j6=k.
This approximation requires the calculation of λ∗(z; tk) for the two new values z = z±β displaced

|˜zk=z; ˜zj=z∗

slightly from zk. This can be accomplished using (I.92) and the double minimization algorithm.

Suitable guesses to initiate the minimization would be

with

and

˜z(0)
j = 


z±β

j = k

zj

j

= k



λ(0,0)
j

= R−1

j

[rj −

˜z(0)
j

], j = 1, ..., n.

(I.95)

(I.96)

(I.97)

(I.98)

Of course, ˜zk = z±β is held ﬁxed in the iteration. This procedure must be followed to calculate

the covariance at each time tk of interest. For each scalar variable, calculating its variance by

this method is roughly twice the work as calculating the optimal estimate itself over the whole

interval of time. However, this statement is misleadingly pessimistic. In fact, the initial points

considered, ˜zk = z±β, ˜zj = zj, j

= k are very close to the optimal history, which is assumed

known. Hence, only small changes will occur in the ˜zj’s, O(δ) corrections to the zj’s, and the

minimization algorithm should converge quite quickly. The contribution of the various small

changes can be read oﬀ from (I.95). The direct contribution from the change in ˜zk to z±β is

[C(tk)]−1 + R−1

k , where C(tk) is the covariance in the unconditioned ensemble. The additional

contributions from the small changes in the ˜zj, j

= k will be similar, but will decay according

to the distance of tj from tk in time. The rate of decay will be determined by some internal

relaxation or memory time of the system.

33

6
6
6
If the number of variables whose variance is required is large, then even the matrix inversion

in (I.90) is diﬃcult and should be avoided. This can be accomplished by following an alternative

procedure, based upon implementing the constraint ˜zk = z by a Lagrange multiplier. In this

case, (I.88) is replaced by an unconstrained minimization

H∗(z; tk) := min
˜z1,...,˜zn

˜H(˜z1, .., ˜zn; ˜λ),

⊤
˜H(˜z1, .., ˜zn; ˜λ) := H∗(˜z1, .., ˜zn) + ˜λ

(z

˜zk),

−

and the Lagrange multiplier ˜λ is chosen subsequently to impose the constraint ˜zk = z. The

condition for the minimum over all the variables ˜zj, j = 1, ...n, is

∂ ˜H
∂˜zj

(˜z1, ..., ˜zn)

:= λ∗

j (˜z1, ..., ˜zn)

˜λδjk

−

Thus, we see that the minimizing ˜zj(˜λ; tk)’s in (I.99) are nothing more than

where

where

= 0.

1, ..., λ∗
n)
(cid:12)
(cid:12)
(cid:12)

∂F∗
∂λ∗
j

˜zj(˜λ; tk) = z∗

j (λ∗

λ∗

k=

˜λ; λ∗

j =0, j6=k

j (λ∗
z∗

1, ..., λ∗

n) :=

(λ∗

1, ..., λ∗

n).

C∗(tk) =

=

∂z∗
k
∂λ∗
k
∂˜zk
∂ ˜λ

(λ∗

1, ..., λ∗
n)
(cid:12)
(cid:12)
(cid:12)
.
(cid:12)

˜λ=0

(˜λ; tk)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

λ∗

j =0, j=1,...,n

Incidentally, it is clear also from (I.102) that the value of the Lagrange multiplier to achieve

the constraint ˜zk = z is just ˜λ = λ∗(z; tk) as given in (I.92),(I.93). The important point for

our considerations here is that formula (I.104) involves no matrix inversion.

Thus, formula (I.104) becomes the basis of an alternative procedure to numerically compute

the covariance. In this procedure, one minimizes ˜H(˜z1, .., ˜zn; λ±β) for the values

(I.99)

(I.100)

(I.101)

(I.102)

(I.103)

(I.104)

(I.105)

Then, using (I.87), one obtains

λ±β =

δ

±

·

ˆeβ

34

to obtain ˜zj(λ±β; tk), j = 1, ..., n. Then one may approximate

C ∗

αβ(tk)

≈

˜zkα(λ+β; tk)

˜zkα(λ−β; tk)

.

−
2δ

The minimization to obtain the ˜zj(λ±β; tk) may be carried out with similar methods as before,

e.g. the double CG-type algorithm initiated with the guesses

˜z(0)
j = zj, j = 1, ..., n

λ(0,0)
j

= R−1

j

[rj −

zj] + λ±βδjk, j = 1, ..., n.

and

with

Our discussion above carries over straightforwardly to the case of continuous-time data acqui-

sition. The entropy at any time t0 is, by the Contraction Principle, given as

with ΓZ,R as in (I.27). Alternatively, one has

HZ,R(z, r; t0) = min

ΓZ,R[z, r]

z:z(t0)=z

HZ,R(z, r; t0) = min

˜ΓZ,R[z, r; ˜λ],

z

⊤
˜ΓZ,R[z, r; ˜λ] := ΓZ,R[z, r] + ˜λ

[z

z(t0)].

−

Either of the approaches outlined above may be used to ﬁnd C(t0; r). For example, in the

second method

˜λ=0
where ˜z[t; r, ˜λ] is the solution of the minimization condition

C(t0; r) =

∂˜z
∂ ˜λ

[t0; r, ˜λ]
(cid:12)
(cid:12)
(cid:12)
(cid:12)

0 =

δ˜ΓZ,R
δz(t)

[z, r; ˜λ] = h[t; z, r]

˜λδ(t

−

t0).

−

This is solved with the double CG-type algorithm, using jump conditions (I.61),(I.62) at t0.

(I.106)

(I.107)

(I.108)

(I.109)

(I.110)

(I.111)

(I.112)

(I.113)

35

II Moment-Approximation of the Optimal Estimator

II.1. The Rayleigh-Ritz Method

Until now all of our theoretical work has been exact and without any approximation, other than

that involved in conditioning on sample averages, the “mean-ﬁeld” approximation discussed in

the section I.3. However, it is clear that additional approximations are required to achieve a

computationally tractable estimation scheme for spatially-extended or distributed systems. As

discussed in the Introduction, the exact calculation of the optimal nonlinear estimator by the

KSP equations is already known to be numerically unfeasible in such situations. Furthermore,

computation of the exact variational estimator is just as impractical as the computation of the

exact KSP optimal estimator for a system with a large number of degrees-of-freedom. It will

not be possible for almost any system of real, practical interest. The existence of a variational

principle does not ameliorate the basic computational diﬃculty imposed by the enormously

many variables. Just as for the KS ﬁlter, moment-closure appears to be the only tractable

numerical approach to an approximate solution. The advantage of the variational formulation is

that it permits ﬁnite-dimensional approximations to be constructed by a Rayleigh-Ritz method

which preserves the main structural properties of the exact estimator, discussed previously. We

shall brieﬂy discuss these features here, referring to previous works [11, 13] for many details.

The Rayleigh-Ritz approximation to the cost function is obtained by means of the charac-

terization of that functional through the constrained variation in (I.19). Rather than varying

over all

L∞,

L1, one varies only over ﬁnitely parametrized trial functions. The trial

A ∈

P ∈

functions are constructed from the usual elements of a moment-closure: a set of moment func-

tions Mi(x, t), i = 1, ..., R and a PDF Ansatz

(x, t; µ), which is conveniently parametrized

by the mean values which it attributes to the moment-functions, µ :=

dx

(x, t; µ)M(x, t).

The left trial function may be taken to be

(t) = 1 + [

(t)

B

− hB

(t)

R
it] with

P

Xi=1
Following the discussion in section 2.3, we have chosen the left trial state in the form (I.22),

(x, t; α) :=

αiMi(x, t).

B

(II.1)

P

A

R

36

to incorporate automatically the overlap constraint (I.20). The histories α(t), µ(t) are the

parameters to be varied over. Substituting the trial forms, one obtains the reduced action

(II.2)

(II.3)

(II.4)

(II.5)

(II.6)

Γ[α, µ] =

dt α⊤(t)[ ˙µ(t)

V(µ(t), t)]

−

tf

ti

Z

V(µ, t) :=

(∂t + ˆL∗)M(t)
µ(t).
i
h

with

Here,

Of course,

µ(t) denotes average with respect to the PDF Ansatz. An unconstrained variation

h·i

of (II.2) recovers the standard moment-closure equation:

˙µ = V(µ, t). For the calculation of

the action, however, there is the additional expectation constraint (I.21). In terms of the trial

functions, it becomes

z(t) = ζ(µ(t), t) + CZ(µ(t), t)α(t).

is the Z-expectation within the PDF Ansatz and

ζ(µ, t) :=

Z(t)
µ
i
h

CZ(µ, t) :=

Z(t)M⊤(t)
µ
i
h

−

ζ(µ, t)µ⊤

is the corresponding ZM -covariance matrix. It is remarkable that ζ(µ, t), CZ (µ, t) are the only

inputs of the PDF Ansatz actually required for the calculation.

When the constraint (II.4) is incorporated into the action functional (II.2) by means of a

Lagrange multiplier h(t), the resulting Euler-Lagrange equations are

˙µ = V(µ, t) + C⊤

Z (µ, t)h(t)

:= VZ (µ, h, t).

(II.7)

and

˙α +

⊤

∂VZ
∂µ

(cid:18)

(cid:19)

⊤

∂ζ
∂µ

(cid:18)

(cid:19)

(µ, h, t)α +

(µ, t)h(t) = 0.

(II.8)

These are solved subject to an initial condition µ(ti) = µ0 and a ﬁnal condition α(tf ) = 0.

When the solutions of the integrations are substituted into (II.2), there results a Rayleigh-Ritz

37

approximation ˜ΓZ [z] to the eﬀective action of Z(t). The value z(t) of the argument is that given

by the constraint equation (II.4) for the given value of the control ﬁeld h(t). A corresponding

approximation of the cumulant generating functional is given by

˜WZ[h] =

dt h⊤(t)ζ(µ(t), t)

(II.9)

tf

ti

Z

in which µ(t) is the solution of just the forward equation (II.7) for the control history h(t).

It is a very attractive feature of the above approximation scheme that the resulting func-

tionals ˜ΓZ [z], ˜WZ [h] remain formal Legendre transforms of each other. That is,

and

˜WZ[h] + ˜ΓZ[z] =< h, z >

h[t; z] =

[z], z[t; h] =

δ˜ΓZ
δz(t)

δ ˜WZ
δh(t)

[h].

(II.10)

(II.11)

This fact makes it possible to carry over directly all of the minimax algorithms discussed in

section I.4 for determination of optimal histories using the exact cost function to the Rayleigh-

Ritz approximate one. Incidentally, the form of the constraint (II.4) makes it more apparent

that this approach generalizes the “sweep method” employed in the case of linear dynamics [8].

The iterative constructions that were discussed for the exact optimal estimator can be

followed also to calculate the moment-closure approximation. For example, consider the two-

step method. As the ﬁrst step, one can calculate the approximate optimal ˜z∗[r] given r, by

˜ΓZ,R[z, r] = ˜ΓZ[z] +

dt [r(t)

z(t)]⊤R−1(t)[r(t)

z(t)].

(II.12)

−

−

tf

1
2

ti

Z

over z with r ﬁxed. This can be accomplished, for example, with a double CG method as

minimizing

before, taking now

z(0)(t) = ζ(µ, t)

h(0,0)(t) = R−1(t) [r(t)

ζ(µ, t)]

−

(II.13)

(II.14)

as the zeroth-order inputs. It is clear that (II.14), substituted into the approximate forward

equation (II.7), is formally equivalent to a moment-closure of the KS-equation. (Although it

38

must be emphasized once more that, in the case of the KS ﬁlter, the closure equation analogous

to (II.7) must be regarded as a stochastic diﬀerential equation.) The second step is to calculate

the approximate optimal ˜x∗[z] by minimizing ˜ΓX,Z[x, z] over x with z ﬁxed. Of course, the

Rayleigh-Ritz approximation ˜ΓX,Z [x, z] is calculated by the analogous equations as (II.7),(II.8):

˙µ = V(µ, t) + C⊤

X(µ, t)k(t) + C⊤

Z (µ, t)h(t)

:= VX,Z(µ, k, h, t).

(II.15)

and

˙α +

∂VX,Z
∂µ

⊤

(cid:19)

(cid:18)

⊤

∂ξ
∂µ

(cid:18)

(cid:19)

⊤

∂ζ
∂µ

(cid:18)

(cid:19)

(µ, k, h, t)α +

(µ, t)k(t) +

(µ, t)h(t) = 0,

(II.16)

where ξ(µ, t), CX(µ, t) are the closure X-mean and XM -covariance, respectively. The ﬁnal

approximate estimator is then the composition ˜x∗[r] = ˜x∗[˜z∗[r]].

However, there is a potential diﬃculty in applying the minimization algorithms: the Rayleigh-

Ritz approximations to the cost functions need not be convex at all! Lack of convexity would

correspond to a failure of realizability of the predicted multi-time correlations [11]. As a conse-

quence of this failure, there might exist local minima in addition to the global one or, possibly,

no minimum at all, local or global. In the former case, a CG algorithm could be trapped in a

local minimum, and, in the latter, it would not converge at all. Thus, for numerical purposes,

it is exceedingly desirable to maintain convexity. It was shown in [12] that convexity will be

maintained —at least for an expansion of the action to quadratic order in small departures from

the minimum—whenever the relative entropy is a Lyapunov stability function for the closure

dynamics. It is possible to construct closures for nonlinear stochastic dynamics which guaran-

tee the validity of such an H-theorem [27], using methods previously developed for Boltzmann

kinetic equations in transport theory [28]. One example of the general scheme are closures

based upon an exponential PDF Ansatz. Such closures have the property that the relative

entropy satisﬁes an H-theorem and thus (local) convexity of the Rayleigh-Ritz approximations

is guaranteed. This is discussed further in [27] and in section II.3 below.

39

II.2. Discrete-Time Data and Ensemble Dispersion

We have seen in section I.5. that the estimation problem based upon discrete-time data has,

in the exact formulation, a simple solution in terms of certain jump conditions. The situation

is worse for closure approximations.

In fact, we shall see below that, for general moment-

closures, the approximate “smoother” with discrete-time data may not even be continuous at

the observation times! This is an important failing since these same methods are also involved

in the calculation of instantaneous ensemble dispersions, as we have seen in section I.6.

Let us illustrate the nature of the problem for a general moment-closure. If one diﬀerentiates

the expression for z(t) in (II.4) with respect to time, using the variational equations (II.7), (II.8),

simple computations give a result of the form

dza
dt

(t) =

(µ, t) + αj

dζa
dt

dC Z
aj
dt

"

(µ, t)

C Z

ai(µ, t)

−

∂Vj
∂µi

(µ, t)

#

+hb(t)

C Z

bi(µ, t)

(µ, t)

C Z

ai(µ, t)

−

+hb(t)

C Z

bi(µ, t)

(µ, t)

C Z

ai(µ, t)

−

∂ζa
∂µi
∂C Z
aj
∂µi

∂ζb
∂µi

(µ, t)
(cid:21)
(µ, t)

∂C Z
bj
∂µi

αj.

#

(cid:20)

"

(II.17)

For any function of µ, t we set d

dt := ∂

∂t +V(µ, t)·∇µ. Equation (II.17) should be compared with

the exact result in (I.77). In contrast to the cancellation of the explicit h(t) terms found there,

such terms remain in the second and third lines above. Only in the case where a single scalar

variable z(t) is considered and thus a = b = 1 is there an obvious cancellation in the last two

terms. This means that, in general, the delta-functions will not cancel if one considers a control

ﬁeld of the form h(t) =

tk), as appropriate for discrete-time data, and z(t) itself

will have jump-discontinuities at the measurement times tk. Of course, one take observations,

k λkδ(t

−

P

not instantaneously, but instead averaged over a small interval of time τ . The delta functions

are then replaced by approximate delta’s δτ (t

tk) with time-window τ . However, the problem

will reappear when τ is taken very small, for then z(t) will change sharply at times tk.

A related problem has to do with the formulation of proper jump conditions in the same

circumstances. Let us even assume that z(t) is a single scalar. Then, the forward equation for

−

40

the moment variable µ becomes

˙µi = Vi(µ, t) + h(t)C Z

i (µ, t).

(II.18)

If h(t) is a sum of delta-functions, then one cannot integrate the equation to obtain the jumps

in µi at the observation times. The diﬃculty is that C Z

i (µ, t) will then also have jump-

discontinuities at those times and it is impermissable to integrate a delta-function against

a discontinuous function. The obvious strategy is ﬁrst to divide both sides by C Z

i (µ, t) and

only afterward integrate across the jump. There is still a problem however. The other variables

besides µi in the integrand also make jumps and it is therefore ambiguous which value should

appear as the integration range shrinks to zero. Thus, the strategy only works in the case where

there is also a single scalar moment variable µ(t). In that case, we can integrate and obtain a

jump condition in the form of an “area rule”:

). The backward jump condition for the adjoint variable α then follows

most easily from the continuity of z(t) noted above. With notations as above, α±

We have set µ±

k = µ(tk±

and so forth, we have

The jumps in ζ, C Z are known, because these are assumed continuous functions of µ, t and the

jump in µ is known from (II.19). Solving for the backward jump gives

µ+
k

−
µ
k

Z

dµ
C Z (µ, tk)

= λk.

k + C Z+
ζ +

k α+

k = ζ −

k + C Z−

k α−
k .

α−

k =

(ζ +

k −

k α+
k

k ) + C Z+
ζ −
C Z−
k

.

(II.19)

k = α(tk±

)

(II.20)

(II.21)

Hence, only in the case of a single scalar moment function and observation variable is it obvious

how to formulate jump conditions, in the case of a general moment-closure.

It still remains in that case to formulate the algorithm to calculate the cost function itself.

The proper deﬁnition turns out to be

FZ (λ1, ..., λn) :=

(∆F )k(λ1, ..., λk)

(II.22)

n

Xk=1

41

where the increment at time tk is given by a second area rule:

µ+
k

−
µ
k

Z

ζ(µ, tk)
C Z(µ, tk)

dµ = (∆F )k.

(II.23)

There is a simple heuristic motivation for both this rule and the previous one. In fact, the basic

approximation is to replace the exponentially-modiﬁed PDF by a PDF from the Ansatz with

an adjusted moment. That is,

with the normalization factor

The M -moment of (II.24) is

1
(λk; µ−

k , tk)

W

eλkZ(x,tk)P (x, tk; µ−
k )

P (x, t; µ+

k ),

≈

(λk; µ−

k , tk) :=

dx eλkZ(x,tk)P (x, tk; µ−

k ).

W

Z

k (λk; µ−
µ+

k , tk)

:=

dx M (x, tk)eλkZ(x,tk)P (x, tk; µ−
k )

1
(λk; µ−
W
µ+
k .

k , tk) Z

≈

The ﬁrst area rule (II.19) is just an integral form of this latter relation (II.27). Likewise, if we

Diﬀerentiating once and using again (II.24) thus gives

∂µ+
k
∂λk

(λk; µ−

k , tk) = C Z (µ+

k , tk).

deﬁne

(∆F )k(λk; µ−

k , tk) := log

(λk; µ−

k , tk),

W

then we see by applying (II.24) twice again that

∂(∆F )k
∂λk

(λk; µ−

k , tk) = ζ(µ+

k , tk).

The second area rule (II.23) is likewise the integral form of (II.29). Note from (II.28) that all

of the dependence of (∆F )k upon λ1, ..., λk−1 is through µ−

k , analogous to (I.75). The cost

function HZ(z1, ..., zn) is ﬁnally deﬁned as the Legendre dual of FZ (λ1, ..., λn) given by (II.22).

42

(II.24)

(II.25)

(II.26)

(II.27)

(II.28)

(II.29)

The jump conditions (II.19),(II.21) may be used very much as the exact ones (I.61),(I.62) for

the purposes of estimation with discrete-time data and of ensemble variance calculation. Only

the Rayleigh-Ritz approximations of the cost functions need be substituted for the exact ones

in the algorithms described earlier. In calculating the Legendre dual HZ (z1, ..., zn) the adjoint

equation is used to evaluate zk = ζ ±

k + C Z±
same result as direct diﬀerentiation zk = ∂FZ
∂λk

k α±

k . Of course, one should check that this gives the

. This is true but we shall not give the proof here,

because we prove a very similar result in the Appendix 2. The proof is based upon the easily

established relations

∂µ+
k
∂µ−
k

=

C Z+
C Z− ,

∂(∆F )k
∂µ−
k

=

ζ −
ζ +
k
k −
C Z− .

Of course, the adjoint equation need not be employed at all, but it is a convenient way of

evaluating the required derivative.

Substantial simpliﬁcations in the jump conditions occur in the important special case where

Z = M . In that case ζ(µ, t) = µ, C Z (µ, t) = C(µ, t). We can then deﬁne a function

where µ(t) is the solution of the unperturbed moment equation. If µ(λ, t) is the inverse function,

then we can also deﬁne

It follows by our deﬁnitions that

Also, using (II.33) we note that

λ(µ, t) :=

µ

µ(t)

Z

d¯µ
C(¯µ, t)

F (λ, t) :=

µ(¯λ, t) d¯λ.

λ

0
Z

F ′(λ, t) = µ, F ′′(λ, t) = C.

λ(µ+

k , tk)

λ(µ−

k , tk) = λk.

−

(∆F )k =

µ+
k

−
µ
k

Z

µ dµ
dµ
dλ

(cid:16)

(cid:17)

43

In terms of the function λ(µ, t) the ﬁrst area rule (II.19) becomes

(II.30)

(II.31)

(II.32)

(II.33)

(II.34)

λ+
k

=

−
λ
Z
k
= F (λ+

µ(λ) dλ

k , tk)

−

F (λ−

k , tk).

(II.35)

Hence, the “area rules” are replaced by equations involving discontinuities of explicit functions,

always assuming, of course, that integrals deﬁning the functions in (II.31),(II.32) may be evalu-

ated. The key to this simpliﬁcation was the relations in (II.33), which imply that F is a convex

“potential” generating the ﬁrst and second moments of the PDF Ansatz. Such a potential will

always exist for functions of one variable, but not in general for multivariate functions.

II.3. Exponential PDF Closures

We have seen above that, for a general closure, there is a satisfactory treatment of estimation

with discrete-time data only for the case where there is both a single measured variable Z(t)

and a single closure variable M (t). Obviously, this is an extreme limitation. However, it may

be possible to circumvent this severe restriction within special classes of closures. In fact, as we

show now, closures constructed with an exponential PDF Ansatz have better properties. We

shall see that they guarantee continuity of optimal estimators. Furthermore, they provide very

simple “jump-conditions” for estimation with discrete-time data.

Exponential PDF closures are one example of the general class considered in [27]. Hence,

we shall only make a quick summary of the properties required here and refer the interested

reader to the paper [27] for more details. Most concretely, the class of closures we consider are

those built from a PDF Ansatz of the exponential form:

with

(x, t; λ) =

P

exp(λ⊤M(x, t))
(λ, t)

P∗(x, t)

N

(λ, t) :=

dx exp(λ⊤M(x, t))

P∗(x, t).

N

Z

(II.36)

(II.37)

Here

P∗(x, t) is a reference PDF. To guarantee some of the good properties of the closure
discussed in [27], the reference PDF must be a solution (or approximate solution) of the Fokker-

Planck equation. However, for the properties discussed here,

P∗(t) may be an arbitrary PDF.

44

The exponential family in (II.36) is parameterized by the “potential” variables λ, rather than

by the moments µ of the closure variables M(x, t). However, there are simple relationships

between these quantities. We may deﬁne

F (λ, t) := log

(λ, t),

N

(II.38)

(II.39)

which is a cumulant-generating function for the variables M(t) in the PDF Ansatz. Likewise,

its Legendre transform

n
is a generating function for irreducible correlation functions of M(t). It is the relative entropy

o

H(µ, t) := max

µ⊤λ

F (λ, t)

λ

−

for the PDF Ansatz in (II.36) with respect to the reference PDF P∗(t). Under some conditions

discussed in [27], it satisﬁes an H-theorem for the closure dynamics constructed with the Ansatz.

However, the role of F, H as generating functions will be more important for us here. Thus,

µ = ∂F

∂λ and conversely λ = ∂H

matrix C of M and that ∂C

∂µ . It is a consequence of the former that ∂µ

∂λ is the covariance
∂λ is the 3rd-order cumulant. These relationships will prove to be

important in the following.

We shall now show that, for the exponential PDF closures, the history z(t) is continuous

even for h(t) consisting of delta-function spikes, when the variables Z(t) are among the closure

variables M(t) themselves. This last condition places some restriction, but a fairly modest and

natural one. Without any loss of generality, we can consider Z(t) to consist of the entire set

of closure variables M(t). As before, some of our previous formulas then simplify considerably.

For example, ζ(µ, t) = µ and CZ(µ, t) = C(µ, t), the usual M M -covariance matrix. Then

(II.4) is replaced by

m(t) = µ(t) + C(µ(t), t)α(t).

(II.40)

The time-derivative of the latter, given in general in (II.17), also simpliﬁes. In fact, the term

in the bracket in the second line becomes

Cba(µ, t)

Cab(µ, t) = 0

(II.41)

−

45

(II.42)

(II.43)

(II.44)

which vanishes by the symmetry of the covariance matrix. The term in the bracket in the third

line of (II.17) becomes

where Cabc(µ, t) is the 3rd-order cumulant of M(t). Indeed,

Cajb(µ, t)

Cbja(µ, t) = 0

−

∂Caj
∂µi

=

∂Caj
∂λk

∂λk
∂µi

= CajkΓki.

Since the irreducible 2nd correlator is the inverse covariance matrix, Γ = C−1, the expression in

(II.42) follows from the corresponding expression in (II.17). However, it is obvious that (II.42)

vanishes, by the symmetry of the 3rd-order cumulant. Putting together all of these results, we

have

dm
dt

(t) = V(µ, t) +

d
dt

"

∂µ
∂λ

(cid:18)

⊤

α.

∂V
∂λ

(cid:19) − (cid:18)

#

(cid:19)

This should be compared with the exact expression (I.77). Just as there, we see that the terms

directly involving h(t) all cancel. Hence, m(t) remains continuous even with h(t) containing

delta-function spikes.

We shall ﬁnally show that the exponential PDF closures also permit the formulation of

simple jump conditions at the times tk where the delta functions occur. This should not be too

surprising, when one considers that the exact jump conditions in (I.61),(I.62) consist simply of

suitable exponential modiﬁcations of the solutions of the foward, backward equations. To derive

the jump conditions in the closure, we use a strategy motivated by that in section II.2. In fact,
observe by C = ∂µ
∂λ and the chain rule that ˙µ = C(λ) ˙λ. Thus, if one deﬁnes W(λ) := Γ(µ)V(µ)
and γ := C(λ)α, then in terms of the new variables γ, λ, the nonequilibrium action, including

the constraint term with the Lagrange multiplier, becomes

Γ[γ, λ] =

dt

γ⊤[ ˙λ

W(λ)] + h⊤(t)[m(t)

(II.45)

µ(λ)

γ]

.

−

−

o

tf

ti

Z

−

n

The Euler-Lagrange equations in terms of these variables become

˙λ = W(λ, t) + h(t),

(II.46)

46

˙γ +

⊤

∂W
∂λ

(cid:18)

(cid:19)

(λ, t)γ + C(λ, t)h(t) = 0,

(II.47)

and the constraint equation

m(t) = µ(λ, t) + γ.

In the ﬁrst equation (II.46) we may integrate across the spike λkδ(t

tk) in h(t) to obtain

−

λ(µ+

k , tk)

λ(µ−

k , tk) = λk.

−

These are the forward jump conditions. As should not be unexpected, the potential λ(µ, t) is

simply incremented by λk at the spike. A similar result can be obtained by integrating the

backward closure equation (II.47) across the spike. However, it is simpler to use the continuity

of m(t) at the jump, which was established above. Then from (II.48) one immediately derives

k = (µ+
γ−

k ) + γ+
µ−
k .

k −

(II.50)

These are the backward jump conditions.

The multi-time cumulant-generating function F (λ1, ..., λn) can be obtained from (I.73) with

the observation that

(tf ) =

N

and thus (I.74) holds with

n
k=1

N (λ+
N (λ−

k ,tk)
k ,tk)

Q

(∆F )k(λ1, ..., λk) = F (λ+

F (λ−

k , tk)

k , tk)

−
k + λk, tk)

F (λ−

k , tk),

−

= F (λ−

generalizing (II.35). Then the multi-time entropy H(m1, ..., mn) is obtained by the Legendre

H(m1, ..., mn) =

m⊤

k λk −

F (λ1, ..., λk).

n

Xk=1

with mk given by (II.40), mk = m(tk), for t = tk, k = 1, ..., n. Of course, it must be shown

transform

that

(II.48)

(II.49)

(II.51)

(II.52)

(II.53)

for all k = 1, ..., n in order for (II.52) to be valid. Cf. equation (I.57). The proof is somewhat

technical, so it is given in the Appendix 2.

mk =

∂F
∂λk

47

While the previous approximation has a rather elegant and tractable formulation, there

is nevertheless also an unpleasant asymmetry between forward and backward time directions.

Thus, information propagates forward in time via the nonlinear closure equation (II.46), but

information propagates backward in time via the equation (II.47) which is linear in the adjoint

variable γ. Ultimately, this asymmetry is due to our employment of a nonlinear (exponen-

tial) Ansatz (II.36) for the PDF, while the solution of the backward equation is taken to be

of the linear form (II.1). However, there is nothing in the Rayleigh-Ritz method which re-

quires the use of the linear Ansatz (II.1) for the left trial state. In fact, that expression has

other unpleasant features. The exact backward Euler-Lagrange equation (I.24) is known to be

positivity-preserving, so that the solution

(x, t) starting from ﬁnal data

(t)

1 must be

everywhere nonnegative. However, the linear Ansatz

(x, t) = 1 +

A

A

A
R
i=1 αi(t)[Mi(x, t)

≡

µi(t)]

−

may easily become negative, if the adjoint variables α become large enough in magnitude. It is

P

therefore desirable to consider more general Ans¨atze for the left trial state than the linear one.

Within the context of exponential PDF closures a particularly symmetric and attractive

choice is to make the double exponential Ansatz:

(x, t) = exp

P

β⊤M(x, t)
h

−

F (β, t)
i

P∗(x, t)

for the right trial state and

(x, t) = exp

A

α⊤M(x, t)
h

−

(∆αF )(β, t)
i

for the left trial state. Here (∆αF )(β, t) := F (α + β, t)

F (β, t) so that the normalization

−

constraint <

(t),

(t) >= 1 is automatically satisﬁed. It is then clear that, for small α, (II.55)

A

P

coincides with the linear Ansatz. (Note that (∆αF )(β, t) = α⊤µ(β, t) + O(α2).) However, this

new Ansatz is globally nonnegative and symmetric in form to the exponential for the right

trial state. An even more attractive feature of this double exponential Ansatz is that, within

it, the Rayleigh-Ritz eﬀective action of the closure variables M themselves may be calculated

(II.54)

(II.55)

48

analytically in closed form. The result is:

Γ[m] =

dt [ ˙m(t)

V(m, t)]⊤Q−1(m, t)[ ˙m(t)

V(m, t)],

(II.56)

−

−

tf

1
4

ti

Z

where

Qij(m, t) :=

(∇xMi)⊤D(∇xMj)
h

iλ(m,t).

(II.57)

This eﬀective action has precisely the Onsager-Machlup form. The statement generalizes a

previous result in [12], for general closures, that the Rayleigh-Ritz eﬀective action has the

Onsager-Machlup form to quadratic order. Let us just brieﬂy sketch the derivation, which will

be given in detail elsewhere [29], along with a complete discussion of its remarkable properties.

It is a straightforward calculation to show that

(∂t+ ˆL∗)

(x, t) =

A

˙α⊤M(x, t) + α⊤ ˙M(x, t) + ∇x(α⊤M)·D·∇x(α⊤M)
n

−

∆α ˙F (β, t)
o

(x, t).

A
(II.58)

In that case

< (∂t + ˆL∗)

(t),

(t) >= ˙α⊤µ(λ, t) + α⊤V(λ, t) + α⊤Q(λ, t)α

∆α ˙F (β, t),

(II.59)

A

P

−

where λ := α + β. However, it is easy to see that the second constraint on the mean values

becomes in these variables m(t) =<

(t), M(t)

(t) >= µ(λ, t). Thus, holding the history m(t)

P
ﬁxed is equivalent to holding λ(t) ﬁxed. We cannot vary independently over α(t) and β(t),

A

but one is determined from the other via the relation λ(t) = α(t) + β(t). Since, for ﬁxed m(t),

(II.59) implies that

Γ[α, β] =

tf

dt

ti

Z

α⊤[ ˙m
n

−

V(m, t)]

α⊤Q(m, t)α

,

−

o

(II.60)

maximizing over α yields (II.56).

Although the Onsager-Machlup form (II.56) is most interesting for theory, practical estima-

tion is easier with the latter expression (II.60). Including the cost function for the observations,

the total action to be minimized is

Γ∗[α, m] =

dt

α⊤[ ˙m

V(m, t)]

α⊤Q(m, t)α

+

−

−

[m(tk)

rk]⊤R−1

k [m(tk)

−

tf

ti

Z

n

rk].

−
(II.61)

n

1
2

o

Xk=1

49

The Euler-Lagrange equations of this problem are

˙m = V(m, t) + 2Q(m, t)α,

(II.62)

˙α +

α⊤Qα
(cid:17)
Solving these equations with boundary values m(ti) = m0 and α(tf ) = 0 can give directly

k [m(tk)

rk]δ(t

(II.63)

α +

Xk=1

R−1

tk).

−

−

=

(cid:18)

(cid:19)

(cid:16)

⊤

∂V
∂m

∂
∂m

n

the optimal history, without the need of applying any explicit minimization algorithm. It is

transparent in this formulation that the optimal history m∗(t) is continuous at the observation

times, because the ﬁrst equation (II.52) contains no delta-functions in time. Only the adjoint

variables α(t) suﬀer jumps at the measurement times t = tk.

The same circle of ideas may be applied to constructing closures of the KSP equations for

the optimal history itself, rather than just the variational approximation. In fact, assume that

the closure variables M consist of the measured variables Z and their tensor products Z

Z,

⊗

M := (Z, Z

Z), with mean values given by m = (ζ, Σ) for a double exponential Ansatz.

⊗

Let the exponential parameters in the left trial state then be denoted as (α, A) and those in

the right trial state as (β, B). Because the states evolve by the (unperturbed) forward and

backward Kolmogorov equations between measurements, the Euler-Lagrange equations within

the closure are of the same form as those in (II.62),(II.63). As there, there are no jumps at

measurement times in the equations for m = (ζ, Σ). On the other hand, there are simple jump

conditions for the adjoint variables (α, A), which may be read oﬀ directly from (A.3),(A.9):

α−

k = α+

k + R−1

k rk,

A−

k = A+

k −

1
2

R−1
k ,

(II.64)

(II.65)

for k = 1, ..., n. Further details, including the formulation for continuous-time observation, will

be given elsewhere. We only note here that there is a price to be paid for constructing a closure

of the KSP equation: the necessity of including among the closure variables the squares of the

observed variables in addition to those variables themselves.

50

III Conclusion

This paper is intended to serve as a primer and technical reference for the application of the

proposed variational estimation scheme to concrete problems. We have discussed the meaning of

the variational estimator within ensemble theory and emphasized its character as a “mean-ﬁeld

approximation” to the optimal estimator. Neither the variational method nor the optimal KSP

method can be directly applied in practice to complex, high-dimensional systems. An action

functional can be used to construct Rayleigh-Ritz or moment-closure approximations of both

the variational and KSP estimators, but the variational scheme has the advantage of requiring

simpler, lower order closures. We have discussed a number of special closure schemes, based in

particular upon exponential Ans¨atze, that preserve good properties of the exact estimators. We

have discussed also the numerical implementation of the variational estimation scheme, both

exactly and within a Rayleigh-Ritz approximation, both to obtain the estimator itself and also

to approximate the variance or ensemble dispersion. Most of the algorithms discussed here have

already been implemented in [30] and in our forthcoming work [31].

In addition to providing a practical estimation scheme, we hope that the variational frame-

work will provide also some additional physical insight into the complex stochastic systems to

which it is applied. It exploits a thermodynamic formalism for far from equilibrium systems

and provides a motivation to understand better the concepts of action and entropy in concrete

physical systems, e.g. atmospheres, oceans, ecosystems, living organisms, etc.

Acknowledgements. The author wishes to thank F. Alexander, M. Anitescu, C. E. Leith, C.

D. Levermore and J. Restrepo for valuable conversations and suggestions which contributed to

this work. He thanks the Isaac Newton Institute for its hospitality during his stay there for the

1999 Turbulence Programme, when part of this work was done. This paper was prepared as

Los Alamos report LA-UR00-5264 and supported by the DOE grant LDRD - ER 2000047.

51

A Appendices

Appendix 1: Optimal Estimation with Discrete-Time Data

We give here a simple derivation of the Kushner-Stratonovich-Pardoux equations for estimation

with data taken at a discrete set of times tk, k = 1, ..., n. The problem set-up is the same as

described in Section I.5. We deﬁne

≥
is right-continuous in time. It is then clear that between measurement times,

P

P∗(x, t) :=

(x, t

r1, ..., rk) for tk+1 > t
|

tk, so that

P∗(t)
P∗(t) evolves by

the forward Kolmogorov equation (I.16). At measurement times,

P∗(x, tk+) =

P∗(x, tk − |

Z(tk) + ρk = rk)

(A.1)

for k = 1, ..., n. Thus, by Bayes’ rule,

P∗(x, tk+) = P∗(Z(tk) + ρk = rk|
P∗(Z(tk) + ρk = rk|
By our assumptions, ρk is a normal random variable of mean 0 and covariance Rk, independent

P∗(x, tk−
)
)
P∗(y, tk−
y, tk−
)

x, tk−

(A.2)

dy

R

)

.

of the process X(t). Hence, if Z, ρ are s-dimensional

P∗(Z(tk) + ρk = rk|

x, tk−

) =

1
(2π)sDet Rk

exp

1
2

(cid:20)−

(Z(x, tk)

rk)⊤ R−1

k (Z(x, tk)

−

−

.

rk)
(cid:21)
(A.3)

The term

1
√(2π)sDet Rk

exp

p
k R−1
1
2 r⊤

k rk

i

−
h

in (A.2). Hence we obtain ﬁnally the forward “jump condition”

may be cancelled between numerator and denominator

P∗(x, tk+) =

exp

k R−1
r⊤
k
h

Z(x, tk)

1
2

Z⊤(x, tk)R−1
k

−
(r1, ..., rk)

W

Z(x, tk)
i

P∗(x, tk−

)

(A.4)

with the normalization factor

Next, we deﬁne for tk−1 < t

tk,

(cid:20)

≤

(r1, ..., rk) :=

dy exp

k R−1
r⊤
k

Z(y, tk)

Z ⊤(y, tk)R−1
k

Z(y, tk)

W

Z

(cid:21) P∗(y, tk−

).

(A.5)

A∗(x, t) := P

(x, t

r1, ..., rn)
|
P∗(x, t)

(x, t
(x, t

r1, ..., rn)
|
r1, ..., rk−1)
|

= P
P

(A.6)

1
2

−

52

and for t > tn.

Writing this deﬁnition as

A∗(x, t) := 1

(A.7)

(A.8)

(A.12)

(A.13)

A∗(x, t) := P
P

r1, ..., rn)
(x, t
|
r1, ..., rk) ·
(x, t
|

(x, t
P
(x, t
P

r1, ..., rk)
|
r1, ..., rk−1)
|

and using the already derived condition (A.4), we obtain for t

A∗(x, tk−

) =

A∗(x, tk+)

h

exp

k R−1
r⊤
k

Z(x, tk)

that

→

tk−
Z ⊤(x, tk)R−1
k

1
2

−
(r1, ..., rk)

W

Z(x, tk)
i

.

(A.9)

This is the backward “jump condition”.

It remains only to show that

A∗(x, t) deﬁned via (A.6) satisﬁes the backward Kolmogorov

equation (I.17) between measurements. We apply again Bayes’ rule, in the form

(x, t

r1, ..., rn) = P
|

P

(rk, ..., rn|
P

x, t; r1, ..., rk−1)
(rk, ..., rn|

r1, ..., rk−1)
(x, t
P
|
r1, ..., rk−1)

.

(A.10)

However, by the Markov property,

(rk, ..., rn|

P

x, t; r1, ..., rk−1) =

x, t)

(rk, ..., rn|
dyk P

P

Z

=

(rk, ..., rn|

yk, tk)

(yk, tk|

P

x, t)

(A.11)

when tk−1 < t

tk. Putting together (A.6),(A.10),(A.11), we conclude that

≤

A∗(x, t) =

dyk

Z

(rk, ..., rn|

P
(rk, ..., rn|

yk, tk)
r1, ..., rk−1) P

P

(yk, tk|

x, t).

Since the transition probability satisﬁes the backward equation in the variables x, t

(∂t + ˆL∗)

(yk, tk|

P

x, t) = 0,

it then immediately follows from the integral representation (A.12) that

A∗(t) satisﬁes (I.17)

for tk−1 < t < tk, k = 1, ..., n.

It is not hard to show that the jump conditions above, (A.4),(A.9), are equivalent to those

given in the text, (I.80),(I.81). One simply multiplies the numerators and denominators in

(A.4),(A.9) by the factor exp

−
h
nents by completing the square.

1
2 h

tk−R−1
⊤
Z(tk)
k h
i

Z(tk)

itk−

i

and rearranges terms in the expo-

53

This is an appropriate place to discuss the close formal resemblance of the KSP jump condi-

tions, (I.80),(I.81), to the jump conditions, (I.61),(I.62), employed in calculating the multitime

entropy HZ (or, more correctly, its Legendre dual FZ .) In fact, the exponential PDF Ansatz

(II.36) has also an interpretation as a conditional PDF. The conditioning is now upon the event

that the empirical average ZN = z in the limit as N

:

→ ∞

N→∞ P∗(x, t
lim

ZN (t) = z) =
|

exp(λ⊤Z(x, t))
(λ, t)

P∗(x, t)

N

(A.14)

with λ = λ(z, t). More precisely, the result is that limN→∞ P

⊗N
∗

(x1, .., xN , t

ZN (t) = z) =
|

N
i=1

i=1 P∗(xi, t) is
Q
Q
taken, to correspond to an ensemble of N independently prepared samples. Convergence to

P∗(xi, t). Here the product measure

(x1, .., xN ; t) =

⊗N
∗
P

N

exp(λ⊤Z (xi,t))
N (λ,t)

the new product measure holds for any ﬁnite-dimensional marginals (i.e. for i

S, any ﬁnite

∈

set, as N

). Statistical physicists will recognize this as an equivalence of ensembles result,

→ ∞

in which the “microcanonical ensemble” corresponding to the condition ZN (t) = z becomes

equivalent in the thermodynamic limit to the “canonical ensemble” with potential λ(z, t).

As a consequence of this, we may interpret the solution

P∗(x, t) of the forward equation,

with the jump conditions (I.61) at measurement times less than t, as

P∗(x, t) =

P

(x, t

z1, ..., zk),
|

tk+1 > t

tk,

≥

(A.15)

where the righthand side is shorthand for the PDF conditioned upon the event ZN (t1) = z1, ...,

ZN (tk) = zk in the limit N

. Likewise,

→ ∞

A∗(x, t)

P∗(x, t) =

P

(x, t

z1, ..., zn),
|

(A.16)

where the conditioning is now upon ZN (ti) = zi for the full set of times ti, i = 1, ..., n, both

those before and after the time t. The proof of this assertion is exactly the same as for the

corresponding results proved earlier in this appendix regarding PDF’s conditioned upon obser-

vations r1, ..., rn. This relation to conditional PDF’s helps to explain the close similarity to the

KSP formalism. Note, however, that this is the wrong set of conditions to use for estimation,

as it is upon ZN itself and not upon (empirical means of) observations rN = ZN + ρN .

54

Appendix 2: Adjoint Calculation of a Derivative

For completeness, we shall give a direct proof of (II.53) here. We ﬁrst observe by (I.74) and

causality that

while

Then we note from (II.51) that

∂F
∂λk

=

n

Xl=k

∂(∆F )l
∂λk

.

∂(∆F )k
∂λk

= µ+
k

∂(∆F )k
∂λ−
k

= µ+

k −

µ−
k .

Thus, by (A.17),(A.18) and the chain rule

Furthermore, by (A.19) and the chain rule,

∂F
∂λk

= µ+

k +

n

∂(∆F )l
∂µ−
l

∂µ−
l
∂λk

.

Xl=k+1

∂(∆F )l
∂µ−
l

=

∂(∆F )l
∂λ−
l

∂λ−
l
∂µ−
l
l ]⊤Γ−
µ−
l .

= [µ+

l −

∂µ−
l
∂λk

∂t

∂µ(t)
∂λk

= A(t)

∂µ(t)
∂λk

,

= C+
k

∂µ(t)
∂λk (cid:12)
(cid:12)
(cid:12)
(cid:12)
k + λk) whence

t=tk+

∂µ+
k
∂λk

∂µ+
l
∂µ−
l

=

∂µ+
l
∂λ−
l

∂λ−
l
∂µ−
l

= C+

l Γ−
l .

55

Therefore, it only remains in (A.20) to evaluate

for l > k. The Jacobian matrix for

arbitrary times t

= tl, l > k satisﬁes the linearized equation

where A(t) := ∂V

∂µ (µ(t), t). The initial condition

is provided by the formula µ+

k = µ(λ−

= C+

k . At the measurement times

t = tl, l > k there is an additional multiplicative factor, which follows from the Jacobian

(A.17)

(A.18)

(A.19)

(A.20)

(A.21)

(A.22)

(A.23)

(A.24)

6
The solution for tl > t > tl−1, l > k, is

∂µ(t)
∂λk

= T exp

A(s) ds

t

"Z

tl−1

l−1

# 


Yj=k+1

C+

j Γ−
j ·

T exp

tj

"Z

tj−1

A(s) ds

C+
k .

#


(A.25)

Here T exp denotes the time-ordered exponential with matrices at increasing times to the left,





and likewise Π is the time-ordered product in the same sense. Thus, the ﬁnal result

∂µ−
l
∂λk

= T exp

A(s) ds

tl

"Z

tl−1

C+

j Γ−
j ·

T exp

tj

tj−1

"Z

A(s) ds

C+
k

(A.26)

l−1

Yj=k+1

# 




#




follows upon setting t = tl−

.

This may be compared with the solution of the adjoint equation

∂tα(t) + A∗(t)α(t) = 0

(A.27)

integrated backward in time for t

= tl and subject to the jump conditions (II.50) at t = tl, l =

1, ..., n. The explicit solution for tk < t < tk+1 is

α(t) =

T exp

tk+1

A∗(s) ds

n

Xl=k+1

t

(cid:20)Z

k+2

j=l

j−1C+
Γ−

j−1 ·

T exp

tj

tj−1

"Z

(cid:21) (

Y

A∗(s) ds

l [µ+
Γ−

l −

µ−
l ].

#)

(A.28)

Now T exp denotes anti-time-ordered exponential with matrices at decreasing times to the left,

and Π is the anti-time-ordered product. Setting t = tk+ and regrouping terms gives

n

α+

k =

Xl=k+1 (

Y

k+1

j=l−1

T exp

tj−1

"Z
tj

A∗(s) ds

j C+
Γ−
j

T exp

# ·

)

"Z

tl−1

A∗(s) ds

l [µ+
Γ−

l −

µ−
l ].

#

tl

Finally, substituting (A.21),(A.26) into (A.20), and using (A.29), gives

∂F
∂λk

= µ+

k +

⊤

α+
k
(cid:16)

(cid:17)

C+

k = mk,

which is exactly the result required.

(A.29)

(A.30)

56

6
References

[1] A. Gelb, ed., Applied Optimal Estimation. (MIT Press, Cambridge, MA, 1974).

[2] R. L. Stratonovich, “Conditional Markov processes,” Theor. Prob. Appl. 5: 156-178 (1960).

[3] H. J. Kushner, “On the diﬀerential equations satisﬁed by conditional probability densities

of Markov processes, with applications,” J. SIAM Control, Ser.A 2: 106-119 (1962).

[4] H. J. Kushner, “Dynamical equations for optimal nonlinear ﬁltering,” J. Diﬀ. Eq. 3: 179-

190 (1967).

[5] H. J. Kushner, Probability Methods for Approximations in Stochastic Control and for El-

liptic Equations. (Academic Press, New York, 1977).

[6] E. Pardoux, “´Equations du ﬁltrage non lin´eaire de la pr´ediction et du lissage,” Stochastics

6: 193-231 (1982).

Basic Eng. 83, Ser.D: 95-108 (1961).

[7] R. E. Kalman and R. S. Bucy, “New results in linear ﬁltering and prediction theory,” J.

[8] J. S. Meditch, “On state estimation for distributed parameter systems,” J. Franklin Inst.

[9] H. J. Kushner, “Approximation to optimal nonlinear ﬁlters,” IEEE Trans. Auto. Contr.

[10] D. Brigo, B. Hanzon, and F. LeGland, “A diﬀerential geometric approach to nonlinear

ﬁltering: the projection ﬁlter,” IEEE Trans. Auto. Contr. 43 247-252 (1998).

[11] G. L. Eyink, “Action principle in nonequilibrium statistical dynamics,” Phys. Rev. E 54:

[12] G. L. Eyink, “Linear stochastic models of nonlinear dynamical systems,” Phys. Rev. E 58:

290: 49-59 (1970).

12 546-556 (1967).

3419-3435 (1996).

6975-6991 (1998).

57

[13] G. L. Eyink, “Fluctuation-response relations for multi-time correlations,” Phys. Rev. E

62: 210-220 (2000).

1505-1512 (1953).

[14] L. Onsager and S. Machlup, “Fluctuations and irreversible processes,” Phys. Rev. 91:

[15] R. Graham, “Path integral methods in nonequilibrium thermodynamics and statistics,” in:

Stochastic Processes in Nonequilibrium Systems, L. Garrido, P. Seglar, and P. J. Shepherd,

eds., Lecture Notes in Physics, vol.84 (Springer-Verlag, Berlin, 1978).

[16] M. I. Freidlin and A. D. Wentzell, Random Perturbations of Dynamical Systems. (Springer-

Verlag, New York, 1984).

[17] C. Itzykson and J.-B. Zuber, Quantum Field Theory (McGraw Hill, New York, 1985).

[18] H. Cram´er, “Sur un noveaux theor`eme-limite de la theorie des probabilit´es,” Actualit´es

Scientiﬁques et Industrielles, 736: 5-23 (1938).

[19] R. R. Bhahadur and S. L. Zabell, “Large deviations of the sample mean in general vector

spaces,” Ann. Prob. 7 587-621 (1979).

[20] S. R. S. Varadhan, Large Deviations and Applications. (SIAM, Philadelphia, 1984).

[21] C. E. Leith, “Theoretical skill of Monte Carlo forecasts,” Mon. Wea. Rev. 102 409-418

(1974).

[22] G. Burgers, P. J. van Leeuwen, and G. Evensen, “Analysis schemes in the ensemble Kalman

ﬁlter,” Mon. Wea. Rev. 126 1719-1724 (1998).

[23] J. Nocedal and S. J. Wright, Numerical Optimization. Springer Series in Optimization

Research. (Springer, New York, 1999).

[24] S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi, “Optimization by simulated annealing,”

Science 220: 671-680 (1983).

58

[25] S. Kirkpatrick, “Optimization by simulated annealing: quantitative studies,” J. Stat. Phys.

[26] M. Zakai, “On the optimal ﬁltering of diﬀusion processes,” Z. Wahrscheinlichkeitstheorie

34: 975-986 (1984).

verw. Geb. 11 230-243 (1969).

in preparation.

1021-1065 (1996).

[27] G. Eyink and C. D. Levermore, “Entropy-based closure of nonlinear stochastic dynamics,”

[28] C. D. Levermore, “Moment closure hierarchies for kinetic theories,” J. Stat. Phys. 83

[29] G. Eyink, “Rayleigh-Ritz eﬀective action in a double exponential Ansatz,” in preparation.

[30] G. Eyink and J. M. Restrepo, “Most probable histories for nonlinear dynamics: tracking

climate transitions,” J. Stat. Phys., to appear.

[31] G. Eyink and J. M. Restrepo, “Optimal variational assimilation in strongly nonlinear

dynamical systems,” in preparation.

59

