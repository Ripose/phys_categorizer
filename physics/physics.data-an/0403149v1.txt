4
0
0
2
 
r
a

M
 
1
3
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
9
4
1
3
0
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A Hidden Markov model for Bayesian data fusion of
multivariate signals

Olivier F´eron and Ali Mohammad-Djafari

Laboratoire des Signaux et Syst`emes,
Unit´e mixte de recherche 8506 (CNRS-Sup´elec-UPS)
Sup´elec, Plateau de Moulon, 91192 Gif-sur-Yvette, France

emails = feron@lss.supelec.fr

djafari@lss.supelec.fr

Abstract

In this work we propose a Bayesian framework for data fusion of multivariate
signals which arises in imaging systems. More speciﬁcally, we consider the case
where we have observed two images of the same object through two diﬀerent
imaging processes. The objective of this work is then to propose a coherent
approach to combine these data sets to obtain a segmented image which can
be considered as the fusion result of these two images.
The proposed approach is based on a Hidden Markov Modeling (HMM) of
the images with common segmentation, or equivalently, with common hidden
classiﬁcation label variables which is modeled by the Potts Markov Random
Field. We propose then an appropriate Markov Chain Monte Carlo (MCMC)
algorithm to implement the method and show some simulation results and ap-
plications.

key words :
Data fusion, Classiﬁcation and segmentation of Images, HMM, MCMC, Gibbs
Algorithm.

1 Introduction

Data fusion and multi-source information has become a very active area of research
in many domains :
industrial nondestructive testing and evaluation ([1]), medical
imaging [2, 3, 4], industrial inspection ([5])(quality control and condition monitoring)
and security systems in general.
In all these areas, the main problem is how to combine the information contents of
diﬀerent sets of multivariate data gi(r). When the data set gi(r) is an image we have

1

r ∈ R2, and the problem becomes how to combine and represent their fusion. Very
often the data sets gi do not represent the same quantities. For example in medical
imaging we have 2D radiographic data g1 and echographical data g2 which are related
to diﬀerent properties f1 and f2 of the body under examination by

gi(r) = [Hifi](r) + εi(r)

(1)

where Hi are the operator functionnal of the measuring systems. We may note that
estimating fi given each set of data gi is an inverse problem by itself which is often
an ill-posed problem even if we may know perfectly the operator Hi. So very often
people use the two data sets separately to obtain two images f1 and f2 and then they
try to make a data fusion. We think it is possible to do a better job if we deﬁne
more precisely what we mean by data fusion of two images f1 and f2 and if we try to
use the data g1 and g2 to estimate directly not only f1 and f2 but also the common
feature of them which we present by a third image z.

20

40

60

80

100

120

140

20

40

60

80

100

120

140

20

40

60

80

100

120

140

160

180

20

40

60

80

100

120

140

160

180

(a)

(b)

(c)

(d)

Figure 1: Examples of images for data fusion. a,b) Copyright American Science
and Engineering, Inc., 2003 : two observations from transmission and backscattering
X rays, c,d) MRI (Magnetic Resonance Imaging) and CT (Computed Tomography)
images in medical imaging.

In this paper, to show the same ideas, we consider ﬁrst the case where the two
measuring systems can be assumed almost perfect which means that we can write

gi(r) = fi(r) + εi(r),

i = 1, 2

(2)

and we focus on deﬁning what we mean by a common feature z of the two images,
how to model the relation between fi and z and how to estimate f1, f2 and z directly
from the two data sets g1 and g2.
The applications we have in mind in this work are either medical imaging or security
systems imaging. As an example of the two data sets in the ﬁrst application we con-
sider MRI and CT images and as an example of the second application we consider a
transmission and a backscattering diﬀusion images using X rays (see ﬁgure 1).
The rest of the paper is organized as follows : In section 2 we introduce the com-
mon feature z, model the relation between the images fi to it through p(fi|z) and its
proper characteristics through a prior law p(z), and describe the Bayesian approach

2

to estimate f1, f2 and z through the a posteriori law p(f1, f2, z|g1, g2). In section 3 we
give some details on the selection of a priori probability laws p(θ) of the hyperparam-
eters which deﬁne the a posteriori law p(f1, f2, z|g1, g2). In section 4 we give detailed
expressions of the aforementionned a posteriori law and propose general structure of
the MCMC algorithm to estimate f1, f2 and z. Finally, in section 5 we present some
simulation results to show the performances of the proposed method.

2 Modeling for data fusion

In this paper we consider the model (2) where after discretization and using the
notations gi = [gi(1), . . . , gi(S)]T , fi = [fi(1), . . . , fi(S)]T and εi = [εi(1), . . . , εi(S)]T
with S the total number of pixels of the images fi, we have :

gi = fi + εi,

i = 1, 2

(3)

Within this model and assuming Gaussian independant noises, p(εi) = N (0, σ2
we have

εiI),

p(g1, g2|f1, f2) =

p(gi|fi) =

pεi(gi − fi)

2

i=1
Y

2

i=1
Y

As we want to reconstruct an image with statistically homogeneous regions, it is
natural to introduce a hidden variable z = (z(1), . . . , z(S)) ∈ {1, . . . , K}S which
represents a common classiﬁcation of the two images fi. The problem is now to
estimate the set of variables (f1, f2, z) using the Bayesian approach :

p(f1, f2, z|g1, g2) = p(f1, f2|z, g1, g2)p(z|g1, g2)

∝ p(g1|f1, z)p(g2|f2, z)p(f1|z)p(f2|z)p(g1|z)p(g2|z)p(z)

∝ p(z)

p(gi|fi)p(fi|z)p(gi|z)

2

i=1
Y

Thus to be able to give an expression for p(f1, f2, z|g1, g2) we need to deﬁne p(gi|fi),
p(fi|z), p(gi|z) and p(z).
Assuming εi centered, white and Gaussian, we have :

p(gi|fi) = N (fi, σ2

εiI)

S
2

=

1
2πσ2

exp

−

||gi − fi||2

1
2σ2
εi

εi (cid:19)
To assign p(fi|z) we ﬁrst deﬁne the sets of pixels which are in the same class :

(cid:26)

(cid:27)

(cid:18)

Rk = {r : z(r) = k},
fik = {fi(r) : z(r) = k}

|Rk| = nk

3

Then we assume that all the pixels of an image fi which are in the same class will be
characterized by a mean mik and a variance σ2

i k :

With these notations we have :

p(fi(r)|z(r) = k) = N (mik, σ2

i k)

p(fik) = N (mik1, σ2

i kI)

p(fi|z) =

N (mik1, σ2

i kI)

K

k=1
Y
K

=

k=1  
Y

nk

1
2πσ2

i k !

1
2σ2
i k

exp

−

||fik − mik1||2

,

i = 1, 2.

(cid:26)
The next step is to deﬁne p(gi|z). To do this we may use the relation (3) and the
laws p(fi|z) and p(εi) to obtain

p

(cid:27)

p(gi(r)|z(r) = k) = N (mik, σ2

i k + σ2
εi)

=

1

2π(σ2

i k + σ2

εi)

(cid:26)

exp

−

1
i k + σ2

εi)

2(σ2

(gi(r) − mik)2

(cid:27)

q

Finally we have to assign p(z). As we introduced the hidden variable z for ﬁnding
statistically homogeneous regions in images, it is natural to deﬁne a spatial depen-
dance on these labels. The simplest model to account for this desired local spatial
dependancy is a Potts Markov Random Field model :

1
T (α)




p(z) =

exp

α

δ(z(r) − z(s))

,






Xs∈V(r)

r∈S
X
where S is the set of pixels, δ(0) = 1, δ(t) = 0 si t 6= 0, V(r) denotes the neighbor-
hood of the pixel r (here we consider a neighborhood of 4 pixels) and α represents
the degree of the spatial dependance of the variable z. This parameter wxill be stud-
ied in the next section and ﬁxed for our algorithm. We have now all the necessary
prior laws p(gi|fi), p(fi|z), p(gi|z) and p(z) and then we can give an expression for
p(f1, f2, z|g1, g2). However these probability laws have in general unknown parame-
ters such as σ2
i k in p(fi|z). In a full Bayesian approach, we
have to assign prior laws to these ”hyperparameters”. This point is addressed in the
next section.

εi in p(gi|fi) or mik and σ2



3 Spatial dependance parameter of the Potts model

In the Potts Markov Random Field (PMRF) model, the parameter α determines the
spatial dependancy between the pixels. With this model we can expect for controlling

4

the size of the homogeneous regions in images. Indeed, if we take for example α = 0
then we consider the pixels independant, and if we increase the value of α, we increase
the spatial dependancy. In this section we study with simulations how this spatial
dependancy involves with the value of α.

(a) : α = 0.5

(b) α = 0.6

(c) α = 0.65

20

40

60

80

100

120

20

40

60

80

100

120

20

40

60

80

100

120

(d) α = 0.7

(e) α = 1

(f) α = 1.3

20

40

60

80

100

120

20

40

60

80

100

120

20

40

60

80

100

120

20

40

60

80

100

120

20

40

60

80

100

120

20

40

60

80

100

120

20

40

60

80

100

120

20

40

60

80

100

120

20

40

60

80

100

120

Figure 2: Simulations of the PRMF with variation of α

Figure 2 represents some realisations of the PRMF on (128×128) images of 8
labels. We can see easily that the size of the homogeneous regions does not increase
linearly with the value of α. Also the simulations show the existence of a threshold
between 0.6 and 0.7. Under this threshold the simultations of the PMRF remain
strongly disturbed. Beyond this threshold some labels become prevalent and the
homogeneous regions become quickly very large.
The PMRF model is often used in image processing and gives a possibility to control
the size of the homogeneous regions. In our algorithm we will ﬁx the value of α to
1.3 for introducing a strong spatial dependancy between labels.

4 Prior selection of the hyperparameters

There is an extensive litterature on the construction of non informative priors. In
this section we use results from [6] to choose particular priors, taking into account
the restriction of our particular parmetrical model. In [6] the authors used diﬀerential
geometry tools to construct particular priors.
Let mi = (mik)k=1,...,K and σ2
i k)k=1,...,K be the means and the variances of the
pixels in diﬀerent regions of the images fi as deﬁned before. We deﬁne θi as the set
of all the parameters which must be estimated :

i = (σ2

θi = (σ2

εi, mi, σ2

i ),

i = 1, 2

5

We choose the prior distribution of θi of the following form :

π(θ) ∝ e−CDδ (pθ ,p0)

||g(θ)||,

where pθ is the likelihood of θ, p0 is a reference distribution, C is a constant which
represents the conﬁdence degree we have on p0, Dδ is the δ − divergence and g is the
Fisher information matrix.
The authors in ([6]) showed that if we choose this prior distribution for θi with δ = 0,
we ﬁnd the conjugate priors. When applied those results for our case, where these
priors become :

p

- Inverse Gamma IG(αεi

0 , βεi

0 ) and IG(αi0, βi0) respectively for the variances σ2
εi

and σ2

i k,

- Gaussian N (mi0, σ2

i 0) for the means mik.

The hyper-hyperparameters αi0, βi0, mi0 and σ2
general too sensitive to their exact values.

i 0 are ﬁxed and the results are not in

5 a posteriori distributions for the Gibbs algo-

rithm

The Bayesian approach consists now to estimate the whole set of variables (f1, f2, z, θ1, θ2)
following the joint a posteriori distribution p(f1, f2, z, θ1, θ2|g1, g2).
It is diﬃcult
to simulate a joint sample ( ˆf1, ˆf2, ˆz, ˆθ1, ˆθ2) directly from his joint a posteriori dis-
tribution. However we can note that considering the prior laws deﬁned before,
we are able to simulate the conditionnal a posteriori laws p(f1, f2, z|g1, g2, θ1, θ2)
and p(θ1, θ2|g1, g2, f1, f2, z). That’s why we propose a Gibbs algorithm to estimate
( ˆf1, ˆf2, ˆz, ˆθ1, ˆθ2), decomposing this set of variables into two subsets, (f1, f2, z) and
(θ1, θ2). Then the Gibbs algorithm follows : given an initial state ( ˆθ1, ˆθ2)(0),

repeat until convergence

Gibbs sampling

1. simulate ( ˆf1
(n)
2. simulate ˆθi

(n)

(n)

, ˆf2
∼ p(θi|gi, ˆfi

(n)

, ˆz(n))

, ˆz(n)) ∼ p(f1, f2, z|g1, g2, ˆθ1

(n−1)

(n−1)

, ˆθ2

)

We will now deﬁne the conditionnal a posteriori distribution we use for the Gibbs
algorithm.

sampling θi|fi, gi, z :

We have the following relation :

p(θi|fi, gi, z) ∝ p(σ2

εi|fi, gi) p(mi, σ2

i |fi, z)

6

and then we can use the Bayes formula :

p(mi, σ2

i |fi, z) ∝ p(fi|z, mi, σ2

i )p(mi)p(σ2
i )

and

p(σ2

εi|fi, gi) ∝ p(gi|fi, σ2

εi)p(σ2
εi)

Those a posteriori distributions are calculated from the prior selection ﬁxed before
and we have

- mik|fi, z, σ2

i k, mi0, σ2

i 0 ∼ N (µik, v2

i k), with

µik = v2
i k

mi0
σ2
i 0

 

+

1
σ2
i k

−1

r∈Rk
X

fi(r)

!

v2
i k =

nk
σ2
i k

+

1
σ2
i 0 (cid:19)

(cid:18)

- σ2

i k|fi, z, αi0, βi0 ∼ IG(αik, βik), with
nk
2
1
2

βik = βi0 +

αik = αi0 +

- σ2

εi|fi, gi ∼ IG(νi, Σi), with

(fi(r) − mik)2

r∈Rk
X

νi =

+ αεi
0 ,

S = total number of pixels

S
2
1
2

Σi =

||gi − fi||2 + βεi
0

Sampling f1, f2, z|g1, g2, θ1, θ2 :

Using the Bayes formula we have :

p(f1, f2, z|g1, g2, θ1, θ2) = p(f1, f2|z, g1, g2, θ1, θ2)p(z|g1, g2, θ1, θ2)

Then the sampling of this joint distribution is again obtained through a Gibbs sam-
pling scheme and then p(fi|gi, z, θi) by sampling ﬁrst p(z|g1, g2, θ1, θ2). For the ﬁrst
step we have :

and for the next step we have :

p(z|g1, g2, θ1, θ2) ∝ p(g1, g2|z, θ1, θ2)p(z)

= p(g1|z, θ1)p(g2|z, θ2)p(z)

p(fi(r)|gi(r), z(r) = k, θi) = N (mi

apost
k

, σ2
i

apost
k

)

7

where

σ2
i

apost
k

=

mi

apost
k

−1

1
σ2
εi

+

(cid:18)
= σ2
i

apost
k

1
σ2
i k(cid:19)
gi(r)
σ2
εi

(cid:18)

+

mik
σ2
i k(cid:19)

.

As we choosed a Potts Markov Random Field model for the labels, we may note that
an exact sampling of the a posteriori distribution p(z|g1, g2, θ1, θ2) is impossible. In
theory, in each step, we have to implement again a third Gibbs sampling to obtain
exact samples of ˆz. However this will increase signiﬁcantly the complexity of the
algorithm. To obtain a faster algorithm, the solution we propose consists in imple-
menting only one cycle of the Gibbs sampling for z in each iteration. In fact it comes
down to decompose the set of variables into three subsets (θ1, θ2), (f1, f2), and z.
The Gibbs algorithm we propose is then : given an initial state ( ˆθ1, ˆθ2, ˆz)(0),

Gibbs sampling

repeat until convergence
1. simulate ˆz(n) ∼ p(z| ˆz(n−1), g1, g2, ˆθ1
(n−1)

(n)

simulate ˆfi
2. simulate ˆθi

(n)

∼ p(fi|gi, ˆz(n), ˆθi
∼ p(θi| ˆfi

(n)

, ˆz(n), gi)

)

(n−1)

(n−1)

, ˆθ2

)

As we choosed a ﬁrst order neighborhood system for the labels, we may also note
that it is pssible to implement the Gibbs algorithm in parallel. Indeed, we can de-
compose the whole set of pixels into two subsets forming a chessboard (see ﬁgure 2).
In this case if we ﬁx the black (respectively white) labels, then the white (respectively
black) labels become independant.

Figure 3: Chessboard decomposition of the labels z

This decomposition reduces the complexity of the Gibbs algorithm because we can
simulate the whole set of labels in only two steps. The Parallel Gibbs algorithm we
implemented is then the following : given an initial state ( ˆθ1, ˆθ2, ˆz)(0),

black labels

white labels

8

Parallel Gibbs sampling

repeat until convergence
1. simulate ˆzB
simulate ˆzW
simulate ˆfi
2. simulate ˆθi

(n) ∼ p(z| ˆzW
(n) ∼ p(z| ˆzB
(n)

(n)

∼ p(fi|gi, ˆz(n), ˆθi
∼ p(θi| ˆfi

(n)

, ˆz(n), gi)

(n−1), g1, g2, ˆθ1
(n), g1, g2, ˆθ1
(n−1)
)

(n−1)

(n−1)

, ˆθ2
(n−1)

)

)

(n−1)

, ˆθ2

In the following we have implemented this algorithm.

6 Spatial dependance in the estimated images

We want now to introduce a dependance between pixels of fi which are in a same
homogeneous region. Our aim is to improve the reconstructed images and then (be-
cause our algorithm is iterative) improve the quality of our classiﬁcation. We will
now describe this new modelisation and the modiﬁcations it implies.

6.1 New modelisation on the images fi

We now consider that pixels fi(r) inside a same region are dependant. However pixels
being in diﬀerent regions stay independant. We then introduce a ”contour” variable
q as follows :

q(r) = 0 if {z(s), s ∼ r} are in a same region

= 1 else

Then we have the following :

p(fi|z, q, θi) =

p(fik|z, q, θi)

Let note fiN (r) = {fi(s), s ∼ r}. Then we can write :

p(fi(r)|z(r) = k, q(r), fiN (r), θi) = N (µk, σ2

k) if q(r) = 1
σ2
k
4

1tfiN (r),

1
4

= N (

) if q(r) = 0

Note also

mfi(r) = q(r)µk + (1 − q(r))

fi(r) = q(r)σ2
σ2

k + (1 − q(r))

1
1tfiN (r)
4
σ2
k
4

Then we can write the distribution p(gi(r)|z(r) = k, q(r), fiN (r), θi) :
fi(r) + σ2
εi)

p(gi(r)|z(r) = k, q(r), fiN (r), θi) = N (mfi(r), σ2

K

k=1
Y

9

6.2 a posteriori distributions

6.2.1 Sampling fi|gi, z, q, θi

With the same method of section 5, we obtain the a posteriori distribution :

p(fi(r)|gi(r), z(r), q(r), fiN (r), θi) = N (mapost, σ2

apost),

with

mapost = σ2

apost

gi(r)
σ2
εi

+

mfi(r)
σ2
−1

fi(r) !

 

+

σ2
apost =

1
σ2
εi

 

1
σ2

fi(r) !

As we choose a spatial dependance between pixels fi(r), we have the same problem
as for the labels. Indeed an exact sampling of the a posteriori law p(fi|gi, z, q, θi)
becomes impossible. The solution is, as for the labels, to decompose the set of pixels
into a chessboard. Let then note fiW and fiB rspectively the white and black pixels
fi(r). Then if we ﬁx fiW , the pixels fiB(r) are independant and we have

p(fiB|gi, z, q, θi) =

p(fi(r)|gi(r), z(r), q(r), θi)

Yr black

and the symetric relation for fiW .
This solution consists then in introducing a Gibbs algortihm for sampling fi and, as
for the labels, we implement only one cycle of the Gibbs sampling for limiting the
complexity of our algorithm.

6.2.2 Sampling z|g1, g2, f1, f2, q, θ1, θ2

As for the ﬁrst case we use the a posteriori distribution :

p(z|g1, g2, f1, f2, q, θ1, θ2) ∝ p(g1|z, f1, q, θ1)p(g2|z, f2, q, θ2)p(z)

The exact sampling of this distribution is still impossible but we can use the decom-
position into a chessboard to obtain :

p(zB|zW , gN 1, gN 2, fB 1, fB 2, qN , θ1, θ2) ∝ p(zB|zW )

p(gN i|z, fiW , qN , θi)

= p(zB|zW )

p(gi(r)|z(r), fN i(r), q(r), θi)

Then we implement for this part one cycle of a Gibbs sampling, as in the ﬁrst method
described in section 5.

2

i=1
Y
2

i=1
Y

Yr black

10

6.2.3 Sampling θi|z, gi, fi, q

We still use the same method to obtain the a posteriori distributions of the parameters
of θi. However we have here to decompose the set Rk into to subsets as follows :

Rk = R0

k ∪ R1
k

k = {r; z(r) = k, q(r) = i}. Let also note ni

with Ri
we can calculate the a posteriori distributions of θi :

k = |Ri

- mik|fi, z, q, σ2

i k, mi0, σ2

i 0 ∼ N (µik, v2

i k), with

k|. With this decomposition

µik = v2

mi0
σ2
i 0

+

i k 

v2
i k =


n1
k
σ2
i k

+

1
σ2
i 0 (cid:19)

(cid:18)

1
σ2
i k

−1

Xr∈R1

k

fi(r)





- σ2

i k|fi, z, q, αi0, βi0 ∼ IG(αik, βik), with

αik = αi0 +

βik = βi0 +

(fi(r) − mik)2 + 2

(fi(r) − 1tfN i(r))2

Xr∈R1
εi|fi, gi ∼ IG(νi, Σi), with

k

- σ2

Xr∈R0

k

νi =

+ αεi
0 ,

S = total number of pixels

Σi =

||gi − fi||2 + βεi
0

nk
2
1
2

S
2
1
2

6.3 New Gibbs algorithm

The only diﬀerence between the algorithm of section 5 is the introduction of the new
variable q and in the sampling of fi. Indeed we have here to decompose fi into two
subsets fiB and fiW . The Gibbs algorithm we have implemented is then :

Parallel Gibbs sampling

(n−1), ˆfi
(n), ˆfi

(n−1)
W , ˆq(n−1), g1, g2, ˆθ1
(n−1)
, ˆq(n−1), g1, g2, ˆθ1
B

(n−1)

(n−1)

(n−1)

(n−1)

, ˆθ2
, ˆθ2

)

)

repeat until convergence
1. simulate ˆzB
simulate ˆzW

(n) ∼ p(zB| ˆzW
(n) ∼ p(zW | ˆzB

2. simulate ˆq(n) ∼ p(q| ˆz(n))
(n)
3. simulate ˆfi
B ∼ p(fiB|fi
(n)
simulate ˆfi
W ∼ p(fiW |fi
(n)
(n)
∼ p(θi| ˆfi
4. simulate ˆθi

(n−1)
W gi, ˆz(n), ˆq(n), ˆθi
(n−1)
gi, ˆz(n), ˆq(n), ˆθi
B
, ˆz(n), gi)

(n−1)

)
(n−1)

)

11

7 Simulation and results

Here we illustrate two applications of the proposed method in cases of medical imaging
and security systems. The ﬁrst application is MRI and CT images of a brain which
are (256 X 256) images.

segmentation estimée (par moyennage)

segmentation estimée (par moyennage)

(a)

(b)

50

100

150

200

250

50

100

150

200

250

segmentation estimée (par moyennage)

(d)

50

100

150

200

250

50

100

150

200

250

(c)

50

100

150

200

250

(e)

(f)

(g)

50

100

150

200

250

Figure 4: Results of data fusion from MRI and CT images. a,b) MRI and CT images
in medical imaging. c,d) segmentation of the two images taken independantly with
respectively 6 and 9 labels. e,f) respective reconstruction of the images. g) result of
data fusion with 9 labels.

Figure 4 shows the data fusion result of the proposed method comparing independant
segmentation of the two images and segmentation using data fusion. As it is seen
on this ﬁgure the fusionned segmentation we obtain contains all the regions and
boundaries of both images. This is particularly visible in the up-center of the image.
The second application is X ray transmission and backscattering images, which are
(141 X 192) images. The observed object is a suitcase containing two guns. Figure 5
shows the result of the proposed method. The independant segmentation of the X ray
backscttering image show clearly the presence of the right gun, but it is diﬃcult to
distinguish the left gun whatever the number of labels. In this ﬁgure we can see that
the X ray transmission image brings essential information to precisely distinguish the
left gun without eliminating the detecton of the one on the right.
In both applications we have satisfactoring results of image fusion, even when images
present a great number of homogeneous regions and boundaries. Figures 4 and 5
show that the proposed method uses both images to increase the performances of the
segmentation. Note also that the segmentation time of one image independantly or
as result of the image fusion is practically the same. Indeed the proposed method
does not really increase the complexity, making fusion and reconstruction in the same
time.
However in both cases the reconstructed images are not visibly improved. This is

12

20

40

60

80

100

120

140

20

40

60

80

100

120

140

segmentation estimée (par moyennage)

segmentation estimée (par moyennage)

20

40

60

80

100

120

140

20

40

60

80

100

120

140

20

40

60

80

100

120

140

160

180

20

40

60

80

100

120

140

160

180

20

40

60

80

100

120

140

160

180

20

40

60

80

100

120

140

160

180

(a)

(b)

segmentation estimée (par moyennage)

(d)

(c)

20

40

60

80

100

120

140

(e)

(f)

(g)

20

40

60

80

100

120

140

160

180

Figure 5: Results of data fusion from X ray images. a,b) two observations from
transmission and backscattering X rays. c) segmentation of only image a) with 7
labels. d) segmentation of only image a) with 8 labels. e,f) respective reconstruction
of the images. g) result of data fusion with 8 labels.

mostly due to the assumption that the values of fi(r) at any two diﬀerent pixels are
independant. We may expect for better results of reconstruction and segmentation if
we introduce some local spatial dependancy between the neighboring pixels of images
fi(r). This point is under developpment and we will report soon on the results.

8 Conclusion

We proposed a Bayesian method for data fusion of images, with a Potts Markov
Random Field model on the hidden variable z. We illustrated how the segmentation
is improved by using data fusion through two applications : MRI and CT images
in medical imaging and X ray transmission and backscattering images in security
systems.
We showed then how reconstruction and fusion can be computed in the same time
using a MCMC algorithm, which reduce the complexity of the algorithm.

References

[1] S. Gautier, G. Le Besnerais, A. Mohammad-Djafari, and B. Lavayssi`ere, Data fusion in
the ﬁeld of non destructive testing. Maximum Entropy and Bayesian Methods, Santa
Fe, nm: Kluwer Academic Publ., K. Hanson ed., 1995.

13

[2] J. Boyd and J. Little, “Complementary data fusion for limited-angle tomography,” in
IEEE Proceeding of Computer vision and Pattern recognition, (Seattle), pp. 288–294,
1994.

[3] J. Boyd, “Limited-angle computed tomography for sandwich structures using data fu-

sion,” in journal of Nondestructive Evaluation, vol.14, no.2, pp. 61–76, 1995.

[4] G. Matsopoulos, S. Marshall, and J. Brunt, “Multiresolution morphological fuson of mr
and ct images of the human brain,” in IEEE Proceedings on Vision, Image and Signal
Processing, vol.141 Issue : 3, (Seattle), pp. 137–142, 1994.

[5] T. Bass, “Intrusion detection systems and multisensor data fusion,” in Comm. of the

ACM, vol. 43, pp. 99–105, 2000.

[6] H. Snoussi and A. Mohammad-Djafari, “Information Geometry and Prior Selection.,”
in Bayesian Inference and Maximum Entropy Methods (C. Williams, ed.), pp. 307–327,
MaxEnt Workshops, American Institute of Physics, August 2002.

[7] G. Gindi, M. Lee, A. Rangarajan, and I. G. Zubal, “Bayesian reconstruction of func-
tional images using anatomical information as priors,” IEEE Transactions on Medical
Imaging, vol. 12, no. 4, pp. 670–680, 1993.

[8] S. Gautier, J. Idier, A. Mohammad-Djafari, and B. Lavayssi`ere, “X-ray and ultra-
sound data fusion,” in Proceedings of the International Conference on Image Processing,
(Chicago, il), pp. 366–369, October 1998.

[9] T. Hebert and R. Leahy, “A generalized em algorithm for 3-D Bayesian reconstruction
from Poisson data using Gibbs priors,” IEEE Transactions on Medical Imaging, vol. 8,
pp. 194–202, June 1989.

[10] D. Geman and G. Reynolds, “Constrained restoration and the recovery of disconti-
nuities,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 14,
pp. 367–383, March 1992.

[11] G. Aubert and L. Vese, “A variational method in image recovery,” SIAM Journal of

Numerical Analysis, vol. 34, pp. 1948–1979, October 1997.

[12] P. Charbonnier, L. Blanc-F´eraud, G. Aubert, and M. Barlaud, “Deterministic edge-
preserving regularization in computed imaging,” IEEE Transactions on Image Pro-
cessing, vol. 6, pp. 298–311, February 1997.

[13] C. Robert, M´ethodes de Monte-Carlo par chaˆınes de Markov. Paris, France: Econom-

ica, 1996.

14

