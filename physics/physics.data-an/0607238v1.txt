A method for extracting the scaling exponents of a self-aﬃne, non-Gaussian process
from a ﬁnite length timeseries.

K. Kiyani,∗ S. C. Chapman, and B. Hnat
Centre for Fusion, Space and Astrophysics; Dept. of Physics,
University of Warwick, Coventry CV4 7AL, UK
(Dated: 25 July 2006)

We address the generic problem of extracting the scaling exponents of a stationary, self-aﬃne
process realised by a timeseries of ﬁnite length, where information about the process is not known
a priori. Estimating the scaling exponents relies upon estimating the moments, or more typically
structure functions, of the probability density of the diﬀerenced timeseries. If the probability density
is heavy tailed, outliers strongly inﬂuence the scaling behaviour of the moments. From an operational
point of view, we wish to recover the scaling exponents of the underlying process by excluding a
minimal population of these outliers. We test these ideas on a synthetically generated symmetric
α-stable L´evy process and show that the L´evy exponent is recovered in up to the 6th order moment
after only ∼0.1-0.5% of the data are excluded. The scaling properties of the excluded outliers can
then be tested to provide additional information about the system.

I.

INTRODUCTION

There is increasing observational evidence that natural
systems often show scaling in a statistical sense, coinci-
dent with non-Gaussian ‘heavy tailed’ statistics. Com-
plex systems approaches aim to understand these phe-
nomena as universal, with a key quantitative prediction
of theory being scaling exponents. Importantly, the iden-
tiﬁcation of universal scaling functions implies the ability
to describe many diﬀerent length and time scales as well
as apparently disjoint physical phenomena with the same
macroscopic scaling behaviour [1, 2, 3].

One of the outstanding challenges in complex system
science is then to ﬁnd robust methods that (i) establish
whether there is scaling and (ii) accurately determine the
scaling exponents for statistical measures of series of data
that are of large, but ﬁnite length. We seek to determine
the scaling properties of probability distributions that are
heavy-tailed. The scaling exponents can be determined
through the scaling behaviour of the moments, usually
characterised by computing structure functions. Where
the probability density is heavy tailed the moments and
structure functions can depend strongly on extremal val-
ues, or outliers. Once we insist that the data series is
represented by a ﬁnite number of measurements, the val-
ues at which these outliers occur will always vary between
one realisation and the next. From an operational point
of view, that is, when the underlying behaviour is not
known a priori, these outliers can potentially distort the
scaling properties of the data and the values of scaling
exponents extracted via the structure functions. In this
paper we propose a generic method for excluding these
outliers in a manner which does not distort the underly-
ing scaling properties of the data. These outliers also con-

∗Electronic address: k.kiyani@warwick.ac.uk

tain information and we explore a method for extracting
this. We will test these ideas on numerically generated
L´evy processes.

There has been considerable interest in fractional ki-
netics as providing stochastic models for the data of
candidate complex systems [4, 5]. L´evy processes have
been identiﬁed for example in biological systems (forag-
ing of albatrosses [6]), ﬁnancial markets (S&P 500 [7])
and physical systems (laser cooling and trapping [8]). A
robust method for determining the L´evy exponent from
ﬁnite sized data sets, where the statistics are not known
a priori is thus important in its own right. The method
that we propose here is however quite generic, with ap-
plication to a wide class of systems that show scaling; for
example those that can be modelled by stochastic diﬀer-
ential equations with scaling [9, 10, 11]. In this wider con-
text L´evy processes, which have non-convergent higher
order moments, provide a particularly stringent test of
our ideas.

A. Statistical self-similarity

One can characterise ﬂuctuations in a timeseries x(t)
on a given time scale τ in terms of a diﬀerenced variable
y(t, τ )

y(t, τ ) = x(t + τ ) − x(t) ,

(1)

for time t and interval τ , where the timeseries/stochastic
process x(t) represents a particular realisation or set of
observations of the system from which the y’s are gener-
ated. We consider the case where the y(t, τ ) satisfy the
following scaling relation

y(bτ ) d= f (b)y(τ ) ,

(2)

d= indicates an
where b is some scale dilation factor;
equality in the statistical/distribution sense; f is some

6
0
0
2
 
l
u
J
 
6
2
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
8
3
2
7
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

scaling function (to be determined); and we have dropped
the time argument in the increments y by assuming sta-
tistical stationarity. Both b and f (b) are positive. The
property in (2) is a generalized form of self-aﬃnity, and
in this sense x(t) is a self-aﬃne ﬁeld. Self-aﬃnity is a
particular case of statistical self-similarity i.e. stochastic
processes that exhibit the absence of characteristic scales
[3, 11, 12]. We can write the scaling transformations (2)
as

τ ′ = bτ ,

y′ = f (b)y ,

(3)

where the primed variables represent scaled quantities.
Conservation of probability under change of variables im-
plies that the probability density function (PDF) of y,
P (y, τ ) is related to the PDF of y′, P (y′, τ ′) by

thus giving from (3)

P (y, τ ) = P ′(y′, τ ′)

,

dy′
dy (cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

P (y, τ ) = f (b)P ′(f (b)y, τ ′) .

(4)

(5)

The result (5) expresses the fact that the stochastic pro-
cess x(t) is statistically self-similar i.e. that a given pro-
cess on scale τ ′ (and thus y′) maps onto another pro-
cess based on a diﬀerent scale τ (and y) by the scaling
transformation in (3); and that the PDFs of both these
processes are related by (5).

We can go further and reduce the expression (5) to a
function of one variable. Since the dilation factor b is
arbitrary we choose b = τ −1, which gives the important
result

P (y, τ ) = f (τ −1)P ′(f (τ −1)y, 1)
= f (τ −1)Ps(f (τ −1)y) ,

(6)

and shows that any PDF P of increments y characterised
by a time increment τ may be collapsed onto a single
unique PDF Ps of rescaled increments f (τ −1)y and time
increment τ = 1, by the above scaling transformation.
Identiﬁcation of this unique scaling function and the en-
suing collapse is a clearer method of discriminating be-
tween diﬀerent (universality) scaling classes than simply
identifying the scaling exponents by themselves [1].

In this paper we will consider the scaling as deﬁned by
the structure functions. The generalised structure func-
tions of order p are simply deﬁned as

Sp(τ ; ±∞) = h|y|pi =

|y|p P (y, τ )dy .

(7)

∞

Z

−∞

The analysis which follows is also valid for the moments;
however, structure functions are typically calculated for
data. This avoids the result that odd order moments of
symmetric PDFs are zero so that as a consequence, in
a physical system, they would be dominated by experi-
mental error. Using the transformation (6), the scaling

of the structure functions is:

Sp(τ ; ±∞)

|y|p P (y, τ )dy

∞

Z

−∞
∞

Z

−∞

=

=

=

′

y

=yf (τ
=

−1)

|y|p f (τ −1)Ps(f (τ −1)y) dy

−p

−p

∞

Z
−∞
Sp

f (τ −1)
(cid:0)
(cid:1)
f (τ −1)
(cid:1)
(cid:0)

|y′|p Ps(y′) dy′

s (1; ±∞) .

(8)

This formalism encompasses a general class of self-aﬃne
systems in the sense that it is not restricted to the well-
studied case of mono-exponent scaling.

The above result (8) holds provided that the PDF P
is deﬁned for all y. However, for ﬁnite data sets this is
not the case. In this situation we have the integral (7)
deﬁned for the interval [y−, y+] where the y± are deﬁned
in some sense by the largest events measured in the data
set. The values of y± will depend on the time scale τ and
the sample size N (which will be held constant). Thus
the structure functions for the ﬁnite data set are

Sp(τ ; y±(τ )) =

|y|p P (y, τ )dy .

(9)

y+(τ )

Z

y−(τ )

Manipulating this in a similar way to (8) results in the
following scaling relation

Sp(τ ; y±(τ )) =

s (1; y±(τ )f (τ −1)) .
Sp

(10)

−p

f (τ −1)
(cid:1)
(cid:0)

If we assume that the values y± scale with τ in the same
way as the increments y in (3), then (10) becomes:

−p

Sp

s (1; ys±(1)) .

Sp(τ ; y±(τ )) =

f (τ −1)
(cid:1)
(cid:0)
We will consider the case of self-aﬃne scaling where
the scaling function f takes the form of a mono-scaling
power law f (b) = bH = τ −H , where H is known as the
Hurst exponent. Equation (6) then becomes

(11)

P (y, τ ) = τ −H Ps(τ −H y) ,

(12)

and (8) becomes

Sp(τ ; ±∞) = τ ζ(p)Sp

s (1; ±∞) ,

(13)

where ζ(p) = Hp for this self-aﬃne case. A log-log plot
of Sp vs. τ for various orders p reveals scaling if present,
and the slope of such a plot determines the exponents
ζ(p) [2, 13]. One then veriﬁes that ζ(p) = Hp by plotting
ζ(p) as a function of p.

The aim of this paper is to obtain a good estimate of
the scaling properties of (7), the structure functions at
N → ∞, via (11) for N large but ﬁnite. However, we
can anticipate that simply setting the limits y± of the
integral (9) to the largest values found in a given reali-
sation of the data, will give a scaling behaviour of (11)
which can diﬀer substantially from that of (13). This

problem arises since the y values of the extremal points
ﬂuctuate between one realisation and the next, and these
ﬂuctuations are more signiﬁcant in heavy tailed distribu-
tions. This in turn will strongly modify the integral. We
will therefore explore the possibility of choosing a range
for the integral (9) based on the scaling property of the
data itself, by systematically excluding the most extreme
outlying points. This has the added advantage of not re-
quiring a priori information about the system.

We stress that as our aim is to extract scaling expo-
nents, we do not attempt to estimate the value of the
moments or structure functions. Thus we will not com-
pute an estimate of the integral (7) per se, rather we will
examine methods for quantifying its dependence on the
dilation factor b (or equivalently τ ). Hence, our method
can be applied to L´evy processes – where the moments
are not deﬁned, but where the PDF has scaling.

The paper is organised as follows. We ﬁrst introduce
the L´evy process that we will use to obtain (9) and brieﬂy
survey results pertaining to its asymptotic behaviour.
We then discuss the eﬀects of ﬁnite sized data sets and
demonstrate the eﬀect of removing outliers on the scal-
ing behaviour of the L´evy process. We then explore the
behaviour of these outliers.

II. L´EVY PROCESSES AND FINITE SIZE
EFFECTS

A. α- stable processes

Many stochastic processes exhibit self-aﬃne scaling
and are characterised by ‘broad tails’ described by power-
laws in their PDFs. Some possible mechanisms by which
these power laws occur are discussed in [2]. This gen-
eral class of stochastic processes can be described in the
context of so-called α-stable L´evy processes [4, 14, 15].
We will restrict our attention to symmetric α-stable pro-
cesses. The PDFs Lγ
α of the increments y of these pro-
cesses are deﬁned through the Fourier transform of their
characteristic function

Lγ

α(y, τ ) =

1
2π Z

∞

−∞

dkeikye−γτ |k|α

,

(14)

where γ ≥ 0 and τ ≥ 0 are the characteristic scales of the
process and describe the width of the distribution; and
α ∈ (0, 2] parameterises the stability of the distribution;
α can be heuristically seen as an indication of the vari-
ability of the increments of such processes (also known as
L´evy ﬂights). In this paper we will take γ = 1 and will
consequently reduce the notation Lγ
α to Lα. The form
and convention of the parameters in equation (14) are
similar to that presented in [16]; for a more rigorous dis-
cussion of the mathematical properties of such processes
readers are referred to [14, 15].

From (14) it follows that the scaling properties of Lα

are

Lα(y, τ ) = τ − 1

α Lα(τ − 1

α y, 1)

a)

b)

Figure 1: Plots showing probability density functions of the
L´evy distribution for index α = 1.4 (N = 106) at diﬀerent
values of diﬀerenced interval τ (a) before and (b) after the
scaling collapse described by (15).

= τ − 1

α Ls,α(τ − 1

α y) ,

(15)

from which the Hurst exponent of symmetric α-stable
processes is H = 1/α, by comparison with (12). Figure
1 (a) shows the Lα(y, τ ) for α = 1.4 and a range of τ =
20, 21, . . . , 210; the scaling collapse (15) has been applied
to these in Figure 1 (b).

We now focus on the asymptotic behaviour of such
distributions. By expanding the complex exponential in
equation (14) and integrating one can show that in the
large y limit we obtain the asymptotic behaviour

lim
y→∞

Lα(y, τ ) ≃

τ Γ(1 + α) sin(πα/2)
π |y|1+α

10

8

6

4

2

0

1.5

1

0.5

)

p
S

(

0
1

g
o

l

)
p
(
ζ

= Dα

τ
|y|1+α .

(16)

1

for y ≫ τ
α [16, 17]. It immediately follows that these
power-law tails ensure that for the pth moment to exist,
p − α < 0. Hence the process has no variance deﬁned for
0 < α < 2, and in the cases where 0 < α ≤ 1 the process
will also have no mean deﬁned i.e. both these quantities
and the other higher order moments are inﬁnite.

A generalized version of the Central Limit Theorem
(CLT) [2] ensures that the sum of all independent and
identically distributed (i.i.d.) random variables with no
ﬁnite variance that have distributions with power law
tails that go asymptotically as y−1−α (α ∈ (0, 2]), will
converge to a L´evy distribution of the same index α. In
practice, however, we will always obtain a ﬁnite mean
and variance from a ﬁnite length timeseries.

B. Finite-Size eﬀects and outliers

We will now consider in detail the procedure for ex-
tracting the scaling exponents, ζ(p),
from the struc-
ture functions in (13). This centres on ﬁrst comput-
ing Sp(τ ; y±) and the gradients ζ(p) of log-log plots of
Sp(τ ; y±) vs. τ . If the process is self-aﬃne (ζ(p) = Hp)
we should obtain a straight line on a plot of ζ(p) vs. p
from which we can measure the gradient and obtain the
Hurst exponent, H. Note that the ζ(p) for several p are
needed to determine H uniquely [11].

However, ﬁnite sample sizes result in pseudo multi-
aﬃne behaviour. As we will show, the primary reason
for this anomalous behaviour is due to the large scat-
ter in the outlying events of the tails of the distribution.
In the case of L´evy-like processes this scaling bias shows
up as a saturation/roll-over on the ζ(p) plots at p > α.
This can be seen in Figure 2 which illustrates both the
methodology of extracting scaling exponents from struc-
ture function plots, and this ﬁnite sample size saturation
eﬀect in a L´evy process of index α = 1.4. This satura-
tion eﬀect is well-known and an explanation for it can be
found in the work by Schmitt et. al.
[5] and Chechkin
and Gonchar [18]. We will now establish the scaling prop-
erties of these extremal events. We need to emphasise,
however, that in contrast to [5, 18] we will propose a
method for estimating the integral in (7) such that the
scaling in (13) is recovered for all p.

We consider the situation where we have many reali-
sations, that is many data series of size N obtained from
the same process. Each of these realisations will have
extremal points y∗ of their respective PDF. We know the
properties of ¯y∗, the ensemble average of the y∗ over the
realisations, since it will fall on the L´evy asymptotic dis-
tribution (16). We will use a simple example of Extreme
Value Theory, EVT, (see [2]) to obtain an estimate of
the largest event in a sample of N i.i.d. measurements
of a random variable y ∈ R+. An approximation to the
probability to see an event that occurs only once can be

p=6

p=5

p=4

p=3

p=2

p=1

6

 

a)

2

3

log

10

4
(τ [secs])

5

0

 

0

b)

2

4

Moment p

6

Figure 2: Plots of (a) generalised structure functions Sp vs. τ
for moments of order p = 1 − 6, and (b) the scaling exponents
ζ(p) vs. p (solid black line). These quantities are shown for a
L´evy process of index α = 1.4 and with N = 106 data points.
The dashed red line indicates the expected scaling ζ(p) = p/α
for p < α; the green dashed line indicates the scaling exponent
observed for p > α in a ﬁnite sized sample. The vertical arrow
at p ≃ α seperates these two regions of scaling.

made by realising that an event with probability P oc-
curs typically N P times. Therefore, the rarest event in a
sample of N measurements, which occurs typically only
once can be seen to be described by N P (y ≥ ¯y∗) = 1,
where P (y ≥ ¯y∗) is the probability of observing an event
greater than or equal to ¯y∗ ; thus

We can generalise this to the mth largest event:

P (y ≥ ¯y∗) =

P (y ≥ ¯y∗

m) =

1
N

.

m
N

.

(17)

(18)

For the case of the L´evy-like process, within the limits of
the integral in P (y ≥ ¯y∗
m) the main contribution is from
the tail and thus we can use (16) and estimate P (y ≥ ¯y∗
m)
to be

P (y ≥ ¯y∗

m) =

Lα(y, τ )dy ≃ Dατ

∞

Z

¯y∗
m

∞

Z

¯y∗
m

dy
|y|1+α . (19)

as expected from equation (2) [24] . We emphasise that
this is the scaling of ¯y∗
m; the average over the mth largest
events of a large number of realisations (timeseries). In
practice we will have a single realisation and thus one
value of y∗
m which will ﬂuctuate about this ensemble av-
eraged ¯y∗
m. The behaviour (25) refers to the property
that any point in the curve P (y, τ ) scales as (6) and (3).

Evaluating the integral and equating with (18) gives the
following result for the scaling behaviour of the mth
largest event

¯y∗
m =

DαN τ

(cid:18)

mα (cid:19)

1
α

.

(20)

A more detailed account would be to attempt to spec-
ify approximately the full PDF of the mth largest event
amongst N i.i.d. measurements. Following Sornette [2]
the cumulative distribution function (CDF) Π(y < ¯y∗
m)
of the maximum value is

III. STRUCTURE FUNCTIONS

A. Eﬀects of ﬁnite sample size

We can now investigate the scaling behaviour of the
structure functions of a L´evy-like process, but now with
a ﬁnite sample size. Following the procedure in (11) we
can discuss the structure functions in the average sense,
that is averaged over many realisations of our N sample
ﬁnite length timeseries:

Π(y < ¯y∗

m) =

pN (y)dy ≃ e− N

∗
m P (y≥¯y

m) ,

(21)

¯Sp(τ ; ¯y∗

1,±(τ )) =

|y|p Lα(y, τ )dy

∗
¯y
m

Z

−∞

where pN (y) is the PDF of the maximum value among N
observations, and is obtained by diﬀerentiating equation
(21) to obtain

dΠ(y < ¯y∗
dy∗
m

m)

= pN (¯y∗

m) =

Lα(¯y∗

m, τ )e− N

∗
m P (y≥¯y

m) .

N
m

(22)
By substituting (19) in (21) we obtain an estimate of
the mth largest value, ¯y∗
m,Π, that will not be exceeded
with probability Π. By setting the LHS of (21) to some
probability 0 < Π < 1, we obtain

¯y∗
m,Π =

DαN τ
mα ln(1/Π) (cid:19)

(cid:18)

1
α

.

(23)

If one was to set Π = 1/2 the value of y∗
m would corre-
spond to the median value of the mth largest event. To
obtain the modal value of ¯y∗
m , we optimise for the max-
imum by diﬀerentiating (22) and setting it to zero. This
gives us the following solution for the modal value of ¯y∗
m

∗
1,+(τ )
¯y

Z

−¯y∗
1,−(τ )
∗
1,+(τ )
¯y

Z

−¯y∗

1,−(τ )

=

|y|p τ − 1

α Ls,α(τ − 1

α y) dy

(26)

where we have set m = 1 in ¯y∗
m to emphasise that this is
the structure function for the raw data with the largest
events obviously bounding the data; the subscripts + and
− indicate the largest positive and negative events. The
substitution y′ = τ − 1

α y gives

¯Sp(τ ; ¯y∗

1,±(τ )) = τ

p
α

|y′|p Ls,α(y′) dy′

∗
1,+(τ )τ
¯y

− 1
α

Z

−¯y∗

1,−(τ )τ

− 1
α

∗
1,+(τ )τ
¯y

− 1
α

= τ

p
α 

Z
0



+

Z
0

∗
1,−(τ )τ
¯y

− 1
α

y′pLs,α(y′) dy′

y′pLs,α(y′) dy′

.(27)



¯y∗
m,mode =

DαN τ
m(1 + α) (cid:19)

(cid:18)

1
α

.

(24)

To approximate the integrals in (27) we assume that val-
ues of the largest events are deep in the tail region of
the distribution so that we may use the asymptotic form
(16). This gives

By comparing these expressions one can see that al-
though the approximation of ¯y∗
m becomes more reﬁned,
the scaling with τ is still that of (20). Thus we will pro-
ceed using the simplest expression (20). In addition, we
will be working with a varying fraction m/N rather than
varying m or N separately.
Importantly, since we are
concerned primarily with the scaling with respect to τ
m more informatively as ¯y∗
we will write ¯y∗
m(τ ) and thus
adding to our scaling relations

¯y∗
m(τ ) = τ

1

α ¯y∗

m(1) ,

(25)

¯Sp(τ ; ¯y∗

1,±(τ )) = τ

¯y∗(p−α)
1,+

(τ ) + ¯y∗(p−α)

1,−

(τ )

Dα
p − α (cid:16)

∀p > α,

(cid:17)
(28)

where the condition p > α is necessary as all structure
functions of order p < α of a L´evy distribution exist
(i.e. are ﬁnite) and this approximation would result in an
infrared divergence in (27), which is clearly incompatible.
For the ensemble average (19), (20) and (25) hold; thus

)

* m
x
 
δ
(

N

p

0.6

0.4

1

0.8

0.2

 
0
0

Λ=1
Λ=2
Λ=4
Λ=8
Λ=16

 

that the scatter in the y∗
with N and decreases with m/N .

m about the average ¯y∗

m increases

B. Conditioning – overview

We now present a method to ‘condition’ data so that
the scaling behaviour (13) emerges from the structure
functions obtained for a ﬁnite data series. From an oper-
ational point of view, that is, when attempting to deter-
mine an (unknown) exponent from a ﬁnite length time-
series, our aim is to recover (13) for as many orders p
as feasible. This method involves excluding a fraction
m/N of the largest events from the data set such that our
post-exclusion tails are now suﬃciently resolved and pop-
ulated. Although there is some literature on the removal
of extreme outliers in data, the ﬁrst time it was clearly
done in the scaling context was by Veltri et. al [21, 22].
They calculated structure functions via the use of a Haar
wavelet transform and conditioned their data by separat-
ing the wavelet coeﬃcients into two classes: the majority
of coeﬃcients which characterise the “quietly turbulent
ﬂow”; and the coeﬃcients which characterise the rare in-
termittent events corresponding to coherent structures.
The partition between these two classes was a wavelet
coeﬃcient based upon a multiple F of the square root of
the second moment of the coeﬃcents. The easiest way to
view this is by looking at the more recent works of Chap-
man et. al. [10, 11] (and refs therein) who employed an
equivalent technique but did not use wavelet transforms
to calculate the structure functions. Along with their so-
lar wind turbulence data, the latter authors also studied
some toy cases of fractional Brownian motion and a L´evy
process of α = 1.8. This conditioning can be succinctly
written as the approximation

(30)

(31)

Sp(τ ; ±∞) =

|y|p P (y, τ )dy

∞

Z

−∞
→ SC (τ ; ±A)
A

=

Z

−A

|y|p P (y, τ )dy ,

(32)

2

6

4

δ x*
m

8

10

Figure 3: Plot showing the PDF, in equation (30), of the mth
largest value of a sample size N of a set of measurements
taken from a L´evy-like process; the L´evy index α = 1.5.

we can simply substitute (25) into (28) to obtain:

Dα
p − α (cid:16)

¯Sp(τ ; ¯y∗

1,±(τ )) = τ

p
α

¯y∗(p−α)
1,+

(1) + ¯y∗(p−α)

1,−

(1)

.

(cid:17)
(29)
In practice the value of y∗
m will vary for each realisa-
tion of P (y, τ ) about the average ¯y∗
m which obeys (25).
For a given functional form of P (y, τ ) the y∗
m will have
some probability density pN (y∗
m) with a statistical spread
about the average ¯y∗
m. An approximation to this can be
made by substituting the asymptotic tail form of equa-
tion (16) into equation (22) to obtain

pN (y∗

m) =

Λ
y∗1+α
m

exp

−

(cid:18)

Λ
αy∗α
m (cid:19)

,

where Λ is given by

Λ =

N Dατ
m

.

Equation (30) is of the form of a stretched exponen-
tial. As with any power-law tailed PDF it has inﬁnite
variance for 0 < α < 2. In the context of EVT, equation
(30) is not surprising as it is simply an Extreme Value
Distribution of Type II i.e. the PDF from a Fr´echet dis-
tribution. The extreme value distributions can be seen
as the large event statistics equivalent to stable distribu-
tions (i.e. Gaussian and L´evy). The interested reader is
referred to [19, 20] for a further discussion of EVT and
extreme value distributions.

A plot of the PDF (30) is given in Figure 3 for various
values of Λ and for α = 1.5. From Figure 3 we see that
as the value of Λ increases, the PDF of y∗
m broadens.
Importantly, the PDF of y∗
m (30) has an inﬁnite variance
and thus has more frequently occuring extreme values of
y∗
m away from ¯y∗
m. Thus from Figure 3 and (31) we see

where A = Qσ(τ ), σ(τ ) is the standard deviation and Q
is some constant. This corresponds to clipping the wings
of the distribution to exclude the very large unresolved
events. Both these studies [11, 21] showed that removing
a relatively few percentage of points is suﬃcient to regain
the scaling. However, the disadvantage of these schemes
is that the measure used to exclude the extreme events
is the standard deviation, σ, of the raw data which must
be calculated a priori and we have already seen in the
above analysis that p > α (and thus σ) is poorly repre-
sented in the unconditioned data. A better estimate is
to condition the data based on the actual extreme events
i.e. by excluding a certain negligible fraction of the data
outliers.

A brief mention should be made of the work by Jes-
persen et. al. [17]. They studied the behaviour of L´evy

ﬂights in external force ﬁelds and used a form of condi-
tioning for obtaining a good statistical ensemble in the
power-law tail range of a L´evy process. Their condition-
ing, however, assumes a priori knowledge of the distribu-
tion and its scaling behaviour, and is thus not congruent
to the applications to which this paper aims; this being
single ﬁnite size natural timeseries.

To summarise, our procedure will be to:

1. Choose limits of the integral in (32) such that the
scaling (13) is recovered – using a method that does
not require a priori knowledge of the PDF P (y, τ )
to specify those limits.

2. This procedure will exclude the most outlying

points (. 1%).

3. These outliers contain some physics of the system.
They may or may not share the scaling (12) with
the core of the PDF P (y, τ ), instead showing ﬁnite
size scaling (exponential roll-oﬀ) or other dynam-
ics. Therefore we will also test the outliers for the
property (25).

C. Conditioning – L´evy process

We now test these ideas with a numerically generated
L´evy process. The increments y of the L´evy process of
index α were generated by using the following algorithm
[23]

)
p
(
ζ

10

8

6

4

2

6

5

4

3

2

1

)
p
(
ζ

0%
0.001%
0.005%
0.01%
0.05%
0.1%
0.5%
1%
2%
3%
4%
5%

0%
0.001%
0.005%
0.01%
0.05%
0.1%
0.5%
1%
2%
3%
4%
5%

0

 

−2

a)

0

2
Moment p

4

6

 

 

y =

sin(αr)
(cos r)1/α (cid:18)

cos [(1 − α)r]
v

(cid:19)

(1−α)/α

,

(33)

0

 

−2

b)

0

2
Moment p

4

6

where r ∈ [−π/2, π/2] is a uniformly distributed random
variable and v is an exponentially distributed random
variable with unit mean. Expression (33) corresponds to
the L´evy distribution (14) with γ = 1 and τ = 1. We
generate a sample of size N and then construct a time-
series by use of a cumulative sum. This timeseries was
then diﬀerenced at various τ as in (1) using an overlap-
ping window; appropriate here since the data increments
are uncorrelated. Structure functions of the increments
Sp(τ ; y∗
±(τ )), are then calculated at diﬀerent orders p and
at diﬀerent values of τ . These are then plotted on a Sp
vs. τ plot and a linear regression is performed to obtain
the gradients ζ(p) for each moment order p. The plots
of these ζ(p) vs. p are shown in Figure 4 for the two
cases α = 1.0 and α = 1.8. The error bars in Figure 4
were obtained from the diﬀerence between the linear re-
gression of the structure functions for all moment orders
concerned, and the linear regression with the 5th and 6th
moment orders not included.

In Figure 4 we see that if no outliers are removed from
the integral for Sp, the resulting values of ζ(p) for p > α
saturate to unity. Removing a small fraction (∼0.001%)
of the outliers results in a drastic change in the ζ(p),
again emphasising the strong eﬀect these points have in

Figure 4: Plots showing the exponents ζ(p) against moment
order p of the generalized structure functions for various val-
ues of the percentage of large events excluded for (a) α = 1.0
and (b) α = 1.8. The arrows indicate the percentage beyond
which convergence to the expected behaviour ζ(p) = p/α is
established. Both plots are for a sample size of N = 106.

the integral for Sp. The ζ(p) converge to the values pre-
dicted by (29) quite rapidly with m/N . The rate of con-
vergence is illustrated in Figure 5 for the two cases shown
in Figure 4. Convergence is achieved at m/N = 0.001 for
α = 1.8 and m/N = 0.005 for α = 1.0; which corre-
spond to the largest event being y∗ ≃ 18 and y∗ ≃ 130
respectively. These values lie in the region given by (16),
as the asymptotic tail region of the PDF is valid for
y ≫ τ 1/α = 1 here.

It is also instructive to investigate the eﬀects of varia-
tions in sample size N on the rates of convergence. Fig-
ure 6 illustrates these eﬀects in the form of ζ(p) vs. p
plots for sizes N = 105 and N = 5 × 106 for a L´evy pro-
cess of index α = 1.0. Recall that decreasing the sample
size would result in further undersampling and thus poor

a)

0

1

2

3

4

5

Percentage of pnts removed

0

 

−2

a)

0

2
Moment p

4

6

 

 

 

α
ζ(2)
ζ(3)

 

10

α
ζ(2)
ζ(3)

7

6

5

4

3

2

1

8

6

4

2

)
p
(
ζ

)
p
(
ζ

0%
0.001%
0.005%
0.01%
0.05%
0.1%
0.5%
1%
2%
3%
4%
5%

0%
0.001%
0.005%
0.01%
0.05%
0.1%
0.5%
1%
2%
3%
4%
5%

4.5

3.5

2.5

1.5

5

4

3

2

1

0.5

 

2.5

1.5

3

2

1

0.5

 

b)

0

1

2

3

4

5

Percentage of pnts removed

0

 

−2

b)

0

2
Moment p

4

6

Figure 5: Plots showing the rapid convergence of the L´evy
parameter α; and the exponents of the 2nd and 3rd moments
ζ(2) and ζ(3). The plots in (a) are for α = 1.0 and in (b) for
α = 1.8 – both have N = 106. ζ(2) and ζ(3) are the best ﬁt
gradients of the Sp vs. τ plots, and α is obtained from the
inverse of the gradient of the ζ(p) vs. p plot shown in Figure
4.

statistics in the tails of the PDF. This can be clearly seen
in Figure 6 (a) where we see a slow convergence to the
line ζ(p) = p/α which is achieved after ∼ 4% of the data
is excluded. The converse of this is shown in Figure 6 (b)
where increasing the sample size by a factor of 20 results
in a very rapid convergence to scaling which is reached
after only ∼ 0.5% of the data is excluded.

Lastly we consider the behaviour of the outliers that
are removed by this procedure. As we succesively re-
move more outliers (increasing m), the behaviour of y∗
m
will more closely correspond to that of ¯y∗
m. This is shown
in Figure 7 where we plot y∗
m(τ ) for increasing m/N . The
anticipated scaling (25) appears at a value of m/N cor-
responding to a few percent. A more established method

Figure 6: ζ(p) vs. p plots for α = 1.0; (a) N = 105 and (b)
N = 5 × 106.

for determining the scaling of outliers is a rank order (or
Zipf) plot (see Sornette [2]); this is shown in Figure 8
where we plot y∗
m(m/N ) for succesively large values of τ .
The scaling with m/N is again as expected from (20)–
(24), and the rank order plots also highlight scatter of
individual realisations of y∗
m from the ensemble average.
In Figure 8 this becomes apparent at higher values of τ .
As we increase τ we require a higher fraction of points to
be excluded before we regain the expected scaling with
m/N . This breakdown of the scaling at higher values of
τ follows from equations (30) and (31). We can see that
Λ increases with τ and so the distribution becomes more
broad. Consequently this will require a higher fraction
m/N of points to be excluded so that we may regain the
scaling behaviour (20). At the largest τ , Figures 7 and
8 show a saturation indicative of the diﬀerence y∗
m being
dominated by a single extremal value x of the original
timeseries in (1). These plots are also a useful indicator

0.001%

)

m*
y
(
n

l

8

7

6

5

4

3

2

1

8

7

6

5

4

3

2

1

)

m*
y
(
n

l

5%

0

 

0

1/grad=1.7925

2

4

ln(τ)

6

Figure 7: Log-log plot illustrating the scaling of the mth
m with τ as m is increased; α = 1.8 , N = 106.
largest event y
For comparison with previous ﬁgures we indicate the % of
points that would be excluded for the particular m.

∗

−1/grad=1.9072

 
0
−12

−10

−8

−6
ln(m/N)

τ=20

−4

−2

Figure 8: Log-log plot illustrating the scaling of the largest
event y∗
m with m/N for various values of τ ; α = 1.8 , N = 106.

of how feasable, for a dataset of size N , it would be to
distinguish a departure from L´evy scaling in the tails.

 

 

τ=210

α-stable L´evy process. We are concerned with the sit-
uation of observations of natural systems, or of experi-
ments, where the underlying PDF is not known a pri-
ori and where one inevitably has a ﬁnite length series of
data. Hence we have proposed a technique that does not
require a priori knowledge of the underlying process and
that has consistency checks.

We have shown that ‘conditioning’ the data by pro-
gressively excluding the outliers, or extremal points,
when computing the scaling exponents from the struc-
ture functions, recovers the underlying scaling of a self-
aﬃne process up to large order. For large datasets of a
L´evy process this corresponds to removing 0.1-1% of the
data. The conditioned structure functions then provide
a straightforward method for determining the self-aﬃne
scaling exponent, in this case the L´evy index α, directly
from the slope of a plot of the exponents versus moment
order.

This method oﬀers two consistency checks. The ﬁrst of
these is that for a self-aﬃne process, as we progressively
remove more outliers we expect that the exponents ob-
tained from the structure functions should converge on
values which then do not vary. Practically speaking, one
would plot the exponents as a function of the location
of the last outlier excluded and expect a plateau that
extended deep into the tail of the PDF. A second check
is obtained by examining the scaling properties of these
discarded outliers.

Importantly, the above analysis assumes that we have
some relatively good statistics – in practice the high vari-
ability of the L´evy process due to the fat tails will always
result in some lone extreme points with a ﬁnite proba-
bility of occurence, resulting in anomalous scaling expo-
nents. This implies that we always need some way of
cleaning or conditioning the data to recover the scaling
behaviour. These lone points can have a drastic eﬀect
since in a L´evy-like process the largest value of a set of
increments of a timeseries can be of the order of the to-
tal sum [2, 8]. Coupled with this we have that the tails
of a distribution are described by the higher order mo-
ments (structure functions here). If the statistics of the
tail are not well resolved then these moments will also
give anomalous values of ζ(p).

In principle, this approach may be extended to the case
of multi-aﬃne timeseries and this will be the subject of
further work.

IV. SUMMARY AND CONCLUSIONS

Acknowledgments

In this paper we have presented a novel technique for
‘conditioning’ data to deal with anomalous scaling prop-
erties that arise due to ﬁnite size eﬀects. We have demon-
strated our ideas on a numerically generated symmetric

The authors would like to thank N. Watkins and G.
Rowlands for helpful discussions and suggestions. KK ac-
knowledges the ﬁnancial support of the Particle Physics
and Astronomy Research Council.

[1] J. P. Sethna, K. A. Dahmen, and C. R. Myers, Nature

[2] D. Sornette, Critical Phenomena in Natural Sciences

410, 242 (2001).

[3] B. B. Mandelbrot, The Fractal Geometry of Nature (Free-

[14] G. Samorodnitsky and M. S. Taqqu, Stable non-Gaussian

(Springer-Verlag, 2000).

man, New York, 1983).

[4] G. M. Zaslavsky, Phys. Rep. 371, 461 (2002).
[5] F. Schmitt, D. Schertzer, and S. Lovejoy, Applied
stochastic models and data analysis 15, 29 (1999).
[6] G. M. Viswanathan, V. Afanasyev, S. V. Buldyrev, E. J.
Murphy, P. A. Prince, and H. E. Stanley, Nature 381,
413 (2002).

[7] R. N. Mantegna and H. E. Stanley, Nature 376, 46

[8] F. Bardou, J. Bouchaud, A. Aspect, and C. Cohen-
Tannoudji, L´evy Statistics and Laser Cooling (Cam-
bridge University Press, 2002).

E 67 (2003).

Res. 110 (2005).

[10] B. Hnat, S. C. Chapman, and G. Rowlands, J. Geophys.

[11] S. C. Chapman, B. Hnat, G. Rowlands, and N. W.
Watkins, Nonlinear Processes in Geophysics 12, 767
(2005).

[12] N. P. Greis and H. S. Greenside, Phys. Rev. A 44 (1991).
[13] T. Bohr, M. H. Jensen, G. Paladin, and A. Vulpiani,
Dynamical Systems Approach to Turbulence (Cambridge

University Press, 1998).

random processes (Chapman & Hall, 1994).

[15] A. Janicki and A. Weron, Simulation and Chaotic Be-
haviour of α-stable Stochastic Processes (Marcel Dekker
Inc, 1994).

[16] W. Paul and J. Baschnagel, Stochastic Processes; From

Physics to Finance (Springer-Verlag, 1999).

[17] S. Jespersen, R. Metzler, and H. C. Fogedby, Phys. Rev.

[21] P. Veltri, Plasma Phys. Control. Fusion 41, A787 (1999).
[22] A. Mangeney, C. Salem, P. Veltri, and B. Cecconi, in
Proceedings of the Sheﬃeld Space Plasma meeting 2001
(2001).

[23] S. Siegert and R. Friedrich, Phys. Rev. E 64 (2001).
[24] note that the distributional equality

d
= is not needed

here as ¯y∗

m is a statistical quantity.

(1995).

[18] A. V. Chechkin and V. Y. Gonchar, Chaos, Solitons and

[19] E. J. Gumbel, Statistics of Extremes (Columbia Univer-

[9] B. Hnat, S. C. Chapman, and G. Rowlands, Phys. Rev.

[20] E. Castillo, Extreme Value Theory in Engineering (Aca-

E 59 (1999).

Fractals 11, 2379 (2000).

sity Press, 1967).

demic Press Inc., 1988).

