PhyStat2003, SLAC, September 8-11

1

Frequentist Hypothesis Testing with Background Uncertainty

K.S. Cranmer
University of Wisconsin-Madison, Madison, WI 53706, USA

3
0
0
2
 
t
c
O
 
2
2
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
8
0
1
0
1
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

We consider the standard Neyman-Pearson hypothesis test of a signal-plus-background hypothesis and
background-only hypothesis in the presence of uncertainty on the background-only prediction. Surprisingly,
this problem has not been addressed in the recent conferences on statistical techniques in high-energy physics –
although the its conﬁdence-interval equivalent has been. We discuss the issues of power, similar tests, coverage,
and ordering rules. The method presented is compared to the Cousins-Highland technique, the ratio of Poisson
means, and “proﬁle” method.

1. Introduction

The probability to commit a Type II error is given by

In the last ﬁve years there have been several con-
ferences on statistics for particle physics. Much of
the emphasis of these conferences were on limit set-
ting and the Feldman-Cousins “uniﬁed approach”, the
quintessential frequentist method based on the Ney-
man construction. As particle physicists prepare for
the Large Hadron Collider (LHC) at CERN, we will
need to reexamine our list of statistical tools in the
context of discovery. In fact, there has been no pre-
sentation at these statistical conferences on frequen-
tist hypothesis testing in the presence of uncertainty
on the background.

In Section 2 we will review the Neyman-Pearson
theory for testing between two simple hypotheses, and
examine the impact of background uncertainty in Sec-
tion 3. In Sections 4- 5 we will present a fully frequen-
tist method for hypothesis testing with background
In
uncertainty based on the Neyman Construction.
the remainder of the text we will present an example
and compare this method to other existing methods.

2. Simple Hypothesis Testing

In the case of Simple Hypothesis testing,

the
Neyman-Pearson theory (which we review brieﬂy for
completeness) begins with two Hypotheses: the null
hypothesis H0 and the alternate hypothesis H1 [1].
These hypotheses are called simple because they have
no free parameters. Predictions of some physical ob-
servable x can be made with these hypotheses and
described by the likelihood functions L(x|H0) and
L(x|H1) (for simplicity, think of x as the number of
events observed).

Next, one deﬁnes a region W ∈ I such that if the
data fall in W we accept the H0 (and reject H1). Con-
versely, if the data fall in I − W we reject H0 and
accept the H1. The probability to commit a Type I
error is called the size of the test and is given by

α =

L(x|H0)dx.

(1)

I−W

Z

WEMT004

β =

L(x|H1)dx.

(2)

Finally, the Neyman-Pearson lemma tells us that the
region W of size α which minimizes the rate of Type II
error (maximizes the power) is given by

W =

x

(

L(x|H1)
L(x|H0)

> kα

.

)

(3)

W

Z

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

3. Nuisance Parameters

Within physics, the majority of the emphasis on
statistics has been on limit setting – which can be
translated to hypothesis testing through a well known
dictionary [1]. When one includes nuisance param-
eters θs (parameters that are not of interest or not
observable to the experimenter) into the calculation
of a conﬁdence interval, one must ensure coverage for
every value of the nuisance parameter. When one is
interested in hypothesis testing, there is no longer a
physics parameter θr to cover, instead one must ensure
the rate of Type I error is bounded by some predeﬁned
value. Analogously, when one includes a nuisance pa-
rameters in the null hypothesis, one must ensure that
the rate of Type I error is bounded for every value
of the nuisance parameter.
Ideally one can ﬁnd an
acceptance region W which has the same size for all
values of the nuisance parameter (i.e. a similar test).
Furthermore, the power of a region W also depends
on the nuisance parameter; ideally, we would like to
maximize the power for all values of the nuisance pa-
rameter (i.e. Uniformly Most Powerful). Such tests
do not exist in general.

In this note, we wish to address how the standard
hypothesis test is modiﬁed by uncertainty on the back-
ground prediction. The uncertainty in the background
prediction represents the presence of a nuisance pa-
rameter: for example, let us assume it is the expected
background b. Typically, an auxiliary, or side-band,
measurement is made to provide a handle on the nui-
sance parameter. Let us generically call that mea-
surement M and L(M |H0, b) the prediction of that

2

PhyStat2003, SLAC, September 8-11

measurement given the null hypothesis with nuisance
parameter b. In Section 8 we address the special case
that L(M |H0, b) is a Poisson distribution.

4. The Neyman-Construction

Usually one does not consider an explicit Neyman
construction when performing hypothesis testing be-
tween two simple hypotheses; though one exists im-
plicitly. Because of the presence of the nuisance pa-
rameter, the implicit Neyman construction must be
made explicit and the dimensionality increased. The
basic idea is that for each value of the nuisance param-
eters θs, one must construct an acceptance interval
(for H0) in a space which includes their correspond-
ing auxiliary measurements M , and the original test
statistic x which was being used to test H0 against
H1.

For the simple case introduced in the previous sec-
tion, this requires a three-dimensional construction
with b, M , and x. For each value of b, one must
construct a two-dimensional acceptance region Wb of
size α (under H0). If an experiment’s data (x0, M0)
fall into an acceptance region Wb, then one cannot
exclude the null hypothesis with 100(1 − α)% conﬁ-
dence. Conversely, to reject the null hypothesis (i.e.
claim a discovery) the data must not lie in any ac-
ceptance region Wb. Said yet another way, to claim
a discovery, the conﬁdence interval for the nuisance
parameter(s) must be empty (when the construction
is made assuming the null hypothesis).

5. The Ordering Rule

The basic criterion for discovery was discussed ab-
stractly in the previous section. In order to provide
an actual calculation, one must provide an ordering
rule: an algorithm which decides how to chose the re-
gion Wb. Recall, that there the constraint on Type I
error does not uniquely specify an acceptance region
for H0. In the Neyman-Pearson lemma, it is the al-
ternate hypothesis H1 that breaks the symmetry be-
tween possible acceptance regions. Also in the uniﬁed
approach, it is the likelihood ratio that is used as an
ordering rule [2].

At the Workshop on conference limits at FermiLab,
Feldman showed that Uniﬁed Method with Nuisance
Parameters is in Kendall’s Theory (the chapter on
likelihood ratio tests & test eﬃciency) [3]. The nota-
tion used by Kendall is given in Table I. Also, Kendall
identiﬁes H0 with θr = θr0 and H1 with θr 6= θr0.

Let us brieﬂy quote from Kendall:

“Now consider the Likelihood Ratio

Variable Meaning
θr
θs
ˆθr, ˆθs
ˆˆθs

physics parameters
nuisance parameters
unconditionally maximize L(x|ˆθr, ˆθs)
conditionally maximize L(x|θr0, ˆˆθs)

Table I The notation used by Kendall for likelihood tests
with nuisance parameters

Intuitively l is a reasonable test statistic
for H0: it is the maximum likelihood un-
der H0 as a fraction of its largest possible
value, and large values of l signify that H0
is reasonably acceptable.”

Feldman uses this chapter as motivation for the pro-
ﬁle method (see Section 9), though in Kendall’s book
the same likelihood ratio is used as an ordering rule
for each value of the nuisance parameter.

The author tried simple variations on this order-
ing rule before rediscovering it as written. It is worth
pointing out that Eq. 4 is independent of the nuisance
parameter b; however, the contour of lα which pro-
vides an acceptance region of size α is not necessarily
independent of b. It is also worth pointing out that
ˆθr and ˆθs do not consider the null hypothesis – if they
did, the region in which l = 1 may be larger than
ˆˆθs, one
(1 − α). Finally, if one uses θs instead of ˆθs or
will not obtain tests which are approximately similar.

6. An Example

Let us consider the case when the nuisance param-
eter is the expected number of background events b
and M is an auxiliary measurement of b. Further-
more, let us assume that we have a absolute prediction
of the number of signal events s. For our test statis-
tic we choose the number of events observed x which
is Poisson distributed with mean µ = b for H0 and
µ = s + b for H1. In the construction there are no as-
sumptions about L(M |H0, b) – it could be some very
complicated shape relating particle identiﬁcation eﬃ-
ciencies, Monte Carlo extrapolation, etc. In the case
where L(M |H0, b) is a Poisson distribution, other so-
lutions exist (see Section 8). For our example, let us
take L(M |H0, b) to be a Normal distribution centered
on b with standard deviation ∆b, where ∆ is some
relative systematic error. Additionally, let us assume
that we can factorize L(x, M |H, b) = L(x|H, b)L(M |b)
(where H is either H0 or H1).

For our example problem, we can re-write the or-

dering rule in Eq. 4 as

l =

ˆˆθs)
L(x|θr0,
L(x|ˆθr, ˆθs)

(4)

l =

ˆˆb)
L(x, M |H0,
L(x, M |H1, ˆb)

,

(5)

WEMT004

PhyStat2003, SLAC, September 8-11

3

140

M

120

100

80

60

40

Figure 1: The Neyman construction for a test statistic x,
an auxiliary measurement M , and a nuisance parameter
b. Vertical planes represent acceptance regions Wb for H0
given b. The condition for discovery corresponds to data
(x0, M0) that do not intersect any acceptance region.
The contours of L(x, M |H0, b) are in color.

where ˆb conditionally maximizes L(x, M |H1, b) and
conditionally maximizes L(x, M |H0, b).

ˆˆb

Now let us take s = 50 and ∆ = 5%, both of which
could be determined from Monte Carlo. In our toy ex-
ample, we collect data M0 = 100. Let α = 2.85 · 10−7,
which corresponds to 5σ. The question now is how
many events x must we observe to claim a discovery?1
The condition for discovery is that (x0, M0) do not lie
in any acceptance region Wb. In Fig. 1 a sample of
acceptance regions are displayed. One can imagine a
horizontal plane at M0 = 100 slicing through the var-
ious acceptance regions. The condition for discovery
is that x0 > xmax where xmax is the maximal x in the
intersection.

|

There is one subtlety which arises from the or-
dering rule in Eq. 5. The acceptance region Wb =
{(x, M )
l > lα} is bounded by a contour of the
likelihood ratio and must satisfy the constraint of size:
Wb L(x, M |H0, b) = (1 − α). While it is true that
the likelihood is independent of b, the constraint on
R
size is dependent upon b. Similar tests are achieved
when lα is independent of b. The contours of the like-
lihood ratio are shown in Fig. 2 together with con-
tours of L(x, M |H0, b). While tests are roughly sim-
ilar for b ≈ M , similarity is violated for M ≪ b.
This violation should be irrelevant because clearly
b ≪ M should not be accepted. This problem can
be avoided by clipping the acceptance region around
M = b ± N ∆b, where N is suﬃciently large (≈ 10)
to have negligible aﬀect on the size of the acceptance

1In practice, one would measure x0 and M0 and then ask,
“have we made a discovery?”. For the sake of explanation, we
have broken this process into two pieces.

WEMT004

20

0

50

100

150

200

250
x

Figure 2: Contours of the likelihood L(x, M |H0, b) are
shown as concentric ellipses for b = 32 and b = 80.
Contours of the likelihood ratio in Eq. 5 are shown as
diagonal lines. This ﬁgure schematically illustrates that if
one chooses acceptance regions based solely on contours
of the likelihood ratio, that similarity is badly violated.
For example, data M = 80, x = 130 would be considered
part of the acceptance region for b = 32, even though it
should clearly be ruled out.

region. Fig. 1 shows the acceptance region with this
slight modiﬁcation.

In the case where s = 50, ∆ = 5%, and M0 = 100,
one must observe 167 events to claim a discovery.
While no ﬁgure is provided, the range of b consis-
tent with M0 = 100 (and no constraint on x) is
b ∈ [68, 200]. In this range, the tests are similar to
a very high degree.

7. The Cousins-Highland Technique

The Cousins-Highland approach to hypothesis test-
ing is quite popular [4] because it is a simple smear-
ing on the nuisance parameter [5]. In particular, the
background-only hypothesis L(x|H0, b) is transformed
from a compound hypothesis with nuisance parameter
b to a simple hypothesis L′(x|H0) by

′

L

(x|H0) =

L(x|H0, b)L(b)db,

(6)

b
Z

where L(b) is typically a normal distribution. The
problem with this method is largely philosophical:
L(b) is meaningless in a frequentist formalism. In a
Bayesian formalism one can obtain L(b) by consider-
ing L(M |b) and inverting it with the use of Bayes’s
theorem and the a priori likelihood for b. Typically,
L(M |b) is normal and one assumes a ﬂat prior on b.

In the case where s = 50, L(b) is a normal distribu-
tion with mean µ = M0 = 100 and standard deviation
σ = ∆M0 = 5, one must observe 161 events to claim a
discovery. Initially, one might think that 161 is quite
close to 167; however, they diﬀer at the 4% level and

4

PhyStat2003, SLAC, September 8-11

the methods are only considering a ∆ = 5% eﬀect.
Still worse, if H0 is true (say bt = 100) and one can
claim a discovery with the Cousins-Highland method
(x0 > 161), the chance that one could not claim a dis-
covery with the fully frequentist method (x0 < 167)
is ≈ 95%. Similarly, if H1 is true and one can claim
a discovery with the Cousins-Highland method, the
chance that one could not claim a discovery with the
fully frequentist method is ≈ 50%. Even practically,
there is quite a diﬀerence between these two methods.

8. The Ratio of Poisson Means

During the conference, J. Linnemann presented re-
sults on the ratio of Poisson means.
In that case,
one considers a background and a signal process, both
with unknown means. By making “on-source” (i.e.
x) and “oﬀ-source” (i.e. M ) measurements one can
If
form a conﬁdence interval on the ratio λ = s/b.
the 100(1 − α)% conﬁdence interval for λ does not in-
clude 0, then one could claim discovery. This approach
does take into account uncertainty on the background;
however, it is restricted to the case in which L(M |b)
is a Poisson distribution.

There are two variations on this technique. The
ﬁrst technique has been known for quite some time
and was ﬁrst brought to physics in Ref. [6]. This ap-
proach conditions on x+M , which allows one to tackle
the problem with the use of a binomial distribution.
Later, Cousins improved on these limits by removing
the conditioning and considering the full Neyman con-
struction [7]. Cousins paper has an excellent review
of the literature for those interested in this technique.

However, Monte Carlo sampling the nuisance param-
eters does not suﬀer from the curse of dimensionality
and serves as a more robust approximation of the full
construction than the proﬁle method.

10. Conclusion

We have presented a fully frequentist method for
hypothesis testing. The method consists of a Ney-
man construction in each of the nuisance parame-
ters, their corresponding auxiliary measurements, and
the test statistic that was originally used to test H0
against H1. We have chosen as an ordering rule the
likelihood ratio with the nuisance parameters con-
ditionally maximized to their respective hypotheses.
With a slight modiﬁcation, this ordering rule produces
tests that are approximately similar. We have com-
pared this method to the most common methods in
the ﬁeld. This method is philosophically more sound
than the Cousins-Highland technique and more gen-
eral than the ratio of Poisson means. This method
can be made computationally less intensive either with
Monte Carlo sampling of the nuisance parameters or
by the approximation known as the proﬁle method.

Acknowledgments

This work was supported by a graduate research fel-
lowship from the National Science Foundation and US
Department of Energy Grant DE-FG0295-ER40896.
The author would like to thank L. Lyons, R.D.
Cousins, and G. Feldman for useful feedback.

9. The Proﬁle Method

References

As was mentioned in Section 3 the likelihood ratio
in Eq. 4 is independent of the nuisance parameters.
If it were not for the violations in similarity between
tests, one would only need to perform the construc-
tion for one value of the nuisance parameters. Clearly,
ˆˆθs is an appropriate choice to perform the construc-
tion. This is the logic behind the proﬁle method. It
should be pointed out that the proﬁle method is an ap-
proximation to the full Neyman construction; though
a particularly good one. In the example above with
x0 = 167, M0 = 100, the construction would be made
ˆˆb = 117 which gives the identical result as the

at b =
fully frequentist method.

The main advantage to the proﬁle method is that
of speed and scalability.
Instead of performing the
construction for every value of the nuisance param-
eters, one must only perform the construction once.
For many variables, the fully frequentist method is
not scalable if one na¨ively loops over on a ﬁxed grid.

[1] J.K Stuart, A. Ord and S. Arnold. Kendall’s Ad-
vanced Theory of Statistics, Vol 2A (6th Ed.). Ox-
ford University Press, New York, 1994.

[2] Gary J. Feldman and Robert D. Cousins. A uni-
ﬁed approach to the classical statistical analysis of
small signals. Phys. Rev., D57:3873–3889, 1998.
[3] J. Feldman, Gary. Multiple measurements and pa-
rameters in the uniﬁed approach, 2000. Workshop
on Conﬁdence Limits, FermiLab.

[4] Search for the standard model Higgs boson at LEP.

Phys. Lett., B565:61–75, 2003.
[5] R.D. Cousins and V.L. Highland.

Incorporating
systematic uncertainties into an upper limit. Nucl.
Instrum. Meth., A320:331–335, 1992.

[6] F. James and M. Roos. Errors on ratios of small
numbers of events. Nucl. Phys., B 172:475–480,
1980.

[7] R.D. Cousins. Improved central conﬁdence inter-
vals for the ratio of Poisson means. Nucl. Instrum.
and Meth. in Phys. Res., A 417:391–399, 1998.

WEMT004

