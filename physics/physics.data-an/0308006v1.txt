3
0
0
2
 
g
u
A
 
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
6
0
0
8
0
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Maximum Entropy method with non linear
moment constraints: challenges

M. Grendar, Jr. and M. Grendar

Institute of Mathematics and Computer Science of Mathematical Institute of Slovak Academy of
Sciences (SAS) and of Matej Bel University, Severn´a ulica 5, 974 00 Bansk´a Bystrica, Slovakia &
Institute of Measurement Science of SAS, D´ubravsk´a cesta 9, 841 04 Bratislava, Slovakia.
umergren@savba.sk

Abstract. Traditionally, the Method of (Shannon-Kullback’s) Relative Entropy Maximization (REM) is
considered with linear moment constraints. In this work, the method is studied under frequency moment
constraints which are non-linear in probabilities. The constraints challenge some justiﬁcations of REM since a)
axiomatic systems are developed for classical linear moment constraints, b) the feasible set of distributions which
is deﬁned by frequency moment constraints admits several entropy maximizing distributions (I-projections),
hence probabilistic justiﬁcation of REM via Conditioned Weak Law of Large Numbers cannot be invoked.
However, REM is not left completely unjustiﬁed in this setting, since Entropy Concentration Theorem and
Maximum Probability Theorem can be applied.

Maximum R´enyi/Tsallis’ entropy method (maxTent) enters this work because of non-linearity of X-frequency
moment constraints which are used in Non-extensive Thermodynamics. It is shown here that under X-frequency
moment constraints maxTent distribution can be unique and diﬀerent than the I-projection. This implies that
maxTent does not choose the most probable distribution and that the maxTent distribution is asymptotically
conditionally improbable. What are adherents of maxTent accomplishing when they maximize R´enyi’s or Tsallis’
entropy?

1 INTRODUCTION

requirements on Π and n.

.
→ ∞

Let Π be a set of empirical probability mass func-
tions (types) which are deﬁned on m-element sup-
port and which can be based on random samples of
size n. Let the supposed source of the types be prob-
ability mass function q. A problem (from category of
ill-posed inverse problems) of recovering probability
distribution from Π amounts to selection of type(s)
from Π, in particular when n

The problem (called hereafter Boltzmann-Jaynes
Inverse Problem, BJIP) can be met
in many
branches of science, ranging from Statistical Physics
(where it originated) to Computer Tomography. Sev-
eral approaches to the problem can be found in the
literature. While most of them are tailored to needs
of the particular branch of science, the method of
(Shannon-Kullback’s) Relative Entropy Maximiza-
tion (REM) is considered as the general solution to
the problem by mathematicians. Arguments which
justify application of REM for selection of distribu-
tion from Π in BJIP range from axiomatic, through
probabilistic and game-theoretic to pragmatic, and
others. As rule, in order to be valid they put certain

So far, most of the REM-justifying work concen-
trated on the case of Π deﬁned by the usual linear
moment constraints. Such Π possesses the attractive
property of convexity, which thanks to concavity of
the Shannon-Kullback’s entropy implies uniqueness
of REM-selected distribution (called I-projection of
q on Π, in the Information Theory). Linearity of the
constraints lays behind the well-known exponential-
ity of the I-projection.

As [35] indicates, so-called frequency moment con-
straints appear rather naturally in several places
in Physics. Frequency moments are non-linear in
probabilities and the feasible set Πf which they de-
ﬁne is non-convex. Due to the non-linearity and
a symmetry of the constraints, there are multi-
ple I-projections of q on Πf. The non-linearity of
moments, non-convexity of the feasible set, non-
exponentiality of recovered distribution and its non-
uniqueness challenge several justiﬁcations of REM.
Two of the most widely employed REM-justifying
arguments: axiomatizations and Conditioned Weak
Law of Large Numbers cannot be invoked in this set-
ting since axiomatic systems are developed for lin-

ear constraints and CWLLN requires assumption of
uniqueness of I-projection. Is there then any reason
to select the most entropic distribution from Πf?
Yes, since Entropy Concentration Theorem (ECT)
and Maximum Probability Theorem (MPT) can be
readily used to justify MaxEnt also in this case.
Though MPT was originally stated with unique I-
projection in mind, the Theorem can be instantly
extended also to the case of multiple I-projections.
The frequency moment constraints can be viewed
as a special case of Tsallis’ (cf. [37]) or MNNP (cf.
[39], [32]) constraints which are used in ’hot topic’
Non-extensive Thermodynamics (NET). The con-
straints are as well non-linear in probabilities. NET
has arisen from Tsallis’ prescription to select from
set which the constraints deﬁne such a distribution
which maximizes Tsallis’ entropy. Thus, in this area
REM was displaced (or generalized, if you wish) by
maximization of Tsallis’ entropy. Besides axiomatic
justiﬁcations (which are based on extensions of those
of REM) and declared success of maxTent in mod-
eling power-law phenomena (which allegedly REM
cannot model), there is however yet no probabilistic
justiﬁcation of the method.

The paper is organized as follows: First, the nec-
essary terminology and notation is set down. Then
probabilistic justiﬁcations of REM: CWLLN, ECT
and MPT are reviewed from perspective of their
applicability in the case of multiple I-projections.
Maximum Probability Theorem is stated in the gen-
eral form which covers the situation of multiple I-
projections. Also, applicability of other justiﬁcations
is brieﬂy discussed. Next we turn to the simplest
of non-linear moment constraints: frequency mo-
ment constraints and note that I-projection on Πf
is non-unique and non-exponential. Frequency mo-
ments constraints are then used to provide an il-
lustration for the general form of Maximum Proba-
bility Theorem. Next, Tsallis’ and R´enyi’s entropies
are introduced, and it is noted that under frequency
moment constraints maximization of R´enyi-Tsallis’
entropy (maxTent) selects no distribution. Under
MNNP constraints it does, but as it will be shown,
the maxTent-selected distribution can be unique but
diﬀerent than the I-projection. Consequences of this
ﬁnding for maxTent are discussed. Concluding com-
ments sum up the paper and point to further con-
siderations. Appendix describes a method for ﬁnding
I-projections on Πf.

2 TERMINOLOGY AND
NOTATION

Let X , {x1, x2, . . . , xm} be a discrete ﬁnite set called
support, with m elements and let {Xl, l = 1, 2, . . . , n}
be a sequence of size n of identically and indepen-
dently drawn random variables taking values in X.
A type ν , [n1, n2, . . . , nm]/n is an empirical
probability mass function which can be based on se-
quence {Xl, l = 1, 2, . . . , n}. Thus, ni denotes number
of occurrences of i-th element of X in the sequence.
Let P(X) be a set of all probability mass functions

(pmf’s) on X. Let Π

P(X).

⊆

Let the supposed source of the sequences (and
P(X), called (prior)

hence also of types) be q
generator.

∈

n!

∈

∈

∈

∈

⊆
A|ν

i=1 qni

Π, ie. π(ν

Let π(ν) denote the probability that q will gener-
n1! n2! ... nm! Qm
i . Then,
A) denotes the probability that q will gen-

ate type ν, ie. π(ν) =
π(ν
erate a type ν which belongs to A
∈
A) = Pν∈A π(ν). Finally, let π(ν
Π) denote
the conditional probability that if q generates type
Π then the type belongs to A. It is assumed that
ν
the conditional probability exists.
I-projection ^p of q on set Π
I(^p
k

P(X) is such
q), where1
^p
∈
I(p
I-
is
k
divergence is known under various other names:
Kullback-Leibler’s distance, KL number, Kullback’s
directed divergence, etc. When taken with minus
sign it is known as (Shannon-Kullback’s) relative
entropy.

Π that
q) , PX pi log pi
qi

⊆
q) = inf p∈Π I(p
k

I-divergence.

the

General framework of this work is established by

Boltzmann-Jaynes inverse problem (BJIP)2:

Let there be a set Π

P(X) of types which are
⊆
deﬁned on m-element support X and which can be
based on random samples of size n. Let the supposed
source of the random samples (and thus also types)
be q. BJIP amounts to selection of speciﬁc type(s)
from Π when information {X, n, q, Π} is supplied.

2

1/3

Example 1: Let n = 6, X = [1

3], q =
[1/3
1/3] and let the feasible set com-
prise all such types which have probability of
ie. Π =
one of the support-points equal to 2/3,
{[2/3 1/6 1/6], [2/3 1/3 0], . . . } where the dots stand
for the remaining 7 permutations of the two listed
types. Given the information {n, X, q, Π} the BJIP
task is to select a type from the set Π.

♦

, log b

0 = +

1 There, log 0 = −
) = 0, conventions
are assumed. Throughout the paper log denotes the natural
logarithm.
2 Equivalently the framework could be phrased as a problem
of induction (or updating), cf. [21].

, 0· (±

∞

∞

∞

If Π contains more than one type (as it is the case
in the above Example), the BJIP becomes under-
determined and in this sense ill-posed.

3 JUSTIFICATIONS OF REM

3.1 Conditioned Weak Law of Large
Numbers

A result of the Method of Types, which was devel-
oped in the Information Theory (cf. [11]), provides
a probabilistic justiﬁcation for application of REM
method for solving BJIP, when n tends to inﬁnity
and Π has certain properties. The result is usually
known as Conditioned Weak Law of Large Numbers
(CWLLN), or as Gibbs conditioning principle (in
large deviations literature, see [14], [12]). The ar-
gument shows (loosely speaking) that any type from
Π which is generated by q and is not close (in L1-
norm) to the I-projection of q on Π becomes condi-
tionally improbable to come from q as sample size
grows large. To establish this result (cf. [45], [44],
[22], [9], [7], [28], [29], [30]) assumption of unique-
ness of I-projection is needed.

(CWLLN) Let ^p be unique I-projection of q on

Π. Let q /
∈

Π. Then for any ǫ > 0

lim
n
→ ∞

π (|νi − ^pi| > ǫ | ν

Π ) = 0

i = 1, 2, . . . , m

∈

(1)

Well-studied is the case of closed, convex Π, which
ensures uniqueness of I-projection, provided that it
exists (cf. [9], and [28], [29], [30] for further devel-
opments). As it is well-known, in this case the I-
projection belongs to the exponential family of dis-
tributions (see [8]).

3.3 Maximum Probability Theorem

Maximum Probability Theorem (MPT), which
was originally (see [16], Thm 1.) stated with unique
I-projection in mind, claims that the type ^ν in Π
which the (prior) generator q can generate with the
highest probability converges to the I-projection of
q on Π, as n
. However proof of the Theorem
(cf. [16]) covers more general situation of multiple
I-projections and thus allows to state MPT in the
following general form:

→ ∞

(MPT) Let q be a generator. Let diﬀerentiable

constraint F(ν) = 0 deﬁne feasible set of types Πn
⊆
Π and let Π , {p : F(p) = 0} be the corresponding
feasible set of probability mass functions. Let ^νj ,
arg maxν∈Πn π(ν), j = 1, 2, . . . , l, be types which have
among all types from Πn the highest probability of
coming from the generator q. Let there be k I-
projections ^p1, ^p2, . . . , ^pk of q on Π. And let n
.
→ ∞
Then l = k and ^νj = ^pj for j = 1, 2, . . . , k.

It should be noted that MPT argument implies
that REM is only a special, asymptotic form of
simple and self-evident method (called Maximum
Probability method (MaxProb) at [16]) which seeks
in Π such types which the generator q can generate
with the highest probability. Thus applicability of
REM in BJIP is inherently limited to the case of
suﬃciently large n.

Also, it is worth noting that a bayesian interpre-
tation can be given to MaxProb, which thanks to
MPT carries over into REM/MaxEnt (cf. [21]).

From the perspective of the current work, it is
important that the MPT holds also when the feasible
set admits multiple types with the highest value of
the probability ^π. An illustration of the convergence
of most probable types to I-projections will be given
in the Section 4, where such a set is determined by
frequency moment constraints.

3.2 Entropy Concentration Theorem

3.4 Axiomatic systems

Without the assumption of uniqueness of the I-
projection, a claim known as the Entropy Concen-
tration Theorem (ECT), weaker than (1), can be still
made (see [7]):

P(X) be nonempty. Let ^I be such
Π. Then for any ǫ > 0

q) for any ν

⊆

that ^I

(ECT) Let Π
I(ν
k
lim
n
→ ∞

π (cid:0)(cid:12)
(cid:12)

≤

∈
q) −^I(cid:12)
(cid:12)

I (ν
k

< ǫ | ν

Π(cid:1) = 1

(2)

∈

Assumption (of whatever form) which guarantees
existence and uniqueness of the I-projection is cru-
cial for coming from statement (2) to the stronger
claim (1).

Besides the probabilistic arguments several ax-
iomatic approaches were developed to support max-
imization of Shannon’s entropy or relative entropy
as the only logically consistent method for solving
BJIP3. However, it should be noted that maximiza-
tion of R´enyi’s entropy was as well found to sat-
isfy some of the axiomatic systems, which had been

3 Strictly speaking, the axiomatizations assume BJIP with
either n unknown or n bigger than any limit. They seem to
be inappropriate for BJIP with ﬁnite sample size.

developed to justify REM (see [42]). For purposes
of the presented work it is suﬃcient to note that
the axiomatic system (cf. [10]) which is perhaps the
most widely accepted requires assumption of linear-
ity of the constraints (or, in general, convexity of
Π). A non-axiomatic argument based on potential-
probability density relationship and a complemen-
tarity (cf. [18]) is restricted to the linear constraints
as well. Also a game-theoretic view of REM (see [23])
assumes the linear constraints.

To sum up: When Π admits several I-projections
the justiﬁcations of REM which are readily avail-
able reduce to Entropy Concentration Theorem and
Maximum Probability Theorem.

4 FREQUENCY MOMENT
CONSTRAINTS

This study was triggered by an interesting paper by
Romera, Angulo and Dehesa (cf. [35]) on frequency
moment problem. There also links to statistical con-
siderations of the frequency moments as well as to
their applications in Physics can be found.

i=1 pα

i − a = 0, Pm

In the simplest case of single frequency moment
constraint, feasible set of types is deﬁned as Πf , {p :
Pm
R.
If m > 2, the problem of selection of type becomes
= 1
ill-posed. Note that the ﬁrst constraint is for α
non-linear in p and Πf is non-convex.

i=1 pi − 1 = 0}, where α, a

∈

4.1 I projection: non uniqueness and
non exponentiality

It is straightforward to observe that I-projection
of q on Πf possesses a symmetry, in the sense that
if certain ^p is I-projection of q on Πf then any
permutation of the vector ^p should necessarily be
also I-projection.

Within this Section q will be assumed uniform (for
a reason which is implied by discussion at Section
5.1), denoted u. Note that when uniform generator
is assumed, the method of Relative Entropy Max-
imization reduces to Maximum Shannon’s Entropy
method (abbreviated usually MaxEnt).

The non-convexity of feasible set makes the prob-
lem of maximization of Shannon’s entropy analyti-
cally unsolvable. Critical value of pi is expressed as:
pi(λ) = k(λ)e−λαpα−1
, where k(λ) = P e−λαpα−1
.
Note that the expression is explicitly self-referential.
Thus, the I-projections should be searched out
either numerically or by a method which is described
at the Appendix.

i

i

4.2 MaxProb justiﬁcation of REM: multiple
I projections

That the most probable types indeed converge
to the corresponding I-projections as the general
form Maximum Probability Theorem states will be
illustrated by the following Example.

Example 2: Let α = 2, X = [1 2 3], m = 3 and
a = 0.42 (the value was obtained for p = [0.5 0.4 0.1]).
For n = 10, 30, 330, 1000, 2000 the feasible sets Πf
were constructed. For example, Πf,10 contains ν =
[5 4 1]/10 and all its permutations (ie. [5 1 4]/10,
etc). This will be called group of types. Πf,30 con-
tains two groups: [15 12 3]/30 and [17 8 5]/30.
The last one has higher probability of coming from
uniform prior generator. For n = 330 the feasi-
ble set comprises groups [0.0939 0.4333 0.4727],
[0.5666 0.2666 0.1666], [0.1 0.4 0.5] and the group
[0.1939 0.2333 0.5727], which has the highest prob-
ability of being generated by u.

For each n, among the feasible types, the most
probable ^ν which could be drawn from the uniform
prior generator was picked up. They are stated at the
Table 1 together with a corresponding I-projection
of u on Πf.

TABLE 1. The most probable
type, for growing n.

n

10
30
330
1000
2000

^p

^ν|u

0.4
0.266
0.2333
0.2280
0.2185

0.5
0.566
0.5727
0.5730
0.5735

0.1
0.166
0.1939
0.1990
0.2080

0.2131

0.2131

0.5737

Clearly, the most probable type (hence also the
whole permutation group of 6 most probable types)
converges to the pmf (permutation group of 3 pmf’s)
♦
which maximizes Shannon’s entropy.

4.3 maxTent: no selection

At this point, both R´enyi’s and Tsallis’ entropies
will be introduced. R´enyi’s entropy (cf. [36], [34]) is
1−α log (cid:0)Pm
deﬁned as HR(p) , 1
R,
α

= 1.
Tsallis’ entropy HT (cf. [24], [43], [37]) is linear ap-
i=1 pα
,

proximation of R´enyi’s entropy: HT (p) , 1−P
where α

i (cid:1), where α

i=1 pα

R, α

= 1.

α−1

∈

m

i

R´enyi’s entropy attains its maximum at the same
pmf as does Tsallis’ entropy. Thus, hereafter max-
Tent will denote both method of maximum R´enyi’s
and Tsallis’ entropy at once. maxTent will be dis-

∈

6
6
6
cussed in greater detail in Section 5. Here it suf-
ﬁces to note that in the set Πf which is deﬁned by
the frequency moment constraint each type has the
same value of R´enyi’s (or Tsallis’) entropy. In other
words, maxTent refuses to make a choice from Πf.
Recall that MaxEnt selects I-projections, and ECT
implies that types conditionally concentrate on the
I-projections in such a way, that as n gets large
there is virtually no chance to ﬁnd a type which has
value of Shannon’s entropy diﬀerent than the maxi-
mal one. MPT complements it by stating that most
probable types turn into the I-projections, as n goes
to inﬁnity.

5 X FREQUENCY MOMENT
CONSTRAINTS

Frequency moment constraints can be viewed as a
special case of non-linear constraints which were
originally introduced into Statistical Mechanics by
Tsallis (see [37]). Tsallis’ constraints deﬁne feasi-
ble set ΠT as follows: ΠT , {p : Pm
i xi − a =
0, Pm

i=1 pi − 1 = 0}.

i=1 pα

Tsallis’ constraints were for Physics reasons su-
perseded by TMP constraints (see [39]). Later on,
the TMP constraints were rearranged by Mart´ınez,
Nicol´as, Pennini and Plastino [32] in MNPP form
which allows for simpler analytic tractability. The
TMP constraints in MNNP form specify feasible set
as Πτ , {p : Pm
i=1 pi − 1 = 0}. A
probability mass function (pmf) from Πτ at which
Tsallis’ (or R´enyi’s) entropy attains its maximum
will be called τ-projection.

i (xi − b) = 0, Pm

i=1 pα

Since an argument which is presented at Section
5.4 is valid both for Tsallis’ constraints and MNNP
constraints, both they will be referred hereafter as
X-frequency moment constraints.

5.1 maxTent: backward compatibility with
MaxEnt

Non-extensive Thermodynamics

(NET) pre-
scribes to use maximization of Tsallis’ entropy for
the pmf selection when the feasible set is deﬁned
by X-frequency constraints. As it was already men-
tioned, the distributions selected by maximization
of Tsallis’ entropy is the same as that by R´enyi’s
entropy maximization. Though it is not our con-
cern here,
for completeness it should be noted
that R´enyi’s entropy is extensive (additive) whilst
Tsallis’ one is not, and that the ’world according

to R´enyi’ has diﬀerent properties than the ’world
according to Tsallis’ (see [26]).

Maximization of R´enyi-Tsallis’ entropy under X-
frequency constraints satisﬁes the elementary re-
quirement of backward compatibility with MaxEnt:
when X-frequency constraints reduce to the classic
linear moment constraints, the Tsallis’ entropy re-
duces to Shannon’s one (it happens for α
1). In
relation to this, it should be noted that maximiza-
tion of Shannon’s entropy is from the point of view
of probabilistic justiﬁcations just a special case (uni-
form q) of Relative Entropy Maximization. However
no relative form of Tsallis’ entropy was yet consid-
ered by adherents of NET. For this reason in our con-
siderations general prior distribution q is replaced
by uniform one, u.

→

5.2 MaxEnt: non exponentiality
maxTent: power law

i

Maximization of Shannon’s entropy under MNNP
form of X-frequency moment constraints by La-
grange multiplier technique leads to pmf which is
of implicit and self-referential form, only: pi(λ)
∝
e−λα(xi−b)pα−1
. Whether it is the I-projection and
whether it is unique cannot be analytically assessed.
Under MNNP constraints, maximization of R´enyi-
Tsallis’ entropy by means of Lagrangean leads to
the ﬁrst order conditions for extremum which are
solved by a pmf of power-law form: pi(λ)
(1 +
λxi(α − 1))1/(1−α) (see [32]). It is important to note,
that the candidate pmf could be a (local/global)
maximum only if α > 0 and if 1 + λxi(α − 1) > 0 for
all i = 1, 2, . . . , m. The latter requirement, known as
Tsallis’ cut-oﬀ condition, should be checked on the
case-by-case basis.

∝

5.3 Generalized entropies and BJIP

Non-shannonian forms of entropies have been
around for long time. Some of them fall into category
of convex statistical distances, and their mathemati-
cal properties are well-studied (cf. [31]). Also, exten-
sions and modiﬁcations of axiomatic systems which
lead to non-shannonian entropies were studied (see
[3]). Some of the ’new’ entropies were found useful,
some not (cf. [2]). As far as R´enyi’s entropy is con-
cerned few its ’operational characterizations’ were
developed in the Information Theory (cf. [1] and lit-
erature cited therein). Little seems to be known how-
ever about its probabilistic justiﬁcation in context
of the ill-posed inverse problems. In particular, it is

not known what is the probabilistic question that
maxTent answers. Neither it is known, whether the
unknown question which maxTent answers is mean-
ingful to ask within the context of BJIP.

5.4 MaxEnt vs. maxTent

maxTent method is by adherents of NET pre-
sented as a generalization of MaxEnt. The general-
ization extends MaxEnt in two directions: Shannon’s
entropy is generalized into the Tsallis’ entropy, and
the traditional linear moment constraints are gen-
eralized into non-linear either Tsallis’ constraints or
MNNP constraints. Though there can be no objec-
tion made to generalization of constraints, rather
vague arguments (see for instance Introduction of
[40]) were advanced to explain why maximization of
Shannon’s entropy should be under the X-frequency
constraints replaced by maximization of Tsallis’ en-
tropy to select a distribution from the feasible set
which the constraints deﬁne.

Conditioned Weak Law of Large Numbers (or
Gibbs conditioning principle), Entropy Concentra-
tion Theorem and Maximum Probability Theo-
rem provide probabilistic justiﬁcation of REM (and
hence also of MaxEnt) method (though adherents
of maxTent might failed to note it, see [41]). As
it was discussed here, ECT and MPT can be read-
ily used also under any non-linear constraints, and
hence the two Theorems give justiﬁcation to applica-
tion of REM/MaxEnt also under Tsallis’ or MNNP
constraints. Thus, when n is suﬃciently large (which
is indeed the case in Statistical Mechanics), anybody
who chooses from the feasible set which is deﬁned
by say MNNP constraints the I-projection(s) can be
sure 1) that (any of) the I-projection is just such a
type in the feasible set which can be drawn from q
with the highest probability when n goes to inﬁnity
(recall MPT), and moreover that 2) any type which
has not value of the relative entropy close to the
maximal value which is attainable within the fea-
sible set is asymptotically conditionally improbable
(recall ECT).

In an interesting paper [27] which for the ﬁrst time
exposed maxTent to a criticism from a probabilistic
point of view, La Cour and Schieve derived neces-
sary conditions for agreement of I- and τ-projections
under MNNP constraints. Also, the authors illus-
trated by means of speciﬁc example (α = 1/2, m = 3,
X = [1 2 3] and a = 7/11) that τ-projection can
be diﬀerent than I-projection. Provided that the I-
projection is unique, one can safely recall CWLLN
to conclude that maxTent-selected τ-projection on

Πτ is asymptotically conditionally improbable. How-
ever, the issue of uniqueness or non-uniqueness of I-
projection on Πτ is to the best of our knowledge not
settled yet.

A diﬀerent argument is used here to show that
maxTent can select asymptotically conditionally im-
probable distribution under X-frequency constraints.
The argument is based on observation that by a
choice of support points of the random variable X
the feasible set of distributions Πτ can be made con-
vex (the same can be done with ΠT ). Convexity of
Πτ guarantees uniqueness of I-projection. Provided
that α > 0 (which implies concavity of Tsallis’ en-
tropy) the τ-projection on the convex Πτ is as well
unique. Both I-projection and τ-projection can be
then found out by straightforward analytic maxi-
mization. Since the two are (except of trivial cases)
diﬀerent, CWLLN implies that the one chosen by
maxTent has asymptotically zero conditional prob-
ability.

The next Example illustrates the argument.
Example 3: Let Πτ = {p : P3

i (xi − b) =
0, P3
i=1 pi − 1 = 0}. Let X = [−2 0 1] and let b = 0.
Then Πτ = {p : p2
1, P pi − 1 = 0} which eﬀec-
tively reduces to Πτ = {p : p2 = 1 − p1(1 + √2), p3 =
√2p1}. Prior generator q is assumed to be uniform
u.

3 = 2p2

i=1 p2

is

The

feasible

set Πτ

convex. Thus

I-
projection ^p of u on Πτ is unique, and can be
found by direct analytic maximization to be
^p = [0.2748 0.3366 0.3886]. Straightforward max-
imization of R´enyi-Tsallis’ entropy lead to unique
τ-projection ^pT = [0.2735 0.3398 0.3867], which is
♦
diﬀerent than ^p.
The ﬁnding that τ-projection can be asymptoti-
cally conditionally improbable prompts Jaynes ques-
tion: What are adherents of maxTent accomplishing
when they maximize R´enyi-Tsallis’ entropy?

6 CONCLUDING COMMENTS

Frequency moment constraints, which are the sim-
plest of non-linear constraints, were employed in this
work to deﬁne feasible set of types Πf for Boltzmann-
Jaynes Inverse Problem. Non-linearity of the fre-
quency constraints implies non-convexity of the fea-
sible set, and together with their symmetry also non-
uniqueness of I-projection. Moreover, because of the
non-linearity, I-projections of q on the feasible set

Πf do not take the canonical exponential form4.

The non-linearity, non-convexity, non-uniqueness
and non-exponentiality revealed limitations of sev-
eral
justiﬁcations of the REM/MaxEnt method.
However, REM is not left completely unjustiﬁed in
this non-traditional setup, since two justiﬁcations
of REM are provided by Entropy Concentration
Theorem and Maximum Probability Theorem. Thus
though REM under frequency constraints loses two
of its charming properties: uniqueness and exponen-
tiality of I-projection, its application within the cor-
responding BJIP remains justiﬁed by the two The-
orems. One of the primary aims of this work was to
give a general (multiple I-projection) formulation of
Maximum Probability Theorem and provide its il-
lustration. At the same time the work was intended
to serve as an invitation to the challenging world
of non-linear constraints which shake several tradi-
tional views of REM/MaxEnt5.

Maximum R´enyi/Tsallis’ entropy method (max-
Tent) was considered here mainly because of the
non-linearity of the constraints which are used in
Non-extensive Thermodynamics (NET). As it was
shown (see Sect. 5), under the constraints max-
Tent can select a distribution which is according
to CWLLN asymptotically conditionally improba-
ble. This ﬁnding prompts Jaynes question: What
are adherents of maxTent accomplishing when they
maximize R´enyi-Tsallis’ entropy? When it will be
answered, maxTent could enter the tiny class of en-
tropies for which the answer is known and which
can thus be consciously applied for distribution se-
lection.

ACKNOWLEDGEMENTS

Hospitality of Banach Centre (BC) of the Institute of
Mathematics of Polish Academy of Sciences, where a
part of this study was performed as a part of the Eu-

4 It obviously does not mean that they cannot be ex post
brought into the canonical exponential
form. Any vector
of non-negative numbers which add up to one is MaxEnt
canonical distribution, recall [5], Thm. 4.1.
5 In particular, they call for reconsideration of CWLLN. The
law states that types conditionally concentrate on the I-
projection, provided that the last is unique. What if Π admits
several I-projections? Do types concentrate on each of the I-
projections? If yes, what is the proportion? Answers to these
questions were given elsewhere (see [20]). There a Theorem
which extends CWLLN to the case of multiple I-projections
was stated, proven and illustrated. In order to leave the reader
chance to appreciate extent of the challenges which non-linear
constraints pose to justiﬁcations of REM/MaxEnt the present
paper was intentionally written as if the answers to these
questions were not known.

ropean Community Center of Excellence programme
(package ’Information Theory and its Applications
to Physics, Finance and Biology’) is gratefully ac-
knowledged. The work was also supported by the
grant VEGA 1/0264/03 from the Scientiﬁc Grant
Agency of the Slovak Republic.

It is a pleasure to thank Brian R. La Cour for
very valuable discussions and comments on [19]. The
thanks extend also to Aleˇs Gottvald, George Judge,
Jonathan D. H. Smith and Viktor Witkowsk´y.

APPENDIX

Observe, that any of the three I-projections at the
Example 2 (Section 4.2) has two of probabilities
equal. This can be elucidated by the following el-
ementary considerations: suppose that the feasible
set is constrained further by additional requirement
p1 = p2 = p3. This additional requirement makes
p0 = [1/3 1/3 1/3] the only pmf in the set. Clearly,
a0 = 1/3,
the pmf is indeed in the set only if a
ie. the ’centre of mass’ of P3
= a0 then
p0 is not in Πf, hence the most entropic pmf should
be searched among those pmf’s which have two of
probabilities equal; say p1 = p2.

≡
i . If a

i=1 p2

The additional requirement turns the under-deter-
mined conditions into a quadratic equation which is
solved by either p1 = 0.2131 or p1 = 0.4535. Hence
the restricted feasible set comprises two groups of
pmf’s [0.2131 0.2131 0.5737] and [0.4535 0.4535
0.0930]. The ﬁrst pmf has Shannon’s entropy HU =
0.9777, the second HL = 0.9381. It does not surprise
that pmf’s from the original set Πf (ie. those which
can have all three probabilities diﬀerent) have Shan-
non’s entropy within the bounds which are set up by
HL and HU.

This is obviously, not a property speciﬁc to the
studied example with the particular choice of α = 2
and m = 3. In general, the ﬁnding permits to state
the following

Proposition Let q be uniform, Πf , {p : P pα

i −
a = 0, P pi − 1 = 0}, where p
Z. Let
∈
H(^p) for
m > α. Then ^p
= ^pm−1,
any p
where ^p1 is one of solutions of the following algebraic
equation:

∈
Πf such that H(p)
Πf, is such that ^p1 = ^p2 =

Rm and α

≤
· · ·

∈

∈

(m − 1)^pα

1 + (1 − (m − 1)^p1)α − a = 0

(3)

Note: Clearly, among the pmf’s which solve equa-
tion (3), ^p is the one with the highest value of Shan-
non’s entropy H. Any permutation of ^p is also I-
projection of u on Πf.

6
BIBLIOGRAPHIC NOTE

Literature on Tsallis’ maximum entropy method is
vast (cf. [38]). arXiv contains a series of preprints
which document evolution of the method. Also, see
March 2002 issue of Chaos, Solitons and Fractals.
Interesting introductory remarks on NET can be
found at [6]. Critical voices are rare: besides the
fundamental [27] see for instance also [15], [46]. This
work draws on and corrects [19].

July 2002, May-July 2003

REFERENCES

1. Arikan E., IEEE Trans. IT, 42, No 1, pp. 99-105,

(1996).

2. Acz´el, J., Aequa. Math., 27, 1-19, (1984).
3. Acz´el, J., and Dar´oczy, Z., On Measures of

Information and Their Characterizations, Academic
Press, New York, (1975).

4. Anteneodo, C. and Plastino, A. R., J. Phys. A 32,

1089, 1999.

5. Athreya, K. B. and Smith, J. D. H., Disc. Math.

Prob. Stat., 20, 167-176, (2000).

6. Cohen, E. G. D., “Some recent advances in classical
statistical mechanics,” in LNP 597, P. Garbaczewski
and R. Olkiewicz (eds.), pp. 7–33, Springer-Verlag,
Berlin, (2002).

7. Cover, T. and Thomas, J., Elements of Information

Theory, Wiley, 1991.

8. Csisz´ar, I., Ann. Prob., 3, No. 1, pp. 146-158,

(1975).

9. Csisz´ar, I., Ann. Prob., 12, No. 3, 768-793, (1984).
10. Csisz´ar, I., Ann. Stat., 19, 2032 -2066, (1991).
11. Csisz´ar, I., IEEE Trans. IT, 44, No. 6, pp.

2505-2523, (1998).

12. Dembo, A and Zeitouni, O., Large Deviations

Techniques and Applications, 2-nd ed., Springer,
Application of Mathematics, vol. 38, 1998.

13. Ellis, R. S., Physica D, pp. 106-136, (1999).
14. Ellis, R. S., Entropy, Large Deviations and

Statistical Mechanics, Springer-Verlag, NY, 1985.

15. Gottvald, A., “Beyond the MaxEnt Principle:

Bayes, Fourier, Zipf and Spirals in Metamorphoses,”
Energy and Information in Non-linear Systems, A.
Gottvald (ed.), 48-51, 2000.

16. Grend´ar, M., Jr. and Grend´ar, M., “What

is the question that MaxEnt answers? A
probabilistic interpretation,” in Bayesian
inference and Maximum Entropy methods, A.
Mohammad-Djafari (ed.), 83-94, AIP, 2001. Also
arxiv.org/abs/math-ph/0009020, Sep 2000.
17. Grend´ar, M., Jr. and Grend´ar, M., Entropy, 3,

58-63, (2001).

18. Grend´ar, M., and Grend´ar, M., Jr., “Why

Maximumu Entropy? A non-axiomatich approach,”
in Bayesian inference and Maximum Entropy

methods, R. L. Fry (ed.), 375-379, AIP, 2002. Also
at arxiv.org/abs/math-ph/0212005, Dec 2002.
19. Grend´ar, M., Jr. and Grend´ar, M., “Frequency

moments inverse problem and Maximum (Shannon
vs Renyi-Tsallis) Entropy. A case study in
MaxProb,” IMPAN preprint, 2002.

20. Grend´ar, M., Jr. and Grend´ar, M., Acta U. Belii

Ser. Math., 10, pp. 3–8, (2003).

21. Grend´ar, M., Jr. and Grend´ar, M., “Maximum

Probability and Maximum Entropy methods:
Bayesian interpretation,” Technical Report IMS
SAS, July 2003.

22. Grooneboom, P., Oosterhoﬀ, J. and Ruymgaart, F.

H., Ann. Prob., 7, 553-586, (1979).

23. Harremo¨es, P. and Topsøe, F., Entropy, 3, 191-226,

24. Havrda and Charv´at, Kybernetika, 3, pp. 30-35,

(2001).

(1967).

25. Jaynes, E.T., Papers on Probability, Statistics and
Statistical Physics, R. D. Rosenkrantz (ed.), D.
Reidel, Dordrecht, 1979.

26. Jizba, P. and Arimitsu, T., “The world according
to R´enyi: thermodynamics of fractal systems,”
arxiv.org/abs/condmat/0108184, Aug 2001.

27. La Cour, B. and Schieve, W. C., Phys.
Rev. E, 62, pp. 7494-7496, (2000). Also,
arxiv.org/abs/condmat/0009216, Sep 2000.
28. La Cour, B. R. and Schieve, W. C., Jour. Stat.

Phys., 107, 3/4, pp. 729-755, (2002).

29. Leonard, Ch. and Najim, J., Bernoulli, 8, 6, pp.

721–743, (2002).

30. Lewis, J. T., Pﬁster, C.-E. and Sullivan, W. G.,
Markov Proc. Rel. Field., 1, pp. 319-386, (1995).
31. Liese, F. and Vajda, I., Convex Statistical Distances,

BSB B.G. Teubner Verlagsgesellschaft, Teubner -
Texte zur Mathematik, Band 95, Leipzig 1987.
32. Mart´ınez, S., Nicol´as, F., Pennini, F. and Plastino,
A., “Tsallis’ entropy maximization procedure
revisited,” arxiv.org/abs/physics/0003098, Dec
2000.

33. Rajagopal, A. K. and Abe, S., Chaos, Solitons and

Fractals, 13, pp. 529-537, (2002).

34. R´enyi, A., “On measures of entropy and

information,” Proc. 4th Berk. Symp. Math.
Statist. and Probl., University of California Press,
Vol. 1, 547-461, 1961.

35. Romera, E., Angulo, J. C. and Dehesa, J. S.,
“Reconstruction of a density from its entropic
moments,” Bayesian Inference and Maximum
Entropy Methods, R. L. Fry (ed.), 449-457, AIP,
2002.

36. Sch¨utzenberger, M. P., “Contribution aux

applications statistique de la th´eorie de
l’information,” Publ. Inst. Stat, U. Paris, 1954.

37. Tsallis, C., J. Stat. Phys., 52, 479, (1988).
38. Visit http://tsallis.cat.cbpf.br/biblio.htm for a

bibliography on maxTent.

39. Tsallis, C., Mendes, R. S. and Plastino, A. R.,

Physica A, 261, 534-554, (1998).
40. Tsallis, C., “Entropic nonextensiv-

ity: a possible measure of complexity,”
arxiv.org/abs/cond-mat/0010150, Oct 2000.

41. Tsallis, C. and Brigatti, E., ”Nonextensive

statistical mechanics: a brief introduction,”
arxiv.org/abs/cond-mat/0305606, May 2003.
42. Uﬃnk, J., Studies Hist. Phil. Modern Phys., 26B,

pp. 223-261, (1995).

43. Vajda, I., Theory of Statistical Inference and
Information, Dordrecht-Boston, KAP, 1989.
44. van Campenhout, J. M. and Cover, T. M., IEEE

IT, 27, 483-489, (1981).

45. Vasicek, O. A., Ann. Prob., 8, 142-147, (1980).
46. Vel´azquez, L. and Guzm´an, F.,

“Where the Tsallis statistic is valid?,”
arxiv.org/abs/condmat/0105378, May 2001.

in memory of El Mar

