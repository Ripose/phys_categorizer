Using projections and correlations to
approximate probability distributions

Dean Karlen∗
Ottawa-Carleton Institute for Physics
Department of Physics, Carleton University
Ottawa, Canada K1S 5B6
(May 7, 1998)

Abstract

A method to approximate continuous multi-dimensional probability density
functions (PDFs) using their projections and correlations is described. The
method is particularly useful for event classiﬁcation when estimates of sys-
tematic uncertainties are required and for the application of an unbinned
maximum likelihood analysis when an analytic model is not available. A sim-
ple goodness of ﬁt test of the approximation can be used, and simulated event
samples that follow the approximate PDFs can be eﬃciently generated. The
source code for a FORTRAN-77 implementation of this method is available.

8
9
9
1
 
y
a
M
 
3
1
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
8
1
0
5
0
8
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Typeset using REVTEX

∗E-mail: karlen@physics.carleton.ca

1

I. INTRODUCTION

Visualization of multi-dimensional distributions is often performed by examining single
variable distributions (that is, one-dimensional projections) and linear correlation coeﬃcients
amongst the variables. This can be adequate when the sample size is small, the distribution
consists of essentially uncorrelated variables, or when the correlations between the variables
is approximately linear. This paper describes a method to approximate multi-dimensional
distributions in this manner and its applications in data analysis.

The method described in this paper, the Projection and Correlation Approximation
(PCA), is particularly useful in analyses which make use of either simulated or control event
In particle physics, for example, such samples are used to develop algorithms
samples.
that eﬃciently select events of one type while preferentially rejecting events of other types.
The algorithm can be as simple as a set of criteria on quantities directly measured in the
experiment or as complex as an application of an artiﬁcial neural network [1] on a large
number of observables. The more complex algorithm may result in higher eﬃciency and
purity, but the determination of systematic errors can be diﬃcult to estimate. The PCA
method can be used to deﬁne a sophisticated selection algorithm with good eﬃciency and
purity, in a way that systematic uncertainties can be reliably estimated.

Another application of the PCA method is in parameter estimation from a data set
using a maximum likelihood technique. If the information available is in the form of simu-
lated event samples, it can be diﬃcult to apply an unbinned maximum likelihood method,
because it requires a functional representation of the multidimensional probability density
function (PDF). The PCA method can be used to approximate the PDFs required for the
maximum likelihood method. A simple goodness of ﬁt test is available to determine if the
approximation is valid.

To verify the statistical uncertainty of an analysis, it can be useful to create a large en-
semble of simulated samples, each sample equivalent in size to the data set being analyzed.
In cases where this is not practical because of limited computing resources, the approxima-
tion developed in the PCA method can be used, as it is in a form that leads to an eﬃcient
method for event generation.

In the following sections, the projection and correlation approximation will be described

along with its applications. An example data analysis using the PCA method is shown.

II. PROJECTION AND CORRELATION APPROXIMATION

Consider an arbitrary probability density function

(x) of n variables, xi. The basis
for the approximation of this PDF using the PCA approach is the n-dimensional Gaussian
n covariance matrix, V , by
distribution, centered at the origin, which is described by an n

P

G(y) = (2π)−n/2

−1/2 exp

V

|

|

×
2 yT V −1 y

1

(cid:17)

(cid:16)−

(1)

|

V

is the determinant of V . The variables x are not, in general, Gaussian distributed
where
so this formula would be a poor approximation of the PDF, if used directly. Instead, the PCA
method uses parameter transformations, yi(xi), such that the individual distributions for yi

|

2

are Gaussian and, as a result, the n-dimensional distribution for y may be well approximated
by Eq. (1).

The monotonic function y(x) that transforms a variable x, having a distribution function

p(x), to the variable y, which follows a Gaussian distribution of mean 0 and variance 1, is

y(x) = √2 erf

−1

(2F (x)

1)

−

where erf−1 is the inverse error function and F (x) is the cumulative distribution of x,
x

xmin p(x′) dx′
F (x) = R
xmin p(x′) dx′
R
The resulting n-dimensional distribution for y will not, in general, be an n-dimensional
Gaussian distribution. It is only guaranteed that the projections of this distribution onto
each yi axis is Gaussian.
In the PCA approximation, however, the probability density
function of y is assumed to be Gaussian. Although not exact, this can represent a good
approximation of a multi-dimensional distribution in which the correlation of the variables
is relatively simple.

(3)

xmax

.

Written in terms of the projections, pi(xi), the approximation of

(x) using the PCA

P

method is,

(2)

(4)

P (x) =

V

|

|

−1/2 exp

1

2 yT (V −1

(cid:16)−

n

I) y

−

(cid:17)

Yi=1

pi(xi)

where V is the covariance matrix for y and I is the identity matrix. To approximate the
projections, pi(xi), needed in Eqs. (3) and (4), binned frequency distributions (histograms)
of xi can be used.

The projection and correlation approximation is exact for distributions with uncorrelated
variables, in which case V = I. It is also exact for a Gaussian distribution modiﬁed by mono-
tonic one-dimensional variable transformations for any number of variables; or equivalently,
multiplication by a non-negative separable function.

A large variety of distributions can be well approximated by the PCA method. However,
there are distributions for which this will not be true. For the PCA method to yield a
good approximation in two-dimensions, the correlation between the two variables must be
If the space can be split into regions, inside of which the
the same sign for all regions.
correlation has everywhere the same sign, then the PCA method can be used on each region
separately. To determine if a distribution is well approximated by the PCA method, a
goodness of ﬁt test can be applied, as described in the next section.

The generation of simulated event samples that follow the PCA PDF is straightforward
and eﬃcient. Events are generated in y space, according to Eq. (1), and then are transformed
to the x space. The procedure involves no rejection of trial events, and is therefore fully
eﬃcient.

III. GOODNESS OF FIT TEST

Some applications of the PCA method do not require that the PDFs be particularly well
approximated. For example, to estimate the purity and eﬃciency of event classiﬁcation,

3

it is only necessary that the simulated or control samples are good representations of the
data. Other applications, such as its use in maximum likelihood analyses, require the PDF
to be a good approximation, in order that the estimators are unbiased and that the esti-
mated statistical uncertainties are valid. Therefore it may be important to check that the
approximate PDF derived with the PCA method is adequate for a given problem.

In general, when approximating a multidimensional distribution from a sample of events,
it can be diﬃcult to derive a goodness of ﬁt statistic, like a χ2 statistic. This is because
the required multidimensional binning can reduce the average number of events per bin to
a very small number, much less than 1.

When the PCA method is used, however, it is easy to form a statistic to test if a sample
of events follows the PDF, without slicing the variable space into thousands of bins. The
PCA method already ensures that the projections of the approximate PDF will match that
of the event sample. A statistic that is sensitive to the correlation amongst the variables is
most easily deﬁned in the space of transformed variables, y, where the approximate PDF is
an n-dimensional Gaussian. For each event the value X 2 is calculated,

and if the events follow the PDF, the X 2 values will follow a χ2 distribution with n degrees
of freedom, where n is the dimension of the Gaussian. A probability weight, w, can therefore
be formed,

X 2 = yT V −1 y ,

w(X 2) =

χ2(t, n) dt ,

∞

Z

X2

(5)

(6)

which will be uniformly distributed between 0 and 1, if the events follow the PDF. The
procedure can be thought of in terms of dividing the n-dimensional y space into layers
centered about the origin (and whose boundaries are at constant probability in y space) and
checking that the right number of events appears in each layer. The goodness of ﬁt test for
the PCA distribution is therefore reduced to a test that the w distribution is uniform.

When the goodness of ﬁt test shows that the event sample is not well described by the
projection and correlation approximation, further steps may be necessary before the PCA
method can be applied to an analysis. To identify correlations which are poorly described,
the goodness of ﬁt test can be repeated for each pair of variables. If the test fails for a pair
of variables, it may be possible to improve the approximation by modifying the choice of
variables used in the analysis, or by treating diﬀerent regions of variable space by separate
approximations.

IV. EVENT CLASSIFICATION

Given two categories of events that follow the PDFs

2(x), the optimal event
classiﬁcation scheme to deﬁne a sample enriched in type 1 events, selects events having the
2(x). Using simulated or control
largest values for the ratio of probabilities, R =
samples, the PCA method can be used to deﬁne the approximate PDFs P1(x) and P2(x),
and in order to deﬁne a quantity limited to the range [0, 1], it is useful to deﬁne a likelihood
ratio

1(x) and

1(x)/

P

P

P

P

4

P1(x)
P1(x) + P2(x)

.

=

L

(7)

With only two categories of events, it is irrelevant if the PDFs P1 and P2 are renormalized
to their relative abundances in the data set. The generalization to more than two categories
of events requires that the PDFs Pi be renormalized to their abundances. In either case,
each event is classiﬁed on the basis of the whether or not the value of
for that event is
larger than some critical value.

L

Systematic errors in the estimated purity and eﬃciency of event classiﬁcation can result if
the simulated (or control) samples do not follow the true PDFs. To estimate the systematic
uncertainties of the selection, the projections and covariance matrices used to deﬁne the
PCA PDFs can be varied over suitable ranges.

V. EXAMPLE APPLICATION

In this section the PCA method and its applications are demonstrated with simple anal-
yses of simulated event samples. Two samples, one labeled signal and the other background,
are generated with, x1

(0, 1), according to the distributions,

(0, 10) and x2

∈

ds(x1, x2) =

(x1

a1)2 + a2

−
a4(1 + a5x2))4 + a6)((x2

(a3(x1

−

a7)4 + a8)

−

∈

1

db(x1, x2) =

(b1(x1 + x2)2 + b2x3

2 + b3)

(8)

where the vectors of constants are given by a= (7, 2, 6, 4, 0.8, 40, 0.6, 2) and b= (0.1, 3, 0.1).
These samples of 4000 events each correspond to simulated or control samples used in the
analysis of a data set. In what follows it is assumed that the analytic forms of the parent
distributions, Eq. (8), are unknown.

The signal and background control samples are shown in Fig. 1 and Fig. 2 respectively.
A third sample, considered to be data and shown in Fig. 3, is formed by mixing a further
240 events generated according to ds and 160 events generated according to db.

The transformation given in Eq. (2) is applied to the signal control sample, which results
in the distribution shown in Fig. 4. To deﬁne the transformation, the projections shown in
Fig. 1 are used, 40 bins for each dimension. The projections of the transformed distribution
are Gaussian, and the correlation coeﬃcient is found to be 0.40. The goodness of ﬁt test,
described in section III, checks the assumption that the transformed distribution is a 2-
dimensional Gaussian. The resulting w(X 2) distribution from this test is relatively uniform,
as shown in Fig. 5.

A separate transformation of the background control sample gives the distribution shown
in Fig. 6, which has a correlation coeﬃcient of 0.03. Note that a small linear correlation
coeﬃcient does not necessarily imply that the variables are uncorrelated. In this case the
2-dimensional distribution is well described by 2-dimensional Gaussian, as shown in Fig. 5.
Since the PCA method gives a relatively good approximation of the signal and back-
ground probability distributions, an eﬃcient event classiﬁcation scheme can be developed,

5

as described in section IV. Care needs to be taken, however, so that the estimation of the
overall eﬃciency and purity of the selection is not biased. In this example, the approximate
signal PDF is deﬁned by 81 parameters (two projections of 40 bins, and one correlation
coeﬃcient) derived from the 4000 events in the signal control sample. These parameters will
be sensitive to the statistical ﬂuctuations in the control sample, and thus if the same control
sample is used to optimize the selection and estimate the eﬃciency and purity, the estimates
may be biased. To reduce this bias, additional samples are generated with the method de-
scribed at the end of section II. These samples are used to deﬁne the 81 parameters, and the
event classiﬁcation scheme is applied to the original control samples to estimate the purity
and eﬃciency. In this example data analysis, the bias is small. When the original control
sample is used to deﬁne the 81 parameters, the optimal signal to noise is achieved with an
eﬃciency of 0.880 and purity of 0.726. When the PCA generated samples are used instead,
the selection eﬃciency is reduced to 0.873, for the same purity.

When the classiﬁcation scheme is applied to the data sample, 261 events are classiﬁed
as signal events. Given the eﬃciency and purity quoted above, the number of signal events
in the sample is estimated to be 217

19.

The number of signal events in the data sample can be more accurately determined by

±

using a maximum likelihood analysis. The likelihood function is deﬁned by

400

Yj=1

L =

(fs Ps(xj) + (1

fs) Pb(xj))

−

(9)

where the product runs over the 400 data events, fs is the fraction of events attributed to
signal, and Ps and Pb are the PCA approximated PDFs, deﬁned by Eq. (4). The signal
0.040, a relative uncertainty
fraction, estimated by maximizing the likelihood, is 0.617
of 6.4% compared to the 8.5% uncertainty from the counting method. To check that the
data sample is well described by the model used to deﬁne the likelihood function, Eq. (9),
the ratio of probabilities, Eq. (7), is shown in Fig. 7, and compared to a mixture of PCA
generated signal and background samples.

±

VI. FORTRAN IMPLEMENTATION

The source code for a FORTRAN-77 implementation of the methods described in this
paper is available from the author. The program was originally developed for use in an
analysis of data from OPAL, a particle physics experiment located at CERN, and makes
use of the CERNLIB library [2]. An alternate version is also available, in which the calls to
CERNLIB routines are replaced by calls to equivalent routines from NETLIB [3].

6

REFERENCES

[1] References to artiﬁcial neural networks are numerous. One source with a focus on applica-

tions in High Energy Physics is:
http://www.cern.ch/NeuralNets/nnwInHep.html.

[2] Information on CERNLIB is available from:
http://wwwinfo.cern.ch/asd/index.html.

[3] Netlib is a collection of mathematical software, papers, and databases found at

http://www.netlib.org.

7

x2

300

200

100

0

1.0

0.8

0.6

0.4

0.2

0.0

0

FIGURES

8

2

4

6

8

10

0

100

200

x1

FIG. 1. The points represent the sample of 4000 events generated according to the function
ds in Eq. (8), which are used as a control sample for the signal distribution. Contours of ds are
shown to aid the eye. The two projections of the distribution are used by the PCA method to
approximate the signal PDF.

x2

300

200

100

0

1.0

0.8

0.6

0.4

0.2

0.0

0

2

4

6

8

10

0

100

200

x1

FIG. 2. The points represent the sample of 4000 events generated according to the function db
in Eq. (8), which are used as a control sample for the background distribution. Contours of db
are shown to aid the eye. The two projections of the distribution are used by the PCA method to
approximate the background PDF.

9

40

30

20

10

0

1.0
x2

0.8

0.6

0.4

0.2

0.0

0

2

4

6

8

10

0

10

20

30

x1

FIG. 3. The points represent the data sample of 400 events consisting of 240 events generated

according to the function ds and 160 generated according to db in Eq. (8).

10

y2

400

200

0

4

2

0

-2

-4

-4

-2

0

2

0

200

400

4

y1

FIG. 4. The points show the distribution of the 4000 signal events after being transformed
according to Eq. (2). The projections are now Gaussian distributions, centered at 0 with width 1,
and the overall distribution appears to follow a 2-dimensional Gaussian. The correlation coeﬃcient
is 0.40.

11

5
0

.

0

 
/
 
r
e
b
m
u
n

5
0
.
0
 
/
 
r
e
b
m
u
n

250

200

150

100

50

0
250

200

150

100

50

0

signal

background

0.0

0.2

0.4

0.6

0.8

1.0

w ( X 2 )

FIG. 5. The upper and lower histograms show the results of the goodness of ﬁt test applied to
the signal and background control samples. The χ2 values are 31 and 14 for 19 degrees of freedom,
respectively.

12

z2

400

200

0

4

2

0

-2

-4

-4

-2

0

2

0

200

400

4

z1

FIG. 6. The points show the distribution of the 4000 background events after being transformed
according to Eq. (2). The correlation coeﬃcient is 0.03, and the two variables appear to be
uncorrelated.

13

Signal
Background
Data

5
2
0
.
0
 
/
 
r
e
b
m
u
n

50

40

30

20

10

0

0.0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1.0

probability ratio

FIG. 7. A check is made that the data sample is consistent with the model used in the maximum
likelihood analysis. The distribution of the probability ratio, Eq. (7), is shown for the data events
and compared to the expected distribution, as given by a mixture of PCA generated signal and
background samples. The agreement is good, the value for χ2 is 36 for 35 degrees of freedom.

14

