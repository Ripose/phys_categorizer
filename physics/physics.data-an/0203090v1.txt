2
0
0
2
 
r
a

M
 
8
2
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
0
9
0
3
0
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Fiducial pdf as special case in either Bayesian or frequentist approach;

equivalence to the information-metric “prior”;

relevance to parameter estimation.

George Kahrimanis ∗

28 March 2002

Abstract

Several previous attempts (mine, too) for deﬁning objective priors have been ineffec-
In a matter-of-fact
tual, on account of both unsure derivation and implausible results.
approach, the existence of a default “prior” probability density is established in a special
case: if the experimental error, as a random variable, is of known density, independently
of the true value. In such cases the prior can be thought of in terms of the experimental
error, assuming that an admissible prior for the main parameter is not available. That is,
we obtain a plain Bayesian interpretation of Fisher’s ﬁducial probability. There is also a
corresponding frequentist interpretation. In a generic case, the default “prior” is demon-
strated to be equivalent to that induced by the information metric; it has been used e.g. by
V. Balasubramanian (1996), following Jeffreys’ ﬁnal approach (1961; not to be confused
with his earlier ones). Consequently, prejudice can be eliminated in Bayesian analysis.
The Likelihood “Principle” is violated by Jeffrey’s “prior”.
In particular, changing the
stopping rule of an experiment can affect the default “prior”.

http://users.hol.gr/˜anakreon/defprior

1 Introduction

To keep this presentation short, I assume that the reader is familiar with the Bayesian pro-
cedure (e.g. D’Agostini, 1999); in particular, with the difﬁculty associated with the apparent
freedom in deciding the prior pdf (prior probability density, in the continuous case; here called
simply “prior”). In Prosper’s (2000) succinct words, “if in fact your answer depends very much
on the prior, then the conclusion should be that you have insufﬁcient data to say anything sen-
sible”. However, as he, Lyons (2000), and others have noted, in the case of zero yield, the
extraction of an upper limit for the event rate involves critically the choice of prior. The reader
can check that the result is zero if the prior is a density uniform in the logarithm of the rate, or
in the meantime, but it agrees with frequentist calculations if the prior is uniform in the rate.

∗anakreon@hol.gr

1

(This is also discussed by F. James, 2000 and Cousins, 1995.) Usually results are reported in
terms of rate; this may explain why the corresponding parametrization is the preferred one, but
I think that it is also perceived as the natural parametrization, albeit in a vague sense.

On account of the usual choice being merely a convention, an unforgiving critic may call
for the abandonment of Bayesian analysis regarding upper limits, for the Neyman construction
of conﬁdence intervals, unless we settle the question of prior. If this sounds too radical, please
consider on what grounds we expect to ﬁnd a ﬁnite 90% Bayesian upper limit: just because
we know that, for a range of hypothetical values of rate near zero, the null sample reserves the
preponderance of probability (>90%). This is deﬁnitely “frequentist thinking”.

So we have a compelling reason to review the problem of the prior. In this work, the scheme
“prior × likelihood = posterior” is not applied if there is no reliable initial information, or if
one decides to explore that possibility. We shall see that we can still obtain a posterior pdf , but
it will not depend on a prior. This does not amount to abandoning the Bayesian approach; we
only extend it to the case of null predisposition. The outcome is a probability density of the
subjective kind, not a conﬁdence interval.

Here is the basic idea. Consider a measurement of a single parameter or variable, such
that for any trial we obtain just a numerical outcome, whose deviation from the true value (in
the following, the term “error” will denote this difference, not the statistical uncertainty of the
measurement) is known to follow a certain pdf , independent of the true value and of the data.
(The choice of parametrization is important.) If there is no reliable preliminary knowledge to
support a prior density, then the only thing we know is the pdf of the difference of the true
value from the outcome. This is an objective pdf , which can be veriﬁed in a frequentist sense.
Then a pdf for the true value, of the subjective kind, can be generated from the outcome and
the pdf of the error. It is the result of the measurement in the absence of predisposition. The
Appendix has a more detailed examination of the prior-less posterior pdf , both in the Bayesian
and in the frequentist approach.1 As we shall see, a prior-free posterior exists not only in the
idealized conditions speciﬁed above, but also in a generic situation.

Note that Bayes’ Theorem is not involved directly in the method introduced here, never-
theless the procedure happens to ﬁt the description “prior × likelihood = posterior” (it will be
demonstrated) though in appearance only. The density that takes the place of prior is called
here “default prior”.
It is derived from the experimental conditions in a veriﬁable manner.
Those conditions include the “stopping rule”. A different experiment may correspond to a
different default prior. To combine the results of two experiments, one must calculate a new
default prior. The derivation of the default prior may be a difﬁcult problem in many real situa-
tions, if the stopping condition of the experiment is debatable (say, if it has stopped for lack of
money or because of a quarrel, or due to unforeseen circumstances). In such cases, usually an
approximate derivation would be adequate.

For a quick inspection of the applied procedure regarding the default prior, see Sec. 3.6.
The existence of the default prior will be proven in this paper, but it is a separate matter
to consider in what kind of problem it is appropriate to apply it. One such case would be a
measurement for which there is some justiﬁable prior, but someone suspects (or considers the

1 For readers familiar with Fisher’s ﬁducial probability: in the Appendix it is proven that in certain simple
situations, even in the absence of a prior, a posterior probability can still be extracted from the experiment, and
is the same as Fisher’s ﬁducial probability in that case. Yet in other ways the present work is contrary to related
assessments and conjectures advanced by Fisher.

2

possibility) that the preliminary information might be fabricated – we shall examine such an
example. To my mind, objectivity in data analysis amounts to a consistently skeptical attitude
with regard to prior information.

The question what constitutes a justiﬁable prior needs to be addressed. My suggestion is
that only uncontroversial priors should be permitted, like those obtained from plain estimates or
from direct sampling measurements. Until now, in the absence of real preliminary information
about the object of measurement, sometimes subjective inclination has been used to derive
a prior probability density. This may be in principle admissible – in certain cases, and only
in reference to a particular mindset or interest group. But often this inclination should be
expressed in a different way, not in the way of a probability density. For instance, if it is based
on predilection for a certain hypothesis, we should form a utility function, not a density, that is
higher at the domain favoured by the hypothesis than elsewhere. If the inclination is based on
unspeciﬁed observations, for example “life would be impossible if the value of this constant
were less than . . . ”, then it is better expressed as coming from previous experiments, to be
combined with the experiment we analyse, rather than as a probability density. We shall return
to this matter.

The present approach differs from the related previous attempts, such as the Jeffreys-Jaynes
priors, in not assuming the scheme “prior × likelihood = posterior” but deriving it from ele-
mentary considerations. The results are identical with those of a suggestion by V. Balasubra-
manian (1996), to deﬁne the “natural” prior (same as the last of priors supported by Jeffreys,
1961) as the density that is derived from the local metric associated with distinguishability
of hypotheses. A short time before the presentation of this work I also noticed that Cousins
(1995) mentions certain works (his references 23 and 35) which use the “information metric”
(also lead to the same “prior” in the case of a Poisson rate, at least). In view of those previous
works, the new thing in this work is the derivation of the information-metric prior from ﬁducial
probability (in a restricted sense, not following Fisher).

1.1 Outline of the argument

The term “translational symmetry” here will apply to a measurement whose outcome is a
single number, used as estimator, if the error is a random variable independent both of the true
value and of the data.

Theorem A. In any measurement characterised by translational symmetry for the error,
an objective posterior can be easily deﬁned, to be used by skeptical bettors who do not trust
preliminary information.

Proof of this theorem is in the Appendix. That is, one proof in the Bsyesian manner and

one proof in the frequentist manner.

If we divide the objective posterior by the likelihood function, we obtain a default prior,
independent of the data, which is invariant under translation; that is, a density uniform in the
related parametrization.

Theorem B. In a situation that is not exactly like the above but differs by a small pertur-
bation, the objective posterior does not disappear. The new objective posterior should differ
from the unperturbed one by an amount proportional to the size of the perturbation (to the ﬁrst
order).

3

If we divide the objective posterior by the likelihood function, we obtain a default prior; it
remains to be proven that this density is independent of the data. (It is shown in the comment
after Theorem E.)

Assumption C (it may well be a theorem). Any situation of interest can be considered
as the ﬁnal product of successive small perturbations, starting with a situation belonging to
Theorem A.

In this way we address the question of existence in general.
Theorem D. Any measurement of a continuous variable or model parameter, if repeated
a large number of times, leads to a situation that is covered by theorems A and B in a spe-
cial parametrization, so that we calculate a default prior for the repeated measurement; it is
asymptotically independent of the number of repetitions. It is also independent of the data.

It remains to be shown exactly independent of the number of repetitions, even for small

numbers: see theorem E.

measurement.

Theorem E. The default prior for a single measurement is the same as that of a repeated

This was not obvious, because the default prior is not derived from subjective predisposi-
tion. (The combination of two different measurements is another matter.) Now we know that
the prior we found in Theorem D applies also to a single measurement. Now we know that a
default prior is independent of the data in any case.

Theorem F. The above approach is checked equivalent to V. Balasubramanian’s (1996) (or
Jefferys, 1961) suggestion to deﬁne the “prior” as the density that is derived from the local
metric associated with distinguishability of hypotheses. His argument in short: a likelihood
ratio between hypotheses h1 and h2 applies not only to these two hypotheses but also to all other
hypotheses in their neighbourhoods, such that are practically indistinguishable (to a degree)
from h1 or from h2.

1.2 Comments about uniform priors

A uniform density corresponds to the simplest and least informative function one can think
of. Yet it is a density, consequently it depends on the choice of parametrization; uniformity is
only half an answer to the problem “ﬁnd an unprejudiced prior”. Now let us look into a tech-
nical aspect of this approach. Apparently a prior density must be normalised or normalisable
because it represents continuously distributed probability. Yet this requirement can be relaxed
(Williams, 1988) because the Bayesian procedure involves a normalisation anyway, which will
be adequate if the integration of the likelihood does not diverge. Also, though unnormalisable
a prior density is still applicable in calculating relative odds; that is, in terms of conditional
probabilities. Therefore the concept of an everywhere uniform density is consistent: it does
not presuppose imposition of cut-off limits.

2 Insight from plain circumstances

4

2.1 Example “Lost Beacon”

Somebody has lost an object; he suspects that it fell off his backpack while he was walking
on a certain trail. That trail is very nearly a straight line. To obtain a clue about the location of
the object, he decides to take advantage of the fact that it is an automatic light beacon, pre-set
to emit a ﬂash at midnight. To monitor the ﬂash, he climbs a watchtower at the beginning of the
trail, along with some friends, all of them Bayesians, bringing a device adapted for the purpose.
Using that device, they record the altitude angle (from the horizon), then use it to calculate the
distance of the beacon from the watchtower.

Practically the only source of uncertainty in this measurement seems to be the random error
in the measurement of angle. That error is estimated to follow a narrow probability density, the
same at any angle.

Next, the operator of the measuring device calculates a (subjective) probability density for
the location of the beacon. Someone proposes a betting scheme based on that density: to divide
the trail into bins of equal probability, so that the beacon would have the same chance of being
found in any of those bins. By the way, he asks what was the assumed prior probability density
in the calculations. Here is the following dialogue.

- I have assumed a density uniform in the angle parametrization, restricted within the range

corresponding to the trail, as seen from the watchtower.

- Can we, please, review your reasoning? I think that I have a different proposal.
- My experience tells me that under these conditions the error follows a nearly Gaussian
probability density, in the sense that in a long series of comparisons against a more precise
method, the error is found to obey the above density. (Note that when ﬁnally we locate the
beacon we will also assess the error of this angle measurement.) This probability is objective,
independent of any prior beliefs. In so far as we exclude any other considerations, this density
also functions as a subjective probability. The corresponding prior density is uniform in terms
of angle, due to the likelihood being proportional to the resulting probability density (one may
say that the instrument was built with that speciﬁcation). Now let us take into account that the
source of the ﬂash cannot be outside the range of angles corresponding to the beginning and the
end of the trail. That is, all current bets would be invalidated if the beacon is found to lie outside
the trail. The related conditional probability is formed by truncating the above probability. This
is equivalent to truncating the uniform prior density (in the angle parametrization).

- I wonder why you have not taken into account that, before we thought of using the watch-
tower, we had arranged to bet according to a density uniform in the distance parametrization.
Should we disregard our previous belief? I know that a frequentist would think so, but I cannot
see why a Bayesian would!

- I thought that your previous betting arrangement had not been based on any kind of
prior knowledge but rather on total ignorance, merely assuming that there is a physical object
somewhere on that trail. Yet the mere existence of an object on the trail does not imply that
the appropriate parametrization is necessarily linear in the distance. Nobody had given me any
substantial reason for that choice.

- I suppose that you were not around when we discussed this matter. Considering all con-
ceivable ways that a person can lose an object on this trail, it seems that this density is the
average. This is the true prior probability density, regardless of the instrument used to record
the ﬂash.

5

- I see now! The prior density that is uniform in distance is as good as proved, because of
what we know about the way the beacon was lost. I agree that the calculation must be revised,
to assume a prior density uniform in distance.

- (A third person) I prefer the angle parametrization for deﬁning the uniform prior. Your
reasoning is ﬁne, but I happen to doubt the presumed prior information. Someone might be
trying to deceive the rest of us.

- Well... yes, it is your right to reject the presumed prior knowledge, because it might have
been introduced with the purpose to mislead the bettors. There is not only one rightful prior
density; it depends on your assumptions. Yet that is not to say that anything goes: if you are
committed to certain assumptions then you are bound to the corresponding prior density.

- (The same third person) I agree. Assuming that I reject any opinion that is not veriﬁable

by me, I am obliged to use the angle parametrization to analyse this measurement.

- Actually the angle parametrization is not exactly the objective one, if we include a minor
effect from the fog. I have not yet ﬁnished my calculation of this correction, so let us put the
matter off for the moment.

- Talking about provisional betting odds, reminds me of a special case among us. Arthur
is expecting his wife to drive him back home as soon as she ﬁnds some free time – but after
he goes away he will not be eligible to win the bet. Therefore it makes sense for him to bet
on the nearest bin (which will be searched ﬁrst), in case the beacon is found there before his
wife arrives. I do not think that his case corresponds to a new prior – only to the multiplication
of probability by his utility function (as if it were a likelihood function). With regard to prior
probability, he may adopt either one of the two approaches we have been discussing.

- This is not the only case of peculiar betting. Isolde believes that she saw the ﬂash from her
car, when he was coming here, so that now she has an independent, though approximate idea
where the beacon lies. She has not yet decided what to use as a prior probability density. Her
experience amounts to a second angle measurement, from a different point. If she accepts the
reasoning that supports the distance-parametrization for the prior density her calculations will
be uncomplicated, but if she doubts it she will have to look for a parametrization appropriate
for the “objective” combination of the two measurements.

2.2 Connection with experimental physics

The above situation has a special property. If we ignore or disregard all prior information
about where and how the beacon is said to have been lost, the error follows a known probability
density, in terms of angle. In other words, the measuring procedure alone determines a default
prior probability (also a default parametrization) if we exclude any unveriﬁable information.
A skeptical bettor adopts this prior probability. We may decide to accept part of the offered
information, such as that the beacon is on the trail. Then the original prior density is modiﬁed
(here, it is truncated). If one adopts all available information and if it amounts to a probability
density then that is his prior probability, without any inﬂuence from the measuring procedure.
Note that in the measurement of a physical constant we have no access to information about
how the constant has come to be what it is – nothing like the story of the beacon accidentally
been lost along the trail. Therefore, in estimating physical constants, we must ﬁnd and adopt
the default prior density, at least when it makes a considerable difference. There is no freedom

6

in the choice of prior probability density for physical constants; at most we may be relaxed
about ﬁnding the exact default prior density if an approximation seems adequate.

Sometimes we have real prior information, not mere predisposition, about the measure-
ment. For example, in the case of particle identiﬁcation, we may take into account the ratios
of the ﬂuxes of different kinds of particles to obtain the probability that the observed particle is
of any speciﬁed kind. In short, any choice of prior that may be disputed is inappropriate in the
context of parameter estimation, but any undisputed prior information ought to be taken into
account, if it is relevant.

3 Proof and derivation

3.1 Existence of default prior in a generic situation

The question arises whether a prior-free posterior exists always or only in special situations,
those marked by a continuous symmetry. With a minute variation of the above example, say if
we take into account the effect of the fog, the symmetry of the problem disappears – but does
this perturbation annul the existence of a prior-free posterior? Then a skeptical bettor would
be left without any basis for betting, which does not seem plausible. Any minor variation, like
the effect of the fog, must introduce only a small correction to a skeptic’s betting odds, not a
radical change.

We have considered the effect of a static perturbing factor, the fog. A perturbing factor may
even be of a random magnitude, provided that its effect can be adjusted to be arbitrarily small.
If we divide the prior-free posterior of the perturbed case by the perturbed likelihood, we
get a density that could be called the default prior, except that we have not yet shown that it is
independent of the data. This will be shown at a later point in this proof; it will not be assumed
until then.

At this point let us presume without detailed proof that a generic case of one-parameter
estimation can be thought of as a mutation of a case of translational symmetry. That is, starting
with an imaginary case in which the pdf of the error is independent of the true value and of the
data, we apply successive small perturbations until we reach the case of interest. In this way
a prior-free posterior is guaranteed in any case. Along with it, the existence of a default prior
(not yet shown to be independent of the data).

3.2 The default prior density for repeated measurements – Part A

The default prior is not a real prior. It does not represent subjective belief. Therefore it
makes sense to ask whether the default prior density for a measurement repeated twice (the
results combined) is the same as the default prior density for the single measurement. At a
later stage of this work shall see that it is so, but until then we will not assume this property.

For example, suppose that we measure the same angle twice, using a cyclical bevel. The
data of the combined measurement consist of a couple of numbers. We can take advantage of
the rotational symmetry and argue that the default prior of the combined measurement cannot
be anything other than a density uniform in the angle. In a less symmetric situation it is not so

7

obvious that the default prior does not change when we repeat a measurement and combine the
results. We shall return to this problem.

3.3 What is the default prior probability in a generic case – Part A

We have concluded the existence of a prior-free posterior pdf in any case. The correspond-
ing default prior is deﬁned from the assumption “prior × likelihood = posterior”, though it still
remains to be shown that the default prior is independent of the data.

In a generic case the measurement error, as a random variable, is not ﬁxed; for example, it
may be a function of the true value, or may depend on the data. Yet, if we consider imaginary
repetitions of the same experiment, we can construct a situation that asymptotically possesses
a translational symmetry, like the special examples discussed above. That symmetry will guar-
antee that the default prior will be independent of the data.

If the number of repetitions is large enough the shape of the likelihood approximates a
narrow Gaussian. We shall look for a parametrization in which these Gaussians are of the same
width.

Let us limit our search, allowing only parametrizations in which the (plain) derivative of
the default prior is uniformly bounded in absolute value. As we shall see, this limitation does
not exclude the answer to our problem. If the number of repetitions is large enough, so that the
width of the likelihood is narrow enough, then the default prior is rather constant in compar-
ison, and the probability density that expresses the result can be taken as proportional to the
likelihood. The default prior (of the combined measurement) becomes asymptotically irrele-
vant – except that it exists.

In this way we have contrived a situation having a symmetry similar to that of the sim-
ple examples. The measurement error is the difference of the true value from the maximum-
likelihood estimate. This error is a random variable that does not depend on the true value,
because by construction the likelihood is a Gaussian of a known width.

Now let us derive the related parametrization, also show that it is asymptotically inde-
pendent of the number of repetitions. We shall deal only with the one-parameter estimation
problem, leaving the higher dimensions for future work.

Here H will represent the parameter of interest (a random variable, in the Bayesian ap-
proach). The data is partitioned into a ﬁnite number of bins, indexed by i. After N measure-
ments, the yield in each bin is yi (such that
yi = N). For any value h of the parameter H, the
probabilities Pr(yi|h; N) are known binomial distributions, each of mean value ˆYiN (h). (Note
that ˆYiN (h) are proportional to N, and that

ˆYiN (h) = N.)

For the bins with ˆYiN (h) ≥ 10 (say) the Gaussian approximation will be supposed ade-
quate. The rest of the bins will be ignored in the following calculations. The resulting error
approaches zero as N → ∞.

P

P

Corresponding to any data set {yi}, the log-likelihood of h is λ ≡
Gaussian approximation, the log-likelihood can be written as −1/2
iN (h)2/ ˆYiN (h) + 2 ˆY ′
ˆY ′
Accordingly, ∂2λ/∂h2 ≡ −
iN (h)(yi− ˆYiN (h))/ ˆYiN (h) − ˆY ′′
iN (h)2(yi− ˆYiN (h))2/ ˆYiN (h)3 − ˆY ′′
ˆY ′

i
P

ln(Pr(yi|h; N)). In the
(yi − ˆYiN (h))2/ ˆYiN (h).

P
iN (h)2(yi − ˆYiN (h))/ ˆYiN (h)2 +
P

iN (h)(yi− ˆYiN (h))2/2 ˆYiN (h)2.

This second derivative is of interest at the point of maximum likelihood, hm, considering
that asymptotically the likelihood approaches the Gaussian shape. The mean and the variance
of YiN are proportional to N (for ﬁxed binning and parametrization), so that compared with

8

In words, the effect of
the ﬁrst term the other terms are negligible in the limit N → ∞.
random ﬂuctuations in the data diminishes, and the choice of parametrization and binning
becomes irrelevant. Therefore in the limit of large N, at the point of maximum likelihood, the
ˆY ′
iN (hm)2/ ˆYiN (hm), with diminishing fractional
second derivative of the log-likelihood is −
uncertainty (which arises from random ﬂuctuations in the data and from the freedom in the
choice of parametrization).

P

We are interested in ﬁnding a parametrization of H, such that the second derivative at the
point of maximum likelihood can be considered as independent of the true value, subject only to
random ﬂuctuations and other asymptotically vanishing effects. This problem is trivial. In the
rest of this subsection let us assume that it has been solved. For completeness, in Subsection 3.6
we shall outline the practical steps of ﬁnding such a parametrization.

In this way the width of the likelihood function will be in effect independent of the true
value of the parameter, for large enough N. (That width can be so short that the variation of the
default prior becomes negligible.) At last we have a situation in which the experimental error is
a random variable independent of the true value, like in the plain examples we have considered
– except for the statistical perturbation. In conclusion, the default prior corresponding to N
repetitions of the measurement is a uniform density in the special parametrization (or any
linear transformations).

The constancy of the width (asymptotically) of the likelihood is equivalent to the condition

(∀h) (∂/∂h)

ˆY ′
iN (h)2/ ˆYiN (h) = 0.

X

(1)

This condition is independent of N, because the mean of YiN are proportional to N. That is,
if N is large enough for the Gaussian approximation to be valid and the randomness to be
negligible, the same condition will also be valid for any larger number of repetitions, for the
speciﬁed parametrization.

This condition can be expressed without the explicit mention of data bins and repeated mea-
surements, as an integral in the space of data. Let R be the random variable that corresponds
to the result of a single measurement, and p(r|h) the (known) probability density of r if H is
h. The above condition is equivalent to
∞

(∀h) (∂/∂h)

Z

−∞

dr [(∂p(r|h)/∂h)2 /p(r|h)] = 0.

(2)

Already we have a method to derive a default prior density for a measurement that has been
repeated many times. We have not yet shown that the same density is the default prior density
for the single measurement. This will be shown in the following.

3.4 The default prior density for repeated measurements – Part B

If a measurement is characterised by a continuous symmetry, like when we measure length
with a ruler or angle with a cyclical bevel, the default prior density cannot be anything other
than a density of the same symmetry. This is so regardless of the number of repetitions of the
same measurement. In a generic case, when there is no such a symmetry, we have to work
harder to show that the default prior is independent of the number of repetitions.

Remember that we regard any generic case as a deformation of a symmetric case. Now
we shall see that the property “the default prior is independent of the number of repetitions”

9

is preserved to the ﬁrst order under a perturbation. In this way the generic case inherits this
property from the imaginary symmetric case.

Here is a proof. Suppose that we have a case for which the default prior is independent of
the number of repetitions. We shall consider perturbations of this case. Let us call the former
case C0 and any perturbed case Cm, where m is the size (with a sign) of the perturbation,
assumed small. In this way we have deﬁned an one-parameter family of cases. As concluded
above, if C0 is repeated, the default prior of C 2
0 is the same as that of C0, but we do not
yet know whether doubling Cm also leaves the default prior unaffected. Let us call Dm(h) the
difference of the default prior of C 2
m from that of Cm (the deﬁnition of “difference” needs some
attention in case the default priors are unnormalisable). Assuming that an analytical expansion
is valid, we obtain to the ﬁrst order Dm(h) = m g(h), for some function r. For instance, with
the opposite perturbation we get the opposite effect.

Now let us consider doubling not only measurements of the one-parameter family deﬁned
by the perturbation, but also composite measurements, like CmCn. That is, we are interested in
the difference of the default prior of (CmCn)2 from that of CmCn; let us call it Dmn(h). Again
we assume that an analytical expansion is valid, so that to the ﬁrst order Dmn(h) = (m +
n) g(h). For instance, if the composite measurement consists of two opposite perturbations,
then the doubled measurement has the same default prior, to the ﬁrst order.

The last expansion can be generalised, for composite measurements consisting of more

than two measurements, like Cm . . . Cn: Dm...n(h) = (m + . . . + n) g(h).

Now we shall compare two cases. The one is Cm, for some small m. The other is (Cm/N )N ,
where N is a very large number. Both cases have the same ﬁrst-order expansion of the effect
we are interested in; therefore, the difference between the default prior of C 2
m and that of Cm is
the same, to the ﬁrst order, as the difference between the default prior between (Cm/N )2N and
that of (Cm/N )N .

But the last difference is zero, because it involves large numbers of repetitions of the same
measurement. (We have shown that the default prior of repeated measurements is asymptoti-
cally independent of the number of repetitions.) Consequently Dm(h), the difference between
the default prior of C 2
m and that of Cm, is zero to the ﬁrst order in m, therefore g(h) ≡ 0. That
is, the effect we have been discussing in this subsection does not exist. The default prior of a
generic case does not change if we repeat the measurement twice; the same can be shown for
additional repetitions of the same measurement.

3.5 What is the default prior probability in a generic case – Part B

We now see that the default prior of a measurement does not change under repetitions,
therefore it is the same as the prior which we have discussed in relation to a large number of
repetitions of the measurement. We have seen that asymptotically it is independent of the data.
At last we can speak of a default prior which is derived from a measurement procedure,
such that does not change when the procedure is repeated and the results combined. As it
were, knowing the measurement procedure creates a subjective prior equal to the default prior.
This is not so really; it seems nonsensical to bet before a measurement using the default prior
(for example before an angle measurement). Still this observation makes it easier to remember
how to apply the notion of a default prior.

10

3.6 The practical prescription

A parametrization in which the default prior is uniform is not (cannot be) unique, but is
deﬁned up to a linear transformation. In the case of continuous data, we should check whether
our assumed parametrization of the estimated parameter is such that Eq. 2 is satisﬁed. If not,
we must look for a new parametrization, corresponding to a function g(h), for which Eq. 2
is satisﬁed. Therefore
/p(r|h) is independent of h. The general
solution is

∞
−∞ dr [∂p(r|h)/∂h /g′(h)]
R

2

g′(h) = C

dr [∂p(r|h)/∂h]

/p(r|h)

2

∞

(cid:20)Z

−∞

for any non zero value of C; we can set C = 1, because linear transformations do not matter
in this problem.

The default prior is uniform in the parametrization deﬁned by g(h), therefore in the h pa-

rametrization the default prior density is (unnormalised)

0.5

(cid:21)

0.5

.

(cid:21)

DP (h) ∝;

dr [∂p(r|h)/∂h]2 /p(r|h)

∞

(cid:20)Z

−∞

In a case with discrete data, the required parametrization is

g′(h) =

ˆY ′
i (h)2/ ˆYi(h)

hX

0.5

.

i

(3)

(4)

(5)

The right side of the above equation is also proportional to the default prior density in the h
parametrization.

3.7 Distinguishability as the natural distance of one hypothesis from an-

other

Here is a brief account of Vijay Balasubramanian’s (1996) suggestion, in simpliﬁed terms.
A likelihood ratio between hypotheses h1 and h2 applies not only to these two hypotheses but
also to all other hypotheses in their neighbourhoods, such that are practically indistinguishable
(to a degree) from h1 or h2. We shall see that in effect this intuitively plausible opinion is
equivalent to the default prior that was derived above. The formula was proposed by Jeffreys,
1961, but it should not be confused with “objective” priors he had introduced earlier (e.g.
1932).

Assuming that h0 is the true value of H, how can we deﬁne the “average” likelihood of any
other value h? We know that likelihoods do not add, but log-likelihoods do (when we combine
experiments without correlations). Therefore it makes sense to add log-likelihoods of repeated
experiments, then divide by their number to deﬁne the average log-likelihood of h, assuming
that h0 is true. This would be

But a likelihood function may be multiplied by any constant without any effect. To stan-
dardise our result, let us refer to the likelihood ratio of h compared to h0: the standardised
∞
−∞ dr p(r|h0) ln(p(r|h)/p(r|h0)). It has been called the rela-
average of the log-likelihood is
R
tive entropy of h with respect to h0.

∞
−∞ dr p(r|h0) ln(p(r|h)).
R

non-vanishing term is of the second order: −1/2

In the Taylor expansion of the relative entropy as a function of the difference h−h0, the ﬁrst
∞
−∞ dr [(Pr(r|h) − Pr(r|h0)]2/P r(r|h0), or
R

11

∞
−∞ dr [(∂/∂h) Pr(r|h0)]2/P r(r|h0) dh2. That is, a local metric in the space of hy-
−1/2
R
potheses is deﬁned. The density induced by this local metric is called the “natural” prior. It
would be uniform in a parametrization in which the local metric is also uniform. This consid-
eration leads to Eq. 2, therefore Balasubramanian’s (Jeffreys’) natural prior is the same as the
default prior.

4 Consequences and paradoxes

Let us look into the problem of combining two experiments in a single analysis. If the
preferred parametrization is the same in both experiments, then the default prior is common
to them and there is no departure from the usual procedure. The general case presents some
difﬁculty. Indeed changes in the stopping rule can have an effect, as we shall see in an example.
The dependence of a Bayesian result on the stopping rule is surprising. Until now only a
frequentist analysis would take the stopping rule into account. Note that, as we shall see, in
the usual case of a ﬁxed-time counting experiment, the parametrization derived here does not
coincide with the one common in current practice but (unlike previously proposed guidelines
for objective prior density) it does not deviate very far from it. And we should not forget that
the stopping rule is indeed irrelevant if we have a dependable prior.

The default prior is not about betting odds; it is only a mathematical construction that can
be utilised in the place of a prior if there is no basis for forming a prior. Yet we have also
seen that the default prior can be handled as a real prior, such that depends on the measuring
procedure. That is, if we change plans for the measurement then that hypothetical subjective
belief must be modiﬁed. Only if one forgets that there is no true subjective belief to be modiﬁed
there is a paradox here. Still, this dependence reminds me of a Bohr’s complementarity. In
either outlook, some objective element of our understanding of the situation depends on the
experimental setup.

Last, a few more words about the way one can include his subjective inclination in a sta-
tistical analysis. Prejudice may be based on facts which are unclear or difﬁcult to analyse
quantitatively, or may be based on plausible assumptions concerning situations that have not
been realised yet. In either case the problem of introducing prejudice in the analysis seems
to be a special instance of combination of experiments. A simpler case is the utility-induced
subjective bias. As an example, let us think of a physicist who does not know or think much
of superstring theories, therefore his short-term professional prospects are better served if the
posterior probability density does not carry any strong indication of superstrings. If that was
the only consideration, he would just set the utility function to zero outside the region he feels
comfortable with, but he also takes care to avoid appearing too unreasonable. At any rate, he
has the right to introduce his utility function, but that is not the same as introducing a prior
density.

4.1 Default prior depends on the stopping condition

The rate of a Poisson process can be measured with a counting experiment. We will ex-
amine two idealised cases, different only with regard to the stopping condition. In the one, the

12

duration of the experiment is decided ahead of the execution of the experiment. In the other
case, the experiment is supposed to run until the yield reaches a pre-set number.2

4.1.1 Assuming that the duration is pre-set

In a ﬁxed-time experiment, the probability of yield n, is a function of the rate r: Pr(n|r; T ) =

e−rT (rT )n/n!. We easily ﬁnd that

[(∂/∂r) Pr(n|r; T )]2/ Pr(n|r; T ) = 1/(rT )

Xn

if we take into account that the variance is equal to rT . Obviously Eq. 1 is not satisﬁed,
In a parametrization q(r) that would
therefore the default prior is not uniform in the rate.
satisfy Eq. 1, the above sum would be constant:

(dr/dq)2[1/(rT )] = C.

Therefore dq = C1dr/r0.5, which implies q = C2r0.5 + C3.

To extract an upper limit from an experiment with null yield, assuming no prior, we should
integrate the likelihood using the default parametrization. That is, a 90% upper limit r0.90 is
deﬁned by

r0.90

Z
0

(dr /r0.5)e−rT = 0.90

(dr /r0.5)e−rT .

∞

Z
0

This is different from the formula in common practice, which does not involve the factor

r−0.5. Yet the integrals are not divergent. In particular, one can check that

(6)

(7)

(8)

(9)

R

Z

(dr /r0.5)e−rT ≡ π0.5 erf (R0.5).

The 63.2% limit (corresponding to 1 − e−1) is 0.41/T rather than 1/T of the common
practice. The often used 90% limit is 1.35/T rather than the classic 2.30/T . The 99% limit is
3.32/T rather than 4.61/T . The results of current common practice (that is, assuming a prior
that is uniform in r) are consistently more conservative than the results with the default prior.
We can also compare the Bayesian average of the rate in either approach. With the com-
monly used prior, uniform in r, an experiment that has run for time T and has yielded N events
produces a posterior with average (N + 1)/T . With the default prior for a measurement of
pre-set time, the average of the posterior is (N + 0.5)/T ; the bias is halved. (The derivation is
not difﬁcult.)

4.1.2 Assuming that the yield is ﬁxed

In the case of an experiment planned to run until the yield reaches a pre-set number N, the

probability density of obtaining the Nth event at time T is

(T |r) = e−rT rN T N −1/(N − 1)!.

Pr
N

(10)

2 These two cases do not correspond to real experiments exactly. A real ﬁxed-time experiment would end
prematurely if its counter reached the device limit before the end of the pre-set time. An experiment of pre-set
yield should also be given a time limit, to make sure that it is performable.

13

We check whether Eq. 2 is satisﬁed. Taking into account that

we obtain

∞

0 dT e−rT T n ≡ n!/rn+1,
R

∞

Z

0

dT [(∂/∂r) Pr
N

(T |r)]2/ Pr
N

(T |r) = N!/r2.

In this case, too, Eq. 2 is not satisﬁed. Note that the default parametrization in this case is

different from that of the case of a ﬁxed-duration experiment.

(11)

(12)

(dr/dq)2[N!/r2] = C.
Therefore dq = C1dr/r, which implies q = C2 ln(r) + C3.

5 Conclusions

The proposal to use the information metric to deﬁne a “prior” is not new, but now we know
that it can be derived from a simple assumption. This assumption seems plausible to physicists:
when we obtain a reading from an instrument, and we know the distribution of the experimental
error, then we already have a subjective belief about the measured quantity, without reference
to what it is. This does not imply that we follow Fisher in the particular way he developed his
idea of ﬁducial probability.

This approach is not an alternative to Bayesian inference but merely its extension in cases
of null prior knowledge, or intentional suspension of belief. Besides, the scheme “prior ×
likelihood = posterior” is maintained, even if in appearance only.

The Appendix shows not only a Bayesian interpretation of ﬁducial probability in the sim-
plest cases but also an equivalent frequentist interpretation. This may be less astonishing if you
consider that the probability of HIV infection after a positive HIV test is meaningful not only
in a Bayesian approach but also in a frequentist sense (in terms of ensembles).

It is a separate question when this method is the appropriate one, especially if there seems
to be some prior available. There is no place for a prior in objective estimation of parameters
for a physical model, because objectivity requires suspension of belief regarding the object of
search. This prior may be perfectly acceptable in another context. We can use a prior as long
as it is not questionable in the context of the particular experiment.

The default prior is not directly related to the question whether the sensitivity of the ex-
periment is adequate for an approximate estimation, or does the real answer hide away from
the range of sensitivity. The full result of a measurement is not just the “posterior” probability
density, but also information about the sensitivity. Both would be conveyed by a plot of likeli-
hood using a parametrization in which the information metric is constant. (Less distinguishable
values would be plotted closer together than more distinguishable values.)

Acknowledgements

The presentation of this work at the March 2002 Conference ”Advanced Statistical Tech-
niques in Particle Physics” at Durham, UK, was partly funded by the Onassis (Ων ´ασης) Foun-
dation, at the recommendation of Mrs. Alcestis Soulogiannis, of the Ministry of Culture of
Greece. I would like to thank G¨unter Zech for stimulating exchanges that have lead to this
work.

14

APPENDIX. Logical steps of deriving the prior-free posterior
in the easiest cases

The existence of a prior-free posterior is shown here in detail, if the situation matches this
description. The measurement produces just one numerical outcome, which is used as the
estimate; no other plausible estimate is available; the experimental error (that is, the difference
from the true value, not the uncertainty of the measurement) is a random variable independent
both of the true value and of the data. This assumption applies in certain plain situations, like
when we measure length with a ruler. It is easy to check that, if we change the parametrization,
this property is preserved only with linear transformations.

If we have no prior knowledge about the true value, or if we want to put aside any predis-
position, then there is no basis for applying Bayes’ theorem. Yet the measurement leads to a
subjective pdf for the unknown true value, as we shall see. This proof is very simple techni-
cally, but I think that it requires ﬁrst to clarify the context of the problem using an example,
such as in Section 2.1 or the example offered here.

A technician has calibrated an electronic thermometer. The instrument is a black box for
him. He has noticed that the outcome is subject to some small random error, and has also
formed a table with the probability distribution of the deviation of the reading from the true
value. This error seems uncorrelated to the true value, also to the outcome. Then the techni-
cian learns that this instrument has been used in a previous measurement and has produced
a reading r. He is not told what that measurement was about, nor is he is inclined to guess.
Nevertheless his experience with this instrument leads him to apply a subjective pdf to the
deviation of r from the true value, even without a prior.

Odd yet true, this result can be understood in either a Bayesian way or a frequentist way, as

we shall see next.

The experimental error is deﬁned as the difference of the output R from the true value T :
E = R − T .3 One can run tests or simulations, varying the “true value”, to make sure that the
distribution of the error E is independent of the true value and of the data. Therefore the error
is a random variable of objective, veriﬁable probability density f (E) = Pr((T + E)|T ).

Note that this property deﬁnes a set of parametrizations of T (the same for Y ), which
In the “Lost Beacon” Example (Section 2.1) such a

are related by linear transformations.
parametrization is in terms of angle (rather than in terms of distance).

The Bayesian way

For the sake of the argument, let us consider what happens when one takes into account his
prior for T , π(t) (assuming that a prior exists and is admissible). The posterior p(t) for the true
value is
p(t) ∝ π(t) Pr(r|t) = π(t)f (r − t).

3 In a strict frequentist interpretation of that previous measurement, the true value is not a random variable but
a ﬁxed value t. After the measurement, the reading is a ﬁxed value r. In that sense, the error is also not a random
variable any more. Yet we shall see that the frequentist approach is rather more subtle than that.

15

Although f has been deﬁned as a density, here it is proportional to the likelihood function; the
correspondence is established with reference to a parametrization that realises the translational
symmetry we have assumed. Note that the corresponding posterior pdf for the error is

Pr(e|r; π) ∝ π(r − e)f (e)

(13)

But if there is no prior for T , or if it is not admissible in the analysis of this experiment,
the subjective pdf of the error remains f (e) even after the measurement, because there is no
intermediate step in Bayesian inference. In other words, note that in Eq. 13 the prior can be
taken to be the pdf f (e), our prior expectation for the error, and the corresponding likelihood
is π(r − e) (the reader can justify this approach in detail).

Therefore the resulting pdf for T is the ﬁducial probability

g(t) ≡ f (r − t).

(14)

We now have a Bayesian interpretation of ﬁducial probability. Note that in the professed
refutation of the notion of ﬁducial probability (e.g. O’Hagan, 1994) a prior for T is taken into
account, but this is contrary to the line of the above argument.

The frequentist way

Bayes’ Theorem applies also in classical statistics, as long as the probabilities are deﬁned
in an objective way. After a quick survey of a couple of interesting examples, we shall mirror
the previous Bayesian argument.

Consider the interpretation of the results of an HIV test. Usually we think of this problem
in Bayesian terms, taking as prior probability the relative incidence of the infection in a group
of people in which the subject arguably belongs. In the frequentist interpretation there is no
sense in a posterior probability for this subject: he is either infected or not. Yet the Bayesian
result is meaninful also in the frequentist approach, in the sense of relative HIV incidence in a
particular ensemble of people (F. James, 2002).

Similarly, for any muon trigger in AMANDA (Hill and DeYoung, 2002) we ﬁnd the like-
lihood of a muon going up (rather than down), and we multiply it with our estimate of up-to-
down ratio (our prior for “up”) to obtain the Bayesian result. In terms of appropriately deﬁned
ensembles, this is also the probability in the frequentist sense (Cousins, 2002) though not ex-
actly in the sense of the probability of this event being an up-going muon. The difference
between the two approaches is not in the result, but in the interpretation.

After the probability of HIV infection and the up-going muons, let us consider the probabil-
ity of the experimental error being between any two ﬁxed values e1 and e2: after the measure-
ment, Pr(e1 < e < e2|r); before the measurement, Pr(e1 < e < e2). In the strict frequentist
sense, the error e after this measurement is no longer a random variable, but the probability
can still be deﬁned in terms of suitable ensembles. If we have some admissible prior π(t) for
the estimated parameter, we can use the result of this measurement to update Pr(e1 < e < e2)
into Pr(e1 < e < e2|r), in accordance with Eq. 13. But if such a prior is not available then
the knowledge of r does not help us in any way to update our initial Pr(e1 < e < e2) (because
there is no other way).

16

Therefore the pdf of the experimental error, f (E), makes sense also in the frequentist ap-
proach, albeit only in terms of relative frequency, for hypothetical runs of the same experiment.
The resulting pdf for the measured variable T is

g(t) ≡ f (r − t)

(15)

We have obtained a frequentist interpretation of the ﬁducial probability g(t). Note that it makes
sense only if the “pivot” parameter E is a random variable of known distribution f (e) for a ﬁxed
t, the same for any t.

References

V. Balasubramanian. (1996) Statistical Inference, Occams Razor and Statistical Mechanics
on The Space of Probability Distributions, Princeton University Physics Preprint PUPT-1587.
Also available electronically as preprint cond-mat/9601030.

R. Cousins. (1995) Why isn’t every physicist a Bayesian. Am. J. Phys. 63, 398. CERN
scan 9501056.

(2002) Comments in the discussion after Hill and DeYoung (2002).

G. D’Agostini.
99-03.

(1999) Bayesian Reasoning in High Energy Physics, CERN Yellow Report

R. A. Fisher. (1935) The Fiducial Argument in Statistical Inference. Annals of Eugenics 6,
391-8. Posted at http://www.library.adelaide.edu.au/digitised/fisher.

G. Hill and T. DeYoung. (2002) Application of Bayesian statistics to muon track reconstruc-
tion in AMANDA. Contribution to the conference “Advanced Statistical Techniques in Particle
Physics”, Durham, UK, http://www.ippp.dur.ac.uk/statistics.

F. James. (2000) Two contributions to the Workshop on Conﬁdence Limits at Fermilab, avail-
able as http://conferences.fnal.gov/cl2k/fredjames_lectures.ps and
http://conferences.fnal.gov/cl2k/copies/fjames.pdf.

(2002) Overview of Bayesian and Frequentist Principles. Introductory Lecture for the con-

ference “Advanced Statistical Techniques in Particle Physics”, Durham,
http://www.ippp.dur.ac.uk/statistics.

E. T. Jaynes. (1968) Prior Probabilities. IEEE Trans. Systems Science and Cybernetics SSC-
4. Repr. Rao Tummala and Henshaw, eds. Concepts and Applications of Modern Decision
Models, Mich. St. U. (1976) and in Jaynes, Papers in Probability, Statistics, and Statistical
Physics, Reidel Publ. Comp., Dordrecht-Holland (1989).

17

H. Jeffreys. (1932) On the Theory of Errors and Least Squares. Proc. Roy. Soc. 138, 48-
55.

(1961) Theory of Probability 3rd edition.

L. Lyons. (2000) Comments during the Workshop on Conﬁdence Limits at CERN, posted
at http://preprints.cern.ch/yellowrep/2000/2000-005.

A. O’Hagan. (1994) Kendall’s Advanced Theory of Statistics, Vol. 2B.

H. Prosper. (2000) Presentation and comments during the Workshop on Conﬁdence Limits
at CERN, posted at http://preprints.cern.ch/yellowrep/2000/2000-005.

D. Williams. (1988) Comment on “Small-signal analysis in high-energy physics: a Bayesian
approach”. Phys. Rev. D 38 (11), 3582-3.

18

