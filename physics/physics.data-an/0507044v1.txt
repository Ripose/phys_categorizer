Improvement of speech recognition by nonlinear noise reduction

APS/123-QED

Krzysztof Urbanowicz∗ and Holger Kantz†
Max Planck Institute for Physics of Complex Systems

N¨othnitzer Str.

38

D–01187 Dresden, Germany
(Dated: February 15, 2014)

The success of nonlinear noise reduction applied to a single channel recording of human voice is
measured in terms of the recognition rate of a commercial speech recognition program. We hence
demonstrate that an algorithm which has its roots in the theory of nonlinear deterministic dynamics
possesses a large potential in a realistic application.

5
0
0
2
 
l
u
J
 
6
 
 
]
n
a
-
a
t
a
d
.
s
c
i
s
y
h
p
[
 
 
1
v
4
4
0
7
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

PACS numbers: 05.45.Tp,05.40.Ca

It is a common nuisance that in signal record-
ing, signal transmission, and signal storage, per-
turbations occur which distort the original signal.
In many cases these perturbations are purely ad-
ditive, so that in principle they could be removed
If these perturbations are suf-
once identiﬁed.
ﬁciently uncorrelated and appear to be random,
they are called noise. Noise reduction is hence
an important data processing task. Traditionally,
the distinction of signal and noise is done in the
frequency domain, where noise contributes with
a broad background to a signal which should oc-
cupy distinguished frequency bands only. If the
signal itself is irregular in time and hence has a
broad power spectrum, spectral methods have a
poor performance. Nonlinear methods for noise
reduction assume and exploit constraints in the
clean signal which are beyond second order statis-
tics and hence are most eﬃciently captured by
non-parametric dynamical modelling of the sig-
nal. In this paper it is shown that a particular
such algorithm is able to denoise a recorded hu-
man voice signal so that the recognition rate of
a commercial speech recognition program is sig-
niﬁcantly enhanced. Hence, we have not only a
more suitable quantiﬁer for the success of noise
reduction on human voice, but we also verify that
noise reduction algorithms do what they should
do, namely enhance the intelligibility of the sig-
nal. This latter aspect is highly non-trivial, since
every noise reduction algorithm when removing
noise also distorts the signal. Finding merely a
positive gain hence does not guarantee that a hu-
man (or algorithm) really understands better the
meaning of the signal.

∗Electronic address: http://www.chaosandnoise.org
†Electronic address: kantz@pks.mpg.de

I.

INTRODUCTION

Noise reduction and source separation are ubiquitous
data analysis and signal processing tasks. In the anal-
ysis of chaotic data, noise reduction became a promi-
nent issue about 15 years ago [1, 2, 3, 4, 5, 6, 7, 8, 9].
Since the analysis of chaotic data in terms of dimen-
sions, entropies and Lypunov exponents requires an ac-
cess to the small length scales (small scale ﬂuctuations
of the signal), already a moderate amount of measure-
ment noise on data is known to be destructive. On the
other hand, a deterministic source of a signal, albeit po-
tentially chaotic, supplies redundancy which enables one
to distinguish between signal and noise and eventually
to remove the latter to some extend. Noise reduction
schemes which exploit such dynamical constraints were
proposed in [1, 2, 3, 4, 5, 6, 7, 8, 9] and where tested
on many data sets. Since such algorithms were designed
to treat chaotic data, they do not make use of spectral
properties of data and can, in principle, even remove in-
band noise, i.e., noise whose high frequency spectrum is
identical to the spectrum of the signal.

Human voice is a typical non-stationary signal, where
noise reduction is a relevant issue. In telecommunication,
in the development of hearing aids, and in automatic
speech recognition, noise contamination of the speech sig-
nal poses severe problems. Having multiple simultaneous
recordings, noise reduction is also known as blind source
separation. However, most often a single recording only
is available. In a previous study [10, 11] we demonstrated
that nonlinear noise reduction can cope with noise on hu-
man speech data and has a performance which is compa-
rable to advanced spectral adaptive ﬁlter banks.

The performance of a noise reduction scheme is usually
measured as gain in dB. For this purpose, one starts with
a clean signal ˜x(t), numerically adds noise to ˜x(t) result-
ing in x(t), and then applies the noise reduction scheme
without making use of ˜x(t). When we call the result of
the noise reduction y(t), then the gain is deﬁned as the
logarithm of the noise power before and after the noise
reduction, i.e.,

gain = 10 log(

h(x(t) − ˜x(t))2i
h(y(t) − ˜x(t))2i

) .

This quantity has three drawbacks, namely i) it cannot be
computed without knowledge of the clean signal ˜x(t), ii)
it can be negative if the initial noise level is low, since dis-
tortion of the signal by the ﬁlter can be stronger than the
reduction of noise, and iii) it does not quantify whether
the intelligibility of the signal was improved by the noise
reduction. Therefore, we employ in this paper a com-
mercial speech recognition program as a quantiﬁer of the
success of noise reduction. The relative number of words
which are not correctly recognized is taken as a quanti-
ﬁer for the signal corruption, regardless of whether this
is noise or some systematic distortion which might be
introduced by the noise reduction scheme.

In this paper we brieﬂy recall the algorithm includ-
ing its adaptation for the treatment of voice data, which
are nonstationary limit cycle-like signals with embed-
ded noisy segments (stemming from the fricatives). We
then apply it to data samples which without added noise
are perfectly recognized by the speech recognition soft-
ware. We demonstrate that our optimised noise reduc-
tion scheme does not reduce the recognition rate when it
is applied to clean data, and that it improves the recog-
nition rate when it is applied to noisy data, which is
comparable with a reduction of the noise amplitude by
about 1/2.

II. METHOD

For the purposes of noise reduction (NR) in voice signal
we use a combination of the GHKSS [9] and the LPNCF
[12] methods. The GHKSS method is one version of the
Local Projective (LP) [1, 2, 3, 4, 5, 6, 7, 8, 9] method
that was developed for chaotic signals corrupted by noise.
Assuming that the clean data are conﬁned to some deter-
ministic attractor in a reconstructed state space, which
itself is locally a subset of a smooth manifold, the method
aims at identifying this local manifold in linear approxi-
mation and to project the noisy state vector (which due
to noise is not conﬁned to this hyperplane) onto the local
manifold. Algorithmically, this means to identify a neigh-
bourhood in the delay embedding space and to perform a
Singular Value Decomposition of a particular covariance
matrix. Some reﬁnements are described in [9].

The LPNCF method, which was particularly devel-
oped for chaotic ﬂows, makes use of nonlinear constraints
which appear because of the time continuous character
of the ﬂow. These constraints vanish for dense sampling.
Let {xi} for i = 1, 2, . . . , N be the time series. The cor-
responding clean signal we denote as {˜xi}, so when the
measurement noise {ηi} is present we come to the for-
mula xi = ˜xi + ηi for i = 1, 2, . . . , N . We can deﬁne
the time delay vectors xi = (xi, xi−τ , . . . , xi−(d−1)τ ) as
our points in the reconstructed phase space. Then we
can ﬁnd two nearest neighbors xk, xj ∈ XN N
to vector
xn (XN N
is the set of nearest neighborhood of the point

n

n

2

(2)

xn). Let us introduce the following function [13]

Gn(s) = xn−s (xk+1−s − xj+1−s)

+xk−s (xj+1−s − xn+1−s) + xj−s (xn+1−s − xk+1−s) ,(1)

for s = 0, 1, . . . , d − 1.

The function Gn(s) vanishes for clean one-dimensional
systems because it appears after eliminating a and b from
following equations:

˜xn+1 = a˜xn + b
˜xk+1 = a˜xk + b
˜xj+1 = a˜xj + b.

In the case of higher dimensional systems function Gn(s)
does not always vanish but is altering slowly in time for
dense sampling.

Now one can check that for a highly sampled clean

dynamics there can be derived such a constraint

Cm

n =

(−1)lGn(k) ≈ 0,

m−1

X
k=0
int(log2(k))

X
s=1

(l = k +

int(k/2s))

(3)

where int(z) is a integer part of z and log2(z) is a loga-
rithm with a base 2 from z. Similarly as in LP methods
the constraints (3) are satisﬁed in this approach by ap-
plication of the method of Lagrange multipliers to an
appropriate cost function. Since we expect that correc-
tions to noisy data should be as small as possible, the cost
function is assumed to be the sum of squared corrections
s=1 (δxs)2. The method is a compromise between
S = P
time and space integration methods. In the constraints
appear nearest neighbors in time and in space so it can
perform better than standard time averaging and stan-
dard LP methods. This is because size of neigbourhood
in time and in space is smaller in the LPNCF method
than in standard methods which use only time or space
averaging.

N

The results of the following section were obtained by a
hybrid method which links the LPNCF and the GHKSS
[9] methods. Corrections coming from the GHKSS and
the LPNCF methods are added and divided by half.

It is known that the voice signal in the most of the
course has many similarities with a ﬂow [10], i.e., it rep-
resents smooth anharmonic oscillations with a frequency
of about 200 Hz. However, articulated human voice is a
concatenation of diﬀerent phones, so that the frequency,
amplitude and, most importantly, the wave form of the
oscillation varies tremendously on time scales of about 50
to 200 ms, causing that this signal is highly nonstation-
ary. A qualitatively diﬀerent component in articulated
human voice is due to fricatives and sibilants, which are
high frequency broad band noise like parts of the sig-
nal. Such a sound starts around n=41200 in Fig. 1 (a).
All nonlinear noise reduction schemes are very suitable

n

 

x

a)

b)

c)

0.2
0.1
0.0
-0.1
-0.2
0.2
0.1
0.0
-0.1
-0.2
0.2
0.1
0.0
-0.1
-0.2

 

 

36000 37000 38000 39000 40000 41000 42000 43000

Time step n

 

The voice time series of the word ”M¨unchen”,
FIG. 1:
recorded with a sampling rate of 22100 kHz. The top panel
is the clean signal, the next one shows the signal with added
noise (%N = 35%), the bottom the signal after noise reduc-
tion.

for removing noise from anharmonic oscillations but they
have the tendency to suppress strongly the fricatives and
sibilants. Since the latter are of utmost relevance for
a correct recognition by a speech recognition algorithm,
we have to take special care of these. Finally, there are
pauses in the speech which are pure noise after noise con-
tamination of the signal. It is important to remove the
noise during the speech pauses, so that the beginning and
ending of words is correctly identiﬁed by the recognition
algorithm. A particular challenge lies in these two op-
posing requirements: noise like fricatives should not be
suppressed, whereas noise during speech pauses must be
eliminated.

So the important modiﬁcation of the standard algo-
rithms for stationary data here is to identify the frica-
tives/sibilants and to treat them in a diﬀerent way. As
a ﬁrst step we compute the auto-correlation function in
a gliding window analysis (using windows of 300 sam-
ple points, i.e., about 15 ms). The location of the ﬁrst
maximum serves as a rough estimate of the dominant pe-
riod in the signal. We can then deﬁne windows in time
during which the dominant frequency is rather constant.
Obtaining the autocorrelation function is rather fast be-
cause we use previous calculations in next windows.

If we detect small maximum, less then some threshold,
we consider this part of the signal as the noise and we
put a maximal period. We are doing such to distinguish
signal with very small period from noise. Noise we would
like to ﬂatten to zero but signal save unchanged thats
why we do not do corrections when the period is less
than 6. Sounds like ’s’,’tch’,’h’ are like a noise with very
little of periodicity but the energy ﬂow (here variance) is
much higher than for the noise (see the Fig. 1 a) starting
from n=41200 begins ’chen’).

The estimated period inside a window is used to ﬁx
almost all of the parameters of the algorithm, e.g., the
embedding dimension and embedding delay in nearest

3

 

 

 

neighborhood searching, the maximal embedding projec-
tion, a maximal range of neighborhood in time etc. We
also optimize some preliminary averaging of the signal
in time on the neigbourhood size of 4/160 of the main
period of the window.

In order to speed up the algorithm, we make use of
the observation that a delay vector xj which is a neigh-
bour of a point xn gives rise to a delay vector xj+s which
most surely is also neighbour of xn+s, if s < 30. Hence,
the neighbour search is only done every 30 time steps,
whereas in between the “old” neighbourhood is simply
translated in time. Due to the rather large embedding
dimensions of about 3-12, it is suﬃcient to perform the
correction for every 6th point only, since the ﬁnal time
series is the arithmetic mean of all corrected vectors xn,
i.e., corrections of unprocessed data come from process-
ing their neighbours and consecutives in time which are
corrected.

III. RESULTS AND CONCLUSIONS

The speech recognition is done by the commercial soft-
ware program Linguatec ViaVoice Pro release 10 for Ger-
man, which is based on the IBM recognition algorithm
viavoice. The diﬃculty in speech recognition lies in the
required training of the algorithm in order to adapt to
a speciﬁc speaker. In order to make our results repro-
ducable, we downloaded the sample sentences together
with the speaker speciﬁc auxiliary data ﬁles, from the
distributor[14].

We were working on the following recorded sentences

in German:
”M¨unchen, der 21.10.04. Sehr geehrter Herr Schnei-
der, Sicher werden wir noch viel zu besprechen haben.
Das Problem liegt oﬀensichtlich an der Funktionsvielfalt.
Ein Vertragsabschluss kann von uns nur erfolgen, wenn
auch eine Konventionalstrafe vereinbart wird, und zwar
in H¨ohe von 1.000,- pro Tag Verzug. Dies wird voraus-
sichtlich in der ersten Juniwoche sein. Mit freundlichen
Gr¨ußen”.

As outlined above, the method was optimized not only
on performance and maximal gain but also for speed.
The algorithm is rather fast. The data recorded with
22050 Hz gives about milion data for 45 seconds, but
nevertheless the method works only ca. 130 seconds i.e.
3 times slower than on-line noise reduction, on a 2 GHz
processor AMD Athlon.
In Fig. 1 we show the signal
which corresponds to the word ”M¨unchen”. In the upper
panel (a) there is a clean signal. In the middle, part (b),
the noisy signal with standard deviation (SD) of noise
equal 0.009 and in the bottom, part c), the noisy signal
after NR. As pointed out before, around n=41200 the
fricative “ch” (pronounced as [¸c]). The autocorrelation
function suggests a period of 4, and the variance is much
larger then for noise on a pause which can be seen on
the beginning of the signal (b). The signal (a) and (c)
are recognized well by the program but the noisy sig-

4

 

 

0.000

0.003
SD of added noise

0.006

0.009

0.012

FIG. 2: Plot of similarities and diﬀerences in letters of the
correct text and texts recognized from noisy signals (squares
and circles) or texts recognized from noisy signals after noise
reduction (triangles). Standard deviation of added noise ap-
pears at the x-axis.

 

 

 Differences
 Similarities
 Differences after NR
 Similarities after NR

 Differences
 Similarities
 Differences after NR
 Similarities after NR

400
350
300
250
200
150
100
50
0
-50

s
r
e
t
t
e
l
 
f
o
 
r
e
b
m
u
N

400
350
300
250
200
150
100
50
0
-50

s
r
e
t
t
e
l
 
f
o
 
r
e
b
m
u
N

0.000

0.003

0.006

0.009

0.012

SD of left noise

FIG. 3: Plot of similarities and diﬀerences in letters of the
correct text and texts recognized from noisy signals (squares
and circles) or texts recognized from noisy signals after noise
reduction (triangles). Standard deviation of left noise after
noise reduction appears at the x-axis.

in the present study are much smaller than those consid-
ered in [11], since larger noise levels completely destroy
the speech recognition. We see that the gain parameter
is not good indicator of the recognition rate. However,
even if the gain is negative the program for speech recog-
nition is not much mislead. On the above examples it
is well seen that noise removing using chaos like features
improve the recognition rate especially for intermediate
noise levels.

nal (b) is badly represented in the recognition of the full
text. Hence, although the noise level appears to be small,
the recognition software is considerably confused and the
recognition rate drops signiﬁcantly.

The algorithm of the recognition program enforces it to
generate reasonable words only. However, if the system
is strongly misled, it can generate a long wrong word
out of several short ones or vice versa, such that the
number of words is not conserved. However, the number
of letters is more or less unchanged. Hence, in order
to do statistics on the recognised sentences, we use the
following indicator: We identify the correctly recognised
words and those words which are not part of the original
sentences, and then count the numbers of letters inside
these two groups of words.

In Fig. 2 we show these diﬀerences and similarities
as a function of the amount of noise added. Without
noise reduction, a standard deviation of the added noise
of more than 0.003 leads to mis-interpretations of the
If one takes into account
speech recognition software.
that every wrongly recognised letter requires a correction
by hand, the recognition is useless when more than half
of the number of characters has to be replaced. This sit-
uation occurs for noise levels above 0.007 (%N = 28%).
After noise reduction, the recognition rate increases con-
siderably. However, for very low noises distortions of the
signal introduced by the noise ﬁltering leads to a small
number of wrongly recognised letters.

The results can be interpreted in an even better way,
when we compute the noise level after noise reduction as
h(y(t) − ˜x(t))2i and present the recognition success as a
function of the latter. This is shown in Fig. 3. In this
ﬁgure the two lines with squares and circles represent-
ing the result without noise reduction are the same as
in Fig. 2. The two lines with triangles in Fig. 3, repre-
senting the results after noise reduction, now lie almost
on the same curve as without noise reduction. We can
therefore conclude that the remaining distortion of the
signal after noise reduction has the same aﬀect as white
noise with a corresponding amplitude, and that the ef-
fective noise level h(y(t) − ˜x(t))2i (which unfortunately
can only be computed in the unrealistic situation where
the clean signal is available) determines the recognition
rate uniquely.

This happens so only if we use the same parameters in
noise reduction and if the noise magnitude is similar in
whole of data set after noise reduction.

The gain parameter corresponding Figs 2,3 is presented
in Fig. 4. One can see that the eﬃciency of noise reduc-
tion is not very high especially for small noise levels. On
the beginning it is even negative because the clean sig-
nal is disturbed during the noise reduction because the
voice is not well represented by a ﬂow and is not always
smooth (see Fig. 1). Also for larger noise levels the gain
is small compared to gains obtained in [11], which re-
ﬂects that the data structures which must be preserved
for a good recognition cannot be directly translated into
gain. Also, however, the noise levels which are relevant

 

5

6

4

2

0

-2

-4

-6

-8

]

B
d
[
 

G

 

-10
0.000

0.003

0.006
SD of added noise

0.009

0.012

FIG. 4: Plot of the gain parameter versus SD of added noise
in the signal.

[1] E.J. Kostelich and T. Schreiber, Phys. Rev. E 48(3),1752

T. Schreiber, Chaos 3(2),127 (1993).

(1993).

(1991).

(1992).

[2] T. Schreiber, Phys. Rev. E 48(1),13(4) (1993).
[3] T. Schreiber, Phys. Rev. E 47(4),2401 (1992).
[4] J. D. Farmer and J.J. Sidorowich, Physica D 47, 373-392

[5] S.M. Hammel, Phys. Lett. A 148, 421 (1990).
[6] M.E. Davies, Physica D 79, 174 (1994).
[7] R. Cawley and G. H. Hsu, Phys. Rev. A 46(6), 3057

[8] T. Sauer, Physica D 58, 193 (1994).
[9] P. Grassberger, R. Hegger, H. Kantz, C. Schaﬀrath and

[10] R. Hegger, H. Kantz and L. Matassini, Phys. Rev. Lett.

84, 3197-3200 (2000).

[11] H. Kantz. R. Hegger, L. Matassini, IEEE Trans. Circuits

and Systems I, 48, 1454 (2001).

[12] K. Urbanowicz and J.A. Ho lyst, will be published,

arXiv:cond-mat/0411324.

[13] K. Urbanowicz, J.A. Ho lyst, T. Stemler and H.
Benner, Acta Phys. Pol B 35 (9), 2175 (2004);
arXiv:cond-mat/0308554.

[14] Linguatec web page: http://www.linguatec.de

