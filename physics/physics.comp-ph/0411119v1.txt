4
0
0
2
 
v
o
N
 
1
1
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
9
1
1
1
1
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A linear theory for control of non-linear stochastic systems

SNN/2004-1

Hilbert J. Kappen∗
Department of Medical Physics & Biophysics
Radboud University, Geert Grooteplein 21
6525 EZ Nijmegen, The Netherlands †
(Dated: February 17, 2014)

In this paper, we consider linear-quadratic control of an arbitrary dynamical system. We show,
that for this class of stochastic control problems the non-linear Hamilton-Jacobi-Bellman equation
can be transformed into a linear equation. The transformation is similar to the transformation
used to relate the Schr¨odinger equation to the Hamilton-Jacobi formalism. The computation can
be performed eﬃciently by means of a forward diﬀusion process that can be computed by stochastic
integration, spectral methods or cumulant expansion.

PACS numbers: 02.30 Yy, 02.50 Ey, 05.45. -a, 07.05.Dz, 45.80.+r

I.

INTRODUCTION

The problem of optimal control of non-linear systems
in the presence of noise occurs in many areas of science
and engineering. Examples are the control of movement
in biological systems, robotics, and ﬁnancial investment
policies.

In the absence of noise, the optimal control problem
can be solved in two ways: using the Pontryagin Mini-
mum Principle (PMP) [1] which is a pair of ordinary dif-
ferential equations that are similar to the Hamilton equa-
tions of motion or the Hamilton-Jacobi-Bellman equation
which is a partial diﬀerential equation [2]. In the presence
of noise described by a Wiener process, the PMP formal-
ism yields a set of stochastic diﬀerential equations which
become diﬃcult to solve due to the boundary conditions
at initial and ﬁnal time (see however [3]). In contrast, the
inclusion of noise in the HJB framework is quite straight-
forward.

The (stochastic) HJB equation is a non-linear partial
diﬀerential equation (pde) and its numerical solution is in
general diﬃcult. A well-known special case occurs when
the dynamics is linear in the state variable x and the
control variable u and when the cost function is quadratic
in x and u (linear-quadratic control). In this case, J is
a quadratic function in x with time-varying coeﬃcients
that satisfy the (stochastic) Ricatti equation, which can
be solved eﬃciently [4].

In this paper, we consider the more general problem,
where the dynamics is linear in u and the cost is quadratic
in u, but where the x and t-dependence is arbitrary. In
other words, we consider an arbitrary dynamical system
that is subject to linear-quadratic control.

We show that under certain conditions on the noise,

the HJB equation can be written as a linear pde

∂tΨ = HΨ

(1)

∗Electronic address: B.Kappen@science.ru.nl
†URL: http://www.snn.kun.nl/~bert

R

H).

with H a (non-Hermitian) diﬀusion operator and ∂t de-
notes partial diﬀerentiation wrt t. The solution of the
control problem then reduces the computation of the
In this way, we relate the non-linear
kernel exp(
control problem to (Euclidean) quantum mechanics and
statistical physics. The solution to Eq. 1 can be either
computed in a ’Heisenberg picture’ where Ψ is a time-
dependent function that is computed backwards in time,
or in a ’Schr¨odinger picture’ where a time-dependent den-
sity evolves forward in time. To compute a numerical
solution in the Schr¨odinger picture, standard approxi-
mation methods can be used, such as Monte Carlo in-
tegration, a spectral decomposition or using a cumulant
expansion of the lower-order moments of the density [5].

II. THE METHOD

Let x be an n-dimensional stochastic variable that is

subject to the stochastic diﬀerential equation

dxi = (bi + ui)dt + dξi

(2)

i

h

dξidξj

with dξ a Wiener process with
= 2νijdt, bi(x, t)
an arbitrary function of x and t, νij independent of x, u, t
and ui the control variables. Given x at an initial time
t, the stochastic optimal control problem is to ﬁnd the
) that minimizes
control path u(
·
)) =
C(x, t, u(
·

φ(x(T )) +

*

T

dt′

1
2

(cid:18)

t
Z

u(t′)T Ru(t′) + V (x(t′), t′)

(cid:19)+x
(3)

with R a matrix independent of x, u, t and V a time-
dependent potential. The brackets
hix denote expecta-
tion value wrt the stochastic trajectories (2) that start
at x.

One deﬁnes the optimal cost-to-go function from any

time t and state x as

J(x, t) = min
u(·)

))
C(x, t, u(
·

(4)

(6)

(7)

(8)

J satisﬁes the stochastic HJB equation which takes the
form

1
2

Jt = min

uT Ru + V + (b + u)T ∂xJ + Tr (ν∂x∂xJ)

(cid:18)
(cid:19)
(∂xJ)T R−1∂xJ + V + bT ∂xJ + Tr (ν∂x∂xJ)(5)

u

1
2

−

=

−

with

u =

R−1∂xJ

−

the optimal control at x, t. The HJB equation is non-
linear in J and must be solved with end boundary con-
dition J(x, T ) = φ(x).

Deﬁne Ψ(x, t) through

J(x, t) =

λ log

−

2
Ψ(x, t)
|
|

and assume there exists a scalar λ such that

λ1 = Rν

with 1 the unit matrix. In the one dimensional case, such
a λ can always be found. In the higher dimensional case,
ν−1. To get an intuition
this restricts the matrices R
for this restriction, consider both R and ν diagonal ma-
trices. In a direction with low noise, the relation states
that control is expensive (Rii large) and only small con-
trol steps are permitted. In noisy directions the reverse
is true: control is cheap and large control values are per-
mitted [9].

∝

When Eq. 8 holds, the HJB equation becomes a linear

equation of the form eq. 1 with

H =

V
2λ −

bT ∂x

Tr(ν∂x∂x)

−

(9)

For functions ρ and ψ, deﬁne the inner product
=
dxρ(x)ψ(x). Then the Hermitian conjugate of H is

ψ
|

ρ
h

i

deﬁned by
R

H †ρ =

V
2λ

ρ + ∂x(bρ)

Tr(ν∂x∂x)ρ

−

We recognize
of a diﬀusion process

−

H † as the evolution kernel for the density

∂tρ =

H †ρ

−

Denote by Ψt = exp(

t
T H)ΨT the solution of Eq. 1 at
time t < T , with ΨT the end condition. Evaluating Ψt
at an arbitrary point x is equivalent to taking the inner
product with a point density ρx(y) = δ(y
x). Therefore,
we have

−

R

Ψ(x, t) =

ρx
h

Ψt
|

i

=

ρx

exp

|

(cid:28)
T

t

H

ΨT

T

(cid:18)Z

(cid:19)

(cid:29)

=

exp

H †

ρx

ΨT
|

+

!

 −

t
Z

=

dyρ(y, T

x, t)Ψ(y, T )
|

(11)

*

Z

2

We arrive at the important conclusion that Ψ(x, t) can
be computed either by backward integration of ΨT or by
forward integration of a point distribution ρx from time
t until T (which we denote by ρ(y, T

x, t)).
|

III. AN EXAMPLE: DOUBLE SLIT

Consider a 1-dimensional case where the stochastic
particle moves with constant velocity from t = 0 to T
in the horizontal direction and where there is deﬂecting
noise in the x direction:

dx = udt + dξ

The cost is given by eq. 3 with φ(x) = 1
2 x2 and V (x, t1)
implements a slit at an intermediate time t1, 0 < t1 < T :

V (x, t1) = 0,

a < x < b,

c < x < d

=

,
∞

else

The problem is illustrated in Fig. 1.

Solving Eq. 1 by means of the forward computation
using Eq. 11 can be done in closed form. First consider
the easiest case t > t1 where we do not have to consider
the slits. The solution for ρ is Gaussian

ρ(y, T

x, t) =
|

1

4πν(T

t)

−

exp

(y
−
4ν(T

x)2
t)

−

(cid:19)

−

(cid:18)

and since ΨT is also Gaussian, Eq. 11 yields

p

Ψ(x, t) =

R
R + T

exp

t

1
4ν

x2
R + T

−

(12)

t

r

Second, consider t < t1. ρ(y, T

(cid:18)
x, t) can be written as
|
a diﬀusion from t to t1, times a diﬀusion from t1 to T
integrating over all x in the slits.

−

−

(cid:19)

ρ(y, T

x, t) =
|

b

d

+

 Z
a

c !

Z

dx1ρ(x1, t1|

x, t)ρ(y, T

x1, t1)
|

Substitution in Eq. 11 yields after some algebra:

(10)

Ψ(x, t) =

(F (b, x)

F (a, x) + F (d, x)

R
R + T

1
2 r
−
F (c, x)) exp

t

−

−
x2
4ν(R + T

−

(cid:18)

t)

(cid:19)

−

(13)

1

A

4ν (x0 −

B(x)
with F (x0, x) = Erf
t1−t +
A )
R+T −t1 and B(x) = x
(cid:16)q
(cid:17)
t1−t . Eqs. 12 and 13 together pro-
vide the solution for the control problem in terms of Ψ.
We can compute the optimal cost-to-go from Eq. 7 and
the optimal control from Eq. 6.

, A = 1

A numerical example for the solution for J(x, t) is
shown in ﬁg. 2. The two parts of the solution (com-
pare t = 0.99 and t = 1.01) are smooth at t = t1 for
x in the slits, but discontinuous at t = t1 outside the

8

6

4

2

0

−2

−4

−6

5

4

3

2

1

J

0

0.5

1

1.5

2

FIG. 1: The double slit problem. The particle moves hor-
izontally with constant velocity from t = 0 to T = 2 and
is deﬂected up or down by noise and control. The end cost
φ(x) = x
/2. A double slit is placed at t1 = 1 with openings
at −6 < x < −4 and 6 < x < 8. Also shown are two example
trajectories under optimal control. R = 0.1, ν = 1, dt = 0.02.

2

t=0
t=0.99
t=1.01
t=2

0
−10

−5

0
x

5

10

FIG. 2: The double slit problem. J(x, t) as a function of x
for t = 0, 0.99, 1.01, 2 as computed from Eq. 12 and 13 and
Eq. 7. R = 0.1, ν = 1, dt = 0.02.

slits. For t = 0, the cost-to-go J is higher around the
right slit than around the left slit, because the right slit
is further removed from the optimal target x = 0 and
thus requires more control u and/or its expected target
cost φ is higher.

IV. APPROXIMATE METHODS

In the above example, the computation of the diﬀu-
sion was easy because V = 0 almost everywhere, H is
Hermitian almost everywhere and the problem was one
dimensional. This allowed us a solution in closed form.
In general, this is not the case and we need approximate

3

methods to solve the control problem. We mention three
diﬀerent approaches: Monte Carlo sampling, a spectral
decomposition and a cumulant expansion.

The value of Ψ(x, t) in Eq. 11 can be computed by

forward sampling of the stochastic process

dxi = bidt + dξi
xi = xi + dxi, with probability1
, with probabilityV dt/2λ
xi =

−

V dt/2λ

(14)

†

†

where
denotes that the particle is taken out of the simu-
lation. Eqs. 14 represents a diﬀusion that runs in parallel
with a particle annihilation process with rate V /2λ. Note
that when V = 0 this diﬀusion process is identical to the
original dynamics Eq. 2 in the absence of control (u = 0).
x, t) the value of x at time T of trajectory
|
i when starting at (x, t). Then for N trajectories, Eq. 11
can be estimated as

Denote x(T, i

Ψ(x, t) =

Ψ(x(T, i

x, t), T )
|

1
N

N

i=1
X

with the understanding that the annihilated particles do
not contribute to the estimate: Ψ(
, T ) = 0. Arbitrary
†
accurate results can be obtained by simulating a suﬃ-
ciently large number of stochastic trajectories.

To assess the validity of this approach, we have esti-
mated J(x, t = 0) of the above double slit problem by
this method. The results are compared with the exact
result and are illustrated in ﬁg. 3. We note, that the
number of required trajectories strongly depends on the
value of λ = νR and φ due to the factor exp(
φ(x)/λ) in
Eq. 14. For high noise, few samples are required, but for
small noise the estimate is dominated by the trajectory
with minimal φ(x) and many samples may be required
to reach this x. For the same reason, large values of J
are more diﬃcult to estimate than small values, as is ev-
ident from Fig. 3. This is in a sense fortunate, since the
objective of the control is to move the particle to lower
values of J so that subsequent estimates become easier.
In addition, the sampling is of course diﬃcult because of
the inﬁnite potential that annihilates most of the trajec-
tories.

−

Since the control requires the computation of the gra-
dient of Ψ(x, t), both ρ(y, T
x + dx, t) for
x, t) and ρ(y, T
|
|
some small dx should be computed. Signiﬁcant speed-ups
can be made because 1) not very accurate u are needed,
since errors in u will average out between subsequent time
steps and 2) results of sample trajectories that start at
time t can be reused at later times.

Another approach is a spectral decomposition.

If H
does not explicitly depend on time, we can solve eq. 1 or
Eq. 10 in terms of the eigenfunctions vE(x) and eigenval-
ues E of H. Ψ or ρ can then be decomposed in terms of
their spectral components. For instance, the solution to
Eq. 1 is given by

Ψ(x, t) =

αE(t)vE(x),

(15)

E
X

10

5

0

−5

−10

0

10

J

8

6

4

2

0.5

1

1.5

2

MC
Exact

0
−10

−5

0
x

5

10

FIG. 3: Monte Carlo sampling of J(x, t = 0) with Ψ from
Eq. 14 for the double slit problem. The parameters are as
in ﬁg. 1. Left: only trajectories that pass through a slit con-
tribute to the estimate. Right: MC estimate of J(x, t) = 0
with N = 100000 trajectories for each x.

−

t)E). When discretized,
with αE(t) = αE(T ) exp((T
H is a sparse matrix. Eﬃcient numerical routines can be
used to compute a few important eigenvalues and eigen-
vectors. An approximate solution can be computed by
restricting the sum in Eq. 15 to only these components.
In general H is not Hermitian, and therefore the eigen-
vectors may not span the full space. Numerical stud-
ies (not reported here) have shown that this approach is
feasible in principle, but computationally challenging for
problems in more than one-dimension.

A third method is to approximate ρ in Eq. 10 by some
of its moments and compute the dynamics for these mo-
ments (cumulant expansion [5]). Such an approach may
be very eﬃcient for not too non-linear dynamics b, but
may be problematic in the presence of obstacles.

4

bitrary cost, where the control acts linearly on the dy-
namics and the cost of control is quadratic. The method
provides a signiﬁcant generalization of the well-known
class of linear quadratic stochastic control problems [3].

For control problems in more than one dimension,
there is a restriction on the relation between the noise
covariance matrix and the control directions as given by
Eq. 8, but this still allows for interesting special cases. I
believe, that important applications of this method may
be found in the control of non-linear plants or in control
of robots in the presence of physical obstacles.

There is a superﬁcial relation between the work pre-
sented in this letter and the body of work that seeks
to ﬁnd a particle interpretation of quantum mechan-
In fact, the log transformation Eq. 7 was moti-
ics.
vated from that work. Madelung [6] observed that if
Ψ = √ρ exp(iS/~) is the wave function that satisﬁes the
Schr¨odinger equation, ρ and S satisfy two coupled equa-
tions. One equation describes the dynamics of ρ. The
other equation is a Hamilton-Jacobi equation for S with
an additional term, called the quantum-mechanical po-
tential. Nelson showed that these equation describe a
stochastic dynamics in a force ﬁeld given by the
S,
where the noise is proportional to ~ [7, 8].

∇

−

Comparing this to the relation Ψ = exp(

J/2νR) used
in this letter, we see that ν plays the role of ~ as in the
QM case. However, an important diﬀerence is that Ψ is
real in our case and the i is lacking in the propagator
exp(
H). The Schr¨odinger equation is complex valued
and describes two real valued equations, one of which
is the evolution of the density. The density evolution is
non-linear because the drift force depends on the density
through S as computed from the HJ equation. Such non-
linearities are absent in our control problem.

R

Finally, it would be interesting to express exp(

H) as

a path integral

R

exp(

H)

[dx] exp(

S/ν)

Z

∝

Z

−

The Action S gives the cost of a trajectory from (x, t)
to (y, T ). In the limit ν
0 the integral is dominated
by the path that minimizes the Action. In this limit we
should recover the PMP principle.

→

V. DISCUSSION

In this letter, I have introduced a linear method for
optimal control of arbitrary non-linear systems with ar-

I would like to thank Hans Maassen for useful discus-
sions. This work is supported in part by the Dutch Tech-
nology Foundation.

Acknowledgments

5

[1] L. Pontryagin, V. Boltyanskii, R. Gamkrelidze, and
E. Mishchenko, The mathematical theory of optimal pro-
cesses (Interscience, 1962).

[2] R. Bellman and R. Kalaba, Selected papers on mathemat-

ical trends in control theory (Dover, 1964).

[3] J. Yong and X. Zhou, Stochastic controls. Hamiltonian

Systems and HJB Equations (Springer, 1999).

[7] E. Nelson, Dynamical Theories of Brownian Motion

(Princeton University Press, Princeton, 1967).

[8] F. Guerra, Physics Reports 77, 263 (1981).
[9] As another example, consider a one-dimensional second
order system subject to additive control ¨x = b(x, t) + u.
The stochastic formulation is of the form

[4] R. Stengel, Optimal control and estimation (Dover publi-

dx = ydt,

dy = (b(x, t) + u)dt + dξ

cations, New York, 1993).

[5] N. van Kampen, Stochastic processes in physics and chem-

istry (North-Holland, Amsterdam, 1981).

[6] E. Madelung, Z. Physik 40, 322 (1926).

Eq. 8 states that due to the absence of a control term in
the equation for dx, the noise in this equation should be
zero.

