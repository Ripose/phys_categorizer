9
9
9
1
 
v
o
N
 
2
1
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
3
2
0
1
1
9
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

An improved Rosenbluth Monte Carlo scheme
for cluster counting and lattice animal
enumeration

C M Care ∗

R Ettelaie †

February 2, 2008

Abstract

We describe an algorithm for the Rosenbluth Monte Carlo enu-
meration of clusters and lattice animals. The method may also be
used to calculate associated properties such as moments or perimeter
multiplicities of the clusters. The new scheme is an extension of the
Rosenbluth method for growing polymer chains and is a simpliﬁcation
of a scheme reported earlier by one of the authors. The algorithm may
be used to estimate the number of distinct lattice animals on any lat-
tice topology. The method is validated against exact and Monte Carlo
enumerations for clusters up to size 50, on a two dimensional square
lattice and three dimensional simple cubic lattice. The method may be
readily adapted to yield Boltzmann weighted averages over clusters.

1 Introduction

The enumeration of lattice animals is an important problem in a variety of
physical problems including nucleation [1], percolation [2] and branched poly-
mers [3]. A lattice animal is a cluster of N connected sites on a lattice with
∗Materials Research Institute, Sheﬃeld Hallam University, Pond Street, Sheﬃeld, S1

†Colloids and Rheology Unit, ICI Wilton, PO Box 90, Wilton, Middlesbrough, Cleve-

1WB, UK

land, TS90 8JE, UK

1

given symmetry and dimensionality and we seek to enumerate all distinct
animals with a given number of sites. Exact enumeration has been carried
out for small lattice animals using a variety of methods [2,4,5] but the meth-
ods become computationally prohibitive for large animals. Many techniques
have been used to enumerate larger lattice animals including various Monte
Carlo growth schemes [2, 6–8], a constant fugacity Monte Carlo method [9],
an incomplete enumeration method [10] and reaction limited cluster-cluster
aggregation [3].

In the following paper we describe an improvement of a method proposed
by one of the authors [11] which was based on an extension of the scheme
proposed by Rosenbluth and Rosenbluth [12] for enumerating self avoiding
polymer chains. The central problem in using the Rosenbluth scheme for lat-
tice animal enumeration is calculating the degeneracy of the clusters which
are generated. In the method proposed by Care, the cluster growth was mod-
iﬁed in a way which forced the degeneracy to be N! where N is the number
of sites occupied by the lattice animal. However the resulting algorithm was
fairly complicated to implement. An alternative method of correcting for
the degeneracy had been proposed by Pratt [13]. In this latter scheme the
correcting weight is more complicated to determine and must be recalculated
at each stage of the cluster growth if results are sought at each cluster size.
However the Pratt scheme does not require any restriction on the growth of
the cluster.

In this paper we show that there are a class of Rosenbluth like algorithms
which yield a degeneracy of N and which are straightforward to implement.
The method provides an estimate of the number of lattice animals and can
also yield estimates of any other desired properties of the animals such as
their radius of gyration or perimeter multiplicities [2]. We describe and
justify the algorithm in Section 2 and present results to illustrate the use of
the method in Section 3. Conclusions are given in Section 4

2 Algorithm

Any algorithm, suitable for the purpose of the enumeration of lattice animals
using the Rosenbluth Monte Carlo approach, must satisfy two important
criteria. First of all it has to be ergodic. That is to say, the algorithm should
have a non zero probability of sampling any given cluster shape. The second
criteria relates to the degeneracy that is associated with each cluster and

2

requires this to be determinable. This degeneracy arises from the number
of diﬀerent ways that the same cluster shape can be constructed by the
algorithm. While it is easy to devise methods of growing clusters that meet
the ﬁrst requirement, the second condition is more diﬃcult to satisfy. For
many simple algorithms the calculation of the degeneracy, for every cluster,
can be a more complex problem than the original task of enumerating the
number of lattice animals.

In the original Rosenbluth Monte Carlo approach of Care [11], this dif-
ﬁculty was overcome by ensuring that the degeneracy for all clusters of size
N was the same and equal to N!. However, to achieve this result the al-
gorithm had to employ a somewhat elaborate procedure. This made the
implementation of the method rather complicated, as well as limiting its
possible extension to enumeration of other type of clusters. Here we shall
consider an alternative algorithm, which while satisfying both of the above
criteria, is considerably simpler than the algorithm proposed by Care.
In
Section 2.1 we describe the algorithm in its most basic form, before proving
in Section 2.2 that the ergodicity and the degeneracy requirements are both
met. In Section 2.3 we demonstrate how the basic algorithm can be further
reﬁned to improve its eﬃciency.

2.1 Basic Algorithm

Having chosen a suitable lattice on which the clusters are to be grown (square
and simple cubic lattices were used in this study for 2D and 3D systems,
respectively), a probability p of acceptance and q = (1 − p) of rejecting
sites is speciﬁed. Although in principle any value of p between 0 and 1 can
be selected, the eﬃciency of the sampling process is largely dependent on a
careful choice of this value, as will be discussed later. In addition, an ordered
list of all neighbours of a site on the lattice is made. For example, for a 2D
square lattice this might read (right, down, left, up). While the order initially
chosen is arbitrary, it is essential that this remains the same throughout a
given run. In the basic algorithm, once chosen, the probability p remains
ﬁxed during the Monte Carlo sampling procedure. However in Section 2.3
the eﬀect of relaxing this requirement is discussed.

We construct an ensemble of NE clusters and for each of these calculate
a weight factor which we subsequently use to calculate weighted averages of
various cluster properties. For a property O of the clusters, the weighted

3

average is deﬁned as

< O >W =

WαOα

(1)

1
NE

NE

Xα=1

The weight associated with cluster α with N sites is deﬁned to be Wα =
1/(dN Pα) where Pα is the normalised probability of growing the cluster and
dN is a degeneracy equal to the number of ways of growing a particular
cluster shape. It can be shown [11] that the weighted average can be used
to estimate the number, cN , of lattice animals of size N and other properties
such as the average radius of gyration R2

N :-

E[< 1 >W ] = cN
cN

E[< R2

ν >W ] =

R2

N ν = cN R2
N

X{ν=1}

(2)

(3)

During the growth of each cluster we maintain a record of the sites which
have been occupied, the sites which have been rejected and a ‘last-in-ﬁrst-out
stack’ of sites which is maintained according to the rules described below.
Each cluster is grown as follows

(i). Starting from an initial position, the neighbours of this site are exam-
ined one at a time according to the list speciﬁed above. An adjacent
site is accepted with a probability p or else is rejected.

(ii). If the adjacent site is rejected, a note of this is made and the next

neighbour in the list is considered.

(iii). If on the other hand it is accepted, then this becomes the current site
and its position is added to top of a stack, as well as to a list of accepted
sites. The examination of the sites is now resumed for the neighbours
of this newly accepted site. Once again this is done in the strict order
which was agreed at the start of the algorithm.

(iv). Sites that have already been accepted or rejected are no longer available
for examination. Thus, if such a site is encountered, it is ignored and
the examination is moved on to the next eligible neighbour in the list.

(v). If at any stage the current site has no more neighbours left, that is
all its adjacent sites are already accepted or rejected, then the current
position is moved back by one to the previous location. This will be
the position below the current one in the stack. The current position is

4

removed from the top of the stack, though not from the list of accepted
sites.

(vi). The algorithm stops for one of the following two reasons. If ever the
number of accepted sites reaches N, then the algorithm is immediately
terminated. In this case a cluster of size N is successfully produced.
Note that unlike some of the other common cluster growth algorithms
[8], it is not necessary here for every neighbour of the generated cluster
to be rejected. Some of these might still be unexamined before the
algorithm terminates. The second way in which the algorithm stops is
when it fails to produce a cluster of size N. In this case, the number of
accepted sites will be M < N, with all the neighbours of these M sites
already having been rejected, leaving no eligible sites left for further
examination. From step (v), it is clear that in cases such as this, the
current position would have returned to the starting location.

(vii). The probability of producing a cluster of size N, in a manner involving
r rejections, is simply p(N −1)qr. Hence the weight, Wα, associated with
the growth of the cluster is given by

Wα = 1/(dN p(1−N )(1 − p)r)

(4)

where the degeneracy, dN , is shown below to be exactly N. Failed
attempts have a zero weight associated with them. However they must
be included in the weighted average of equation (1).

(viii). During the growth of a cluster of size N, we may also collect data for all
the clusters of size M where M ≤ N. It must be remembered that the
weights for these smaller clusters must be calculated with a degeneracy
of M.

A speciﬁc example is helpful in demonstrating the algorithm. Figure 1
displays a successful attempt in forming a cluster of size N = 4, on a square
lattice. The order in which the neighbours were examined was chosen to
be right, down, left and up. Let us now consider various steps involved
in construction of this cluster in detail. Beginning from the initial position
labelled cell one, the adjacent site to the right of this position is examined. In
this case the site is rejected and the current position remains on the cell one.
Such rejected cells are indicated by the letter X. The next neighbour in the
list is the one below, labelled cell two. As it happens this is accepted. Thus,
the current position moves to this site and its position is added to the top

5

Figure 1: Sequence of accepted sites leading to a cluster of size N = 4. The
sites examined but rejected along the way are indicated by X. In our notation
this sequence can be represented by {0,1,1,0,0,0,1}

of the stack, ahead of the position of cell one. The process of examining the
neighbours is resumed for sites adjacent to cell two. Once again, following the
strict order in the list, the site labelled three to the right of current position
is considered ﬁrst. This is also accepted and as before is placed at the top of
the stack. At this stage the stack contains the positions of cells three, two
and one, in that order. The current position is now cell three.

The site to the right of this, followed by the one below, are tested and
both rejected in succession. Since both the neighbours to the left ( ie cell
one) and the one above have already been considered, the current position
has no more eligible neighbours left to test. Therefore, following step (v)
above, site three is removed from the stack. This leaves the position of cell
two at the top of the stack, making this the current position again. The cell
two has two neighbours, the adjacent sites below and to the left, which are
still unexamined. Of these, according to our agreed list, the site below takes
precedent, but as shown in Figure 1 this is rejected. Current position remains
on the cell two and the neighbouring site (cell labelled four) to the left of this
position is tested. As it happens this is accepted. A cluster of the desired
size N = 4 is achieved, bringing this particular attempt to a successful end.

For the subsequent discussion, it is useful to represent a sequence of ac-
ceptance and rejections by a series of 1 and 0. Thus, for the case shown in

6

Figure 1 we have {0,1,1,0,0,0,1}. Note that at any stage throughout a series,
the position of the current site and that of the neighbour to be examined,
relative to the starting cell, are entirely speciﬁed by the decisions that have
been made so far. In other words, given a sequence of one and zeros we can
determine precisely the shape of the cluster that was constructed. This is
only possible because of the manner in which the neighbours of the current
position are always tested in a strict pre-deﬁned order. For an algorithm
that considers the neighbouring sites at random, the same will clearly not be
true.

The procedure described above needs to be repeated a large number of
times, to obtain the weights for the ensemble average deﬁned in equation (1).
In particular, using equation 2, the number of lattice animals of size N can
now be determined.

2.2 Ergodicity and degeneracy of the algorithm

Let us now discuss the issue of the ergodicity of the algorithm. We wish to
see whether, starting from any particular site on a given cluster, a series of
acceptance and rejections (1 and 0) can always be determined which leads to
that cluster shape. We stress that we are not concerned about how probable
such a sequence is likely to be, but merely that it exists. We can attempt
to construct such a sequence by following the same rules as our algorithm
described above, with one exception; we accept and reject each examined
site according to whether it forms part of the target cluster shape or not.
Obviously, in the original algorithm, each such move has a non zero chance
of occurring, provided p is not set to zero or one. Since we only accept
sites that belong to the cluster in question, it follows that if the sequence
is successful then we would achieve the desired cluster shape. However, we
might argue that for some choice of target cluster and starting position, a
series started in this manner will always terminate prematurely. That is to
say, it will inevitably lead to a failure, with only part of the required cluster
having been constructed. Now, it is easy to see that this cannot be true. If
the series fails, it implies that all the neighbouring sites of the sub-cluster
formed so far are rejected. However, the rest of the cluster must be connected
to this sub-cluster at some point. Hence, at very least, one neighbouring site
of the sub-cluster must be part of the full cluster and could not have been
rejected. Starting from any of the sites belonging to a cluster then, it is
always possible to write down a sequence of one and zeros that will result

7

in the formation of that cluster. Similarly, considering every starting point
on a cluster of size N, another implication of the above result is that the
corresponding cluster shape can be generated in a minimum of at least N
distinct ways.

Next, we shall show that the degeneracy of a cluster of size N in our
algorithm is in fact exactly N (unlike the original algorithm of Care [11]
which has a degeneracy of N!). Let us suppose that starting from a particular
site on a given target cluster shape, our algorithm has two distinct ways of
forming this cluster. Associated with each of these, a series of one and zeros
can be written down, in the same manner as that indicated above. The
two ways of constructing the cluster must necessarily begin to diﬀer from
each other at some stage along the sequence, where we will have a 1 in one
case and a 0 in the other. Now since up to this point the two series are
identical, the site being examined at this stage will be the same for both
cases. This is rejected in one sequence (hence 0) whereas it is accepted in
the other (hence 1). It immediately follows that these two diﬀering ways of
constructing the cluster cannot result in the same shape. Using this result,
together with previous one regarding the ergodicity of the algorithm, we are
lead to conclude that, starting from a given site on a cluster, the algorithm
has one and only one way of constructing the cluster. Hence, for a cluster of
size N, the degeneracy is simply N.

2.3 Reﬁned algorithms

2.3.1 Adjacent site stack

During the growth of the cluster a stack can be constructed of all the sites
which are adjacent to the cluster and still available for growth. When a new
site is added to the cluster, its neighbours are inspected in the predetermined
sequence and any available ones are added to the top of this stack. (Note
that this stack diﬀers from that discussed in Section (2.1)). The choice of
site to be occupied can be made from all the adjacent sites in a single Monte
Carlo decision. Thus, if we consider the underlying process in the method
described above, at each step there is a probability p of the site being accepted
and a probability q = 1 − p of the site being rejected. We therefore need
to generate a random number with the same distribution as the number
of attempts needed to obtain an acceptance. The probability of making k

8

attempts of which only the last is successful, is

pk = qk−1p

where 1 ≤ k < ∞ and
we note that the associated cumulative distribution, Cm, is given by

∞
k=1 pk = 1. In order to sample from this distribution

P

Hence if we generate a random number, η, uniformly distributed in the range
0 < η < 1, then a number m given by

Cm =

qk−1(1 − q) = 1 − qm

m

Xk=1

m = Int

ln(η)
ln(q)

(cid:20)

+ 1

(cid:21)

(5)

(6)

(7)

will have been drawn from the required distribution. Thus we generate the
number m according to equation (7) and use this to determine which site on
the stack is selected, with m = 1 corresponding to the site at the top of the
stack. If m > Nadj, where Nadj is the number of available adjacent sites, the
cluster growth is terminated as explained in step ((vi)) in Section 2.1. All
the adjacent sites lying above the chosen site in the stack are transferred into
the list of rejected sites. The list of adjacent sites is then adjusted to include
the new available sites adjacent to the recently accepted site. As before, it
is crucial that these are added to the top of the list in the strict predeﬁned
order.

2.3.2 Variable probability

An apparent disadvantage of the methods so far described is that with ﬁxed
choice of probability, p, occasions arise when a cluster growth will terminate
before reaching a cluster of size N, simply because the Monte Carlo choice
rejected all the neighbouring sites. This problem can be overcome if the
value of p is allowed to vary as the cluster grows. The simplest method is to
determine the number, Nadj, of available adjacent sites at each point in the
cluster growth and select one of these sites with uniform probability. This
eﬀectively makes p = 1/Nadj and thereby increases the chances of growing a
cluster of size N. Note that it is still possible for a cluster growth to become
blocked. This happens when the chosen site is the one at the bottom of
the current eligible neighbours list, thus causing all the other neighbouring
If the newly accepted site has
sites in the list to be rejected in one step.

9

itself no unexamined neighbours to add to the list, the algorithm terminated
prematurely. Modiﬁed in the manner described above the weight associated
with a cluster is now

Wα =

ΠN

i=1N i
adj
N

(8)

rather than the expression given in equation (4).

However, when this variable probability method was tested it was found
that although it reduced the number of rejected clusters, it was ineﬃcient
at sampling the space of possible clusters when compared with method de-
scribed in section (2.3.1). This ineﬃciency was measured by comparison of
the standard deviation in the estimated cluster number for any given number
of clusters in the sampling ensemble. It is thought that the ineﬃciency of
the variable probability method arises because it gives too much weight to
sites lower in the stack, yielding many non-representative clusters. It is pos-
sible that this problem could be overcome by using a non-uniform sampling
distribution (cf [11]) but this was not tested in this work and the method
described in (2.3.1) was used to obtain the results described in Section (3) .

3 Results

In order to test the algorithm described in Section (2) it was used to esti-
mate the number of lattice animals on a square 2D lattice and a simple cubic
3D lattice for which exact results are known up to certain sizes [5]. Before
collecting data it was necessary to determine the optimum value of the prob-
ability p with which an adjacent site is accepted during the cluster growth.
The eﬀect of changing p on the estimated error in the number of clusters of
size 50 on the 2D and 3D lattices can be seen in Figure 2. It can be seen that
there is a fairly broad range of values of p for which the error is a minimum
and a value of p = 0.6 was used to obtain the results described below for the
2D lattice and 0.72 for the 3D lattice. The distribution of weights is log nor-
mal [11] and becomes highly skewed for large cluster sizes; this is a standard
problem with Rosenbluth methods [14]. The minimum in the error achieved
by the choice of the value of the probability p has the eﬀect of minimising
the variance of the distribution of the weights, Wα.

In Table 1 we present results obtained using the algorithm deﬁned in
section 2 using the adjacent site stack method of section 2.3 to enumerate
clusters on a simple cubic 3D lattice for clusters up to size 50. The results

10

Figure 2: Percentage errors for clusters of size 50

were obtained from an ensemble of 2.5 × 107 clusters. The data took 3.3
hours to collect on a R5000 Silicon Graphics workstation using code written
in the language C but with no attempt to optimise the code. Only 30% of the
clusters achieved a size of 50. The results are quoted together with a standard
error, eest, calculated by breaking the data into 50 blocks and determining
the variance of the block means for each cluster size. If the number of samples
in each block is suﬃcient, it follows from the central limit theorem that the
sampling distribution of the means should become reasonably symmetrical.
We therefore also quote a skewness, ξ, deﬁned by [15]

ξ = m3/m3/2

2

(9)

where mi is the ith moment about the mean of the sampling distribution.
It is expected that ξ <∼ 0.5 for a symmetrical distribution and ξ > 1 for a
highly skew distribution. The statistic ξ should be treated with some caution
since it is likely to be subject to considerable error because it involves the
calculation of a third moment from a limited number of data points.

Exact results are known for clusters up to size 13 [6] and in the table we

quote the values for the quantity χ deﬁned by

χM = |

cexact
M − cest
M
M eest
cexact
M

|

11

(10)

Figure 3: Variation of percentage error with cluster size.

where cM is the number of clusters of size M and it can be seen that all the
values of χ are O(1). Hence we assume that eest is an acceptable method
of estimating the error in the method. However it is likely that the eest will
underestimate the true error if the distribution becomes more skew. We also
quote in Table 1 the values of cN calculated by Lam [6] using a Monte Carlo
incomplete enumeration method together with the error estimates reported
for this method.

In Table 2 we quote data collected from a square two dimensional lattice
by collecting data from 2.5 × 107 clusters up to size 50. This data only
took 1.45 hours to collect but only 2% of the clusters achieved a size of 50.
Comparison is given with exact results [5] up to clusters of size 19. The
rate of growth of errors for the two and three dimensional data is shown
in Figure 3 and it can be seen that the errors associated with the method
diverge are beginning to diverge quite rapidly above clusters of size 50. This
behaviour is to be expected with a technique which is based on sampling from
a log normal distribution. In the previous paper [11] equivalent results were
obtained for clusters up to size 30 with approximately the same sample size.
The improvement up to clusters of size 50 obtained by the new method arises
because the weight associated with clusters of a certain size is generated from
roughly half as many random numbers. This eﬀectively halves the standard

12

deviation of the log normal distribution of the weights and allows larger
clusters to be sampled before the method becomes unusable.

4 Conclusions

We have described a simple Rosenbluth algorithm for the Monte Carlo enu-
meration of lattice animals and clusters which can be applied to any lattice
topology. A merit of the scheme is that for thermal systems it may be easily
adapted to include Boltzmann weightings following, for example, the argu-
ments used by Siepmann at al [16] in the development of the conﬁgurational
bias technique. Similarly, the method can be applied to calculation of the av-
eraged properties of a cluster of a given size, in the site percolation problem.
In this case we have

< O >=

< (1 − P )tO >W
< (1 − P )t >W

=

P

NE
α=1 Wα(1 − P )tαOα
NE
α=1 Wα(1 − P )tα

(11)

P

where P is the probability of site occupation in the percolation problem of
interest and tα the number of perimeter sites [17] of the cluster α. Preliminary
results also indicate that the method may be useful in the study of the
adsorption of clusters onto solid surfaces. A possible numerical limitation of
the method arises from the highly skew probability distribution of Rosenbluth
weights which occurs for large cluster sizes. However the method presented
in this work is able to work to considerably higher cluster sizes than the one
described in [11] before this becomes a problem.

References

(1983).

[1] G. Jacucci, A. Perini, and G. Martin, J Phys A:Math and Gen 16, 369

[2] B. F. Edwards, M. F. Gyure, and M. Ferer, Phys Rev A 46, 6252 (1992).

[3] R. C. Ball and J. R. Lee, J Phys I France 6, 357 (1996).

[4] H. P. Peters, D. Stauﬀer, H. P. H¨olters, and K. Loewenich, Z Physik B

34, 339 (1979).

[5] M. F. Sykes and M. Glen, J Phys A: Math Gen 9, 87 (1976).

13

[6] P. M. Lam and F. Family, Physica A 231, 369 (1996).

[7] D. Stauﬀer, Phys Rev Lett 41, 1333 (1978).

[8] P. L. Leath, Phys Rev Lett 36, 921 (1976).

[9] S. Redner and P. J. Reynolds, J Phys A: Math and Gen 14, 2679 (1981).

[10] P. M. Lam, Phys Rev A 34, 2339 (1986).

[11] C. M. Care, Phys Rev E 57, 1181 (1997).

[12] M. N. Rosenbluth and A. W. Rosenbluth, J Chem Phys 23, 356 (1955).

[13] L. Pratt, J Chem Phys 77, 979 (1982).

[14] J. Batoulis and K. Kremer, J Phys A: Math Gen 21, 127 (1988).

[15] M. G. Bulmer, Principles of Statistics (Oliver and Boyd, London, 1965).

[16] J. I. Siepmann and D. Frenkel, Mol Phys 75, 59 (1992).

[17] D. Stauﬀer, A. Aharony, and Taylor, Introduction to percolation theory

(Taylor and Francis, 1992).

List of Figures

1

2

3

Sequence of accepted sites leading to a cluster of size N = 4.
The sites examined but rejected along the way are indicated
by X. In our notation this sequence can be represented by
{0,1,1,0,0,0,1} . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

Percentage errors for clusters of size 50 . . . . . . . . . . . . . 11

Variation of percentage error with cluster size.

. . . . . . . . . 12

14

N Rosenbluth

Exact
value

Lam [6]
Lam [6]
estimate % error % error % error

True

eest

χ

ξ

3
15
86
534
3 481
23 502
162 913
1 152 870
8 294 738
60 494 540
446 205 905
3 322 769 129

estimate
3.000×100
1.499×101
8.600×101
5.339×102
3.483×103
2.351×104
1.630×105
1.153×106
8.302×106
6.054×107
4.464×108
3.326×109
2.496×1010
1.887×1011
1.436×1012
1.098×1013
8.448×1013
6.520×1014
5.048×1015
3.929×1016
3.063×1017
2.399×1018
1.882×1019
1.485×1020
1.169×1021
9.214×1021
7.316×1022
5.790×1023
4.600×1024

2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30

0.03
0.03
0.04
0.05
0.05
0.06
0.06
0.06
0.07
0.08
0.07
0.07
0.10
0.10
0.09
0.11
0.13
0.14
0.14
0.16
0.19
0.21
0.21
0.20
0.21
0.24
0.25

8.594×101
5.321×102
3.475×103
2.353×104
1.631×105
1.155×106
8.291×106
6.042×107
4.442×108
3.291×109
2.461×1010
1.862×1011
1.416×1012
1.082×1013
8.329×1013
6.446×1014
5.002×1015
3.897×1016
3.052×1017
2.391×1018
1.877×1019
1.480×1020
1.168×1021
9.209×1021
7.290×1022
5.786×1023
4.610×1024

15

Table 1: Table continued on next page

0.00
0.02
0.05
0.02
0.03
0.03
0.09
0.08
0.05
0.11

0.51
0.54
0.58
0.63
0.65
0.73
0.86
0.87
0.87
0.97
1.09
1.16
1.22
1.27
1.37
1.38
1.41
1.47
1.49
1.61
1.68
1.70
1.75
1.81
1.88
1.96
2.01

0.18
0.77
1.30
0.42
0.58
0.50
1.40
1.29
0.70
1.34

0.07
0.00
0.14
0.14
0.73
0.62
0.16
0.50
0.12
0.48
0.35
-0.10
0.25
-0.03
0.12
0.20
-0.07
-0.21
-0.42
-0.11
0.16
-0.02
-0.11
0.06
0.18
-0.12
0.44

-0.28
0.26
0.54
0.46
-0.32
0.33
1.08
0.18
0.27
0.54
0.35
0.23
0.35
2.32
0.43
0.65
0.36
0.53
0.02
0.78

N Rosenbluth Exact Lam [6]

True

Lam [6] χ

ξ

value

estimate % error % error % error

estimate
3.674×1025
2.929×1026
2.342×1027
1.872×1028
1.501×1029
1.199×1030
9.631×1030
7.691×1031
6.203×1032
4.984×1033
3.999×1034
3.205×1035
2.605×1036
2.100×1037
1.684×1038
1.353×1039
1.087×1040
8.892×1040
7.223×1041
5.789×1042

31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50

eest

0.26
0.25
0.27
0.31
0.31
0.32
0.39
0.35
0.40
0.45
0.43
0.46
0.49
0.62
0.71
0.69
0.58
0.68
0.79
0.75

16

Table 1: Continued:- Degenerate Rosenbluth estimate of the number of lat-
tice animals of size N on a three dimensional square lattice using 2.5 × 107
sample clusters, each grown to N = 50 with p = 0.72; exact values from [6];
estimated values and associated errors from incomplete enumeration method
of Lam [6]; calculation of error estimate described in text; ‘true’ error is frac-
tional diﬀerence of Rosenbluth estimate and exact value; χ and ξ are deﬁned
in the text.

N Rosenbluth

Exact
value

eest

True
% error %error

χ

ξ

2
6
19
63
216
760
2 725
9 910
36 446
135 268
505 861
1 903 890
7 204 874
27 394 666
104 592 937
400 795 844
1 540 820 542
5 940 738 676

estimate
1.999×100
6.000×100
1.900×101
6.300×101
2.160×102
7.601×102
2.724×103
9.903×103
3.644×104
1.352×105
5.056×105
1.903×106
7.205×106
2.741×107
1.046×108
4.009×108
1.543×109
5.942×109
2.298×1010
8.895×1010
3.451×1011
1.341×1012
5.228×1012
2.039×1013
7.970×1013
3.122×1014
1.225×1015
4.831×1015
1.883×1016

2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30

0.02
0.03
0.03
0.03
0.04
0.04
0.05
0.05
0.06
0.07
0.08
0.09
0.09
0.09
0.11
0.12
0.10
0.13
0.15
0.17
0.18
0.20
0.19
0.26
0.25
0.24
0.28
0.30

0.01
0.00
0.01
0.00
0.02
0.03
0.07
0.01
0.04
0.04
0.04
0.01
0.05
0.01
0.03
0.13
0.01

0.22
0.00
0.31
0.00
0.43
0.60
1.48
0.21
0.69
0.66
0.51
0.06
0.49
0.07
0.29
1.09
0.15

-0.48
-0.65
0.14
0.36
-0.27
0.08
-0.14
0.10
0.09
-0.04
-0.24
-0.13
-0.33
-0.09
0.74
0.44
0.26
-0.42
-0.02
0.62
0.61
1.61
-0.04
-0.05
0.00
0.33
0.20
-0.13

Table 2: Table continued on next page

17

N Rosenbluth Exact

χ

ξ

estimate
7.426×1016
2.945×1017
1.160×1018
4.561×1018
1.800×1019
7.121×1019
2.823×1020
1.122×1021
4.417×1021
1.763×1022
6.979×1022
2.738×1023
1.088×1024
4.341×1024
1.704×1025
6.802×1025
2.673×1026
1.058×1027
4.209×1027
1.664×1028

31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50

eest
True
value % error %error
0.33
0.45
0.34
0.47
0.40
0.52
0.57
0.67
0.65
0.83
0.84
0.78
0.82
0.93
0.97
1.10
1.07
1.02
1.14
1.28

0.97
0.59
0.19
0.44
0.23
0.29
0.67
-0.03
0.71
1.30
1.02
0.37
-0.16
2.12
0.52
0.73
0.41
0.60
0.26
0.29

Table 2: Continued:- Degenerate Rosenbluth estimate of the number of lat-
tice animals of size N on a two dimensional square lattice using 2.5 × 107
sample clusters, each grown to N = 50 with p = 0.60; exact results from [5];
calculation of error estimate described in text; ‘true’ error is fractional dif-
ference of Rosenbluth estimate and true value; χ and ξ are deﬁned in the
text.

18

