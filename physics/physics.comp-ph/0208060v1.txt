Solving the Maxwell equations by the Chebyshev method:
A one-step ﬁnite-diﬀerence time-domain algorithm

H. De Raedt∗, K. Michielsen†, J.S. Kole‡, M.T. Figge§
Centre for Theoretical Physics and Materials Science Centre
University of Groningen, Nijenborgh 4
NL-9747 AG Groningen, The Netherlands
(Dated: February 2, 2008)

We present a one-step algorithm that solves the Maxwell equations for systems with spatially vary-
ing permittivity and permeability by the Chebyshev method. We demonstrate that this algorithm
may be orders of magnitude more eﬃcient than current ﬁnite-diﬀerence time-domain algorithms.

I.

INTRODUCTION

Most ﬁnite-diﬀerence time-domain (FDTD) calculations solve the time-dependent Maxwell equations using algo-
rithms based on a proposal by Yee [1, 2, 3]. The Yee algorithm is ﬂexible, fast and easy to implement. A limitation
of Yee-based FDTD techniques is that their stability is conditional, meaning that their numerical stability depends
on the mesh size used for the spatial discretization and on the time step of the time integration [2, 3]. In practice,
the amount of computational work required to solve the time-dependent Maxwell equations by present FDTD tech-
niques [2, 3, 4, 5, 6, 7, 8, 9, 10] prohibits applications to a class of important ﬁelds such as bioelectromagnetics and
VLSI design [2, 11, 12]. The basic reason for this is that the time step in the FDTD calculation has to be relatively
small in order to maintain a reasonable degree of accuracy in the time integration.

In this paper we describe a one-step algorithm, based on Chebyshev polynomial expansions [13, 14, 15, 16, 17, 18],
to solve the time-dependent Maxwell equations for arbitrarily long times. We demonstrate that the computational
eﬃciency of this one-step algorithm can be orders of magnitude larger than of other FDTD techniques.

II. ALGORITHM

We consider EM ﬁelds in linear, isotropic, nondispersive and lossless materials. The time evolution of EM ﬁelds in
these systems is governed by the time-dependent Maxwell equations [19]. Some important physical symmetries of the
Maxwell equations can be made explicit by introducing the ﬁelds

X(t)

√µ H(t) and Y(t)

√ε E(t) .

≡

≡

Here, H(t) = (Hx(r, t), Hy(r, t), Hz(r, t))T denotes the magnetic and E(t) = (Ex(r, t), Ey(r, t), Ez(r, t))T the electric
ﬁeld vector, while µ = µ(r) and ε = ε(r) denote, respectively, the permeability and the permittivity. In the absence
of electric charges, Maxwell’s curl equations [2] read

(cid:18)
where J = (Jx(r, t), Jy(r, t), Jz(r, t))T represents the source of the electric ﬁeld and

(cid:18)

(cid:18)

(cid:19)

(cid:19)

(cid:19)

∂
∂t

X(t)
Y(t)

=

H

X(t)
Y(t)

1
√ε

−

0
J(t)

,

denotes the operator

H

(1)

(2)

(3)

H ≡  

1
√ε ∇ ×

1
√µ

0

−

1
√µ ∇ ×
0

1
√ε

.

!

Writing Z(t) = (X(t), Y(t))T it is easy to show that
product

, with respect to the inner
Z′ dr, where V denotes the system’s volume. In addition to Eq.(2), the EM ﬁelds also satisfy
(√εY(t)) = 0.

is skew symmetric, i.e.

Z′
Z
|
h
(√µX(t)) = 0 and

T =

−H

i ≡

ZT

H

H

V

∇ ·

·
∇ ·

R

2
0
0
2
 
g
u
A
 
5
1
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
0
6
0
8
0
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

∗ E-mail: deraedt@phys.rug.nl
† E-mail: kristel@phys.rug.nl
‡ E-mail: j.s.kole@phys.rug.nl
§ E-mail: m.t.ﬁgge@phys.rug.nl
http://www.compphys.rug.nl/

A numerical algorithm that solves the time-dependent Maxwell equations necessarily involves some discretization
procedure of the spatial derivatives in Eq. (2). Ideally, this procedure should not change the basic symmetries of the
Maxwell equations. We will not discuss the (important) technicalities of the spatial discretization (we refer the reader
to Refs. [9, 10]) as this is not essential to the construction of the one-step algorithm.

On a spatial grid Maxwell’s curl equations (2) can be written in the compact form [9, 10]

∂
∂t

Ψ(t) = HΨ(t)

Φ(t) .

−

The vector Ψ(t) is a representation of Z(t) on the grid. The matrix H is the discrete analogue of the operator (3),
and the vector Φ(t) contains all the information on the current source J. The formal solution of Eq. (4) is given by

Ψ(t) = U (t)Ψ(0)

U (t

u)Φ(u)du ,

−

−

t

0
Z
where U (t) = etH denotes the time-evolution matrix. The underlying physical symmetries of the time-dependent
Maxwell equations are reﬂected by the fact that the matrix H is real and skew symmetric [9], implying that U (t) is
orthogonal [20].

Numerically, the time integration is carried out by using a time-evolution operator U(t) that is an approximation
to U (t) = etH. We denote the approximate solution by Ψ(t). First we use the Chebyshev polynomial expansion to
approximate U (t) and then show how to treat the source term in Eq. (5). We begin by “normalizing” the matrix
H. The eigenvalues of the skew-symmetric matrix H are pure imaginary numbers. In practice H is sparse so it is
k1 all lie in the
. Then, by construction, the eigenvalues of B
easy to compute
1, 1] [20]. Expanding the initial value Ψ(0) in the (unknown) eigenvectors bj of B, we ﬁnd from Eq. (5)
interval [
−
with Φ(t)

Hi,j|
i |

k1 ≡

maxj

≡ −

iH/

P

H

H

0:

k

k

≡

Ψ(t) = eizBΨ(0) =

eizbj bjh

bj|

Ψ(0)
,
i

j
X
where the bj denote the (unknown) eigenvalues of B. Although there is no need to know the eigenvalues and
eigenvectors of B explicitly, the current mathematical justiﬁcation of the Chebyshev approach requires that B is
diagonalizable and that its eigenvalues are real. The eﬀect of relaxing these conditions on the applicability of the
Chebyshev approach is left for future research. We ﬁnd the Chebyshev polynomial expansion of U (t) by computing
the expansion coeﬃcients of each of the functions eizbj that appear in Eq. (6). In particular, as
1, we can
∞k=1 ikJk(z)Tk(bj) , where Jk(z) is the Bessel function of integer order k to
use the expansion [21] eizbj = J0(z) + 2
write Eq. (6) as

bj ≤

−

≤

1

P

"

Ψ(t) =

J0(z)I + 2

Jk(z)

Tk(B)

∞

Xk=1

e

Ψ(0) .

#

e
T0(B)Ψ(0) = Ψ(0) ,

T1(B)Ψ(0) = iBΨ(0) ,

e

e

Tk+1(B)Ψ(0) = 2iB

Tk(B)Ψ(0) +

Tk

1(B)Ψ(0) ,

−

Here, I is the identity matrix and
by the recursion relations

Tk(B) = ikTk(B) is a matrix-valued modiﬁed Chebyshev polynomial that is deﬁned

and

k

e

≤

≥

k1 ≤

K. As

e
Tk(B)

1 by construction and

1. In practice we truncate the sum in Eq. (7), i.e. to obtain the approximation Ψ(t) we will sum only the
for k
k/2kk! for z real [21], the resulting
contributions with k
|
error vanishes exponentially fast for suﬃciently large K. In Fig.1 we show a plot of Jn(z = 200) as a function of
n to illustrate this point. From Fig.1 it is clear that the Chebyshev polynomial expansion will only be useful if K
lies to the right of the right-most extremum of Jn(z = 200). From numerical analysis it is known that for ﬁxed K,
the Chebyshev polynomial is very nearly the same polynomial as the minimax polynomial [22], i.e. the polynomial
of degree K that has the smallest maximum deviation from the true function, and is much more accurate than for
instance a Taylor expansion of the same degree K. The coeﬃcients Jk(z) should be calculated to high precision and
< κ for all k > K. Here, κ is a control parameter that determines the
the number K is ﬁxed by requiring that
k1 (there is no requirement on t being
accuracy of the approximation. For ﬁxed κ, K increases linearly with z = t

e
Jk(z)
|

Jk(z)
|
|

z
| ≤ |

H

e

k

2

(4)

(5)

(6)

(7)

(8)

(9)

3

(10)

(11)

(12)

small), a result that is essential for the eﬃciency of the algorithm. Using the recursion relation of the Bessel functions,
all K coeﬃcients can be obtained with
) arithmetic operations [22]. Clearly this is a neglible contribution to the
total computational cost for solving the Maxwell equations.

(
K

O

Performing one time step amounts to repeatedly using recursion (9) to obtain

Tk(B)Ψ(0) for k = 2, . . . , K, multiply
the elements of this vector by Jk(z) and add all contributions. This procedure requires storage for two vectors of the
same length as Ψ(0) and some code to multiply such a vector by the sparse matrix H. The result of performing one
time step yields the solution at time t, hence the name one-step algorithm. In contrast to what Eqs. (8) and (9)
might suggest, the algorithm does not require the use of complex arithmetic.

We now turn to the treatment of the current source J(t). The contribution of the source term to the EM ﬁeld
at time t is given by the last term in Eq. (5). One approach might be to use the Chebyshev expansion (7) for
u) = e(t
u)H and to perform the integral in Eq. (5) numerically. However that is not eﬃcient as for each value
U (t
u we would have to perform a recursion of the kind Eq. (9). Thus, it is better to adopt another strategy. For
of t
simplicity we only consider the case of a sinusoidal source

−
−

e

−

J(r, t) = Θ(T

t)s(r) sin(Ωt),

−

where s(r) speciﬁes the spatial distribution and Ω the angular frequency of the source. The step function Θ(T
t)
indicates that the source is turned on at t = 0 and is switched oﬀ at t = T . Note that Eq. (10) may be used to
compose sources with a more complicated time dependence by a Fourier sine transformation.

−

The formal solution for the contribution of the sinusoidal source (10) reads

t

0
Z

e(t

−

u)H Φ(u) du = (Ω2 + H 2)−

1e(t

−

′

T

)H

′

H

(ΩeT

Ω cos ΩT ′

H sin ΩT ′)Ξ

×

−

−

f (H, t, T ′, Ω)Ξ ,

≡
Θ(T

≡

where T ′ = min(t, T ) and Φ(u)
t) sin(Ωt)Ξ with Ξ a vector of the same length as Ψ(0) that represents the
time-independent, spatial distribution s(r). The coeﬃcients of the Chebyshev polynomial expansion of the formal
solution (11) are calculated as follows. First we repeat the scaling procedure described above and substitute in Eq. (11)
k1. Then, we compute the (Fast) Fourier Transform with
H
H
H = ix
k
respect to x of the function f (x, z, Z ′, ω) (which is non-singular on the interval
1). By construction, the
x
≤
Fourier coeﬃcients Sk(t

k1) are the coeﬃcients of the Chebyshev polynomial expansion [21].
Taking into account all contributions of the source term with k smaller than K ′ (determined by a procedure similar

k1, T ′ = Z ′/
H

k1, and Ω = ω

k1, t = z/

H

H

−

≤

−

k

k

k

k

1

to the one for K), the one-step algorithm to compute the EM ﬁelds at time t reads

Ψ(t) =

J0(t

H

k

k1)I + 2

Jk(t

H

k

k1)

Tk(B)

#

Ψ(0)

"





+

S0(t

H

k1)I + 2

k

Sk(t

H

k

e
Tk(B)
k1)

e

Ξ .





K

Xk=1
K

′

Xk=1

III. RESULTS

We emphasize that in our one-step approach the time dependence of the source is taken into account exactly, without
actually sampling it.

t

The following two examples illustrate the eﬃciency of the one-step algorithm. First we consider a system in vacuum
(ε = ε0 and µ = µ0) which is inﬁnitely large in the y- and z-direction, hence eﬀectively one dimensional. The current
source (10) is placed at the center of a system of length 250.1 and oscillates with angular frequency Ω = 2π during
In Table I we present results of numerical experiments with two diﬀerent
the time interval 0
Ψ(t) as obtained by the FDTD algorithm of Yee [1, 2]
time-integration algorithms. In general, the error of a solution
, where Ψ(t)
or the unconditionally stable FDTD algorithm T 4S2 [9, 10] is deﬁned by ∆(t)
denotes the vector of the EM ﬁelds as obtained by the one-step algorithm. The error on the Yee-algorithm result
vanishes as τ 2 for suﬃciently small τ [1, 2]. However, as Table I shows, unless τ is made suﬃciently small (τ
0.0125
in this example), the presence of the source term changes the quadratic behavior to almost linear. The rigorous bound
on the error between the exact and T 4S2 results tells us that this error should vanish as τ 4 [9, 24]. This knowledge

T = 4 [23].

Ψ(t)
k

Ψ(t)
k

Ψ(t)

≡ k

−

≤

≤

≤

e

e

/

k

4

(13)

(14)

can be exploited to test if the one-step algorithm yields the exact numerical answer. Using the triangle inequality we
can write

Ψ(t)

Ψ(t)

k

−

τ 4tC

≤

Ψ(t)
t

Ψ(t)
k

−
J(u)
e
k

du

Ψ(t)
k

+

Ψ(t)

k
+ ∆(t)
k

e

−
Ψ(t)
k

k ≤ k
1 +

(cid:18)

0 k
Z

(cid:19)

0 as τ 4
where C is a positive constant [24]. The numerical data in Table I (third column) show that ∆(t)
and, therefore, we can be conﬁdent that the one-step algorithm yields the correct answer within rounding errors.
Furthermore, since the results of the one-step algorithm are exact within almost machine precision, in general the
(√εY(t)) = 0 within the same precision. This high precision also
solution also satisﬁes
allows us to use the one-step algorithm for genuine time stepping with arbitrarily large time steps, this in spite of the
fact that strictly speaking, the one-step algorithm is not unconditionally stable.

(√µX(t)) = 0 and

∇ ·

∇ ·

→

From Table I it follows that if one ﬁnds an error of more than 2.5% acceptable, one could use the Yee algorithm,
though we recommend to use the one-step algorithm because then the time-integration error is neglegible. The Yee
algorithm is no competition for the T 4S2 algorithm if one requires an error of less than 1%, but the T 4S2 algorithm
is not nearly as eﬃcient as the one-step algorithm with respect to the number of required matrix-vector operations.
A more general quantitative analysis of the eﬃciency can be made using the fact that for an nth-order algorithm
(n = 2 for the Yee algorithm and n = 4 for the T 4S2 algorithm), the error ∆(t) vanishes no faster with τ than τ nt.
M Ψ), e.g. for a three-dimensional
Each time step takes a number W (n) of matrix-vector operations (of the type Ψ′
system we have W (2) = 1 and W (4) = 10 for the Yee algorithm and the T 4S2 algorithm, respectively. In practice
the actual number of ﬂoating point operations carried out by our algorithms agrees with these estimates. The total
number of matrix-vector operations it takes to obtain the solution at a reference time tr with error ∆r(tr) is then
r . The number of operations N that it will take to
given by Nr = W (n)tr/τr and thus ∆r(tr)
compute the EM ﬁelds at time t with accuracy ∆(t) is then calculated from

W (n)ntn+1

/N n

←

∝

r

N = Nr

∆r(tr)
∆(t)

1/n

(n+1)/n

.

t
tr (cid:19)

(cid:18)

(cid:18)

(cid:19)
We note that one numerical reference experiment per nth-order algorithm is suﬃcient to determine the parameters
Nr, ∆r(tr), and tr. While these parameters may be diﬀerent for diﬀerent systems, the scaling of N with t3/2 and with
t5/4, respectively, for second- and fourth-order algorithms, will not be aﬀected. Most importantly, since the number
of matrix-vector operations required by the one-step algorithm scales linearly with t, it is clear that for long enough
times t, the one-step algorithm will be orders of magnitude more eﬃcient than the current FDTD methods. In Fig.2
we show the required number of operations as a function of time t taking, as an example, simulation data of 3D
systems (discussed below) to ﬁx the parameters Nr, ∆r(tr), and tr. We conclude that for longer times none of the
FDTD algorithms can compete with the one-step algorithm in terms of eﬃciency. For t = 20, the one-step algorithm
is a factor of ten faster than the Yee algorithm. Thereby we have disregarded the fact that the Yee algorithm yields
results within an error of 0.1% while the one-step algorithm gives the numerically exact solution.

As the second example we use the one-step algorithm to compute the frequency spectrum of a three-dimensional
photonic woodpile [25]. This structure, shown in the inset of Fig. 3, possesses a large infrared bandgap and is under
current experimental and theoretical investigation [25, 26]. To determine all eigenvalues of the corresponding matrix H
we follow the procedure described in Refs. [9, 27, 28]. We use random numbers to initialize the elements of the vector
Ψ(0). Then we calculate the inner product F (t) =
Ψ(t)
Ψ(0)
as a function of t and average f (t) = F (t)/F (0)
i
|
h
over several realizations of the initial vector Ψ(0). The full eigenmode distribution,
(ω), is obtained by Fourier
(ω), as obtained by T 4S2 and the one-step algorithm, with a time step
transformation of f (t). In Fig. 3 we show
τ = 0.075 (set by the largest eigenvalue of H), a mesh size δ = 0.1, and 8192 time steps. For this choice of parameters,
the Yee algorithm would be unstable [2, 3] and would yield meaningless results. The T 4S2 calculation shows a peak
(√µX(t)) and
at ω = 0. This reﬂects the fact that, in a strict sense, the T 4S2 algorithm does not conserve
(√εY(t)) [9, 10]. However, the peak at ω = 0 vanishes as τ 4. Repeating the T 4S2 calculation with τ = 0.01 yields
∇ ·
a
(ω) (not shown) that is on top of the result of the one-step algorithm (see Fig. 3) and is in good agreement with
D
band-structure calculations [25]. For τ = 0.01 the one-step algorithm is 3.5 times more eﬃcient than T 4S2. Note
that in this example, the one-step algorithm is used for a purpose for which it is least eﬃcient (time-stepping with
relatively small time steps). Nevertheless the gain in eﬃciency is still substantial. In simulations of the scattering of
the EM ﬁelds from the same woodpile (results not shown), the one-step algorithm is one to two orders of magnitude
more eﬃcient than current FDTD algorithms, in full agreement with the error scaling analysis given above.

∇ ·

D

D

IV. CONCLUSION

5

We have described a one-step algorithm, based on the Chebyshev polynomial expansions, to solve the time-
dependent Maxwell equations with spatially varying permittivity and permeability and current sources. In practice
this algorithm is as easy to implement as FDTD algorithms. Our error scaling analysis shows and our numerical
experiments conﬁrm that for long times the one-step algorithm can be orders of magnitude more eﬃcient than current
FDTD algorithms. This opens possibilities to solve problems in computational electrodynamics that are currently
intractable.

H.D.R. and K.M. are grateful to T. Iitaka for drawing our attention to the potential of the Chebyshev method and

for illuminating discussions.

Acknowledgments

[1] K.S. Yee, “Numerical Solution of Initial Boundary Value Problems Involving Maxwell’s Equations in Isotropic Media”,

IEEE Transactions on Antennas and Propagation 14, 302 (1966).

[2] A. Taﬂove and S.C. Hagness, Computational Electrodynamics - The Finite-Diﬀerence Time-Domain Method, (Artech

House, Boston, 2000).

[3] K.S. Kunz and R.J. Luebbers, Finite-Diﬀerence Time-Domain Method for Electromagnetics, (CRC Press, 1993).
[4] See http://www.fdtd.org
[5] F. Zheng, Z. Chen, and J. Zhang, “Towards the development of a three-dimensional unconditionally stable ﬁnite-diﬀerence

time-domain method” IEEE Trans. Microwave Theory and Techniques 48, 1550 (2000).

[6] T. Namiki, “3D ADI-FDTD Method - Unconditionally Stable Time-Domain Algormithm for Solving Full Vector Maxwell’s

Equations”, IEEE Trans. Microwave Theory and Techniques 48, 1743 (2001).

[7] F. Zheng and Z. Chen “Numerical dispersion analysis of the unconditionally stable 3D ADI-FDTD method” IEEE Trans.

[8] W. Harshawardhan, Q. Su, and R. Grobe, “Numerical solution of the time-dependent Maxwell’s equations for random

[9] J.S. Kole, M.T. Figge and H. De Raedt, “Unconditionally Stable Algorithms to Solve the Time-Dependent Maxwell

Microwave Theory and Techniques 49, 1006 (2001).

dielectric media”, Phys. Rev. E 62, 8705 (2000).

Equations”, Phys. Rev. E 64, 066705 (2001).

[10] J.S. Kole, M.T. Figge and H. De Raedt, Phys. Rev. E (in press). “Higher-Order Unconditionally Stable Algorithms to

Solve the Time-Dependent Maxwell Equations”, Phys. Rev. E 65, 066705-1 (2002).

[11] O.P. Gandi, Advances in Computational Electrodynamics - The Finite-Diﬀerence Time-Domain Method, A. Taﬂove, Ed.,

(Artech House, Boston, 1998).

[12] B. Houshmand, T. Itoh, and M. Piket-May, Advances in Computational Electrodynamics - The Finite-Diﬀerence Time-

Domain Method, A. Taﬂove, Ed., (Artech House, Boston, 1998).

[13] H. Tal-Ezer, “Spectral Methods in Time for Hyperbolic Equations”, SIAM J. Numer. Anal. 23, 11 (1986)
[14] H. Tal-Ezer and R. Kosloﬀ, “An accurate and eﬃcient scheme for propagating the time dependent Sch¨odinger equation”,

J. Chem. Phys. 81, 3967 (1984).

[15] C. Leforestier, R.H. Bisseling, C. Cerjan, M.D. Feit, R. Friesner, A. Guldberg, A. Hammerich, G. Jolicard, W. Karrlein,
H.-D. Meyer, N. Lipkin, O. Roncero, and R. Kosloﬀ, “A Comparison of Diﬀerent Propagation Schemes for the Time
Dependent Schr¨odinger Equation”, J. Comp. Phys. 94, 59 (1991).

[16] T. Iitaka, S. Nomura, H. Hirayama, X. Zhao, Y. Aoyagi, and T. Sugano, “Calculating the linear response functions of

noninteracting electrons with a time-dependent Sch¨odinger equation”, Phys. Rev. E 56, 1222 (1997).

[17] R.N. Silver and H. R¨oder, “Calculation of densities of states and spectral functions by Chebyshev recursion and maximum

[18] Y.L. Loh, S.N. Taraskin, and S.R. Elliot, “Fast Time-Evolution Method for Dynamical Systems”, Phys. Rev. Lett. 84,

entropy”, Phys. Rev. E 56, 4822 (1997).

2290 (2000); ibid. Phys.Rev.Lett. 84, 5028 (2000).

[19] M. Born and E. Wolf, Principles of Optics, (Pergamon, Oxford, 1964).
[20] J.H. Wilkinson, The Algebraic Eigenvalue Problem, (Clarendon Press, Oxford, 1965).
[21] M. Abramowitz and I. Stegun, Handbook of Mathematical Functions, (Dover, New York, 1964).
[22] W.H. Press, B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling, Numerical Recipes, (Cambridge, New York, 1986).
[23] We measure distances in units of λ. Time and frequency are expressed in units of λ/c and c/λ, respectively.
[24] H. De Raedt, “Product Formula Algorithms for Solving the Time Dependent Schr¨odinger Equation”, Comp. Phys. Rep.

7, 1 (1987).

[25] S.Y. Lin, J.G. Fleming, D.L. Hetherington, B.K. Smith, R. Biswas, K.M. Ho, M.M. Sigalas, W. Zubrzycki, S.R. Kurtz,

and J. Bur, “A three-dimensional photonic crystal operating at infrared wavelengths”, Nature 394, 251 (1998).

[26] J.G. Fleming, S.Y. Lin, I. El-Kady, R. Biswas, and K.M. Ho, “All-metallic three-dimensional photonic crystals with a large

Infrared bandgap”, Nature 417, 52 (2002).

[27] R. Alben, M. Blume, H. Krakauer, and L. Schwartz, “Exact results for a three-dimensional alloy with site diagonal disorder:

comparison with the coherent potential approximation”, Phys. Rev. B 12, 4090 (1975).

[28] A. Hams and H. De Raedt, “Fast algorithm for ﬁnding the eigenvalue distribution of very large matrices”, Phys. Rev. E

62, 4365 (2000).

6

TABLE I: The error ∆(t) after simulation time t = 100 as a function of the time step τ for two FDTD algorithms. The number
of matrix-vector operations required to compute the solution, is K ′ = 2080, t/τ , and 6t/τ for the one-step, Yee, and T 4S2
algorithm, respectively.

τ
0.10000 × 10+0
0.50000 × 10−1
0.25000 × 10−1
0.12500 × 10−1
0.62500 × 10−2
0.31250 × 10−2
0.15625 × 10−2
0.78125 × 10−3

Yee
0.75 × 10−1
0.25 × 10−1
0.12 × 10−1
0.66 × 10−2
0.24 × 10−2
0.63 × 10−3
0.16 × 10−3
0.39 × 10−4

7

T 4S2
0.51 × 10−1
0.33 × 10−2
0.21 × 10−3
0.13 × 10−4
0.91 × 10−6
0.30 × 10−6
0.15 × 10−7
0.60 × 10−8

FIG. 1: Dependence of the Bessel function Jn(z = 200) on the order n.

8

FIG. 2: The number of Ψ′ ← M Ψ operations N needed to compute the solution of the 3D Maxwell equation at time t for
systems like those shown in Fig.3. Solid line: One-step algorithm; dashed line: Yee algorithm [1, 2, 3] yielding a solution within
0.1% error; dotted line: T4S2 algorithm [9, 10] yielding a solution within 0.1% error.

9

FIG. 3: Frequency spectrum of a three-dimensional photonic woodpile (inset) [25] as obtained by T 4S2 (dashed line) and the
one-step algorithm (solid line). The width, height and period of the rods are 0.55, 0.7, and 2, respectively. The dielectric
constant of the rods is 12.96 and the simulation box measures 6 × 6 × 5.6 [23], subject to periodic boundary conditions.

