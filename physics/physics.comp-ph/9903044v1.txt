9
9
9
1
 
r
a

M
 
0
3
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
4
4
0
3
0
9
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A New Technique for Sampling
Multi-Modal Distributions

APLHA 99-03

K.J. Abraham
Department of Physics and Astronomy
Iowa State University
Ames IA 50011
e-mail abraham@iastate.edu

L.M. Haines
Department of Statistics and Biometry
University of Natal
Private Bag X01
3209 Scottsville
Pietermaritzburg
South Africa
e-mail haines@stat.unp.ac.za

Abstract

In this paper we demonstrate that multi-modal Probability Dis-
tribution Functions (PDFs) may be eﬃciently sampled using an al-
gorithm originally developed for numerical integration by monte-carlo
methods. This algorithm can be used to generate an input PDF which
can be used as an independence sampler in a Metropolis-Hastings
chain to sample otherwise troublesome distributions. Some exam-
ples in one, two, and ﬁve dimensions are worked out. We also com-
ment on the possible application of our results to event generation in
high energy physics simulations.(Subj. Classif. 68U20, 65C05, 81V25,
81V15. Keywords Monte Carlo Optimisation, Metropolis-Hastings
Chain, Vegas Algorithm, Independence Sampler).

The key to solving a wide range of optimisation problems in science and
engineering lies in being able to eﬃciently sample a (possibly very complex)
PDF in one or more dimensions. In many cases of interest, this requires in-
verting an integral which may not be possible by analytical or semi-analytical
means. In such circumstances, eﬃcient computer algorithms are crucial. The
perhaps best known such algorithm is the Metropolis algorithm [1], which
can in principle be used to generate an accurate sample from any PDF no
matter how complex, by a guided random walk. However, the Metropolis al-
gorithm is potentially ineﬃcent when confronted with a PDF with multiple
modes, or peaks, especially if they are well seperated. As is well known, a
very large number of random steps may needed to locate a new mode, once
one mode has been discovered, leading to a dramatic drop in the eﬃciency of
the scheme. In this paper we will show how this problem can be circumvented
in a certain class of problems.

In order to make the subsequent discussion more clear, we will present
a brief analysis of the weakness of the Metropolis scheme outlined in the
previous paragraph. Let ~Xi be some randomly choosen point in the space
where the PDF of interest Π (not necessarily normalised), is to be sampled.
A new point ~Xf at a distance δ from ~Xi is choosen and the ratio Π( ~Xi)
is
Π( ~Xf )
~Xf is accepted.
evaluated. If this ratio is larger than one, then the move ~Xi
Otherwise it is accepted with probability Π( ~Xi)
. As can be imagined, locating
Π( ~Xf )
a single peak of Π can be easily accomplished. However, moving from one
peak to another separated by a distance which is large compared with the
stepsize δ may require a long succession of steps ”against the grain”; the
net probability of such a sequence is sometimes so small that a prohibitively
large number of trials may be needed in order to establish the existence of the
second peak. This in a nutshell, is the reason for the potential ineﬃciency of
the Metropolis algorithm alluded to earlier.

→

One plausible remedy, varying δ with each move has been incorporated
into the Metropolis-Hastings algorithm [2], where the sequence of steps is
made on the basis of a proposal distribution.
If the proposal distribution
mimics Π, then all the peaks of Π may be found without diﬃculty. However,
without prior knowledge of the separation between the peaks of Π, it is diﬃ-
cult to make a suitable choice for the proposal distribution. In other words,
Π must be mapped out globally in the region of interest before it has even

2

been studied. This requirement may appear to present an insurmountable
obstacle to the use of the Metropolis-Hastings algorithm; the rest of this
paper deals with methodology we have developed to deal with this problem.
The key to our approach is the observation that the global structure of
Π is required for another seemingly diﬀerent problem, the evaluation of the
deﬁnite integral of Π over the region of interest. One technique for doing
do which is easily adapted to integrands of higher dimensions is adaptive
Monte Carlo simulation. A number of points are thrown at random along
the boundaries of the region of interest (deﬁning a grid) and the function is
evaluated at these points. This process is repeated, however the second time
around the grid from the ﬁrst iteration is reﬁned so that it is ﬁner in regions
where the function is larger and coarser where the function is smaller. On
the third iteration, the grid previously obtained is further reﬁned, and so
on. After a suitable number of iterations a reliable estimate of the integral
may be obtained, for a large class of integrands of interest. Several diﬀerent
variants of this basic algorithm have been developed; we use the VEGAS
algorithm [3]. In VEGAS the grid points are used to subdivide the axes into
a maximum of ﬁfty bins. The bin boundaries may be used to break up the
region of integration into a number of hypercubes. Ideally, the boundaries
of the hypercubes are such that Π integrated over each hypercube gives the
same contribution to the deﬁnite integral of Π over the region of interest.
Smaller hypercubes would then correspond to regions where Π is large, larger
hypercubes to regions where Π is small.

P

P

which roughly mimics Π. Sampling from

Quite apart from the deﬁnite integral, the grid information may also
be used to deﬁne a PDF
is
straightforward; hypercubes are picked at random in such a way that the
probability of picking any given hypercube is the same for all hypercubes,
and a random number is used to locate a point ~X in the hypercube by
is deﬁned so that it is the same for all points in a
uniform sampling.
1
given hypercube, and the value of
∆V .
More speciﬁcally, in one dimension a random number is used to pick a bin
along the x axis in such a way that the probability of picking any bin is
the same. Then a second random number is used to pick a point within
the bin, all points within the bin sampled uniformly. ∆V is the bin width,
for the point chosen is deﬁned as the inverse of the width of the bin
so
in which the point is located, independent of the precise point choosen in
the bin. In two dimensions two random numbers are used to pick an area

in a hypercube of volume ∆V is

P

P

P

3

element, and another two random numbers are used to pick a point in the
area element. ∆V is now the area, so
at the point chosen is deﬁned to
be the inverse of the area element. In eﬀect, we have sampled the function
globally and have used VEGAS to adaptively construct a PDF
which is
diﬀerent from Π which nonetheless mimics Π. This procedure can obviously
generalised to arbitrarily high dimensions. Regions where Π is large (small)
corespond the regions where ∆V is small (large) and hence to regions where

P

P

P

is large(small).
Our strategy for sampling from Π amounts to setting up a Metropolis-
as a proposal distribution. From the discussion in
Hastings chain using
the previous paragraph it is clear that regions where Π are large are more
likely to be selected than where Π is small. A move ~Xi
~Xf is accepted
(rejected) if

→

P

P

P

(1)

Π( ~Xi)

( ~Xi) ×

> rn(< rn)

( ~Xf )
P
Π( ~Xf )
where rn is a random number uniformly distributed between 0 and 1. Essen-
as an independence sampler for Π. This method does
tially, we are using
preserve the condition of detailed balance and the stationary distribution of
the resulting Markov Chain does indeed correspond to Π [4]. Note that the
ﬁxed step size δ plays no role whatsoever, rather δ varies from move to move
tuned to the seperation between the peaks of Π. One potential objection to
this scheme is that the function must be evaluated a large number of times by
VEGAS before a random sample can be drawn from it and it is not obvious
whether the number of function evaluations needed is less than would be re-
quired in an approach with ﬁxed step-size. This objection will be addressed
in the example we consider.

The ﬁrst and simplest example we consider is a mixture of univariate

gaussians deﬁned in the interval [0, 22]. The precise function Π is given by

.5

(x, 3, 1)
}

{N

+ .2

(x, 14, .025)
}

{N

+ .3

(x, 19, .75)
}

{N

(2)

(x, x, σ2) denotes a uni-variate gaussian with mean x and variance
where
σ2. This function clearly has well-seperated multiple peaks; generating a
sample from this PDF of this kind is thus liable to be problematic.

N

The ﬁrst step in our approach is to integrate Π with VEGAS preserving
the grid information generated by VEGAS. In this case the grid information
is a set of 50 points in the interval [0, 22]. The points deﬁne bins which are

4

such that the contribution to the deﬁnite integral from each bin is nearly
equal. As expected, the bins are narrow (wide) where the integrand is large
(small). Π was evaluated 2500 times for this purpose and a grid reﬂecting
the peaks in Π was used to generate bins of varying widths. These bins were
used to deﬁne
thus
obtained has been plotted in Fig. 1; the correspondence between Fig. 1 and
Eq. 2 is striking.

in the interval [0, 22] along the lines just described.

P

P

P

The next step is to generate a sample from Π using

as an independence
sampler. The acceptance rate of the Metropolis-Hastings chain is remarkably
high, about 80%; i.e. about 80 % of the moves were accepted using the crite-
rion deﬁned in Eq. 1. This is desirable from the point of view of minimising
CPU time and reﬂects the accuracy with which
mimics the underlying dis-
tribution Π deﬁned in Eq. 2. In all, Π was evaluated a total of 15,000 times
to generate a sample. We have checked that the average value of the random
variable as well as a number of higher moments are correctly reproduced,
within statistical error bars. This implies not only that all peaks have been
discovered but crucially, that the relative weights of all the peaks have also
been correctly reproduced. By way of comparision, we have checked that
running a Metropolis chain with the Π evaluated over 100 000 times with
ﬁxed step size does not convincingly reproduce even the ﬁrst two moments.
The advantage of our approach is clear.

P

P

P

· · ·

= pi(xi)pj(xj)

is factorisable; i.e.

We now go on to two dimensional examples. Here a complication arises;
in dimensions larger than one the VEGAS algorithm implicitly assumes
may be accurately represented in the form
that
. For many functions of interest this is a reasonable ap-
P
proximation, however if the function has a peak along a lower dimensional
hypersurface other than a co-ordinate axis, this approximation may be a poor
In particular, the VEGAS algorithm performs poorly if the function
one.
(assumed to be deﬁned in a hypercube) has a peak along a diagonal of the
hypercube. However, this does not mean that the distribution
generated
from the VEGAS grid cannot be used to sample from Π. All that happens
is that the acceptance rate of the resulting Metropolis chain is lower. To
illustrate this point, we consider a mixture of two bi-variate gaussians in a
square whose means lie along a diagonal. The precise function is deﬁned
below.

P

Π = 0.7

(x, y, 4, 4, 1, 1, .8)
}

{G

{G

+ 0.3

(x, y, 12, 12, 1, 1,

.8)
}

−

(3)

5

where

(x, y, µx, µy, σx, σy, ρ) is deﬁned by

G
1

2πσxσy√1

ρ2

2(1

ρ2) "

exp

−

1
−
−

(x

µx)2
2

−
σx

(y

+

µy)2
2

−
σy

−

2ρ(x

−

µx)(y
σxσy

−

µy)

#

The region of integration is an (16

16) square with one corner at the ori-
×
gin and sides along the positive x and y axes. This function is not well suited
to evaluation by VEGAS as both peaks lie along a diagonal of the square, and
this is reﬂected in the fact that the acceptance rate of the Metropolis-Hastings
chain is only
23%. However, the grid information does correctly reﬂect the
location of both peaks and the values of < xnym > where (m + n)
6 are
corectly reproduced, indicating not only that both peaks have been found,
but also that the relative weights assigned to both peaks is correct. As a
check, we have considered another function,

∼

≤

Π = 0.7

(x, y, 4, 4, 1, 1, .8)
}

{G

{G

+ 0.3

(x, y, 12, 4, 1, 1,

.8)
}

−

which diﬀers from the bi-variate gaussian in Eq. 3 in that both peaks now
lie along a line parallel to the x axis. Once again, grid information is used
to generate a sample from which correct moments can be recovered. This
time though, due to the more favourable location of the peaks the accep-
tance rate is almost twice as high as previously. We see again that an
adaptive Monte Carlo approach can generate an independence sampler for a
Metropolis-Hastings chain even when the target distribution Π is two dimen-
sional and has well seperated modes. It is worth pointing out that modifying
Π by the introduction of stepping stone distributions [5] has been suggested
as a means to facilitate sampling PDFs of this nature; in our approach no
such modiﬁcations are necessary.

We conclude with a brief discussion of the relevance of our methods for
event generation in experimental high energy physics simulations, where
a sample from a potentially very complicated diﬀerential scattering cross-
section dependent on more than two variables is required. If analytic inver-
sion is not possible (as is often the case), another approach such as rejection
sampling is needed. This however requires an enveloping distribution which
must be somehow obtained, either by guesswork or possibly by using the VE-
GAS grid information [6]. Alternatively the grid information may be used
to construct an importance sampler for a Metropolis-Hastings chain which
can be used to generate events. To test this in practise, we have considered

6

→

the example of anomalous single t production in future γγ colliders, followed
by t
bℓν evaluated in the narrow width approximation for the t and W
[7]. The ﬁve dimensional phase space has been integrated over with VEGAS
and the resulting grid was used as an importance sampler to generate events
along the lines of the previous examples. Neglecting the eﬀects of cuts, smear-
ing and hadronisation, we obtained an acceptance rate of about 75%, even
though no attempt whatsoever was made to optimise the grid. In particular,
our sampling did not make any use of simpliﬁcations resulting either from
the use of the narrow width approximation or from the (V
A) structure
of weak decays. This suggests that the methods we have outlined may be
worthwhile incorporating into event generators for high energy physics, at
least in instances when the phase space can be integrated over with VEGAS.
Acknowledgments KJA wishes to thank Prof. Krishna Athreya for valuable
encouragement and useful discussions, and Prof.J. Hauptman for reading a
preliminary version of the manuscript.

−

7

References

[1] N. Metropolis et.al.; ”Equations of state calculations by a fast comput-

ing machine” J.Chem.Phys. 21:1087-1091 (1953).

[2] W.K. Hastings; ”Monte Carlo sampling methods using Markov Chains

and their applications” Biometrika 57: 97-109 (1970).

[3] P. Lepage; ”A New Algorithm for Adaptive Multidimensional Integra-

tion” J.Comp.Phys. 27:192 (1978).

[4] L. Tierney; ”Markov Chains for Exploring Posterior Distributions”

Ann.Statist. 22:1701-1762 (1994).

[5] N. Sheehan & A. Thomas; ”On the irreducibility of a Markov Chain
deﬁned on a space of genotype conﬁgurations by a sampling scheme”
Biometrics 49:163-175 (1993).

[6] S. Kawabata; ”A New Monte Carlo Event Generator for High Energy

Physics” Comput.Phys.Commun. 41:127 (1986).

[7] K.J. Abraham, K. Whisnant, & B.-L. Young; ”Searching for an Anoma-
lous tqγ Coupling via Single Top Quark Production at a γγ Collider”
Phys.Lett.B 419:381-386 (1998).

8

40

35

30

25

20

15

10

5

0

0

Fig.1

5

10

15

20

25

