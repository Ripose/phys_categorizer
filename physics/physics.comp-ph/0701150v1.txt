7
0
0
2
 
n
a
J
 
2
1
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
0
5
1
1
0
7
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Accurate numerical solutions of the time-dependent Schr¨odinger equation

W. van Dijk∗
Physics Department, Redeemer University College, Ancaster, Ontario L9K 1J4, Canada and
Department of Physics and Astronomy, McMaster University, Hamilton, Ontario L8S 4M1, Canada

F. M. Toyama†
Department of Information and Communication Sciences,
Kyoto Sangyo University, Kyoto 603-8055, Japan
(Dated: February 2, 2008)

We present a generalization of the often-used Crank-Nicolson (CN) method of obtaining numerical
solutions of the time-dependent Schr¨odinger equation. The generalization yields numerical solutions
accurate to order (∆x)2r−1 in space and (∆t)2M
in time for any positive integers r and M , while CN
employ r = M = 1. We note dramatic improvement in the attainable precision (circa 10 or greater
orders of magnitude) along with several orders of magnitude reduction of computational time. The
improved method is shown to lead to feasible studies of coherent-state oscillations with additional
short-range interactions, wavepacket scattering, and long-time studies of decaying systems.

PACS numbers: 02.60.-x, 02,70.-c, 03.67.Lx, 03.65.-w

I.

INTRODUCTION

Whereas there are a number of examples of exact an-
alytic solutions of time-independent problems in quan-
tum mechanics, such solutions of time-dependent prob-
lems are few. The analytic solutions of both types that
do exist tend to provide approximate models to actual
physical systems. No doubt such solutions are instruc-
tive for gaining insight into the behavior of the physi-
cal systems that they describe. Nevertheless because the
models themselves are often approximations and because
one wishes to describe real systems as precisely as possi-
ble, one also relies on accurate numerical methods.

The time-dependence of nonrelativistic quantum sys-
tems, which is the focus of this paper, has become
important in diverse areas of atomic and subatomic
physics. Examples of these include the study of nu-
clear processes such as the decay of unstable nuclei and
associated phenomena like atomic ionization [1, 2] and
bremsstrahlung [3, 4, 5], the study of fundamental pro-
cesses necessary for quantum computing [6], the study of
mesoscopic physics or nanophysics devices [7], and the
motion of atoms in a trap. A reliable and accurate nu-
merical determination of the time-dependent wave func-
tion such as we discuss in this paper will no doubt be
necessary and/or helpful in making advances in the un-
derstanding of a variety of quantum processes.

In this paper we consider the numerical solution of
the time-dependent nonrelativistic Schr¨odinger equation.
Much has been learned about basic scattering processes
from the numerically generated solutions of traveling
wavepackets as they pass through a potential region [8],
as well as the time-evolution of unstable quantum pro-

∗Electronic address: vandijk@physics.mcmaster.ca
†Electronic address: toyama@cc.kyoto-su.ac.jp

cesses [9]. However, the methods used in the past, and
still employed currently, are limited in that the solutions
often degrade after a certain time interval, so that they
reduce to noise. Furthermore for processes in which the
wave function spreads or travels away from the source
one often requires such a large number of space steps
that the computation becomes prohibitive.

The goal of this study is to improve the existing stan-
dard approach by allowing for relatively large step sizes
both in time and in space and thus to reduce the number
of basic arithmetical calculations while obtaining more
accurate solutions. We have been able to make signiﬁ-
cant improvement to one conventional approach, viz., the
Crank-Nicolson (CN) implicit integration scheme for the
time-dependent Schr¨odinger equation. Many years ago
the CN approach was shown to be successful in the study
of wavepacket scattering in one dimension by Goldberg
et al. [8]. In recent years the CN method continues to
be employed for its space- and/or time-development al-
gorithm to study various time-dependent problems. See,
for example, Refs. [10, 11, 12, 13]. The attractive as-
pect of this method is that the solution is constrained to
be unitary at every time step. It is this constraint that
makes the solution stable regardless of time- or space-step
size. Although the evolution of the solution is unitary,
the wave function is not correct if the step sizes are too
((∆x)2, (∆t)3), where ∆x and ∆t
large. The error is of
are the spatial and temporal step size, respectively.

O

The method was successfully generalized to two di-
mensional scattering by Galbraith et al. [14] and, more
recently, to multichannel scattering [15]. Furthermore al-
ternative methods which are fast computationally were
introduced by Kosloﬀ and Kosloﬀ [16]. These involve the
fast Fourier transform of the kinetic energy operator of
the Schr¨odinger equation. Variants of this method were
discussed in Ref. [17]. Although this approach is fast
and is able to handle large time intervals in one pass, it
is not unitary and does require a large number of space

intervals.

where

O

O

Improved CN algorithms have been discussed by a few
authors. Mi¸sucu et al. [5] introduced a seven-point for-
mula for the second-order spatial derivative with error
((∆x)6) and an improved time-integration scheme
of
((∆t)5). They claim to obtain two
with an error of
orders of magnitude improvement in the time advance.
Moyer [18] uses a Numerov scheme for the spatial inte-
((∆x)6) but has a one-
gration method with error of
stage time evolution giving the CN precision in time,
((∆t)3). Moyer also introduces
i.e., with an error of
transparent boundary conditions for unconﬁned systems.
We have found these very useful for making long-time or
large-space problems tractable [7], but we will not discuss
such boundary conditions further in this paper. Puzynin
et al. [19, 20] indicate how to generalize the time devel-
opment to higher order, but do not discuss spatial inte-
gration.

O

O

In this paper we present a generalization of the often-
used CN method of obtaining numerical solutions of
the time-dependent Schr¨odinger equation. The gener-
alization yields numerical solutions accurate to order
(∆x)2r−1 in space and (∆t)2M in time for any positive
integers r and M , while CN employ r = M = 1. By
appropriate choice of r and M the improvement can be
of such a nature that hitherto computationally unfeasible
problems become doable, and solutions with low to mod-
est precision can now be obtained extremely accurately.
In the following we consider the generalization of spa-
tial integration in Sec. II and the generalization of the
time integration in Sec. III. In Sec. IV we discuss errors
and a way of dealing with a particular type of bound-
ary condition. We study speciﬁc examples to illustrate
the improvement of the generalizations over the standard
CN procedure in Sec. V. Some general observations and
conclusions are made in Sec. VI.

II. SPATIAL INTEGRATION

We describe a general procedure for solving the one-

dimensional time-dependent Schr¨odinger equation

i¯h

∂
∂t −

(cid:18)

(cid:19)

H

ψ(x, t) = 0,

ψ(x, t0) = φ(x),

(2.1)

2

(2.2)

H =

¯h2
2m

∂2
∂x2 + V (x),

−

and φ(x) is a given wave function at initial time t0. In
this section we use the standard time-advance procedure
of the CN method, but generalize the spatial integration.
In Sec. III we generalize the time-evolution procedure.

The time evolution of the system can be expressed in
terms of an operator acting on the wave function at time
t which gives the wave function at a later time t + ∆t
according to the equation

ψ(x, t + ∆t) = e−

iH∆t/¯hψ(x, t).

(2.3)

iH∆t/¯h can be expanded
The time-evolution operator e−
to give a unitary approximation of the operator by setting

iH∆t/¯h =

e−

1
−
1 + 1

1
2 iH∆t/¯h
2 iH∆t/¯h

+

((∆t)3).

O

(2.4)

Inserting the approximate form of the operator into
Eq. (2.3), we obtain the equation

1
2

1
2

1
(cid:18)

−

1 +

iH∆t/¯h

ψ(x, t+∆t) =

iH∆t/¯h

ψ(x, t),

(cid:19)

(cid:18)

(cid:19)

O

(2.5)
((∆t)3). Here we focus on the second-
with an error of
order spatial derivative in H of Eq. (2.2) and leave im-
provements with respect to the time derivative to Sec. III.
We generalize the usual three-point formula and the
seven-point formula of Mi¸sicu et al. [5], for the second-
order derivative to a (2r + 1)-point formula. Such a for-
mula has the form

y′′(x)

y(2) =

≡

1
h2

c(r)
k y(x + kh) +

(h2r),

(2.6)

O

k=r

Xk=−r

where c(r)
k
c(r)
k we make expansions

are real constants. To obtain the coeﬃcients

y(x + kh) = y(x) + (kh)y(1)(x) +

(kh)2y(2)(x) +

(kh)2r+1y(2r+1)(x) +

(h2r+2)

y(x

kh) = y(x)

(kh)y(1)(x) +

(kh)2y(2)(x)

−

−

(kh)2r+1y(2r+1)(x) +

(h2r+2),

1
2!
1
2!

+

+

1
(2r + 1)!
1)2r+1
(
−
(2r + 1)!

· · ·

− · · ·

O

O

for k = 1, 2, . . . , r; y(i) denotes the ith derivative with respect to x. When we add the two equations, the terms with
odd-order derivatives cancel, resulting in the equation

2

(kh)2
2!

(kh)4
4!

(kh)2r
(2r)!

· · ·

y(2)(x) + 2

y(4)(x) +

+ 2

y(2r)(x) = y(x + kh) + y(x

kh)

2y(x) +

(h2r+2).

(2.7)

−

−

O

Thus we obtain the system of r equations in r unknowns, i.e., y(2k)(x) for k = 1, . . . , r,

y(2)(x) + 2

y(4)(x) +

+ 2

y(2r)(x) = y(x + h) + y(x

y(2)(x) + 2

y(4)(x) +

+ 2

y(2r)(x) = y(x + 2h) + y(x

2

(h)2
2!
(2h)2
2!

2

2

(rh)2
2!

(h)4
4!
(2h)4
4!
...
(rh)4
4!

(h)2r
(2r)!
(2h)2r
(2r)!

(rh)2r
(2r)!

· · ·

· · ·

· · ·

h)

2y(x)

−

−

2h)

2y(x)

−

−

y(2)(x) + 2

y(4)(x) +

+ 2

y(2r)(x) = y(x + rh) + y(x

rh)

2y(x).

−

−

(2.8)

3

We solve these equations to obtain y(2)(x). It is evident
from the terms on the right side of Eqs. (2.8) that y(2)(x)
has the form of Eq. (2.6) and the coeﬃcients c(r)
can
k
be identiﬁed. Because the equations (2.8) are invariant
under the change of h to
h, the coeﬃcients satisfy the
relation c(r)
for k = 1, 2, . . . , r. For example,
the ﬁrst seven sets of coeﬃcients (up to the ﬁfteen-point
formula) are given in Table I.

−k = c(r)

−

k

r k = 0

1

2

3

4

5

6

7

2

1

−2
− 5
2
− 49
3
18
4 − 205
72
5 − 5269
1800
6 − 5369
1800
7 − 266681
88200

8

3

20

12

1
3 − 1
4
2 − 3
5 − 1
3 − 5
7 − 15
4 − 7

56

24

21

5

5

7

12

1
90
8

560

5

315 − 1
126 − 5
189 − 1
108 − 7

10

7

112

528

1008

1
3150
2

1925 − 1
3300 − 7

7

16632

30888

1
84084

TABLE I: The coeﬃcients c(r)

k up to r = 7.

Let us partition the range of x and t values so that
xj = x0 + j∆x, j = 0, 1, . . . , J and tn = t0 + n∆t,
n = 0, 1, . . . , N . The numerical approximation of the
wave function at a mesh point in space and time is de-
ψ(xj , tn) and we set Vj = V (xj ). Using
noted as ψj,n ≈
expression (2.6) in Eq. (2.5), we obtain

ψj,n+1 −

i¯h∆t
4m(∆x)2

= ψj,n +

i¯h∆t
4m(∆x)2

k=r

"

Xk=−r
k=r

"

Xk=−r

c(r)
k ψj+k,n+1

+

Vj ψj,n+1

i∆t
2¯h

#

c(r)
k ψj+k,n

i∆t
2¯h

# −

Vj ψj,n, (2.9)

for j = 0 to J. The indices in the sums may go out of
range, so we set ψj,n = 0 when j < 0 and j > J. Deﬁne

i¯h∆t
2m(∆x)2 , z(1)

1 ≡ −

b

≡

2 and a(r)

k ≡

b
z(1)
1

c(r)
k , (2.10)

and subsequently

dj ≡

1 + a(r)

0 −

i∆t/¯h
z(1)
1

Vj,

j = 0, 1, . . . , J.

(2.11)

The notation includes z(1)
1 which is consistent with that
used in the generalization of the time dependence of the
wave function discussed in the next section.

The solution ψj,n+1 is obtained by solving the system

of linear equations

AΨn+1 = A∗Ψn,

(2.12)

where the matrix A is the (2r + 1)-diagonal matrix





· · ·
· · ·
· · ·

a2
a1
d2
...

a1
d1
a1
...

d0
a1
a2
...
ar ar−1 ar−2 · · ·
ar−1 · · ·
0

ar

0
ar
ar−1
ar
ar−2 ar−1
...
...
a1
dr
dr+1
a1

,

. . .

A =































dJ−1 a1


dJ


(2.13)

where the superscript (r) of the ak is assumed. The ma-
trix A∗ is the complex conjugate of matrix A. The wave
function at tn+1, i.e., Ψn+1, is a column vector consisting
of the ψj,n+1 as components, and can be determined if
Ψn is known. The matrix equation (2.12) can be solved
using standard techniques.

a1

III. TIME ADVANCE

In this section we extend the work of Puzynin et
al. [19, 20]. The basic idea is to replace the exponen-
tial operator exp(
iH∆t) by the diagonal Pad´e approxi-
mant. The [M/M ] Pad´e approximant of the exponential
function may be written as

−

f (z) = ez =

a0 + a1z +
b0 + b1z +

· · ·
· · ·

+ aM zM
+ bM zM =

m=0
X
M

M

amzm

,

′

bm′zm

Xm′=0

(3.1)

4

where the am and the bm′ are complex constants. It is
evident that when z = 0, a0/b0 = 1, which makes one of
the coeﬃcients arbitrary. By convention we take b0 = 1
which immediately ﬁxes a0 = 1. There are 2M constants
remaining, which can be found from the known coeﬃ-
cients of the series expansion of the exponential function,
(z2M+1). The prop-
giving an error term in Eq. (3.1)
erty of Pad´e approximants that can be used to advantage
is that, if f (z) is unitary, so is its diagonal Pad´e approx-
imant [21].

O

In general we solve for the coeﬃcients am and bm′ by

multiplying Eq. (3.1) by the denominator so that

M

∞

M

′

bm′zm

cizi

=

!

 

Xm′=0

!  

i=0
X

 

m=0
X

!

amzm

,

(3.2)

where the ci are known since ez =
∞
i=0 zi/i!. Multi-
plying out the sums on the left side of Eq. (3.2), and
equating the coeﬃcients of z through z2M on both sides,
we obtain 2M equations in 2M unknowns. The last M of

P

these equations contain no am and hence can be solved
for the bm′, which in turn can be inserted in the ﬁrst
M equations to obtain the am. The numerator and the
denominator of the diagonal Pad´e approximant of the
exponential function have been studied extensively [21].
When each is factored it is found that the roots of the
denominator are the negative complex conjugates of the
roots of the numerator. Thus the [M/M ] Pad´e approxi-
mant of the exponential function leads to

M

ez =

s=1  
Y

z/z(M)
1
s
1 + z/¯z(M)

−

s !

+

(z2M+1),

O

(3.3)

s

is the complex conjugate of z(M)

where z(M)
, s = 1, . . . , M , are the roots of the numera-
s
tor, and ¯z(M)
. These
roots can be found to a desired precision for virtually any
value of M . We have found them to 17 digit precision
for M up to 20, a sample of which for M = 1 to 5, each
rounded to ﬁve decimal places, is given in Table II.

s

2

s = 1

M
1 −2.00000 + i0.00000
2 −3.00000 + i1.73205 −3.00000 − i1.73205
3 −4.64437 + i0.00000 −3.67781 − i3.50876 −3.67781 + i3.50876
4 −4.20758 + i5.31484 −5.79242 + i1.73447 −5.79242 − i1.73446 −4.20758 − i5.31483
5 −4.64935 + i7.14205 −6.70391 + i3.48532 −7.29348 + i0.00000 −6.70391 − i3.48532 −4.64935 − i7.14205

4

5

3

TABLE II: The roots z(M )
proximant of the exponential function for M from 1 to 5.

of the numerator of the Pad´e ap-

s

We use the Pad´e approximant to express the time evo-

lution operator. Deﬁne the operator

K (M)

s ≡

1

−

1 +

iH∆t/¯h
z(M)
s
iH∆t/¯h
¯z(M)
s

,

Assuming that Ψn is known, we determine Ψn+1/M from
Eq. (3.7) which has a form similar to that of Eq. (2.5).
We use therefore the same method of Sec. II to ob-
tain Ψn+1/M . This is repeated to obtain in succession
Ψn+2/M , Ψn+3/M , . . . , Ψn+(M−1)/M , Ψn+1. Since the op-
erators K (M)
commute, they can be applied in any order.

s

(3.4)

so that

iH∆t/¯h =

e−

K (M)

s +

((∆t)2M+1).

(3.5)

O

Since Ψn+1 = e−

iH∆t/¯hΨn, we write the relation

Ψn+1 =

K (M)

s Ψn.

(3.6)

M

s=1
Y

M

s=1
Y

Deﬁning Ψn+s/M ≡
Ψn+1 recursively, starting with

K (M)

s Ψn+(s−1)/M , we can solve for

IV. DISCUSSION OF ERRORS AND
BOUNDARY CONDITIONS

A. Errors

In this section we discuss the errors as a function of the
orders of the method, i.e., r and M . Let us separate the
truncation errors due to the integration over space and
those due to integration over time. At a given time t the
spatial integration with the rth-order expansion yields a
truncation error

Ψn+1/M = K (M)

1 Ψn.

(3.7)

e(r) = C(r)(∆x)2r,

(4.1)

5

e(r)

constant
J 2r

.

≈

(4.3)

 0

 5

 15

 20

 10
M

FIG. 1: The average, the minimum and the maximum values
of {|z(M )

|, s = 1 . . . M }, as a function of M .

s

where C(r) is assumed to be slowly varying with r. Ac-
/(2r!) for some x∗ in the range
ψ(2r)(x∗, t)
tually C(r) =
|
|
of spatial integration, and thus is model dependent. If
we specify an acceptable error, the step size ∆x can be
adjusted to obtain that error. Since ∆x = (x0 −
xJ )/J,
an adjustment of ∆x is equivalent to a change in J. Re-
xJ is ﬁxed, we obtain
calling that x0 −

∆x =

xJ

x0 −
J

=

1/2r

,

e(r)
C(r)

(cid:18)

(cid:19)

and

|z(M)|

(4.2)

z(M)
avge
z(M)
min
z(M)
max

 30

 25

 20

 15

 10

 5

 0

We have assumed that C(r) is approximately constant.
The CPU time for the calculation is proportional to the
number of basic computer operations in solving the ma-
trix equation (2.12). This involves elementary row oper-
1 columns to bring the matrix
ations on r
to upper triangular form, plus J back substitutions to
obtain the solution. Hence

1 rows in J

−

−

CPU time

# operations

Jr

∝

r
(e(r))1/2r .

∝

∝

(4.4)

This form gives a minimum (optimum) CPU time which
occurs when

r

≈ −

ln e(r)
2

.

(4.5)

For the time integration we assume a truncation error
independent of r. For a given r the error due to ﬁnite ∆t
has a ﬁrst term in the expansion

e(M) = C(M)(∆t)2M+1,

(4.6)

where again C(M) is assumed to be a slowly varying func-
tion of M . We note that the factor 1
2 in the numerator
and denominator of Eq. (2.4) is replaced by 1/z(M)
in
each of the M factors (3.4) of Eq. (3.5). As M increases
z(M)
, which we
the average over diﬀerent values of s of
s
|
|
denote as z(M)
avge, also increases. In fact z(M)
avge is a linear
function of M as is seen in Fig. 1. The eﬀective expan-
sion parameter can be approximated by 2∆t/z(M)
avge rather
than ∆t and hence is proportional to ∆t/M . Thus we can
replace the relation of Eq. (4.6) by

s

e(M)

C(M)(∆t/M )2M+1,

(4.7)

≈

where the constant C(M) is appropriately adjusted. If we
take the total time tmax = N ∆t to be ﬁxed, then

CPU time

e(M)

∝

(cid:16)

(cid:17)

−

1
2M + 1 .

(4.8)

e
m

i
t
 

U
P
C

 50

 40

 30

 20

 10

 0

r, M increases from 1 through 5 or larger. For increas-
ing M the CPU time continues to decline although the
decrements become smaller at larger M . For increasing
r there is a minimum depending on the speciﬁed error
and beyond the minimum the curve shows a slow in-
crease with increasing r. Superimposed on the curves
are the CPU times (as dots) of a model calculation (see
Sec. V A), in which the numerical and exact solutions can
be compared. Clearly the theoretical trends, including
the minimum as a function of r, occur in the computed
example. It should be noted that it “pays” to increase

e(r)(theory)
e(M)(theory)
e(r)(calculated)
e(M)(calculated)

 2

 4

 6

 8

 12

 14

 16

 18

 20

 10
r, M

FIG. 2: The normalized theoretical variation of the CPU time
for a given error of 1.0 × 10−8. The calculated CPU times for
the example of Sec. V A are shown as dots.

In Fig. 2 the curves of the (scaled) CPU times are plot-
ted. Both curves clearly show the sharp decline when

M indeﬁnitely, whereas there is an optimum value of r
which depends on the magnitude of e(r).

B. Boundary conditions

V. EXAMPLES

6

Below Eq. (2.9) we indicate that we set ψj,n = 0 when
j < 0 or j > J, or when j goes out of range. These are
appropriate boundary conditions when the wave function
and its ﬁrst r + 1 derivatives are zero at the boundaries,
since it was assumed in the derivation of the method
that all these derivatives exist.
If however that is not
the case, for instance, at the boundary of an (in)ﬁnite
square well or barrier where the second-order derivative
does not exist, one must devise ways of incorporating the
proper boundary conditions.

One case of importance, which we discuss in the third
example (see Sec. V C) of the paper, is the case of radial
behavior of a partial wave when angular momentum de-
composition has been done. In the S-wave case the wave
function, deﬁned only for nonnegative values of the radial
coordinate, is zero at the origin but the ﬁrst derivative
is ﬁnite. Muller [22] discusses a related, but not identi-
cal, situation. He considers three-point formulas for the
Coulomb potential which lead to a radial wave function
which is zero when the radial variable ρ = 0, but has ﬁrst
and second derivatives which are nonzero at ρ = 0. His
approach can be adapted to the (2r + 1)-point formula
of this work.

We treat this case by making the ansatz that the wave
function behaves like an odd function about the origin
and continues in the unphysical region of the negative
radial variable. With this assumption we do not aﬀect
the behavior of the system at positive values of the radial
variable, but all the required derivatives exist. Further-
more, the wave function at negative j values can be com-
bined with the ones with corresponding positive j values,
so that the space need not be enlarged but instead the
ﬁrst few matrix elements of the matrix A can be changed
to account for the boundary condition. This is achieved
by replacing A by A′ = A

B in Eq. (2.13) where

−

We consider three systems to which this numerical
method may be applied. The ﬁrst two allow us to make
a comparison with the exact solution and to test the pre-
cision of the numerical procedure. The third involves the
time evolution of a quasi-stable quantum process.

A. Oscillation of a coherent wavepacket

The oscillation of a coherent state in the harmonic os-
cillator well is described in Ref. [23]. The time evolution
of such states has been discussed recently in connection
with the quantum abacus. (See Ref. [6].) In that case
there is a point interaction at the center of the oscillator
well. It is of interest to consider narrow but ﬁnite-range
interactions to simulate more realistic physical systems.
In order to test the robustness of the quantum gates one
needs a very stable numerical procedure. We test the
precision of the numerical procedure by investigating the
case without the central interaction, so that the numeri-
cal results can be compared with the exact ones.
The time-dependent Schr¨odinger equation is

i¯h

ψ(x, t) =

∂
∂t

¯h2
2m

∂2
∂x2 +

1
2

−

(cid:18)

(cid:19)

Kx2

ψ(x, t).

(5.1)

We consider the time evolution of the initially displaced
ground-state wave function

ψ(x, 0) =

α1/2
π1/4 e− 1

2
2 α

(x−a)

2

,

(5.2)

where α4 = mK/¯h2, ω =
K/m, and a is the initial
displacement. The closed expression for the time evolved
p
wave function is

ψexact =

ξ0 cos ωt)2

α1/2
π1/4 exp
1
2

i(

−

1
2

(ξ

−

−

(cid:20)

+ ξξ0 sin ωt

1
4

−

ξ2
0 sin 2ωt)
(cid:21)

, (5.3)

a1
a2
a3
...

a2 a3 · · ·
0
a3 a4 · · ·
0
a4 a5 · · ·
0
...
...
...
0 ar−1 ar 0
0
0
0
0
...
...

· · ·
· · ·
· · ·

ar
0
...

0
0
...

ar−2 ar−1 ar 0
0 0
ar
ar−1
0 0
0
ar
...
...
...
...
0 0
0
0
0 0
0
0
0 0
0
0
...
...
...
...

· · ·
· · ·
· · ·

· · ·
· · ·
· · ·

B =




















.















(4.9)

where ξ = αx and ξ0 = αa. We set ¯h = m = 1, ω = 0.2,
and a = 10. We choose our space such that x
[x0, xJ ] =
[
40, 40]. The period of oscillation is then T = 10π. We
−
allow the coherent state to oscillate for eleven periods
before comparing the numerical solution to the exact one.
The error is calculated as e2 using the formula [19]

∈

(e2)2 =

xJ

x0

Z

dx

ψ(x, t1)
|

−

2,
ψexact(x, t1)
|

(5.4)

A hard-core type potential could be dealt with in the
same way. Diﬀerent forms of boundary conditions are
more complicated to implement, but Ref. [22] suggests
an approach to including such boundary conditions. For
the purpose of the radial wave function of a nonsingular
potential, the above approach is suﬃcient.

where t1 = 11T for our example. The results including
the relative CPU time [34] are displayed in Table III.

In the above tests we have tried to obtain a precision
better than 10−8. While varying the number of steps
for the spatial integration, we kept the number of time
factors per time step constant at 20. Given that the

M r

∆t

∆x

J

e2

CPU time

π
π
π
π
π
π
π
π
π
π

0.44444 180 6.717 × 10−9
20 20
0.38095 210 7.044 × 10−9
20 15
0.27586 290 7.506 × 10−9
20 10
0.18182 440 9.353 × 10−9
7
20
0.09877 810 9.330 × 10−9
5
20
0.05755 1390 9.871 × 10−9
4
20
0.03810 2100 2.102 × 10−7
3
20
0.03810 2100 1.624 × 10−4
2
20
0.03810 2100 1.749 × 10−1
20
1
0.26667 300 5.106 × 10−9
20 10
15 10 π/1.5 0.26667 300 5.153 × 10−9
0.26667 300 4.995 × 10−9
10 10
10 π/15 0.26667 300 8.787 × 10−9
5
10 π/150 0.26667 300 1.840 × 10−9
3
10 π/3000 0.26667 300 5.046 × 10−4
1

π/3

18.38
14.23
10.84
10.12
12.83
18.61
23.67
18.42
13.75
10.77
12.13
16.16
40.42
242.9
1627

TABLE III: Summary of computational time and errors in-
curred by using the numerical integration procedure when the
initial wave function is the displaced ground state. The last
column indicates a relative CPU run time. The upper half of
the table gives the eﬀects of changing the number of spatial
steps; the lower half the eﬀects of changing the number of
time steps.

total space is ﬁxed and spans 80 units, we adjusted the
number of spatial steps J to give the required precision.
We limited (arbitrarily) the maximum number of spatial
steps to 2100. With M = 20 the 15-point formula (r = 7)
is most eﬃcient. When r < 4 (less than 9-point formula),
we were unable to reach the precision criterion because
of the imposed limit on J.
It is clear from the trend
however that the eﬃciency is signiﬁcantly less for the
lower r values. The 9-point formula is roughly half as
eﬃcient as the 15-point formula.

The eﬀect of diﬀerent order time formulas as seen in
the lower part of Table III is even more dramatic. For the
spatial integration we used the 21-point formula (r = 10),
and varied the time-order formula, i.e., M , from 20 to 1.
We see at least two orders of magnitude improvement in
computational speed as M is increased over this range.
A comparison with the standard CN approach (r =
M = 1) is instructive. We considered the same sys-
tem with x0 =
25 and xJ = 25, ∆x = 0.005 and
∆t = 0.5(∆x)2. The standard CN method yielded an
10−5 when t = T /4 which increased
error of e2 = 7.1
10−3 at t = 10T . Whereas
exponentially to e2 = 2.7
×
the CPU time in Table III is given in seconds, the CPU
time required to complete this last calculation exceeded
24 hours.

×

−

The computed CPU times shown in Fig. 2 exceeded the
“theoretic” values by increasing amounts as r increased
beyond 10. This can be attributed to the approximate
nature of the error analysis in which the model depen-
dence of C(r) (and C(M)) was neglected. In this exam-
ple a more elaborate analysis could be done since the
wave function is known analytically. In practical situa-
tions where a numerical method is used the analytic wave

7

function is usually not known and an estimate such as we
have given here would be all that is available. The main
point is that dramatic improvements result both theoret-
ically and computationally when larger values of r and
M are employed.

B. Propagation of a wavepacket

For this example we return to the work of Ref. [8] and
consider the main features of that analysis with a view
of determining the improvement brought about by the
generalizations of this paper. This problem was revis-
ited by Moyer [18] to illustrate the eﬃcacy of the Nu-
merov method and the use of transparent boundary con-
ditions for the propagation of free-particle wavepackets.
The authors of Ref. [8] consider wavepackets impinging
on a square barrier and study their behavior in time. We
consider ﬁrst free wavepacket propagation (without po-
tential), and second the reﬂection and transmission of a
wavepacket by a smooth potential.

Thus we ﬁrst assume V (x) = 0 and take as initial wave

function

0)−1/4eik0(x

ψ(x, 0) = (2πσ2

.
(5.5)
(Note that our σ0 is that of Ref. [8] divided by √2.) The
wave function at later time is given by

x0)e−

x0)2/(2σ0)2

(x

−

−

ψ(x, t) = (2πσ2

0)−1/4[1 + i¯ht/(2mσ2

0)]−1/2

×

i¯hk2

0t/(2m)

.

(x

exp

−

−

x0)2/(2σ0)2 + ik0(x

x0)
−
1 + i¯ht/(2mσ2
0)

−

(cid:26)

−

(cid:27)
(5.6)
We use parameters comparable to those of Ref. [8].
We set ¯h = 1 and m = 1
2 . The coordinate range we take
is from
0.5 to 1.5 rather than from 0 to 1 since over
the smaller space the normalization of the packet is not
as precise as we require because the tails of the Gaus-
sian are nonzero outside the (0,1) interval. We choose
σ0 = 1/20, k0 = 50π, ∆t = 2(∆x)2, and allow as much
time as it takes the packet to travel from x0 = 0.25 to
around 0.75. For the ﬁnal position the numerically cal-
culated wave function is compared to the analytic one
and e2 is determined. In Table IV we list some of the
computed results. We observe that the traditional CN
method (M = 1 and r = 1) has a low precision and that
using greater J (smaller ∆x) results in modest gain in
precision. By using higher-order time formula one can
make signiﬁcant gain in precision (seven orders of mag-
nitude) with no increase in computational time compared
with that of Ref. [8]. (Compare the ﬁrst row to the last
two rows of Table IV.) Rows 5 through 9 of Table IV
illustrate the transition from less precise to more precise
solutions. It is consistent with the ﬁnding of the authors
of Ref. [5] who use an M = 2, r = 3 method and obtain
two orders of magnitude improvement of the results of

Refs. [1, 3]. The results are sensitive to surprisingly high
orders of ∆x and ∆t.

Another test using wavepacket scattering to show the
eﬃcacy of the higher-order approach is scattering from
a potential. Rather than using the square barrier of
Ref. [8], we consider the repulsive P¨oschl-Teller type po-
tential [24, 25] of the form

V (x) =

¯h2
2m

β2λ(λ
1)
−
cosh2 βx

.

(5.7)

Since this potential does not have discontinuities the im-
proved CN method works well with it. The transmission
and reﬂection coeﬃcients are known analytically. We
can also compute them by considering the wavepacket
Eq. (5.5) incident on the potential. Over a suﬃciently
long time the wavepacket will have interacted with the
potential and transmitted and reﬂected packets emerge
and travel away from the potential region. At that point
we can calculate the probabilities of the particle repre-
sented by the packet on the left and on the right of the
potential; these probabilities correspond to the transmis-
sion and reﬂection coeﬃcients provided the packet is suf-
ﬁciently narrow in momentum space. This means that
one needs an initial packet which is wide in coordinate
space.
In our calculation we choose β = 1, λ = 2.5,
m = 1, and σ0 = 10. This gives a spread in the inci-
dent momentum-space wave packet of σk = 0.05. The
width in momentum space of the reﬂected and transmit-
ted wavepackets also has this value. The domain of the
300 to +300 and the initial posi-
x coordinates is from
tion of the packet is at x0 =
150 to ensure that there
is no overlap of the initial packet and the potential. We
ﬁnd good agreement between the transmission and reﬂec-
tions probabilities determined by plane-wave scattering
approach and the time-dependent calculation as shown
in Fig. 3.

−

−

M r

J

e2

CPU time

1

1

2
2
3
3
4
4
5
5
6
6
10 10
20 20

2000 9.418 × 10−2
4000 2.189 × 10−2
8000 5.368 × 10−3
16000 1.336 × 10−3
2000 3.018 × 10−4
2000 1.321 × 10−6
2000 6.577 × 10−9
2000 3.648 × 10−11
2000 8.437 × 10−13
3.606 × 10−9
440
4.542 × 10−9
260

2.20
18.04
151.92
1287.8
5.99
12.57
22.64
37.13
56.05
2.12
2.51

TABLE IV: Summary of computational parameters used to
calculate the propagating free packet and compare it to the
analytic wavepacket.

8

T(k)
T(k)
R(k)
R(k)
Twp(k)
Twp(k)
Rwp(k)
Rwp(k)

)
)
k
k
(
(
R
R

 
 
,
,
)
)
k
k
(
(
T
T

 1
 1

 0.8
 0.8

 0.6
 0.6

 0.4
 0.4

 0.2
 0.2

 0
 0

 1
 1

 1.5
 1.5

 2.5
 2.5

 3
 3

 2
 2

k
k

FIG. 3: The transmission and reﬂection coeﬃcients as a func-
tion of k when β = 1, λ = 2.5, m = 1, and σ0 = 10. The sub-
script “wp” indicates that the coeﬃcients are obtained from
the emerging wavepackets. The quantities without subscripts
are calculated using the time-independent method.

C. Long-time behavior of decay of quasi-stable
system

There are few analytically solvable models of the time
evolution of unstable quantum systems [26, 27]. Real-
istic systems need to be solved numerically. Long-time
calculations are required for systems which require both
nuclear and atomic time-scales such as ionization and
bremsstrahlung due to radioactive decay of the nucleus
of an atom [2, 3, 5]. To study the short-time anoma-
lous power law behavior of the decay and the long-time
inverse-power law behavior the method of this paper is
appropriate. This is especially relevant because of the
recently observed violation of the exponential-decay law
at long times [28].

To illustrate the numerical method discussed in this
paper as applied to decaying systems let us consider a
variant of the model with a δ-shell potential [9], but with
the δ function replaced by a gaussian. Thus in the S
partial wave of a spherical system the potential is

V (ρ) =

λ
w√π

exp [

(ρ

−

−

a)2/w2],

(5.8)

where ρ is the radial coordinate. This potential reduces
to the δ-shell potential, Vδ(ρ) = λδ(ρ
→
0. For small but ﬁnite values of w this potential leads
to scattering results which are good approximations of
those of the δ-shell interaction [35]. Initially the quantum
system is in the state

a) when w

−

ψ(ρ, 0) =

2/a sin (πρ/a).

(5.9)

p

In our example we take ¯h = 1, λ = 3, m = 1
2 , a = 1 and
w = 0.10. Using the numerical method of this paper,
including the modiﬁcation of matrix A as described in
Sec. IV B to take care of the boundary conditions at ρ =

0, we determine the wave function at later times, i.e.,
ψ(ρ, t). From that we obtain the nonescape probability,
a
2 dρ, which is shown
ψ(ρ, t)
as a function of t, P (t) =
0 |
|
in Fig. 4. It clearly shows the exponential decay-region
R

)
t
(
P
0
1

 

g
o
l

 0

-1

-2

-3

-4

-5

-6

-7

-8

-9

P(t)

 1
 0.8
 0.6
 0.4
 0.2
 0

 0  0.2  0.4  0.6  0.8  1

t

 0

 2

 4

 6

 8

 10

 12

 14

t

FIG. 4: The nonescape probability as a function of time for
the interaction with λ = 3, a = 1, and w = 0.10. We also
take ¯h = 1 and m = 1
2 .

in time, the inverse power-law behavior for long times,
the deviation from exponential decay at short times, and
the transition regions [9].

The quadratic short-time behavior is seen in Fig. 4
as is the inverse power law behavior at long times [29].
Remarkably the decaying system can be studied in this
manner for a time exceeding thirty half-lives. In Fig. 5
we plot the square of the absolute value of the wave
function at times t = 5, 10, 15. Notice that the wave

|ψ(r,t)|2

 0.08

 0.06

 0.04

 0.02

 0

 0

V1(r)V1(r)
V1(r)V1(r)

|ψ(r,0)|2
|ψ(r,0)|2

 0
 0

 0.4  0.8  1.2
 0.4  0.8  1.2
r
r

 2
 2
 1.5
 1.5
 1
 1
 0.5
 0.5
 0
 0

 80
r

 20

 40

 60

 100

 120

 140

FIG. 5: The square of the absolute value of the wave function
as a function of ρ at times t = 5, 10, 15 for the same param-
eters apply as in Fig. 4. The insert gives the t = 0 graph as
well as the scaled potential, V1(ρ) = V (ρ)/8.

function (packet) has three distinct regions: a precursor
due to energy components of the initial wave function
larger than that associated with the exponential decay,

9

the main packet which corresponds to the exponential de-
cay at the resonance energy, and the follower, which is a
small blip that stretches in time (travels more slowly) and
is due to energy components in the initial wave function
which have lower energy that the resonance energy. If the
maximum spatial coordinate, which is set at 800 for this
calculation, were set at a smaller value, say 400, then
one observes a fuzziness in the precursor of the right-
most wave function. This can be attributed to the ﬁ-
nite space in which the wavepacket travels so that the
fast precursor has been partially reﬂected from the right
boundary and interferes with the wave front of the main
wavepacket. The numerical parameters for this calcula-
tion are ∆ρ = 0.1, ∆t = 0.02, r = 20 and M = 20.

VI. REMARKS

The generalized CN method that we have presented in
this paper gives many orders of magnitude improvement
in the precision of the results and several orders of mag-
nitude in the computational time required to obtain the
results. Clearly, since this method enhances the eﬃciency
of the numerical calculations, it can be a signiﬁcant tool
for studying time-dependent processes. It goes beyond
the improvement of Ref. [5] in a systematic way. It also
is an advance over the method of Ref. [18], since the Nu-
((∆x)6), and it is diﬃcult
merov method has an error
O
to see how it can be generalized systematically to higher
order spatial errors. The generalized time evolution al-
gorithm can be applied to Moyer’s [18] method.

We have applied the method for r and M up to and in-
cluding 20 for both. Having achieved signiﬁcant improve-
ments with these values of r and M we did not consider
larger values although there does not seem to be a prac-
tical reason that this cannot be done. Although the ap-
proach seems to saturate at r around 10 (see Table III),
there is no visible saturation in the time-evolution part of
the problem. One would expect higher orders of spatial
errors to be signiﬁcant when the wave function and/or
the potential has large spatial ﬂuctuations. Even so, at
r = 7 we are using a 15-point formula for the second-
order spatial derivative, and it is surprising that a smaller
number of points in the formula is not suﬃcient for op-
timal results in this case.
It should be noted that the
higher order method as discussed in this paper are suit-
able only for well-behaved, suﬃciently diﬀerentiable so-
lutions; these occur when the potential function is well
behaved. As the authors of Ref. [10] point out for sin-
gular functions higher-order methods do not necessarily
lead to greater accuracy.

It should be noted that in this paper we consider pri-
marily one-dimensional systems, but the method applies
equally well to partial-wave equations of two- or three-
dimensional systems. The study of the decaying quasi-
stable state is an example of the latter.

An interesting avenue to investigate further is the
this approach may have on two- or

that

impact

involved is equal

to the dimension.

three-dimensional systems, where the number of vari-
ables
The
Peaceman-Rachford-type approach [30], also known as
the alternating-direction implicit method, of factoring
the approximation of the time evolution operator may
apply as it did in Refs. [14, 31] or more recently in, for ex-
ample, Refs. [32, 33]. Using the Crank-Nicolson method
the authors of Refs. [14, 31] show that in two dimension
the kinetic energy parts of the evolution operator factor-
izes. Whether such factorization can be generalized in
the spirit of the method of this paper is under investiga-
tion.

Calculations on one-dimensional multichannel systems
indicate that this approach also leads to substantially
greater eﬃciencies.

Preliminary studies with the Numerov spatial integra-
tion scheme [18] and the generalized time evolution as
described in this work indicate that signiﬁcant improve-
ments occur if one incorporates appropriate changes in
the spatial step size for diﬀerent regions of space. This
is important in the case of discontinuous potentials and
potentials that have great variation in some region and
little or no variation in other regions. Furthermore it is
well known that the wavepacket has large ﬂuctuation in a

10

(short-range) potential region and little variation in the
asymptotic regions. A great savings in computational
time can be achieved by using diﬀerent space-step sizes
in the diﬀerent regions. One needs to investigate whether
such variable step size can be incorporated in the gener-
alized spatial integration scheme of this paper. The ap-
proach that dealt with the discontinuous ﬁrst- or second-
order derivative in this paper and Ref. [22] is worth ex-
ploring. We intend to study this in the future.

Acknowledgments

We are grateful to Professor Y. Nogami for carefully
reading the manuscript and the constructive comments,
as well as useful and helpful discussions. One of the au-
thors (WvD) expresses gratitude for the hospitality of the
Department of Information and Communication Sciences
of Kyoto Sangyo University where most of this work was
completed. He also acknowledges the ﬁnancial support
for this research from the Natural Sciences and Engi-
neering Council of Canada and the Japan Society for the
Promotion of Science.

[1] W. van Dijk, F. Kataoka, and Y. Nogami, J. Phys. A:

[20] I. Puzynin, A. Selin, and S. Vinitsky, Comp. Phys.

[2] F. Kataoka, Y. Nogami, and W. van Dijk, J. Phys. A:

Math. Gen. 32, 6347 (1999).

Math. Gen. 33, 5547 (2000).

[3] C. A. Bertulani, D. T. de Paula, and V. G. Zelevinsky,

Phys. Rev. C 60, 031602 (1999).

[4] W. van Dijk and Y. Nogami, Few-Body Systems Supple-

ment 14, 229 (2003).

[5] S¸. Mi¸sicu, M. Rizea, and W. Greiner, J. Phys. G: Nucl.

Part. Phys. 27, 993 (2001).

Comm. 126, 158 (2000).

[21] G. A. Baker, Jr. and P. Graves-Morris, Pad´e Approxi-
mants: Part I: Basic Theory (Addison-Wesley Publish-
ing Company, Reading, Massachusetts, 1981).

[22] H. G. Muller, Laser Physics 9, 138 (1999).
[23] L. I. Schiﬀ, Quantum mechanics, International series in
pure and applied physics (McGraw-Hill Inc., New York,
1968), 3rd ed.

[24] S. Fl¨ugge, Practical Quantum Mechanics (Springer-

[6] T. Cheon, I. Tsutsui, and T. F¨ul¨op, Physics Letters A

Verlag, New York, 1974).

330, 338 (2004).

[7] C. N. Veenstra, W. van Dijk, D. Sprung, and J. Martorell

(2006), e-print cond-mat/0411118.

[8] A. Goldberg, H. M. Schey, and J. L. Swartz, Am. J. Phys.

35, 177 (1967).

[9] R. G. Winter, Phys. Rev. 123, 1503 (1961).

[10] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and
B. P. Flannery, Numerical recipes in C: The art of scien-
tiﬁc computing (Cambridge University Press, Cambridge,
1992), 2nd ed.

[11] M. Patriarca, Phys. Rev. E 50, 1616 (1994).
[12] X. Qian, J. Li, X. Lin, and S. Yip, Phys. Rev. B 73,

[25] L. D. Landau and E. M. Lifshitz, Quantum mechanics
(Nonrelativistic theory), vol. 3 of Course of theoretical
physics (Pergamon Press, Oxford, 1977), 3rd ed., trans-
lated from Russian by J. B. Sykes and J. S. Bell.

[26] W. van Dijk and Y. Nogami, Phys. Rev. C 65, 024608

(2002); Phys. Rev. C 70, 039901(E) (2004).

[27] W. van Dijk and Y. Nogami, Phys. Rev. Lett. 90, 028901

(2003).

[28] C. Rothe, S. I. Hintschich, and A. P. Monkman, Phys.

Rev. Lett. 96, 163601 (2006).

[29] L. A. Khaﬂin, Soviet Physics JETP 6(33), 1053 (1958).
[30] D. W. Peaceman and J. H. H. Rachford, J. Soc. Indust.

Appl. Math. 3, 28 (1955).

035408 (2006).

52, 60 (1984).

[13] V. M. Vyas, T. S. Raju, C. N. Kumar, and P. K. Pani-

[31] K. C. Kulander, K. S. Devi, and S. E. Koonin, Phys. Rev.

grahi, J. Phys. A: Math. Gen. 39, 9151 (2006).

A 25, 2968 (1982).

[14] I. Galbraith, Y. S. Ching, and E. Abraham, Am. J. Phys.

[32] N. H. Shon, A. Suda, and K. Midorikawa, RIKEN Review

29, 66 (2000).

[15] W. van Dijk, K. Kiers, Y. Nogami, A. Platt, and

K. Spyksma, J. Phys. A: Math. Gen. 36, 5625 (2003).

[16] D. Kosloﬀ and R. Kosloﬀ, J. Comp. Phys. 52, 35 (1983).
[17] C. Leforestier, et al., J. Comp. Phys. 94, 59 (1991).
[18] C. A. Moyer, Am. J. Phys. 72, 351 (2004).
[19] I. Puzynin, A. Selin, and S. Vinitsky, Comp. Phys.

Comm. 123, 1 (1999).

[33] K. L. Ishikawa, Phys. Rev. A 70, 013412 (2004).
[34] The CPU time is a relative measure. The calculations of
Table III were done on a computer with an Intel Pentium
4 Mobile CPU 1.90 Ghz processor. Those of Table IV
were done with a AMD Opteron processor 250 running
at 2.4 GHz. The CPU times within a table give a rough
comparison of the eﬃciency of the method. CPU times
in diﬀerent tables should not be compared.

[35] To be published.

11

