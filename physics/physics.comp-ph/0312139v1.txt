A Parallel/Recursive Algorithm

W. R. Gibbs

New Mexico State University, Las Cruces NM, 88003

Abstract

An algorithm is discussed for converting a class of recursive processes to a parallel sys-
tem. It is argued that this algorithm can be superior to certain methods currently found
in the literature for an important subset of problems. The cases of homogeneous and non-
homogenous two term recursion are treated. Applications to three problems (ﬁnding the
eigenvalues of a tri-diagonal matrix, the solution of a radial wave equation and the solution
of a tri-diagonal matrix) are discussed.

3
0
0
2
 
c
e
D
 
3
2
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
9
3
1
2
1
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

1

1 Introduction

The solution of some problems require more total computation to implement an appropriate
parallel algorithm than one that would be used in a strictly serial calculation. A gain in speed
can still be expected by running them on a parallel machine but there is a cost factor such
that one can not expect to achieve an increase in speed equal to the number of processors
when compared with the best non-parallel algorithm.

As an example, consider two term iteration.

xi+1 = aixi + bixi−1 i = 1, 2, . . . N

(1)

One method suggested in the literature[1] is to replace the steps in the algorithm by
matrix multiplication. This algorithm requires extra operations which will be discussed
further at the end of section 2.1

Another possible algorithm (the one considered here) is based on the fact that there are
only two independent solutions to Eq. 1. The proper linear combination of them to represent
the actual solution can be determined by the starting values. In this paper the application
of such an algorithm for Eq. 1, as well as a similar one for the iteration when there is an
additional term, ci, on the right hand side, is discussed.

2 General Description of the Algorithm

2.1 Homogeneous Case

A recursion relation, such as Eq. 1, can be viewed as one long sequence of values which
leads from a beginning pair of values to the end. A desirable procedure for a parallel system
would be to cut up this sequence into separate strips (as many as there are processors) and
let each processor work through its part independently. For the ﬁrst processor there is no
problem since the starting values are known there. But the second processor (and the rest)
will not have available their starting values (the ﬁnal values in the previous processor) so this
procedure doesn’t seem possible. With a little expense, however, it can be done. Since there
are only two independent solutions of Eq. 1 we can construct two (arbitrary but independent)
solutions, which will provide basis functions, and combine them when the starting values for
each processor are known from the result of the previous one. For simplicity, consider the
same algorithm running on all processors ignoring the fact that it could be computed more
eﬃciently on the ﬁrst processor.

Let the total length of the recursion relation be N + 2 with M processors. Each processor
will be assigned a recursion of length L = N/M which is supposed to be integer and large.
In order to see how such an algorithm works, let us analyze a (very modest) system of 32
recursion steps to be calculated with 4 processors.

2

(2)

(3)

(4)

(5)

Each processor will do the recursion twice, once with starting values 0 and 1 and once
with values 1 and 0. That is, each processor calculates the two basis function starting with
the ﬁrst two values (1,0) and (0,1). It uses the appropriate values of ai and bi for its position
in the global sequence, of course. For the ﬁrst processor the basis functions start with

0 = 1; y10
y10

1 = 0; and y01

0 = 0; y01

1 = 1.

Since any solution of the recursive formula can be written as a linear combination of the

two basis functions

we can see from the deﬁnition of the initial values in the ﬁrst processor that

xi = αy10

i + βy01
i ,

x0 = α; x1 = β,

where x0 and x1 are the starting values for Eq. 1. We could ﬁnd all of the values of the
function in the ﬁrst processor by calculating

xi = x0y10

i + x1y01
i

First Processor i = 0, 1, . . . , 8, 9

but it is better not to do that immediately. Since each value is independent, we may calculate
only the last two values if we wish. These would be, in this simple case, x8 and x9. Notice
that these are the starting values for the second processor. Thus, for the second processor
since it started with y10
9 = 1 choosing the proper linear
combination (α and β) to give the true values of x8 and x9 (known from the ﬁrst processor)
again we could calculate all of the values

9 = 0 and y01

8 = 0; y01

8 = 1; y10

xi = x8y10

i + x9y01
i

Second Processor i = 8, 9, . . . , 16, 17.

(6)

Again, we need calculate only the last two (x16 and x17) to get the starting values for the
third processor. From these we obtain the last values in the third processor x24 and x25 and
the fourth processor x32 and x33. Thus, we have found the last two values of the sequence
with the evaluation (after the parallel computations) of 8 equations. For 4 processors there
will always be 8 equations regardless of the length of iteration, L, within each processor.

The table below gives the operations explicitly for this small example. In this case each
processor has only 8 recursions to do. In a more practical example numbers more like 106
might be expected. The table lists the initial conditions at the top followed by the iterations.
The generic variable, y, indicates both y01 and y10 are to be calculated.

3

Processor 0
y01
0 = 0; y01
1 = 1
0 = 1; y10
y10
1 = 0
y2 = a1y1 + b1y0
y3 = a2y2 + b2y1
· · ·
· · ·
· · ·

Processor 1
y01
8 = 0; y01
9 = 1
8 = 1; y10
y10
9 = 0
y10 = a9y9 + b9y8
y11 = a10y10 + b10y9
· · ·
· · ·
· · ·

Processor 2
y01
16 = 0; y01
16 = 1; y10
y10

17 = 1
17 = 0

Processor 3
y01
24 = 0; y01
24 = 1; y10
y10

25 = 1
25 = 0

y18 = a17y17 + b17y16 y26 = a25y25 + b25y24
y19 = a18y18 + b18y17 y27 = a26y26 + b26y25

· · ·
· · ·
· · ·

· · ·
· · ·
· · ·

y7 = a6y6 + b6y5 y15 = a14y14 + b14y13 y23 = a22y22 + b22y21 y31 = a30y30 + b30y29
y8 = a7y7 + b7y6 y16 = a15y15 + b15y14 y24 = a23y23 + b23y22 y32 = a31y31 + b31y30
y9 = a8y8 + b8y7 y17 = a16y16 + b16y15 y25 = a24y24 + b24y23 y33 = a32y32 + b32y31

After this work has been done the following sequential steps need to be taken using only

the last two values taken from each processor.

8 + x1y01
16 + x9y01
24 + x17y01
32 + x25y01
The absolute indices have been used above on the basis functions.

8 ; x9 = x0y10
16; x17 = x8y10
24; x25 = x16y10
32; x33 = x24y10

x8 = x0y10
x16 = x8y10
x24 = x16y10
x32 = x24y10

9 + x1y01
9
17 + x9y01
17
25 + x17y01
25
33 + x25y01
33

It is often more
convenient to use a combination of the local index and the processor number. The local
index will be denoted by λ and runs from 0 to L + 1.

In general, only two values in any processor need be computed to ﬁnd the starting values
and hence the coeﬃcients of the two basis functions for the next processor. So the serial
overhead is only twice 3 ﬂoating point operations per processor. Even if all of the values
of the sequence are needed, it is better to do this operation ﬁrst, because the intermediate
values can then be found in parallel using the starting values obtained in this way.

Repeating the above argument for the general case with M processors labeled µ =
0, 1, 2, . . . , M − 1 and N + 2 total values of the indices of xi, the resulting sequences are
calculated in a (long) parallel calculation,

µy10
λ

and µy01
λ ;

λ = 2, 3, . . . , L + 1;

[µ = 0, 1, . . . , M − 1].

(7)

The square brackets indicate that the calculations for the diﬀerent values of µ are done in
parallel. After this step, the equations

x(µ+1)L = xµL
x(µ+1)L+1 = xµL

µy10

L + xµL+1
µy10

µy01
L
L+1 + xµL+1

µy01

(

L+1 )µ=0,1,...,M −1

(8)

4

n N = 2n Sequential m = 2 m = 3 m = 4 m = 5 m = 6
128
30
7
256
42
8
512
66
9
1024
114
10
2048
210
11
4096
402
12
8192
786
13
16384
1554
14
32768
3090
15
65536
6162
16
131072
12306
17
24594
262144
18
49170
19
524288
98322
20 1048576

39
60
105
198
384
63
108
201
390
768
111
204
393
774
1536
207
396
777
1542
3072
399
780
1545
3078
6144
783
1548
3081
6150
12288
1551
3084
6153
12294
24576
3087
6156
12297
24582
49152
6159
12300
24585
49158
98304
12303
24588
49161
98310
196608
24591
49164
98313
196614
393216
49167
393222 196617
98316
786432
1572864
98319
786438 393225 196620
3145728 1572870 786441 393228 196623

Figure 1: Strip iteration algorithm. Columns 3 through 9 give the number of ﬂoating point
operation times until completion of the iteration algorithm. Column 3 gives the number for
straight iteration in one processor. The number of iterations is N = 2n with a number of
processors M = 2m. This “power of two” representation is only for simplicity and is not
needed for the algorithm.

are evaluated in a (short) sequential calculation. The number of equations is always twice
the number of processors. The values of x have been written with absolute indices but we
may use a notation for individual processors. The pre-superscript µ as used above denotes
results from a given processor µ so we could write equally valid representations of x as

In matrix notation we may write Eqs. 8 as

xµL+λ =µ xλ.

µ+1x0
µ+1x1 !

=

 

µy10
L
µy10

L+1

 

µy01
L
µy01
L+1 !  

µx0
µx1 !µ=0,1,...,M −1

(9)

(10)

Figure 1 shows the number of ﬂoating point times to be expected with various recursion
lengths and number of processors. The increase in speed over scalar is M/2 for large N. If
only the end value of the sequence is needed one can stop at this point (the “short form” of
the algorithm). This factor of two cost is not the best that can be obtained if the values of
ai and bi are being calculated along with the iteration. The same values of these coeﬃcients
are used in each iteration and, if the time for the calculation of the coeﬃcients is signiﬁcant,

5

the overhead to calculate two iterations rather than one (as would happen if the calculation
were not in parallel) may be small.

At this point (if needed) one can proceed to calculate the entire sequence of values in a

second parallel calculation (the “long form” of the algorithm). These will be given by

µxλ = xµL+λ = xµL

µy10

λ + xµL+1

µy01
λ ;

λ = 2, 3, . . . , L + 1;

[µ = 0, 1, . . . , M − 1]

(11)

These evaluations come at the cost of an additional 3L ﬂoating point operations per
processor, roughly a cost factor of 4 i.e., the speed increase is M/4 compared to the pure
sequential algorithm. This cost can be reduced greatly in certain cases as we shall see later.
It may be useful to leave the strip functions (or even the strip basis functions) in the processor
where they were calculated.

We can now compare with the matrix algorithm mentioned in the introduction. If we

deﬁne

then

yi =

xi+1
xi !

 

; αi =

ai
1

 

bi
0 !

,

yi =

xi+1
xi !

=

 

ai
1

 

bi
0 !  

xi
xi−1 !

= αiyi−1

xN +1
xN !

 

= yN = αN αN −1αN −2 · · · α1

x1
x0 !

 

and the end member of the sequence is given by

(12)

(13)

(14)

The multiplication of matrices can be done pairwise on diﬀerent processors. The ﬁrst
multiplication of the simple matrices can be done with two multiplications and one addition
but this operation generates full two by two matrices so that the second step in the pairwise
reduction of the multi-factor product is a complete matrix multiplication and requires 8
multiplications and 4 additions. When compared with the 2 multiplications and 1 addition
necessary to actually do the iteration, one sees that there is a cost of a factor of 4 which
is paid in this case. Assuming 12 operations for all steps the maximum speed up with M
processors is M/4. The matrix algorithm gives only the end point of the sequence so is to be
compared with M/2 from the algorithm just presented. With a modest number of processors,
over half of the time of the matrix algorithm is spent in the ﬁrst set of multiplications so that
considerable savings can be achieved by considering the special case for the ﬁrst operation.
This cost factor is not the only problem. The work done in each matrix multiplication
is not very much (12 ﬂoating point operations). Hence, communication must take place
between processors very often so that message passing time may dominate.

Another possible problem is that often the entire sequence of xi is needed. This algorithm

simply doesn’t give it.

6

2.2

Inhomogeneous Recursion Relation

For the inhomogeneous recursion

xi+1 = aixi + bixi−1 + ci

3 basis solutions are needed to provide a general representation. For the third basis function
we can take z00
µL+1 = 0. The general form
i
of the solution is thus

, deﬁned to have the starting conditions z00

µL = z00

xi = αz10

i + βz01

i + γz00
i

where z10
i
the recursion relation is α + β + γ = 1.

, and z00

, z01
i

i all separately satisfy Eq. 15. The requirement that this form satisﬁes

Using this last expression to replace γ we can write

xi = α(z10

i − z00

i ) + β(z01

i − z00

i ) + z00
i

.

It is easy to show that

i ≡ z10
y10

i − z00
i

and y01

i ≡ z01

i − z00
i

satisfy the homogeneous equation (i.e. with ci = 0) with the same starting points as the z10
i
and z01
, exactly as in the homogeneous case treated before. Thus, the general form can be
i
written as

where y10

i + z00
i
i can be calculated as in the previous section, i.e. without reference to ci.
λ or

The procedure in this case is ﬁrst to calculate in parallel (either along with the µyij

i and y01

i + βy01

xi = αy10

(19)

separately) the (long) recursion

µz00

λ+1 = aµL+λ

µz00

λ + bµL+λ

µz00

λ−1 + cµL+λ;

λ = 1, 2, 3, . . . , L;

[µ = 0, 1, . . . , M − 1]. (20)

Since both starting values of µz00
again just the last values from the previous processor so that the equations

λ are zero, the values of the coeﬃcients of y10

i and y01

i are

x(µ+1)L = xµL
x(µ+1)L+1 = xµL

µy10

L + xµL+1
µy10

µy01
L+1 + xµL+1

L +µz00
L
µy01

L+1 +µz00

(

L+1 )µ=0,1,...,M −2

or in processor notation,

(µ+1)x0 =µ x0
(µ+1)x1 =µ x0

µy10
µy10

L +µx1
L+1 +µx1

µy01

L +µz00
L
L+1 +µz00
µy01

(

L+1 )µ=0,1,...,M −2

need to be evaluated in a (short) sequential calculation.

7

(15)

(16)

(17)

(18)

(21)

(22)

If needed, the intermediate values in the recursive sequence can now be evaluated in

parallel. These will be given by

xµL+λ = xµL

µy10

λ + xµL+1

µy01

λ +µz00
λ ;

λ = 2, 3, . . . , L + 1;

[µ = 0, 1, . . . , M − 1]

(23)

or

µxλ =µx0

µy10

λ +µx1

µy01

λ +µz00
λ ;

λ = 2, 3, . . . , L + 1;

[µ = 0, 1, . . . , M − 1]

(24)

If the recursion relation is needed for a large number of functions, ci, with the same ai

and bi, then the basis functions y10 and y01 need be calculated only once.

3 Applications

3.1 Eigenvalues of a tri-diagonal matrix

The process of ﬁnding eigenvalues of a real tri-diagonal matrix plays a central role in the
solution of the eigenvalue problem of more general real symmetric matrices. Commonly,
algorithms are converted to a parallel environment either by having each processor search
for an eigenvalue (method A) [2] or ﬁnding all of the eigenvalues by means of divide and
conquer algorithms (method B) [3]. It is often useful be able to pick out only a few of the
eigenvalues (the lowest ones) which is the case considered here.

For a symmetric tri-diagonal matrix

a1
b1
b1 a2
0

0
b2
b2 a3



0 . . .
0
0 . . .
0
b3 0 . . .
. . .
. . . bN −2 aN −1
bN −1
. . .
0
. . .
0
0

A =













there exists a well-known solution for eigenvalues (see, for example, Refs.
[4, 2]) based on
Sturm sequences with bisection which allows the selection of eigenvalues. With the deﬁnition

0
bN
aN +1

bN −1
aN
bN














(25)



the recursion relation

x0 = 1; x1 = a1 − Λ

xi+1 = (ai+1 − Λ)xi − b2

i xi−1

(26)

(27)

generates the determinant, D(Λ), of A − ΛI as the value of xN +1. The eigenvalues of A
can be found by locating the zeros of D(Λ). Furthermore, the number of sign diﬀerences

8

between successive members in the recursion sequence identiﬁes the eigenvalues in order.
For example, the lowest eigenvalue occurs at the transition from 0 to 1 sign diﬀerences in
the sequence. The desired transition (and hence eigenvalue) can be found with Newton’s
method of bisecting some Λmin and Λmax at each step.

Implementing this recursion in a parallel fashion is straightforward using the algorithm
given in Section 2.1.
In order to calculate the number of sign diﬀerences, the individual
members of the sequence need to be generated which requires the long form of the algorithm,
thus seeming to cost a factor of 4 compared to a non-parallelized version. However, a hybrid
method makes the cost factor closer to 2 than 4. When the diﬀerence in sign count has been
reduced to unity between Λmin and Λmax it is known that a single eigenvalue lies in this
region and that it is the correct one. From this point on, the method needs only the ﬁnal
value of the sequence (the determinant itself) which requires only half the time.

Hence, the algorithm can be thought of as proceeding in two phases. In the ﬁrst phase
the desired eigenvalue is isolated by ﬁnding two values of the estimated eigenvalue with only
a single zero of the determinant between them. After that, in the second phase, only the
value of the determinant is needed and with those values one can estimate a new trial value
more eﬃciently than a simple bisection by using

Λ =

Λmin|D(Λmax)| + Λmax|D(Λmin)|
|D(Λmax)| + |D(Λmin)|

.

(28)

One must be careful of the convergence since it may come about with the trial eigenvalue
approaching one of the limit eigenvalues without the two limits approaching each other. This
improvement in eﬃciency is available to either the parallel or non-parallel version and tends
to make the ﬁrst phase dominant in time consumed.

A common method of implementing this general algorithm on parallel computers is to
simply give each processor an eigenvalue to ﬁnd (method A above). In this case each eigen-
value is obtained in a purely sequential fashion but the values arrive in a parallel manner.
In the present algorithm each eigenvalue is calculated in a parallel manner and the values
arrive one after the other. One improvement which is not generally available to method A
is due to the availability of useful information after the ﬁrst and subsequent eigenvalues are
found in the ﬁrst phase. It is only necessary to keep a table of the tested values of Λ vs.
the corresponding number of sign diﬀerences. When the next eigenvalue is to be found, the
table can be searched for the closest starting values. This table grows as the eigenvalues
are found. If each processor is ﬁnding an eigenvalue starting from the outer bounds of the
eigenvalue sequence this advantage is not available.

An important consideration in this algorithm (parallel or non-parallel) is the growing of
the values with each step so that overﬂow occurs. One can solve that problem by performing
a renormalization at regular intervals. In the non-parallel version, when the value of xi+1
is observed to exceed some predeﬁned value then both xi+1 and xi are multiplied by an

9

appropriate constant reducing factor. This does not change the number of relative sign
diﬀerences nor the sign of the last value. For the parallel version both basis functions can
be renormalized in the same way (both must be done at the same time) and the recursion is
not destroyed since it is only the relative values of the basis functions which determines the
number of sign diﬀerences and the sign of the ﬁnal value. In the version tested here a check
for renormalization was made every 16 steps.

The algorithm was calculated for the matrix deﬁned by

ai = 0, i = 1, 2, . . . N + 1; b2

i = i(N + 1 − i),

i = 1, 2, . . . N

(29)

with N even. The eigenvalues are known to be the even integers from –N to N[2, 5]. In
addition to the renormalization mentioned above, the entire system was renormalized such
that the smallest b2
i was unity. Calculations were made for matrices of size up to N =
10, 240, 000 ﬁnding eigenvalues to an accuracy of 1 part in 1011. The method was tested on
a Beowulf cluster with a 100 Mbit Ethernet (using MPICH[6, 7]) and the scaling eﬃciency
[deﬁned as T1/(MTM ) where TM is the time for execution on M processors] exceeded 0.96
up through 4 processors.

The “cost” of the method was calculated by comparing one-processor versions of the
present algorithm with a simple sequential calculation but with the present algorithm taking
advantage of the information contained in the table of the number of sign diﬀerences vs. trial
Λ. For a single eigenvalue the present method takes about 2.5 times longer than method A.
For 5 eigenvalues it still takes about 20% longer. For 10 eigenvalues it is 0.85 as long, for 20
it is 0.72 as long and for 40 it requires 0.64 of the time for method A.

Procedure A also may suﬀer from an incommensurability with the number of processors.
If one wishes 8 eigenvalues with 64 nodes then only 1/8 of the capacity of the machine is
being used. The calculation of the relative eﬃciency of the methods can be quite complicated,
however. For example, if one wishes 16 eigenvalues with 8 processors then two passes will be
made with method A and in the second pass tables of values accumulated in the ﬁrst pass
can be used. Incorporating this information could well make method A faster.

3.2 Solving wave equations

Wave equations (the Schr¨odinger equation is considered here) can be solved, after an expan-
sion in Legendre polynomials, by means of one-dimensional second order diﬀerential equa-
tions. An accurate solution can be obtained with Noumerov’s method where the iteration
equations for the reduced wave function are given by

2ψi − ψi−1 − h2

ψi+1 =

12 [10wiψi + wi−1ψi−1]
1 + h2

12 wi+1

,

(30)

where

10

w(r) = k2 −

2m
¯h2 V (r) −

ℓ(ℓ + 1)
r2

,

(31)

and h is the spacing in the radial variable r.

This form is converted readily into that considered in Section 2.1 with much of the
work of the computation of ai and bi being done before the iteration. Keeping k2 as a free
parameter and precomputing one vector {1 − h2[ 2m
]} the calculation of ai and
bi requires seven ﬂoating point operations. Given that each iteration requires an additional
three operations, we might expect that the parallel algorithm involves a cost of an increase
from ten to thirteen operations or about 30% over the purely sequential one.

¯h2 V (r) + ℓ(ℓ+1)
r2

In the present case the Schr¨odinger equation is solved for a bound state. The solution is
started at the origin with zero for the ﬁrst point and an arbitrary value for the second point
and a search is made for a value of the energy (expressed here as k2 = 2mE/¯h2) that causes
the wave function at some large value of r to be zero.

The problem was treated with a near maximum precomputation of the values of ai and
bi. Clearly, if one chooses not to compute as much as possible in advance, and hence to
spend a larger amount of time in the computation of the coeﬃcients, then the addition of
a second iteration (the expense of this algorithm) would make less diﬀerence. Thus, a true
test of the algorithm relies on a realistic degree of precomputation.

The calculation was coded and tested for ℓ = 2. The number of steps taken was 25.2×106.
Because of the boundary conditions of the problem (reduced wave function zero at the origin)
the calculation of the basis function y10 is not needed in the ﬁrst processor. By comparing
a one-processor calculation with it computed or not it was found that the cost factor of the
algorithm was 1.31, in agreement with the 30% increase estimated above. The method was
tested on the Beowulf cluster and no decrease in eﬃciency was seen through 16 processors.

3.3 Tri-diagonal Matrix Solution

Consider the recursive solution to a tri-diagonal matrix (size N + 2), at ﬁrst without any
parallelism.

11











c0
c1
c2
. . .
. . .
. . .
cN −1
cN
cN +1

x0
x1
x2
. . .
. . .
. . .
xN −1
xN
xN +1

a0
e0
0
b1 a1 e1
0



0 . . .
0
0 . . .
0
b2 a2 e2 0 . . .
. . .
. . .
. . .
. . .
. . .
. . .

=

0
0

(32)

0
eN






















































































bN −1 aN −1 eN −1
aN
bN
bN +1 aN +1
0

















If any ei (let the ﬁrst occurrence be at i = k) is zero then the system can be reduced to
two subsystems. To see this observe that the ﬁrst equation alone consists of one equation
in two unknowns, the ﬁrst two equations two equations in three unknowns, etc. If ek = 0
then introducing that equation introduces no new unknown so the system of the ﬁrst k + 1
equations can be solved alone giving the value (among others) of xk.
In the remaining
equations the kth column can be taken to the right hand side so that they can be solved. In
this case the system is separable. For a symmetric system, if ek = 0 then bk+1 = 0 also and
the two blocks are completely decoupled. Here it is assumed that this is NOT the case so
that NO ei = 0. Thus, we can divide all equations by ei or, equivalently, we can set ei = 1
in the system we wish to consider. Of course, the conversion of a general system to this
form entails the cost of one inverse and two multiplications per equation on the left hand
but needs to be done only once in the case of a number of diﬀerent right hand sides (N + 1
more multiplications are necessary for each right hand side).
For these reasons, the following system is considered.

a0
1
b1 a1
0

0
1

0 0 . . .
0 0 . . .
b2 a2 1 0 . . .
. . .
. . .
. . .
. . .
. . .
. . .




















x0
x1
x2
. . .
. . .
. . .
xN −1
xN
xN +1


























































c0
c1
c2
. . .
. . .
. . .
cN −1
cN
cN +1







































=

(33)

Starting from the second row the equations can be expressed as the recursion relation

xi+1 = −aixi − bixi−1 + ci; i = 1, 2, 3, . . . , N − 1, N,

(34)

bN −1 aN −1

0
0

bN
0

0
1

1
aN
bN +1 aN +1

12

where neither the ﬁrst or last equations have been used.

The three basis solutions discussed in Section 2.2 (called here f 10

i ) can be used
to provide “global” basis functions (global in the sense that they represent the full recursion
sequence to be distinguished from the strip functions to be discussed shortly) to express the
solution. The ﬁrst two basis solutions do not involve ci and need only be calculated once for
many right hand sides. Thus, the solution separates into two parts, somewhat similar to the
common factorization and back substitution methods. Once we have the basis solutions we
can apply the conditions implied by the ﬁrst and last equation to determine the coeﬃcients
α and β in Eq. 19. For the ﬁrst equation we have

i and g00

, f 01

i

a0x0 + x1 = a0(αf 10

0 + βf 01

0 + g00

0 ) + αf 10

1 + βf 01

1 + g00

1 = c0

From the last equation we have

a0α + β = c0.

aN +1xN +1 + bN +1xN = aN +1(αf 10

N +1 + βf 01

n+1 + g00

N +1) + bN +1(αf 10

N + βf 01

N + g00

N ) = cN +1 (37)

α(aN +1f 10

N +1 + bN +1f 10

N ) + β(aN +1f 01

N +1 + bN +1f 01

N ) = cN +1 − aN +1g00

N +1 − bN +1g00
N

(38)

From these two equations we obtain α and β and all values of xi can be obtained from

As an alternative to Eq. 38 one can iterate one further step with Eq 34 to obtain

N +2, f 01
f 10

N +2 and g00

N +2 and use the condition that xN +2 = 0 to ﬁnd

αf 10

N +2 + βf 01

N +2 = −g00

N +2.

Returning to the parallel considerations, we can express the global basis functions in
terms of the strip basis solutions in each processor, obtain the three global functions that
were used in the above algorithm and then calculate the solution. However, it is much more
eﬃcient to combine the two operations.

First write the global recursion basis functions in terms of the strip basis functions.

or

or

Eq. 19.

(42)
where the µα and µβ are to be obtained from the matching conditions for µ = 1, 2, . . . , M −1.

µL+λ = µα00 µy10
g00

µL+λ = µα10 µy10
f 10

λ +µβ10 µy01
λ

µL+λ = µα01 µy10
f 01

λ +µβ01 µy01
λ
λ +µz00
λ

λ +µβ00 µy01

µα10 = µ−1α10 µ−1y10

L +µ−1β10 µ−1y01

L

13

(35)

(36)

(39)

(40)

(41)

(43)

µβ10 = µ−1α10 µ−1y10
µα01 = µ−1α01 µ−1y10
µβ01 = µ−1α01 µ−1y10

L+1 +µ−1β10 µ−1y01
L +µ−1β01 µ−1y01
L+1 +µ−1β01 µ−1y01

L

L+1

L+1

µα00 = µ−1α00 µ−1y10

µβ00 = µ−1α00 µ−1y10

L +µ−1β00 µ−1y01
L+1 +µ−1β00 µ−1y01

L +µ−1 z00
L+1 +µ−1z00

L

L+1

with the starting values

0α10 = 1; 0α01 = 0; 0β10 = 0; 0β01 = 1; 0α00 = 0β00 = 0.

Using the last two values of the global basis functions calculated from Eq. 40-42 we can
solve for the global α and β (from Eq. 36 and 38) to write

xµL+λ =µ α µy10

λ +µβ µy01
where the coeﬃcients are given by

λ +µz00

λ ; λ = 2, 3, . . . , L + 1 [µ = 0, 1, . . . , M − 1]

(50)

µα = α µα10 + β µα01 +µα00

µβ = α µβ10 + β µβ01 +µβ00

It is common to compare the relative speed of any algorithm for solving tri-diagonal
matrices with Gaussian Elimination (GE) which is relatively eﬃcient. For this case GE
becomes, ﬁrst for the LU reduction

d0 = 1/a0

gi = bidi−1; di = 1/(ai − gi)

i = 1, 2, . . . , N + 1,

followed by the two back substitutions

zg
0 = c0; zg

i = ci − gizg

i−1;

i = 1, 2, . . . , N + 1,

and

xg
N +1 = zg

N +1; xg

i = (zg

i − xg

i+1)di;

i = N, N − 1, . . . , 0.

If we assume that the equations are being solved for many right hand sides, then we
should compare the time for the solutions of the z00 equations and the calculation of the
vector (Eqs. 20 and 50) with the work of the two back substitutions in GE (Eqs. 54 and
55). A ﬁrst estimation can be made for the relative speed by counting the number of ﬂoating
point operations per step (4 for GE and 8 for the parallel algorithm) to get a cost factor of 2.
This is only a very crude estimate since the form of the equations is diﬀerent. For example,
Eq. 50 requires only the broadcast of a scalar instead of vector multiplication. Optimization

14

(44)

(45)

(46)

(47)

(48)

(49)

(51)

(52)

(53)

(54)

(55)

or not of the G77 compiler was observed to make a large diﬀerence also. With no optimizing
GE does better than this estimate giving a cost factor of 2.6. However, with optimization,
the eﬃciency of the parallel method is improved more than GE to result in a cost factor of
1.4.

To save on message passing for the resultant vector, one may want to use the strips in
the processor in which they were formed. In some cases it may be more eﬃcient never to
construct the vectors at all. As an example of such a case, consider the problem of solving the
set of equations for a large number of diﬀerent right hand side vectors which are a function
of some parameter, η, hence, ci(η). Suppose also that we wish the sum (an integral perhaps)
of some weighting function over the solution

N +1

S(η) =

wixi(η)

(56)

Xi=0
as a function of η. The sum can be distributed among the strip basis functions in the
processors via Eq. 50. The y basis function integrals need be calculated only once. The
z00 integral can be calculated as this basis function is generated. Only the strip integrals
need to be sent to the master processor to be combined with the coeﬃcients µα and µβ. The
calculation of the solution (Eq. 50) is not needed. In this special case, a count of the number
of ﬂoating point operations estimates the speed to be the same as GE (in the limit of large
N and large number of values of η). In one-processor tests, because of the simplicity of the
equations mentioned above, the strip algorithm was found to run somewhat faster than GE.
Large systems (720, 720 × k with k = 10, 20, 40, 80, and 160) with 100 values of η
were tested on the Beowulf cluster. Essentially no degradation of performance was seen with
all eﬃciencies ≥ 0.99. The largest system tested (N = 115, 315, 200) could only be run by
spreading the solution basis vectors over 13 processors.

A common algorithm discussed in the literature is the parallel cyclic reduction of a
matrix[8]. The basic cost of this algorithm has been reported to be a factor of 4 [9, 10]. It
requires frequent exchange of information and is not very eﬃcient for multiple right hand
sides. The “divide and conquer” method [8] is also ineﬃcient for multiple driving terms.
Hence, the technique presented here would seem to oﬀer an attractive alternative to these
methods in some cases.

The restriction to ei 6= 0 may prove to be inconvenient in some cases or the division may
lead to large errors. Tests with ei ≡ 1 showed that the stability of the method was as good
or better than GE.

4 Discussion

These algorithms may also be useful on vector machines. For a processor with a 64 word
vector register, for the case of the homogeneous recursion relation, the total length can be

15

broken into 32 strips with each pair of words in the vector register acting as a processor.
Thus, the iteration might take place as

y10
i+1
y01
i+1
y10
L+i+1
y01
L+i+1
. . .
. . .

y10
µL+i+1
y01
µL+i+1
. . .
. . .

y10
31L+i+1
y01
31L+i+1























































ai
ai
aL+i
aL+i
. . .
. . .
aµL+i
aµL+i
. . .
. . .
a31L+i
a31L+i























































y10
i
y01
i
y10
L+i
y01
L+i
. . .
. . .
y10
µL+i
y01
µL+i
. . .
. . .

y10
31L+i
y01
31L+i























































bi
bi
bL+i
bL+i
. . .
. . .
bµL+i
bµL+i
. . .
. . .
b31L+i
b31L+i























































y10
i−1
y01
i−1
y10
L+i−1
y01
L+i−1
. . .
. . .

y10
µL+i−1
y01
µL+i−1
. . .
. . .

y10
31L+i−1
y01
31L+i−1























































=

×

+

×

(57)

for i = 1, 2, . . . L.

The method can be generalized for a larger number of terms in the iteration (leading to

larger width in banded matrices, for example).

There are clearly some limitations to the application of the algorithm. The conversion to
a parallel system does not work for recursions non linear in xi so most classical mechanics
calculations are not possible with it.

I wish to thank Slava Solomatov for discussions and Alexei Vezolainen for help with
one of Beowulf clusters in the Dept. of Physics. This work was supported by the National
Science Foundation under contract PHY-0099729.

References

ford (1988)

[1] Jagdish J. Modi, “Parallel Algorithms and Matrix Computation”, Claredon Press, Ox-

[2] A. Basermann and P. Weidner, A parallel algorithm for determining all eigenvalues of
large real symmetric tridiagonal matrices, Parallel Computing 18(1992) 1129-1141

[3] F. Tisseur and J. Dongarra, A parallel divide and conquer algorithm for the symmetric
eigenvalue problem on distributed memory architectures, SIAM J. Sci Comput. 20,
(1999) 2223-2236

16

[4] W. R. Gibbs, “Computation in Modern Physics”, World Scientiﬁc Publishing, Singapore

(1999)

[5] R. T. Gregory and D. L. Karney, A Collection of Matrices for Testing Computational

Algorithms (Krieger Publ. Huntington, NY, 1978

[6] W. Gropp, E. Lusk, N. Doss and A. Skjellum, Parallel Computing, 22, 789(1996)

[7] William D. Gropp and Ewing Lusk, “User’s Guide for mpich, a Portable Implementation

of MPI”, ANL-96/6, 1996

[8] Duc Thai Nguyen, “Parallel-Vector Equation Solvers for Finite Element Engineering

Applications”, Kluwer Academic/Plenum Publishers, (2002)

[9] I. N. Hajj and S. Skelboe, A multilevel parallel solver for block tridiagonal and banded

linear systems, Parallel Computing, 15 (1989) 21-45

[10] F. Reale, A tridiagonal solver for massively parallel computer systems, Parallel Com-

puting, 16, (1990) 361-368

17

