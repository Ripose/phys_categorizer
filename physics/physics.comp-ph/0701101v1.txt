7
0
0
2
 
n
a
J
 
9
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
1
0
1
1
0
7
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

JOB SUBMISSION ON
GRID

An Users Introduction

Rudra Banerjee

ADVANCED COMPUTING LAB.
Dept. of Physics, University of Pune

February 20, 2014

Abstract

This is an user’s introduction to grid using Globus®Toolkit from
an user’s point of view. With a brief introduction to what grid is,
In this part, i have done
I have shifted quickly to the game itself.
an step by step introduction, starting from the access to the grid to
submitting the job.

In the appendix, a special note is there on using GARUDA grid.
Hope this will be of help for the users.

1 The Garuda Grid

1.1 What is Grid???

A computational Grid is an aggregation of heterogeneous and geo-
graphically distributed resources such as computing, storage and spe-
cial equipments. The aim of the grid is to dynamically share resources
to facilitate optimal utilization. Grid allows us to solve complex prob-
lems that could not be dealt with otherwise. It provides high-speed
and seamless access to supercomputers and also enables creation and
management of dynamic virtual collaborations and organizations

Leading scientist is this ﬁeld, Dr. I. Foster has given Three Point

Checklist in this purpose :

A Grid is a system that

ˆ coordinates resources that are not subject to central-

ized control

Integrates and coordinates diﬀerent resources and users that

live in diﬀerent control domain

ˆ using standard, open, general-purpose protocols

Protocols such as authentication, authorization and access

should be open and standard and open. Otherwise the sys-

tem is application speciﬁc.and

ˆ interfaces to deliver nontrivial qualities of service

Should deliver various quality of service in a coordinated

1

way so that the utility of the system is signiﬁcantly greater

then the sum of its part.

and is accepted as present standard.

1.2 Garuda Grid

GARUDA is a collaboration of science researchers and experimenters
on a nation wide grid of computational nodes, mass storage and sci-
entiﬁc instruments that aims to provide the technological advances
required to enable data and compute intensive science for the 21st
century.

GARUDA aims at strengthening and advancing scientiﬁc and tech-
nological excellence in the area of Grid and Peer-to-Peer technologies.
To achieve its objective, GARUDA brings together a critical mass of
well-established researchers, from 48 research laboratories and aca-
demic institutions, who have constructed an ambitious program of ac-
tivities. (35 Research and Academic Institutions, 11 C-DAC centers
and ERNET, Delhi). Right now four nodes of this Grid are working-
Pune, Bangalore, Chennai and Hyderabad center of C-DAC. To pro-
vide high performance computing facilities and services for the sci-
entiﬁc and research community and for the enterprise, C-DAC had
earlier set up the National PARAM Supercomputing Facility (NPSF)
at Pune, housing its PARAM 10000 supercomputer with a peak com-
puting power of 10 Gﬂops. In its continuing eﬀort in this direction,
C-DAC has established Center for Tera-scale Supercomputing Facility
(CTSF) at its C-DAC Knowledge Park, Bangalore with the PARAM
Padma machine in its Tera-scale conﬁguration. The PARAM Padma
at CTSF has a peak computing power of one Tera-ﬂop.

In this four center, not all of the machines are equivalent. Like
Pune is Linux cluster, on the other hand B’lore has Linux, AIX and
Solaris. There main capacities and IP are given in the table:

2

GARUDA GRID IN BRIEF

place

Pune

B’lore

resource

number

IP

Linux Cluster

16+head node

xn00.npsf.cdac.ernet.in

Linux (Xeon) Cluster
AIX Cluster
Solaris Cluster

5 nodes(10 CPU)

xn02.ctsf.cdac.org.in
tf34.ctsf.cdac.org.in
e1.ctsf.cdac.org.in

H’bad

Linux Cluster

5 nodes(10 CPU)

hyd01.hardware.cdac.ernet.in

Chennai

Linux Cluster

che01.hardware.cdac.ernet.in

2 Prerequisites

2.1 Getting Permission

First thing ﬁrst. To submit job in a grid you must have to have a
login and fully working account in the grid-client’s node. Next thing
is you must have the pass phrase for the grid-proxy to submit jobs in
grid. Once you submit grid-proxy-init you will get the access of the
grid, for 1 day (24 hr)by default. It is advisable to get a tentative idea
about the running time of your job and if it is more then 1 day, ask
permission for longer period. Some often used option of grid-proxy-init
are given below:
Syntax: grid-proxy-init [-help][-pwstdin][-limited][-hours H]
...

Options
-help, -usage Displays usage
-verify
-pwstdin
-hours H

Veriﬁes certiﬁcate to make proxy for
Allows passphrase from stdin
Proxy is valid for H hours (default:12)

2.2 Do You Have the Right BINARY File?

Given that the resource is varied, it is assumed that the user should
have a matching binary. For example, if your binary is compiled on

3

Figure 1: Grid resources: screen-shot

Intel machine, it is most suitable for Xeons; but it is likely that it
may not run on Solaris, as the Fortarn90 compiler of Solaris is not
dependable at all1 .

Now few more things you should remember.

If you are using a

1I ll advice to avoid f90 jobs in Solaris as the fortran 90 compiler (CF90)of this system

is not dependable.

4

binary that calls other library ﬁle (more often then not, they do)
you statically compiled version of the binary. For Intel fortran, the
command is

$ ifort -static my ﬁle.f90

(cid:3)RB⌋

3 A Little on RSL File

The Globus Resource Speciﬁcation Language (RSL) provides a neutral
way to describe the resource needs of submitted jobs, a way that
can be used by other parts of the Globus job-management system
and that can be translated into each participating computer’s local
job-management jargon . The Globus Resource Allocation Manager
(GRAM) relies on RSL strings to perform its management functions
and to coordinate with other Globus software.

RSL provides

basic elements,

later reuse, and

1. a syntax used to compose complex resource descriptions from

2. a way to record resource decisions as attribute-value pairs for

3. a vocabulary of job attributes, each of which serves as a param-
eter to control job behavior when passed to the (remote) system
that actually schedules the job.

The Globus web site oﬀers several detailed descriptions of and
technical speciﬁcations for RSL. This subsection (and the next two)
summarize the most important RSL features and the aspects of RSL
most relevant for remote users submitting jobs to LC machines

5

3.1 Syntax of RSL Files

begins all single-job (GRAM-managed) resource descriptions.

begins all multiple-job (DUROC-managed) resource descrip-

The ﬁrst recognizer is about job numbers:
&
+
tions. The next thing is diﬀerent attributes:
(attribute = ”value”)
assigns value to the job resource named by attribute. Each attribute/value
pair is called an RSL relation, and each is separately enclosed in paren-
theses. On the very ﬁrst, we generally mention executable. For my
PWscf submission, I have

Example

(executable=$(GLOBUSRUN GASS URL)/home/garuda/rudra/pw/espresso-
3.1/bin/pw.x)

(cid:3)RB⌋

(cid:3)RB⌋

The next most important attributes are stdin, stdout and stderr.
They informs GRAM about the input, output and the error ﬁle. In
my above stated PWscf submission, these three reference are

Example

(stdin=$(GLOBUSRUN GASS URL)/home/garuda/rudra/al.in)
(stdout=$(GLOBUSRUN GASS URL)/home/garuda/rudra/pwout)
(stderr=$(GLOBUSRUN GASS URL)/home/garuda/rudra/pwerr)

In above examples, my executable is pw.x which is in the directory
/home/garuda/rudra/pw/espresso-3.1/bin/
my input is al.in in /home/garuda/rudra/ and I expect the outputs
stdout & stderr to be in in the same directory.

6

The next attribute one need is arguments. This is used in various
purpose from reading input values to shifting library ﬁles to working
site, depending on the argument.

To run PWscf, you need to have your Pseudopotential ﬁles in the
working node. There is to way to do that. one is sftp it manually
(which is tedious when you need a lot of such ﬁle); and the other is to
use arguments to do this job. So f my Pseudopotential ﬁles are in the
directory /home/garuda/rudra/pw/espresso-3.1/Pseudo/ and I need
the ﬁle Al.vbc.UPF then the argument looks like

Example

(arguments=ﬁle:///home/garuda/rudra/pw/espresso-3.1/Pseudo/Al.vbc.UPF
gsiftp://remote pwd/Al.vbc.UPF)

(cid:3)RB⌋

remote pwd is the slot where your job is supposed to run. This is the
full rsl ﬁle, let it be named as pw.rsl

3.2 Other Commands

According to your need, you may need many other commands to sub-
mit jobs successfully and comfortably. One of the is already shown in
argument. There my ﬁle /pw/espresso-3.1/Pseudo/Al.vbc.UPF has
to be shifted to working node of the grid. gsigtp is used to do this job.
If the situation is such that you have to move your ﬁle to a third loca-
tion, then you can use gsiftp twice. Suppose you want to move a ﬁle
from working site to a third site. Then you should use the command

7

Example

(arguments=gsiftp://working node/path/target ﬁle
gsiftp://remote site/path/destination)

(cid:3)RB⌋

globus-url-copy or gridftp are two other command used for same job.

4 A Little on Grid Variables

GRAM, GASS and all that

4.1 GRAM

The Globus Toolkit includes a set of service components collectively
referred to as the Grid Resource Allocation and Management (GRAM).
GRAM simpliﬁes the use of remote systems by providing a single stan-
dard interface for requesting and using remote system resources for
the execution of ”jobs”. The most common use (and the best sup-
ported use) of GRAM is remote job submission and control. This is
typically used to support distributed computing applications. GRAM
is designed to provide a single common protocol for requesting and
using remote system resources, by providing a uniform, ﬂexible inter-
face to local job scheduling systems. GRAM reduces the number of
mechanisms required for using remote resources (such as remote com-
pute systems). Local systems may use a wide variety of management
mechanisms (schedulers, queuing systems, reservation systems, and
control interfaces), but users and application developers need to learn
how to use only one GRAM to request and use these resources. This
connection is maintained through GRAM. Both sides need work only
with GRAM, so the number of interactions and protocols that need
to be used are greatly reduced. GRAM does not provide scheduling
or resource brokering capabilities.

8

4.2 GASS

Global Access to Secondary Storage (GASS) simpliﬁes the porting and
running of applications that use ﬁle I/O to the Globus environment.
Libraries and utilities are provided to eliminate the need to

1. manually login to sites and ftp ﬁles

2. install a distributed ﬁle system

The APIs are designed to allow reuse of programs that use Unix or
standard C I/O with little or no modiﬁcation. Currently the ftp and
x-gass (GASS server) protocols are supported. The typical user’s view
of GASS comprises a simple ﬁle access API for opening, closing, and
prefetching ﬁles. Planned are some RSL extensions for remote cache
management.

1. File Access API (to be deﬁned).

2. RSL extensions.

5 Submitting Jobs

So, now you know a lot about grid terminology and ready to submit
(at least I hope) jobs on Grid. Lets have a look on your resources.
You have a binary executable and inputs to run that ﬁle, right? So go
for shooting the job. There are several options for shooting jobs on
Grid.

5.1

globusrun

The easiest submission is globusrun. The *.rsl ﬁle is used here and I
think it is best to start with that.

9

Example

$globusrun -s -r abcd -f pw.rsl

where abcd is the remote machine where I want to ﬁre the job.

Check the table at Ch. 1 for actual host name.
The globusrun syntax is as follows: Syntax:

globusrun [options] [RSL String]

(cid:3)RB⌋

-f<rsl ﬁlename> |

-help|

-i |

-q |

-o |

-s |

-w |

-usage
Display help
-interactive
Run globusrun in interactive mode (multi requests only)
-ﬁle <rsl ﬁlename>
Read RSL from the local ﬁle <rsl ﬁlename>. The RSL can
be either a single job request, or a multi request
-quiet
Quiet mode (do not print diagnostic messages)
-output-enable
Use the GASS Server library to redirect standout output
and standard error to globusrun. Implies -quiet
-server
$(GLOBUSRUN GASS URL) can be used to access ﬁles local
to the submission machine via GASS. Implies -output-enable
and -quiet
-write-allow
Enable the GASS Server library and allow writing to
GASS URLs. Implies -server and -quiet.

5.2

globus-job-run

globus-job-run is an on line interface to job submission, featuring stag-
ing of data and executables using a GASS server. Staging is the pro-
cess in which ﬁles are copied from the local machine to the remote ma-

10

chine on which the processing takes place and automatically deleted
from it when processing is complete. This command is used for short,
interactive jobs in foreground.

The basic syntax is

Example

$globus-job-run work-site -s binary arg

For multiple submission, it looks like:

Example
$ globus-job-run
$ -: host1 np 2 s myprog.linux arg1
$ -: host2 np 3 s myprog.aix arg2

where host is the remote work node, -np n is the number of processors
you want for a job called myprog.* . Here you can see that since I
am using same program but compiled in diﬀerent system(Linux and
AIX) I am supposed to choose my host accordingly.
Other frequently used options are stdin,stderr & stdout. Job stdin
defaults to /dev/null.
For other commands, go for
$globus-job-run -help

11

(cid:3)RB⌋

(cid:3)RB⌋

5.3

globus-job-submit

This is little better then globus-job-run in the sense that that it has
a batch interface.

The job is submitted using globus-job-submit , its status is then
checked using globus-job-status , the standard output of the job is the
obtained by using globus-job-get-output and then the job is ﬁnally
cleaned using the globus-job-clean command.

12

.1 The Garuda Portal: How Should You Use
It

There is two way of submitting jobs is Garuda grid. One is what I
talked about...commandline submission; and the second is via Portal.
You can access this only if you are log in to the grid http://192.168.60.40:8080/GridPortal/.

But even you prefer to use command line submission, then also
the Portal is very helpful. Most important of them is monitor the
workload on diﬀerent noads. By this you can choose where to shoot

Figure 2: Screen-shot: Garuda Portal

the jobs. The page shown, gives many ﬁrst hand information like CPU
load and noad status. From then they give the exact status (Like of
there available resources, status,Installed packages)of diﬀerent noad.
It is strongly advised to keep a look on the state of a speciﬁc node
before shooting jobs there.

13

