Application of Coarse Integration to Bacterial Chemotaxis

Department of Physics, Princeton University, Princeton, NJ 08544

NEC Research Institute, 4 Independence Way, Princeton,
NJ 08540, and Department of Chemical Engineering,
Princeton University, Princeton, NJ 08544

S. Setayeshgar∗,

C. W. Gear,

H. G. Othmer,

I. G. Kevrekidis

Department of Mathematics, University of Minnesota, Minneapolis, MN 55455

Department of Chemical Engineering,
and Program in Applied and Computational Mathematics,
Princeton University, Princeton, NJ 08544
(Dated: December 31, 2013)
Abstract
We have developed and implemented a numerical evolution scheme for a class of stochastic prob-
lems in which the temporal evolution occurs on widely-separated time scales, and for which the
slow evolution can be described in terms of a small number of moments of an underlying probability
distribution. We demonstrate this method via a numerical simulation of chemotaxis in a popula-
tion of motile, independent bacteria swimming in a prescribed gradient of a chemoattractant. The
microscopic stochastic model, which is simulated using a Monte Carlo method, uses a simpliﬁed de-
terministic model for excitation/adaptation in signal transduction, coupled to a realistic, stochastic
description of the ﬂagellar motor. We show that projective time integration of “coarse” variables
can be carried out on time scales long compared to that of the microscopic dynamics. Our coarse
description is based on the spatial cell density distribution. Thus we are assuming that the system
“closes” on this variable so that it can be described on long time scales solely by the spatial cell
density. Computationally the variables are the components of the density distribution expressed
in terms of a few basis functions, given by the singular vectors of the spatial density distribution
obtained from a sample Monte Carlo time evolution of the system. We present numerical results
and analysis of errors in support of the eﬃcacy of this time-integration scheme.

3
0
0
2
 
g
u
A
 
0
1
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
0
4
0
8
0
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

∗ Corresponding author. E-mail: simas@princeton.edu, Tel: (609) 258-4320, Fax: (609) 258-1549

1

I.

INTRODUCTION

A recurring bottleneck in computational modeling of physical processes is the existence
of multiple space and/or time scales. Important examples include patterns in ﬂuids, defect
dynamics in solids, and molecular dynamics of macromolecules. For example, in the latter
case, the evolution of the physical conﬁguration from initial to ﬁnal state typically occurs
on the time scale of milliseconds, while the interactions between constituent components
must be resolved on the picosecond time scale. Furthermore, it is increasingly important
in simulating biological systems to have a hybrid computational framework for interact-
ing stochastic and deterministic processes, which occur on diﬀerent time scales. Multiscale
computational methods combine processing on ﬁne space/time scales according to the gov-
erning microscopic description with macroscopic changes on a coarse grid (see for example,
[1, 2, 3]).

Here we present a computational scheme for “coarse projective” time integration of the
macroscropic dynamics of stochastic processes that involve multiple, widely-separated time
scales. To illustrate the method we apply it to a microscopic model that generates the
biased random walk describing the macroscopic motion of a bacterium such as E. coli in
an attractant gradient. Details of this Monte Carlo model of bacterial chemotaxis that
integrates signal transduction with the motor response are given in Section III. The focus
of our analysis in this paper is the computational scheme, and as such, our results address
its plausibility rather than the phenomenology of chemotaxis.

In Section II we discuss previous work on coarse time integration of microscopic dynamics
and the new features of the method developed here, and we motivate its application to
chemotaxis. The Monte Carlo description is presented in Section III. We outline the coarse
integration scheme in Section IV, and present numerical results and analysis of errors in
Section V. We conclude with future extensions and applications of this work.

II. PREVIOUS WORK

The traditional approach to studying long-term dynamics of multiscale processes involves
(a) the derivation of a “coarse-grained” set of evolution equations, followed by, (b) the ana-
lytical and/or computational study of these reduced equations using established, continuum
numerical analysis tools. Recently, a so-called “equation-free” approach to the study of the
coarse-grained behavior of such problems has been proposed which circumvents the ﬁrst
step ([4, 5, 6]). This computational approach is based on the “coarse,” or macroscopic time-
stepper, a map from the coarse variables at time t = 0 to those at time t = T , where T is
typically much larger than characteristic microscopic time scales in the system. This map
is not obtained directly from the macroscopic evolution equations, which we may not know,
but rather through short time evolution intervals of appropriately initialized microscopic
simulations. The initial macroscopic variables are lifted to microscopic variables to initialize
the microscopic simulation. At the completion of a burst of microscopic simulation, the mi-
croscopic variables are restricted back to macroscopic variables, providing an approximation
to the macroscopic time step. This provides a chord of the macroscopic solution, which is
an approximation to the time derivative of the macroscopic solution. This value can then
be used in any conventional continuum numerical method for the macroscopic equations.
This approach has been applied in several microscopic contexts, and the results appear to
be promising [7, 8, 9, 10].

2

In this work we apply the coarse timestepper in a projective integration study of a
spatially-distributed kinetic Monte Carlo simulation of a biased random walk. When, as
in this case, the microscopic equations are stochastic, an eﬀective algorithm must reduce
the variance inherent in individual realizations of the stochastic process to a level that can
be tolerated by the continuum numerical algorithm applied to the coarse system. This can
be done by lifting to multiple copies, or, as is done here, by estimating the derivative from
a least-squares ﬁt to a large number of microscopic time steps. The projective integration
method applied here uses a derivative estimate for the projective step, so that the stochastic
noise is ampliﬁed by the inverse of the eﬀective step length used in the derivative estimate.
Hence, variance reduction is very important. Augmenting the number of copies of the sim-
ulation (which, for our noninteracting particle model corresponds also to a simulation with
a larger number of cells) is the most direct approach to variance reduction; other variance
reduction schemes are discussed in [11, 12].

In the context of bacterial chemotaxis, the computational scheme developed here can
be viewed as a direct method to compute the macroscopic evolution of the cell density in
space and time without actually deriving these equations. An alternate approach begins
with the transport equation for the velocity jump process, in which discontinuous changes
in the direction (or speed) of an individual cell are generated by a Poisson process. It can
be shown rigorously that this reduces to the chemotaxis equation under suitable scaling of
space and time [13]

∂µ0
∂t

=

∇

∇

(D

S),

∇ ·

µ0χ(S)

µ0 −
In the above, µ0(x, t) represents the density of particles at spatial position x at time t, D
is the diﬀusion constant, S is the concentration of the chemotactic attractant/repellent,
and χ(S) is the chemotactic sensitivity. However, there is as yet no analytical procedure
available for determining the diﬀusion constant and chemotactic sensitivity when dependence
on internal state variables determining the cell’s response to the external signal is explicitly
included the transport equation. We show that a macroscopic time-stepper can be used here
in the time evolution of the spatial density, even though the macroscopic evolution equations
are not known.

(1)

III. BACTERIAL CHEMOTAXIS

A. Signal transduction

The ability to sense and respond to environmental cues is necessary for the survival of
most organisms. Escherichia Coli (E. coli) is a common and well-known single cell organ-
ism, with roughly 4000 genes, whose chemotaxis network has emerged as a prototype for
understanding signal transduction networks in general [14]. Its genome is known, the crystal
structures of many proteins have been obtained, and a large number of mutant strains exist,
allowing detailed behavioral studies.

For each cell, chemotactic behavior begins when attractant or repellent molecules bind
to membrane receptors, triggering a cascade of chemical reactions inside the cell that culmi-
nates in the production of the phosphorylated form of a response regulator protein (CheY-P)
which controls the direction of rotation of the ﬂagellar motor. The series of reactions that
converts the extracellular signal (attractrant/repellent) into cellular response is referred to

3

as the signal transduction pathway. Flagella possess an inherent chirality, such that counter-
clockwise (CCW) rotation results in bundling-up of the six to eight ﬂagella per cell, allowing
them to act as a single propeller and leading to smooth swimming motion of the bacterium.
When the ﬂagella rotate clockwise (CW), the bundle ﬂies apart and the bacterium tumbles.
As conditions become increasingly favorable due to increase in chemoattractant concentra-
tion, a bacterium extends its run-length; otherwise, it tumbles, and the subsequent direction
of motion is randomly chosen, allowing a more favorable direction to be discovered. The
resulting motion is a biased random walk toward favorable conditions and away from less
favorable ones.

The sequence of biochemical reactions that take place inside a bacterium, starting with the
binding of an attractant or repellent molecule to receptors on the cell surface and leading to
the change in concentration of the response regulator species, CheY-P, has been extensively
studied. Both deterministic models of these biochemical pathways, based on the law of mass
action and Michaelis-Menten kinetics [15, 16], as well as fully stochastic models exist [17].
Measurement of concentration change is achieved through a temporal rather than a spatial
comparison: fast sampling of the present external concentration is compared with memory
of that concentration some time ago. Order-of-magnitude analyses for why measurement of
concentration changes as spatial gradients across the cell length is not physically feasible
have been given [18].

Memory in the signal transduction network is achieved through the existence of fast and
slow reaction time scales. The fast reactions are receptor-ligand binding and phosphorylation
kinetics; the slow reactions are methylation and demethylation. Ligand binding reduces the
autophosphorylation rate of the corresponding membrane-bound receptor, in turn decreasing
the rate of transfer of phosphoryl groups to CheY, and resulting in a (fast) drop in [CheY-
P]. Addition of methyl groups to ligand-bound receptors restores the autophosphorylation
rate, resulting in (slow) increase in [CheY-P]. The rate of demethylation becomes signiﬁcant
once a high methylation level is achieved. Hence, [CheY-P] reﬂects the balance between the
fraction of ligand-bound receptors and methylated receptors. Perfect adaptation refers to the
return of [CheY-P] to the same steady state level, regardless of the constant concentration
level of the external stimulus. This value falls within the ﬁxed operational range of the
motor response to CheY-P.

A minimal model representing the signal transduction process includes fast excitation

and slow adaptation to an external stimulus and is given in [19]:

τa. We
where τe and τa are the excitation and adaptation times, respectively, with τe ≪
identify u1 with the deviation of [CheY-P] from its steady state value, and u2 as the number
of methylated receptors per unit volume. f (S) = f (S(t)) is a function of the external
stimulus; for example, it is the number of bound receptors per unit volume in the presence
of an external signal concentration, S:

NT is the total number of receptors per unit volume, and KL is the dissociation constant
for the ligand-binding process.

u1

,

−

du1
dt
du2
dt

=

=

(f (S)

f (S)
τa

−

u2)
−
τe
u2

,

f = NT S/(KL + S).

4

(2)

(3)

(4)

The formal solution to Eqs. (2)–(3) can be easily obtained for each cell as

t

e−t/τa
τa Z
e−t/τe
τe  Z

t

u2(t) =

f (S(t′)) et′/τadt′,

(5)

t

t′

u1(t) =

f (S(t′)) et′/τedt′

1
τa Z
However, because S(t) = S(x(t), t), where x(t) is a random variable that represents the cell’s
position at time t in a given external concentration ﬁeld, the integration takes place along the
cell trajectory, which is a biased random walk: x(t′) for t′ < t biases the probability of x(t).
Hence, S(t) is a stochastic variable, and the integration must be carried out computationally.

f (S(t′′)) et′′/τadt′′ dt′

e−t′(1/τa−1/τe)

.(6)

!

−

Z

B. Motor and cell response

We adopt a stochastic approach to modeling the response of the ﬂagellar motor to the
regulator species, CheY-P. The motor is assumed to be in one of two states, CW or CCW,
corresponding to clockwise or counterclockwise rotation [20, 21]. The rates of transition
between these states are functions of [CheY-P]:

CCWi

CWi

i = 1, ..., Nf ,

k+−→
←−
k−

where Nf is the number of ﬂagella per cell. For any concentration of CheY-P, the motor has
a nonzero probability of being in either state. The probability of waiting at least a time T
for a transition from CCW to CW, Φ+, or a transition from CW to CCW, Φ−, is given by:

Φ± = e−

T

0 k±(t)dt .

R

If the motor is probed at a time T
change in direction will occur in (T, T + ∆t) can be approximated as

∆t, such that k±∆t

≪

≡

1, then the probability that a

1

Φ±

k±(0)∆t .

≈
Systematic studies have been undertaken that show simulation results are qualitatively in-
dependent of the choice of ∆t once the above restrictions are met.

−

In this work, we use equilibrium transition rates, k±, consistent with recent experimental
measurements [22] of the single ﬂagellum clockwise bias, bCW , and the reversal frequency,
w, as functions of [CheY-P]. The rates are related to these measured quantities according
to [23]:

(7)

(8)

(9)

(10)

(11)

where the reversal frequency is the geometric mean of the transition rates. We take bCW
to be described by a Hill function, bCW = yp
P], with
experimentally measured values for the Hill coeﬃcient and dissociation constant, equal to

h), where yp = [CheY

h/(KM

h + yp

−

bCW =

w =

k+
k+ + k−
2k+ k−
k+ + k−

,

,

5

h = 10.3 and KM = 3.1 µM. In these experiments, it was noted that the data were consistent
with w = (2 µM s−1) ∂bCW /∂yp. Based on these results, we use

k+ =

k− =

h−1

h yp

,

h

h + yp
h KM

h

KM

h + yp

h

.

KM
1
yp

(12)

(13)

(14)

(15)

In a constant chemoattractant ﬁeld, [16, 24] show that the “Voting Hypothesis” is suc-
cessful in producing the correct running bias of the cell, BCCW , from the individual ﬂagellar
bias, bCCW :

BCCW =

Nf

Nf
j

j=ν (cid:18)
X

(cid:19)

bj
CCW (1

bCCW )Nf −j ,

−

where ν is the minimum number of ﬂagella required to be in the CCW state for the cell
to run. Although cooperativity among the ﬂagella is not yet fully understood, we similarly
adopt the “majority rules” algorithm to determine whether each cell will run or tumble in
the presence of a chemoattractant gradient:

Nf

ν =

s(i) .

i=1
X
where s(i) = 0, 1 is the state of the ith ﬂagellum, corresponding to CW and CCW directions
of rotation, respectively. Based on the experimentally measured gain of a single ﬂagellum
[22], a steady state value of ¯yp = 2.95 µM yields bCCW ∼
0.64 to within experimental error.
0.86 for Nf = 6
The resulting running bias for the cell, according to Eq. 14, is BCCW ∼
and ν = 3, in agreement with experimental results. Hence, if three or more ﬂagella are
determined to be in the CCW state, the cell in our simulation runs; otherwise, it tumbles.

C. Monte Carlo scheme

For each cell, the Monte Carlo scheme can be outlined as follows. At tn:

(a) Each ﬂagellum has a state sn, where sn = 0 if CW, and sn = 1 if CCW. To determine
[0, 1].

sn+1, for each ﬂagellum, we draw a uniformly distributed random number, ζ

∈

(b) We determine an approximation to the probability for changing direction of rotation,
given by Eq. 9. If the values of k± are such that this approximation is not valid, ∆t is
reduced until it is. This probability is a function of [CheY-P], which depends on the
trajectory that the cell has taken along the external chemoattractant gradient.

– If the ﬂagellum is in the CW state (sn = 0) and ζ < k− ∆t, it continues in the

CW state (sn+1 = 0); else, it switches to the CCW state (sn+1 = 1).

– If the ﬂagellum is in the CCW state (sn = 1) and ζ < k+ ∆t, it continues in the

CCW state (sn+1 = 1); else, it switches to the CW state (sn+1 = 0).

6

(c) If three or more ﬂagella are now in the CCW state, νn+1 ≥

3 in Eq. 15, and the cell
runs; else, it tumbles. If the cell is determined to run and νn < 3, the direction of
motion is chosen to be left or right with equal probability. Otherwise, it continues to
run in the same direction.

(d) The position of the jth cell, xn(j), is accordingly updated to xn+1(j) (using the accepted
time step ∆t), with the cell speed, vcell, assumed to be constant and independent of
position.

(e) The signal transduction variables (u1, u2) are integrated in time, using the forward

Euler scheme. Their time history is a function of each cell’s trajectory.

D. Combining signal transduction and motor response

Although we use a toy excitation-adaptation model to describe signal transduction, it is
coupled to an experimentally realistic description of the ﬂagellar switch. To do so requires
introducing (i) a shift in the steady state value of u1, and (ii) an ampliﬁcation or gain factor,
g0, for the signal transduction network, required so that the output of this network spans
the dynamic range of the motor:

yp = ¯yp −

g0 u1

(16)

The issue of gain in chemotaxis continues to receive much attention [25]. Given the level
of simplicity of our signal transduction model, we do not imply this treatment of network
gain to be physically realistic. An obvious drawback is that, like other parameters in the
toy model (excitation and adaptation times), it is static, whereas in the actual biological
system, these parameters depend on the external signal.

In Table I, we report the numerical values for the MC model parameters that operationally
interface the toy signal transduction model with the realistic model of the ﬂagellar switch.
Hence, although the choice of toy model parameters was “physically motivated”, we do not
attempt to make direct correspondence with experimental values. We caution the reader
against making quantitative connection between our numerical results at these values and
experimental results.

TABLE I: Numerical values for parameters used in the Monte Carlo evolution.

Parameter
τa
τe
g0
NT
KL
¯yp
KM
vcell

7

Value
100 s
0.1 s
5
15 µM
1 µM
2.95 µM
3.1 µM
20 µm s−1

IV. COARSE INTEGRATION

For the present problem of simulating the chemotactic response of a population of inde-
pendent bacteria, the microscopic phase space is a directproduct of the phase space for each
cell, consisting of its

signal transduction variables: ~u = (u1, u2),

ﬂagellar state: ~s, where s(i) = 0, 1 for i = 1 . . . Nf ,

•

•

•

•

position: x,

direction of motion, d = R, L, T , corresponding to running right, running left and
tumbling, respectively.

Rather than evolving all microscopic degrees of freedom, a coarse integration scheme iden-
tiﬁes suitable reduced variable(s) to be integrated. A clearly relevant reduced variable in
population studies is the spatial density distribution of cell positions, µ0(x, t), obtained from
the set of individual cell positions, xj, which are a subset of the full microscopic phase space.
However, it is possible that the unknown equations of the coarse description use additional
variables, for example, the densities of the right moving, left moving, and tumbling cells,
ρi where i = R, L, or T . In this case, µ0(x, t) =
i ρi(x, t). Indeed, an optimal reduced
representation balances accuracy and eﬃciency of modeling the physical process. Here, we
propose to retain only the spatial density distribution µ0(x, t) as the relevant macroscopic
variable in coarse modeling of chemotaxis since, as we will demonstrate numerically, the
density of cells in each state rapidly approaches a functional of the total density.

P

A systematic approach to testing the adequacy of a particular coarse description is dis-
cussed in [9]. It is based on locating the same ﬁxed point at diﬀerent levels of coarse descrip-
tion, and examining the slow eigenvalues and corresponding eigenvectors of the linearization
of the coarse timestepper at these ﬁxed points (see also the discussion in [7]).

The separation of characteristic time scales describing the underlying macroscopic and
microscopic dynamics – for example, the (long) time scale on which the spatial density dis-
tribution of a population of bacteria moving in a chemoattractant proﬁle changes versus the
(short) mean runtime of a single cell – allows taking time steps in evolving the macroscopic
state that are “long” in comparison with the “fast” microscopic time scales in the prob-
lem, resulting in a computationally - eﬃcient time evolution of the macroscopic state. We
demonstrate this assumption of the separation of time scales explicitly in Section V. Figure
1 shows a cartoon sketch of the coarse integration (CI) procedure, where the solid trajec-
tories denote the restriction of the full dynamics onto a suitable low-dimensional subspace
(see Section IV A for how a low dimensional representation of the macroscopic spatial dis-
tribution, µ0(x, t), is constructed). At each CI step, the coarse-integrated solution is lifted
from the lower dimensional space into the full microscopic state space and evolved according
to the Monte Carlo scheme, allowing the error incurred during the coarse time step to relax
~u, ~s
to the slow manifold parameterized by the cell density. Because the internal state
}
{
of cells, and their directions of motion, d, are ignored in obtaining µ0(x, t), they must be
suitably reinitialized to construct the initial condition for the next MC step (see Section
IV B).

8

(i+1)
tk+1

(i+1)
tk+m+1

(i+1)
tk+m+p+1

(i)
tk+m+1

(i)
tk+1

t(i)
k+m+p+1

MC 

 th
n    coarse integration step, using
(n)
tk+1

(n)
tk+m+1

to

FIG. 1: Schematic illustration of the coarse integration procedure.

A. SVD-based restriction scheme

Below, we outline our coarse integration scheme which operates on data from singular
value decomposition of the distribution of cell positions from Monte Carlo time evolution
results. In the following, the solution at a “reporting step” refers to the sorted cell positions
at speciﬁed time intervals, Tstep. Note that this time interval should be distinguished from
a single Monte Carlo iteration, of which it contains a large number.

1. The Monte Carlo description is simulated for k reporting steps, corresponding to a
total time interval equal to Tsettle. Step by step results are accumulated for a further
m reporting steps, corresponding to a total time interval equal to Tf it.

2. At each reporting step, we sort the cell positions, xi(j), to obtain Xi(j), i =
k + 1, . . . , k + m, and j = 1, . . . , Ncells. The matrix Aℓ is constructed (columnwise):
Aℓ =
. Figures 2 and 3 show the chemoattractant proﬁle, and
representative time sequences of sorted cell positions and corresponding histograms of
the spatial density distributions, respectively. However, we ﬁnd it more convenient to
work with the cumulative probability distribution function, deﬁned as

~Xk+1, ~Xk+2, . . . , ~Xk+m}

{

which is related to the sorted cell positions at that time according to

P (X, t) =

µ0(x′, t)dx′,

1
L

X

xmin

Z

j/Ncells = P (Xi(j), ti) ,

(17)

(18)

where L
or equivalently the sorted cell positions, ~Xi, as the macroscopic variable [26].

xmin is the spatial domain. We will use approximations to P (X, t),

xmax −

≡

3. A low dimensional representation of the sorted cell positions is constructed in terms

of orthonormal numerical basis functions,

α(r)(ti) = ~u(r)

~Xi =

u(r)(j) Xi(j),

(19)

,

~u(r)
{

}
Ncells

j=1
X

·

9

0.1

0.08

0.06

0.04

0.02

n
o
i
t
a
r
t
n
e
c
n
o
C

 
t
n
a
t
c
a
r
t
t
a
o
m
e
h
C

0

1

3

5

7

Space

9

11

FIG. 2: Chemoattractant proﬁle used in Monte Carlo simulation of chemotaxis: S(x) = S0(x
−
10−4 and (xmin, xmax) = (1, 11). The choice of this proﬁle
xmin)2(x
ensures zero gradient of chemoattractant at the boundaries, consistent with no-ﬂux boundary
conditions for the motion of bacteria.

xmax)2, where S0 = 1.6

×

−

where the basis functions are obtained from singular value decomposition of the MC
data as described below.

We distinguish between two approaches to obtaining the numerical basis set.

•

Local basis functions: The singular value decomposition of Aℓ, constructed in
Step 2, is computed:

Aℓ = Uℓ Wℓ V ⊤

ℓ

(20)

(r)

}

{

~uℓ

, r = 1, . . . , m, are the numerical basis func-
The columns of Uℓ, given by
tions. We assume that they remain valid basis functions during the projected
step. Wℓ is a diagonal matrix, where
are the singular values.
Global basis functions: Using a single MC evolution from initial conditions to
steady state, Tf , the matrix Ag is constructed from the full data according to Step
~X1, ~X2, . . . , ~XM }
, where M = Tf /Tstep. Singular value decomposition
2: Ag =
of Ag gives the the global basis functions,
. (In practice, initial data from
t = 0 to t = Tsettle are not included.)

wℓ1, wℓ2, . . . , wℓm}
{

~ug

(r)

{

}

{

•

4. We perform linear least squares extrapolation of

using i = k+1, . . . , k+m+1
}
, corresponding to a projected time equal to Tproj. The

α(r)(ti)

{

to obtain
projected solution is given by:

α(r)(tk+m+1+p)

}

{

~Yk+1+m+p =

α(r)(tk+m+1+p)~u(r).

(21)

r
X

10

0

2000

4000

6000

8000

10000

Cell Index

T = 200,000

T = 100,000

T = 60,000

T = 20,000

T = 0

11

9

7

5

3

1

n
o
i
t
i
s
o
P

 
l
l
e
C

1000

500

0
1000

500

0
500

250

0
250

125

0
250

125

T = 0
T = 20,000
T = 60,000
T = 100,000
T = 200,000

11

0

1

3

5
7
Cell Position

9

11

FIG. 3: Sorted cell positions (top), and corresponding histograms (bottom) using a bin size equal
to 0.1, at T = 0 (thin solid line), T = 20, 000 (dashed line), T = 60, 000 (long-dashed line) and
T = 100, 000 (dot-dashed line), and T = 200, 000 (thick solid line). From the time evolution of
the variance of these distributions we have determined that at T = 200, 000, the coarse solution is
very close to the stationary state.

5. In practice, we use only the numerical basis functions associated with the dominant
singular values, r = 1, . . . , rmax, where the truncated number of basis functions, rmax,
depends on the spectrum of singular values.

The use of empirical orthogonal eigenfunctions, also referred to as the Karhunen-Lo`eve
expansion or the Proper Orthogonal Decomposition, obtained through singular value de-
composition of experimental or simulation data, for model reduction in systems with spa-
tiotemporal dynamics originates with Lorenz in the context of weather prediction [27] and
has found widespread use in the dynamical systems context since the mid-80’s (see the
monograph [28] and references therein).

The SVD process is computationally expensive, so if the computational cost of the mi-
croscopic cell simulations were small, using global basis functions generated in a preliminary
run would be less costly than using local basis functions. However, in a simulation of a large
number of cells, the total microscopic simulation cost for the cell population may be much
larger that for the SVD process. For example, in the numerical experiments reported here
the CPU time for one simulation step of an individual cell was 2.07 microseconds, while the
time for one SVD step was 22.4 milliseconds. However, in a simulation of 104 cells using
109 times versus 16
local basis functions, the microscopic integration routine was called 4
calls on the SVD routine so that 0.0041% of the time was spent on SVD.

×

B. Reinitialization of internal variables

The question of consistent schemes for combining microscopic and macroscropic descrip-
tions of a physical process is central to multiscale modeling. Here, to alternate each CI step
with MC, in principle allowing relaxation of the numerical error in the projective step, we
must deﬁne an appropriate reinitialization procedure: We know the position of each cell, x,
after the CI step, but we discard all information about its internal state,
, given by
the values of the signal transduction variables and the ﬂagellar states, and its direction of
motion, dj.

~u, ~s
{

}

Our reinitialization protocol is empirically motivated: the signal transduction variables
are set equal to their local equilibrium values, ~uj =
, where j refers to the
jth cell. This allows the subsequent response of each cell to be within the most sensitive
range of the motor gain. For simplicity, all (six) ﬂagella are restarted in the CW state,
~sj =
. In Figure 4, we show relaxation of the ratios of the numbers of right,
}
left and tumbling cells at a set location along the chemoattractant proﬁle. These ratios at
steady state for a ﬂat chemoattractant proﬁle are

0, f (S(xj))
{

0, 0, . . . , 0

}

{

ρR + ρL
µ0

= B,

(22)

where the right and left moving ratios are equal. For the present choice of numerical pa-
rameters, B
0.43. Other ﬂagellar reinitialization schemes lead to
similarly rapid relaxation rates.

0.86 and ρR = ρL ∼

∼

12

e
l
b
m
u
T

0.5

t
f
e
L

0.5

1

0
1

0
1

t
h
g
R

i

0.5

0

0

2

4

6

8

10

Time

Ratios of right moving,

left moving and tumbling cells at x = 4 (

FIG. 4:
0.1), using
j = 1, . . . , Ncells = 100, 000 and starting from an initially uniform distribution of cells along the
chemoattractant proﬁle: Averages over 5 Monte-Carlo realizations started from diﬀerent random
number seeds are plotted. The error bars, corresponding to the root-mean-square of the distribu-
tion of these ratios, are shown for select points. We note fast relaxation of these ratios to their
equilibrium values. The signal transduction variables were initialized to their local equilibrium
values, ~uj =

±

.

0, f (S(xj))
}
{

V. NUMERICAL RESULTS

A. Low-dimensional representation

In Figures 5 and 6, we show the ﬁrst four dominant global basis functions and singular
values obtained from MC evolution of Ncells = 104 from initial conditions to steady state.
Figure 7 shows the mean coeﬃcients over NMC = 10 MC realizations

¯α(r)(t) =

α(r)
k (t) ,

1
NMC

NMC

Xk=1

(23)

13

and the root-mean-square of the distribution of coeﬃcients, given by

NMC

σ(r)
α (t) =

1
NMC −

1

(

α(r)
k (t)

¯α(r)(t)

−

1/2

2

.

)

Xk=1 h
Hence, the error bars in this ﬁgure denote the expected statistical variation in the values of
these coeﬃcients as a function of time.

i

(24)

u2

u1

0.2

0.1

0

−0.1

−0.2

0.1

0

0.05

0

−0.05

u4

u3

5000

10000

5000

10000

0.04

0.02

0

−0.02

−0.04

0

0

−0.005

−0.01

−0.015

−0.02

0

5000
Cell Index

10000

−0.1

0

5000
Cell Index

10000

FIG. 5:
density.

~u(r)
g
{

, r = 1, . . . , 4 are the ﬁrst four global SVD basis functions for the cumulative cell
}

102 and Tproj = 5

α(1)(t), α(2)(t), α(3)(t), α(4)(t)

In Figure 8, we show the low-dimensional representation of the coarse-integrated solution
103. For each CI step, after evolving the
for Tsettle = Tf it = 5
×
×
Monte Carlo for Tsettle, we use a linear ﬁt to
during the
interval Tf it to project the solution forward in time by Tproj. The points correspond to
averages over NMC = 5 realizations, and the error bars give the rms of the distribution
of these coeﬃcients. For reference, we have included the average MC coeﬃcients in this
, whose
ﬁgure. These results indicate that for the higher order coeﬃcients,
coarse dynamics are described by a shorter characteristic time-scale, a higher order time
integration scheme would be more eﬀective than the explicit Euler method used here [29].
Consequently, although for intermediate times the diﬀerence between the CI and MC results
the straightforward CI scheme has captured the macroscopic dynamics of the solution.

α(3)(t), α(4)(t)

(cid:9)

(cid:8)

(cid:8)

(cid:9)

14

1e+06

10000

]
i
[

w

100

1

0.01

0

5

10
Index, i

15

20

FIG. 6: Largest singular values from global SVD of Monte Carlo data from initial conditions to
steady state (Tf = 200, 000, Tstep = 200). The ﬁrst four dominant modes (rmax = 4) are used to
construct the low-dimensional representation of the cumulative cell density distribution.

These results also illustrate the implicit assumption of separation of time scales: The
, governing the macroscopic behavior of the system, vary on a time
(104) units, while the longest microscopic time scale (adaptation time of the signal

α(r)(t)

coeﬃcients
scale of
transduction model) is

O

(cid:9)

(cid:8)

(102).

O

B. Analysis of Errors

For comparison of solutions at diﬀerent values of the CI parameters, (Tsettle, Tf it, Tproj),

with the MC, we construct the following measure of relative error:

ε(t) =

4
r=1

¯α(r)(t)

α(r)(t)
−
r=1 [¯α(r)(t)]2
4

)

(cid:3)

2

1/2

.

(P

(cid:2)

P

(25)

α(1)(t), α(2)(t), α(3)(t), α(4)(t)

, used in computing the relative error of the
The coeﬃcients
}
CI solution are obtained as inner products of the solution with the global basis set, regardless
(a) of whether global or local basis sets were used in the restricting/lifting step, and (b) the
dimensionality of the restricted space.

{

In Figure 9, we ﬁrst plot the average relative error for NMC = 10 MC runs, given by:

¯ε(t) =

εk(t).

(26)

NMC

Xk=1

1
NMC

15

20

10

0

40

20

0

−20

−40

−60

200

100

0

−590

−600

−610

−620

−630

−640

α

2

α

4

−100

0

100000

−10

200000

0

100000

200000

0

200000

0

200000

α

1

100000
Time

α

3

100000
Time

Ncells
j=1 u(r)(j)Xi(j), where the
FIG. 7: Coeﬃcients of SVD basis functions: α(r)(ti) = ~u(r)
points represent averages over NMC = 10 MC realizations, starting from diﬀerent random number
are obtained from one of the MC runs. The error bars,
seeds. The global basis functions
plotted for select points, correspond to the root-mean-square of the distribution of coeﬃcients.

~u(r)
{

~Xi =

P

}

·

The error bars denote the error on the mean, given by σ¯ε = σε/√NMC, where σε is the
root-mean-square of the distribution of the error

NMC

σε(t) =

1
NMC −

1

(

[εk(t)

¯ε(t)]2

−

)

1/2

.

(27)

Xk=1
We similarly compute the relative error for CI solutions, obtained using either (i) global
or (ii) local SVD basis functions in each step. Figure 10 shows the mean errors for solu-
tions with CI parameters given by (Tsettle, Tf it, Tproj) = 103
(1, 1, 10) and
103
(2, 2, 20). Note that for these parameter values, the eﬃciency of the CI scheme re-
In this ﬁgure, solid lines show results obtained using global SVD basis
mains the same.
g , ~u(3)
g , ~u(2)
~u(1)
, in the CI steps. Dashed lines show these results obtained
functions,

2, 5), 103

g , ~u(4)
g

( 1
2 , 1

×

×

×

n

o

16

200

100

0

−590

−600

−610

−620

−630

−640

α2

α4

−100

0

100000

−10

200000

0

100000

200000

α1

100000
Time

α3

100000
Time

0

200000

0

200000

FIG. 8: Coeﬃcients of SVD basis functions: α(r)(ti) = ~u(r)
g (j)Xi(j), with
g
CI parameters (Tsettle, Tf it, Tproj) = 103
2 , 5). The points represent averages over NMC = 5
P
realizations, starting from diﬀerent random number seeds. The error bars, plotted for select points,
correspond to the root-mean-square of the distribution of coeﬃcients. The average MC coeﬃcients
(dashed line) are shown for comparison.

j=1 u(r)
Ncells

~Xi =

( 1
2 , 1

×

·

~u(1)
l

, ~u(2)
l

using local SVD basis functions. In the latter case, since singular value decomposition is
applied to a short segment of the MC, we found the higher order local basis functions to be
were used in each CI step. Note that the rms of the
relatively “noisy”; hence,
distribution of errors obtained for CI solutions using local basis function is larger; in this
case, the basis functions themselves are also subject to statistical variations. We ﬁnd that
the relative errors using global SVD basis functions are generally smaller than those corre-
sponding to CI solutions obtained using local SVD basis functions. Using either global or
local basis functions in the CI step, the smallest relative error is achieved with the ﬁrst two
sets CI of parameters, corresponding to projected time intervals short enough to resolve the
macroscopic dynamics of the higher order coeﬃcients of the low-dimensional representation

n

o

20

10

0

40

20

0

−20

−40

−60

17

 

r
o
r
r
E
e
v
i
t
a
e
R

l

0.01

0.008

0.006

0.004

0.002

0

−0.002

0

50000

1.5e+05

2e+05

1e+05
Time

FIG. 9: Relative error given by εk(t) =

points correspond to the average error, obtained over k = 1, . . . , 10 MC realizations starting from
diﬀerent random number seeds. The error bars denote the error on the mean, σ¯ε.

P

P

(cid:2)

(cid:3)

i

(cid:27)

4
r=1

α(r)
k (t)

−

(cid:26)

h

¯α(r)(t)

2

/

4
r=1

¯α(r)(t)

2

1/2

: The

of the solution.

}

×

As a benchmark,

(1, 1, 0), using global SVD functions

in Figure 11 we show the error obtained for (Tsettle, Tf it, Tproj) =
~u(r)
103
, with r = 1, . . . , 4 (dotted line) and
g
{
r = 1, . . . , 8 (solid line). These results show the error incurred in restricting the spatial
distribution of cell positions to the low dimensional representation given by
, without
the contribution from the projective step. First, we note that the maximum error obtained
g , . . . , α(8)
α(1)
from the restriction to
are comparable, indicating that
g
using a higher dimensional restriction is not signiﬁcantly advantageous here. Secondly, this
error is comparable to the total error in Figure 10(b), which includes projective integration.
Given that the total error increases with a longer projective time step, Tproj, as shown in
Figure 10(c), these results point out that the “optimal” Tproj, for which the errors due to the
projective time step and restriction are separately comparable, is achieved in Figure 10(b).
Finally, in Figure 12, we compare CI errors using two diﬀerent reinitialization schemes

g , . . . , α(4)
α(1)
g

α(r)

and

}

{

}

{

{

}

and ﬁnd them to be equivalent.

VI. CONCLUDING REMARKS

We have demonstrated, through a coarse projective integration algorithm, that short
bursts of appropriately initialized microscopic simulations can be used to simulate the macro-

18

r
o
r
r
E
 
e
v
i
t
a
l
e
R

0.04

0.02

0
0.04

0.02

0
0.04

0.02

0

0

(c)

(b)

(a)

50000

1.5e+05

2e+05

1e+05
Time

α(r)(t)

4
, where
FIG. 10: Relative error given by ε(t) =
r=1
α(r)(t) are the coeﬃcients of the global SVD basis functions for CI solutions corresponding to pa-
rameters (Tsettle, Tf it, Tproj) = 103
(2, 2, 20)
(top). The CI solution at each step was constructed using the ﬁrst four global basis functions, shown
using solid lines, and using the ﬁrst two local basis functions, shown using dashed lines. The points
correspond to averages over NMC = 5 realizations starting from diﬀerent random number seeds.
The error bars denote the error on the mean, σ¯ε.

o
2 , 5) (bottom), (103, 103, 104) (middle), and 103

¯α(r)(t)

¯α(r)(t)

2 , 1
( 1

nP

4
r=1

P

×

−

×

/

(cid:2)

(cid:3)

(cid:2)

(cid:3)

2

1/2

2

scopic evolution of the cell density distribution in bacterial chemotaxis. The outer level of
our computational structure was a traditional, continuum Euler integration scheme; the
time-derivatives of the cell density ﬁeld it employed, however, were estimated from short
time evolution intervals of the Monte-Carlo description of this process, and not evaluated
from a known, macroscopic expression. This approach leads to a general framework for the
computer-assisted analysis of systems whose dynamics are given at a microscopic/stochastic
“ﬁne” level, but for which we require averaged, macroscopic information.

It is interesting to discuss the beneﬁts and shortcomings of such a procedure. If accurate
closed chemotactic equations exist, one should use them instead of the two-tier modeling
we propose here. In addition to the insight gained from exact or approximate analytical
solutions, computer-aided time-evolution or bifurcation analysis using explicit equations is
more eﬃcient than kinetic Monte Carlo simulations. However, if such model equations
are not available, our hybrid computational approach can become more economical than
long-time direct Monte Carlo simulation. Furthermore, when one is interested in qualita-

19

0.015

r
o
r
r
E

0.01

0.005

0

0

50000

1.5e+05

2e+05

1e+05
Time

FIG. 11: Relative error given by ε(t) =

(Tsettle, Tf it, Tproj) = 103
restarted from its low dimensional representation given by

(1, 1, 0): After each (Tsettle + Tf it) interval, the MC evolution is
(dotted line) or

i
P
g , . . . , α(4)
α(1)
g

P

×

h

(cid:2)

(cid:3)

(cid:27)

4
r=1

α(r)
g (t)

−

(cid:26)

¯α(r)(t)

2

/

4
r=1

¯α(r)(t)

2

1/2

with

n

o

g , . . . , α(8)
α(1)
g

(solid line).

n

o

tive transitions or bifurcations of the macroscopic behavior, marginally stable or unstable
stationary states may be diﬃcult to identify through direct microscopic simulations, while
coarse timestepping holds promise when combined with traditional bifurcation algorithms
[7, 9, 29].

It appears, therefore, that a modeler would ultimately gain in obtaining quantitative
computational answers eﬃciently, but perhaps lose in the fundamental understanding of a
physical process that macroscopic model equations would oﬀer. Therefore a promising re-
search direction is to use such algorithms to test the validity of explicit closures that assume
slaving of certain higher order moments of the evolving distribution to lower order ones. In
the chemotaxis context, when signal transduction and corresponding motor response of the
cell to an external signal are taken into account as we do here, macroscopic model equa-
tions derived systematically from the microscopic description do not exist. The assumption
implicit our the coarse integration algorithm was that the macroscopic description closes at
the level of the spatial density distribution. In one spatial direction, for example, it would
be interesting to learn when this assumption breaks down, requiring separate evolution of
right-going, left-going and tumbling cell density distributions.

More generally, we believe that the approach illustrated here for coarse time integration
of a Monte Carlo description of bacterial chemotaxis, is broadly applicable with diﬀerent
types of microscopic simulators describing, for example, Brownian, Lattice-Boltzmann, or

20

0.02

0.01

r
o
r
r
E
e
v

 

i
t
a

l

e
R

0

0

50000

1.5e+05

2e+05

1e+05
Time

FIG. 12: Comparison of relative errors for CI solutions (using local SVD basis functions) cor-
responding to two diﬀerent ﬂagellar reinitialization schemes. The signal transduction variables
were initialized to their local equilibrium values, ~uj =
. In one case, all ﬂagella were
}
started in the CW state, shown in the thin solid line; in the second case, all ﬂagella were started
in the CCW state, with those cells to the left (right) of the chemoattractant peak running right
(left), shown in the thick dashed line. The points correspond to averages over NMC = 5 realizations
starting from diﬀerent random number seeds. The error bars denote the error on the mean, σ¯ε.

0, f (S(xj))

{

molecular dynamics, and leading to emergent macroscopic dynamic behavior. Such a hybrid
scheme allows eﬃcient simulation of the macroscopic behavior, and may provide insight into
macroscopic model equations.

ACKNOWLEDGEMENTS

The work reported here was supported by the Princeton Council on Science and Technol-
ogy Fellowship (SS), NIH Grant #GM29123 and NSF Grant #DMS 0074043 (HGO), and
AFSOR (Dynamics and Control) and NSF-ITR grants (CWG and IGK).

[1] V. B. Shenoy, R. Miller, E. B. Tadmor, D. Rodney, R. Phillips and M. Ortiz, J. Mechanics

and Phys. Solids 47, 611 (1999).

[2] A. L. Garcia, J. B. Bell, W. Y. Crutchﬁeld and B. J. Alder, J. Comp. Phys. 154, 134 (1999).
[3] I. G. Kevrekidis, C. W. Gear, J. M. Hyman, P. G. Kevrekidis, O. Runborg and K.
Theodoropoulos, submitted to Comm. Math. Sciences, August 2002; Can be obtained as

21

physics/0209043 at arXiv.org.

[4] K. Theodoropoulos, Y. H. Qian and I.G.Kevrekidis, Proc. Natl. Acad. Sci. 97, 9840 (2000).
[5] C. W. Gear, I. G. Kevrekidis and C. Theodoropoulos, Comp. Chem. Engng. 26, 941 (2002).
[6] J. Li, P. G. Kevrekidis, C. W. Gear and I.G.Kevrekidis, SIAM MMS; Can be obtained as

physics/0212034 at arXiv.org.

[7] A. G. Makeev, D. Maroudas, and I. G. Kevrekidis, J. Chem. Phys. 116, 10083 (2002).
[8] A. G. Makeev, D. Maroudas, A. Z. Panagiotopoulos and I. G. Kevrekidis, J. Chem. Phys.

117, 8229 (2002).

[9] C. Siettos, M. D. Graham and I. G. Kevrekidis, J. Chem. Phys. 118, 10149 (2003); Can be

obtained as cond-mat/0211455 at arXiv.org.

[10] G. Hummer and I.G.Kevrekidis, J. Chem. Phys. 118, 10762 (2003); Can be obtained as

physics/0212108 at arXiv.org.

[11] M. Melchior and H. C. Oettinger, J. Chem. Phys. 103, 9506 (1995).
[12] M. Melchior and H. C. Oettinger, J. Chem. Phys. 105, 3316 (1996).
[13] H. G. Othmer and T. Hillen, SIAM JAM 62, 1222 (2002).
[14] R. M. Macnab and D. E. Koshland, Proc. Natl. Acad. Sci. 69, 2509 (1972); S. M. Block, J.
E. Segall, and H. C. Berg, J. Bacteriol. 154, 312 (1983); J. E. Segall, S. M. Block, and H. C.
Berg, Proc. Natl. Acad. Sci. 83, 8987 (1986); J. B. Stock and M. G. Surette in Escherichia
coli and Salmonella, Cellular and Molecular Biology, eds. F. C. Neidhardt et al., 1103 (1996);
J. Stock and S. Da Re, Encyclopedia of Microbiology 1, 772 (2000).

[15] N. Barkai and S. Leibler, Nature 387, 913 (1997).
[16] P. A. Spiro, J. S. Parkinson and H. G. Othmer, Proc. Natl. Acad. Sci. 94, 7263 (1997).
[17] C. J. Morton-Firth and D. Bray, Journal of Theoretical Biology 192, 117 (1998).
[18] H. C. Berg and E. M. Purcell Biophysical Journal 20, 193 (1977).
[19] H. G. Othmer and P. Schaap, Comments on Theoretical Biology 5, 175 (1998).
[20] S. M. Block, J. E. Segall and H. C. Berg, Journal of Bacteriology 154, 312 (1983).
[21] R. M. Macnab, in Two-component Signal Transduction, J. A. Hock and T. J. Silhavy eds.,

181 (1995).

[22] P. Cluzel, M. Surette and S. Leibler, Science 287, 1652 (2000).
[23] B. E. Scharf, K. A. Fahrner, L. Turner and H. C. Berg, Proc. Natl. Acad. Sci. 95, 201 (1998);
L. Turner, A. D. T. Samuel, A. S. Stern, and H. C. Berg, Biophysical Journal 77, 597 (1999).

[24] A. Ishihara, J. E. Segall, S. M. Block, and H. C. Berg, J. Bacteriol. 155, 228 (1983).
[25] F. W. Dahlquist, Science’s STKE (2002),

http://www.stke.org/cgi/content/full/OC sigtrans;2002/132/pe24; D. Bray, Proc.Natl. Acad.
Sci. 99, 7 (2002).

[26] C. W. Gear, “Projective Integration Methods for Distributions”, NEC TR 2001-130, 26

November 2001.

Cambridge, MA (1956).

[27] E. N. Lorenz, Tech Rep 1, MIT, Department of Meteorology, Statistical Forecasting Project,

[28] P. J. Holmes, J. L. Lumley and G. Berkooz, Turbulence, Coherent Structures, Dynamical

Systems and Symmetry, (Cambridge University Press, 1996).

[29] R. Rico-Martinez, C. W. Gear and I. G. Kevrekidis, submitted to J. Comp. Phys.; Can be

obtained as nlin.CG/0307016 at arXiv.org.

22

