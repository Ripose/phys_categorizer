A uniﬁed approach for the solution of the Fokker-Planck equation

Department of Computational Science, National University of Singapore, Singapore 117543

(February 2, 2008)

G. W. Wei

This paper explores the use of a discrete singular convolution algorithm as a uniﬁed approach for
numerical integration of the Fokker-Planck equation. The uniﬁed features of the discrete singular
convolution algorithm are discussed. It is demonstrated that diﬀerent implementations of the present
algorithm, such as global, local, Galerkin, collocation, and ﬁnite diﬀerence, can be deduced from a
single starting point. Three benchmark stochastic systems, the repulsive Wong process, the Black-
Scholes equation and a genuine nonlinear model, are employed to illustrate the robustness and to
test accuracy of the present approach for the solution of the Fokker-Planck equation via a time-
dependent method. An additional example, the incompressible Euler equation, is used to further
validate the present approach for more diﬃcult problems. Numerical results indicate that the present
uniﬁed approach is robust and accurate for solving the Fokker-Planck equation.

0
0
0
2

 
r
p
A
8
2

 

 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 

1
v
4
7
0
4
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

1

I. INTRODUCTION

Much research has been done in the exploration of accurate and stable computational methods for the numerical
solution of the Fokker-Planck equation [1–25]. A detailed comparison of several diﬀerent approaches was given by
Park and Petrosian [26] (see Ref. [25] for a literature review). In fact, the solution of the Fokker-Planck equation,
in particular the nonlinear form of this equation, is still a non-trivial problem. In somewhat a broader sense, ﬁnding
numerical solutions for partial diﬀerential equations (PDEs) is still a challenge owing to the presence of possible
singularities and/or homoclinic manifolds that induce sharp transitions in the solutions [27]. These phenomena can
be observed in many real systems such as black holes in astronomy, shock waves in compressible ﬂuid ﬂow, vortex
sheets in incompressible ﬂow associated with a high Reynolds number, and burst events in the turbulent boundary
layer. The diﬃculties associated with these phenomena can often be characterized by sharp changes occurring in
a very small spatial region which can strongly inﬂuence the global properties of the system. The presence of these
phenomena can be extremely sensitive to numerical algorithms and can easily lead to numerically induced spatial
and/or temporal chaos [28]. At present, there are two major classes of numerical methods for solving PDEs, namely,
global methods and local methods. In global methods, unknown functions and their derivatives are expanded in terms
of a ﬁnite basis set with each element having a global support. The expansion coeﬃcients are often determined by
the method of tau, or Galerkin, or collocation, or others. In the Tau method, the residual for a truncated expansion
is required to be orthogonal to a subset of basis functions used in the expansion, which, together with the boundary
conditions, determines the expansion coeﬃcients.
In the global Galerkin method, a new set of basis functions is
constructed by the superposition of the original basis functions. The requirement of the residual be orthogonal to the
new set of basis functions, together with the boundary conditions, determines the expansion coeﬃcients. In the global
collocation approach, the residual vanishes at a subset of node points of the highest order basis function used in the
expansion. The global collocation is also called pseudospectral method. Three most important local approaches are
ﬁnite diﬀerence, ﬁnite volume and ﬁnite element methods. In ﬁnite diﬀerence methods, the solution is interpolated
in terms of a set of grid values; the spatial derivatives are usually approximated by algebraic expressions involving
nearest neighbor grid points. In ﬁnite volume approaches, the emphasis is on a set of integro-diﬀerential equations
and their associated surface and volume integrations. The values on the boundary of each “numerical molecule” are
usually interpolated by low order schemes. The spatial derivatives are approximated in the same way as those used
in the ﬁnite diﬀerence methods. Finite element methods form one of the most versatile classes of numerical methods.
Depending on the system under study, ﬁnite element methods can be formulated either in terms of the method of
weight residuals or in terms of variational principles. Usually, PDEs are integrated by using a set of trial functions,
each with a small region of support. The solution is represented by linear superpositions of these trial functions.

Global methods are highly localized in their spectral space, but are unlocalized in the coordinate space. By contrast,
local methods have high spatial localization, but are delocalized in their spectral space. In general, global methods are
much more accurate than local methods, while the major advantage of local methods is their ﬂexibility for handling
complex geometries and boundary conditions. Moreover, the use of global methods is usually restricted to structured
grids, whereas, local methods can be implemented to block-structured grids and even unstructured grids.

There were hectic debates among the numerical computation communities over the advantages and disadvantages
of various numerical methods in the past a few decades. These debates stimulated the development of powerful
numerical methods for a wide variety of science and engineering applications. Such development has, in association
with the availability of inexpensive high-performance computers, led to the establishment of numerical simulations as
an alternative approach for researches and applications. The connection of various numerical methods has always been
an important research topic. Finlayson discussed the relation between the Galerkin and the Ritz variational principle
[29]. Canuto et al rearranged their spectral basis functions so that some global collocation method can be regarded as a
special case of certain global Galerkin methods [30]. Fornberg addressed the common feature between pseudospectral
methods and high order ﬁnite diﬀerence methods [31]. The connection between global and local methods can also be
realized in the framework of the method of weighted residual by choosing trial functions of either piecewise Lagrange
polynomials or global Lagrange polynomials. The connection of methods of ﬁnite element, ﬁnite diﬀerence and ﬁnite
volume is now well understood [32]. However, to our knowledge, none has reported a uniﬁed scheme for the discussion
of all of the abovementioned methods.

In previous work [25], we proposed a discrete singular convolution (DSC) algorithm and demonstrated its use for
the numerical solution of Fokker-Planck equation via eigenfunction expansions. The DSC algorithm was shown to
be a potential numerical approach for Hilbert transform, Abel transform, Radon transform and delta transform.
Three standard problems, the Lorentz Fokker-Planck equation, the bistable model and the Henon-Heiles system, were
utilized to test the accuracy, reliability, and speed of convergence of the DSC-eigenfunction approach. All results
were in excellent agreement with those of previous methods in the ﬁeld. Recently, the DSC algorithm has been
successfully tested for integrating the sine-Gordon equation with initial values close to homoclinic orbits [33], which is

2

extremely diﬃcult to compute because of the possible presence of numerical chaos [28]. Excellent results are obtained
for solving the Navier-Stokes equation and for engineering structural analysis [34]. The purpose of the present paper
is twofold. First, we study the uniﬁed features of the DSC algorithm for treating partial diﬀerential equations. This
is accomplished by focusing on the DSC kernels of the delta type and their approximations. Second, we explore the
use of the DSC as a uniﬁed approach for solving the Fokker-Planck equation via direct explicit time propagations.
The eigenfunction expansion approach provides a Schr¨odinger-equation type picture for the understanding of the
Fokker-Planck equation. However, its use is restricted to a certain class of Fokker-Planck operators (essentially for
the Fokker-Planck operators their equivalent Schr¨odinger potentials are bounded from below). The present direct
approach is applicable to a wider class of problems. These two DSC-based approaches have the same level of accuracy
for the numerical solution of the Fokker-Planck equation. They are complementary to each other for solving a wide
variety of Fokker-Planck systems arising from practical situations.

This paper is organized as the follow. The uniﬁed features of the DSC algorithm are discussed in Section II. We
demonstrate that, the present DSC algorithm provides a uniﬁed framework for solving the Fokker-Planck equation,
and partial diﬀerential equations in general. In particular, we show that various diﬀerent implementations of the DSC
algorithm, such as global, local, Galerkin, collocation, and ﬁnite diﬀerence, can be deduced from a single starting
point. The application of the present DSC approach to the solution of the Fokker-Planck equation and Euler equation
is presented in Section III. We use four examples to illustrate the present approach. The ﬁrst example is the repulsive
Wong process which is useful for testing the ability of handling monomodality-bimodality transition. The second
example is the Black-Scholes equation for option derivatives. This is interesting stochastic model for option pricing in
ﬁnancial market. The third case treated is a nonlinear stochastic model which has certain connection to a mean-ﬁeld
model for self-organization processes in biological systems such as muscle contraction. Notably, all of these problems
are treated by an explicit time-propagation approach in contrast to the eigenfunction expansion used in our previous
work [25]. Since the abovementioned examples are of strong parabolic type, we consider an additional problem, the
incompressible Euler equation, to further validate the DSC approach for more diﬃcult problems. The incompressible
Euler equation is chosen because its equations for velocity vector and pressure ﬁeld are of strong hyperbolic type and
elliptic type, respectively. Thus, this last example is complimentary to other three examples from the point of view
of numerical analysis. This paper ends with a discussion.

II. PROPERTIES OF THE DISCRETE SINGULAR CONVOLUTION

This section presents the properties of the discrete singular convolution (DSC) algorithm for solving diﬀerential
equations. The ﬁrst subsection addresses the uniﬁed features of the DSC algorithm in the line of the method of
weighted residuals. Relevant properties of DSC trial functions are discussed the second subsection.

A. Uniﬁed features

Without the loss of generality, it is assumed that at a ﬁxed time, a stochastic process is governed by a diﬀerential
equation. To solve the diﬀerential equation, one can start with either by approximating the original diﬀerential
operator or by approximating the actual solution of the diﬀerential equation while maintaining the original diﬀerential
operator. The latter is accomplished by explicitly deﬁning a functional form for approximations. Let us assume that
the diﬀerential equation has the form

Lu(x) = f (x), x ∈ Ω,

(1)

where L is a linear operator and u(x) is the unknown solution of interest. Here f (x) is a known force term, Ω denotes
the domain over which the diﬀerential equation applies.
The approximate solution is sought from a ﬁnite set of N DSC trial functions of a given resolution α, denoted by
SN,M
α,σ with M being the half width of support of each element. Here σ is a regularization parameter for improving the
regularity of the set. The case of regularization free is easily obtained by setting σ → ∞. Elements of the set SN,M
can be explicitly given by {φM
α,σ;N}. For a given computational domain, the resolution parameter α
is determined by N .
α,σ;k} is that when the trial function is free of regularization,

An important property of the DSC trial functions {φM

each member of the set is a reproducing kernel at highest resolution

α,σ;1, φM

α,σ;2, ..., φM

α,σ

< φM

α,σ;k, η >= η(xk),

lim
α→∞

3

(2)

where < ·,· > denotes the standard inner product. In fact, if an appropriate basis is used for φ and the limit on σ is
taken, φ of each resolution can be a reproducing kernel for L2 functions bandlimited to appropriate sense. In general,
we require the low pass ﬁlter property that for given α 6= 0, σ 6= 0 and M ≫ 0

< φM

α,σ;k, η >≈ η(xk).

(3)

This converges uniformly when the resolution is reﬁned, e.g., α → ∞. Many examples of such DSC trial functions are
given in Refs. [25] and [36]. Further discussion on these functions is given in the next subsection. Equations (2) and
(3) are special requirements satisﬁed by the DSC kernels of delta type [25].

In the present DSC approach, an approximation to the function of interest u(x) can be expressed as a linear

combination

U N,M

α,σ (x) =

N

Xk=1

Uα,σ;kφM

α,σ;k(x),

(4)

where x is an independent variable and Uα,σ;k is a DSC approximation to the solution wanted at point xk. This
structure is due to the DSC trial function property (3) and it dramatically simpliﬁes the solution procedure in
practical computations.

In this formulation, we choose the set SN,M

is a good approximation to u(x). To determine Uα,σ;k, we minimize the amount by which U N,M
the original governing equation (1). A measure of this failure can be deﬁned as

α,σ a priori, and then determine the coeﬃcients {Uα,σ;k} so that U N,M

α,σ (x)
α,σ (x) fails to satisfy

RN,M
α,σ (x) ≡ LU N,M

α,σ (x) − f (x),

(5)

α,σ (x) is constructed by using the DSC trial functions, φM

where RN,M
α,σ (x) is the residual for particular choices of resolution, regularization and half width of the support. Note
that Eq. (5) is similar to the usual statement in the method of weighted residuals. However, the approximation
U N,M
α,σ;k(x), in the present treatment. Let Eq. (1) and its
associated boundary conditions be well-posed, then there exists a unique solution u(x) which generally resides in an
inﬁnite-dimensional space. Since the DSC approximation U N,M
is constructed from a ﬁnite-dimensional set, it is
α,σ
generally the case that U N,M

α,σ (x) 6= u(x) and therefore RN,M

α,σ (x) 6= 0.

α,σ (x) by forcing it to zero in a weighted average sense over the domain Ω. A

Galerkin. We seek to optimize RN,M
convenient starting point is the Galerkin

ZΩ

RN,M

α,σ (x)φM′

α′ ,σ′;l(x)dx = 0, φM′

α′,σ′;l(x) ∈ SN ′,M′

α′,σ′

,

(6)

where the weight set SN ′,M′
α′,σ′
(6) as a DSC-Galerkin statement.

can be simply chosen being identical to the DSC trial function set SN,M

α,σ . We refer Eq.

Collocation. First, we note that in view of Eq. (2), the present DSC-Galerkin statement reduces to a collocation

one at the limit of α′

lim

α′→∞ZΩ

RN,M

α,σ (x)φM′

α′ ,σ′;l(x)dx = RN,M

α,σ (xl) = 0,

(7)

where {xl} is the set of collocation points. However, in digital computations, we cannot take the above limits. It
follows from the low pass ﬁlter property of the DSC trial functions, Eq. (3), that

ZΩ

RN,M

α,σ (x)φM′

α′,σ′;l(x)dx ≈ RN,M

α,σ (xl) ≈ 0.

(8)

It can be proven that for appropriate choice of SN ′,M′
α′,σ′
diﬀerence between the true DSC-collocation,

, the ﬁrst approximation of Eq. (8) converges uniformly. The

and the Galerkin induced collocation, (8), diminishes to zero for appropriate DSC trial functions.

Global and local. Global approximations to a function and its derivatives are realized typically by a set of truncated
L2(a, b) function expansions. It is called global because the values of a function and its derivatives at a particular

RN,M

α,σ (xl) = 0,

lim
α′→∞

(9)

4

point xi in the coordinate space involve the full set of grid points in a computational domain Ω. Whereas a local
method does so by requiring only a few nearest neighbor points. In the present DSC approach, since the choices of M
and/or M′ are independent of N , one can choose M and/or M′ so that a function and its derivatives at a particular
point xl are approximated either by the full set of grid points in the computational domain Ω or just by a few nearest
neighbor grid points. In fact, this freedom for the selection of M endows the DSC algorithm with controllable accuracy
for solving diﬀerential equations and the ﬂexibility for handling complex geometries.

Finite Diﬀerence. In the ﬁnite diﬀerence method, the diﬀerential operator is approximated by diﬀerence operations.
In the present approach, the DSC-collocation expression of Eq. (8) is equivalent to a 2M + 1 (or 2M ) term ﬁnite
diﬀerence method. This follows from the fact that the DSC approximation to the nth order derivative of a function
can be rewritten as

dqu

dxq(cid:12)(cid:12)(cid:12)(cid:12)x=xk

cq
kl,M =

≈

k+M

Xl=k−M

cq
kl,M u(xl),

dq
dxq φM

.

α,σ;l(x)(cid:12)(cid:12)(cid:12)(cid:12)x=xk

(10)

(11)

where cq

kl,M are a set of DSC weights for the ﬁnite diﬀerence approximation and are given by

Obviously, for each diﬀerent choice of φM
α,σ, we have a diﬀerent DSC-ﬁnite diﬀerence approximation. Hence, the
present DSC approach is a generalized ﬁnite diﬀerence method. This DSC-ﬁnite diﬀerence was tested in previous
studies [36]. When M = 1, the DSC-ﬁnite diﬀerence approximation reaches its low order limit and the resulting
matrix is tridiagonal. In this case, the present DSC weights cq
kl,M can always be made exactly the same as those
of the second order central diﬀerence scheme (i.e.
∆2 for the
second order derivative. Here ∆ is the grid spacing.) of the standard ﬁnite diﬀerence method by appropriately
choosing the parameter σ. However, even in this case, the DSC-ﬁnite diﬀerence approximation does not have to be
the same as the standard ﬁnite diﬀerence scheme and can be optimized in a practical application by varying σ.

2∆ for the ﬁrst order derivative and 1

2∆ , 0,− 1

∆2 ,− 2

∆2 , 1

1

B. DSC trial functions

There are many DSC trial functions that satisfy Eq. (3). The requirement of Eq. (3) can be regarded as an
approximate reproducing kernel or quasi reproducing kernel. The reason for using an approximate reproducing kernel
can be understood from the following analysis of Shannon’s kernel sin(αx)

. Shannon’s kernel is a delta sequence

πx

sin(αx)

πx

lim
α→∞

= δ(x),

(12)

where δ(x) is the delta distribution which can be regarded as a universal reproducing kernel because its Fourier
transform is the unit. However, such a universal reproducing kernel cannot be directly used in digital computations
because it is a distribution (Precisely, it is belongs to Sobolev space of order -1, H−1.) and it does not have a value
anywhere in the coordinate space. Therefore, in certain sense, constructing a reproducing kernel in an appropriate
L2(a, b) space is equivalent to ﬁnding a sequence of approximation of the delta distribution in the L2(a, b). In fact,
Shannon’s kernel is an element of the Paley-Wiener reproducing kernel Hilbert space B2
π

f (x) =Z ∞

−∞

f (y)

sin π(x − y)
π(x − y)

dy,

∀f ∈ B2
π,

(13)

π indicates that, in its Fourier representation, the L2 function f vanishes outside the interval [−π, π].
where ∀f ∈ B2
What is important for digital computations is the fact that the Paley-Wiener reproducing kernel Hilbert space has a
sampling basis Sk(x)

Sk(x) =

sin π(x − yk)
π(x − yk)

, yk = k, ∀k ∈ Z,

(14)

where symbol Z denotes the set of all integers. Expression (14) provides a discrete representation of every (continuous)
function in B2
π

5

f (x) = Xk∈Z

f (yk)Sk(x),

∀f ∈ B2
π.

(15)

This is Shannon’s sampling theorem and is particularly important to information theory and the theory of sampling.
Note that Shannon’s kernel is obviously interpolative on Z

Sn(xm) = δn,m,

(16)

where δn,m is the Kronecker delta function. Computationally, being interpolative is of particular importance for
numerical accuracy and simplicity.

sin(πx)

πx

In wavelet analysis,

it is an unsmoothed, ideal low pass ﬁlter.

is Shannon’s wavelet scaling function and its Fourier transform is a characteristic
function, i.e.
In physical language, it is a projection to the frequency
subband [−π, π]. By the Heisenberg uncertainty principle, such a (sharp) projection must be an inﬁnite impulse
response (IIR) ﬁlter. The usefulness of such a ﬁlter is limited because it is de-localized in the coordinate space
and requires inﬁnitely many sampling data. In practical computations, a truncation is required, which leads to large
truncation error and even worse, numerical instability. To improve the smoothness and regularity of Shannon’s kernel,
we introduce a regularization

where Rσ is a regularizer which has properties

Φσ(x) =

sin(πx)

πx

Rσ(x)

(σ > 0),

and

Rσ(x) = 1

lim
σ→∞

Rσ(0) = 1.

(17)

(18)

(19)

Here Eq. (18) is a general condition that a regularizer must satisfy, while Eq. (19) is speciﬁcally for a delta regularizer,
which is used in regularizing a delta kernel. Various delta regularizers can be used for numerical computations. An
excellent one is the Gaussian

Rσ(x) = exp(cid:20)−

x2

2σ2(cid:21) .

(20)

An immediate beneﬁt of the regularized Shannon’s kernel, Eq. (17), is that its Fourier transform is inﬁnitely diﬀer-
entiable because the Gaussian is an element of the Schwartz class functions. Qualitatively, all kernels of the Dirichlet
type oscillate in the coordinate representation. Speciﬁcally, Shannon’s kernel has a long tail which is proportional
to 1
x , whereas, the regularized kernels decay exponentially fast, especially when the σ is very small. In the Fourier
representation, regularized Shannon’s kernels have an “optimal” shape in their frequency responses. Of course, they
all reduce to Shannon’s low pass ﬁlter at the limit

Quantitatively, one can examine the normalization of Φσ(x)

lim
σ→∞

Φσ(x) = lim
σ→∞

sin πx

πx

e− x2

2σ2 =

sin πx

πx

.

(−1)k
k!(2k + 1)(cid:18) πσ

√2(cid:19)2k

2 Z ∞

0

e− t2

2σ2 −πtdt

∞

Z Φσ(x)dx = ˆΦσ(0)
= √2πσ
Xk=0
√2(cid:19)
= erf(cid:18) πσ
= 1 −r 2
e− σ2 π2
√2(cid:19)
= 1 − erfc(cid:18) πσ
6= 1,

1
σ

π

6

(21)

(22)

(23)

(24)

0 e−t2

where erf(z) = 2√π R z
dt is the error function and erfc(z) is the complementary error function. Note that for
) is positive deﬁnite. Thus, ˆΦσ(0) is always less than unity except at the limit of σ → ∞.
a given σ > 0, erfc( πσ√2
Therefore, Φσ(x) is no longer a reproducing kernel. However, we argue that Φσ(x) is an approximate reproducing
kernel because when we choose σ ≫ √2/π, which is the case in many practical applications, the residue term, erfc( πσ√2
),
approaches zero very quickly. As a result, ˆΦσ(0) is extremely close to unity. As trial functions, regularized Shannon’s
kernels do not form a sampling basis. They are no longer orthogonal in general. However, they just slightly miss the
orthogonality and the requirement of a basis.

For numerical computations, it turns out that the approximate reproducing kernel has much less truncation errors
for interpolation and numerical diﬀerentiations. Qian and the present author [37] have recently given the following
theorem for truncation errors.
Theorem Let f be a function f ∈ L2(R)∩ Cs(R) and bandlimited to B, (B < π
t ∈ R and σ > 0, denote g(x) = f (x)Hk( t−x√2σ

), where Hk(x) is the kth order Hermite polynomial. If g(x) satisﬁes

∆ , ∆ is the grid spacing). For a ﬁxed

for x ≥ t + (M1 − 1)∆, and

g′(x) ≤ g(x)

(x − t)

σ2

g′(x) ≥ g(x)
for x ≤ t − M2∆, where M1, M2 ∈ N , then for any s ∈ Z +
f (n∆)(cid:20) sin π

⌈ t
∆⌉+M1

∆ (t − n∆)
∆ (t − n∆)

π

(x − t)

σ2

(25)

(26)

exp(−

(t − n∆)2

2σ2

)(cid:21)(s)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)L2(R)

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)

2πσ( π

∆ ⌉−M2
kf (s)(t)kL2(R)
∆ − B) exp( σ2( π

Xn=⌈ t

f (s)(t) −
√3"
≤
+kf (t)kL2(R)Pi+j+k=s
+kf (t)kL2(R)Pi+j+k=s

exp( (M2∆)2

2σ2

)

2σ2

∆ −B)2
2

)

s!πi−1Hk( −M1∆
√2σ

)

i!k!∆i−1(√2σ)k((M1−1)∆)j+1

exp( (M1∆)2

)

s!πi−1Hk( −M2 ∆
√2σ

i!k!∆i−1(√2σ)k(M2∆)j+1

)




,

(27)

where superscript, (s), denotes the sth order derivative. The proof and detailed discussion (including a comparison
with the truncation errors of Shannon’s sampling theorem) are given in Ref. [37] and are beyond the scope of this
paper.

This theorem provides a guide to the choice of M , σ and ∆. For example, in the case of interpolation (s = 0), if

the L2 norm error is set to 10−η (η > 0), the following relations can be deduced from Eq. (27)

and

r(π − B∆) >p4.61η,

(28)

(29)

where r = σ/∆ (The choice of σ is always proportional to ∆ so that the width of the Gaussian envelope varies with
the central frequency). The ﬁrst inequality states that for a given grid size ∆, a large r is required for approximating
high frequency component of an L2 function. The second inequality indicates that if one chooses the ratio r = 3, then
the half bandwidth M ∼ 30 can be used to ensure the highest accuracy in a double precision computation (η = 15).
However, for lower accuracy requirement, a much smaller half bandwidth can be used. In general, the value of r is
proportional to M . The use of M values is determined by the accuracy requirement. This theoretical estimation is
in excellent agreement with a previous numerical test [36].

M
r

>p4.61η,

7

III. ILLUSTRATIVE CALCULATIONS

In this section, we illustrate the use of the present approach for solving the Fokker-Planck equation and the
incompressible Euler equation. Many DSC kernels are discussed in the previous work [25,36] and they can be used as
the DSC trial functions. For simplicity, we focus on three DSC kernels, a regularized Shannon’s kernel (RSK),

φM

π

∆ ,σ;k(x) =

sin π
∆ (x − xk)
∆ (x − xk)

π

exp(cid:20)−

(x − xk)2

2σ2

(cid:21) ,

a regularized Dirichlet kernel (RDK),

φM

π

∆ ,σ;k(x) =

and a regularized Lagrange kernel (RLK)

sin(cid:2) π
(2m + 1) sinh π

∆ (x − xk)(cid:3)
2m+1i

x−xk

∆

exp(cid:20)−

(x − xk)2

2σ2

(cid:21) ,

φM

π

∆ ,σ;k(x) =

2m

Yi6=k

x − xi
xk − xi

exp(cid:20)−

(x − xk)2

2σ2

(cid:21) ,

(30)

(31)

(32)

for our numerical test. Note that the resolution is given by α = π
∆ which is the frequency bound in the Fourier
representation. The goal of this section is to test the present method for the solutions of the Fokker-Planck equation
via time propagation and the incompressible Euler equation. For the numerical solution of the Fokker-Planck equation,
we choose σ = 3.8∆ for the RSK and RDK, σ = 2.8∆ for the RLK, with π/∆ being the resolution. In fact, a wide
range of σ values can be used to deliver excellent results. The half bandwidth, M , can be chosen to interplay between
the local limit and the global limit and is set to 40 in all calculations. Finally, m controls the order of the regularized
Dirichlet and Lagrange kernels and is set to 40 in all calculations (note that the selection of m is independent of the
grid used in the computation). It is noted that all of the abovementioned DSC trial functions are of Schwartz class
and are capable of auto-regularizing when used as integral kernels. The fourth order explicit Runge-Kutta scheme is
used for time discretization. Details of these computations are described in the ﬁrst three subsections. For treating
the incompressible Euler equation, many other DSC parameters are tested as indicated in the last subsection. Double
precision is used in all calculations.

A. The repulsive Wong process

One of important stochastic systems is the repulsive Wong process [38–40,20], given by

dx = 2γ tanh(x)dt + √2dFt,

where dFt is the Gaussian white noise which has the standard statistical properties

and

< dFt >= 0

< dFt, dFτ >= δ(| t − τ |).

(33)

(34)

(35)

The repulsive Wong process is Markovian due to the deriving Gaussian white noise term. Its transition probability

density is governed by the Fokker-Planck equation of the form [38–40]

∂f (x, t)

∂t

= −2γ

∂[tanh(x)f (x, t)]

∂x

+

∂2f (x, t)

∂x2

,

with the usual initial condition

and the normalization

f (x, 0) = δ(x − x0),

8

(36)

(37)

For γ = 1, the solution [39,40] of the Fokker-Planck equation (36) is analytically given by (for x0 = 0)

Z ∞

−∞

f (x, t)dt = 1.

f (x, t) =

1

2√4πt(cid:20)e−

(x−x−

)2

4t + e−

(x−x+ )2

4t

(cid:21) ,

(38)

(39)

where x± = ±2t are centers of two moving Gaussians. Here the superposition of two Gaussians gives rise to a
monomodality-bimodality transition as time increases. The Wong process is useful for illustrating the connection
between stochastic processes and quantum measurements. It is also useful for distinguishing spectrum diﬀerences
between the Master equation and its Fokker-Planck equation approximations.

The accurate simulation of the Wong process is not a simple task because of the monomodality-bimodality transition.
Two Gaussian peaks centered at x± = ±2t move apart as time increases. The computational domain is to be
suﬃciently large in order to avoid boundary reﬂection (Otherwise, more complicated techniques, such as absorption
boundaries, are to be implemented.). In the present computations, the resolution is chosen as π
∆ = 10π. The initial
functions are approximated by a unit impulse function located at 0. The equation (36) is integrated up to 10 time
units with a time increment of 0.001. The errors for a wide range of propagation times are listed in TABLE I and are
measured by error norms of L2 and L∞. It is seen that the present uniﬁed approach is extremely accurate and reaches
machine precision. All of the DSC kernels behave very similar to each other and provide the same level of accuracy
and speed of convergence. In fact, other DSC kernels, such as regularized modiﬁed Dirichlet kernel, provide similar
results. The results of the RSK and RDK are slightly more accurate than those of the RLK. It is evident that the
present uniﬁed method, in associated with the DSC trial functions, is capable of delivering extremely high accuracy
and numerical stability for the Wong process. To our knowledge, the DSC solution for this system is the best to the
date.

B. The Black-Scholes equation

The Fokker-Planck equation and stochastic analysis have interesting applications in mathematical modeling of
ﬁnancial market option pricing. Consider a writer of a European call option on a stock, he is exposed to the risk of
unlimited liability if the stock price rises acutely above the strike price. To protect his short position in the option,
he should consider purchasing certain amount of stock so that the loss in the short position in the option is oﬀset by
the long position in the stock. In this way, he is adopting a hedging procedure. A hedge position combines an option
with its underlying asset so as to achieve the goal that either the stock protects the option against loss or the option
protects the stock against loss. This risk-monitoring strategy has been commonly used by practitioners in ﬁnancial
markets. The most well-known stochastic model for the equilibrium condition between the expected return on the
option, the expected return on the stock and the riskless interest rate is the Black-Scholes equation [41]

∂c
∂t

=

ν2
2

S2 ∂2c

∂S2 + rS

∂c
∂S − rc,

(40)

where S is the asset price which undergoes geometric Brownian motion, c(S, t) the call price, ν the volatility and r
the constant riskless interest rate. Black-Scholes equation is a fundamental equation in ﬁnance and economics and is
also an excellent example application of stochastic analysis. By a simple transformation

and

x = ln S,

f (x, t) = ertc(x, t),

the Black-Scholes equation is transformed into the Fokker-Planck equation of the standard form

∂f
∂t

=(cid:18)r −

ν2

2 (cid:19) ∂f

∂x

+

ν2
2

∂2f
∂x2 .

(41)

(42)

(43)

The numerical simulation of the Black-Scholes equation and its generalized versions is an important issue in ﬁnancial
analysis and computational ﬁnance community [42–45]. Essentially, all existing numerical methods are tested for
potential usefulness in estimating the option derivatives because both computational accuracy and eﬃciency are very

9

important to option modeling and risk estimation. In the present time-dependent approach, the resolution is set to
∆ = 2π and the time increment is chosen as 0.01. For simplicity, we choose ν2
π
2 = 0.5 and r = 0.7 in our calculations.
We chosen our initial distribution as a unit impulse function located at x = 0, which is a poor approximation to the
true delta distribution. Obviously, had one started with a smooth initial function, or used a denser grid, one would
have obtained much higher accuracy at earlier times as well. We have veriﬁed this computationally, but these results
are not presented. Both L2 and L∞ error analyses are used to evaluate the quality of the DSC approach, the results
of which are listed in TABLE II. To our knowledge, the present time-dependent DSC approach provides the most
accurate numerical results yet obtained for the Black-Scholes equation.

As in the ﬁrst example, three DSC kernels provide extremely similar results in solving the Black-Scholes equation.
This is not an isolated coincidence. In fact, we can come up a number of other DSC kernels with all of their results
being very similar to those of the present three kernels.

C. A nonlinear stochastic model

To illustrate the accuracy and robustness of the present approach further, we choose the following nonlinear stochas-

tic model

∂f (x, t)

∂t

=

∂[(ωx + θ < x(t) >)f (x, t)]

∂x

+ D

∂2f (x, t)

∂x2

,

where < x(t) > is the ﬁrst moment of the distribution function

< x(t) >=Z ∞

−∞

xf (x, t)dx,

and ω, θ and D are constant. The initial probability distribution is also given by

f (x, 0) = δ(x − x0).

(44)

(45)

(46)

Equation (44) is a true nonlinear stochastic model since the instantaneous position average depends on the distribution
function. This is one of few analytically soluble nonlinear systems which are very valuable for testing new numerical
approaches. For example, Drozdov and Morillo have recently employed this system to test their K-point Stirling
interpolation formula ﬁnite diﬀerence method [23]. The exact solution to Eq. (44) is

where < x(t) > and ν(t) are analytically given by

f (x, t) =

exp(cid:20)−

(x− < x(t) >)2

2ν(t)

(cid:21) ,

1

p2πν(t)

and

ν(t) =

respectively. Obviously, ν(t) is the theoretical value of the second moment M2(t)

< x(t) >= x0e−(ω+θ)t

D

ω (cid:0)1 − e−2ωt(cid:1) ,

M2(t) =< x2(t) > − < x(t) >2,

(47)

(48)

(49)

(50)

which can also be used as a measure of computational accuracy.

In the present computations, the resolution is chosen as π

20 π. The time increment is taken as ∆t = 0.005. In
this example, the errors are measured by error norms of L1 and L∞ from which all other error norms, such as the
L2 error norm, can be interpolated. The L1 and L∞ errors are listed in TABLE III, for D = 0.1, ω = 1, θ = 2 and
x0 = 2.0422. The initial accuracy of computations is hindered by the poor approximation of the impulse function
to the Dirac delta function. However, the auto-regularization property of the Schwartz class trial functions enables
the numerical integration to stabilize at smooth solution and eventually reach the machine precision at a slightly late
time.

∆ = 239

10

D. The Euler equation

All cases considered in the last three subsections are of strong parabolic type with a solution which becomes more
and more ﬂat and smooth as time increases. In this subsection, we consider an additional problem, the incompressible
Euler equation, to conﬁrm that the results obtained for the Fokker-Planck equation are not due to the parabolic nature.
We also use this example to demonstrate the inter-connection between the collocation and the ﬁnite diﬀerence, and
between the local and the global. It is hoped that this additional example helps to build conﬁdence for using the
DSC approach for treating more diﬃcult problems. Conceptually and numerically, it is convenient to describe the
incompressible Euler equation from the point of view of the incompressible Navier-Stokes equation

+ v · ∇v = ∇p +

∂v
∂t
∇ · v = 0,

1
Re∇2v,

(51)

(52)

where v is the velocity ﬁeld vector, p is the pressure ﬁeld and Re is the Reynolds number. The Euler equation is
attained by setting Re= ∞. Finding a general solution to the Euler equation is not an easy job. In the present study,
we consider a solution domain of [0, 2π] × [0, 2π] with periodic boundary conditions. Under such a constraint, the
Navier-Stokes equation (51) exists an exact solution

u(x, y, t) = − cos(x) sin(y)e− 2t
v(x, y, t) = sin(x) cos(y)e− 2t

Re

Re

p(x, y, t) = −

1
4

[cos(2x) + cos(2y)]e− 4t
Re ,

(53)

where (u, v) are the velocity components in the x-direction and y-direction, respectively. Note that, for the Euler
equation, the solution (53) does not decay with time.

In the present study, we use a standard approach for treating the incompressible Navier-Stokes equation, i.e.
deriving a Poisson equation for the pressure from the incompressible condition. The velocity ﬁelds are iterated by
using the implicit Euler scheme. At time tn+1, there are two coupled equations for the velocity ﬁelds

(cid:18) 1
Re∇2 −
(cid:18) 1
Re∇2 −

x

1

∆t(cid:19) un+1 = pn+1/2
∆t(cid:19) vn+1 = pn+1/2

1

y

+ Sn
x

+ Sn
y ,

and a Poisson equation for the pressure

∇2pn+1/2 = Sn
p .

Here Sn

x , Sn

y and Sn

p are given by

+ (unun

x + vnun
y )

+ (unvn

x + vnvn
y )

un
Sn
x = −
∆t
vn
Sn
y = −
∆t
1
Sn
(un
p =
∆t

x + vn

y ) − (un

x)2 − (vn

y )2 − 2un

y vn
x .

(54)

(55)

(56)

(57)

At each time tn+1, the pressure ﬁeld pn+1/2 is solved according Eq. (56) from the known velocity ﬁeld vector (un, vn).
The velocity ﬁeld vector (un+1, vn+1) is then updated according to Eqs. (54) and (55). These linear algebraic equations
are solved by using a standard (LU decomposition) solver.

The derivatives in Eqs. (54-56) are computed by using the generalized ﬁnite diﬀerence scheme, Eq. (10), and the
required ﬁnite diﬀerence weights are given by Eq. (11). The involved trial functions, φM
α,σ, are given by the regularized
Shannon’s kernel (RSK) [Eq. (30)], the regularized Dirichlet kernel (RDK) [Eq. (31)], and the regularized Lagrange
kernel (RLK) [Eq. (32)]. Here m = 40 is used for both RDK and RLK. We choose a small time increment (∆t = 0.001)
so that the main error is caused by the spatial discretization. The number of grid points in each dimension is chosen
as N = 4, 8, 16 and 32 in various test calculations. The α value is speciﬁed as α = π
2 . For a given N ,
the matrix half bandwidth, M , can be chosen as M ≤ N . In particular, if M = N , the approach has a global (full)

∆ = π
2π
N−1

= N−1

11

computational matrix. For all M < N , the matrix is banded. In the present DSC approach, the connection between
the global and the local can be easily achieved by selecting an M value for a given N . In particular, if M ≪ N , the
DSC approach behaves truly like a ﬁnite diﬀerence scheme. To achieve optimal (or near optimal) accuracy, the σ is
chosen in proportional to M and ∆. When M = 32, 16, 8, 4, 2 and 1, σ
∆ are chosen as 3.2, 2.5, 1.8, 1.2, 0.9 and 0.6 for
both RSK and RDK, and 2.8, 2.0, 1.6 1.0 0.8 and 0.6 for RLK. We compute the L2 and L∞ errors of u for a number
of combinations of N and M and the results are listed in TABLE IV for 4 diﬀerent times (t = 0.5, 1.0, 1.5, 2.0). A
good consistent in accuracy among solutions at diﬀerent times (or equivalently, over 2000 iterations) is observed. The
DSC results are quite accurate when N = M = 4 and are of machine precision when N = M = 32. It is interesting to
note that for ﬁxed M = 4, the results of N = 32 and N = 4 diﬀer little in accuracy. We also checked the DSC-ﬁnite
diﬀerence approximation at the tridiagonal matrix limit (M = 1) and the result is very good for N = 4 (i.e. a total
of 4 interior points in a (2π)2 box).

IV. DISCUSSION

The main purpose of this paper is to discuss the uniﬁed features of the discrete singular convolution (DSC) algorithm
[25]. It is found that the implementations of the DSC algorithm into a number of computational methods can be
deduced from a single starting point, the method of weighted residual. This chain of deduction provides a uniﬁed
approach for solving the Fokker-Planck equation and other diﬀerential equations in general. Some of these deduction
relations are novel to our knowledge.

We demonstrate that by adjusting the support of the DSC trial functions, the DSC algorithm can be easily im-
plemented either as a local method or as a global method. For this reason, the present DSC approach has global
method’s accuracy while maintains local method’s ﬂexibility for handling complex boundary and geometry. In fact,
the solution of the Fokker-Planck equation of a previous paper [25] was obtained by using the global limit. Whereas,
in the present computations, a local approximation is used for all Fokker-Planck problems. A comparison between
global and local DSC treatments is given in solving the Euler equation.

We also show that the DSC implementations of Galerkin and collocation are computationally equivalent, i. e. the
collocation, Eq. (8) can be deduced from the Galerkin, Eq. (6) because of the choice of the DSC trial functions.
Galerkin methods have a profound inﬂuence to the theory of approximations. Both spectral methods and ﬁnite
element methods are often formulated in the framework of the Galerkin approach. There has been a great deal of
argument about advantage and disadvantage of the Galerkin in comparison to many other methods. The present
DSC approach might provide a uniﬁed framework for the discussion of these methods.

The present Galerkin-induced collocation scheme provides a nature base for the realization of ﬁnite diﬀerence
methods. High order ﬁnite diﬀerence is not a new idea in numerical approximations [31]. However, the mathematical
constructions of high order ﬁnite diﬀerence schemes often become too cumbersome to use in practical applications as
the order increases. The present DSC approach provides a simple, systematic algorithm for the generation of ﬁnite
diﬀerence schemes of an arbitrary order. The implementation of this ﬁnite diﬀerence is demonstrated in solving the
Euler equation with a number of diﬀerent matrix bandwidths.

Recently, wavelet theory and techniques have had great success in signal processing, data compression, and telecom-
munication. Two most important features of the wavelet theory are multiresolution analysis and time-frequency lo-
calization. Their potential applications in solving partial diﬀerential equations have been extensively explored [46–51]
in hope to come up with uniﬁed approaches for numerical approximations. However, before wavelet approaches can
be of practical use, a number of technical diﬃculties are to be overcome. In our view, the ﬁrst diﬃculty is the imple-
mentation of boundary conditions in a multiresolution setting. The second diﬃculty is the requirement of suﬃciently
high wavelet regularity to provide suﬃciently weak solutions. Moreover, there is a lack of general and systematic
numerical algorithms for incorporating wavelets in an eﬃcient manner. Nevertheless, the wavelet multiresolution
analysis still has great potential for developing adaptive grid and multigrid algorithms. The present DSC algorithm
is closely related to the wavelet theory [25,36]. In fact, the DSC kernels have a feature in common with wavelets in
terms of time-frequency (position-momentum) localization. However, unlike in a wavelet algorithm, multiresolution
analysis is feasible but it is not required in the DSC algorithm.

In contrast to our earlier work dealing with the application of the DSC approach to the Fokker-Planck equation via
an eigenfunction expansion [25], we have explored in this paper a DSC-based time-propagation approach for solving
the Fokker-Planck equation. Three typical DSC kernels, the regularized Shannon’s kernel (RSK), the regularized
Dirichlet kernel (RDK), and the regularized Lagrange kernel (RLK), are used as trial functions in the framework of
the present method. Four benchmark examples are chosen to demonstrate the usefulness and to test the accuracy
of the present DSC approach. The ﬁrst example is the repulsive Wong process. This is used for objectively testing
the ability of handling the monomodality-bimodality transition. The Wong process requires a large computational

12

domain to ensure that the boundary reﬂection of density ﬂux has little inﬂuence in a highly accurate computation.
By using reasonable resolution, regularization and a quite large time increment, the present approach performs very
well in characterizing the transition. In fact, the present uniﬁed approach delivers machine accuracy at an early time.
The Black-Scholes equation of option pricing was chosen as the second numerical example. This ﬁnancial equation
can be regarded as a reaction-diﬀusion equation, although, its derivation was entirely based stochastic analysis. By
using a simple transformation, the Black-Scholes equation is converted into the standard form of the Fokker-Planck
equation which admits an analytical solution. The present numerical results for the Black-Scholes equation are
obtained by using three diﬀerent DSC kernels with a reasonable resolution and relatively large time mesh. The
extremely high accuracy in the present calculation indicates that the DSC-based uniﬁed algorithm is a valuable
potential approach for various option pricing simulations.

The third example treated is a nonlinear stochastic model. The eﬀective potential of the corresponding Fokker-
Planck equation is time depended through the ﬁrst order moment of the transition probability density. Despite of
the nonlinearity and poor approximation of the initial density distribution, the numerical solutions quickly settle to
a smooth, stable and correct distribution after a few iterations. This is due to the fact that the DSC trial functions
are chosen as Schwartz class functions and they are capable of auto-regularizing when used as integration kernels.
Our results are of machine precision at a relatively late time. To our knowledge, this is the best numerical solution
to this nonlinear Fokker-Planck equation to the date. These illustrative calculations indicate that the present uniﬁed
approach is extremely accurate, eﬃcient and robust for numerical simulations of stochastic systems.

A common feature in the abovementioned Fokker-Planck equation is that the equation is of strong parabolic type
and the solution decays as time increases. Therefore, it is necessary to employ an additional example to validate the
present DSC algorithm further for handling more complicated partial diﬀerential equations. To this end, we choose the
incompressible Euler equation with its velocity ﬁeld equations being of strong hyperbolic type and a derived equation
for the pressure being of elliptic type. A standard implicit Euler scheme is used for the time discretization and at
each time tn+1, linear algebraic equations are constructed by using the collocation method. In the present approach,
carrying out diﬀerentiations in the collocation is equivalent to implementing the ﬁnite diﬀerence weights computed
from the DSC trial functions. We test the DSC algorithm by using 4, 8, 16 and 32 grid points in each dimension
in association with many diﬀerent half matrix bandwidths (M = 4, 8, 16 and 32). As expected, the DSC algorithm
achieves its highest accuracy at the global limit (M = N ) for each given N . The machine precision is reached when
N = M = 32. Very good results are also obtained for many banded matrix calculations. We believe that the feature
of being able to provide both global and local approximations in one formulation is of practical importance for large
scale computations.

Although this paper emphasizes the connection of a few computational methods and the uniﬁed features of the
DSC approach, it claims neither that all computational methods are the same, nor that the DSC algorithm engulfs
all methods. For example, it is still not clear whether the DSC algorithm is applicable in adaptive and unstructured
grids (progress is made on a DSC-multigrid method). The reader is urged to keep the distinction of various methods
in mind and maintain a perspective.

This work was supported in part by the National University of Singapore. The author is grateful to the referee for

Acknowledgment

valuable comments and suggestions.

References

1. Suzuki M 1981 Adv. Chem. Phys. 46, 195

2. Risken H 1984 The Fokker-Planck equation: methods of solution and application (Springer-Verlag)

3. Caroli B, Caroli C and Roulet B 1979 J. Stat. Phys. 21 26 (1979).

4. Larson R S and Kostin M 1978 J. Chem. Phys. 69 4821

5. Indira R, Valsakumar M C, Murthy K P N and Ananthakrishna G 1981 J. Stat. Phys. 33 181

6. Wehner M F and Wolfer W G 1983 Phys. Rev. A 27 2663

7. Brand H, Schenzle A and Schr¨oder G 1982 Phys. Rev. A 25 2324

8. Shizgal B 1981 J. Comput. Phys. 41 309

9. Blackmore R and Shizgal B 1985 Phys. Rev. A 31 1855

10. Kometani K and Shimizu H 1975 J. Stat. Phys. 13 473

13

11. Brey J J, Casado J M and Morillo M 1984 Physica A 128 597

12. Haken H 1975 Rev. Mod. Phys. 47 175

13. Grabert H and Green M S 1979 Phys. Rev. A 19 1747

14. Dekker H 1979 Phys. Rev. A 19 2102

15. Frisch H L and Nowakowski B 1993 J. Chem. Phys. 98 8963

16. Mu˜noz M A and Garrido P L 1994 Phys. Rev. E 50 2458

17. Kho T H 1985 Phys. Rev. A 32 66

18. Ermak D L and Buckholtz H 1980 J. Comput. Phys. 35 169

19. Forsythe G E and Wasow W R 1967 Finite Diﬀerence Methods for Partial Diﬀerential Equations (New York:

Wiley)

20. Palleschi V, Sarri F, Marcozzi G and Torquati M R 1990 Phys. Lett. A 146 378

21. Chang J S and Cooper G 1970 J. Comput. Phys. 6 1

22. Larson E W, Levermore C D, Pomraning G C and Sanderson J G 1985 J. Comput. Phys. 61 359

23. Drozdov A N and Morillo M 1996 Phys. Rev. E 54 931

24. Epperlein E M 1994 J. Comput. Phys. 112 291

25. Wei G W 1999 J. Chem. Phys. 110 8930

26. Park B T and Petrosian V 1996 Astrophys. J. Suppl. Ser. 103 255

27. Kadanoﬀ L P 1997 Phys. Today 50(9) 11

28. Ablowitz M J, Herbst B M and Schober C 1996 J. Comput. Phys. 126 299

29. Finlayson B A 1972 The Method of Weighted Residuals and Variational Principles (New York: Academic Press)

30. Canuto C, Hussaini M Y, Quarteroni A and Zang T A 1988 Spectral Methods in Fluid Dynamics (Berlin:

Springer-Verlag)

31. Fornberg B 1996 A practical guide to pseudospectral methods (Cambridge University Press)

32. Dow J O 1999 A Uniﬁed Approach to the Finite Element Method and Error Analysis Procedures (San Diego:

Academic Press)

33. Wei G W 2000 Physica D 137 247

34. Wei G W 2000 Comput. Methods Appl. Mech. Engng. in press

35. Schwartz L 1951 Th´eore des Distributions (Paris: Hermann)

36. Wei G W 1998 Chem. Phys. Lett. 296 215

37. Qian L W and Wei G W J. Approx. Theor. submitted.

38. Wong E 1964 in Am. Math. Soc. Proc. of the 16th Symposium on Appl. Math. 264

39. Gisin N 1984 Phys. Rev. Lett. 52 1657

40. Hongler M O and Desai R 1986 Helv. Phys. Acta 59 367

41. Black F and Scholes M, 1973 J. Political Economy 81 637; Kwok Y K 1998 Mathematical Models of Financial

Derivatives (Springer Finance)

42. Boyle P, Broadie M and Glasserman P 1997 J. Economic Dynamics and Control 21 1267

14

43. Brennan M J and Schwartz E S 1978 J. Financial Quantitative Analysis 13 461

44. Tian Y 1993 J. Futures Markets 13 563

45. Cox J C, Ross R and Rubinstein M J. Financial Economics 7 229

46. Dahmen W and Kunoth A 1992 Numer. Math. 63 315

47. Schult R L and Wyld H W 1992 Phys. Rev. A 46 12

48. Qian S and Weiss J 1993 J. Comput. Phys. 106 155

49. Jawerth B and Swelden W SIAM Rev. 36 377

50. Vasilyev O V, Paolucci S and Sen M 1995 J. Comput. Phys. 120 33

51. Beylkin G and Keiser J M 1997 J. Comput. Phys. 132 233

15

TABLE I. Errors for solving the repulsive Wong process

RSK

RDK

RLK

L2

1.94(-09)
4.67(-11)
3.47(-12)
8.76(-13)
3.57(-13)
6.29(-14)
4.72(-14)
5.23(-14)
4.44(-14)
5.87(-14)
7.63(-14)
9.27(-14)
7.19(-14)
6.98(-14)

L∞

2.32(-09)
3.73(-11)
2.05(-12)
4.89(-13)
1.83(-13)
2.69(-14)
2.04(-14)
1.97(-14)
1.19(-14)
1.88(-14)
2.38(-14)
2.78(-14)
1.99(-14)
1.70(-14)

L2

1.94(-09)
4.67(-11)
3.47(-12)
8.76(-13)
3.57(-13)
5.92(-14)
3.60(-14)
3.76(-14)
3.16(-14)
5.23(-14)
7.30(-14)
9.08(-14)
6.24(-14)
5.25(-14)

L∞

2.32(-09)
3.73(-11)
2.05(-12)
4.95(-13)
1.91(-13)
3.00(-14)
1.63(-14)
1.39(-14)
1.12(-14)
1.64(-14)
2.16(-14)
2.58(-14)
1.79(-14)
1.39(-14)

L2

1.94(-09)
4.67(-11)
3.47(-12)
8.83(-13)
3.78(-13)
2.18(-13)
2.86(-13)
3.53(-13)
4.10(-13)
4.68(-13)
5.25(-13)
5.80(-13)
6.33(-13)
6.87(-13)

L∞

2.32(-09)
3.72(-11)
2.03(-12)
4.60(-13)
1.91(-13)
8.92(-14)
9.76(-14)
1.12(-13)
1.21(-13)
1.32(-13)
1.43(-13)
1.54(-13)
1.63(-13)
1.73(-13)

Time
0.10
0.25
0.50
0.75
1.00
2.00
3.00
4.00
5.00
6.00
7.00
8.00
9.00
10.0

16

TABLE II. Errors for the numerical solution of the Black-Scholes equation

Time

1
2
3
4
5
6
7
8
9
10
20

RSK

RDK

RLK

L2

1.85(-03)
1.19(-04)
4.57(-06)
2.53(-07)
1.81(-08)
1.63(-09)
1.81(-10)
2.41(-11)
3.83(-12)
7.82(-13)
4.86(-14)

L∞

1.14(-03)
8.55(-05)
2.89(-06)
1.68(-07)
1.15(-08)
1.09(-09)
1.26(-10)
1.59(-11)
2.55(-12)
6.25(-13)
2.70(-14)

L2

1.83(-03)
1.18(-04)
4.48(-06)
2.46(-07)
1.75(-08)
1.56(-09)
1.71(-10)
2.25(-11)
3.54(-12)
7.30(-13)
4.91(-14)

L∞

1.12(-03)
8.45(-05)
2.84(-06)
1.63(-07)
1.10(-08)
1.04(-09)
1.19(-10)
1.48(-11)
2.37(-12)
5.85(-13)
2.78(-14)

L2

2.18(-03)
1.42(-04)
6.44(-06)
4.23(-07)
3.66(-08)
4.02(-09)
5.48(-10)
9.03(-11)
1.76(-11)
4.01(-12)
4.84(-14)

L∞

1.41(-03)
1.06(-04)
4.29(-06)
2.84(-07)
2.43(-08)
2.74(-09)
3.92(-10)
6.05(-11)
1.15(-11)
2.84(-12)
2.74(-14)

17

TABLE III. Errors for solving the nonlinear model

Time

1
2
3
4
5
6
7
8
9
10
20

RSK

RDK

RLK

L1

4.13(-01)
4.66(-01)
2.03(-01)
4.88(-02)
7.41(-03)
1.02(-03)
1.38(-04)
1.87(-05)
2.53(-06)
3.42(-07)
3.64(-14)

L∞

3.09(-02)
3.68(-02)
1.68(-02)
4.92(-03)
7.84(-04)
1.12(-04)
1.52(-05)
2.05(-06)
2.77(-07)
3.75(-08)
3.11(-15)

L1

6.46(-01)
7.41(-01)
3.26(-01)
7.97(-02)
1.22(-02)
1.68(-03)
2.28(-04)
3.09(-05)
4.17(-06)
5.65(-07)
4.75(-14)

L∞

4.71(-02)
5.86(-02)
2.68(-02)
8.04(-03)
1.29(-03)
1.84(-04)
2.50(-05)
3.38(-06)
4.58(-07)
6.19(-08)
4.88(-15)

L1

4.67(-02)
2.48(-03)
7.24(-04)
1.23(-04)
1.68(-05)
2.26(-06)
3.06(-07)
4.14(-08)
5.59(-09)
7.56(-10)
1.00(-13)

L∞

3.98(-03)
2.27(-04)
6.51(-05)
1.31(-05)
1.82(-06)
2.48(-07)
3.36(-08)
4.54(-09)
6.13(-10)
8.29(-11)
1.51(-14)

18

N

4

M

1

2

4

8

8

16

16

32

4

8

16

32

Time

0.5
1.0
1.5
2.0
0.5
1.0
1.5
2.0
0.5
1.0
1.5
2.0
0.5
1.0
1.5
2.0
0.5
1.0
1.5
2.0
0.5
1.0
1.5
2.0
0.5
1.0
1.5
2.0
0.5
1.0
1.5
2.0
0.5
1.0
1.5
2.0

TABLE IV. Errors for solving the Euler equation

RSK

RDK

RLK

L1

3.16(-2)
3.10(-2)
3.06(-2)
3.04(-2)
1.27(-2)
3.10(-2)
1.37(-2)
1.44(-2)
9.33(-3)
9.43(-3)
9.62(-3)
9.92(-3)
1.30(-4)
1.52(-4)
1.82(-4)
2.17(-4)
6.30(-10)
6.76(-10)
8.00(-10)
9.68(-10)
5.25(-4)
7.40(-4)
1.04(-3)
1.40(-3)
1.78(-6)
2.41(-6)
3.23(-6)
4.17(-6)
6.95(-11)
7.48(-11)
8.06(-11)
8.67(-11)
1.02 (-14)
2.03(-14)
2.98(-14)
4.05(-14)

L∞

6.12(-2)
6.02(-3)
5.90(-3)
5.77(-3)
2.48(-3)
6.02(-3)
2.86(-3)
3.08(-3)
1.70(-3)
1.79(-3)
1.88(-3)
1.96(-3)
4.26(-5)
5.13(-5)
6.10(-5)
7.13(-5)
2.37(-10)
2.40(-10)
2.65(-10)
3.35(-10)
2.10(-4)
2.88(-4)
4.25(-4)
5.87(-4)
7.32(-7)
1.06(-6)
1.39(-6)
1.79(-6)
2.93(-11)
3.23(-11)
3.51(-11)
3.79(-11)
6.99(-15)
1.45(-14)
1.88(-14)
2.31(-14)

L1

3.15(-2)
3.09(-2)
3.05(-2)
3.04(-2)
1.27(-2)
1.31(-2)
1.37(-2)
1.45(-2)
9.32(-3)
9.42(-3)
9.61(-3)
9.91(-3)
1.33(-4)
1.54(-4)
1.83(-4)
2.16(-4)
6.75(-10)
6.82(-10)
7.57(-10)
8.81(-10)
5.24(-4)
7.41(-4)
1.04(-3)
1.40(-3)
1.93(-6)
2.62(-6)
3.51(-6)
4.52(-6)
9.52(-11)
1.03(-10)
1.11(-10)
1.19(-10)
1.36(-14)
2.51(-14)
3.68(-14)
5.04(-14)

L∞

6.12(-2)
6.01(-3)
5.89(-3)
5.76(-3)
2.48(-3)
2.66(-3)
2.87(-3)
3.08(-3)
1.69(-3)
1.79(-3)
1.88(-3)
1.95(-3)
4.36(-5)
5.25(-5)
6.26(-5)
7.32(-5)
2.76(-10)
2.87(-10)
3.18(-10)
3.49(-10)
2.10(-4)
2.90(-4)
4.27(-4)
5.89(-4)
7.95(-7)
1.15(-6)
1.51(-6)
1.92(-6)
4.00(-11)
4.42(-11)
4.81(-11)
5.19(-11)
1.21(-14)
1.80(-14)
2.74(-14)
3.13(-14)

L1

3.09(-2)
3.03(-2)
2.99(-2)
2.99(-2)
1.29(-2)
1.29(-2)
1.32(-2)
1.35(-2)
9.34(-3)
9.44(-3)
9.64(-3)
9.93(-3)
1.24(-4)
1.54(-4)
1.92(-4)
2.34(-4)
1.23(-8)
1.56(-8)
1.99(-8)
2.48(-8)
2.37(-3)
2.96(-3)
3.75(-3)
4.62(-3)
9.50(-7)
1.24(-6)
1.64(-6)
2.09(-6)
1.90(-10)
2.40(-10)
3.04(-10)
3.76(-10)
1.10(-14)
2.22(-14)
3.54(-14)
4.80(-14)

L∞

6.01(-2)
5.88(-3)
5.73(-3)
5.57(-3)
2.44(-3)
2.54(-3)
2.66(-3)
2.78(-3)
1.70(-3)
1.79(-3)
1.88(-3)
1.96(-3)
3.40(-5)
4.79(-5)
5.66(-5)
6.72(-5)
3.63(-9)
5.16(-9)
6.76(-9)
8.53(-9)
7.14(-4)
1.00(-3)
1.33(-3)
1.67(-3)
3.05(-7)
5.22(-7)
7.73(-7)
1.03(-6)
5.73(-11)
8.15(-11)
1.08(-10)
1.36(-10)
7.88(-15)
1.54(-14)
2.22(-14)
3.12(-14)

19

