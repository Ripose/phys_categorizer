New approach to Dynamical Monte Carlo Methods: application

to an Epidemic Model

O.E. Aiello and Marco A.A. da Silva

Departamento de F´ısica e Qu´ımica da FCFRP,

Universidade de S˜ao Paulo, 14040-903 Ribeir˜ao Preto, SP, Brazil

(Dated: October 29, 2001; Received text; Revised text; Accepted text; Published text)

Abstract

A new approach to Dynamical Monte Carlo Methods is introduced to simulate markovian pro-

cesses. We apply this approach to formulate and study an epidemic Generalized SIRS model. The

results are in excellent agreement with the forth order Runge-Kutta Method in a region of deter-

ministic solution. We also demonstrate that purely local interactions reproduce a poissonian-like

process at mesoscopic level. The simulations for this case are checked self-consistently using a

stochastic version of the Euler Method.

2
0
0
2
 
y
a
M
 
3
1
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
9
3
0
5
0
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

1

I-Introduction - Monte Carlo (MC) methods have been used mainly to equilibrium
systems[1], and they have broad applications, since simple systems like hard spheres[2] up

to complex systems like proteins[3, 4]. Good reviews in applications of MC methods to

statistical physics can be seen in the references[1, 5]. In the last decades the development

of techniques dealing with non-equilibrium systems has been increased[6], specially those

that concern with stochastic processes. Several attempts were done [5]-[11] to simulate real

time processes with this method. Some success was achieved within the scope of poissonian

processes [8] that has been only recently properly formalized by Fichtorn and Weinberg [9].

Another important approach from a theoretical point of view is the waiting (or residence)

time distribution used by Prados et al.[7], whose application is limited to simple systems,

like Ising models. Some improvement in the real time calculation was presented by Cao[10],

but in a particular and non rigorous way. In this letter we surmount this problem using

directly the Master Equation, ignoring thus what type of distribution we are dealing. In

this way, we also avoid the direct waiting (ﬁne-grained) time distribution calculation; this

is substituted by the calculation of interevent (coarse-grained) times. In our approach, the

time is a dependent stochastic variable whose distribution is constructed from the Master

Equation with appropriate transition probabilities. This gives the hierarchy of the process.

The approach is developed for a class of markovian processes with no simultaneous events in

the smallest scale considered. Thus, it is for a restricted markovian, but more general than

poissonian processes. This method has already been applied[14] to an extensive study of

the epidemic Susceptible-Infected-Recovered-Susceptible (SIRS) systems (to details of these

epidemic systems see [11] and references therein). Here, we apply this new approach to

formulate an epidemic Generalized SIRS (GSIRS) model, and study two particular cases of

it.

II-The Method - For discrete systems, the markovian Master Equation is given by:

dPi(t)
dt

=

wj→iPj −

wi→jPi,

Xj

Xj

(1)

where Pi is the probability to ﬁnd the system at the state i at the time t, and wi→j is the

transition probability per unity of time. Considering Tij the probability of transition from
i to j, we may write wi→j = Tij
τ i

[12], where τ i is a time constant (lifetime) characteristic of

the state i.

We now start by choosing a convenient physical extensive microscopic quantity Ai that

2

is time independent for each state i. The mean value for this quantity at the time t is given

by:

This equation represents a continuous physical macroscopic quantity A(t). We can diﬀer-

entiate both sides of the equation above, with respect to t. After that, using (1), and by

deﬁning ∆Aij = Ai − Aj, we get

Consider now the nearest-neighbor states j of a given state i; if we measure the “distance”

between the states, say by the quantity |∆Aij|, such that the non-null minimum value is

|∆Aij| = a, we may approach the equation(3) by:

A(t) = hAi =

Pi(t)Ai.

Xi

dA(t)
dt

=

Xi Xj

wj→iPj∆Aij.

dA(t)
dt

=

X<ij>

wj→iPjaδij,

where the symbol < ij > denotes a nearest-neighbour pair of states, and δij = ∆Aij/|∆Aij|.

Now we consider another physical quantity A† that is a source for the quantity A. Thus, we

can rewrite (4) as:

dA(t)
dt

=

r+
j PjA†

j −

r−
j PjAj,

Xj

Xj

where rj =< wj→i >i are the transition probabilities per unity of time averaged over the

ensemble of the nearest-neighbour states i of j at some time t, i.e., the mesoscopic rates.

Here, ensemble means a set of conﬁgurations accessible at a some ﬁnite (small) time around

a time t; in this sense we are using a time dependent ergodicity idea[5], and so generally

the systems are non ergodic in non equilibrium states. The superscripts “ + ” and “ − ”

mean respectively the contributions to increasing and to decreasing the quantity A(t). In
the particular case that r+
j = r− are constants (or only function of the time)

j = r+ and r−

we have:

dA
dt

= r+A† − r−A,

what is the analogous to the kinetic equation for the ﬁrst order chemical reaction A† ⇄ A,
being A† and A the respective concentrations of the chemical elements A† and A. The

equilibrium can be reached by imposing the balance at macroscopic (or mesoscopic) level:

3

(2)

(3)

(4)

(5)

(6)

r+A† = r−A. This follows immediately if we require the detailed balance, but it is not

necessary at all[13].

We can write the equation (4) in an approximated form of a discrete integral

A(t) − A(t0) ≃

wj→iPj(tk)aδij∆tk.

(7)

n

Xk=0 X<ij>

Let now be the set of possible wj→i represented by Pt = {wj→i}, being the states i and

j occurring around a given instant t, and wmax

t = sup Pt. The phase space may be divided

into N parts, in such way that each part may contain only one element of the system. Thus,

each element of time in the equation (7) may be represented by

∆tk =

1
wmax
tk N

.

We can do the approach to the equation A(t) considering n = ℓN, with ℓ sweeps over the

discretized space; in the limit of N → ∞ we have the exact solution of the equation (4) for

a given initial condition.

written in the form:

Monte Carlo Approach -With the considerations above the equation (7) may be

A(t) − A(t0) =

Pj(tk)aδij.

(9)

ℓN

Xk=0 X<ij>

wj→i
wmax

(cid:18)

tk (cid:19) (cid:18)

1
N (cid:19)

We can create a hierarchical process choosing the probabilities of transition

(8)

(10)

T ∗
j→i =

wj→i
wmax
tk

,

that reproduce the correct frequencies of events at each time tk to solve (9). This hierarchy

have subtle diﬀerences with an earlier hierarchy introduced by Fichtorn et al[9]: ﬁrst in that

work (mesoscopic) rates were required, while here we primarily use transition probability per

unity of time. Second, they used a global maximum to the rates, while here we use a more

local maximum; in recent work[11] this was done without a rigorous proof, based only in

the detailed balance principle applied to a speciﬁc case. To carry out the MC procedure,
an element is selected randomly with a probability 1

N , and thus a transition is tried with
probability given by (10). The space is swept ℓ times, with the increment of time in each

MC step (one MC step here, means a single try to change the state of one element of the

4

system) given by (8) up to reach a time t. Starting from the same initial conditions for

the physical quantities, the process may be repeated, and we can get the average quantity

A(t) at each instant t. We must emphasize that the probabilities Pj are generated by this

process. As a given state is chosen with its correct probability in a given time, an ideal MC

procedure leads to

A(t) − A(t0) =

ℓN

(

r+A†
(cid:10)

Xk=0

−

jk

r−A
jk
(cid:11)
(cid:10)

)

1
wmax
tk N (cid:19)

,

(cid:18)

(cid:11)
where the averages are taken over the ensemble of the states jk at each instant tk. This is

(11)

just an approach to the integration result of the equation (5).

We need to observe some important points: ﬁrst, generally diﬀerent runs give diﬀerent

time tk results at the same MC step k, and the sample averages may be done by linear

interpolating or extrapolating the data set, in each MC realization, to do them at the same
point of the time. Second, in one complete sweep around a time tk, the value wmax

tk must be
approximately constant in order do not change the hierarchy and so the result. Third, as the

conﬁgurations do not change drastically in few steps, the microscopic transitions reproduce

the mesoscopic result.

Another approach consists in estimating the interevent times by the following rule

∆te

k =

,

f k
e a
jkAe
re
jk
jk and Ae

where re

jk = r+

jk and Ae

jk = A†

jk, or, re

jk = r−

if the outcome of the experiment increase or decrease the quantity A. The quantity f k

jk = Ajk depending on, respectively,
e is

an arbitrary e-event dependent factor that must obey the relationship

time tk. We emphasize that the time given by (12) represents the average waiting time to

transitions from a given state jk to any neighbor state i; if the microscopic state remains

unchanged, the time does not evolve. It can be shown that this procedure leads to the same

f k
e = 1, for each

Pe

result as using (8) at each MC step observing that

∆tk =

Xe Xi

wjk→i
wmax

tk (cid:19) (cid:18)

1
N (cid:19)

(cid:18)

∆te
k.

As re

jkAe

jk = a

wjk→i, using the equation (12) and the normalization condition to f k

e in

(13), we obtain the expression (8). In particular, if we choose f k

e = 0, for most events e,

Pi

(12)

(13)

5

except some e = s, we have f k

s = 1, so, with this condition, the interevent time has the

meaning of the waiting time between type-s events. Based on this and in the fact that at

the equilibrium the relative frequencies of occurrence of events are all equal, we may deﬁne
e ≡ nk
f k
events, in a time interval (arbitrary) near to some time tk.

e is the number of e−events, and Nk =

e is the total number of

e /Nk, where nk

e nk

P

III-GSIRS model - Based on (5), we formulated the GSIRS model through the

following set of diﬀerential equations and inter-classes rates:

dS
dt

dI
dt

dR
dt

=

=

=

j

Xj

Xj

Xj

rj
R→SPjRj −

rj
S→IPjSj,

rj
S→IPjSj −

rj
I→RPjIj,

rj
I→RPjIj −

rj
R→SPjRj,

Xj

Xj

Xj

(14)

(15)

(16)

where S, I, and R are the populational classes, respectively, of the number of individuals in
the susceptible, infective and recovered classes. Being the mesoscopic rates rj
rj
R→S, for each state j, respectively, from S → I, I → R and R → S. Note that we meant
that, for example, if A = I, then A† = S in the equation (5). The conservation law with

S→I , rj

I→R and

the total number of individuals N = S(t) + I(t) + R(t) is satisﬁed. In particular, a model
N µ Sµ−1I + Λ [1 −(1 −p0)n], and wI→R = q
commonly used[11, 15] give wR→S = m, wS→I = Γ b
to the transition probabilities per unity of time. We must observe that the mesoscopic rates

are resulting from local (“instantaneous”) averages of the respective transition probabilities

per unity of time. For practical purposes the individuals are distributed on a square lattice

of N = M × M sites. All the individuals at the lattice boundary have their states ﬁxed at

susceptible state.

IV-Results and Conclusions - We set the lattice size to M = 200. This
size was suﬃcient to get good results compared with the continuum limit when only global

interactions (Λ = 0) are considered. The initial condition for the system is set up by

I0 = 2000 infectives being randomly distributed on the lattice and the remaining sites being

occupied by S0 = N − I0 susceptibles, so R0 = 0.

We consider here two particular cases of the system deﬁned by (14 − 16). First, we

set Λ = 0, and the other model parameters as q = 0.2, b = 0.8, m = 0.01 and

6

µ = 2. The non-minimum value, to the diﬀerences ∆S, ∆I and ∆R , used in(12) is

a = |∆I| = |∆S| = |∆R| = 1. Figure 1 shows the temporal evolution of I(t). Continu-

ous lines represent numerical (fourth-order Runge-Kutta) checking solutions for the set of

diﬀerential equations (14 − 16), and open circles correspond to the MC simulations. The

accuracy of the deterministic solution (Runge-Kutta) was estimated as less than 0.1% (see

ref.[11]).

Results to the system far from equilibrium showed that the interevent times

given by (12) have poissonian-like distribution (see inset in ﬁgure 1) as expected[11]. At the

equilibrium, the present method leads to converge the distributions of interevent times to

delta distributions, because the values to the rates and other physical quantities converge
to constant values. A total of 4 × 106 steps, corresponding to 3, 5 × 105 conﬁgurations, was

generated by the MC procedure, leading to a total real time of approximately 500 days.

The total number of conﬁgurations used to get the interevent times distribution was about
8 × 104, what corresponds to approximately 60 days. Second, we set Γ = 0 and m = 0, i.e., a

SIR system with purely local variables. The variable n is an integer ranging from n = 0 up

to 8, since the ﬁrst and second nearest infected neighbors are indistinguishably considered

for each susceptible. To this case we use again the expression (12), but the rates rS→I are

obtained by averaging the individual probabilities to the conﬁgurations in every successful

event. This may coast some simulation time. A good optimization for an approximation to

the exact average is done by drawing randomly susceptibles (1000 here was suﬃcient) for

each conﬁguration reached and doing a sample mean with the site transition probabilities

per unit of time wS→I. It must be observed that this type of average is equivalent to let

the system advance some small time and take an average over the sample. As the system

conﬁgurations do not change much around some time tk, the small time average corresponds

to an average in an instantaneous time. To see the self-consistency of the approach, we

integrate numerically (14 − 16) given constant (or piecewise constant) time step as in (7)

by choosing the maximum local transition probability per unit of time. This maximum is in

fact actualized at each MC step, when necessary, using a table. When a transition changes a

state of an individual that changes the maximum, the table is updated. The quantities S, I

and R are calculated with iterations; the rates are chosen randomly by the MC procedure,

and thus we use the Euler Method procedure to solve ﬁrst order diﬀerential equations. Ex-

periments using poissonian distributions[9] to obtain the interevent times showed that the

processes are poissonian-like to all ranges of p0, being so, unnecessary the hypothesis of low

7

p0 (“weak interaction”) as done by Aiello et al[11]. To illustrate, we show in the Figure 2

the results to p0 = 0.8. We compare, also, in ﬁgure 2 the iterative method with the MC

technique described above (restricted markovian method), estimating the interevent time by
(12). The total number of conﬁgurations used in the MC procedure was about 4 × 104 what

gives approximately 10 days. The results are in excellent agreement among them. For both

cases (Figures 1 and 2), results with respect to the MC simulations correspond to an average

of 20 independent trajectories. The typical MC data errors are in the interval 0.1-1.0%, so

most of the error bars are smaller than the symbols in the ﬁgures.

We believe that the class of epidemic SIRS models studied here are poissonian-like in

the mesoscopic scale because of two factors. First, the approach itself implies that no two

or more events occur in a short scale of time. Second, the mesoscopic rates are slowly

varying with the time, resembling the independence between events. So, the two conditions

for a poissonian process were met. We emphasize that low correlations between events are

not required. It is necessary that the results for independent runs be uncorrelated, so we

can use the averages obtained for each time t to represent properly the physical quantities

of the process. To do this we need a local equilibrium hypothesis, what may be at ﬁrst

glance restrictive, however we may even reduce the time observation suﬃciently such that

the system does not have time to leave some metastable states. So, we can average it there.

In the practice of the simulation this is done by increasing the number of observations, i.e.,

the number of time experiments. In forthcoming works we expect to generalize still more

the method, including up to non-markovian processes.

The authors gratefully acknowledges funding support from FAPESP Grant n. 00/11635-7

and 97/03575-0. The authors would also like to thank Drs. F.L.B. da Silva and A. Caliri

for many stimulating discussions and suggestions.

8

Figure Captions

FIG. 1. Infected numbers I(t) vs Time. Continuos line: numerical forth-order Runge-

Kutta solution. Open circles: restricted markovian DMC simulation.

Inset: shows the

behavior of the interevent time ∆t distribution.

FIG. 2. Infected numbers I(t) vs Time. Continuos line: Iterative stochastic Euler Method

solution. Squares: restricted markovian DMC simulation. Open circles: poissonian DMC

simulation.

9

[1] K. Binder, Monte Carlo Method in Statistical Physics (Spriger-Verlag, Berlin, 1986).

[2] A. Caliri, M. A. A. da Silva, and B. J. Mokross, J. Chem. Phys. 91, 6328 (1989).

[3] D. Bouzida, S. Kumar, and R. H. Swendsen, Phys. Rev. A 45,8894 (1992).

[4] M. Cieplak, M. Henkel, J. Karbowski, and J.R. Banavar, Phys. Rev. Lett. 80, 3654 (1998).

[5] K. Binder, Rep. Prog. Phys. 60, 487 (1997).

[6] F.J. Alexander, A. L. Garcia, and B. J. Alder, in 25 Years of Non-Equilibrium Statistical

Mechanics, edited by J. J. Brey et al (Springer-Verlag, Barcelona, Spain, 1994).

[7] A. Prados, J.J. Brey, and B. S´anchez-Rey, Journal of Statistical Physics 89, 709 (1997).

[8] D. T. Gillespie, J. Comp. Phys. 22, 403 (1976).

[9] K. A. Fichtorn and W. H. Weinberg, J. Chem. Phys. 95, 1090 (1991).

[10] Pei-Lin Cao, Phys. Rev. Lett. 73, 2595 (1994).

[11] O.E. Aiello, V.J. Haas, A. Caliri, and M. A. A. Silva, Physica A. 282, 546 (2000).

[12] P.G. Hoel, S.C. Port, and C.J. Stone, Introduction to Stochastic Processes (Waveland Press,

Inc., Prospect Heights, Illinois, 1987).

[13] L. D. Fosdick, in Methods Comp. Phys., edited by B. Alder, S. Fernback and M. Rotenberg,

Vol. 1 (Academic Press, 1963), p. 245.

[14] O.E. Aiello and M. A. A. Silva (to be published).

[15] V.J. Haas, A. Caliri, and M.A.A. da Silva, J. of Biol. Phys., 25, 309 (1999).

10

3
-
0
1
 
x
 
)
t
(
I

12

10

8

6

4

2

0

Figure 1

4
-
0
1
 
x
 
y
c
n
e
u
q
e
r
F

 

5

4

3

2

1

0

0

1

4

5

2

3

  ∆t x 103

Restricted markovian DMC
Runge-Kutta

0

100

200

300
Time (days)

400

3
-
0
1
 
X
 
)
t
(
I

12.5

10.0

7.5

5.0

2.5

0.0

Figure 2

 Iterative
 Restricted markovian DMC
 Poissonian DMC

0.0

2.5

5.0
7.5
Time (days)

10.0

