Performance of the Cell processor for bio-molecular simulations

G. De Fabritiis1, ∗
1Computational Biochemistry and Biophysics Lab (GRIB-IMIM/UPF),
Barcelona Biomedical Research Park (PRBB), C/ Dr. Aiguader 88,
08003, Barcelona, Spain. http: // www. iac. rm. cnr. it/ ~ gianni

The new Cell processor represents a turning point for computing intensive applications. Here,
I show that for molecular dynamics it is possible to reach an impressive sustained performance in
excess of 30 Gﬂops with a peak of 45 Gﬂops for the non-bonded force calculations, well over an
order of magnitude faster than a single core standard processor.

6
0
0
2
 
v
o
N
 
1
2
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
1
0
2
1
1
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

The Cell broadband engine is a new processor architec-
ture created by Sony-Toshiba-IBM1 which allows for high
computational performance and low production costs re-
moving, by design, many important bottlenecks of stan-
dard processors.
In the present version, it comprises
one simpliﬁed power PC core (PPE) which runs the op-
erating system and acts as a standard processor and
8 independent synergetic processing elements (SPEs).
Main memory can be accessed only by the PPE core
while each SPE can use its limited in-chip local memory
(local store) accessed directly without any intermediate
caching. This architectural design removes the memory
bottleneck which is aﬄicting modern processors and fur-
nishes a direct way to improve performance by adding
more SPEs without having to rely only on clock fre-
quency. Each core (PPE or SPEs) features a single in-
struction multiple data (SIMD) vector unit which gives
a combined peak performance of around 230 Gﬂops at
3.2Ghz.

All this computational power comes at the cost of a
programming paradigm change. An existing application
would run on the Cell processor using only the PPE core
without any performance beneﬁt. Therefore, in order to
obtain the maximum performance, it is necessary to use
all SPEs and to adapt the code to match the underly-
ing hardware architecture. This means addressing issues
of vectorization, memory alignment and communication
between main memory and local stores. In the follow-
ing, the performance of a ﬁrst implementation for the
important application case of bio-molecular simulations
is presented.

Molecular dynamics (MD) is a simulation methodology
which enables, for instance, the study of the dynamics of
proteins in their environment. It is used by pharmaceuti-
cal companies for a wide variety of applications including
drug design, drug screening and in general to investigate
protein function. This has been achieved through the use
of carefully tuned force ﬁelds which reproduce the molec-
ular speciﬁcity of each protein3. However, the impact of
molecular dynamics would be much greater if faster ways
to perform MD simulations were found in order to reach
the time scales of biological processes (micro-milli sec-
onds). These time scales cannot be simulated yet despite
the use of costly high performance supercomputers with
hundreds of processors. Specialized hardware like the
Cell processor could help to approach this goal.

FIG. 1: Ion channels are essential to life by regulating trans-
port across lipid membranes. Here, it is shown a Gramicidin
A channel solvated in a lipid membrane with water and ions.
Lipids are only partially shown for clarity2.

The molecular dynamics software produced for these
benchmarks is able to read the CHARMM27 force ﬁeld3
and to simulate bio-molecular models such as proteins,
lipids and TIP3P water with periodic boundary condi-
tions. Electrostatic and Lennard-Jones interactions are
handled by simple truncation with CHARMM switching
functions used to smooth the force to zero at the cutoﬀ
radius. The current Cell MD code can be used for ap-
plications such as ion permeation of protein channels4 as
depicted in Figure 1 and polymer collapse5.

Meaningful benchmarks require a code which is close
enough to the performance of real production MD codes.
As a reference, I take a widely used molecular dynamics
package NAMD2.66 which is specially optimized for par-
allel processing, but still fast on a single processor. The
MD simulations are mostly run on the molecular system
depicted in Fig. 1 which consists of Gramicidin A trans-
membrane protein embedded in a DMPC lipid bilayer
and water for a total of 29 thousand atoms4.

For the ﬁrst benchmark, in Figure 2, I use two plat-
forms, an Opteron processor running at 2Ghz and a dual
Cell blade at 3.2Ghz and three codes, a scalar MD code,
the fully Cell MD optimized code running on 1-8SPEs
and NAMD as a reference. A standard cell index method
is used for handling non-bonded interactions within the

MD
PPE

MD
PC

NAMD
PC

MD
8SPEs

10

20

30

atoms (1000)

40

50

FIG. 2: Simulation elapsed time to run 50 iterations of Gram-
icidin A in the set-up of Figure 1. The MD code is run on the
PPE, on a PC Opteron and on 8 SPEs. The same simulation
with NAMD is reported for reference. The Cell MD code is
over 19 times faster than the scalar code and 15 times faster
than NAMD on the Opteron.

)
s
(
 
e
m

i
t

140

120

100

80

60

40

20

0

p
u
−
d
e
e
p
s

40

30

20

10

0

PPE

1SPE 2SPEs 4SPEs 6SPEs 8SPEs

FIG. 3: Performance comparisons for diﬀerent numbers of
SPEs (1-8) for Gramicidin A. A speed-up of 35 times is ob-
tainable by running on 8 SPEs compared to the PPE.

cutoﬀ radius7. The Cell MD code has a fully vectorized
loop for the calculation of non-bonded forces. which is
distributed on the SPEs. Code vectorization requires a
manual control by the programmer of issues like mem-
ory alignment which can be complex to manage in re-
alistic application codes like this one. The scalar MD
code shares the same algorithmic solutions as the Cell
MD code but it does not use any vector hardware, nor
the SPEs. As such it can be compiled for the Opteron
processor and for the PPE of the Cell processor (use of
SSE hardware on the Opteron is envisaged but not yet
implemented). Benchmarks for NAMD were measured
over 3000 iterations because NAMD requires a larger ini-
tialization time, while the Cell MD timing was measured
over just 500 iterations. Both results were rescaled to 50
iterations. The ﬁrst two columns of Figure 2 show the
same scalar code running on both platforms, Cell and
Opteron processors. The ﬁrst result is that the PPE is
outperformed by an Opteron chip although it runs at a

2

)
s
(
 
e
m

i
t

8

6

4

2

0

FIG. 4: Performance measured by the elapsed time over 50
iterations for Cell MD on 8 SPEs for water boxes at diﬀerent
problem sizes: 5, 11, 30 and 49 thousand atoms. The scaling
is linearly dependent on problem size.

much higher clock frequency. This is due to fact that the
PPE is not a fully equipped PowerPC but rather a simpli-
ﬁed version of it designed to reduce power consumption
and leave space on die for the SPEs on which comput-
ing intensive tasks are expected to run. The second and
third columns of Figure 2 show that NAMD is slightly
faster than my scalar MD code. This performance dif-
ference is due to algorithmic optimizations of modern
production MD engines which reduce the amount of cal-
culations. Despite this fact, the Cell MD code on 8 SPEs
is 15 times faster than NAMD on the Opteron processor
(fourth column is 3.8 s).

In Fig. 3, the performance speed-up measured over
Gramicidin A is shown for 1 to 8 SPEs using the PPE
as the base reference. The Cell MD code with just one
SPE is already 6 times faster than the scalar version run-
ning on the PPE. By increasing the number of SPEs the
scalability remains good showing the strength of the in-
terconnection bus on die8. The calculated sustained per-
formance of Cell MD on 8 SPEs is in excess of 30 Gﬂops.
This increases to 45 Gﬂops if we consider only the non-
bonded force calculation, quite close to peak performance
considering that we have measured ﬂops distinguishing
between vector madd operations (multiply and add, 8
ﬂop) and simple vector multiplies (4 ﬂop). Another im-
portant factor is the scalability of the Cell MD code for
varying number of atoms. For instance, a domain de-
composition parallelization scheme scales well only above
about one thousand atom per processor for the best codes
like NAMD. Therefore, I have benchmarked the code at
varying number of atoms. Figure 4 shows the elapsed
time for 50 iterations for water boxes with 5, 19, 30,
49 thousand atoms all running on 8 SPEs. The scaling
is linearly dependent on the system size, therefore the
maximum performance is achievable even for the small-
est system.

In conclusion, the Cell processor runs existing appli-
cations on the standard PowerPC core but in general

3

you should expect a performance penalty compared to
current standard processors.
Instead, the strength of
the Cell processor are the 8 synergetic processing units
which require low level programming skills. The cost
of this eﬀort cannot be underestimated but the perfor-
mance obtainable compared to a traditional processor is
about 20 times faster for the realistic case of molecular
dynamics of biomolecules. Similar results are also possi-
ble for other computing intensive scientiﬁc and technolog-
ical problems9,10 such as computational ﬂuid dynamics,
systems biology and Monte Carlo methods for ﬁnance.
We plan to extend this work to these applications in the
immediate future. The performance measures of this ar-
ticle are to be considered conservative but quite accu-
rate. Optimizations are in progress which could further
enhance the speed of the Cell MD code. The innovative

design and low cost per chip of the Cell processor are
likely to be key factors in the probable success of this
technology. Part of the cost beneﬁts comes from the fact
that the Sony PlayStation311 features the Cell processor
guaranteeing high production volumes from the very be-
ginning. New multi-core standard processors will need
to show that they can reach similar performance levels
at the same cost. The implications of this technology
for science are also important. Without a doubt it ex-
pands the frontier of scientiﬁc computing while lowering
the cost of entry in terms of the computational infras-
tructure required to run molecular based software.

Acknowledgments. I am grateful to Barcelona Supercom-
puting Center (BSC) for support and access to Cell hard-
ware and to Giovanni Giupponi, Massimo Bernaschi, Peter
Coveney and Jordi Vill`a-Freixa for their help.

gdefabritiis@imim.es

∗
1 IBM

website

on

the

Cell

processor,

http://www.research.ibm.com/cell/.

2 W. Humphrey, A. Dalke, and K. Schulten, J. Molec.

Graphics 14, 33 (1996).

3 A. MacKerell, D. Bashford, M. Bellott, R. Dunbrack,
J. Evanseck, M. Field, S. Fischer, J. Gao, H. Guo, S. Ha,
et al., J. Phys. Chem. B 102, 3586 (1998).

4 G. De Fabritiis, P. V. Coveney, and J. Vill`a-Freixa,

preprint (2006).

(2006).

5 G. De Fabritiis, G. Giupponi, and P. V. Coveney, preprint

6 J. C. Phillips, R. Braun, W. Wang, J. Gumbart,
E. Tajkhorshid, E. Villa, C. Chipot, R. D. Skeel, L. Kal´e,
and K. Schulten, J. Comp. Chem. 26, 1781 (2005).

7 M. P. Allen and D. J. Tildesley, Computer Simulations of

Liquids (Oxford University Press, Oxford, 1987).

8 M. Kistler, M. Perrone, and F. Petrini, IEEE Micro 26, 10

(2006), ISSN 0272-1732.

9 J. Langou, P. Luszczek, J. Kurzak, A. Buttari, and J. Don-
garra, Exploiting the Performance of 32 bit Floating Point
Arithmetic in Obtaining 64 bit Accuracy (University of
Tennessee Computer Science Tech Report, UT-CS-06-574,
LAPACK Working Note 175, April 2006).

10 S. Williams, J. Shalf, L. Oliker, S. Kamil, P. Husbands,
and K. Yelick, The potential of Cell processor for scientiﬁc
computing (CF06 May 3-5, 2006, Ischia, Italy, 2006).
on

Playstation3,

11 Sony

the

website
http://www.playstation.com.

