9
9
9
1
 
l
u
J
 
7
1
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
5
2
0
7
0
9
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

International Journal of Modern Physics C,
❢c World Scientiﬁc Publishing Company

SIMPLE AND EFFICIENT ALGORITHM FOR LARGE SCALE
MOLECULAR DYNAMICS SIMULATION IN HARD DISK SYSTEM

MASAHARU ISOBE∗
Department of Physics, Kyushu University 33
Fukuoka 812-8581, Japan

Received (received date)
Revised (revised date)

A simple and eﬃcient algorithm of the molecular-dynamics simulation of the hard disk
system based on the Event-Driven method is developed. From the analysis of algorithm,
the complexity is
(log N ) per 1 event, and the constant coeﬃcient of the complexity
is smaller than conventional eﬃcient algorithm based on the concept of Cell-Crossing
Event. The maximum performance more than 460 millions of collisions per CPU-hour
on the Alpha600 compatible in 2500 particle system is achieved. An extension to the
inﬁnite-space system based on this algorithm is also proposed.

O

1. Introduction

Molecular dynamics method (MD) was worked in a paper for the ﬁrst time by Alder
and Wainwright in 1957,1 and there is a series of works after it by them.2,3,4 Their
simulations were performed with many hard disks (or hard spheres in 3-d) near the
liquid-solid phase-transition point, and they found that the system was crystallized
despite the particle had only repulsive force. These discover smashed the common
sense of those days, and gave a big inﬂuence to the development of the study in the
computer simulation.

In the hard disk system, the dynamics consists of only collisions and straight-line
movement. Since distinct events occur one after another in time, we do not need
to integrate the diﬀerential equations with a constant time step based on Newton’s
equation of motion. The method that is based on the ﬁnite constant time step and
integration with the equations of particles step by step in time are sometimes called
”Time-Step-Driven Molecular Dynamics” (TSDMD). On the other hand, in the
hard disk system, the simulation that proceeds based on events is called ”Event-
Driven Molecular Dynamics” (EDMD). Compared with TSDMD simulation, the
algorithm of EDMD simulation is completely diﬀerent. We need the knowledge of
an advanced algorithm and a data structure to perform the eﬃcient simulation in
EDMD. The strategy of direct computation of particle-pairs result in the complexity
(N 2) for large particle number N . The point of improvement in the speed in hard
O
disk system is how we deal with the queue of a future event and the data structure

∗E-mail: isobe@stat.phys.kyushu-u.ac.jp.

1

2 Simple and Eﬃcent Algorithm for Large Scale...

well.

O

The improvement of complexity in the algorithm of large-scale hard disk system
was developed by Rapaport (1980).5,6 This algorithm is based on the concept of
sub-cell method,7 and both Collision Event and Cell-Crossing Event are stored
into Multiple-Event Time List. Then the minimum time is searched by Binary
Search Tree(BST).8 When the event occurs, the particle-pair or the particle - sub-
cell respectively relevant to Collision Event or Cell-Crossing Event is deleted, and
collision time for the particle relevant to the event is re-computed and new nodes are
created. The BST is reconstructed by inserting these new nodes, and the minimum
time is searched. On this algorithm, the averaged complexity per Event become

(log N ), and the reduction of the large amount of computation is realized.

O

However, since the algorithm of Rapaport is very complicated and diﬃcult to un-
derstand, in the 90s the several algorithms to simplify a data structure and improve
the eﬃciency in the large-scale molecular dynamics simulation were proposed.9,10,11
Mar´ın et al.12 developed the technique of Local Minima Algorithm (LMA) to avoid
additional re-computation for Event List. When we actually schedule future event
list, LMA put only the minimum event time relevant to each particle into Complete
Binary Tree (CBT). In 1995, Mar´ın and Cordero13 compared various
(log N )
searching algorithms actually in EDMD simulation, systematically. They con-
cluded that the eﬃciency of Complete Binary Tree (CBT) was the most suitable
for hard disks system in all density regions. In the number increase of particles,
CBT was clearly showed that eﬃciency increased signiﬁcantly from other searching
algorithms. Compared the BST of Rapaport with CBT of Mar´ın et al., although the
(log N ), a simplicity, eﬃciency and memory reduc-
complexity is the same order
tion, and constant coeﬃcient is diﬀerent actually carrying out EDMD simulation.
In this paper, we developed an algorithm based on a strategy diﬀerent from
Cell-Crossing type. The algorithm is extended on Exclusive Particle Grid Method
(EPGM) developed by Form et al.,15 (Sec. 2) Then, bookkeeping method16 is
applied. (Sec. 3) Compared with the Cell-Crossing type, our algorithm extended
the concept of Linked-Cell Method17,18 and Neighbor List, which are often used
in TSDMD to carry out an eﬃcient simulation.19 From the analysis of complexity,
we show our algorithm is smaller than the complexity of Cell-Crossing type. By
an empirical evaluation of the simulation in hard disk system, our code could be
showed that the performance was better than that of any past-published works.

O

In either soft-core or hard-core system, it is regarded as the improvement in the
speed base on conventional sub-cell method being impossible in the system with
inﬁnite volume.10 This is because the space spreads out inﬁnitely, inﬁnite arrays
must be prepared for inﬁnite sub-cells. We developed the method of compressing
information about the inﬁnite sub-cells into limited ﬁnite array. In addition, the
hashing method, which is known as the most eﬃcient searching algorithm, is applied
to our method in order to pull out the information on a neighbor cells in high
speed. Especially, it is found that the hashing method could be applied easily on
our method.

M. Isobe

3

Various applications in a very wide range ﬁeld will be possible by changing ex-
ternal ﬁeld and the collision rule in the large-scale EDMD. The typical examples
performed by EDMD so far are as follows; phase transition in the equilibrium sys-
tem (solid-liquid transition and 2-dimensional melting),1,2,3,4 the non-equilibrium
ﬂuid system (e.g. Rayleigh-B´enard convection),20,21 the non-equilibrium chemical-
reaction system,22 the non-equilibrium dissipative system (granular system),23,24,25
random disk packing.26,27 When large-scale computation become possible in these
system, the worth of simulation in a hard disk system must increase signiﬁcantly.

The outline of this paper is as follows. In Sec. 2 and 3, the developed algorithms
themselves are explained. The comparisons with the algorithm of Cell-Crossing type
by analyzing the complexity are shown in Sec. 4. The empirical evaluation is also
given in Sec. 5. The extension to the inﬁnite system based on developed algorithms
is explained in Sec. 6.
In Sec. 7, a short summary and a ﬁnal comment are
presented.

2. Extended Exclusive Particle Grid Method

Sub-cell method is often used to achieve the signiﬁcant reduction of computation. In
the EDMD, the complexity of producing and updating future event list for restoring
event time of each particle-pair are reduced to
(1), respectively, by the
sub-cell method. LCM is the method of dividing the system by small sub-cells.
When the size of sub-cell is bigger than a particle diameter, we will have a diﬃculty
to code a program, because we do not know how many particles enter in each
sub-cell. Therefore, link lists must be prepared for the particles in each sub-cell.

(N ) and

O

O

On the other hand, another eﬃcient sub-cell method, called Exclusive Parti-
cle Grid Method (EPGM), was individually developed by Buchholtz and P¨oschel
(1993)14 and Form, Ito, and Kohring (1993)15 to simulate the soft-core granular
particle system in TSDMD. In this method, there is only one particle in each sub-
cell. Though the EPGM is substantially the method of putting a particle to one
sub-cell in LCM, it does not need to use pointers for neighbor sub-cells or link list.
Here sub-cells in EPGM are called ”grid”. In the EPGM, the length of grid lgx is
determined by the following inequality;

σ < lgx < √2σ,

where σ is the radidus of particle. One example of the number of grid ngx, ngy in
the system length and the length of grid lgx, lgy can be calculated by the following
equations.

lgx = IN T (lx/(√2σ)) + 1

lgy = IN T (ly/(√2σ)) + 1

ngx = lx/lgx

ngy = ly/lgy.

(1)

(2)

(3)

(4)

(5)

4 Simple and Eﬃcent Algorithm for Large Scale...

Figure 1: A typical example of the mapping pattern using EPGM when packing
fraction ν = 0.70. Both the position of hard disks and the occupied lattices are
shown.

×

Note that the total number of grid is ng = ngx
ngy. As an analogy of the lattice
spin system, EPGM is regarded as N + 1-states potts model of the square lattice
system. This is because the particles are completely mapped into each lattice (i.e.
one grid corresponds to one particle respectively), and we put 0 into the rest of
grids in which a particle is not contained (see Fig. 1). Since continuous and random
positions of the particles are mapped into the lattice, the speciﬁcation of neighbor
particles becomes very easy.
Form et al.15 applied this algorithm in the high-density soft-core granular system
with shot-distance interaction in TSDMD. They achieved high eﬃciency on a vector
computer. Based on this algorithm, the extension of EPGM to EDMD in the hard
disk system is developed.

When the system is in high-density, EPGM can be simply applied to EDMD.
For a candidate of next colliding particle-pairs, we need to search only 24 neighbor
grids, which form the square mask. If neighbor grid is not 0, the collision times of
candidates of colliding particle-pairs are computed only registered particle number
in the square mask. We call these 24 neighbor grids MIN, because this is the
minimum mask in the simulation of EDMD. Note that if the smaller mask is used,
the computation wills breakdown during the simulation, since a possibility of overlap
between a central particle in the mask and particles out of the mask occurs. When
EPGM is applied in the high-density system, the computation is optimized because
a suﬃcient number of particles contained in the mask MIN. These are enough as
candidates of particle-pairs of collision, and only required particles are registered in
the mask MIN; the eﬃciency increases as a result of the computational reduction
of collision time for neighbor particle-pairs.

On the other hand, when the system is in low-density, suﬃcient number of

M. Isobe

5

Figure 2: Minimum mask (MIN.) and larger masks, which are generated by the
algorithm of making circle on the computer display, are shown. The solid lines in
each mask denote the minimum distance from the central lattice of mask to the
frame of mask.

particles as candidates of collision are not registered in the mask MIN. Under such
a situation, the computation will breakdown, since collision time between the central
particle in the mask and particles out of the mask will become next minimum time.
In order to prevent this breakdown, the extension of EPGM is developed. The
region must be extended to look for candidates of collision particle-pairs bigger
than MIN. Since the rigorous isotropy of neighbors in EDMD are not necessarily
demanded, the shape of mask might approximate with a rough circle. It is found
that the mask approximated by the lattice-like grid with the circle can use the
algorithm describing the circle on the discrete space of computer display. Figure 2
displayed the circles from R= 3 to R= 10 on the discrete space of computer display,
which MIN is also showed over Fig.2. The total number of neighbor grids (mask)
are 24 (MIN), 36 (R= 3), 68 (R=4), 96 (R=5), 136 (R=6), 176 (R=7), 224 (R=8),
292 (R=9), 348 (R=10), respectively. This extension of EPGM is called Extended
Exclusive Particle Grid Method (EEPGM).

Compared with LCM, EEPGM is simple, because rough neighbor particles can
be simply regulated by grids so that only the necessary minimum may be taken.
In EEPGM, since link list and pointers for neighbor sub-cell is not necessary, a
memory is also sharply reducible, and the number of operation for setting EEPGM
is small, and the program become very simple. Moreover, the extension to the
inﬁnite volume system is easy when using a hashing method to EEPGM. This is
explained at Sec. 6 in detail.

3. Neighbor List and Dynamical Upper Time Cut-Oﬀ

6 Simple and Eﬃcent Algorithm for Large Scale...

Though EEPGM realize signiﬁcant reduction of computation compared with con-
sidering all particle-pairs, it is inadequate when large number of particle simulation
is really performed. In this section, the next step of the strategy of increase in eﬃ-
ciency based on EEPGM is developed. Here, the concept of Neighbor List (NL)16
is adopted. Since grid correspond to each particle, we can regard the registration of
Neighbor List as already being completed. Therefore, we can only search neighbor
particles along to the form of mask.

In the usual way of LCM+NL, after the system divided into sub-cells, particles
are listed into link list. Then neighbor particles within radius rN L are entered into
Neighbor List from link list. However, since the length of both lists is unknown,
they must be estimated by trial and error. Although registration of NL is completed
by one operation in EEPGM, LCM+NL must use two diﬀerent unknown size lists,
which is accompanied by a complicated procedure and requires diﬃculty of pro-
gramming. Therefore, EEPGM (+NL) is simple, which means that both debugging
and extension do not require excessive eﬀort, moreover, only the minimum nearest
particles can be seen, because the system is divided into the minimum sub-cells, i.e.
grid. Since registration of NL is completed by one operation in EEPGM, eﬃciency
is better than LCM+NL at a result.

O

The next improvement in speed is that the computation of collision time only
from particle-pairs which are registered in the mask of EEPGM during the time
(1) instead of
tN L. Then the complexity of EEPGM for every event is reducible to
(N ). After time tN L proceeds, the grids are again re-mapped in order to update
O
neighbor particles. The time of Neighbor List tN L must be determined that the
central particle does not collides with the particle out of the mask completely. The
far length of tN L occurs a count mistake of particle-pairs, which produces negative
collision time during the simulation. This conventional determination of tN L needs
huge trial and error. In order to overcome these diﬃculties, tN L is determined by the
following procedure. First, after completing EEPGM, the maximum velocity vmax
in the system is searched, and the value of its velocity is restored (the complexity
of this searching is the same order of EEPGM
(N )). Next, time tN Lmin of the
system is calculated. In this calculation we suppose both the central particle and the
particle out of the mask has the maximum velocity and those particles undergoes
head-on collision. If tN L = tN Lmin, a count mistake of collision pairs in the system
never occurred during the time tN Lmin. The minimum NL distance rN Lmin is
required when tN Lmin is calculated, which become clear from the geometry of the
adopted mask shown in Fig. 2. Therefore, tN Lmin is given by

O

tN Lmin =

rN Lmin

(2σmax)

−
2vmax

(6)

where σmax is the maximum radius of particle in the system. The minimum dis-
tances rmin for each mask are shown in Table 1.

When we simulate in the equilibrium system, this strategy will work well because
tN Lmin hardly changes. However, in the non-equilibrium system (e.g. the relaxing

Table 1. The minimum distance for each mask.

rmin/lgx

MIN. R=3 R=4 R=5 R=6 R=7 R=8 R=9 R=10
√85

√13 √18 √29 √40 √52 √72

√5

2

M. Isobe

7

process or the system with heat bath) it breakdown because the maximum velocity
changes drastically at every step. To overcome this diﬃculty, we must check the
maximum velocity for each event with energy increase. Fortunately the complexity
of this checking process is
(1). Therefore, in the simulation of the non-equilibrium
system tN L will change one after another. We call this changing tN L techniques
Dynamical Upper Time Cut-oﬀ (DUTC). The development of DUTC, EEPGM
became applicable in the non-equilibrium system.

O

Although in the high-density system we do not need to update the grid pattern
for a long time, in the low density we should often update the grid pattern when we
use the mask MIN because the grid pattern changes drastically. In order to reduce
the frequency of updating grid pattern, we can only use a bigger mask.

4. Analysis of Complexity

Analysis of complexity is one of important factor to estimate the eﬃciency of algo-
rithm. In this section, a comparison of analysis of complexity between the algorithm
of the Cell-Crossing type and the EEPGM + DUTC is shown. The diﬀerence be-
tween the algorithm of Cell-Crossing type and the strategy of EEPGM + DUTC
is Cell-Crossing Event itself. Therefore, especially looking at this point, both com-
plexities with a constant coeﬃcient k are estimated in the case of A
N collisions
being actually simulated. Note that the particle number N is supposed to be a
quite large number and the techniques of improvement in the speed are also used
in both algorithm denoted by Mar´ın et al.12

×

Cell-Crossing type (LCM + Cell-Crossing Event)

•

×

– The initial and last step (

1)
Linked-Cell Method — kLCM
Computation of Event Time — kP P
×
Construction of Complete Binary Tree — kCBT
×
Update the ﬁnal position of particles — kUP DAT E

Nc

N

×

×

×

9

– Iteration Step (loop)

N + kP C

4

N

×

×

N

×

N

(A

N )

(kP P

9

Nc+kCBT

log N )+(B

N )

(kP C

3+kCBT

log N )

×

×

×

×

×

×

×

×

×

where Nc is the number of particles contained in per sub-cell. The most
important point is that the Cell-Crossing Event occurs by a certain ratio of
N times Cell-
Collision Event. Therefore, the additional computation of B
N times Collision
Crossing Events are needed, when we want to simulate A

×

×

8 Simple and Eﬃcent Algorithm for Large Scale...

Events. Since the complexity of the terms related to Cell-Crossing Event is
always

(N ), this is not negligible in the actual simulation.

O
EEPGM + DUTC

•

×

N

C)

– Update of EEPGM (
EEPGM — kEEP GM
Computation of Event Time — kP P
×
Search the Maximum Velocity — kMV S
Construction of Complete Binary Tree — kCBT
×
Update the ﬁnal position of particles — kUP DAT E

×
N

Ng

N

×

×

– Iteration Step (loop)

(A

N )

(kP P

Ng + kCBT

log N )

×

×

×

×

N

×

N ,

where Ng is the averaged particle number of the mask. Actually the value of
A, which is the same order of the frequency of updating
C is an order C
EEPGM.

∼

Now, the comparison with order N in both algorithm with constant coeﬃcient is
as follows:

•

•

Cell-Crossing type

9

(kLCM + kP P
N + (A

×
×
kCBT + B

×
EEPGM + DUTC

Nc

×

(kEEP GM + kP P
log N
N

×

×

×

(A + 1) + kP C
N

×
kCBT )

×
log N

(3

×

×

×

B + 1) + kCBT + kUP DAT E)

×

2

Ng + kMV S + kCBT + kUP DAT E)

C

N + (A

kCBT )

×

×

×

×

×

×

×

O

N

kCBT

(N log N ) (i.e. B

The most striking point is that the complexity of Cell-Crossing Event is of order
of
log N ). This result of analysis suggest that
the eﬃciency of EEPGM + DUTC is better than Cell-Crossing type when the
simulation with the enormous number of particle is performed. On the other hand,
in the comparatively small particle system, the coeﬃcient of C
N terms in EEPGM
+ DUTC may be larger than Cell-Crossing type. However, the diﬀerence might
be quite small, and it is impossible to estimate an exact coeﬃcient of algorithms
analytically. To the author’s knowledge, the coeﬃcient of N terms is strongly
dependent on the ratio of Nc to Ng, and the rough estimation shows both algorithms
4. Actually, the increase of computing Cell-Crossing
are same when Ng/Nc
Events is almost not eﬀect to CPU time as far as the simulation in the very large
number particle system is actually performed.

×

∼

5. Empirical Evaluation

M. Isobe

9

At the stage of actually running the simulation, the order of the complexity is not
so reliable, because it depends strongly on a constant coeﬃcient when the number
of the particle is relatively small. Moreover, the eﬃciency of the code changes
signiﬁcantly by the ability of a computer, the language, the performance of compiler,
and the ability of programmers. Though a perfect comparison of eﬃciency of codes
developed by the past workers is impossible, some literatures showed how many
particle collisions per CPU-hour can their codes be computed by their computers.
Mar´ın et al.(1993)12 simulated with hard disk system, and Mar´ın et al. also
compared their code with the codes based on two main high-speed algorithms pro-
posed by Rapaport(1980)5 and Lubachevsky(1991),9 respectively. At a result, it
was shown that the eﬃciency of the code of Mar´ın et al. was superior in the entire
density region. Therefore, the author’s code should be compared with the code of
Mar´ın et al., and it computed with the number of the particles equal. Mar´ın et
al. achieved the maximum performance at 16.07 millions of collisions per one CPU
hour on workstation SUN690. Note that the eﬃciency showed only the highest per-
formance because the performance is diﬀerent for a diﬀerent density of the system.
On the other hand, author’s code achieved the maximum performance 460 millions
of collisions per one CPU hour (Alpha600 compatible, DEC-Fortran). It was found
that the high eﬃciency was realized as for the author’s code even if the performance
of the machine was deducted.

Note that the workstation of our laboratory could actually simulate the 2,500,000
particle system. In this simulation, the amount of an installed memory was 250M byte
and the computation performance was 130 millions of collisions per one CPU hour.

6. Extension to Inﬁnite Volume System

In this section, a simple example in the open boundary system that does not have a
ceiling is considered. This is the case that there is an energy source at the bottom
of the system under the uniform gravity.

The system is also divided into grids by EEPGM. However, because the top of
the system is opened, grid goes to the top of the system inﬁnitely. This means that
the number of arrays for grid becomes inﬁnity, and the simulation is impossible
from ﬁnite memory. To overcome this diﬃculty, the hashing method, which is well
known as the fastest searching algorithm, is applied to keep the number of arrays
in ﬁnite size and to simulate the dynamics of the system in high-eﬃciency.

Construction of Data Structure

•

Firstly, the serial number of grid NG(ig, jg) is deﬁned by

NG = Ngx(jg

1) + ig,

−

(7)

Ngx) are the total number of grid and the index
where Ngx and ig(1
≤
of grid in the horizontal direction, respectively; jg(1
) means the
index of grid in the vertical direction. In addition, the maximum number of

≤ ∞

jg

≤

≤

ig

10 Simple and Eﬃcent Algorithm for Large Scale...

the serial grid NGmax is calculated by NGmax = Ngx(jgmax
pair (igmax, jgmax) is at the maximum grid pair of containing the particle.

1) + igmax; the

−

≤

≤

NG

The serial grid NG(1
NGmax) is one-dimensional array, in which
particle number or 0 are listed. This is called one-dimensional Virtual Ar-
ray. When jmax is large value, there are many 0’s in the one-dimensional
Virtual Array. Though there is only information that a particle is not just in
grid, these 0 relates to the memory capacity directly. Now Virtual Array is
compressed. After all, the necessary information is the particle number and
its index of grid. Therefore, one-dimensional integer arrays are prepared for
A(N ), BX(N ), BY (N ), and grids of 0 in Virtual Array are ignored, and then
packed in order from the end; A(N ) stores the particle numbers only, and
BX(N ) and BY (N ) stores indexes of ig and jg for each particle, respectively.
If you want to know whether there is a particle in grid (i′
g), you have only
to search the index-pairs correspond to (i′
g) in the lists of BX(N ), BY (N )
linearly. However, this process is ineﬃcient because the complexity of
(N )
is necessary in searching.

g, j′

g, j′

O

Therefore, the hashing method known as an algorithm which can realize the
searching with
(1) is applied. The following simplest hashing function is
explained here as an example though various hashing functions can be con-
sidered and the room of the development is still left.

O

First, hashing function is deﬁned by

1

(8)

] + 1

k = [

NG
−
L
which means that Virtual Array is equally divided by the length L (e.g.
10) and key k is calculated correspond to serial number NG. Then, kmax =
5
∼
[ NGmax
] is calculated using NGmax. Then additional arrays C(kmax), D(kmax)
L
are prepared, these arrays are restored in C(k) where k begins in A(N ) and
in D(k) how much size of arrays for each k.
In this case, necessary ar-
rays are A(N ), BX(N ), BY (N ), C(kmax), D(kmax), and these are conﬁned
to a ﬁnite value. Since additional arrays to use the hashing method is only
C(kmax), D(kmax)(kmax < N ), the amount of use of a memory slightly in-
crease in comparison with the linear searching.

•

Searching Process
In order to know what the particle number is in the grid (i′
g), the following
G = Ngx(j′
process is carried out. First, a serial number is calculated by N ′
g −
g. Next, k′ is calculated by the equation of hashing function (8). Then,
1) + i′
C(k′) +
the searching ranges of BX, BY are limited only to index of [C(k′)
∼
D(k′)
L). If there are equal pairs of grid (i′
g) as a result of the
searching of BX, BY , the index s of BX, BY reveals A(s) which is the particle
number in the grid (i′
g, j′
g). When equal pair is not found in BX, BY , there
is no particle in the grid.

g, j′

g, j′

1] (

≤

−

This procedure becomes possible in high-speed simulation. The complexity
becomes
(N ), because a searching is
(1) instead of the linear searching
only carried out on the length of L with hashing method.

O

O

M. Isobe

11

A computation is possible for other boundary conditions with the same proce-
dure if one-dimensional Virtual Array can be created. Therefore, high-speed sim-
ulation is possible what kind of boundary is applied, in principle. There will be a
room of the improvement in hashing function, which is the easiest dividing equally,
because it is obviously inappropriate when particles are distributed heterogeneously.
The strategy of EEPGM has an advantage that the extension is easy. The ease

of a development is an important factor of the evaluation of an algorithm.

Note that a problem in low-density system is that the arrays assigned to grid
increases overwhelmingly in comparison with the number of the particles. This is
not desirable from the point of the memory capacity as the same of inﬁnite system.
However, arrays for grid are compressed to the size of the particle number in the
same way as described above. Since supplementary arrays is made by hashing
method and information on neighboring grids is eﬃciently obtained, there is no
problem both eﬃciency and memory capacity.

7. Concluding remarks

In this paper, we developed an algorithm for hard disk system without using Cell-
Crossing Event, which is simple, eﬃcient and easy to extend. EEPGM can be
easy to extension because of its simplicity, which can never be realized in LCM.
One example is the system that hard disks with various size of diameter coexist.
Though there was a limitation in the degree of the poly-dispersion with EPGM
described to Buchholtz et al.,14 EEPGM can be applied easily to those system.
First, grid is made based on the smallest particle radius in the system. Next, we
have only to check the nearest grids by using the suitable mask of the bigger level
when the poly-dispersity increases. Like this, EEPGM has a wider application than
EPGM.

This code achieved the fastest simulation speed in the world; about 460 million
of collisions per CPU hour for the 2500 disk system on the VT-Alpha-600. Since
the order of complexity is
(log N ), the increase of complexity is slow when the
particle number increase. Now, we can carry out large-scale molecular dynamics
simulation (

106) on the usual Workstation in our laboratory.

O

Hard particle simulation is a powerful tool to study the ﬂuidized state described
by the kinetic theory or hydrodynamics. Therefore, the large-scale simulation in
the hard particle system will become an important subject.

At the end, the algorithm in this paper is suitable for the scalar machine, and
the development of the algorithm for the parallel machine is a future subject. Note
that we discuss only hard disks system in 2-d for simplicity, but an extension to
hard spheres system in 3-d is easy to be carried out.

∼

12 Simple and Eﬃcent Algorithm for Large Scale...

Acknowledgements

The auther thanks Prof. Nakanishi for reading the manuscript and making a number
of helpful suggestions. He also gratefully acknowledge helpful discussions with Dr.
Muranaka on several points in the paper. A part of the computation in this work
was done by the facilities of the Supercomputer Center, Institute for Solid State
Physics, University of Tokyo.

References

1. B. J. Alder and T. E. Wainright, J. Chem. Phys. 27, 1208 (1957).
2. B. J. Alder and T. E. Wainright, J. Chem. Phys. 31, 459 (1959).
3. B. J. Alder and T. E. Wainright, J. Chem. Phys. 33, 1439 (1960).
4. B. J. Alder and T. E. Wainright, Phys. Rev. 127, 359 (1962).
5. D. C. Rapaport, J. Comput. Phys. 34, 184 (1980).
6. D. C. Rapaport, The art of molecular dynamics simulation (Cambridge University

Press, Cambridge, 1995).

7. J. J. Erpenbeck and W. W. Wood, in Modern Theoretical Chemistry Vol.6, Statis-
tical Mechanics Part B, ed. B.J.Berne (Plenum, New York, 1977), Chap. 1, p. 1.
8. D. E. Knuth, Sorting and Searching, The Art of Computer Programming, Vol.3,

(Addison-Wesley, Reading, Mass., 1973).

9. B. D. Lubachevsky, J. Comput. Phys. 94, 255 (1991).
10. K. Shida and Y. Anzai, Comput. Phys. Commun. 69, 317 (1992).
11. A. T. Krantz, ACM Trans. Model. Comput. Sim. 6, 185 (1996).
12. M. Mar´ın, D. Risso, and P. Cordero, J. Comput. Phys. 109, 306 (1993).
13. M. Mar´ın and P. Cordero, Comput. Phys. Commun. 92, 214 (1995).
14. V. Buchholtz and T. P¨oschel, Int. J. Mod. Phys. C4, 1049 (1993).
15. W. Form, N. Ito, and G. A. Kohring, Int. J. Mod. Phys. C4, 1085 (1993).
16. L. Verlet, Phys. Rev. 159, 98 (1967).
17. B. Quentrec and C. Brot, J. Comput. Phys. 13, 430 (1975).
18. R. W. Hockney and J. W. Eastwood, Computer Simulation Using Particles

(McGraw-Hill, New York, 1981).

19. M. P. Allen and D. J. Tildesley, Computer Simulation of Liquids (Clarendon Press,

Oxford, 1987).

2550 (1988).

20. M. Mareschal, M. Malek-Mansour, A. Puhl, and E. Kestemont, Phys. Rev. Lett. 41,

21. D. C. Rapaport, Phys. Rev. Lett. 60, 2480 (1988).
22. T. Kawakatsu and A.Ueda, J. Phys. Soc. Jpn. 56, 847 (1987).
23. I. Goldhirsch and G. Zanetti, Phys. Rev. Lett. 70, 1619 (1993).
24. S. McNamara and W. R. Young, Phys. Rev. E53, 5089 (1996).
25. C. Bizon, M. D. Shattuck, J. B. Swift, W. D. McCormick, and H. L. Swinney, Phys.

Rev. Lett. 80, 57 (1998).

26. B. D. Lubachevsky and F. H. Stillinger, J. Stat. Phys. 60, 561 (1990).
27. B. D. Lubachevsky, F. H. Stillinger, and E. N. Pinson, J. Stat. Phys. 64, 501 (1991).

