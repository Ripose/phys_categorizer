2
0
0
2
 
t
c
O
 
8
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
5
3
0
0
1
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Numerical methods for solving the time-dependent Maxwell equations∗

H. De Raedt†, J.S. Kole‡, K.F.L. Michielsen§, M.T. Figge¶
Applied Physics - Computational Physics∗∗,
Materials Science Centre
University of Groningen, Nijenborgh 4
NL-9747 AG Groningen, The Netherlands
(Dated: February 2, 2008)

We review some recent developments in numerical algorithms to solve the time-dependent Maxwell
equations for systems with spatially varying permittivity and permeability. We show that the Suzuki
product-formula approach can be used to construct a family of unconditionally stable algorithms,
the conventional Yee algorithm, and two new variants of the Yee algorithm that do not require the
use of the staggered-in-time grid. We also consider a one-step algorithm, based on the Chebyshev
polynomial expansion, and compare the computational eﬃciency of the one-step, the Yee-type, the
alternating-direction-implicit, and the unconditionally stable algorithms. For applications where
the long-time behavior is of main interest, we ﬁnd that the one-step algorithm may be orders of
magnitude more eﬃcient than present multiple time-step, ﬁnite-diﬀerence time-domain algorithms.

PACS numbers: 02.60.Cb, 03.50.De, 41.20.Jb

I.

INTRODUCTION

The Maxwell equations describe the evolution of electromagnetic (EM) ﬁelds in space and time [1]. They apply to
a wide range of diﬀerent physical situations and play an important role in a large number of engineering applications.
In many cases, numerical methods are required to solve Maxwell’s equations [2, 3]. A well-known class of algorithms
is based on a method proposed by Yee [4]. This ﬁnite-diﬀerence time-domain (FDTD) approach owes its popularity
mainly due to its ﬂexibility and speed while at the same time it is easy to implement [2, 3].

A limitation of Yee-based FDTD techniques is that their stability is conditional, depending on the mesh size of
the spatial discretization and the time step of the time integration [2, 3]. Furthermore, in practice, the amount of
computational work required to solve the time-dependent Maxwell equations by present FDTD techniques [2, 3, 5,
6, 7, 8, 9, 10, 11, 12] prohibits applications to a class of important ﬁelds such as bioelectromagnetics and VLSI
design [2, 13, 14]. The basic reason for this is that the time step in the FDTD calculation has to be relatively small
in order to maintain stability and a reasonable degree of accuracy in the time integration. Thus, the search for new
algorithms that solve the Maxwell equation focuses on removing the conditional stability of FDTD methods and on
improving the accuracy/eﬃciency of the algorithms.

A systematic approach to construct unconditionally stable algorithms is to employ a Suzuki product-formula [15]
to approximate the time evolution operator [16]. In the case of EM ﬁelds, the latter is the matrix exponential of a
skew-symmetric matrix and the approximations take the form of products of orthogonal transformations [11, 12]. The
resulting numerical algorithms are unconditionally stable by construction [16, 17].

The spectral-domain split-operator technique proposed in Ref.[10] is one of the many forms that results from the use
of the Lie-Trotter-Suzuki product formulas [15]. This technique makes use of Fast Fourier Transforms to compute the
matrix exponentials of the displacement operators. The choice made in Ref. [10] yields an approximation to the time-
evolution operator that is no longer orthogonal and hence unconditional stability is not automatically guaranteed [18].
In contrast, the methodology proposed in Refs. [11, 12] yields eﬃcient, explicit, unconditionally stable schemes that
operate on the EM ﬁelds deﬁned on the real space grid only. These algorithms naturally allow for the spatial variations
in both the permittivity and the permeability.

The Suzuki product-formula approach also provides a uniﬁed framework to construct and analyse other time
stepping algorithms [16, 19]. To illustrate this point we show that the conventional Yee algorithm and the alternating-
direction-implicit (ADI) time-stepping algorithms [6, 7, 8, 9, 19] ﬁt into this framework. Furthermore we propose new
variants of the Yee algorithm.

∗ Invited talk presented at the International Computational Accelerator Physics Conference 2002
† E-mail: deraedt@phys.rug.nl
‡ E-mail: j.s.kole@phys.rug.nl
§ E-mail: kristel@phys.rug.nl
¶ E-mail: m.t.ﬁgge@phys.rug.nl
∗∗ http://www.compphys.org

Another route to improve upon the accuracy/eﬃciency of time-integration schemes is to make use of the Chebyshev
polynomial expansions of the matrix exponential [20, 21, 22, 23, 24, 25]. In this paper we also discuss a one-step
algorithm, based on Chebyshev polynomials, to solve the time-dependent Maxwell equations for (very) large time
steps [26, 27].

The main purpose of this paper is to review the basic ideas behind the recent developments in numerical algorithms
to solve the time-dependent Maxwell equations and to compare the virtues and shortcomings of the diﬀerent methods.
The plan of the paper is as follows. In Section II we brieﬂy discuss the basic physical symmetries of the time-dependent
Maxwell equations. The general framework to construct time-integration algorithms is laid out in Section III. We
also pay attention to the numerical treatment of the current source term. In Section IV we use the simplest case of
the time-dependent Maxwell equations to illustrate how the various algorithms can be implemented. We explicitly
show how the conventional Yee algorithm naturally ﬁts into this framework and, by minor modiﬁcation, construct
second-order and fourth-order time-accurate schemes that do not require the use of staggered-in-time ﬁelds, nor extra
memory to store intermediate results. Then we recall the steps to construct the unconditionally stable algorithms
proposed in Ref. [11, 12] and analyse a modiﬁcation to improve the time-integration accuracy. Finally we discuss the
implementation of the ADI and one-step algorithms. A discussion of the results of numerical experiments and our
conclusions are given in Section V and VI respectively.

II. THEORY

We consider EM ﬁelds in linear, isotropic, nondispersive and lossless materials. The time evolution of EM ﬁelds in
these systems is governed by the time-dependent Maxwell equations [1]. Some important physical symmetries of the
Maxwell equations can be made explicit by introducing the ﬁelds

X(t)

√µ H(t) and Y(t)

√ε E(t) .

≡

≡

Here, H(t) = (Hx(r, t), Hy(r, t), Hz(r, t))T denotes the magnetic and E(t) = (Ex(r, t), Ey(r, t), Ez(r, t))T the electric
ﬁeld vector, while µ = µ(r) and ε = ε(r) denote, respectively, the permeability and the permittivity. In the absence
of electric charges, Maxwell’s curl equations [2] read

where J(t) = (Jx(r, t), Jy(r, t), Jz(r, t))T represents the source of the electric ﬁeld and

denotes the operator

H

X(t)
Y(t)

∂
∂t

(cid:18)

=

(cid:19)

H

(cid:18)

X(t)
Y(t)

1
√ε

0
J(t)

,

(cid:19)

(cid:18)

−

(cid:19)

0

H ≡  

1
√ε ∇ ×

1
√µ

−

1
√µ ∇ ×
0

1
√ε

.

!

Writing Z(t) = (X(t), Y(t))T it is easy to show that
product
also satisfy
measure distances in units of λ and expresss time and frequency in units of λ/c and c/λ, respectively.

, with respect to the inner
Z′(t) dr, where V denotes the system’s volume. In addition to Eq.(2), the EM ﬁelds
(√εY(t)) = 0 [1]. Throughout this paper we use dimensionless quantities: We

Z′(t)
Z(t)
V
·
|
h
(√µX(t)) = 0 and
R
∇ ·

is skew symmetric, i.e.

ZT (t)

T =

−H

i ≡

∇ ·

H

H

A numerical algorithm that solves the time-dependent Maxwell equations necessarily involves some discretization
procedure of the spatial derivatives in Eq. (2). Ideally, this procedure should not change the basic symmetries of the
Maxwell equations. We will not discuss the (important) technicalities of the spatial discretization (we refer the reader
to Refs. [2, 3]) as this is not essential to the discussion that follows. On a spatial grid Maxwell’s curl equations (2)
can be written in the compact form [11]

The vector Ψ(t) is a representation of Z(t) on the grid. The matrix H is the discrete analogue of the operator (3),
and the vector Φ(t) contains all the information on the current source J(t). The formal solution of Eq. (4) is given by

∂
∂t

Ψ(t) = HΨ(t)

Φ(t) .

−

Ψ(t) = U (t)Ψ(0)

U (t

u)Φ(u)du ,

t

−

0
Z

−

2

(1)

(2)

(3)

(4)

(5)

where

denotes the time-evolution matrix. If the discretization procedure preserves the underlying symmetries of the time-
dependent Maxwell equations then the matrix H is real and skew symmetric [11], implying that U (t) is orthogonal [28].
Physically, the orthogonality of U (t) implies conservation of energy [11].

U (t) = etH,

III. TIME INTEGRATION ALGORITHMS

There are two, closely related, strategies to construct an algorithm for performing the time integration of the time-
dependent Maxwell equations deﬁned on the grid [17]. The traditional approach is to discretize (with increasing level
of sophistication) the derivative with respect to time [17]. The other is to approximate the formally exact solution, i.e.
the matrix exponential U (t) = etH by some time evolution matrix
U (t) [16, 17]. We adopt the latter approach in this
paper as it facilitates the construction of algorithms with speciﬁc features, such as unconditional stability [11, 16].

If the approximation

U (t) is itself an orthogonal transformation, then

denotes the 2-norm
=
, for an arbitrary initial condition Ψ(0) and for all times t and hence the time integration algorithm deﬁned

= 1 where
of a vector or matrix X [28]. In the absence of source terms (i.e. Φ(t) = 0) this implies that
Ψ(0)
k
k
by

U(t)Ψ(0)
k

X
k
Ψ(t)
k

U(t)
k

k
k

=

e

e

e

e

k

k

e

U (t) is unconditionally stable by construction [16, 17].
In the presence of current sources, for general

U (t), it follows immediately from Eq.(5) that

e

Ψ(t)

k

k ≤ k

e
Ψ(t)
k

t

+

ǫ

Ψ(0)
k

+

Φ(u)
k

du

,

(cid:19)

0 k
Z

k
(cid:18)

where

e
u
≤
From Eq.(5) it follows that the EM ﬁelds Ψ(t) change according to

ǫ for 0

t and

U (u)

U(u)

k ≤

−

≤

e

k

ǫ is a measure for the accuracy of the approximation

U(t).

e

e

e

e

Ψ(t + τ ) = eτ HΨ(t)

e(t+τ

u)HΦ(u)du.

−

t+τ

−

t
Z
In the time-stepping approach we approximate the source term in Eq.(8) by the standard 3-point Gauss-Legendre
quadrature formula [29]

Ψ(t + τ ) = eτ HΨ(t) +

wie(1+xi)τ H/2Φ(t + (1 + xi)τ /2) +

(τ 7),

O

τ
2

2

i=0
X

where x0, x1, x2 are the zeros of the Legendre polynomial P3(x) = x(5x2
In practice we replace e(1+xi)τ H/2 in Eq.(9) by an approximation

−
U ((1 + xi)τ /2).

3)/2 and wi = 8/(1

i )(15x2
x2

i −

−

3)2 [29].

We now consider three options to construct the approximate time evolution matrix

U (t). We exclude from the
discussion the exceptional cases for which the matrix exponential U (t) = etH can be calculated directly, as these
are usually of little relevance for realistic problems. The ﬁrst approach yields the conventional Yee algorithm, a
higher-order generalization thereof, and the unconditional schemes proposed in Ref.[11]. The second option is to use
rational approximations to the exponential, yielding the standard ADI methods. Finally, the Chebyshev polynomial
approximation to the matrix exponential is used to construct a one-step algorithm.

e

e

A systematic approach to construct approximations to matrix exponentials is to make use of the Lie-Trotter-Suzuki

formula [15, 30]

A. Suzuki product-formula approach

etH = et(H1+...+Hp) = lim

etHi/m

p

i=1
Y

m

→∞  

m

,

!

3

(6)

(7)

(8)

(9)

(10)

4

(11)

(12)

(13)

(14)

(15)

(16)

and generalizations thereof [31, 32]. Expression Eq. (10) suggests that

U1(τ ) = eτ H1 . . . eτ Hp,

might be a good approximation to U (τ ) if τ is suﬃciently small. Applied to the case of interest here, if all the Hi
are real and skew-symmetric U1(τ ) is orthogonal by construction and a numerical scheme based on Eq. (11) will be
unconditionally stable. For orthogonal matrices U (τ ) and U1(τ ) it can be shown that [16]

U (τ )

U1(τ )

k

−

k ≤

[Hi, Hj]
k

k

,

τ 2
2

i<j
X

HjHi is, in general, non-zero. Relaxing the condition that U (τ ) and U1(τ ) are orthogonal
where [Hi, Hj] = HiHj −
matrices changes the τ dependence in Eq. (12) but for small τ the error still vanishes like τ 2 [32]. From Eq. (12) it
follows that, in general, the Taylor series of U (τ ) and U1(τ ) are identical up to ﬁrst order in τ . We will call U1(τ ) a
ﬁrst-order approximation to U (τ ).

The product-formula approach provides simple, systematic procedures to improve the accuracy of the approximation

to U (τ ) without changing its fundamental symmetries. For example the matrix

U2(τ ) = U1(

τ /2)T U1(τ /2) = eτ Hp/2 . . . eτ H1/2eτ H1/2 . . . eτ Hp/2,

−

is a second-order approximation to U (τ ) [31, 32]. If U1(τ ) is orthogonal, so is U2(τ ). For orthogonal U2(τ ) we have

U (t)

k

−

[U2(t/m)]m

c2τ 2t,

k ≤

where c2 is a positive constant [16].

Suzuki’s fractal decomposition approach [32] gives a general method to construct higher-order approximations based

on U2(τ ) (or U1(τ )). A particularly useful fourth-order approximation is given by [32]

U4(τ ) = U2(aτ )U2(aτ )U2((1

4a)τ )U2(aτ )U2(aτ ),

−

41/3). The approximations Eqs.(11) and (13), and (15) have proven to be very useful in many
where a = 1/(4
applications [15, 16, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41] and, as we show below, turn out to be equally useful for
solving the time-dependent Maxwell equations. As before, for orthogonal U4(τ ) we have [16]

−

U (t)

k

−

[U4(t/m)]m

c4τ 4t,

k ≤

where c4 is a positive constant.

As our numerical results (see below) show, for suﬃciently small τ , the numerical error of a time integrator vanishes
with τ according to the τ -dependence of the corresponding rigorous bound, e.g. Eqs.(12),(14), or (16). Our experience
shows that if this behavior is not observed, there is a fair chance that the program contains one or more errors.

In practice an eﬃcient implementation of the ﬁrst-order scheme is all that is needed to construct the higher-order
algorithms Eqs.(13) and (15). The crucial step of this approach is to choose the Hi’s such that the matrix exponentials
exp(τ H1), ..., exp(τ Hp) can be calculated eﬃciently. This will turn the formal expressions for U2(τ ) and U4(τ ) into
eﬃcient algorithms to solve the time-dependent Maxwell equations.

B. ADI algorithms

Instead of hunting for a decomposition that leads to matrix exponentials exp(τ H1), ..., exp(τ Hp) that are easy to
compute, one can opt for an algorithm in which each of these exponentials is calculated approximately. In principle
this might be beneﬁcial because there is more ﬂexibility in decomposing H. The standard strategy, preserving
the symmetry of H1, ..., Hp is to use rational (Pad´e) approximations to the exponential [17]. For instance, the
approximation ex
x/2) with some decompostion H = H1 + H2 yields the second-order-accurate ADI
algorithm [17, 19, 42]

(1 + x/2)/(1

−

≈

U ADI
2

(τ ) = (I

τ H1/2)−

1(I + τ H2/2)(I

τ H2/2)−

1(I + τ H1/2),

−

−

(17)

5

FIG. 1: Dependence of the Bessel function Jn(z = 200) on the order n.

where I is the identity matrix. As the subscript indicates, the algorithm (17) is second-order accurate in time. For
general skew-symmetrix H1 and H2, it is easy to show that the algorithm U ADI
(τ ) is unconditionally stable. Following
Ref. [19] we rearrange factors and obtain

2

U ADI
2

(τ )

m

k

(cid:2)

=

k

k

(I

(I

−

τ H1/2)−

τ H1/2)−

1X2X1X2 . . . X1X2(I + τ H1/2)
k
1

(cid:3)

≤ k

−
We used the fact that for skew-symmetric Hi, Xi ≡
X2X1X2 . . . X1X2k
k
is non-singular. Hence, for any number of time steps m,
constant, proving that the U ADI

2 = 1.

kk

X2X1X2 . . . X1X2kk
(I

k

1

k

=

−

(I

τ H1/2)−

(I + τ H1/2)
k
kk
1(I + τ Hi/2) is orthogonal and that
τ Hi/2)−
1
X)−
C, where C is some ﬁnite positive

(I + τ H1/2)
k

−
U ADI
2

. (18)

(τ )

−

m

k ≤

The matrix inversions appearing in Eq.(17) suggest that for practical purposes the implicit method U ADI

(τ ) will

(τ ) is unconditionally stable in the Lax-Richtmyer sense [17].
(cid:2)

(cid:3)

2

not be very useful unless I

τ H1/2 and I

τ H2/2 take special forms that allow eﬃcient matrix inversion [17, 42].

2

−

−

If X is skew-symmetric, it’s eigenvalues are pure imaginary and therefore (I

C. One-step algorithm

The basic idea of this approach is to make use of extremely accurate polynomial approximations to the matrix
exponential. First we use the Chebyshev polynomial expansion to approximate U (t) and then show how to treat the
source term in Eq. (5). We begin by “normalizing” the matrix H. The eigenvalues of the skew-symmetric matrix
H are pure imaginary numbers. In practice H is sparse so it is easy to compute
maxj
. Then, by
1, 1] [28]. Expanding the initial value Ψ(0)
k1 all lie in the interval [
iH/
construction, the eigenvalues of B
−
in the (unknown) eigenvectors bj of B, we ﬁnd from Eq. (5) with Φ(t)
0:
≡
Ψ(0)
bj|
eizbj bjh
,
i

Ψ(t) = eizBΨ(0) =

Hi,j|
i |

k1 ≡

≡ −

(19)

P

H

H

k

k

j
X

k

H

where z = t
k1 and the bj denote the (unknown) eigenvalues of B. There is no need to know the eigenvalues
and eigenvectors of B explicitly. We ﬁnd the Chebyshev polynomial expansion of U (t) by computing the expansion
coeﬃcients of each of the functions eizbj that appear in Eq. (19). In particular, as
1, we can use the
∞k=1 ikJk(z)Tk(bj) , where Jk(z) is the Bessel function of integer order k to write
expansion [29] eizbj = J0(z) + 2
Eq. (19) as

bj ≤

≤

−

1

Xk=1
Here ˆTk(B) = ikTk(B) is a matrix-valued modiﬁed Chebyshev polynomial that is deﬁned by the recursion relations

P

Ψ(t) =

J0(z)I + 2

∞

"

Jk(z) ˆTk(B)
#

Ψ(0) .

ˆT0(B)Ψ(0) = Ψ(0) ,

ˆT1(B)Ψ(0) = iBΨ(0) ,

(20)

(21)

6

(22)

(23)

(24)

and

for k
As

1.
≥
ˆTk(B)
k

ˆTk+1(B)Ψ(0) = 2iB ˆTk(B)Ψ(0) + ˆTk

1(B)Ψ(0) ,

−

≤

k ≤

z
| ≤ |

Jk(z)
|

1 by construction and

K only. The number K is ﬁxed by requiring that

k/2kk! for z real [29], the resulting error vanishes exponentially
|
fast for suﬃciently large K. Thus, we can obtain an accurate approximation by summing contributions in Eq. (20)
< κ for all k > K. Here, κ is a control parameter
with k
that determines the accuracy of the approximation. For ﬁxed κ, K increases linearly with z = t
k1 (there is no
requirement on t being small). From numerical analysis it is known that for ﬁxed K, the Chebyshev polynomial
is very nearly the same polynomial as the minimax polynomial [42], i.e. the polynomial of degree K that has the
smallest maximum deviation from the true function, and is much more accurate than for instance a Taylor expansion
of the same degree K. In Fig.1 we show a plot of Jn(z = 200) as a function of n to illustrate these points. From
Fig.1 it is clear that the Chebyshev polynomial expansion will only be useful if K lies to the right of the right-most
extremum of Jn(z = 200), i.e. K has to be larger than 200 in this example.

We now turn to the treatment of the current source J(t). The contribution of the source term to the EM ﬁeld at

Jk(z)
|
|

H

k

time t is given by the last term in Eq. (5). For simplicity we only consider the case of a sinusoidal source

J(r, t) = Θ(t)Θ(T

t)s(r) sin(Ωt),

−

where s(r) speciﬁes the spatial distribution and Ω
Θ(t) and Θ(T
be used to compose sources with a more complicated time dependence by a Fourier sine transformation.

2πfs the angular frequency of the source. The step functions
t) indicate that the source is turned on at t = 0 and is switched oﬀ at t = T . Note that Eq. (23) may

≡

−

The formal expression for the contribution of the sinusoidal source (23) reads

t

0
Z

e(t

−

u)H Φ(u) du = (Ω2 + H 2)−

1e(t

−

′

T

)H

′

H

(ΩeT

Ω cos ΩT ′

H sin ΩT ′)Ξ

×

−

−

f (H, t, T ′, Ω)Ξ ,

≡

≡

Θ(t)Θ(T

t) sin(Ωt)Ξ. The vector Ξ represents the spatial (time-independent)
where T ′ = min(t, T ) and Φ(u)
distribution s(r) and has the same dimension as Ψ(0). The coeﬃcients of the Chebyshev polynomial expansion of the
formal solution (24) are calculated as follows. First we repeat the scaling procedure described above and substitute in
Eq. (24) H = ix
k1. Then, we compute the (Fast) Fourier Transform
k1, t = z/
k
with respect to x of the function f (x, z, Z ′, ω) (which is non-singular on the interval
1). By construction,
x
≤
H
the Fourier coeﬃcients Sk(t

k1, T ′ = Z ′/
k1) are the coeﬃcients of the Chebyshev polynomial expansion [29].

Taking into account all contributions of the source term with k smaller than K ′ (determined by a procedure similar

k1, and Ω = ω

H

H

H

H

−

≤

−

k

k

k

k

1

to the one for K), the one-step algorithm to compute the EM ﬁelds at time t reads

ˆΨ(t) =

J0(t

H

k

k1)I + 2

"

Jk(t

H

k

k1) ˆTk(B)
#

Ψ(0) +

S0(t

H

k

k1)I + 2

Sk(t

H

k





′

K

Xk=1

Ξ .

(25)

k1) ˆTk(B)



K

Xk=1

Note that in this one-step approach the time dependence of the source is taken into account exactly, without actually
sampling it.

In a strict sense, the one-step method does not yield an orthogonal approximation. However, for practical purposes
it can be viewed as an extremely stable time-integration algorithm because it yields an approximation to the exact
time evolution operator U (t) = etH that is exact to nearly machine precision, i.e. in practice the value of
ǫ in Eq.(7)
(εE(t)) =
is very small. This also implies that within the same precision
∇ ·
(εE(t = 0)) holds for all times, implying that the numerical scheme will not produce artiﬁcial charges during the
e

(µH(t = 0)) and

(µH(t)) =

∇ ·

∇ ·

∇ ·
time integration [2, 3].

IV.

IMPLEMENTATION

The basic steps in the construction of the product-formula and one-step algorithms are best illustrated by considering
the simplest case, i.e. the Maxwell equations of a 1D homogeneous problem. From a conceptual point of view nothing
is lost by doing this: the extension to 2D and 3D nonhomogeneous problems is straigthforward, albeit technically
non-trivial [11, 12, 26, 27].

We consider a system, inﬁnitely large in the y and z direction, for which ε = 1 and µ = 1. Under these conditions,
the Maxwell equations reduce to two independent sets of ﬁrst-order diﬀerential equations [1], the transverse electric

FIG. 2: Positions of the two TM-mode ﬁeld components on the one-dimensional grid. The distance between two next-nearest
neighbors is denoted by δ.

(TE) mode and the transverse magnetic (TM) mode [1]. As the equations of the TE- and TM-mode diﬀer by a sign
we can restrict our considerations to the TM-mode only. The magnetic ﬁeld Hy(x, t) and the electric ﬁeld Ez(x, t) of
the TM-mode in the 1D cavity of length L are solutions of

∂
∂t
∂
∂t

Hy(x, t) =

Ez(x, t),

Ez(x, t) =

Hy(x, t)

Jz(x, t),

−

∂
∂x
∂
∂x

subject to the boundary condition Ez(0, t) = Ez(L, t) = 0 [1]. Note that the divergence of both ﬁelds are trivially
zero.

Following Yee [4], to discretize Eqs.(26) and (27), it is convenient to assign Hy to odd and Ez to even numbered
lattice sites, as shown in Fig. 2. Using the second-order central-diﬀerence approximation to the ﬁrst derivative with
respect to x, we obtain

∂
∂t

∂
∂t

Hy(2i + 1, t) = δ−

1(Ez(2i + 2, t)

Ez(2i, t)),

Ez(2i, t) = δ−

1(Hy(2i + 1, t)

Hy(2i

1, t))

Jz(2i, t),

−

−

−

−

where we have introduced the notation A(i, t) = A(x = iδ/2, t). The integer i labels the grid points and δ denotes
the distance between two next-nearest neighbors on the lattice (hence the absence of a factor two in the nominator).
We deﬁne the n-dimensional vector Ψ(t) by

Ψ(i, t) =

Hy(i, t), i odd
i even
Ez(i, t),

.

(cid:26)

The vector Ψ(t) contains both the magnetic and the electric ﬁeld on the lattice points i = 1, . . . , n. The i-th element of
Ψ(t) is given by the inner product Ψ(i, t) = eT
Ψ(t) where ei denotes the i-th unit vector in the n-dimensional vector
i ·
space. Using this notation (which proves most useful for the case of 2D and 3D for which it is rather cumbersome to
write down explicit matrix representations), it is easy to show that Eqs.(28) and (29) can be written in the form (4)
where the matrix H is given by

H = δ−

1

e

i

eT
i+1 −

e

eT
i

i+1

n

1

−

i=1
X

(cid:0)

0
δ−

1

−

1

δ−
0
. . .

= 






(cid:1)

1

δ−
. . .
δ−

1

−

. . .
0
δ−

1

−

.









1

δ−
0

We immediately see that H is sparse and skew-symmetric by construction.

First we demonstrate that the Yee algorithm ﬁts into the product-formula approach. For the 1D model (31) it is

easy to see that one time-step with the Yee algorithm corresponds to the operation

A. Yee-type algorithms

U Y ee
1

(τ ) = (I + τ A)(I

τ AT ) = eτ Ae−

τ AT

,

−

7

(26)

(27)

(28)

(29)

(30)

(31)

(32)

where

A = δ−

1

e

i

eT
i
−

1 −

e

i

eT

i+1

=

n

−

1

′

i=2
X

(cid:0)

1

−

0 δ−
0
0
δ−
0
0
0
0
0
...
...

1

0
0
0
0
1 0 δ−
0
0
δ−
0
...
...

−

0
0
0
0
1 0
...

· · ·
· · ·
· · ·
· · ·
· · ·
. . .

,











(cid:1)











and we used the arrangements of H and E ﬁelds as deﬁned by Eq.(30). We use the notation
′ to indicate that the
stride of the summation index is two. Note that since A2 = 0 we have eτ A = 1 + τ A exactly. Therefore we recover the
time-step operator of the Yee algorithm using the ﬁrst-order product formula approximation to eτ H and decomposing
AT . However, the Yee algorithm is second-order, not ﬁrst order, accurate in time [2, 3]. This is due to the
H = A
use of a staggered grid in time [2, 3]. To perform one time step with the Yee algorithm we need to know the values
of Ez(t) and Hy(t + τ /2), not Hy(t). Another method has to supply the Hy-ﬁeld at a time shifted by τ /2.

P

−

Within the spirit of this approach, we can easily eliminate the staggered-in-time grid at virtually no extra com-
putational cost or progamming eﬀort (if a conventional Yee code is available) by using the second-order product
formula

U Y ee
2

(τ ) = eτ A/2e−

τ AT

eτ A/2 = (I + τ A/2)(I

τ AT )(I + τ A/2).

−

(34)

The eﬀect of the last factor is to propagate the Hy-ﬁeld by τ /2. The middle factor propagates the Ez-ﬁeld by τ .
In this scheme all EM ﬁelds are to be taken at the same
The ﬁrst factor again propagates the Hy ﬁeld by τ /2.
(τ ) is second-order accurate in time by construction [16]. Note that eτ A/2 is
time. The algorithm deﬁned by U Y ee
2
e+τ A/2, we
(τ )
not orthogonal so nothing has been gained in terms of stability. Since
see that, compared to the original Yee algorithm, the extra computational work is proportional to (1 + 2/m), hence
negligible if the number of time steps m is large.

U Y ee
1

U Y ee
2

= e−

(τ )

τ A/2

m

m

(cid:0)

(cid:0)

(cid:1)

(cid:1)

According to the general theory outlined in Sec.III, the expression

U Y ee
4

(τ ) = U Y ee

(aτ )U Y ee

(aτ )U Y ee

((1

4a)τ )U Y ee

(aτ )U Y ee

(aτ ),

2

2

2

2

2

(35)

−

deﬁnes a fourth-order accurate Yee-like scheme, the realization of which requires almost no eﬀort once U Y ee
has
been implemented. It is easy to see that the above construction of the Yee-like algorithms holds for the much more
complicated 2D, and 3D inhomogeneous case as well. Also note that the fourth-order Yee algorithm U Y ee
does not
require extra storage to hold ﬁeld values at intermediate times.

4

2

B. Unconditionally stable algorithms

Guided by previous work on Schr¨odinger and diﬀusion problems [16, 35, 40], we split H into two parts

H1 = δ−

e

i

eT
i+1 −

e

eT
i

i+1

=

(cid:1)

H2 = δ−

e

i+1

eT
i+2 −

e

eT

i+2

i+1

=

n

−

1

′

1

i=1
X

(cid:0)

n

−

2

′

1

i=1
X

(cid:0)













(cid:1)

−

1

0
δ−
0
0
0
0
...

0
0
0
0
0
0
...













1

δ−
0
0
0
0
0
...
0
0
δ−
0
0
0
...

1

−

1

−

0
0
0
δ−
0
0
...
0
δ−
0
0
0
0
...

1

1

0
0
δ−
0
0
0
...
0
0
0
0
δ−
0
...

1

−

1

−

0
0
0
0
0
δ−
...
0
0
0
δ−
0
0
...

1

· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
. . .

,













· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
. . .

.













8

(33)

(36)

(37)

such that H = H1 + H2. In other words we divide the lattice into odd and even numbered cells. Clearly both H1 and
H2 are skew-symmetric block-diagonal matrices, containing one 1
2 skew-symmetric
matrices. According to the general theory given above, the ﬁrst-order algorithm is given by

1 matrix and (n

1)/2 real, 2

−

×

×

n

−

1

′




i=1
Y

n

−

2

′







i=1
Y

(cid:1)(cid:3)

U1(τ ) = eτ H1eτ H2 =

exp

1

τ δ−

e

i

eT
i+1 −

e

eT
i

i+1

exp

1

τ δ−

e

i+1

eT
i+2 −

e

eT

i+2

i+1

.

(38)

(cid:2)

(cid:0)

(cid:2)

(cid:0)

e

e





To derive Eq.(38) we used the block-diagonal structure of H1 and H2 (see Eqs.(36) and (37)) and obtained an exact

expression for
U1(τ ) in terms of an ordered product of matrix exponentials: the order of the matrix exponentials
between each pair of curly brackets is irrelevant as these matrices commute with each other. Each of these matrix
exponentials only operates on a pair of elements of Ψ(t) and leaves other elements intact. The indices of each of these
pairs are given by the subscripts of e and eT . From Eq.(38) it is clear what a program should do: Make loops over
i with stride 2. For each i pick a pair of elements from Ψ(t) according to the subscripts of e and eT , compute (or
fetch from memory) the elements of the plane rotation (see Eq. (39)), perform the plane rotation, i.e. multiply the
2
2 matrices and the vectors of length two, and overwrite the same two elements. As the matrix exponential of a
block-diagonal matrix is equal to the block-diagonal matrix of the matrix exponentials of the individual blocks, the
numerical calculation of eτ H1 (or eτ H2) reduces to the calculation of (n
2 matrices.
The matrix exponential of a typical 2

2 matrix appearing in eτ H1 or eτ H2 is given by

1)/2 matrix exponentials of 2



×

−

×




(cid:1)(cid:3)

×
0 1
1 0

exp

α

(cid:20)

(cid:18)

−

(cid:19)(cid:21) (cid:18)

(cid:19)

(cid:18)

−

Ψ(i, t)
Ψ(j, t)

=

cos α
sin α

sin α
cos α

Ψ(i, t)
Ψ(j, t)

.

(cid:19)

(cid:19) (cid:18)

(39)

Using the algorithm to compute Eq.(38), it is easy to construct the unconditionally stable, higher-order algorithms
U2(τ ) and

U4(τ ), see Eq.(13) and Eq.(15).

Obviously, the decomposition into H1 Eq.(36) and H2 Eq.(37) yields the most simple real-space algorithm. It is
not diﬃcult to imagine that a better but slightly more complicated algorithm can be constructed by using blocks of
e
3

2 matrices. Thus we are lead to consider the decomposition

e
3 instead of 2

×

×

H3 = δ−

1

e

i

i+1 + e
eT

i+1

eT
i+2 −

e

i+1

e

eT
i −

eT

i+2

i+1

=

,

(40)

(cid:1)













(cid:1)

−

1

0
δ−
0
0
0
0
...

−

1

1

δ−
0
δ−
0
0
0
...

0
δ−
0
0
0
0
...

0
1 0
0
0
0
0
...

0
0
0
0
0
δ−
...

1

−

0 0
0 0
0 0
0 0
0 0
0 0
...
...

1

0
0
0
δ−
0
0
...

1

1

0
0
δ−
0
δ−
0
...

−

−

1

0
0
0
δ−
0
0
...













· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
. . .













· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
. . .













H4 = δ−

1

e

eT
i+3 + e

i+3

i+2

eT
i+4 −

e

i+3

eT
i+2 −

e

eT

i+4

i+3

=

.

(41)

where the double prime indicated that the stride of the index i is three. Obviously both H3 and H4 are skew-symmetric
block-diagonal matrices, build from the 3

3 skew-symmetric matrix

×

B =

1

0
δ−
0

1

1

δ−
0
δ−

−



−



.

1

0
δ−
0 


As B3 =

2B we have

−

−
s
−
c
−
where s = sin(√2τ ) and c = sin2(τ /√2). In practice, using the 3
more diﬃcult. We will denote the corresponding second and fourth-order algorithm by U 3
2

eτ B = 1 + sB + cB2 =

3 instead of the 2

2c
−
s
−

c 






×

×

−

1

1

,

1

c

s

c
s

2 decomposition is marginally
3
respectively.
×

and U 3
4

×

3

n

−

2

′′

i=1
X

(cid:0)

n

−

4

′′

i=1
X

(cid:0)

9

(42)

(43)

10

(44)

0.08

0.06

0.04

0.02

0

-0.02

-0.04

-0.06

-0.08

0

50

100

150

200

250

x

FIG. 3: The ﬁeld Hy(x, t = 100) generated by a current source at x = 125 that oscillates at frequency fs = 1 during the interval
0 ≤ t ≤ 6, as obtained by the one-step algorithm with K ′ = 2103 (K = 0 in this case).

For the tri-diagonal matrix (31), the ADI algorithm reduces to the Cranck-Nicholson method [42]. The tri-diagonal
(n) operations by standard linear algebra

1Ψ in

τ H/2)−

structure of the matrix H permits the calculation of (I
methods [42].

−

O

The one-step algorithm is based on the recursion (see Eqs.(21) and (22))

C. ADI algorithm

D. One-step algorithm

Ψk+1 =

Ψk + Ψk

1.

−

2H
H

k1

k

Thus, the explicit form Eq.(31) is all we need to implement the matrix-vector operation (i.e. Ψ′
Eq.(44).

←

HΨ) that enters

O

The coeﬃcients Jk(z) and Sk(t) (see Eq.(25)) should be calculated to high precision. Using the recursion relation
(K) arithmetic operations [42]. The numbers Sk(t)
(K log K) by standard Fast Fourier transformation techniques. Clearly both computations are

of the Bessel functions, all K coeﬃcients can be obtained with
can be calculated in
a neglible fraction of the total computational cost for solving the Maxwell equations.

Performing one time step amounts to repeatedly using recursion (22) to obtain ˆTk(B)Ψ(0) for k = 2, . . . , K, multiply
the elements of this vector by Jk(z) (or Sk(z)) and add all contributions. This procedure requires storage for two
vectors of the same length as Ψ(0) and some code to multiply such a vector by the sparse matrix H. The result
of performing one time step yields the solution at time t, hence the name one-step algorithm. In contrast to what
Eqs. (21) and (22) might suggest, the algorithm does not require the use of complex arithmetic.

O

In the sequel, the caret ˆ on top of a symbol indicates that the results have been obtained by means of the one-step

algorithm.

V. NUMERICAL EXPERIMENTS

Except for the conventional Yee algorithm, all algorithms discussed in this paper operate on the vector of ﬁelds
deﬁned at the same time t. We use the one-step algorithm (with a time step τ /2) to compute Ez(τ /2) and Hy(τ /2).
Then we use Ez(0) and Hy(τ /2) as the initial values for the Yee algorithm. In the presence of a current source, there
are some ambiguities with this procedure as it is not obvious how to treat the source term in Eq.(9). In order to
permit a comparison of the ﬁnal result of the conventional Yee algorithm with those of the other methods, we use
the one-step algorithm once more to shift the time of the Hy ﬁeld by
τ /2. This procedure to prepare the initial
and to analyse the ﬁnal state of the Yee algorithm does in fact make the results of the Yee algorithm look a little

−

11

TABLE I: The error k ˜Ψ(t) − ˆΨ(t)k/k ˆΨ(t)k at time t = 100 as a function of the time step τ for eight diﬀerent FDTD algorithms.
The current source is positioned at the center of the system (see Fig.3), and oscillates at frequency fs = 1 during the interval
0 ≤ t ≤ 6, ˆΨ(t) is the vector obtained by the one-step algorithm with κ = 10−9, using K ′ = 2103 matrix-vector operations
Ψ′ ← M Ψ. Yee: ˜Ψ(t) obtained by the Yee algorithm [2, 3, 4]; Other columns: ˜Ψ(t) obtained by the algorithms indicated.

τ

Yee

U Y ee
2

U ADI
2

U2

0.10000E + 0
0.50000E − 1
0.25000E − 1
0.12500E − 1
0.62500E − 2
0.31250E − 2
0.15625E − 2
0.78125E − 3
0.39063E − 3

0.16E + 1
0.18E + 1
0.68E + 0
0.21E + 0
0.63E − 1
0.19E − 1
0.61E − 2
0.23E − 2
0.10E − 2

0.15E + 1
0.18E + 1
0.65E + 0
0.19E + 0
0.55E − 1
0.14E − 1
0.35E − 2
0.86E − 2
0.22E − 3

0.15E + 1
0.13E + 1
0.12E + 1
0.35E + 0
0.10E + 0
0.28E − 1
0.69E − 1
0.17E − 2
0.43E − 3

0.15E + 1
e
0.16E + 1
0.72E + 0
0.13E + 1
0.35E + 0
0.88E − 1
0.22E − 1
0.55E − 2
0.14E − 2

3×3
U
2

e

0.14E + 1
0.13E + 1
0.12E + 1
0.31E + 0
0.78E − 1
0.20E − 1
0.49E − 2
0.12E − 2
0.31E − 3

U Y ee
4

0.15E + 0
0.36E − 1
0.25E − 2
0.16E − 3
0.99E − 5
0.62E − 6
0.39E − 7
0.24E − 8
0.24E − 9

U4

0.37E + 0
e
0.33E − 1
0.22E − 2
0.14E − 3
0.87E − 5
0.55E − 6
0.34E − 7
0.21E − 8
0.24E − 9

3×3
U
4

e

0.27E + 0
0.23E − 1
0.15E − 2
0.96E − 4
0.60E − 5
0.38E − 6
0.24E − 7
0.15E − 8
0.22E − 9

FIG. 4: The data presented in Table I plotted on a double logarithmic scale. Lines are guide to the eye.

more accurate than they would be if the exact data of the τ /2-shifted ﬁelds are not available. Thus, the results on
the errors of the conventional Yee algorithm presented in this paper give a too optimistic view on the accuracy of
this algorithm but we nevertheless adopt the above procedure to make a quantitative comparison between the various
algorithms.

We deﬁne the error of the solution ˜Ψ(t) for the wave form by

where ˆΨ(t) is the vector of
EM ﬁelds obtained by the one-step algorithm. Thereby we have already assumed that the one-step algorithm yields
the exact (within numerical precision) results but this has to be demonstrated of course. A comparison of the results
of an unconditionally stable algorithm, e.g.
U4 with those of the one-step algorithm is suﬃcient to show that within
rounding errors the latter yields the exact answer. Using the triangle inequality

ˆΨ(t)
k

ˆΨ(t)
k

˜Ψ(t)

−

k

k

/

e

Ψ(t)

ˆΨ(t)

k

−

k ≤ k

Ψ(t)

˜Ψ(t)
k

−

+

˜Ψ(t)

k

ˆΨ(t)
k

,

−

(45)

12

TABLE II: The error k ˜Ψ(t)− ˆΨ(t)k/k ˆΨ(t)k at time t = 100 as a function of the time step τ for eight diﬀerent FDTD algorithms.
The system is the same as in Fig.3 and Table I. The initial values of the EM ﬁelds are random, distributed uniformly over
the interval [-1,1]. ˆΨ(t) is the vector obtained by the one-step algorithm κ = 10−9, using K = 2080 matrix-vector operations
Ψ′ ← M Ψ. Yee: ˜Ψ(t) obtained by the Yee algorithm [2, 3, 4]; Other columns: ˜Ψ(t) obtained by the algorithms indicated.

τ

Yee

U Y ee
2

U ADI
2

U2

0.10000E + 0
0.50000E − 1
0.25000E − 1
0.12500E − 1
0.62500E − 2
0.31250E − 2
0.15625E − 2
0.78125E − 3
0.39063E − 3

0.99E + 1
0.13E + 1
0.13E + 1
0.12E + 1
0.70E + 0
0.18E + 0
0.46E − 1
0.11E − 1
0.29E − 2

0.11E + 2
0.13E + 1
0.13E + 1
0.12E + 1
0.70E + 0
0.18E + 0
0.46E − 1
0.11E − 1
0.29E − 2

0.14E + 1
0.13E + 1
0.13E + 1
0.14E + 1
0.12E + 1
0.36E + 0
0.92E − 1
0.23E − 1
0.57E − 2

0.15E + 1
e
0.13E + 1
0.13E + 1
0.12E + 1
0.32E + 0
0.82E − 1
0.20E − 1
0.51E − 2
0.13E − 2

3×3
U
2

e

0.17E + 1
0.14E + 1
0.12E + 1
0.63E + 0
0.16E + 0
0.41E − 1
0.10E − 1
0.26E − 2
0.64E − 3

U Y ee
4

0.11E + 1
0.78E + 0
0.57E − 2
0.36E − 2
0.22E − 3
0.14E − 4
0.89E − 6
0.56E − 7
0.35E − 8

U4

0.13E + 1
e
0.16E + 0
0.11E − 1
0.71E − 3
0.45E − 4
0.28E − 5
0.17E − 6
0.11E − 7
0.68E − 9

3×3
U
4

e

0.13E + 1
0.16E + 0
0.11E − 1
0.71E − 3
0.45E − 4
0.28E − 5
0.17E − 6
0.28E − 8
0.18E − 9

FIG. 5: The data presented in Table II plotted on a double logarithmic scale. Lines are guide to the eye.

and the rigorous bound

Ψ(t)

˜Ψ(t)

−

k ≤

k

c4τ 4t

Ψ(0)
k

+

k
(cid:18)

t

J(u)
k

du

,

(cid:19)

0 k
Z

(46)

ˆΨ(t)
k

−

k

we can be conﬁdent that the one-step algorithm yields the numerically exact answer if i) Eq.(46) is not violated and
ii) if

vanishes like τ 4.

˜Ψ(t)

In Fig.3 we show a typical result of a one-step calculation on a grid of n = 5001 sites with δ = 0.1 (corresponding to
a physical length of 250.05), and a current source placed at i = 2500 to eliminate possible artifacts of the boundaries.
The frequency of the source is set to one (fs = 1) and the number of periods the source radiates is set to six (i.e.
T = 6). In Table I (Fig.4) we present results for the errors, as obtained by repeating the simulation shown in Fig.3
using eight diﬀerent FDTD methods. In Tables II and III (Figs.5 and 6 respectively) we shown similar results but

13

TABLE III: The error k ˜Ψ(t) − ˆΨ(t)k/k ˆΨ(t)k at time t = 100 as a function of the time step τ for eight diﬀerent FDTD
algorithms The system is the same as in Fig.3 and Table I. The initial state of the EM ﬁelds is a Gaussian wave packet
(Ez(t) = exp(−(x − x0 − t)2/σ2) with a width σ = 4, and its center x0 = 125 positioned at the middle of the system (see Fig.3).
ˆΨ(t) is the vector obtained by the one-step algorithm with κ = 10−9, using K = 2080 matrix-vector operations Ψ′ ← M Ψ.
Yee: ˜Ψ(t) obtained by the Yee algorithm [2, 3, 4]; Other columns: ˜Ψ(t) obtained by the algorithms indicated.

τ

Yee

U Y ee
2

U ADI
2

U2

U Y ee
4

U4

0.10000E + 0
0.50000E − 1
0.25000E − 1
0.12500E − 1
0.62500E − 2
0.31250E − 2
0.15625E − 2
0.78125E − 3
0.39063E − 3

0.25E − 2
0.63E − 3
0.16E − 3
0.40E − 4
0.99E − 5
0.25E − 5
0.63E − 6
0.16E − 6
0.41E − 7

0.25E − 2
0.63E − 3
0.16E − 3
0.39E − 4
0.98E − 5
0.25E − 5
0.61E − 6
0.15E − 6
0.38E − 7

0.50E − 2
0.13E − 2
0.32E − 3
0.79E − 4
0.20E − 4
0.49E − 5
0.12E − 5
0.31E − 6
0.77E − 7

0.14E + 1
e
0.90E + 0
0.26E + 0
0.65E − 1
0.16E − 1
0.41E − 2
0.10E − 2
0.25E − 3
0.64E − 4

3×3
U
2

e

0.79E + 0
0.25E + 0
0.65E − 1
0.16E − 1
0.41E − 2
0.10E − 2
0.26E − 3
0.64E − 4
0.16E − 4

0.28E − 6
0.17E − 7
0.11E − 8
0.69E − 10
0.12E − 10
0.12E − 10
0.12E − 10
0.12E − 10
0.12E − 10

0.15E − 1
e
0.95E − 3
0.60E − 4
0.37E − 5
0.23E − 6
0.15E − 7
0.91E − 9
0.55E − 10
0.43E − 10

3×3
U
4

e

0.17E − 1
0.15E − 3
0.97E − 4
0.61E − 5
0.38E − 6
0.24E − 7
0.15E − 8
0.10E − 9
0.46E − 10

FIG. 6: The data presented in Table III plotted on a double logarithmic scale. Lines are guide to the eye.

instead of using a current source, a random wave form (Table II) and Gaussian wave packet (Table III) was taken as
the initial condition.

From the data in Tables I, II and III we conclude that the error of algorithm

U4 vanishes like τ 4, demonstrating that
the one-step algorithm yields the numerically exact result (see Eqs.45 and 46). The results presented in Tables II and
e
III have been obtained by using a vector of initial values that is normalized to one, i.e.
= 1
ˆΨ(t)
for 0
for all entries in Tables II and III. The
k
high precision of the one-step algorithm also allows us to use it for genuine time stepping with arbitrarily large time
steps, this in spite of the fact that strictly speaking, the one-step algorithm is not unconditionally stable.

100 to at least 10 digits,

Ψ(0)
k

ˆΨ(t)
k

ˆΨ(t)
k

ˆΨ(t)
k

= 1. As

˜Ψ(t)

˜Ψ(t)

−

=

≤

−

≤

k

k

k

k

k

/

t

The data in Tables I, II and III suggests that there does not seem to be a signiﬁcant diﬀerence between the
but in fact there is. The time evolution matrix corresponding to
2) is not

conventional Yee algorithm and its variant U Y ee
the Yee and the U Y ee

algorithm is not orthogonal. Therefore the energy of the electromagnetic ﬁeld (
k

Ψ(t)
k

2

2

14

1.015

1.01

1.005

1

0.995

0.99

0.985

0.98

0.975

0.97

W

e

0

2

4

6

8

10

t

FIG. 7: The energy of the EM ﬁelds W = ΨT (t) · Ψ(t) as the function of time as obtained by the Yee (solid line), U Y ee
(dashed line), and
U4 (dotted line) algorithm for a 1D cavity of size 48.05 (n = 97 mesh points), a mesh size δ = 0.1 and a time
step τ = 0.01.

2

2

2

Ψ(0)
k

conserved. Furthermore, in the conventional Yee algorithm, the E and H-ﬁelds are time-shifted by τ /2 with respect
to each other. These artifacts of are less prominent if we use U Y ee
instead of the Yee algorithm. In Fig.7 we show
results of the time evolution of the total energy of the EM ﬁeld, for a system of n=97 sites, a mesh size δ = 0.1 and
2 = 1) random initial condition was used. Furthermore, for this type
a time step of τ = 0.01. A normalized (
k
of application, it makes no sense to invoke the procedure described at the beginning of this section to time-shift one
of the EM-ﬁelds by τ /2: as this operation has to be performed at each time step and is computationally expensive
(because it is numerically exact), we could as well use the same numerically exact procedure for time stepping itself.
algorithm.
U4 algorithm (dotted, horizontal line) exactly conserves the energy. The fact
As expected on theoretical grounds, the
that U Y ee
conserves EM-ﬁeld energy much better than the Yee algorithm also has a considerable impact on the quality
Ψ(0) (see ref.[11] for more
of the eigenmode distribution. The latter is obtained by Fourier transformation of ΨT (t)
details). In Fig.8 we show the low-frequency part of the eigenmode distribution of the same system as the one of
Fig.7. It is obvious that there is a signiﬁcant improvement in the quality of the spectrum if we use U Y ee
instead of
the Yee algorithm but for this application

For the Yee algorithm, the ﬂuctuations of the energy are a factor of ten larger than in the case of the U Y ee

U4 performs much better than the Yee-type algorithms.
U2 is the least eﬃcient of the ﬁve FDTD methods: It uses more arithmetic operations than
the Yee algorithm and yields errors that are larger than those of the Yee algorithm. However, this conclusion is biased
by the choice of the model problem and does not generalize. If the initial EM ﬁeld distribution is random then, for
U2 is more accurate than the two second-order accurate Yee algorithms, as is clear from
suﬃciently small τ , algorithm
the data in Table II [43]. Also in this case, for the largest τ in Table II, the Yee and U Y ee
algorithm are operating
at the point of instability, signaled by the fact that the norm of Ψ(t) grows rapidly, resulting in errors that are very
large. From Tables I and II one might conclude that the decomposition that generates Yee-type algorithms yields
the least accurate approximations to the time evolution operator, although the diﬀerence is not really signiﬁcant,
but, as Table III shows, this conclusion would be wrong. If the initial state is a Gaussian wave packet that is fairly
broad, the Yee-type algorithms are much more accurate than the unconditionally stable algorithms employed in this
paper. From the data in Tables I, II and III we conclude that there is no good reason to use the ADI algorithm (even
disregarding the fact that it is slower than the other second-order methods). In general the
) algorithm

Table I suggests that

e

e

e

e

×

×

2

2

2

3

3

·

U 3
2

U 3
(
4

e

e

15

)
s
e

t

a
t
s
 
f

o
 
y
t
i
s
n
e
d
(
 
g
o
L

0

-2

-4

-6

-8

-10

-12

-14

-16

0

2

4

6

8

10

Angular frequency

FIG. 8: The eigenvalues distribution of the matrix H, as obtained by Fourier transformation of ΨT (t) · Ψ(0), for the same
system as in Fig.7. The function ΨT (t) · Ψ(0) is sampled at time intervals of 0.1, the total number of samples being 4096. Solid
line: Yee algorithm; dashed line: U Y ee

algorithm; dotted line: energy conserving algorithm

U4.

2

e

e

e

U2 (

performs a little better than
U4) but the gain is marginal. In contrast to the numerical data presented in Ref.[19],
for all algorithms the data of Tables I,II and III clearly agree with the theoretically expected behavior of the error as
a function of τ if τ is small enough [44].

Usually if a current source is present we have Ψ(0) = 0. Then the one-step algorithm requires K ′ (sparse) matrix-
vector operations (Ψ′
M Ψ) to compute Ψ(t). For a 1D system the standard Yee, U Y ee
U4
algorithms perform (in worst case, without additional optimization), respectively, 1, 3/2, 6, 3/2, and 6 M Ψ-operations
M Ψ to complete this
per time step. The one-step algorithm carries out K ′ = 2103 matrix-vector operations Ψ′
e
e
simulation. This implies that for all τ < t/K ′, the FDTD algorithms will perform more Ψ′
M Ψ operations than
the one-step algorithm. For the data presented in this paper, this is the case if τ < 0.05 for the Yee algorithm and is
always the case for

U4 because the latter uses a factor of 6 more Ψ′

M Ψ operations than the Yee algorithm.

and U Y ee

U2 , and
,

←
←

←

2

4

e

←

VI. CONCLUSION

The answer to the question which of the algorithms is the most eﬃcient crucially one depends on the accuracy that
one ﬁnds acceptable. Taking the data of Table I as an example we see that if one is satisﬁed with an error of more
than 2%, one could use the Yee algorithm. With τ = 0.05 it needs 2000 time steps to ﬁnd the solution at t = 100,
close to the K ′ = 2103. Nevertheless we recommend to use the one-step algorithm because then the time-integration
U4 is
error is neglegible. The Yee algorithm is no competition for
not nearly as eﬃcient (by a factor of about 6) as the one-step algorithm. Increasing the dimensionality of the problem
favors the one-step algorithm [26, 27]. These conclusions seem to be quite general and are in concert with numerical
experiments on 1D, 2D and 3D systems [27]. A simple theoretical analysis of the τ dependence of the error shows
that the one-step algorithm is more eﬃcient than any other FDTD method if we are interested in the EM ﬁelds at a
particular (large) time only [26, 27]. This may open possibilities to solve problems in computational electrodynamics
that are currently intractable. The Yee-like algorithms do not conserve the energy of the EM ﬁelds and therefore
they are less suited for the calculation of the eigenvalue distributions (density of states), a problem for which the
U4
algorithm may be the most eﬃcient of all the algorithms covered in the paper.

U4 if one requires an error of less than 1% but then

e

e

e

16

The main limitation of the one-step algorithm lies in its mathematical justiﬁcation. The Chebyshev approach
requires that H is diagonalizable and that its eigenvalues are real or pure imaginary. The eﬀect of relaxing these
conditions on the applicability of the Chebyshev approach is left for future research.

In this paper we have focused entirely on the accuracy of the time integration algorithms, using the most simple
discretization of the spatial derivatives. In practice it is straightforward, though technically non-trivial, to treat more
sophisticated discretization schemes [2, 12] by the methodology reviewed is this paper.

Acknowledgments

H.D.R. and K.M. are grateful to T. Iitaka for drawing our attention to the potential of the Chebyshev method and
for illuminating discussions. This work is partially supported by the Dutch ‘Stichting Nationale Computer Faciliteiten’
(NCF), and the EC IST project CANVAD.

[1] M. Born and E. Wolf, Principles of Optics, (Pergamon, Oxford, 1964).
[2] A. Taﬂove and S.C. Hagness, Computational Electrodynamics - The Finite-Diﬀerence Time-Domain Method, (Artech

House, Boston, 2000).

[3] K.S. Kunz and R.J. Luebbers, Finite-Diﬀerence Time-Domain Method for Electromagnetics, (CRC Press, 1993).
[4] K.S. Yee, IEEE Transactions on Antennas and Propagation 14, 302 (1966).
[5] See http://www.fdtd.org
[6] F. Zheng, Z. Chen, and J. Zhang, IEEE Trans. Microwave Theory and Techniques 48, 1550 (2000).
[7] T. Namiki, IEEE Trans. Microwave Theory and Techniques 48, 1743 (2001).
[8] F. Zheng and Z. Chen, IEEE Trans. Microwave Theory and Techniques 49, 1006 (2001).
[9] S.G. Garcia, T.W. Lee, S.C. Hagness, IEEE Trans. and Wireless Prop. Lett. 1, 31 (2002).
[10] W. Harshawardhan, Q. Su, and R. Grobe, Phys. Rev. E 62, 8705 (2000).
[11] J.S. Kole, M.T. Figge and H. De Raedt, Phys. Rev. E 64, 066705 (2001).
[12] J.S. Kole, M.T. Figge and H. De Raedt, Phys. Rev. E 65, 066705 (2002).
[13] O.P. Gandi, Advances in Computational Electrodynamics - The Finite-Diﬀerence Time-Domain Method, A. Taﬂove, Ed.,

(Artech House, Boston, 1998).

[14] B. Houshmand, T. Itoh, and M. Piket-May, Advances in Computational Electrodynamics - The Finite-Diﬀerence Time-

Domain Method, A. Taﬂove, Ed., (Artech House, Boston, 1998).

[15] M. Suzuki, S. Miyashita, and A. Kuroda, Prog. Theor. Phys. 58, 1377 (1977).
[16] H. De Raedt, Comp. Phys. Rep. 7, 1 (1987).
[17] G.D. Smith, Numerical solution of partial diﬀerential equations, (Clarendon Press, Oxford, 1985).
[18] This is due to the speciﬁc split-up adopted in [10] and not an intrinsic property of the spectral-domain approach.
[19] R. Horv´ath, preprint 2002; http://www.win.tue.nl/analysis/preprints/2002.html
[20] H. Tal-Ezer, SIAM J. Numer. Anal. 23, 11 (1986).
[21] H. Tal-Ezer and R. Kosloﬀ, J. Chem. Phys. 81, 3967 (1984).
[22] C. Leforestier, R.H. Bisseling, C. Cerjan, M.D. Feit, R. Friesner, A. Guldberg, A. Hammerich, G. Jolicard, W. Karrlein,

H.-D. Meyer, N. Lipkin, O. Roncero, and R. Kosloﬀ, J. Comp. Phys. 94, 59 (1991).

[23] T. Iitaka, S. Nomura, H. Hirayama, X. Zhao, Y. Aoyagi, and T. Sugano, Phys. Rev. E 56, 1222 (1997).
[24] R.N. Silver and H. R¨oder, Phys. Rev. E 56, 4822 (1997).
[25] Y.L. Loh, S.N. Taraskin, and S.R. Elliot, Phys. Rev. Lett. 84, 2290 (2000); ibid. Phys.Rev.Lett. 84, 5028 (2000).
[26] H. De Raedt, K. Michielsen, J.S. Kole, and M.T. Figge, in Computer Simulation Studies in Condensed-Matter Physics

XV, eds. D.P. Landau et al., Springer Proceedings in Physics, (Springer, Berlin in press).

[27] H. De Raedt, K. Michielsen, J.S. Kole, and M.T. Figge, submitted to IEEE Antennas and Propagation, LANL prepint:

physics/0208060

[28] J.H. Wilkinson, The Algebraic Eigenvalue Problem, (Clarendon Press, Oxford, 1965).
[29] M. Abramowitz and I. Stegun, Handbook of Mathematical Functions, (Dover, New York, 1964).
[30] H.F. Trotter, Proc. Am. Math. Soc. 10, 545 (1959).
[31] H. De Raedt and B. De Raedt, Phys. Rev. A 28, 3575 (1983).
[32] M. Suzuki, J. Math. Phys. 26, 601 (1985); ibid 32 400 (1991).
[33] A.J. Chorin, T.J.R. Hughes, M.F. McCracken, and J.E. Marsden, Comm. Pure Appl. Math. XXXI, 205 (1978).
[34] H. Kobayashi, N. Hatano, and M. Suzuki, Physica A 211, 234 (1994).
[35] H. De Raedt, K. Michielsen, Comp. in Phys. 8, 600 (1994).
[36] A. Rouhi, J. Wright, Computers in Physics 9, 554 (1995).
[37] B.A. Shadwick and W.F. Buell, Phys. Rev. Lett. 79, 5189 (1997).
[38] M. Krech, A. Bunker, and D.P. Landau, Comp. Phys. Comm. 111, 1 (1998).
[39] P. Tran, Phys. Rev. E 58, 8049 (1998).

[40] K. Michielsen, H. De Raedt, J. Przeslawski, and N. Garcia, Phys. Rep. 304, 89 (1998).
[41] H. De Raedt, A.H. Hams, K. Michielsen, and K. De Raedt, Comp. Phys. Comm. 132, 1 (2000).
[42] W.H. Press, B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling, Numerical Recipes, (Cambridge, New York, 1986).
[43] This also explains why the unconditionally stable algorithms

U4 yield more accurate eigenvalue distributions than

U2 and

[44] The data for small τ , obtained from the Yee algorithm for the case of a current source is an exception. This is due to the

e

e

the Yee algorithm [11].

ambiguities mentioned in Sec.V.

17

