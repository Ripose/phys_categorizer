Order Reductions of “Predictive Dynamical Systems”

J. M. Aguirregabiria,

Theoretical Physics,

The University of the Basque Country,

P. O. Box 644, 48080 Bilbao, Spain

Abstract

It has been recently pointed out that dynamical systems depending on future values of the unknowns may

be useful in different areas of knowledge. We explore in this context the extension of the concept of order

reduction that has been useful with singular and delay differential equations in electrodynamics and general

relativity. We discuss some general properties of order reductions in this new context and explore a method

of successive approximations, which among other things is used to check and improve the “extrapolate

prediction” and “ﬁxed rate prediction” methods.

PACS numbers: 02.30.Mv, 05.10.-a, 05.90.+m

Keywords: nonlinear dynamical system, predictive dynamical system, discrete dynamical system, order reduction

6
0
0
2
 
n
u
J
 
8
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
9
7
0
6
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

1

I.

INTRODUCTION

T. Ohira has recently proposed and analyzed a formalism and concrete examples of dynamical

systems governed by predictions of future states, which he calls “predictive dynamical systems”

[1]. Since initial conditions are not sufﬁcient to solve this kind of dynamical system (and make

sure the solution is unique), Ohira proposes two methods of predicting the future values of the

unknowns necessary to ﬁnd (numerically) the solution to the system: “ﬁxed rate prediction” and

“extrapolate prediction.” Since both methods can at most provide some approximate solution of

the dynamical system, it may be interesting to explore other methods that could eventually improve

the quality of the approximation.

In classical electrodynamics and general relativity one ﬁnds singular differential equations and

delay differential equations for which the usual physical initial conditions are not enough to com-

pute the solution. In this context the idea of order reduction has been useful [2, 3, 4, 5, 6, 7, 8, 9,

10, 11].

We extend the concept of order reduction to predictive dynamical systems in section II, as well

as a method of successive approximations to compute the solution. Since we lack a rigorous theory

of this method, a simple but illustrative example is analyzed in section III. Numerical results are

discussed in section IV for the same dynamical systems discussed in [1]. In section V we brieﬂy

explore higher order reductions and compare again our numerical results with those of Ohira’s.

II. ORDER REDUCTIONS OF PREDICTIVE DYNAMICAL SYSTEMS

Although our deﬁnition and results can be readily extended to continuous dynamical systems,

for simplicity we will consider only discrete dynamical systems in which a physical quantity x is

deﬁned only for integer values n = 0, 1, 2, . . . of “time” according to a law in the form

with some advance p = 1, 2, . . . It is obvious that an initial condition x0 for, say, n = 0 is not

enough to predict the future. Even if one could solve (1) for xn+p, the resulting dynamical system

would require specifying p initial conditions: x0, x1, . . . , xp−1. In consequence more assumptions

are necessary to solve (1). In Ohira’s “ﬁxed rate prediction” method [1], one replaces xn+p on the

xn+1 = M (xn, xn+p) ,

xn+p = N (xn, xn+1)

2

(1)

(2)

right hand side of (1) by xn + p (xn

xn−1), which still needs some additional initial condition

−

for n =

1 or another suitable assumption. In the “extrapolate prediction” method one would

−

substitute for xn+p the value obtained by applying p times to xn the map (1) with p = 0. It is clear

that, in general, both methods will provide at most approximations to a solution of the original

dynamical system.

The idea behind order reductions is that (1) is not the true evolution equation but only a neces-

sary condition every solution to the actual (unknown) dynamical system must satisfy. If the true

dynamical system is a deterministic one in the form

xn+1 = F (xn) ,

knowledge of the future is only necessary because our incomplete theory did not led us to (3)

but only to a less restrictive condition in the form (1). Since the latter must be satisﬁed by every

solution to (3), we have the following condition for the unknown F :

F (x) = M (x, F p(x)) ,

F p

p times

F
z
≡

◦

F

}|
◦ · · · ◦

F .
{

Of course, in general, one cannot solve (4) for F (this is the reason it is unknown) but one can

try ﬁnding good approximations by different methods. In some cases there is a small parameter

in the problem, so that the natural way would be to try Taylor expansions with respect to that

parameter. But we are here going to explore a general method of successive approximations which

have proved useful with singular al delay differential equations [9, 10, 11].

We will construct a succession of approximations F0, F1, . . . deﬁned by

along with some suitable initial F0(x). It is clear that if the succession is convergent, its limit

F (x)

limm→∞ Fm(x) is a solution of (4). One obvious choice for the initial condition is

≡

Fm+1(x) = M (x, F p

m(x))

F0(x) = M (x, x) ,

(3)

(4)

(5)

(6)

in which case F1 (xn) is the value xn+1 obtained by means of Ohira’s “extrapolate prediction;” but,

although the limit F (xn) will be unattainable in practice, the approximation can be improved by

computing successive Fm (xn) until

Fm (xn)

is below some tolerance value. How-

−
ever, we will see later that different initial conditions may change dramatically the convergence

|

Fm+1 (xn)
|

3

rate (moreover, the may lead to different order reductions), so that in practice some additional

criterion must be used (for instance, in electrodynamics one can use the limit in which the charge

vanishes to select the right order reduction).

The problem of the existence of the limit F is here posed in too general grounds to have an

answer. Instead of that we will consider an artiﬁcial but illustrative problem.

III. A LINEAR EXAMPLE

Let us ﬁrst consider the discrete dynamical system

xn+1 = axn + bxn+1,

(a

= 0, b

= 0, 1).

Of course, this can be written as

xn+1 = αxn,

α

≡

1

a

−

;

b

but let us pretend we do not know that and want to solve (7) by the method of successive ap-

proximations. It is easy to see that for F0(x) = (a + b)x, which corresponds to (6), or for any

F0(x) = α0x with constant α0, we have

with

Fm(x) = αmx

αm+1 = a + bαm.

Since (α

αm+1) = b (α

αm), whatever α0 is, the recurrence (10) will converge (to α) if and

only if

< 1. In consequence, in this example the method of successive approximations will

−

b
|

|

−

converge (to the right dynamical system) when

< 1 and diverge for

> 1. One cannot

b
|

|

b
|

|

expect the method to be convergent always, but the example suggests that (as is often the case in

electrodynamics [9, 10, 11]) it may work if some parameter in the theory is small enough.

The following example is

xn+1 = axn + bxn+2,

(a

= 0, b

= 0,

1
−

−

a).

Also in this case we can solve for xn+2 to obtain a two-point recurrence which needs two initial

conditions (say x−1 and x0). Instead, we seek an order reduction (3) which only requires one

initial condition and must satisfy

(7)

(8)

(9)

(10)

(11)

(12)

F (x) = ax + bF (F (x)).

4

6
6
6
6
For 4ab

1 this functional equation has, at least, the following two linear solutions:

≤

F (x) = αx,

α = α±

1

±

√1
2b

−

4ab

.

≡

Starting from any F0(x) = α0x with constant α0 we get again (9) with

But this quadratic map is just the logistic map whose properties have been explored in depth in

chaos theory [12]. For this reason it is easy to prove that αm will converge to α− for any parameter

values such that

3 < 4ab < 1 provided the initial condition is choosed so that

−

αm+1 = a + bα2
m.

α0| ≤
|

1 + √1
−
b
2
|

|

4ab

.

This is the case for α0 = a + b —which correspond to (6)— for

small enough. For other

a + b
|

|

initial conditions or parameters αm may go to inﬁnity, approach a cycle of any period or change

chaotically. Again we see that the method could work for small parameter values, but also that

it could never converge to the right solution (F (x) = α+x, for instance), in which case other

methods should be tried (maybe an appropriate series expansion, or a numerical method to solve

(13)

(14)

(15)

(1) for xn+p).

IV. NUMERICAL RESULTS

Successive approximations to the order reduction can be numerically computed in any program-

ming language. For instance, the Mathematica code [13] in Table I will compute and display xn

(for n = 0, 1, . . . , 10) by using the second approximation F2, in the case of the “sigmoid function”

discussed in reference [1]:

M(x, y) = (1

µ)x +

−

2
1 + e−βy −

1.

(16)

We have use that code for Figure 1, where the values x0, x1, . . . , x10 obtained with F1, F2, F4

and F5 are displayed for µ = 0.5, β = 0.8, p = 5 and initial guess (6). The dots in the upper

polygonal have been computed with F1 and, thus, are the same obtained by Ohira’s “extrapolate

prediction.” We can see there is room for improvement, for the values with F2 are rather smaller,

while those obtained with F4 and F5 are indistinguishable in the ﬁgure, proving they are very near

those one would obtain with the limit F . We can see in Figure 2 the importance of a good guess

5

for F0: selecting F0(x) = M (x, x0) leads to a much slower convergence and even F8 is not a good

approximation.

[1],

very close.

In Figure 3 one can see that convergence is faster for the “Mackey-Glass function” of reference

−
with µ = 0.5, β = 0.8, s = 10, p = 5 and initial guess (6): solutions with F2 and F3 are already

M(x, y) = (1

µ)x +

βy
1 + ys ,

(17)

One can also have the program compute at each step xn successive approximations Fm (xn)

until the difference between two consecutive approximations is below some maximum relative

error, which is called tol in the code in Table II for the “Mackey-Glass function” of reference [1].

For more complex calculations this code can (must) be improved in many ways, including a better

storage management (here every computed value is stored) and using a compiled programming

language.

V. HIGHER ORDER REDUCTIONS

To keep things simple we have reduced (1) to the ﬁrst-order dynamical system (3), which only

needs x0 to identify each solution. In some cases we might have theoretical reasons to think that

the true dynamical system is of second order,

xn+1 = G (xn, xn−1) ,

G(x, y) = M (cid:16)x, G(p)(x, y)(cid:17) ,

with

and

G(0)(x, y)

x, G(1)(x, y)

G(x, y), G(p+1)(x, y)

≡

≡

≡

G (cid:16)G(p)(x, y), G(p−1)(x, y)(cid:17) ,

(20)

so that x−1 and x0 must be speciﬁed. Notice that in the corresponding scheme of successive

approximations,

one could use Ohira’s “ﬁxed rate prediction” [1] to provide the following starting guess:

Gm+1(x, y) = M (cid:16)x, G(p)

m (x, y)(cid:17) ,

G0(x, y) = M (x, x + p(x

y)) .

−

6

(18)

(19)

(21)

(22)

We have used the code in Table III to compute the results in Figure 4, where the results for G2,

G4, G6 and G8 are displayed for µ = 0.5, β = 0.8, p = 5, x0 = x−1 = 0.5 and initial guess

(22). Wee see that the successive approximations converge slowly to the same solution displayed

in Figure 1: in particular this means that in this example (3) is also an order reduction of (18).

VI. FINAL COMMENTS

We have extended the concept of order reduction to predictive dynamical systems and discussed

some examples in which it can be used to construct good approximations to exact solutions of those

systems. In particular, we have shown that a method of successive approximations may be used to

check and improve the accuracy of Ohira’s extrapolate prediction [1]. We are not claiming that the

method will work always, but that, as happens with singular and delay differential equations, there

may be interesting cases in which it can be used to construct solutions to predictive dynamical

systems. Iin other cases one must have to resort to other approximation scheme, such as series

expansions, backward integration, shooting methods, (or a root ﬁnding routine to solve for xn+p

at each step), etc.

To keep things simple we have only considered discrete dynamical systems; but the con-

cepts explored here can be extended in an obvious way both to reductions of higher order and

to differential-difference equations of advanced type (with the meaning deﬁned in reference [14]).

Acknowledgments

This work was

supported by The University of

the Basque Country (Research

Grant 9/UPV00172.310-14456/2002).

[1] T. Ohira, “Predictive Dynamical Systems,” arXiv:cond-mat/0605500.

[2] E. Kerner, J. Math. Phys. 6, 1218 (1965).

[3] Ll. Bel and X. Fustero, Ann. Inst. H. Poincar´e 25, 411 (1976).

[4] J. L. Sanz, J. Math. Phys. 20, 2334 (1979).

[5] Ll. Bel, in “Relativistic Action at a Distance: Classical and Quantum Aspects,” ed. J. Llosa Springer,

Berlin, (1982), p. 21.

7

[6] Ll. Bel and H. Sirousse-Zia, Phys. Rev. D 32, 3128 (1985).

[7] Ll. Bel, J.-L. Boulanger and N. Deruelle, Phys. Rev. A 37, 1563 (1988).

[8] L. Parker and J. Z. Simon, Phys. Rev. D 47, 1339 (1993).

[9] J. M. Aguirregabiria, J. Phys. A 30, 2391 (1997).

[10] J. M. Aguirregabiria, A. Hern´andez and M. Rivas, J. Phys. A 30, L651 (1997).

[11] J. M. Aguirregabiria, Ll. Bel, A. Hern´andez and M. Rivas, Comp. Phys. Comm. 116, 95 (1999).

[12] E. Ott, “Chaos in Dynamical Systems,” 2nd. Ed., Cambridge, Cambridge (2002).

[13] Mathematica, Wolfram Research, Inc., Version 5.1, Champaign, IL (2004).

[14] R. Bellman and K. L. Cooke, “Differential-Difference Equations,” Academic Press, New York (1963).

8

m=1

m=2

m=4

m=5

m=2

m=4

m=6

m=8

xn

0.5

0.4

0.3

0.2

0.1

xn

0.5

0.4

0.3

0.2

0.1

2

4

6

8

10

n

FIG. 1: x0, x1, . . . , x10 obtained with F1, F2, F4 and F5, in the case of the “sigmoid function.”

2

4

6

8

10

n

FIG. 2: Same as Fig. 1 but with F0(x) = M (x, x0).

9

xn

1

0.8

0.6

0.4

0.2

xn

0.5

0.4

0.3

0.2

0.1

2

4

6

8

10

n

FIG. 3: x0, x1, . . . , x10 obtained with F1, F2 and F3, in the case of the “Mackey-Glass function.”

m=1

m=2

m=3

m=2

m=4

m=6

m=8

2

4

6

8

10

n

FIG. 4: x0, x1, . . . , x10 obtained with G2, G4, G6 and G8, in the case of the “sigmoid function.”

10

Clear[F]

(* Forget previous calculation *)

F[m_,x_] := F[m,x] =

M[x,Nest[F[m-1,#]&,x,p]]

(* Recurrence *)

F[0,x_] := F[0,x] = M[x,x]

(* Initial guess *)

M[x_,y_] := (1-0.5)x+2/(1+Exp[-0.8 y])-1 (* Map *)

p = 5;

x0 = 0.5;

m = 2;

(* Advance *)

(* Initial condition *)

(* Approximation *)

ListPlot[NestList[F[m,#]&,x0,10]];

(* Plot F_m(x_n) *)

TABLE I: Mathematica program to compute and display Fm (xn).

11

Clear[F]

(* Forget previous calculation *)

F::"iterations" = "Too many iterations.";

F[x_] := F[x] =

Module[{m},

(* Successive approximations *)

Abs[(F[m,x]-F[m-1,x])/(F[m,x]+0.001)] > tol,

If [m > mmax, Message[F::"iterations"]; Break[]]

For[m = 1,

m++,

];

F[m,x]

]

F[m_,x_] := F[m,x] =

M[x,Nest[F[m-1,#]&,x,p]]

(* Recurrence *)

F[0,x_] := F[0,x] = M[x,x]

(* Initial guess *)

M[x_,y_] := (1-0.5)x+0.8y/(1+yˆ10)

(* Map *)

p = 8;

x0 = 0.5;

tol = 10ˆ-5;

mmax = 10;

(* Advance *)

(* Initial condition *)

(* Maximum relative error *)

(* Maximum value of m *)

ListPlot[NestList[F,x0,10]];

(* Plot F(x_n) *)

TABLE II: Mathematica program to compute and display an approximation to F (xn).

12

Clear[G,x]

(* Forget previous calculation *)

G[0,m_,x_,y_] := x

(* Recurrence *)

G[p_,m_,x_,y_] := G[p,m,x,y] = G[1,m,G[p-1,m,x,y],G[p-2,m,x,y]]

G[1,m_,x_,y_] := G[1,m,x,y] = M[x,G[p,m-1,x,y]]

G[1,0,x_,y_] := G[1,0,x,y] = M[x,x+p(x-y)]

(* Initial guess *)

M[x_,y_] := (1-0.5)x+2/(1+Exp[-0.8 y])-1

(* Map *)

p = 5;

x[m_,-1] := 0.5;

x[m_,0] = 0.5;

(* Advance *)

(* Initial conditions *)

x[m_,n_] := x[m,n] = G[1,m,x[m,n-1],x[m,n-2]] (* Order reduction *)

m = 1;

(* Approximation *)

ListPlot[Table[x[m,n],{n,0,50}]];

(* Plot solution *)

TABLE III: Mathematica program to compute and display Gm (xn, xn−1).

13

