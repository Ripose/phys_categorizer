7
9
9
1
 
b
e
F
 
9
1
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
1
2
0
2
0
7
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

SIMULTANEOUSLY DISSIPATIVE OPERATORS
AND THE INFINITESIMAL MOORE EFFECT
IN INTERVAL SPACES

A.N.Gorban1, Yu.I.Shokin2, V.I.Verbitskii1

1Krasnoyarsk Computing Center
Russian Academy of Sciences, Siberian Branch
Krasnoyarsk-36, 660036, Russian Federation
E-mail: gorban@cc.krascience.rssi.ru
2Institute of Computational Technologies
Russian Academy of Sciences, Siberian Branch
Novosibirsk-90, 630090, Russian Federation

Abstract. In solving a system of ordinary diﬀerential equations by an interval method the
approximate solution at any considered moment of time t represents a set (called interval)
containing the exact solution at the moment t. The intervals determining the solution of
a system are often expanded in the course of time irrespective of the method and step used.

The phenomenon of interval expansion, called the Moore sweep eﬀect, essentially decreases the

eﬃciency of interval methods. In the present work the notions of the interval and the Moore

eﬀect are formalized and the Inﬁnitesimal Moore Eﬀect (IME) is studied for autonomous

systems on positively invariant convex compact. With IME the intervals expand along any

trajectory for any small step, and that means that when solving a system by a stepwise interval

numerical method with any small step the interval expansion takes place for any initial data

irrespective of the applied method. The local conditions of absence of IME in terms of Jacobi

matrices ﬁeld of the system are obtained. The relation between the absence of IME and

simultaneous dissipativity of the Jacobi matrices is established, and some suﬃcient conditions

of simultaneous dissipativity are obtained. (The family of linear operators is simultaneously

dissipative, if there exists a norm relative to which all the operators are dissipative.)

INTRODUCTION

For solving systems of ordinary diﬀerential equations diﬀerent classes of numerical
methods with guaranteed error estimation including interval methods are used. In
solving a system by an interval method the approximate solution at any considered
moment of time t represents a set (called interval) containing the exact solution at
the moment t. The detailed account of interval methods can be found in monographs
by R.Moore [1] and S.A.Kalmykov, Yu.I.Shokin, Z.Kh.Yuldashev [2].

As a rule, all kinds of rectangular parallelepipeds with sides parallel to coordinate
axes [1,2] are used as intervals, less frequently – ellipsoids [3], balls of ﬁxed norm
[4,5] etc.

One of shortcomings of stepwise interval methods is the following. The intervals
determining the solution of a system are often expanded in the course of time irre-
spective of the method and step used. The simplest example of strong expansion
of intervals during a short time, belonging to R.Moore, is given in [1]. The phe-

eﬀect was investigated only for some particular systems and particular intervals [1].
In the present work the notions of the interval and the Moore eﬀect are formalized
and the Moore eﬀect is studied for autonomous systems on positively invariant
convex compact.

Formally, one can get rid of the interval expansion for any globally stable system
(i.e. such a system, any solution of which is stable according to Lyapunov). To
demonstrate that, let consider a smooth autonomous system:

on the positively invariant compact B ⊂ Rn. Construct a metric ρ on the set B,
assuming for any x ∈ B, y ∈ B:

dx
dt

= f (x)

(1)

ρ(x, y) = sup
t≥0

kx(t) − y(t)k,

where x(t), y(t) are the solutions of the system (1) with the initial conditions
x(0) = x, y(0) = y. This metric is constricting for (1), i.e. for any pair x(t), y(t)
of the solutions of (1) with the initial conditions in B

ρ(x(t), y(t)) ≤ ρ(x(s), y(s)) at t ≥ s.

The metric ρ is topologically equivalent to norm if and only if the system (1) is
globally stable in B. If one considers as intervals all balls of the metric ρ, then in
a deﬁnite sense the Moore eﬀect is absent. That is, there is no interval expansion
when constructing the exact interval solution with any step h > 0. The exact
interval solution of X(t) is deﬁned in the following way: X(0) = X0, where X0 is
the initial interval with the centre at the point x(0) = x0; X((n+1)h) is the minimal
interval with the centre at the point x((n + 1)h) containing ThX(nh), where Tt is
the transformation of the phase ﬂow of (1) during the time t ≥ 0. Indeed, the radius
X((n + 1)h) does not exceed the radius X(nh) at any n.

If the system is not globally stable, then metric is not topologically equivalent to
the norm. It means that small, in usual sense, intervals became large in the metric ρ.
This circumstance makes one refuse from consideration of similar metrics. Moreover,
if the system (1) is absolutely unstable (for example, a system with mixing), then
there is no reasonable way to get rid of the Moore eﬀect.

The decsribed method of elimination the Moore eﬀect for globally stable system
is non-constructive. This can be demonstrated as follows:
for constructing the
constricting metric ρ one must know all exact solutions of the system (1). But then
it is unreasonable to solve the system numerically. We must have constructively
veriﬁable conditions of absence of the Moore eﬀect and a way of construction of
corresponding intervals. This is what we deal with in the present paper. The
conditions of absence of the Moore eﬀect are of local character and formulated
in terms of Jacobi matrices of the system. Except that the causes of frequent
appearance of the Moore eﬀect will be pointed out.

1

Interval spaces and the Moore eﬀect

1.1 Interval Spaces

Deﬁnition 1. We call the family J of convex compacts in Rn the interval space

(and its elements – intervals), if it satisﬁes the following conditions:

a) J is closed with respect to multiplication by non-negative scalars:

if W ∈ J, α ≥ 0, then αW = {αx | x ∈ W } ∈ J;

b) J is closed with respect to intersection:

if W1 ∈ J, W2 ∈ J, then W1 ∩ W2 ∈ J;

c) J is closed according to Hausdorﬀ (i.e. in the Hausdorﬀ metric);
d) if W ∈ J, W 6= {0}, then 0 ∈ riW .
Remind [6] that the Hausdorﬀ metric on the set of all compacts in Rn is introduced

as follows:

ρH(x, y) = max{max
x∈X

min
y∈Y

kx − yk, max
y∈Y

min
x∈X

kx − yk},

where x, y are the compacts in Rn, k.k is a ﬁxed norm in Rn. All Hausdorﬀ metrics
in Rn are equivalent.

Further on by limHi→∞ Wi we denote the Hausdorﬀ limit of the sequence {Wi}+∞
i=1

at i → ∞.

Give several examples of interval spaces.
Example 1. J is the set of all convex compacts symmetric with respect to 0. It

satisﬁes all the properties from a) to d).

Example 2. J is the set of all symmetric with respect to 0 rectangular paral-

lelepipeds (including non-singular), i.e. sets of the form

{x = (x1, . . . , xn) ∈ Rn :

|xk| ≤ ak (k = 1, . . . , n)},

Wi.

where ak ≥ 0 (k = 1, . . . , n). It satisﬁes the properties a), b) and d).

Let now {Wi}∞

i=1 ⊂ J, limHi→∞ Wi = W with a(i)

k being ak, corresponding to

If ρH(Wi, W ) < ε, then W ⊂ Wi + Pε, Wi ⊂ W + Pε, where Pε = {x ∈ Rn :
|xk| ≤ ε (k = 1, . . . , n)} (here a norm in the deﬁnition of the Hausdorﬀ metric is
the l∞-norm). Then for any x ∈ W

is true and for any x ∈ Wi

i.e. there exist the limits

|xk| ≤ a(i)

k + ε (k = 1, . . . , n)

|xk| ≤ limi→∞a(i)
k ;
k ≤ limi→∞a(i)
a(i)
k ,

lim
i→∞

˜ak = lim
i→∞

a(i)
k

(k = 1, . . . , n).

If x ∈ W , then

|xk| ≤ lim
i→∞

a(i)
k

(k = 1, . . . , n).

(2)

Let b = min

(a(i)/˜a ). If for some x ∈ Rn the inequalities (2) are satisﬁed, then

Obviously, x(i) = bix ∈ Wi, i.e. there exists such a subsequence of {x(i)}∞

i=1 that
|xk| ≤ ˜ak (k = 1, . . . , n)}, i.e.

x(i) ∈ Wi, x = limi→∞ x(i). Hence W = {x ∈ Rn :
W ∈ J and the property c) is also satisﬁed.

In constructing interval methods of solving diﬀerent problems it is, as a rule, the

considered interval space that is made use of [1,2].

Example 3. Let k.k be a norm in Rn, r = {x ∈ Rn : kxk ≤ r}, where r ≥ 0. Let

J = {r| r ≥ 0},

i.e. J is the set of all closed balls (further on we omit the word ”closed”) of the
norm. All the properties from a) to d) are satisﬁed. These interval spaces are used,
for example, in [4,5].

Example 4. The construction of example 3 can be generalized as follows. Let

k.k1, . . . , k.km be the ﬁnite set of norms in Rn,

(k)

rk = {x ∈ Rn : kxkk ≤ rk (k = 1, . . . , m)}

where rk ≥ 0 (k = 1, . . . , m)

and

Wr1,...,rm =

(k)
rk .

\1≤k≤m

Let J = {Wr1,...,rm :
a), b), and d).

rk ≥ 0 (k = 1, . . . , m)}. Obviously, J possess the properties

Note that the same element of J can be associated with diﬀerent sets of {rk}. To
1 = W1,C′, where C ′ is

demonstrate that, let m = 2, supx6=0(kxk2/kxk1) = C. Then (1)
any number not less than C. Also, even if one of rk is equal to 0, then

To each compact W ⊂ Rn can be juxtaposed the set

Wr1,...,rm = {0}.

{rk(W )}m

k=1 :

rk(W ) = max
x∈W

kxkk (k = 1, . . . , m).

If W ∈ J then W = Wr1 ∩ . . . ∩ Wrm.

Let now the sequence {Wi}∞

i=1 converge according to Hausdorﬀ to the compact

W , with Wi ∈ J for all i. Similarly to example 2, from the inclusions
Wi ⊂ W + (k)

ε , W ⊂ Wi + (k)
ε

satisﬁed for each ε > 0 for all i > i0(ε) derive the existence of the limits:

˜rk = lim
i→∞

rk(Wi) (k = 1, . . . , m)

and conclude that

i.e. W ∈ J, and the property c) is satisﬁed.

W = W˜r1,...,˜rm,

Example 5. Let Q be a compact convex body without symmetry centre (for

instance, a triangle in R2), 0 ∈ intQ. Assume

J = {αQ : α ≥ 0}.

J possesses the properties from a) to d).

Remark 1. Example 5 can be generalized. For this purpose it is necessary to
consider compact convex bodies Q1, . . . , Qm, the interior of each of them contains 0,

J

T

1.2 Dissipative Operators

In this section the properties of the operators dissipative with respect to compact
are studied. First, let remind some notations.

The aﬃne envelope of the convex set W is denoted by Af f W , the relative interior
W (the interior of W in Af f W ) is denoted by riW , the relative boundary of W (the
boundary of W in Af f W ) is denoted by r∂W . For the boundary of the set X we use
the notation ∂X, intX – for the interior of X, coX – for the convex envelope of X.
By the sum of the sets of X and Y from Rn we mean the set {x + y : x ∈ X, y ∈ Y },
by I – the unit operator.

Let introduce a new notion.
Deﬁnition 2. The linear operator A in the space Rn is called dissipative with
respect to the family of sets {Wν} ⊂ Rn if every set Wν is positively invariant with
respect to the system

dx
dt

= Ax.

(3)

In other words, every Wν is invariant with respect to the semi-group of the

operators exp(At) (t ≥ 0).

Below we consider operators dissipative with respect to families of convex com-
pacts. In particular, the operator is dissipative with respect to the families of all
balls of some norm (for this, dissipativity with respect to only one ball is suﬃcient)
if and only if k exp(At)k ≤ 1 at all t ≥ 0. Thus, in this case we come to the known
deﬁnition of dissipativity with respect to the norm [7].

The set of all operators dissipative with respect to {Wν} is denoted by K({Wν}).
Remark 2. If an operator is dissipative with respect to the family of compacts
and the interior of at least one of them is not empty, then it is dissipative with
respect to some norm.

Indeed, any symmetric with respect to 0 compact convex body is a ball of some

norm (see, for example, [7]). Choose as a ball the following set:

S = co{W ∪ (−W )}

(4)

where W is any set of the considered family of {Wν}, for which intW 6= ∅.

However, if W is a compact and the operator is dissipative with respect to the
norm whose ball is S (4), then it does not yet mean that the operator is dissipative
with respect to W (see also example 8).

Remark 3. From the invariance of a family of compacts with respect to the
linear operator follows the invariance of the Hausdorﬀ closure (i.e. closure in the
Hausdorﬀ metric) of this family. Therefore from dissipativity of the operator with
respect to the family of compacts follows the dissipativity with respect to Hausdorﬀ
closure of this family.

Let W be a convex compact in Rn with 0 ∈ riW . In this case Af f W is a linear
subspace, and if the operator A is dissipative with respect to W , then Af f W is
invariant with respect to A.
Introduce the following functional on the subspace
L(W ) of the space L(Rn) (of linear operators in Rn), consisting of the operators,
with respect to which Af f W is invariant:

µW (A) = sup
x∈W

µW (Ax).

(5)

It is easy to see that A ∈ K(W ) if and only if

µW (exp(At)) ≤ 1

for all t ≥ 0.

In particular, the operator A ∈ L(W ) is strongly dissipative with respect to convex
compact W if exists such ε > 0 that µW (exp(At)) ≤ exp(−εt) at all t ≥ 0. In general,
the operator A is strongly dissipative with respect to convex compact W if and only
if A + εI ∈ K(W ) for some ε > 0.

If W is a ball of the norm k.k, then strong dissipativity with respect to W means
the existence of such ε > 0 that k exp(At)k ≤ exp(−εt) for all t ≥ 0. We come to
the deﬁnition of stable dissipativity with respect to the norm [11, 12, 19].

Introduce in L(Rn) the following functional:

γW (A) = lim
h→+0

µW (I + hA) − 1
h

In the case, when W is a ball of some norm (i.e. µW is a norm), arrive at the known
deﬁnition of the logarithmic Lozinsky norm [9, 10].

Lemma 1. The operator A ∈ L(Rn) is dissipative (strongly dissipative) with

respect to W , if and only if the inequality γW (A) ≤ 0 (γW (A) < 0) is satisﬁed.

Proof. Suﬃciency. The following inequality is obtained in [9]

k exp(At)k ≤ exp(γ(A)t)

where γ(A) is the Lozinsky norm of the operator A, corresponding to the norm k.k.
By literal repetition of the reasonings from [9] (with a substitution of the norm by
Minkovski functional), one can obtain the inequaliny

µW (exp(At)) ≤ exp(γW (A)t)

for all t ≥ 0, from which immediatelly follows the suﬃciency.

Necessity. Evidently,

µW (exp(At)) = µW (I + At) + o(t) (t → 0).

Therefore,

γW (A) = lim
h→+0

µW (eAh) − 1
h

.

Let ε ≥ 0. If µW (exp(At)) ≤ exp(−εt) at all t ≥ 0, then

γW (A) ≤ lim
h→+0

exp(−εh) − 1
h

= −ε,

which proves the necessity. The lemma is proved.

Assign a relatively open convex cone Qx(W ) to every point x ∈ r∂W according

to the rule: y ∈ Qx(W ) if and only if there exists such ε > 0 that

x + εy ∈ riW.

Lemma 2. For strong dissipativity of A with respect to convex compact W it is

necessary and suﬃcient that for every point x ∈ r∂W the inclusion

be true. For dissipativity of A with respect to W it is necessary and suﬃcient that
for every point of X ∈ r∂W the inclusion

Ax ∈ Qx(W )

be true.

Proof. Note that the operator A is strongly dissipative with respect to W if and
only if there exists such t0 > 0 that µW (I + At0) < 1. Indeed, the existence of such
t0 for a strongly dissipative operator follows immediately from the negativeness
of γW (A). Conversely,
if µW (I + At0) < 1, then there exists such ε > 0 that
µW (I + (A + εI)t0) < 1. But then γW (A + εI) ≤ 0, the operator (A + εI) is
dissipative. It means that A is strongly dissipative.

If the operator A is strongly dissipative with respect to W , then, according to
the above, for each x ∈ r∂W there exists such tx > 0 that (I + txA)x ∈ riW . It
means that the vector Ax belongs to to the cone Qx(W ).

Conversely, let the latter condition be satisﬁed. According to the hypothesis of
the theorem and convexity of W , for each x ∈ r∂W there exists the only positive
number s = s(x) such that (I +sA)x ∈ r∂W . Show that s0 = inf x∈r∂W s(x) > 0. Let
it be not so. Then there exists such a subsequence {xn}+∞
n=1 that limn→∞ s(xn) = 0.
′. For every
Choose from {xn} a converging subsequence {xn
n ∈ N and for every ε > 0

′}. Let ˜x = limn→∞ xn

[I + (s(xn

′) + ε)A]xn

′ /∈ W.

Passing to the limit, obtain

(I + εA)˜x /∈ riW

which contradicts the hypothesis of the theorem.

Thus, s0 > 0. For any t0 ∈ (0; s0) is true µW (I + At0) < 1, i.e. the operator A is

strongly dissipative.

If A ∈ K(W ), then for any ε > 0 we have AX − εx ∈ Qx(W ) (for any x ∈ r∂W ),
i.e. Ax ∈ ¯Qx. Conversely, if Ax ∈ ¯Qx, then Ax − εx ∈ Qx at any ε > 0, and A
represents a limit point of the family of dissipative operators, i.e. A ∈ K(W ). The
lemma is proved.

Remark 4. Immediately from the Krein-Milman theorem [8] follows that it is
suﬃcient to require from the lemma conditions that inclusions be satisﬁed not for
all points x ∈ r∂W , but for extremal points of W only.
In particular, if W is
a polyhedron, then it is suﬃcient to test its vertices only. Thus, to elucidate the
question about dissipativity (strong dissipativity) of the operator with respect to the
polyhedron, one should test only the fulﬁlment of ﬁnite number of linear inequalities.
Remark 5. In the proof lemma 2 we have used the obvious fact: the closure of

the set K(W ).

One more fact follows directly from lemma 2.
Lemma 3. The set K(W ) is a closed convex cone. The cone of all strongly dissi-
ε>0(K(W ) −
pative with respect to W operators coincides with riK(W ) and with
εI). If {Wν} is a family of convex compacts with 0 ∈ riWν for all ν, then K({Wν})
is a closed convex cone.

S

Remark 6. If intW = ∅, then intK(W ) = ∅. Indeed, if Af f W is invariant with
respect to the operator A1, then A + εA1 /∈ K(W ) at ε 6= 0. If intW 6= ∅, then

Deﬁnition 4. The operator A ∈ K(W ) is called stable (or roughly) dissipative

with respect to W , if A ∈ intK(W ).

Deﬁnition 4 generalize the deﬁnition of the stable dissipativity with respect to

the norm [11, 19].

Pass to the consideration of operators dissipative with respect to interval spaces.
Let ﬁnd out for which interval spaces J the interior of the cone K(J) is not empty.
Let V be a set of all compact convex bodies in Rn. Fix some norm k.k in Rn and

assume

V .

d(W ) = min
x∈∂W
Lemma 4. The function d(W ) is continuous according to Hausdorﬀ on the set

kxk.

Proof. First note that if X ∈ V, Y ∈ V , then ρH(∂X, ∂Y ) ≤ ρH (X, Y ). Indeed,
let ρH(X, Y ) ≤ ε. Then X ⊂ Y + Sε where Sε = {x ∈ Rn : kxk ≤ ε}. Let, further
on, there exists such y0 ∈ (∂Y ) ∩ X that y0 /∈ Sε + ∂X. Construct at the point
y0 a tangent hyperplane L to Y . Let l be the direction of the external normal to
∂Y at the point y0 orthogonal to L. Draw a ray from the point y0 in the direction
of l to the point x0 of crossing with ∂X. Construct such a ball S of the norm k.k
with the centre at the point x that y0 ∈ ∂S. The radius of S is larger than ε and
S ∩ Y = {y0}. Thus, if one constructs a ball S′ ⊂ S of the radius ε with the centre
at x0, then

S′ ∩ Y = 0.

But then x0 /∈ Y + Sε, i.e. X 6⊂ Y + Sε what is contrary to the assumption.

The existence of such y0 ⊂ ∂Y that y0 /∈ X ∪ (∂X + Sε) is also impossible, since
then y0 /∈ X + Sε, i.e. Y 6⊂ X + Sε. Consequently, ∂Y ⊂ Sε + ∂X, and that means
d(X) ≤ d(Y ) + ε. Similarly, d(Y ) ≤ d(X) + ε. It means that |d(X) − d(Y )| ≤ ε,
and the function d(W ) is continuous on V . The lemma is proved.

Lemma 5. For non-emptiness of intK(J) it is necessary and suﬃcient for all the

elements of the interval space J, exept {0}, to posess non-empty interior.

Proof. Necessity. Follows immediately from remark 6.
Suﬃciency. Show that under the conditions of the theorem the inclusion

−I ∈ intK(J)

(6)

takes place.

To each point x (kxk = 1) we assign the set Wx according to the rule:

Wx =

W.

\W ∋x,W ∈J

˜W =

Wx

According to the conditions b) and c) from deﬁnition 1, Wx ∈ J. The set

[kxk=1
is compact. Indeed, ˜W is contained in any element of J containing unit ball of the
norm k.k; such an element exists due to non-emptiness of the interior of all intervals
(exept {0}) and the property a) from deﬁnition 1. Note that Hausdorﬀ closure of the
family {Wx : kxk = 1} represents a compact in the Hausdorﬀ metric, contained in
J

of lemma 4) the existence of such ε > 0 that d(Wx) ≥ ε for all such x that kxk = 1
(indeed, d(Wx) > 0, since 0 ∈ intWx).

Thus, there exists such ε > 0 that for all x (kxk = 1) the inclusion

Ax ∈ intWx

is true if kAk < ε.

In other words, Ax − x ∈ Qx(Wx) if kAk < ε, kxk = 1 (see lemma 1). The more
so, as Ax − x ∈ Qx(W ) for all W ∈ J (W ∋ x, kAk < ε) at all such x that kxk = 1.
But then Ax − x ∈ Qαx(αW ) for all α > 0, kAk < ε. Hence, A − I ∈ K(J), i.e. (6)
is satisﬁed. The lemma is proved.

Thus, we have shown that under the conditions of lemma 5 K(J) is a convex solid

cone.

J if it belongs to intK(J).

Deﬁnition 5. The operator is stable dissipative with respect to the interval space

For stable dissipative operators the remark 2 is true:

if an operator is stable
dissipative with respect to the family of compacts and the interior of at least one of
them is not empty, then it is stable dissipative with respect to some norm.

1.3 The Moore Eﬀect for Autonomous Systems

The results of the previous section can be applied to the study of the Moore sweep
eﬀect. First give the exact deﬁnition of what we understand by the Moore eﬀect.

Let in the vicinity of a compact convex body B ⊂ Rn be given a smooth au-

tonomous system

dx
dt

= f (x)

(7)

with B positively invariant with respect to (7), and let x(0) be determined inexactly,
namely

x(0) ∈ x0 + W0,
where x0 ∈ B, W0 ∈ J, x0 + W0 ∈ B, J is some interval space (see deﬁnition 1).

Remark 7. Irrespective of particular numerical method (i.e. dealing with the ex-
act solution of the initial value problem for (7) with the initial conditions x(0) = x0)
a stepwise interval solution with step h > 0 can be described as follows.

Let Th be the transformation of the phase ﬂow of (7) during the time t (shift over
time t), W0 ∈ J is the initial interval (its sense is an uncertainty in initial data).
Assume

X0 = x0 + W0,

Xm+1 = T(m+1)hx0 + Wm+1,

Wm+1 =

W,

W ⊃Wm+1(h),W ∈J
\

Wm+1(h) = Th(Tmhx0 + Wm) − T(m+1)hx0.

The sequence {Xm}+∞
Deﬁnition 6. The absence of inﬁnitesimal Moore eﬀect (IME) means that
m=0 is enclosed: Wm ⊃ Wm+1 for all m, i.e. the

m=0 is the exact stepwise interval solution of (7).

for any h > 0 the sequence {Wm}+∞
obtained intervals do not expand.

any small step the interval expansion takes place for any initial data irrespective of
the applied method (since it is true even for exact solutions).

Generalizing the construction [10] for norms, introduce the following functional:

NW (x, y) = lim
h→+0

µW (x + hy) − µW (x)
h

.

Literally (with substitution of the norm for Minkovski functional) repeating the

reasonings from [10] (pp.127, 426), come to the following statemets.

Statement 1. If x(t) with values in Rn is diﬀerentiable on connected subset T of
the real axis, and W is a convex compact (0 ∈ riW ), then the function µW (x(t)) is
almost everywhere diﬀerentiable on T and the derivative (where it exists) coincides
with the right-hand derivative, equal to NW (x(t), ˙s(t)). The right-hand derivative
of µW (x(t)) exists everywhere on T except the right-hand end.

Statement 2.

γW (A) = sup
x∈W

NW (x, AX).

By f ′(x) further on we denote the mapping derivative of f .
The main part of further results on IME can be obtained from the following

theorem.

Theorem 1. Let in the region U ⊂ Rn be given a smooth autonomous system
(7), B ⊂ U be positively invariant with respect to (7) compact convex body. IME
is absent for compact B, system (7) and interval space J if and only if

f ′(x) ∈ K(J)

(8)

for all x ∈ B, i.e. for any x ∈ B the Jacoby matrix of system (7) in the point x is
strongly dissipative with respect to J.

Proof. Suﬃciency. Let W ∈ J. Consider two solutions x1(t), x2(t) of system (7)
with initial conditions from B. Denote ∆(t) = x1(t) − x2(t). Using statements 1 and
2 and the theorem on ﬁnite increment, estimate the derivative of µW (∆(t)):

d
dt

≤ sup
0≤Θ≤1

≤ sup
0≤Θ≤1

µW (∆(t)) = NW (∆(t), d∆(t)/dt) ≤

NW (∆(t), f ′(xc(t))∆(t)) ≤

γW (f ′(xc(t)))µW (∆(t)),

where xc(t) = x1(t)+Θ(x2(t)−x1(t)), 0 ≤ Θ ≤ 1 for all t ≥ 0. By (8) and statement
1 we obtain

d
dt

µW (∆(t)) ≤ 0.

Since the latter inequality holds for all t ≥ 0 and for all W ∈ J, in systen (7) on

B IME with respect to J is absent.

Necessity. Let W ∈ J, x0 ∈ intB, t0 ≥ 0, y ∈ Af f B, y 6= 0. There exists such
h0 > 0 that x0 + h0y ∈ B. Due to smoothness of system (7) there exist and are
unique the solutions x1(t), x2(t) of the initial value problem for (7) with the initial
conditions x1(t0) = x0, x2(t0) = x0 + h0y. Assume ∆(t) = x1(t) − x2(t). Then

= NW

∆(t0)
µW (∆(t0))

 

, f ′(xc)

∆(t0)
µW (∆(t0)) !

=

= NW

y
µW (y)

 

, f ′(xc)

y
µW (y) !

,

where xc = x0 + Θh0y, 0 < Θ < 1.
By virtue of absence of IME

d
dt

ln µW (∆(t)) ≤ 0

for all t ≥ 0. Since if x0 + h0y ∈ b, then:
(a) x0 + hy ∈ B for all h ∈ [0; h0],
(b) a set of those h ∈ [0; h0], for which

NW

y
µW (y)

 

, f ′(x)

y
µW (y) !

≤ 0,

is dense on the segment [0; h0],
and (c) due to its closureness coincides with this segment.

By virtue of arbitrarity of the choice of x0 for any x0 ∈ intB, t ≥ 0, y ∈ Af f B,

y 6= 0 the inequality

NW

y
µW (y)

 

, f ′(x)

y
µW (y) !

≤ 0

is satisﬁed. It holds also for any x ∈ B, t ≥ 0, y ∈ Af f B, y 6= 0. Hence, from lemma
1 and statement 2 immediately follows dissipativity of f ′(x) with respect to J for all
x ∈ B. The theorem is proved.

Deﬁnition 7. The family of linear operators {Aα} is called simultaneously dis-

sipative, if there exists a norm relative to which all the operators are dissipative.
Simultaneously dissipative operators were studied in detail in [11, 12, 17-22].
From theorem 1, example 3, and remark 2 we obtain the following theorem.
Theorem 2. For existence of interval space in which at least one interval posesses
non-empty interior and with respect to which in system (7) there is no IME on B,
it is necessary and suﬃcient for the family {f ′(x) : x ∈ B} to be simultaneously
dissipative.

Thus, the problem of existence of the interval space, with respect to which IME
is absent, is reduced to the problem of simultaneous dissipativity of Jacobi matrices.
As sought for space one can choose a set of all balls of that norm relative to which
all Jacobi matrices are dissipative. This norm is constricting for (7) on B (i.e. the
distance between two solutions with initial conditions from B will not expand with
time). Hence, all systems without IME (with respect to some interval space) on B
are globally stable in B (see introduction).

Bellow by C 1(B) we denote the Banach space of smooth mappings of B in Rn

with the norm

kf kC1(b) = max
x∈B

kf (x)k +

n

Xk=1

max
x∈B (cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

∂f
∂xk (cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

where k.k is a ﬁxed norm in Rn.

Further on, speaking about properties of autonomous systems, we mean the prop-

Immediately from lemma 3 and theorem 1 the following statement can be ob-

Theorem 3. The set of systems on B without IME with respect to J is closed

tained.

convex cone in C 1(B).

For this cone we use the notation FB(J).
Further on, speaking about the vicinity of an autonomous system in C 1(B) we
mean a part of the vicinity, consisting only of those systems for which the set B is
positively invariant.

Let us study under what conditions the interior of the cone FB(J) is non-empty.
Theorem 4. For non-emptiness of intFB(J) in C 1(B) it is necessary and suﬃ-

cient for all elements of J, exept {0}, to possess non-empty interior.

Proof. Necessity. Let exist such a set W ∈ J that intW = 0. Consider any
system (7) without IME with respect to J on B. Since intB 6= 0, there exist
two diﬀerent concentrical balls S1 and S2 of usual l2-norm, belonging to intB with
S1 ⊂ S2. Construct such a function g ∈ C∞(Rn) that g(x) = 1 for all x ∈ S1 and
g(x) = 0 at all x /∈ S2. Since Af f W 6= Rn, one can construct a linear operator
A ∈ L(Rn) mapping Af f W into such a subspace E0 6= {0} that (Af f W )∩E0 = {0}.

Consider the system

dx
dy

= f (x) + εg(x)AX,

(9)

where ε > 0 is arbitrary. The set B is positively invariant with respect to (9), since
the vector ﬁeld generating (9) coincides with f in the vicinity of ∂B. On the other
hand, there exist Jacobi matrices (9) relative to which Af f W is not invariant, i.e.
in (9) exist IME with respect to J on B. Since in any vicinity of f there is at least
one vector ﬁeld, generating (9), then

Suﬃciency. Consider the system dx/dt = −x. It is a system on B without IME
with respect to J. Furthermore, if all elements of J, except {0}, possess non-empty
interior, then by lemma 5 the matrix of the system is stable dissipative with respect
to J (see deﬁnition 5).

Consider the system:

(10)

where kvkC1(B) < ε with ε chosen so that

intFB(J) = 0.

dx
dy

= −x + v(x),

A − I ∈ K(J)

if kAk < ε (see the proof of lemma 5). Then all Jacobi matrices (10) are dissipative
with respect to J, and if v is choosen so that B is positively invariant with respect
to (10), then in (10) IME is absent (by theorem 1). The theorem is proved.

Thus, intFB(J) 6= 0 if and only if intK(J) 6= 0.
It is easy to see that in the proof of suﬃciency in theorem 4 one can instead
of the system dx/dy = −x consider any system whose Jacobi matrices are stable
dissipative with respect to J.

Remark 8. By analogy with the space C 1(B) one can construct the Banach

spaces C k(B) (k ∈ N) with the norm

k

X

where α = (α1, . . . , αn) is a multiindex:

|α| = α1 + . . . + αn, Dαf =

∂|α|f
1 . . . ∂xαn
n

∂xα1

and the metric space C ∞(B) with the system of seminorms

{max
x∈B

k(Dαf )(x)k :

|α| ≤ m}+∞

m=0.

Small C k-additions (1 ≤ k ≤ +∞) are small and in the C 1-norm. Therefore, for
C k-smooth systems under the conditions of theorem 4 the interior of FB(J) is non-
empty and in C k(B). As shows the proof of theorem 4 (necessity), if conditions of
the theorem are not satisﬁed,then the interior of FB(J) in C k(B) is empty.

Let clarify what autonomous system without IME in speciﬁc interval spaces looks

Theorem 5. Any system without IME with respect to J from example 1 has the

like.

form:

dx
dt

= ax + c,

where a ≤ 0, C ∈ Rn is a constant vector.

Proof. Let A ∈ K(J). All the segments symmetrical with respect to 0 belong to
J. Every such a segment has the form {y ∈ Rn|y = ax, |a| ≤ 1} for some x ∈ Rn.
The cone Qx (see lemma 2) for each segment consists of vectors of the form ax,
where a < 0. Thus, every non-zero vector x ∈ Rn is eigenvector of the operator A,
corresponding to non-positive eigenvalue. Thus:

K(J) = {aI| a ≤ 0}.

(11)

Let now a system without IME have the form

= f1(x1, . . . , xn);
· · ·

= fn(x1, . . . , xn).

dx1
dt

dxn
dt






∂fi
∂xj

≡ 0 (i 6= j);

According to (11) and theorem 1

(12)

∂f2
∂x2
From (12) follows that fk depends only on xk (k = 1, . . . , n).

It means that
∂fk/∂xk also depends only on xk, i.e. by virtue of (13) ∂fk/∂xk = const (k =
1, . . . , n). Then

∂fn
∂xn

∂f1
∂x1

≡ . . . ≡

≤ 0.

(13)

≡

∂f1
∂x1
and the system has the form:

≡

∂f2
∂x2

≡ . . . ≡

≡ a ≤ 0

∂fn
∂xn

dx

= ax + c,

Thus, whatever nonlinear (or even linear with non-scalar matrix) system we con-
sider, if we take as J the interval space of example 1 (or any wider space), IME will
be present in the system. From theorem 5 also follows that any dissipative with
respect to all norms operator has the form aI, where a ≤ 0 (see also remark 3).

Example 6. Consider J from example 2. J contains all symmetrical with respect
to 0 segments of coordinate axes (thus, the conditions of theorem 4 are not satisﬁed,
i.e. intFB(J) = 0). Let A ∈ K(J). Reasoning like in proof of theorem 5, conclude
that all coordinate axes are eigenspaces of the operator A, corresponding to non-
positive eigenvalues. In other words, the matrix of the operator A is diagonal and
non-positive. On the other hand, by virtue of lemma 2, all such operators belong to
K(J). Thus, systems without IME with respect to J on B have the form

= f1(x1);

· · ·

= fn(xn)

dx1
dt

dxn
dt






∂fk
∂xk

≤ 0 (k = 1, . . . , n)

where

for all x ∈ B.

From the considered example follows that when using standard intervals (rectan-

gular parallelepipeds) IME will be observed in almost all systems in Rn if n 6= 1.

The systems without IME with respect to J from example 3 on B represent all
systems for which the norm k.k is constricting in B (see the text after theorem 2).
Remark 9. Note that testing of dissipativity (stable dissipativity) of the operator
with respect to the norm is equivalent to non-positiveness (negativeness) of the
corresponding Lozinsky norm. For some norms an explicit form of corresponding
Lozinsky norm is known (see, for example, [9] or [10, p.463-465]).
In particular,
for the Euclidean norm the Lozinsky norm of the operator A coincides with the
largest eigenvalue of the operator (A∗ + A)/2. The Lozinsky norm of the operator
A represented by the matrix (aij)n
i,j=1 with respect to l1− and l∞-norms is given by
the formulae, respectively:

max
1≤i≤n

max
1≤i≤n

(Re aii +

|aji|);

(Re aii +

|aij|).

Xj6=i

Xj6=i

In remark 9 it is assumed that the operator A acts in the space C n. The deﬁnitions
and used here properties of dissipative operators in complex spaces are analogous
to those in real ones.

Example 7. Let J be the interval space from example 4. Then

\1≤k≤m
where Kk.kk is the cone of all operators dissipative with respect to the norm Kk.kk.

K(J) =

Kk.kk ,

sets of an autonomous system. Similarly,

intK(J) =

intKk.kk.

\1≤k≤m
Let, for example, k.k1 be l∞-norm, k.k2 be l2-norm in R2. Then the conditions
i,j=1 with respect to J

of stable dissipativity of the operator A with the matrix (aij)2
according to remark 9 are of the form:

Thus, for the system of the form

if the inequalities

(14)

4a11a22

> (a12 + a21)2;

a11 + |a12| < 0;

|a21| + a22 < 0.






dx1
dt
dx2
dt

∂f2
∂x2
∂f1
∂x2 (cid:12)
(cid:12)
(cid:12)
∂f2
(cid:12)
(cid:12)
∂x2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
+
(cid:12)

4

·




∂f1
∂x1
∂f1
∂x1
∂f2
∂x1 (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)






= f1(x1, x2);

= f2(x1, x2)

>

∂f1
∂x2

 

+

2

;

∂f2
∂x1 !

< 0;

< 0

= −2x1 + x2;

= 2x1 − 3x2

dx1
dt
dx2
dt





are satisﬁed and the compact convex body B is positively invariant with respect
to (14), then in (14) IME with respect to J (from example 4) is absent on B. For
example, such is the following system:

if B is the square {(x1, x2) : |x1| ≤ 1, |x2| ≤ 1} or the circle {(x1, x2) : x2

2 ≤ 1}.
Example 8. Consider J from example 5. Let Q be rectangular triangle with

1 = x2

vertices at the points (−1; 2); (−1; −1); (1; −1).

From lemma 2 and theorem 1 follows that the cone FB(J) consists of the systems
of the form (14), with respect to which the compact B is positively invariant and

Substituting all the inequality signs in (15) by strict ones, obtain intFB(J). For

≤ 0;

≤ 0;

≤ 0;

(15)

for which

∂f1
∂x1
∂f1
∂x1
∂f2
∂x1

+

− 2

+

∂f1
∂x2
∂f1
∂x2
∂f2
∂x2 (cid:12)
(cid:12)
(cid:12)
∂f1
(cid:12)
(cid:12)
∂x2

+ 6

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

−3

∂f1
∂x1

3

∂f1
∂x1






∂f1
∂x2

dx1
dt
dx2
dt

is true.

example, the system




belongs to intFB(J) for B = Q.

− 2

+ 4

≤ 0;

∂f2
∂x1

∂f2
∂x1

∂f2
∂x2

∂f2
∂x2

− 3

+ 2

− 2

≤ 0.

= −x1;

= −6x1 − 4x2

K(J) = K(Q) ⊂ K(S).

−4 −1





2

0 


Corresponding ball S (see remark 2) is the parallelogram with the vertices in the

points (−1; 2); (−1; −1); (1; −2); (1; 1). From remark 2 follows that

One can see that K(J) 6= K(S). For example, the operator given by the matrix

is dissipative with respect to S, but it is not dissipative with respect to J. In other
words, in the systems without IME with respect to {αS : α ≥ 0} (i.e. constricting
according to the norm whose ball is J) there can be observed IME with respect to
J.

This example can be generalized as follows. Consider J from remark 2. In system
(7) on B IME is absent with respect to J if the operators f ′(x) for all x ∈ B are
dissipative with respect to all sets Qk(k = 1, . . . , m).

To sum up, one can say the following. When using suﬃciently wide interval
In
spaces in almost all systems in accordance with theorem 4, IME is observed.
particular, IME takes place almost for all systems when using standard intervals
(see example 6). Expansion of the interval space results in the appearance of new
systems with IME: thus, in using a set of all symmetrical to 0 convex compacts
IME is absent only for linear systems with non-positive scalar matrices. And the
most impotent: the question about the existence of interval space, with respect to
which in the considered system IME is absent, is reduced to the problem of joint
dissipativity of the Jacobi matrices. Therefore, there is no interval space with respect
to which all (or even if in some sense almost all) globally stable systems would have

corresponding interval spaces for each particular system. These problems are solved
constructively very rarely.

We have treated the Moore eﬀect in a very strong sense. The condition of bound-
edness of the sequence of intervals {Wm}+∞
m=0 at any step h > 0 (see remark 7)
is weaker (and acceptable, generally speaking, for constructing suﬃciently narrow
interval solutions). This condition can be called the condition of absence of the
asymptotic Moore eﬀect (AME). It is the weakest from acceptable conditions, since
with AME it is impossible to use stepwise interval methods to obtain narrow interval
solutions at large times. The study of AME is still not completed. It is evident only
that for a linear autonomous system in considering the interval space from example
3 AME is equivalent to IME. One can suggest a hypotesis: the problem of existence
and constructing of the interval space with respect to which AME is absent in the
autonomous system is reduced to the question of simultaneous dissipativity of Jacobi
matrices (and of constructing a constricting norm).

2 Conditions of Simultaneous Dissipativity of Operators

2.1 Some General Results

In the present section some conditions of simultaneous dissipativity of the operators
will be considered (see deﬁnition 7).

A deﬁnition of a simultaneous dissipativity can be generalized in such a way.
Deﬁnition 7′. A family of linear operators {Aα} is called simultaneously stable
dissipative if there exists a norm with respect to which all operators Aα are stable
dissipative.

Lemma 6. Let the space Rn be expanded into direct sum of subspaces Ei (i =
1, . . . , k) and each of them is invariant with respect to all operators of the family
{Aα}. Further on, let restriction of the family {Aα} on any Ei be simultaneously
(sumultaneously stable) dissipative. Then {Aα} is simultaneously (simultaneously
stable) dissipative.

Proof. Let k.ki (i = 1, . . . , k) be the norms in Ei in which the restrictions of
{Aα} on Ei are simultaneously (simultaneously stable) dissipative. Deﬁne the norm
in Rn in this way:

kxk =

kxiki,

k

Xi=1

where x =

k
i=1 xi with xi ∈ Ei (i = 1, . . . , k).

In this norm all operators Aα are simultaneously (simultaneously stable) dissipa-

tive. The lemma is proved.

P

It is known [7] that for one operator the norm with respect to which it is dissipa-
tive exists if and only if the spectrum of the operator lies in the closed left half-plane
and the boundary part is diagonalizable (i.e. Jordan boxes corresponding to pure
imaginary, including zero ones, eigenvalues are diagonal). The norm, with respect
to which the operator is stable dissipative, exists if and only if the spectrum of the
operator lies in the open left half-plane.

Several stable dissipative (in their own norms) operators not necessarily are si-
multaneously dissipative. To demonstrate that, consider operators represented by

the matrices

A1 =

; A2 =

−1

3





0 −1 


−1

0

.





3 −1 


Each of them is stable dissipative in its norm (due to the location of the spectrum).
But

A1 + A2 =



−2

3

.

3 −2 



The spectrum of the operator (A1 + A2) contains the point λ = 1 which does not
belong to the closed left half-plane. Thus, the operator (A1 +A2) is not dissipative in
any norm. By lemma 6 the operators A1 and A2 are not simultaneously dissipative.
The problem to ﬁnd out necessary and suﬃcient conditions of simultaneous dis-
sipativity of an arbitrary (even ﬁnite) family of operators seems to be wery diﬃcult.
Nevertheless, one can obtain some suﬃcient conditions imposing diﬀerent constraints
on the operators. Obtain the suﬃcient condition of simultaneous dissipativity of the
family generating a solvable Lee algebra. Remind [13] that a family of matrices gen-
erates solvable Lee algebra if and only if all elements of this family are simultaneously
reducible to triangular form (generally speaking in complex basis).

Theorem 6. Let the family {Aα} be compact and generate solvable Lee algebra,
and the spectrum of each operator Aα lies in the open left half-plane. Then {Aα}
is simultaneously stable dissipative.

Proof. First consider the case of complex space Cn. Consider matrices of the

operators Aα in the basis where they are of triangular form.

Let each matrix Aα have the form

λ(α)
1

.

0

.

µ(α)
21

λ(α)
2

0

0

.

· · ·

· · ·

· · ·

0

0

0

µ(α)
n1 µ(α)

n2 µn3(α)

· · · µ(α)

n,(n−1) λ(α)

n

0

0

0

.
















Aα =
















Show the existence of such a set of positive numbers {ck}n

k=1 that all Aα are stable

dissipative in the norm

kzk = max
1≤k≤n

|zk|
ck

(here zk is the k-th coordinate of the vector z in the given basis), whose unit ball is
the polycylinder

|zk| ≤ ck (k = 1, . . . , n).

If {ek}n

k=1 is the considered basis, then, evidently, norm (16) coincide with the

l∞-norm with respect to the basis {ck/ek}n

i,j=1 in the norm (16):

(16)

(17)

(18)

Re aii +

|aij| < 0 (i = 1, . . . , n).

cj
ci

Xj6=i

For the matrices Aα the conditions (18) look like this:

< 0;

< 0;

· · ·

(19)

Re λ(α)
1

Re λ(α)

2 +

|µ(α)
21 |

c1
c2

c1
cn






Re λ(α)

n +

|µ(α)

n1 | + . . . +

|µ(α)

n,(n−1)| < 0.

cn−1
cn

Suppose µ = supα,k6=l |µ(α)

kl |; λ = − supα,k Re λ(α)
k . From the conditions of the
theorem follows that 0 < λ < +∞, 0 < µ < +∞. To fulﬁl (19) for all Aα, it is
suﬃcient that the inequalities

(c1 + . . . + ck−1)µ < ckλ (k = 1, . . . , n); c1 > 0

(20)

be satisﬁed.

Show the solvability of system (20). Let c1 = 1. Choose the others ck so that

c2 > µ/λ; c3 > (1 + c2)µ/λ; . . . ;

cn > (1 + c2 + . . . + cn−1)µ/λ.
Then the inequalities (20) are satisﬁed, i.e. all operators Aα are stable dissipative
in the norm (14).

Let now operators Aα act in the space Rn.

In usual way complexify Rn and
the family Aα. Then, as it has been described above, construct a cylinder (17).
Intersection of (17) with the initial space Rn produce a ball of the norm in which
all Aα are stable dissipative. The theorem is proved.

If instead of stable dissipative operators one considers dissipative operators, then

the analog of theorem 6 is not true, starting from real dimension 4. Let

A1 =

; A2 =

i

1





0 2i 


2i 1

0





.

i 


A1 + A2 =



3i

2

.

0 3i 


Each of the operators A1,2 is dissipative in its norm. The ﬁnite family is compact,
the matrices A1 and A2 generate solvable Lee algebra. Nevertheless


The only eigenvalue of the operator (A1 + A2) is pure imaginary, with the matrix
of this operator representing (up to a constant factor) non-trivial Jordan box. That
means it is not dissipative in any norm, i.e. A1 and A2 are not simultaneously
dissipative. To obtain a real example, one has to make the matrices A1 and A2 real:

0 −1 1

0 0

0 0 −2

; AR

2 =

0

1

















0 −2 1

0

1

0 0

0 0 −1

2

0

















.

















AR

1 =

1

0

















To keep true the statement about simultaneous dissipativity for nonstable dissi-
pative operators, it is suﬃcient to strengthen the requirement of solvability up to
nilpotency. Remind [13] that for each linear operator A in the space E the operator
ad A in L(E) is deﬁned:

(ad A)B = AB − BA.

The family {Aα} generates the nilpotent Lee algebra if and only if there exists
k=1 (among the elements of wich

such a number m ∈ N that for any set of {Aαk}m
there may be the same ones) and for all α:

m

Yk=1

(ad Aαk )Aα = 0.

(21)

Nilpotent Lee algebra is always solvable. Commutative Lee algebra is nilpotent

(for it m = 1) and solvable.

Theorem 7. Let the family {Ak} be ﬁnite and generate nilpotent Lee algebra,
and for each operator Ak exist a norm with respect to which it is dissipative. Then
{Ak} is simultaneously dissipative.

Proof. Without loss of generality one can assume that among the operators Ak
there are no scalar ones (if A = aI, where Re a ≤ 0, then A is dissipative in any
norm) and exists at least one operator (denote it A1), among eigenvalues of which
there are pure imaginary (otherwise we are under the conditions of theorem 6).

First assume that Ak operates in Cn. We prove the theorem by induction on
dimension of space. In dimension 1 the statement of the theorem is trivial. Show
that one can expand all the space Cn into a direct sum of two non-trivial subspaces
invariant with respect to all Ak. Since in both of them the conditions of the theorem
(for corresponding restrictions of {Ak}) are satisﬁed, then to complete the proof one
has to use lemma 6.

Let λ be an imaginary eigenvalue of A1; E′ be the corresponding to λ eigen-
subspace (by virtue of diagonalizability of boundary part of A1 it coincides with
whole corresponding root subspace); E′′ be the sum of root subspaces corresponding
to all the others eigenvalues of A1. Evidently, Cn = E′ ⊕E′′ (the sign ⊕ means direct
sum); E′ 6= Cn, otherwise the operator A1 is scalar. Show the invariance of E′ and
E′′ with respect to all Ak.
Let x ∈ E′. Then

On the other hand,
(ad A1)mAk = 0 for all k and

in accordance with (21) there exists such m ∈ N that

A more general fact is true: if Ax = 0 and (ad A)mB = 0, then AmBx = 0. For

m = 0 the fact is obvious. Let that be true for m = r. Assume

A1x = λx.

(A1 − λI)mAkx = 0.

Ax = 0; (ad A)r+1B = 0.

Then (ad A)r(ad A)B = 0, and according to the inductive hypothesis
Ar(ad A)Bx = 0. But Ar+1Bx = Ar(BAx + (ad A)Bx), i.e. Ar+1Bx = 0, as
was to be proved.

As a consequence of coincidence of E′ with the whole root subspace, correspond-

i.e. A1Akx = λAkx, Akx ∈ E′.

Show now the invariance of E′′. Let {ej}n

j=1 be the Jordan basis of the operator
A1 with E′ being corresponded to the vectors {ej}j2
j=j1. One has to show that for
any j less then j1 or more then j2 the coordinates of Akej with the numbers from j1
to j2 with respect to the assigned basis are equal to zero. Let it be not so and exist
such j′ that ej′ ∈ E′′, but the j1-th coordinate (j1 ≤ j0 ≤ j2) of the vector Akej′ is
a 6= 0. Write it like this:

Akej′ = . . . = aej0.

Let ej′ be an eigenvector of A1 corresponding to the eigenvalue µ 6= λ. Then

(ad A1)Akej′ = A1(. . . + aej0) − µ(. . . + aej0) = . . . + (λ − µ)aej0.

Verify that

(ad A1)mAkej′ = . . . + (λ − µ)maej0.
For m = 0 it is obvious. Let it be satisﬁed for m = r. Then

(ad A1)r+1Akej′ = (ad A1)(ad A1)rAkej′ =

= A1(ad A1)rAkej′ − (ad A1)rAkA1ej′ =
= A1(. . . + (λ − µ)raej0) − µ(ad A1)rAkej′ =
= . . . + (λ − µ)raλej0 − µ(λ − µ)raej0 =
= . . . + (λ − µ)r+1aej0,

i.e. that is true also for m = r + 1, and, hence, for all m ∈ N.

Thus,

(ad A1)mAkej′ = . . . + (λ − µ)maej0 6= 0

for any m ∈ N, which contradicts (21).

Let now ej′ be a root (but not eigen) vector, corresponding to the eigenvalue µ,

with the j0-th coordinate of the vector Akej′−1 equal to 0. Then

(ad A1)Akej′ = A1(. . . + aej0) − Ak(ej′−1 + µej′) = . . . + (λ − µ)aej0.

Analogously

(ad A1)mAkaj′ = . . . + (λ − µ)maej0 6= 0

for any m ∈ N, which contradicts (21).

Since the sequence of basis vectors belonging to the root subspace begins with

the eigenvector, the required statement for complex space is proved.

The transfer onto the case of real space can be done in the same way as in the
proof of theorem 6 (the ball of corresponding norm in the copmlexiﬁed Rn intersects
with Rn). The theorem is proved.

From theorems 6 and 7 follows, in particular, that a ﬁnite (compact) commutative
family consisting of operators dissipative (stable dissipative) in their own norms is
simultaneously dissipative (simultaneously stable dissipative).

2.2 The Mass Action Law and Dissipative Mechanisms

Some constructive conditions of simultaneous dissipativity can be obtained for ﬁnite
families of operators of rank 1. The problem of the absence of Moore eﬀect in the
system constructed in accordance with the Mass Action Law (MAL) is reduced to
the problem on simultaneous dissipativity of such operators.

MAL systems appear from mathematical description of systems of chemical and
biological kinetics and in some other problems. To the considered process is assigned
an algebraic object, called reaction mechanism and having the form:

αr1A1 + . . . + αrnAn → βr1A1 + . . . + βrnAn, (r = 1, . . . , d).

(22)

Speaking in terms of chemical kinetics, the reaction mechanism is a list of stoi-
chiometric equations of elementary reactions (22). In this case A1, . . . , An are the
substances taking part in the reaction; αri, βri are the non-negative integers called
stoichiometric coeﬃcients and showing in what amount the particles of Ai enter into
the r-th elementary reaction as the initial substance (αri) or product (βri). The fol-
lowing notations are accepted: γri = βri − αri, γr is the vector with the components
γri (i = 1, . . . , n) – so-called stoichiometric vector of the r-th elementary reaction.

In accordance with MAL [14,15], to the mechanism (22) corresponds the following

system of ordinary diﬀerential equations:

(23)

where ci(t) is the concentration of substance Ai at the moment of time t ≥ 0,

dci
dt

d

r=1
X

=

γriwr

wr = kr(t)

cαrj
j

n

Yj=1

aiγri = 0

n

Xi=1

n

i=1
X

is the rate of the r-th elementary reaction, continuously depending on time.
In
particular, if reaction proceeds under constant external conditions, then kr(t) =
const (r = 1, . . . , d) and kr is called rate constant of the r-th elementary reaction.
In the latter case (23) represents an autonomous system with polynomial right sides.
r=1. If L 6= Rn, then there exist such

Let L be a linear envelope of the family {γr}d

ai (i = 1, . . . , n), not all equal to sero, that for all r = 1, . . . , d the equalities

are satisﬁed, from which for system (23) follows that

aici(t) = const

(24)

Relationships (24) are called stoichiometric conservation laws. If all ai are posi-
tive, then the corresponding stoichiometric law is called the positive conservation law
[15]. In MAL positive conservation laws takes place rather often (but not always).
As it is known [15], balance polyhedrons are intersections of aﬃne subspaces of
the form (L + c), where c is a constant vector, with a cone of non-negative vectors

to (23) convex sets (one can ﬁnd the proof of their positive invariance in [15]). If
there exists at least one of positive conservation law, they are compact.

The question arises: under what conditions does the norm exist in Rn according
to which the system (23) is constricting in all balance polyhedrons and independent
of rate constants?

Deﬁnition 8. Mechanism (22) is called dissipative, if for system (23) there
exists a norm, constricting in all balance polyhedrons irrespective of rate constants
(in other words, the constricting norm depends on the mechanism only).

We use the notation Mri for the operator in Rn, represented by the matrix, in
the i-th column of which there are components of the vector γr, and on other places
– zeros. The subspace L is invariant with respect to all Mri [15]. The notation M ′
ri
stays for restriction of Mri on L.

Theorem 8. Let for mechanism (22) exist at least one positive conservation
ri : αri > 0} is

low. This mechanism is dissipative if and only if the family {M ′
simultaneously dissipative.

Proof. Suﬃciency. It is known [15] that the Jacobi matrix Jc of system (22) at

the point c, whose coordinates are positive, has the form

Jc =

αri

Mri.

wr
ci

αri>0
X

(25)

Matrices Jc belong to the convex cone produced by the family {Mri| αri > 0}.
Besides, the diﬀerence of any two solutions (23) from one balance polyhedron belongs
to the subspace L. Under the conditions of lemma 3 and theorem 2 obtain the
existence of constricting norm in the subspace L. It can be expanded onto all Rn.
Necessity. Matrices Mri (αri > 0) belong to the closure of the family of matrices
Jc for arbitrary non-negative vectors c and rate constants kr. To prove this, ﬁrst
let consider the case when cj (j = 1, . . . , n) and kr are ﬁxed and all kl(l 6= r) tend
In the limit in (25) only the sum for given r is left. Further on, ﬁx all
to zero.
cj > 0 (j 6= i) and let ci tend to zero, changing kr so that the equality αriwr/ci = 1
holds true. Then all the terms except one tend to zero and in the limit we obtain
Mri.

Thus, the matrices M ′

ri (αri > 0) belong to the closure of the family of restrictions
of the matrices Jc on the subspace L. Hence, according to lemma 3 and theorem 2
the necessity follows. The theorem is proved.

Note that matrices Mri represent matrix-columns (in each matrix there is only
one non-zero column) and that means that the rank of each of them is equal to
unity. We come to the problem of simultaneous dissipativity of the ﬁnite family of
operators of rank 1.

Note that dissipative mechanisms of reactions were studied in details in [12]. In
particular, some classes of dissipative mechanisms are pointed out and all dissipative
3
i=1 βri ≤ 3 (r = 1, . . . , d), c1 +c2+c3 = const
mechanisms for n = 3,
enumerated.

3
i=1 αri ≤ 3,

In the next subsection are obtained necessary and suﬃcient conditions of simul-
taneous dissipativity of the operators of rank 1 in R2 (corresponding to the case
dimL = 2) and some suﬃcient conditions of simultaneous dissipativity of matrix-
columns.

P

P

2.3

Constructive Conditions of Simultaneous Dissipativity of

One-Dimensional Operators

Before consideration of simultaneous dissipativity of operators of rank 1, ﬁnd out
what can be said about dissipativity of one such operator. From necessary and
suﬃcient conditions (see the paragraph after lemma 6) follows that the norm in
which the given operator of rank 1 is dissipative exists if and only if it has a negative
eigenvalue.

Positive semi-trajectories of system (3) corresponding to the initial condition
x(0) = x0 are in this case rectilinear segments parallel to the image of A and
connecting x0 with Ker A. Operator A of rank 1 is dissipative in the given norm if
and only if for any point x (kxk = 1) there exists such ε > 0 that kx + εAxk ≤ 1.
It means that the negative number belongs to the spectrum of A, and the image of
A is orthogonal to its kernel (in the given norm, the subspace E2 is orthogonal to
E1 if kx + yk ≥ kxk for any x ∈ E1, y ∈ E2 [7]).

Let now be given a family {Mk}m

k=1 of operators of rank 1 in Rn. Each of them
can be represented in the form (· ; ψk)ϕk, i.e. Mkx = (x ; ψk)ϕk where (· ; ·) is
the standard scalar product in Rn. The vectors ϕk and ψk are determined by the
operator Mk unambiguously (up to scalar factors). Let λk = (ϕk; ψk), i.e. λk is an
eigenvalue of Mk (either it is the only non-zero eigenvalue, or 0, if the operator Mk
is nilpotent). As it has already been mentioned, for simultaneous dissipativity of
{Mk} the conditions

λk < 0 (k = 1, . . . , m)

(26)

are necessary.

Assign to each operator Mk the projector Pk projecting parallel to the image of
Mk on the kernel of Mk. It is easy to see that Pk = I − Mk/λk. By virtue of the
above-mentioned condition of dissipativity of the operator of rank 1 in the given
norm the operator Mk is dissipative in some norm if and only if Pk is constriction
in this norm.

All Pk can be constrictions in one norm if and only if all products of the form
q
j=1 Pkj (q ∈ N is arbitrary; kj ∈ {1, . . . , m} and they are not necessarily diﬀerent)

are jointly bounded. We come to the following conclusion.
Q

Lemma 7. The family {Mk}m

k=1 of operators of rank 1 is simultaneously dissi-
pative if and only if the conditions (26) are satisﬁed and all products of the form
q
j=1 Pkj (q ∈ N is arbitrary; kj ∈ {1, . . . , m} and they are not necessarily diﬀerent)

are jointly bounded. As a constricting norm one can take
Q

kxk =

sup
q∈N,1≤ kj≤m

{kxk0,

q

j=1
Y

(
(cid:13)
(cid:13)
(cid:13)

},

0

Pkj )x
(cid:13)
(cid:13)
(cid:13)

(27)

where k.k0 is any norm in Rn.

Proof. All statements of the lemma, exept the latter, follow immediatily from
q
j=1 Pkj are jointly bounded, then

the above reasonings. Further on, if all products

(
(cid:13)
(cid:13)
(cid:13)
for each x ∈ Rn. This expression possesses all properties of norm and all operators

sup
q∈N,1≤ kj≤m

{kxk0,

} < ∞

j=1
Y

0

q

Q
Pkj )x
(cid:13)
(cid:13)
(cid:13)

From lemma 7 follows a simple consequence.
Corollary 1. If all ϕk are collinear (images of Mk coincide) or all ψk are collinear
(kernels of Mk coincide) and (ϕk; ψk) < 0 for all k = 1, . . . , m, then the operators
Mk (k = 1, . . . , m) are simultaneously dissipative. As corresponding constricting
norm one can take

To demonstrate this, it is suﬃcient to note that in these cases

sup
q∈N,1≤kj≤m

{kxk0, kPkxk0}.

or

respectively.

q

q

Yj=1

j=1
Y

Pkj = Pk1

Pkj = Pkq,

Remark 10. If not all ϕk are collinear, then as a norm in lemma 7 one can take

sup
q∈N,1≤kj≤m

q

(
(cid:13)
(cid:13)
(cid:13)

.

Pkj )x
0
(cid:13)
(cid:13)
(cid:13)

j=1
Y
The criterion established in lemma 7 is not constructive. Constructive criteria
of simultaneous dissipativity of ﬁnite family of operators of rank 1 in Rn have been
obtained only at n = 2 (for arbitrary n there exist suﬃcient conditions for one class
of operators; they are given at the end of the section). Pass to the consideration of
the case n = 2.

Consider the family {Mk}m

k=1 of the operators of rank 1 in R2. As before, represent

each operator Mk in the form (· ; ψk)ϕk. Let ﬁrst m = 2.

Lemma 8. The operators M1 = (· ; ψ1)ϕ1 and M2 = (· ; ψ2)ϕ2 are simultaneously

dissipative in R2 if and only if the condition

(28)

(29)

is satisﬁed together with the conditions

(ϕ1; ψ2) · (ϕ2; ψ1)
(ϕ1; ψ1) · (ϕ2; ψ2) (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ 1

(ϕ1; ψ1) < 0; (ϕ2; ψ2) < 0.

As a corresponding constricting norm one can take

kxk = max{kxk0, kP1xk0, kP2xk0, kP1P2xk0, kP2P1xk0}.

(30)

Proof. In R2 the projectors P1 and P2 have rank 1 and are represented in the

form

P1 = (· ; η1)χ1; P2 = (· ; η2)χ2,

where η1, η2, χ1, χ2 are some vectors in R2.
q
j=1 Pkj are bounded when the spectrum of the operator (P1P2)

The operators

lies on the segment [−1; 1]:

Q

In a standard orthonormalized basis Pk acts like this:

Pkx =

1
(ϕk; ψk)

·

;

x(1)
x(2) 














ϕ(2)
k
−ϕ(1)
k

·













ψ(2)
k
−ψ(1)
k





where

denotes the vector with the coordinates a(1) and a(2). Hence

a(1)
a(2) 






(η1; χ2) =

(χ1; η2) =

(ϕ1; ψ2)
(ϕ2; ψ2)

;

(ϕ2; ψ1)
(ϕ1; ψ1)

,

i.e. condition (31) takes the form (29).

To complete the proof, use lemma 7. To check a possibility of choosing corre-

sponding norm in the form (30), note that

(P1P2)rP1 = (η1; χ2)r · (η2; χ1)r · P1;

(P2P1)rP2 = (η1; χ2)r · (η2; χ1)r · P2

for any r ∈ N.
oneself to ﬁnite number of products. The lemma is proved.

It means that with the account of (31), in (27) one can restrict

Remark 11. If ϕ1 and ϕ2 are non-collinear, then as required norm we can take

max{kP1xk0, kP2xk0, kP1P2xk0, kP2P1xk0}.

This follows from remark 10. Then the ball of the norm is determined by the

inequalities

|(x; η1)| ≤ min

|(x; η2)| ≤ min

1
kχ1k0

(

1
|(χ1; η2)| · kχ2k0 )

;

1
kχ2k0

(

1
|(χ2; η1)| · kχ1k0 )

,

,

,

i.e. it is parallelogram.

Also note that for simultaneous dissipativity of a family the dissipativity of each
operator from convex envelope of the family is insuﬃcient. To see this, consider the
operators represented by the matrices

M1 =

; M2 =

−1 1





0 0 


0

0

.





−2 −1 


Each of them is dissipative in its norm. It is easy to show that spectrum of any
non-trivial convex combination of M1 and M2 lies in open left half-plane. Neverthe-
less

(ϕ1; ψ2) · (ϕ2; ψ1)
(ϕ ; ψ ) · (ϕ ; ψ )

= −2,

(32)

(33)

(34)

(35)

Reasoning like in proof of lemma 8, it is easy to obtain a criterion of a simulta-

neous dissipativity for arbitrary m. The result is a set of conditions of the form

(ϕk; ψk) < 0 (k = 1, . . . , m);

(ϕk1; ψk2) · (ϕk2; ψk3) · . . . · (ϕkq; ψk1)
(ϕk1; ψk1) · (ϕk2; ψk2) · . . . · (ϕkq; ψkq) (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ 1,

where {kj}q
j=1 is a set of diﬀerent numbers from 1 to m, and inequalities (33) holds
for all such sets. The number of conditions has the order O((m − 1)!) and for any
large m testing of these conditions becomes unrealizable. It turns out, however, that
among inequalities (33) there are dependent ones and the number of conditions can
be reduced.

Theorem 9. Let the vectors ψk (k = 1, . . . , m) lie in one half-plane clockwise.
Then the family of operators {Mk}m
k=1 where Mk = (·; ψk)ϕk is simultaneously dis-
sipative if and only if the vectors ϕk (k = 1, . . . , m) lie in one half-plane clockwise
and the conditions (32) and the followings ((34), (35)) are satisﬁed:

(ϕk; ψk+1) · (ϕk+1; ψk)
(ϕk; ψk) · (ϕk+1; ψk+1) (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ 1

(k = 1, . . . , m with ϕm+1 = −ϕ1; ψm+1 = −ψ1);

(ϕ1; ψ2) · (ϕ2; ψ3) · . . . · (ϕm; ψ1)
(ϕ1; ψ1) · (ϕ2; ψ2) · . . . · (ϕm; ψm) (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(ϕ1; ψm) · (ϕm; ψm−1) · . . . · (ϕ2; ψ1)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(ϕ1; ψ1) · (ϕ2; ψ2) · . . . · (ϕm; ψm) (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)






≤ 1;

≤ 1.

The corresponding norm can be chosen polyhedral (a norm, whose ball is polygon).
Proof. Necessity. Let lk be the kernels of the operators Mk (i.e. straight lines
orthogonal to ψk). Straight lines lk divide the plane into 2m sectors.
If among
the vectors ψk there are collinear, then some sectors are singular, but this does not
change the further reasonings. In each sector G and for each p ∈ {1, . . . , m}

sign(x1; ψp) = sign(x2; ψp)

for all x1 ∈ int G, x2 ∈ int G.

Let Gr be a sector lying between corresponding rays of straight lines lr and lr+1
It is enough to consider the sectors {Gk}m
(where lm+1 = l1).
k=1 into which one
half-plane is divided, since for sectors lying in vertical angles to Gk the reasons are
the same.

Note that by inequality (32) for each operator Mk the projector Pk is determined,
which operates in each sector Gk as a projector in the direction υkr = sign(x; ψk) ·
ϕk (x ∈ Gr) onto the straight line lk.

A norm with respect to which all Mk are dissipative exists if and only if there
exist a convex body Q symmetrical with respect to 0 and positively invariant with
respect to all systems of the following form

dx
dt

m

Xk=1

=

hk(t)(x; ψk)ϕk,

(36)

where hk(t) is any function piecewise continuous and non-negative for t ≥ 0. The
suﬃciency is evident (suppose hk(t) ≡ 1, hj(t) ≡ 0 for j 6= k and come to dissipa-
tivity of Mk with respect to Q). To prove the necessity, it is suﬃcient to make an
estimation analogous to that made in the proof of theorem 1:

d
dt

kx(t)kQ = NQ

x(t),

hk(t)Mkx(t)

≤

(cid:16)

(cid:17)

≤ γQ

hk(t)Mkx(t)

· kx(t)kQ ≤ 0.

m

Xk=1

(cid:17)

m

(cid:16)

Xk=1

Here k.kQ is a norm whose unit ball is Q.

Since (x; ψk)ϕk = |(x; ψk)| · υkr at x ∈ Gr, then (36) can be rewritten as follows:

m

=

yk(t)υkr

dx
dt

(37)

Xk=1
where yk(t) is piecewise continuous and non-negative for t ≥ 0. Thus, it is suﬃcient
to construct such a polygon W that from each point of its boundary ∂W all the
vectors υkr are not directed into the exterior of W . Then one can take

Q = co {W ∪ (−W )}.

Let (37) have at least one unbounded solution, whose positive semi-trajectory
lies inside one of sectors. Then (36) has an unbounded solution, i.e. the operators
Mk are not simultaneously dissipative.

The notation C{υkr} is used for a convex cone produced by {υkr}m
Let this cone concide with R2 at least in one sector Gr (i.e. the vectors generating
it do not lie in one half-plane). Then as yk(t) one can choose such constants that
m
k=1 ykυkr ∈ Gr, and then, drawing a ray from the point x0 ∈ intGr in the
υ =
direction of υ, obtain a positive semi-trajectory of unbounded solution (47) lying
P
inside Gr.

r=1.

Thus, for simultaneous dissipativity of {Mk} it is necessary to satisfy the condi-

tions

C{υkr} 6= R2 (k = 1, . . . , m).

(38)

If C{υkr} in some sector is a half-plane, then it must contain the vertical angle to
Gr - ˆGr (and thus intersect with Gr only at zero); otherwise (37) has an unbounded
solution. For each sector Gr consider the boundary of the cone C{υkr}. It consists
of two directions. Show that for Gj it is υjj, υ(j+1),j. It is suﬃcient to show that for
j = 1.

Let υ1,1 and υ2,1 be collinear and oppositely directed. Then to satisfy (38) it is
necessary tha the other υk1 lie on one side of the straight line, stretched on υ1,1. But
if υ1,1 and υ2,1 are non-collinear, then all other υk1 can be expanded in terms of the
basis υ1,1, υ2,1.

Let, for example, υ3,1 = c1υ1,1 + c2υ2,1, and υ3,1 be collinear to one of the basis
vectors (for example, υ1,1; the case with υ2,1 is considered analogously). Then c2 = 0.
If c1 > 0 then υ3,1 ∈ C{υ1,1, υ2,1}. Let c1 < 0. Then to satisfy (38) in G1 it is
necessary for υ1,1 and υ3,1 to be boundary directions in C{υk1}. Since υk,(l+1) = υkl,
if k 6= l + 1, and υ
, then the same directions are boundary

= −υ

C{υk1}, υ2,2 = −υ2,1 ∈ C{υk2}. It means C{υk1} and {υk2} represent half-plane
whose join is all R2, what is impossible. That means c1 > 0.

Let now υ3,1 be non-collinear neither to υ1,1 nor to υ2,1. If c1 < 0, c2 < 0, then in
G1 (38) is not satisﬁed. If c1 < 0, c2 > 0, then in G2 there υ3,2 = c1υ1,2 + (−c2)υ2,2,
i.e again (38) is not satisﬁed. Analogous reasonings hold for the case c1 > 0, c2 < 0,
i.e. the only possible case is c1 ≥ 0, c2 ≥ 0 and therefore υ3,1 ∈ C{υ1,1, υ2,1} (where
C{x, y} is a convex cone, stretched on the vectors x and y).
The case is left when the directions υ1,1 and υ2,1 coincide.
Without loss of generality one can assume non-collinearity of υ3,1 and υ1,1. Then
υ2,2 and υ3,2 are boundary directions in C{υk2}. Consequently, υ1,1 ∈ C{−υ1,1, υ3,1}
i.e. the directions υ3,1 and υ1,1 coincide contrarily to the assumption. It means that
if υrr and υ(r+1),r are co-directed, all υkr are collinear, i.e. all ϕk are collinear. In
this case the directions υrr and υ(r+1),r are also boundary.
We call the obtained fact the boundariness condition.
Since all ψk lie clockwise in one half-plane, then it is easy to check that in sector
Gm either all (x; ψk) ≥ 0 for all k or (x; ψk) ≤ 0 for all k. Thus, by virtue of
(32), all ϕk lie in one half-plane. From the boundariness condition follows that
ϕk ∈ C{ϕk−1, ϕk+1}, i.e vectors ϕk are arranged either clockwise, or anti-clockwise.
Let, for example, υ1,1 = ϕ1 (the case υ1,1 = −ϕ1 is considered analogously).
Then υ2,1 = ϕ2 lies in the half-plane bounded by the straight line stretched on υ1
and containing ˆS1. Therefore the direction from ϕ1 to ϕ2 in the half-plane containing
all ϕk is the same as from ψ1 to ψ2, i.e. clockwise.

The necessity of the other conditions is obvious, since (34)-(35) is simply a part

of conditions (33).

Suﬃciency. Let the family {ϕk}m

k=1 be arranged clockwise in one half-plane and
the conditions (32) and (34)-(35) be satisﬁed. Assume that among ϕk there are
non-collinear vectors, and among ψk there are no collinear ones.

The condition of clockwise arrangement of ϕk in one half-plane means that
the angle (counted from ϕ1 clockwise) between ϕ1 and the vectors ϕ1, ϕ2, . . . , ϕm,
ϕm+1 = −ϕ1 monotonously increases from 0 to π. Taking into account that the an-
gle between ϕk1 and (−ϕk2) is the angle between ϕk1 and ϕk2, taken with opposite
sign, it is easy to conclude that systems {υkr} (in each sector) lie in one half-plane
and are arranged clockwise (to avoid exiting from corresponding half-plane we start
counting in sector Gr from υ(r+1),r).

From conditions (34) follows that in each sector there is a ”convex conﬁguration”,

i.e. there is vector x ∈ Gr, representable in the form

x = −

ckυkr,

m

Xk=1

where all ck > 0.

It means that if from one point ˜x ∈ int Gr one draws segments ¯a and ¯b in the
directions of υrr and υ(r+1),r up to the crossing with lr and lr+1, respectively, then
these segments together with the segments connecting 0 with the point of crossing
¯a with lr and ¯b with lr+1, respectively, form a convex polygon (if υrr and υ(r+1),r are
oppositely directed, it will be a triangle, and if they are non-collinear – a quadrangle;
as we have seen before they cannot be co-directed).

Due to the same orientation of {ϕk} and {ψk} all the other υkr are directed (from

Fix now the point x0 ∈ l1 (x0 6= 0) on the boundary ray of sector G1 (actually,
one can begin from any straight line lk; we begin from l1). Due to the boundariness
condition either direction from x0 on l2 goes into sector G1, or direction from x0 on
lm goes into ˆGm.

If one and only one of these statements is true, continue moving in the correspond-
ing direction (to the neighboring straight line) till the direction on the neighboring
straight line goes into the neighboring sector. In other words, move from lr to lr+1
in the direction parallel to ϕr, if this direction goes into sector Gr (or, into ˆGr−1,
respectively). As a polygon W mentioned after (37) one should take a polygon
formed by the segments which we moved along, and the segments of those straight
lines on which the movement broke (if exit on the initial ray did not occur, in our
case it is a part of l1 corresponding to G1, then it is a segment connecting x0 with
0, and a segment of that straight line on which the movement broke, connecting the
point of breaking with zero; if exit on the initial ray occured, then it is a segment
connecting x0 with the point of exit).

If both statements are satisﬁed, then as W one can take a join of two such

polygons formed in moving to both sides from x0.

This algorithm is easy to check proceeding from boundariness conditions, ”convex
conﬁguration”, and (35) (the latter condition means that if exit on the initial ray
occured in moving in either side, then the point of exit is no farther from the
beginning of coordinates than the initial point; in particular, if the point of exit
coincides with the initial point, then the formed polygon can be taken as W ). The
ball of the sought for norm is a polygon.

If some of ψk are collinear, then some sectors Gk are singular. This, however,
does not change the results. The reasonings are analogous to the case when among
ψk there are no collinear vectors. The only diﬀerence here is the following: some
straight lines lk correspond to several directions {ϕj}k1
j=k0. Then in constructing W
one needs to move along ϕk0.

In the case when all ϕk (or all ψk) are collinear (see corollary 1), all the same one

can regard that {ϕk} and {ψk} have the same orientation, starting from (32).

Conditions (34)-(35) are satisﬁed in this case. The norm can be chosen polyhe-

dral, if one chooses a polyhedral norm as k.k0 in (30). The theorem is proved.

Remark 12. One can obtain the arrangement of vectors ψk required by the
conditions of theorem 9 by renumbering vectors and (if it is necesary) changing
signs of some of them.

Thus, the problem of simultaneous dissipativity of a family of operators of rank 1
in R2 is solved completely. The number of conditions to be checked now, in contrast
to (33), is only of the order O(m).

With theorem 9 one can study the MAL mechanism on dissipativity (and, re-

spectively, on the absence of IME). For example, let the mechanism be

A1 → A2, A1 → A3, A2 → A1, A2 → A3,

3A2 → A1 + 2A3, 2A1 → A2 + A3, 2A2 → A1 + A3,
2A3 → A1 + A2, 3A1 → A2 + 2A3, 3A2 → 2A1 + A3,
A1 + A2 → 2A3.

(39)
This mechanism possesses positive conservation law c1 + c2 + c3 = const. The

corresponding subspace is the plane

Obviously, dimL = 2, and one can use theorem 9. Writing matrices M ′
ri and using
theorem 9, let make sure that mechanism (39) is dissipative. The corresponding
norm in the subspace L has the form

kck = |c1| + |c2|.

It can be expanded onto all R3, for example, in this way:

kck = |c1| + |c2| + |c1 + c2 + c3|.

To complete the section, consider the question of simultaneous dissipativity of the
ﬁnite family of operators of rank 1 of special form in Rn for arbitrary n. Namely, we
consider operators represented by matrix-columns. Let obtain suﬃcient conditions
of simultaneous dissipativity of such operators.

Let the basis {ek}n

k=1 and the norm

n

kxk =

pk|xk|

(40)

Xk=1
be given in Rn, where pk > 0 (k = 1, . . . , n), xk is the k-th coordinate of vector x in
the basis {ek}. Norm (40) coincides with l1 norm with recpect to the basis {ek/pk}.
Therefore, the necessary and suﬃcient dissipativity conditions of the operator A
represented by the matrix (aij)n

i,j=1 according to remark 9 have the form

piaii +

pj|aji| ≤ 0 (i = 1, . . . , n).

(41)

Xj6=i

Let now there be a family of operators, represented by the matrix-columns Aklk
lk = 0, . . . , rk), where Aklk is the lk-th matrix with non-zero k-th

(k = 1, . . . , n;
column:

Aklk =

(42)

0 . . . 0 a(lk)
1k

0 . . . 0

0 . . . 0 a(lk)
2k

0 . . . 0

. . .

. . .

. . .

0 . . . 0 a(lk)
nk

0 . . . 0















.















Coming from (41), write dissipativity conditions of all operators in norm (40)

with some constants pk:

pka(lk)

kk +

pj|a(lk)

jk | ≤ 0 (k = 1, . . . , n; lk = 0, . . . , rk).

(43)

Xj6=k

inequalities

Theorem 10.

If the system of linear inequalities (43) complemented by the

pk > 0 (k = 1, . . . , n)

(44)

has a solution, then the family of operators represented by matrices (42) is simulta-
neously dissipative.

Proof. Solvability of the systems (43)-(44) means the existence of positive con-
stants pk (k = 1, . . . , n) for which inequalities (43) are satisﬁed, and that is dissipa-

Thus, for simultaneous dissipativity of ﬁnite family of operators represented by
matrices-columns the solvability of above written ﬁnite system of linear inequali-
ties proves to be suﬃcient. To check solvability, one can use algorithms of linear
programming [16].

Remark 13. The solution of the system (43)-(44) exists if there exists solution
of the system of (n − d) linear inequalities complemented by inequalities (44) (where
d is the number of those k for which rk = 0; evidently 0 ≤ d ≤ n − 1). To prove
this, assume

akk = max
0≤lk≤rk

a(lk)
kk ; ajk = max
0≤lk≤rk

|a(lk)

jk | (j 6= k)

(k = 1, . . . , n).

Consider the system

pkakk +

pjajk ≤ 0 (k = 1, . . . , n).

(45)

Xj6=k

Obviously, if the set {pk} satisﬁes the system (44)-(45), then it satisﬁes the system
(43)-(44) as well. Numbers k for which rk = 0 are excluded. Therefore, in system
(45) there are (n − d) inequalities.

Remark 14. For n = 2 theorem 10 provides necessary and suﬃcient conditions
of simultaneous dissipativity. To demonstrate that, note that for operator Mk of the
considered form the vector ψk (see the notation at the beginning of the subsection)
is directed along one of the coordinate axes. Therefore (see the proof of suﬃciency
in theorem 9), if the family is simultaneously dissipative, then one can choose paral-
lelogram as a ball of the corresponding norm, with vertices on coordinate axes, i.e.
the norm is of the form (40). In the case of arbitrary n the conditions of theorem
10 are already not necessary. To see this, let

−1 0 0

−1 0 0

1 0 0

A1 = 






0 −1 0









; A2 = 






0 −1 0

.

0

1 0









The system of linear inequalities

has no positive solutions. Nevertheless, simultaneous dissipativity exists, since each
of the operators is dissipative in its norm and ϕ1 = ϕ2 (see corollary 1).

−p1 + p2 + p3 ≤ 0;

p1 − p2 + p3 ≤ 0






Conclusion

Let us resume. The inﬁnitesimal Moore eﬀect (IME) in the interval space for
smooth autonomous system on positively invariant convex compact is studied. The
local conditions of absence of IME in terms of Jacobi matrices ﬁeld of the system are

of the Jacobi matrices is established, and some suﬃcient conditions of simultaneous
dissipativity are obtained.

On the basis of the conducted analysis the reason of weak eﬃciency of interval
stepwise methods is pointed out. The main reason is that to solve the problem of
absence of IME in the system and to construct corresponding interval space one
needs analysis of simultaneous dissipativity of Jacobi matrices of system and con-
structing a constricting norm. The latter questions are rarely solved constructively.
Besides, in suﬃciently rich interval spaces (for example, in using standard intervals
– rectangular parallelepipeds) IME is almost always present. One should, however,
remember that the notion of the Moore eﬀect in the work is treated suﬃciently
strongly. The ﬁnal conclusion on the eﬃciency of stepwise interval methods can be
drawn only after studying asymptotic Moore eﬀect (AME). It should also be noted
that there may be deﬁnitions of interval spaces, diﬀerent from deﬁnition 1.

Some particular classes of systems without IME and corresponding interval spaces
are pointed out. These results can be used in solving by interval methods particular
systems from the pointed out classes.

References

1. Moore R.E. Interval analysis.– N.-Y.: Prentice-Hall, 1966.
2. Kalmykov S.A., Shokin Yu.I., Yuldashev Z.Kh. Methods of interval analysis.–

Novosibirsk: Nauka, 1986.– 221 p.

3. Chernousko F.L. Optimal guaranteed estimations of uncertainty by means of

ellipsoides // Izv. AN SSSR.– Tekhnich. kibernetika.– 1980.– N 5.– P.5–10.

4. Kracht M., Schoeder G. Zur Intervallrechnung in linear Raumen.– Computing.–

1973.– V.11.– P.73–79.

5. Ratschek H. Nichtnumerische Aspecte der Intervallarithmetik // Interval Ma-

thematics.– Berlin-Heidelberg: Springer-Verl., 1975.– P.48–74.

6. Kuratovskii K. Topology. V.1.–Moscow: Mir, 1966.– 594 p.
7. Belitskii G.R., Lyubich Yu.I. Matrix norms and their applications.– Kiev:

Naukova dumka, 1984.– 151 p.

706 p.

8. Kantorovich L.V., Akilov G.P. Functional analysis.– Moscow: Nauka, 1977.–

9. Lozinsky S.M. Error estimation of numerical integration of ordinary diﬀerential

equations // Izv. vuzov. Ser. mat.– 1958.– N.5.– P.52–90.

10. Bylov B.F., Vinograd P.A., Grobman D.M., Nemytskii V.V. Lyapunov index
theory and its applications to the problems of stability.– Moscow: Nauka, 1966.–
576 p.

11. Verbitskii V.I., Gorban A.N. Simultaneously dissipative operators and their
applications in dynamical systems.– Krasnoyarsk, 1987.– 32 p. (Preprint /AS USSR,
SB, Computing Center).

12. Verbitskii V.I., Gorban A.N. Thermodynamical restrictions and quasi-termo-
dynamicity conditions in chemical kinetics // Mathematical problems of chemical
kinetics / Ed. by K.I.Zamaraev and G.S.Yablonskii.– Novosibirsk: Nauka, 1989.–
P.42–83.

13. Burbaki N. Lie groups and algebras.– Moscow: Mir, 1976.– 496 p.
14. Volpert A.I., Khudyaev S.I. Analysis in the classes of discontinuous functions

and equations of mathematical physics.– Moscow: Nauka, 1975.– 394 p.

15. Gorban A.N., Bykov V.I., Yablonskii G.S. Essays on chemical relaxation.–

Novosibirsk: Nauka, 1986.– 300 p.

cow: Sov.radio, 1966.– 524 p.

16. Golshtein Ye.G., Yudin D.B. New tendencies in linear programming .– Mos-

17. Verbitskii V.I., Gorban A.N., Utjubaev G.Sh., Shokin Yu.I. Moore eﬀect in

interval spaces // Dokl. AN SSSR.– 1989. V. 304, N 1.– P.17–21.

18. Bykov V.I., Verbitskii V.I., Gorban A.N. On one estimation of solution of
Cauchy problem with uncertainty in initial data and rigt part // Izv. vuzov, Ser.
mat.– 1991. N. 12.– P.5–8.

19. Verbitskii V.I., Gorban A.N. Simultaneously dissipative operators and their

applications // Sib. mat. jurnal.– 1992. V.33, N 1.– P.26–31.

20. Verbitskii V.I., Gorban A.N. Simultaneously dissipative operators and quasi–
thermodynamicity of the chemical reactions systems // Advances in Modelling and
Simulation, Tassin (France): AMSE Press. 1991.– V.26, N 1.– P.13–21.

21. Verbitskii V.I., Gorban A.N. On one approach to the analysis of stability of
nonlinear systems and diﬀerential inclusions // Advances in Modelling and Analysis,
A. Tassin (France): AMSE Press.– V.19, N 4, 1994.– P.15–27

22. Verbitskii V.I., Gorban A.N. Stability analysis and solution evaluation for
nonlinear systems by ”Jacobian ﬁelds” and Liapunov norms // AMSE Transactions,
Scientiﬁc Siberian, A, V. 4. Dynamics. Tassin (France): AMSE Press. 1992.– P.104–
133.

