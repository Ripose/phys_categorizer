Gaussian limits for discrepancies.
I: Asymptotic results

Andr´e van Hameren∗ and Ronald Kleiss†
University of Nijmegen, Nijmegen, the Netherlands

Jiri Hoogland‡
CWI, Amsterdam, the Netherlands

July 22, 2013

Abstract

We consider the problem of ﬁnding, for a given quadratic measure of non-unifor-
mity of a set of N points (such as L2 star-discrepancy or diaphony), the asymptotic
distribution of this discrepancy for truly random points in the limit N
. We
then examine the circumstances under which this distribution approaches a normal
distribution. For large classes of non-uniformity measures, a Law of Many Modes in
the spirit of the Central Limit Theorem can be derived.

→ ∞

7
9
9
1
 
g
u
A
 
3
1
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
4
1
0
8
0
7
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

∗andrevh@sci.kun.nl
†kleiss@sci.kun.nl
‡jiri@cwi.nl

Contents

1 Introduction

2 General deﬁnitions and statements

2.1 Quadratic discrepancy and complexity . . . . . . . . . . . . . . . . . . . .
2.2 Gaussian measures on a countable basis . . . . . . . . . . . . . . . . . . . .
2.3 General form of discrepancy distributions . . . . . . . . . . . . . . . . . . .
2.4 Standardized variables and the Gaussian limit . . . . . . . . . . . . . . . .
2.5 A Law of Many Modes . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 Applications to diﬀerent examples

. . . . . . . . . . . . . . . . . . . . .
3.1 Fastest approach to a Gaussian limit
3.2 L2 star-discrepancy and the Wiener measure . . . . . . . . . . . . . . . . .
3.3 Diaphony . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.1 General deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.2 Fourier diaphony . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.3 Fourier diaphony with product clustering
. . . . . . . . . . . . . .
3.3.4 Fourier diaphony with sum clustering . . . . . . . . . . . . . . . . .
3.3.5 Fourier diaphony with spherical clustering . . . . . . . . . . . . . .
3.3.6 Walsh diaphony . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4 Lego discrepancy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Appendix C: Spectral representation of the L2 star-discrepancy

4 Conclusions

Appendix A: The form of G0(z)

Appendix B: A counterexample

Appendix D: The magnitude of Q

F (p)

Q

References

1 Introduction

1

3
3
4
5
6
7

9
9
10
12
12
12
13
14
15
16
18

19

20

21

21

23

24

In the ﬁeld of numerical integration, there are two aspects of the general problem which
bear on the accuracy of the numerical result. The ﬁrst is of course the behaviour of the
integrand: typically, wildly ﬂuctuating functions are integrated with less accuracy than
relatively smooth ones, for the same number of integration points. The second one is
the distribution of the set of points at which one evaluates the integrand.
It stands to
reason that, if one has no a-priori knowledge of the integrand, a set of points that is
fairly uniformly distributed may be expected to do better than one in which many points

1

cluster together. It is therefore useful to quantify and study the notion of ‘uniformity of
point sets’, and this has been the topic of a great number of publications [1, 2]. The most
important of such notions are those of the star-discrepancy and L2 star-discrepancy, and
more recently other measures of non-uniformity that go under the name of diaphony have
been introduced as well [3]. In this paper, we shall call all such measures ‘discrepancies’.
As has been shown in Ref. [4, 5], the use of a particular discrepancy in assessing the
uniformity of a given point set implies that one has some notion of the generic behaviour of
the integrand: it is tacitly assumed that the integrands to be attacked belong to some class
of functions. The particular discrepancy is then recognized as the average-case complexity
of the integration problem over that function class [6, 7].

While the Monte Carlo method, in which the integration points are chosen at random,
has long been recognized as a robust and useful way of evaluating multivariate integrals,
its relatively slow convergence has inspired a search for other point sets whose discrepancy
is lower than that expected for truly random points. Such low-discrepancy point sets
and low-discrepancy sequences have developed into a veritable industry, and sequences
with (asymptotically, for large N) very low discrepancy are now available, especially for
problems with very many variables [8]. For point sets that are extracted as the ﬁrst
N elements of such a sequence, though, one is usually still compelled to compute the
discrepancy numerically, and compare it to the expectation for random points in order to
show that the point set is indeed ‘better than random’. This implies, however, that one has
to know, for a given discrepancy, its expectation value for truly random points, or preferably
even its probability density. In Refs. [9, 10, 11, 12] we have solved this problem for large
classes of discrepancies. Although computable, the resulting distributions are typically not
very illuminating. The exception is usually the case where the number of dimensions of the
integration problem becomes very large, in which case a normal distribution often arises
[5, 13]. In this paper, we investigate this phenomenon in more detail, and we shall describe
the conditions under which this ‘law of large dimensions’ applies.

The layout of this paper is as follows. In section 2, we deﬁne the general structure of a
discrepancy related to a class of integrands of which it is an average-case complexity. We
show how to derive the probability density of this discrepancy when viewed as a stochastic
variable deﬁned on sets of truly random points. Then, we investigate the conditions under
which this density approaches a normal density. Finally, in section 3 we apply our results
to a few toy-models and standard choices of discrepancy. A number of technical points are
collected in the various Appendices. Throughout this discussion, we shall only consider
the asymptotic limit of a very large number of integration points. This implies that, in
this paper, we cannot make any statements on how the number of points has to approach
inﬁnity with respect to the number of dimensions, as was for instance done in Ref. [13].
In Ref. [15], we repair this defect, and shall be able to show which precise combination of
limits has to be taken.

2

2 General deﬁnitions and statements

To set the stage, we shall always consider the integration region to be the s-dimensional unit
hypercube K = [0, 1)s. The point set XN consists of N points xµ
k , where k = 1, 2, . . . , N
labels the points and µ = 1, 2, . . . , s their co-ordinates.

2.1 Quadratic discrepancy and complexity

We will deﬁne quadratic discrepancies as the average-case complexity of an integration
problem in terms of its averaged squared integration error[6]. For the given class of real-
valued functions f (x), with x
K, let a measure dµ(f ) on the class of functions be given,
such that the one- and two-point connected Green’s functions are given by

∈

f (x) dµ(f ) = 0 ,

Z

Z

ZL

f (x1)f (x2) dµ(f ) =

h(y; x1)h(y; x2) dµ(y) .

(1)

Here we assume, that we can deﬁne a function h(y, x) and a measure dµ(y) over some
space L such that the above expression makes sense. The variable y has to be suitably
deﬁned; it may be a continuous variable with a continuous integration measure dµ(y), or a
dµ(y) reduces to a sum over an enumerable set of discrete
discrete variable, in which case
values, such as a lattice: all cases we will consider in this article can be expressed in terms
of an enumerable set of discrete values. For the moment we will stick to the more general
notation of dµ(y). we deﬁne the quadratic discrepancy1 DN as follows [4]:

R

Z
1
N

N

Xk=1

1
N

N

Xk,l=1

ZL

DN
N

=

η2 [f ] dµ(f ) ,

η [f ] =

f (xk)

f (x) dx .

−

ZK

(2)

(3)

In Ref. [4] it was shown that, if the function measure dµ(f ) is Gaussian in the sense
that the only non-vanishing connected Green’s function is the two-point function, then the
integration error will be normally distributed with zero mean and variance equal to DN /N.
The discrepancy DN can be written as

DN =

β(xk, xl) ,

β(xk, xl) =

ω(y; xk)ω(y; xl) dµ(y)

, ω(y; xk) = h(y; xk)

h(y; x) dx .

(4)

−

ZK

1Note that we have taken a factor N out of the deﬁnition of the discrepancy compared to other
deﬁnitions in the literature. This has the advantage that the discrepancy averaged over the ensemble of
truly random point sets is independent of N .

3

In fact, DN measures how well the function h(y;
) is integrated by the point set XN ,
averaged over y. Notice that DN is nonnegative by construction, and that for an inﬁnite
DN /N = 0. Moreover, the expected value of DN for a
equidistributed sequence, limN
set of N truly random points in K is given by

→∞

·

E [DN ] =

V [f ] dµ(f ) =

ω(y; x)2 dx dµ(y) ,

Z

ZL ZK

where E [
] denotes the expectation value w.r.t. the uniform distribution over the ensemble
·
of truly random point sets with N points, and V [f ] is the variance of the function f (
). We
shall always assume this expectation value to be a ﬁnite quantity, otherwise this discrepancy
cannot meaningfully be used for truly random points.

·

In our approach to the calculation of discrepancy distributions, we will also use the
N ] (m = 1, 2, 3, . . . ), which therefore have to be assumed to be ﬁnite2.

higher momenta E [Dm
We will also deﬁne some useful functions βk and Γk:

βk(x1, x2) =

β(x1, x)βk

1(x, x2) dx ,

Γ(y1, y2) =

ω(y1; x)ω(y2; x) dx ,

ZK

ZK

ZL

−

−

Γk(y1, y2) =

Γ(y1, y)Γk

1(y, y2) dµ(y) ,

with β1 = β and Γ1 = Γ. The function Γ is in a certain sense dual to the function β. It
will be more convenient to use, because the variable y is often an element of a countable
set and Γ can then be viewed as a matrix, with Γk(y1, y2) = Γ(y1, y2)k.

2.2 Gaussian measures on a countable basis

In this paper, we shall consider function classes with functions f that can be written as
linear combinations of a countable set of basis functions

:

un}

{

Often we will refer to the basis functions as modes. We assume that integrals over combi-
nations un1(x)un2(x)

exist and introduce the parameters

f (x) =

vnun(x) .

n
X

ZK

· · ·

wn =

un(x) dx and am,n =

um(x)un(x) dx .

The variance of f can then be written as

V [f ] =

f (x)2 dx

f (x) dx

=

ZK

−

(cid:18)ZK

m,n
X

2For the discrepancies we discuss, this is a valid assumption.

vmvn (am,n −

wmwn) .

ZK

2

(cid:19)

4

(5)

(6)

(7)

(8)

(9)

(10)

(11)

A Gaussian measure on the class of functions is obtained by taking

dµ(f ) =

exp(

−

v2
n/2σ2
n)
2πσ2
n

dvn .

n
Y

Z

p

For the measure to be suitably deﬁned, the strengths σn have to satisfy certain restrictions.
In particular we want the functions f to be quadratically integrable on the average. The
reasonable requirement that E [DN ] must exist ensures that the variance of the functions
f exists on the average and thus imposes a condition on the strengths:

E [DN ] =

V [f ] dµ(f ) =

σ2
nV [un]

.

n
X

Now we can use the formalism of the previous section to construct the discrepancy. The
two-point connected Green’s function is given by

f (x1)f (x2) dµ(f ) =

σ2
nun(x1)un(x2) ,

Z

n
X

which is nothing but a spectral representation. The functions h and ω can be taken equal
to

hn(x) = σnun(x)

, ωn(x) = σn(un(x)

wn) ,

−

where the variable y is replaced by the countable index n. The function β and the matrix
Γ are given by

β(x1, x2) =

σ2
n(un(x1)

−

wn)(un(x2)

wn) ,

−

n
X

Γm,n = σmσn(am,n −

wmwn) .

Note that we have for the trace of Γm,n:

Tr (Γ) =

σ2
nV [un] = E [DN ]

.

n
X

2.3 General form of discrepancy distributions

We now turn to the problem of computing the probability density of such a discrepancy
when the N points are (independently and uniformly) randomly distributed over K. In-
troducing the Dirac δ-distribution and its representation as a Laplace transform, we may
write the probability density H(t) for the value t of discrepancy DN = DN (x1, x2, . . . , xN )
as

H(t) =

δ (DN (x1, x2, . . . , xN )

t) dx1dx2 · · ·

−

dxN

ZK

+i

ZK ZK · · ·
1
2πi

∞

Z
i
∞
−

=

e−

ztG0(z) dz ,

5

(12)

(13)

(14)

(15)

(16)

(17)

(18)

(19)

where the z integration runs along the imaginary axis, and G0(z) is the moment-generating
function

G0(z) = E

ezDN

=

(cid:2)

(cid:3)

0
m
X
≥

zm
m!

E [Dm
N ]

.

At this point it may be useful to note that, since DN is nonnegative by construction, we
must have H(t) = 0 for t < 0, and hence no singular point of G0(z) may have a negative
real part.

The task is, now, to compute G0(z) as a series expansion around z = 0. In Refs. [5,
9, 10, 12] we have shown how Feynman diagrams may be usefully employed to do this in
a systematic way in the limit of large N. In this paper we shall restrict ourselves to the
leading behaviour N

, in which limit we have

→ ∞

(2z)k
2k

Xk>0

log(G0(z)) =

Rk

, Rk =

βk(x, x) dx =

Γk(y, y) dµ(y) .

(21)

ZK

ZL

In those cases where the y variables are discrete and enumerable, Γ can be written as a
real symmetric matrix, and then we simply have

G0(z) = (det(1

2zΓ))−

1/2

, Rk = Tr

Γk

.

−

(22)

We shall – symbolically – employ the matrix and trace notation for the continuous case as
well. In general, we have

(cid:0)

(cid:1)

Γ1(y1, y2) = A(y1, y2)

B(y1)B(y2) ,

−

A(y1, y2) =

h(y1; x)h(y2; x) dx , B(y) =

h(y; x) dx .

(23)

ZK

ZK

In many cases (cf. the case of orthonormal functions bases), we have B(y) = 0, but this
consists of 2k terms. However, as shown in
In general, then, Tr
is not necessary.
Appendix A, we can combine them nicely and arrive at

Γk

(cid:0)

(cid:1)

G0(z) = exp(ψ(z))/

χ(z) ,

ψ(z) =

Xk>0
χ(z) = 1 +

(2z)k
2k

p
Tr

Ak

,

(cid:0)

(2z)k Tr

(cid:1)
BAk

1B

−

.

Xk>0

(cid:0)

(cid:1)

(20)

(24)

2.4 Standardized variables and the Gaussian limit

We now have derived the expression for G0(z) in the large-N limit. Given the form of
Γ(y1, y2), we can now compute H(t) for given discrepancy t, if only numerically; in fact
this was done for the L2 star-discrepancy in Ref. [5] for several dimensionalities. In some

6

special cases, H(t) can even be given in more-or-less closed form [10, 11]. Here, however,
we are interested in possible Gaussian limits, and therefore it is useful to replace the value
t of the discrepancy by the standardized variable ξ, as follows:

t = t(ξ) = E [DN ] + ξ

V [DN ]

,

(25)

p

where the expectation E [DN ] and variance V [DN ] of the discrepancy (which equal R1 and
2R2, respectively) are taken out such that the stochastic variable ξ always has expectation
zero and variance 1. By furthermore going over from z to u = z/√2R2 in Eq. (19), we can
write the probability density ˆH(ξ) of ξ as

ˆH(ξ) = H(t(ξ))

dt(ξ)
dξ

exp(

ξ2/2)

+i

∞

=

−
2πi

Z
i
∞
−

γk = R2

k/Rk

2 .

du exp

1
2

(u

−

 

ξ)2 +

2)/2

uk 2(k

−
k

γ1/2
k

,

!

3
Xk
≥

(26)

All information on the particulars of the discrepancy are now contained in the constants
γk, and we have that the probability density of ξ approaches the normal density whenever
γk →

3. It remains to examine under what circumstances this can happen.

0 for all k

≥

2.5 A Law of Many Modes

Let us assume, for the moment, that the matrix Γ is indeed a real symmetric matrix, for
instance the case of Gaussian measures on a countable basis. Moreover, since we know
that G0(z) has no singularities for negative values of Re z, the eigenvalues of Γ are also
nonnegative, and we may write

Tr

Γk

=

λk
n

,

γk =

(cid:0)

(cid:1)

n
X

2

λk
n

k

−

λ2
n

!

 

n
X

!

 

n
X

,

λn ≥

0 ,

(27)

where the various eigenvalues have been denoted by λn. Note that the sum may run over a
ﬁnite or an inﬁnite number of eigenvalues, but all these sums must converge since E [DN ]
is ﬁnite. Note, moreover, that γk is homogeneous of degree zero in the λn: therefore, any
scaling of the eigenvalues by a constant does not inﬂuence the possible Gaussian limit
(although it will, of course, aﬀect the mean and variance of DN ).

We now proceed by noting that γk+1 ≤

γk, because

2

λk+1
n

 

n
X

!

≤  

n
X

!  

n
X

λ2k
n

λ2
n

! ≤  

n
X

!

 

n
X

λ2
n

!

,

(28)

2

λk
n

7

where the ﬁrst inequality is simply the Schwarz inequality, and the second one holds because
the λn are nonnegative. This means that γk will approach zero for k > 3, whenever γ3
approaches zero. To see when this happens we deﬁne

xn =

λn
m λ2
m

,

x = max

xn ,

n

so that

n x2

pP
n = 1. It is then trivial to see that

x3

P
≤

γ3 ≤

x ,

from which we derive that the necessary and suﬃcient condition for the discrepancy dis-
tribution to approach a Gaussian is that

C =

λ2

n →

0

,

λ = max

λn .

n

λ2

n
P

The Gaussian limit is thus seen to be equivalent to the statement that even the largest
eigenvalue becomes unimportant. Clearly, a necessary condition for this is that the total
number of non-vanishing eigenvalues (number of modes) approaches inﬁnity. Incidentally,
the condition (31) also implies that

λ

→

0 ,

λ2
n →

0 ,

n
X

for all those discrepancies that have E [DN ] =
n λn = 1. This is eminently reasonable,
since a distribution centered around 1 and (by construction) vanishing for negative argu-
ment can only approach a normal distribution if its variance approaches zero. On the other
hand, the condition λ
0 is by itself not suﬃcient, as proven by a counterexample given
in Appendix B.

P

→

Another piece of insight can be obtained if we allow the eigenvalues to take on ran-
dom values. We may introduce the rather dizzying concept of an ensemble of diﬀerent
deﬁnitions of discrepancy, each characterized by its set of eigenvalues (all nonnegative)
~λ =
, with the usual constraint that they add up to 1; we keep M ﬁnite
for simplicity. A natural probability measure on this ensemble is given by the probability
density Pλ(~λ) of the random vector λ:

λ1, λ2, . . . , λM }

{

Pλ(~λ) = Γ(M) δ

M

 

n=1
X

λn −

1

!

.

Here Γ denotes Eulers gamma-function. It is easily computed that the expectation and
variance of Rk =

n are given, for large M, by

n λk

E [Rk]

P
k!
1
M k

−

∼

, V [Rk]

∼

(2k)!

−

(1 + k2)(k!)2
1
M 2k

−

,

8

(29)

(30)

(31)

(32)

(33)

(34)

so that the Rk become sharply peaked around their expectation for large M. In that case,
we have

γ3 ∼

9
2M

,

(35)

and we see that, in the above sense, almost all discrepancies have a Gaussian distribution
in the limit where M, the number of modes, approaches inﬁnity.

3 Applications to diﬀerent examples

3.1 Fastest approach to a Gaussian limit

We now examine the various deﬁnitions of discrepancies, and assert their approach to a
Gaussian limit. Usually this is envisaged, for instance in Ref. [13], as the limit where the
dimensionality s of K becomes very large. But, as we have shown, this is only a special
case of the more general situation where the number of relevant modes becomes very large:
another possible case is that where, in one dimension, the number of modes with essentially
equal strength σn becomes very large. As an illustration, consider the case where the basis
functions with the Gaussian measure are orthonormal and M of the nontrivial modes
have equal strength σ2
n = 1/M, and the rest have strength zero. The moment-generating
function then takes on a particularly simple form, and so does the discrepancy distribution
[11]:

log(G0(z)) =

M
2

−

log

1
(cid:18)

−

2z
M

(cid:19)

, H(t) =

tM/2
−

1e−

tM/2 .

(36)

(M/2)M/2
Γ(M/2)

It is easily seen that the gamma-distribution H(t) approaches a normal one when M
becomes very large. At the same time, we see the ‘physical’ reason behind this:
it is
the fact that the singularity of G0(z) in the complex plane (in the more general case, the
singularity nearest to z = 0) moves away to inﬁnity. One observation is relevant here: in
Eq. (26), we have kept the integration over u along the imaginary axis Re u = 0. We might
consider performing a saddle-point integration, with a non-vanishing value of Re u. That
may give us, for a ﬁnite number of modes, a good approximation to the actual form of
H(t). It is quite possible, and, indeed, it happens in the above equal-strength model, that
this approximation is already quite similar to a Gaussian. In the equal-strength model, a
saddle-point approximation for H(t) gives precisely the form of Eq. (36), the only diﬀerence
being that Γ(M/2) is replaced by its Stirling approximation. On the other hand, for not-
so-large M, this form is not too well approximated by a Gaussian centered around t = 1,
since the true maximum resides at t = 1
2/M. Nevertheless, in this paper we are only
interested in the limiting behaviour of H(t), and we shall stick to the use of condition (31)
as an indicator of the Gaussian limit.

−

One interesting remaining observation is the following. For any ﬁnite number M of
n is

eigenvalues λn (n = 1, 2, . . . , M), the smallest value of the indicator C = λ2/

n λ2

9

P

obtained when λn = 1/M for all n. In this sense, the equal-strengths model gives, for ﬁnite
M, that discrepancy distribution that is closest to a Gaussian.

3.2 L2 star-discrepancy and the Wiener measure

Here we shall discuss the standard L2 star-discrepancy [2]. We start with a formulation of
the problem using a continuous variable y on K, and dµ(y) = dy. The function h is given
by

h(y; xk) =

θ(xµ

k < yµ) ,

s

µ=1
Y

where we have introduced the θ(
measure corresponding to this discrepancy is therefore seen to be deﬁned by

) as the logical step-function3. The Gaussian function

·

f (x1)f (x2) dµ(f ) =

min(1

xµ
1 , 1

xµ
2 ) ,

−

−

Z

s

µ=1
Y

which we can recognize as that variation of the standard Wiener sheet measure in which
the function f (x) is pinned down at x = (1, 1, . . . , 1) rather than at x = (0, 0, . . . , 0). This
is the content of the original Wo´zniakowski lemma from Ref. [6].

A formulation of this discrepancy in terms of a Gaussian measure on a countable basis
can be constructed by realizing that a spectral representation of the integration kernel
g(x1, x2) =

2 ) exists [17] and is given by

µ=1 min(xµ

1 , xµ

s

Q
g(x1, x2) =

σ2
~n u~n(x1)u~n(x2) ,

where the functions u~n are given by

u~n(x) = 2s/2

sin

r(nµ) π

2 xµ

,

(cid:0)

(cid:1)

and the strengths σ2

0
X~n
≥

s

µ=1
Y
~n by

s

s

σ2
~n =

4
π2

1
r(nµ)2

(cid:18)

(cid:19)

µ=1
Y

,

r(n) = (2n + 1) θ(n

0) .

≥

Because a Gaussian measure is completely deﬁned by its two-point Green’s function, the
measure deﬁned by the basis functions u~n is equivalent with the Wiener measure.
In
3The logical step-function θ(P ) of an expression P is equal to 1 if the P is true, and 0 if P is false.

Therefore θ(x < y) is in fact equal to the Heavyside function θ(y

x).

−

10

(37)

(38)

(39)

(40)

(41)

Appendix C we show that the discrepancy deﬁned using this formulation of the Gaussian
measure on a countable basis is equivalent to the L2 star-discrepancy.

The functions u~n are orthonormal, and we have

wn = 2s/2σ~n

and am,n = δm,n ,

where we introduced the Kronecker symbol δm,n. The matrix Γ is given by

and an eigenvalue equation for the eigenvalues λ can be written down easily:

In value the strengths σ~n are degenerate. Labelling the strengths with diﬀerent values by
σp with p =

s
µ=1 r(nµ), the degeneracy is given by

Γ ~m,~n = σ2

~mδ ~m,~n −

2sσ2

~mσ2

~n ,

(σ2

~n −

λ)

2s

1
"

−

Y~n

σ4
~m

σ2
~m −

λ #

X~m

= 0 .

Q
QW (p) =

θ

p =

r(nµ)

,

!

 

0
X~n
≥

s

µ=1
Y

2s

1

−

p
X

QW (p)

= 0 .

σ4
p

σ2
p −

λ

so that λ = σ2
1)-fold degeneracy. If
we factorize these solutions we obtain the following equation for the remaining eigenvalues:

p is solution to the eigenvalue equation with a (QW (p)

−

Some assertions concerning the remaining eigenvalues can be made using this equation.
On inspection, it can be seen that there are no negative solutions, nor solutions larger
than σ2
1, so that σ2
1 can be used as an upper bound of the eigenvalues of Γ. If we order
σ2
. . . . This implies that
the λ such that λ1 ≥
λ1 ≥
1 ≥
3 ≥
σ2k
p QW (p) σ2k
Tr
1 . Note that
so that
≤
traces of gk are upper bounds of traces of Γk. Now we have
P
1
(2n + 1)p ,

λ3 ≥
p QW (p) σ2k

λ3 ≥
p −

. . . , then σ2

ǫ where 0

p = Tr

ξ(2k)s

ξ(p) =

4
π2

(47)

Γk

P

gk

Tr

gk

≤

=

=

ks

(cid:1)

(cid:0)

(cid:1)

(cid:0)

ǫ

,

(cid:18)
(cid:0)
and therefore for k

(cid:1)

≥
ξ(2k)2
ξ(4)k

γk ≤

(cid:19)
3:
s

0
n
X
≥

s

+

4
5

2
3

s

k

−

.

2

−

1
(cid:18)

(cid:19)

(cid:19)

(cid:19)

(cid:19)

(cid:18)

(cid:18)

(cid:18)
The second factor decreases monotonically from (15)k for s = 1 to one as s
; for
the ﬁrst factor, we note that 1 < ξ(2k) < ξ(4) for all k > 2. Therefore γk can be made
arbitrarily small by choosing s large enough, and the Gaussian limit of high dimensionality
is proven. Note, however, that the approach is not particularly fast: for large s, we have
s/25), so that s has to become of the order of one hundred or
γ3 ∼
so to make the Gaussian behaviour manifest. In fact, this was already noted by explicit
numerical computation in Ref. [5].

(24/25)s

→ ∞

exp(

∼

−

11

(42)

(43)

(44)

(45)

(46)

(48)

3.3 Diaphony

3.3.1 General deﬁnition

In one dimension the discrepancy deﬁned through a Gaussian measure on a countable basis
un}
is called diaphony if the basis functions

are such that

{

wn = 0 and am,n = δm,n .

These relations are typically satisﬁed when the functions are orthonormal and u0(x) = 1
is one of the basis functions. The matrix Γ is given by

Γm,n = σ2

nδm,n ,

so the eigenvalues are given by the squares σ2
n of the strengths itself. An extension to more
s
µ=1 unµ(xµ) of one dimensional
dimensions can be obtained by taking products u~n(x) =
functions. However, in contrast to the Wiener sheet measure that underlies the L2 star-
discrepancy, there appears to be no ‘natural’ generalization of the strengths σn to more
dimensions, and therefore we shall discuss various possibilities. In general, we want to let
the strength σ~n depend on a global property of the vector ~n, for instance, the product of
the components, or the sum of the components: we shall call such alternatives clusterings.

Q

3.3.2 Fourier diaphony

As an application of the above, let us consider the orthonormal functions deﬁned by the
one-dimensional factors

u2k

1(x) = √2 sin(2πkx)

,

u2k(x) = √2 cos(2πkx)

,

k = 1, 2, 3, . . .

.

(51)

−

Furthermore, it is useful to take the σ~n such that the sine and cosine modes with equal
wavenumber appear with equal coeﬃcients. Let us deﬁne

k(n) = k θ (2k

1

n

2k) .

−
We require that σ~n only depends on ~n via ~k(~n):

≤

≤

σ~n = σ

~k(~n)
(cid:16)

(cid:17)

In that case, the diaphony is equal to

,

~k(~n) = (k(n1), k(n2), . . . , k(ns)) .

DN =

1
N

σ2(

,

k1|

|

k2|

|

, . . . ,

)

ks|

|

N

2

e2iπ~k

~xl
·

,

X~k
=0

(cid:12)
Xl=1
(cid:12)
(cid:12)
(cid:12)
where, this time, the vector ~k runs over the whole integer lattice except the origin; and it
(cid:12)
has the appealing property that the value of the Fourier discrepancy is the same for point
sets diﬀering only by a translation mod 1; the L2 star-discrepancy does not have this nice
property.

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

12

(49)

(50)

(52)

(53)

(54)

6
3.3.3 Fourier diaphony with product clustering

One of the most straightforward generalizations of the Fourier diaphony, and the choice
made in Ref. [3], is to let σ~n depend on the product of the frequency components:

σ2
~n =

1

(1 + π2/3)s

1

−

µ=1
Y

s

1
r(nµ)2

,

r(n) = θ(n = 0) + k(n) θ(n > 0) .

(55)

The normalization of the σ~n ensures that E [DN ] = 1, independent of s.
In this case,
keeping in mind that sines and cosines occur with equal strength, we have to consider the
multiplicity function

Q

F (p) =

Q

θ

p =

r(nµ)

,

 

0
X~n
≥

µ
Y

!

p, we have to know the behaviour
F (p) in order to ensure convergence of E [DN ]. In order to do so, we introduce the

Actually, before assigning a strength σ~n, or rather σ2
of Q
Dirichlet generating function for Q

F (p):

Q

Q

F (1)

s (x) =

Q

Q

F (p)
px = (1 + 2ζ(x))s

,

p>0
X

where we use the Riemann ζ function. Since this function (and, therefore, F (1)
s (x) as well),
F (p) exceeds the value cp1+ǫ at most for a
converges for all x > 1, we are ensured that Q
ﬁnite number of values of p, for all positive c and ǫ. This is proven in Appendix D. It is
therefore suﬃcient that σ2

p decreases as a power (larger than 1) of p. In fact, taking

Q

σ2
p = cp−

β

,

β > 1 ,

we immediately have that

Rk =

σ2k
~n =

Q

F (p)σ2k

Q

p −

1 = ck [(1 + 2ζ(kβ))s
σ2k

1]

,

−

X~n>0

p>0
X

which, for given β, ﬁxes c such that R1 = E [DN ] = 1, and, moreover, gives

a(β)s

as

s

γ3 ∼

→ ∞

,

a(β) =

(1 + 2ζ(3β))2
(1 + 2ζ(2β))−

3 .

As indicated above, in Ref. [3] the value β = 2 is used, with a(2)
0.291. The supremum
, and the (more interesting) inﬁmum is a(1), about 0.147.
of a(β) equals 1/3, as β
We conclude that, for all diaphonies of the above type, the Gaussian limit appears for
high dimensionality. For large β, where the higher modes are greatly suppressed, the
convergence is slowest, in accordance with the observation that the ‘equal-strength’ model

→ ∞

∼

13

(56)

(57)

(58)

(59)

(60)

gives the fastest convergence; however, the convergence is still much faster than for the
L2 star-discrepancy, and the Gaussian approximation is already quite good for s
4.
The fastest approach to the Gaussian limit occurs when we force all modes to have as
equal a strength as is possible within the constraints on the β. The diﬀerence between the
supremum and inﬁmum of a(β) is, however, not much more than a factor of 2.

∼

Another possibility would be to let σ2

p depend exponentially on p. In that way one can
ensure convergence of the Rk while at the same time enhancing as many low-frequency
modes as possible. It is proven in Appendix D that the function

F (2)

s (x) =

Q

F (p) xp

Q

p>0
X

p = (β′)p with β′
has radius of convergence equal to one, and therefore we may take σ2
between zero and one. If we choose β′ to be very small, we essentially keep only the modes
with p = 1, and therefore in that case we have γ3 ∼
1). This is of course in reality
−
the same type of discrepancy as the above one, with β
. On the other hand, taking
→ ∞
β′
0 (see, again, Appendix D). The diﬀerence with the ﬁrst model
is, then, that we can approach the Gaussian limit arbitrarily fast, at the price, of course, of
xl,
having a function β(xk, xl) that is indistinguishable from a Dirac δ-distribution in xk −
and hence meaningless for practical purposes.

1 we arrive at γ3 →

1/(3s

→

3.3.4 Fourier diaphony with sum clustering

In the above, we have let the strength σ~n depend on the product of the various r(nµ). This
can be seen as mainly a matter of expediency, since the generalization to s > 1 is quite
simple in that case. From a more ‘physical’ point of view, however, this grouping of the
σ is not so attractive, if we keep in mind that each ~n corresponds to a mode with wave
vector ~k(~n). Under the product rule, wave vectors diﬀering only in their direction but
with equal length may acquire vastly diﬀerent weights: for instance, ~k = (m√s, 0, 0, . . . )
and ~k = (m, m, m, . . . ) have equal Euclidean length, m√s, but their strengths under the
product rule are 1/(sm2) and 1/(m2s), respectively. This lack of ‘rotational’ symmetry
could be viewed as a drawback in a discrepancy distinguished by its nice ‘translational’
symmetry. One may attempt to soften this problem by grouping the strengths σ~n in another
way, for instance by taking

σ~n = σ

k(nµ)

,

 

µ
X

!

so that σ depends on the sum of the components rather than on their product. The
multiplicity of a given strength now becomes, in fact, somewhat simpler:

(61)

(62)

(63)

Q

F (p) =

P

θ

p =

 

k(nµ)

=

!

X~n>0

s

µ=1
X

s
m

s

−

m

1 + p
m
p

−

−

(cid:19)

,

0 (cid:18)

m
X
≥

(cid:19)(cid:18)

14

where the last identity follows from the generating function

F (3)

s (x) =

Q

F (p) xp =

P

0
p
X
≥

s

1 + x
x
1

−

(cid:18)

(cid:19)

.

This also immediately suggests the most natural form for the strength: σ2
is

µ k(nµ) as above. We see that R1 converges as long as β < 1, and moreover,

~n = βp, where p

P

γ3 =

1+β3
β3
1

−
1+β2
β2
1

−

s

2

1

1

−

−

i

(cid:17)
s

(cid:17)

h(cid:16)

h(cid:16)

a(β)s ,

i
3 ∼

where a(β) has supremum a(0) = 1, and decreases monotonically with increasing β. For
β close to one, we have a(β)
β)/9, so that the Gaussian limit can be reached as
quickly as desired (again with the reservations mentioned above). At the other extreme,
note that for very small β we shall have

4(1

−

∼

γ3 ∼

1
2s

if

sβ2

1 .

≪

This just reﬂects the fact that, for extremely small β, only the 2s lowest nontrivial modes
contribute to the discrepancy; and even in that case the Gaussian limit is attained, although
much more slowly. The criterium that determines whether the behaviour of γ3 with s and
β is exponential or of type 1/(2s) is seen to be whether sβ2 is considered to be large or
small, respectively.

Another alternative might be a power-law-like behaviour of the strengths, such as σ2

p =

1/pα. Also in this case we may compute the Rk, as follows:

Rk =

p>0
X

Q

F (p)

P

1
pkα =

1
Γ(kα)

∞

Z0

zkα
−

1

F (3)

s (e−

z)

1

dz ,

(cid:0)

−

(cid:1)

from which it follows that α > s to ensure convergence of E [DN ]. In the large-s limit, we
therefore ﬁnd that, also in this case, γ3 →
3.3.5 Fourier diaphony with spherical clustering

1/(2s).

A clustering choice which is, at least in principle, even more attractive from the symmetry
2, hence assuring the
point of view than sum clustering, is to let σ~n depend on
maximum possible amount of rotational invariance under the constraint of translational
invariance. We therefore consider the choice

~k(~n)
|

|

(64)

(65)

(66)

(67)

(68)

σ2
~n = exp

α
 −

µ
X

k(nµ)2

.

!

15

For the function β(x1, x2) = β(x1 −
related by Poisson summation:

x2) we now have the following two alternative forms,

of which the ﬁrst converges well for large, and the second for small, values of α; the sum
over ~m extends over the whole integer lattice. The Rk are, similarly, given by

αk2

e−

cos(2πkxµ)

β(x) =

1 +

−

−

=

1 +

s

+

∞

Xk=
−∞
s/2

µ=1  
Y
π
α

(cid:16)

(cid:17)

exp

−

(cid:18)

X~m

!
π2(~x + ~m)2
α

,

(cid:19)

s

1

−

!
+

∞

Rk =

+

∞

kαq2

e−

 

q=
X
−∞
π
kα

s/2

(cid:16)

(cid:17)

=

 

m=
X
−∞

π2m2/kα

e−

s

1 .

−

!

For large α (where, again, only the ﬁrst few modes really contribute) we recover, again,
: for small α we have, again, an exponential approach to
the limit γ3 →
the Gaussian limit:
s/2

1/(2s) as s

→ ∞

γ3 ∼

8α
9π

(cid:18)

(cid:19)

as

s

.

→ ∞

−

3.3.6 Walsh diaphony

The distinction between the two limiting behaviours is now the magnitude of the quantity
2α), which now takes over the rˆole of the sβ2 of the previous paragraph.
s exp(

Another type of diaphony is based on Walsh functions, which are deﬁned as follows. Let,
in one dimension, the real number x be given by the decomposition
3x3 +

1x1 + 2−

2x2 + 2−

x = 2−

(72)

0, 1

,

,

· · ·

xi ∈ {

}

and let the nonnegative integer n be given by the decomposition

n = n1 + 2n2 + 22n3 + 23n4 +

· · ·

, ni ∈ {

0, 1

}

.

Then, the nth Walsh function Wn(x) is deﬁned as

Wn(x) = (

1)(n1x1+n2x2+n3x3+

···

)

.

−

The extension to the multidimensional case is of course straightforward, and it is easily
seen that the Walsh functions form an orthonormal set. The Walsh diaphony is then given
by

DN =

W~n(xk)

.

1
N

N

σ2
~n

X~n>0

 

Xk=1

2

!

16

(69)

(70)

(71)

(73)

(74)

(75)

In Ref. [13], the following choice is made:

σ2
~n =

s

1

3s

1

1
r(nµ)2 ,

−

µ=1
Y
r(n) = θ(n = 0) + θ(n > 0)

2p θ

2p

n < 2p+1

.

≤

0
p
X
≥

(cid:0)

(cid:1)

Note that, in contrast to the Fourier case where each mode of frequency n contains two basis
functions (one sine and one cosine), the natural requirement of ‘translational invariance’
in this case requires that the Walsh functions from 2p up to 2p+1 get equal strength. The
clusterings are therefore quite diﬀerent from the Fourier case. We slightly generalize the
notions of Ref. [13], and write

σ2
~n =

1
r(nµ)2 ,

s

µ=1
Y

r(n) = θ(n = 0) + θ(n > 0)

(αβp)−

1/2 θ(2p

n < 2p+1) .

0
p
X
≥

≤

Here, we have disregarded the overall normalization of the σ’s since it does not inﬂuence
the Gaussian limit. It is an easy matter to compute the Rk; we ﬁnd

Rk =

σ2k
~n =

1 +

αk

s

1 ,

(cid:18)

2βk

1

−

(cid:19)

−

X~n>0

so that the requirement E [DN ] = R1 <
for not too small values of α, we have

∞

implies that we must have β < 1/2. Therefore,

γ3 ∼

a(α, β)s

,

a(α, β) =

(1 + α3/(1
(1 + α2/(1

2β3))2
2β2))3 .

−
−

∼

The choice made in Ref. [13] corresponds to α = 1 and β = 1/4, for which we ﬁnd
a(1, 1/4)
0.4197. The Gaussian limit should, therefore, be a good approximation for
s larger than 6 or so. An interesting observation is that for ﬁxed β, a(α, β) attains a
2β2), so that the choice β = 1/4 could in principle lead
minimum at α = (1
to a(31/28, 1/4) = 0.4165 with a marginally faster approach to the Gaussian. The overall
inﬁmum is seen to be a(3/2, 1/2) = 2/11
0.182. As in the Fourier case with product
∼
clustering and a power-law strength, there is a limit on the speed with which the Gaussian
is approached: in both cases this is directly related to the type of clustering.
At the other extreme, for very small α we ﬁnd the limiting behaviour

2β3)/(1

−

−

γ3 ∼

2β2)3
2β3)2

1
s

(1
(1

−
−

if

sα2

1 .

≪

Again in this case, the slowest possible approach to the Gaussian limit is like 1/s, directly
related to the symmetry of the discrepancy deﬁnition with respect to the various coordinate
axes.

17

(76)

(77)

(78)

(79)

(80)

3.4 Lego discrepancy

Another class of integrands and discrepancies can be constructed by dissecting the hyper-
cube K into M non-overlapping bins Am (m = 1, 2, . . . , M), and taking the characteristic
functions ϑm of the bins as the basis functions of the measure. Then wn is the volume of
Am, and

M

m=1
X

wm = 1 and am,n = wnδm,n .

(81)

Note that in this case n runs over a ﬁnite set of values. Moreover, this model is dimension-
independent, in the sense that the only information on the dimension of K is that contained
in the value of M: if the dissection of K into bins Ak is of the hyper-cubic type with p bins
along each axis, then we shall have M = ps. Also, a general area-preserving mapping of K
onto itself, such as the Arnol’d cat-transform, will leave the deﬁnition of the discrepancy
invariant in the sense that it will lead to a distortion (and possibly a dissection) of the
various bins Am, but this inﬂuences neither wm nor (by deﬁnition) σm. Owing to the
ﬁniteness of M, a ﬁnite point set can, in fact, have zero discrepancy in this case, namely if
every bin Am contains precisely wmN points (assuming this number to be integer for every
m).

The matrix Γm,n has now indices that label the bins (m, n = 1, 2, . . . M), where M is

the total number of bins:

Γm,n = σmσn (wmδm,n −

wmwn) .

We shall now examine under what circumstances the criterion (31) for the appearance of
the Gaussian limit is fulﬁlled. The eigenvalues λi of the matrix Γm,n are, of course, given
as the roots of the eigenvalue equation

M

 

m=1
Y

(λi −

σ2
mwm)

M

wnλi
σ2
nwn !

λi −

!  

n=1
X

= 0 .

It is seen that there is always one zero eigenvalue (the corresponding eigenvector has 1/σm
for its mth component). Furthermore the eigenvalues are bounded by maxm(σ2
mwm), and
this bound is an eigenvalue if there is more than one m for which the maximum is attained.
At any rate, we have for our criterion, that

C =

λ2

maxm(σ2

mwm)2

λ2
i ≤

Tr (Γ2)

=

maxm(σ2

mwm)2
2wm) + (

mw2
σ4

m(1

−

mwm)2 .
σ2

i
P

m
P

Since the generality of the Lego discrepancy allows us to choose from a multitude of pos-
sibilities for the σ’s and w’s, we now concentrate on a few special cases.

(82)

(83)

(84)

m
P

18

1. All wm equal. This models integrands whose local details are not resolved within
areas smaller than 1/M, but whose magnitude may ﬂuctuate. In that case, we have

C <

1

−

1
2/M

(maxm σm)4
σ4
n

,

n
P

and a suﬃcient condition for the Gaussian limit is for this bound to approach zero.
Note that here, as in the general case, only bins m with σm 6
= 0 contribute to the
discrepancy as well as to the criterion C, so that one has to be careful with models
in which the integrand is ﬁxed at zero in a large part of the integration region K:
this type of model was, for instance, examined in Ref. [14].

2. All σm equal.

In this case, the underlying integrands have more or less bounded
magnitude, but show ﬁner detail in some places (with small w) than in other places
(with larger w). Now, it is simple to prove that

M ¯w2
2 ¯w + 1/M

C

≤

1

−

,

¯w = max

wm ,

m

so that a suﬃcient condition is that M ¯w2 should approach zero.

3. All σ2

mwm equal. This choice models functions in which the largest ﬂuctuations
appear over the smallest intervals. Although not a priori attractive in many cases,
this choice is actually quite appropriate for, e.g. particle physics where cross sections
display precisely this kind of behaviour. In this case we simply have

(85)

(86)

(87)

1

C =

(M + 2)(M

1)

−

,

and the Gaussian limit follows whenever M

.

→ ∞

4 Conclusions

We have shown that a large class of discrepancies, including the L2 star-discrepancy and
the diaphonies, can be formulated as the induced discrepancy of a class of functions deﬁned
by a countable set of basis functions. These basis functions we called modes. For such a
discrepancy we derived the probability distribution, in the limit of a large number of points,
over the ensemble of truly random point-sets. We have shown under what conditions this
distribution tends to a Gaussian. In particular, the question of the limiting behaviour of a
given distribution can be reduced to solving an eigenvalue problem. Using the knowledge of
the eigenvalues for a given function class it is possible to determine under which conditions
and how fast the Gaussian limit is approached. Finally, we have investigated the limiting
behaviour of the probability distribution for the discrepancy of several function classes
explicitly.

19

The discrepancy that most rapidly approaches the Gaussian limit occurs for models in
which the number of modes with non-zero equal strength goes to inﬁnity, while the sum of
the strengths is ﬁxed. In fact, we give an argument why we cannot improve much on this
limit. However, a drawback of this model is that the discrepancy itself becomes a sum of
Dirac δ-functions in this limit: it only measures whether points in XN coincide or not, and
is therefore not very useful in practice.

Secondly, we have examined the L2 star-discrepancy. Here a Gaussian distribution
appears in the limit of a large number of dimensions. It is however a very slow limit: only
(102) does the Gaussian behaviour
when the number of dimensions becomes of the order
become manifest.

O

For the various diaphonies, the choice of the mode-strengths is more arbitrary. The
strengths we discuss are chosen on the basis of some preferred global properties of the
diaphony, such as translation- and/or rotation-invariance. Again for large dimensions the
Gaussian limit is attained, either as a power-law or inverse of the number of dimension.
It is possible to choose the strengths in such a way that the Gaussian limit is approached
arbitrarily fast. But the diaphony corresponding to that case again consists of a sum of
Dirac δ-functions.

Finally, for the Lego-discrepancy, we can assign strengths to the diﬀerent modes in
several ways. One possibility is to keep the product of the squared strength and volume of
the modes ﬁxed: then, the Gaussian limit is reached for a large number of modes.

All these results have been derived in the limit of large number of points. It remains to
be seen however whether this is reasonable in practice. To determine when the asymptotic
regime sets in, i.e. for which value of N, it is necessary to take into account the next-to-
leading contributions. This will be the subject of Ref. [15].

Appendix A: The form of G0(z)

In this Appendix, we derive the result (24) for the form of G0(z) in terms of the quantities
A and B of Eq. (23). For simplicity of notation, we shall assume the discrete case where the
Am,n is a matrix, and the Bm a vector; the indices m, n are then what we called the variables
y in the foregoing. Moreover, let us denote by [BAkB] the sum
m,n Bm(Ak)m,nBn. Since
the matrix Γm,n can be written as

P

(88)

Γm,n = Am,n −

BmBn ,

the kth power of this matrix has the general form

(Γk)m,n = (Ak)m,n −

0 νr)!

(
r
≥
ν0!ν1!ν2!

P

· · ·

p,q,ν0,1,2,...
X

≥

0

(ApB)m(BAq)n

[BArB])νr

,

(89)

(

−

0
r
Y
≥

with the constraint k
directly from the possible positionings of the dyadic factors

1 = p + q + ν0 + 2ν1 + 3ν2 +

· · ·

−

. The combinatorial factor follows
1
BmBn. Multiplying by (2t)k

−

−

20

and summing over the k then gives us immediately

Tr

Γ
2tΓ

(cid:19)

1

(cid:18)

−

=

(2t)k

1Tr

−

Ak

+

1
Xk
≥

(cid:0)

(cid:1)

1 +

1
−
(2t)n[BAn
1
n
≥
P

1B]

−

0
r
X
≥

(r + 1)(2t)r[BArB]

,

(90)

where the last factor, with r + 1, comes from the double sum over p and q with p + q = r.
Upon integration of this result over t from 0 to z we ﬁnd

log(G0(z)) =

Tr (Γn)

(2z)n
2n

(2z)n
2n

n>0
X

n>0
X

=

Tr (An)

log

1 +

(2z)n[BAn

1B]

−

.

(91)

1
2

−

 

n>0
X

!

This result has, in fact, already been obtained for the case of the L2 star-discrepancy in
Ref. [5], but here we demonstrate its general validity for more general discrepancy measures.
In those cases where Bm = 0, the second term of course vanishes.

Appendix B: A counterexample

In this Appendix we prove that the condition (31) for the occurrence of a Gaussian limit
is, in a sense, the best possible. Namely, consider a set of eigenvalues λn, again adding up
to unity as usual, deﬁned as follows:

λ1 = λ ,
λn = (1
λn = 0 ,

−

λ)/(M

1) ,

−

n = 2, 3, . . . , M ,
n > M .

Clearly, λ will indeed be the maximal eigenvalue as long as M > 1/λ. Now,

λ2
n λ2
n

=

λ2
λ)2/(M

,

1)

−

λ2 + (1

−

P

and this ratio can be driven as close to unity as desired by choosing M suﬃciently large.
This shows that the simple condition λ
0 is not always enough to ensure the Gaussian
limit.

→

Appendix C: Spectral representation of the L2 star-
discrepancy

Mercer’s theorem[17] states that a nonnegative-deﬁnite and continuous function on (1, 0]
(1, 0] has a spectral decomposition. Applying this to the function min(xµ

×
2 ), then tells

1 , xµ

(92)

(93)

21

us that the two-point connected Green’s function g of the Wiener measure has a spectral
decomposition of Eq. (39). The eigenvalues σ2
~n and eigenfunctions u~n for g are given by
Eq. (41) and Eq. (40).

To show that the discrepancy deﬁned through the functions u~n is the same as the L2
star-discrepancy pinned down at (1, 1, . . . , 1), we prove the equality of the β-functions for
the two measures:

σ2
~n(u~n(x1)

2s/2σ~n)(u~n(x2)

2s/2σ~n)

X~n

=

−

s

ZK ′  

µ=1
Y

−

s

µ=1
Y

θ(xµ

1 −

yµ)

−

yµ)

(1

−

θ(xµ

2 −

yµ)

−

yµ)

(1

−

!

dy .

(94)

s

!  

µ=1
Y

s

µ=1
Y

Evaluating both sides of the equation we obtain:

σ2
~n u~n(x1) u~n(x2)

2s/2σ3

~n u~n(x1)

2s/2σ3

~n u~n(x2) + 2sσ4
~n

−

−

X~n

(cid:0)

= g(x1, x2)

s

−

µ=1
Y

(cid:0)

xµ
1 −

1

2(xµ

1 )2

s

(cid:1)
2(xµ
2 )2

1

xµ
2 −

−

(cid:1)

µ=1
Y

(cid:0)

+

s

1
3

(cid:18)

(cid:19)

(cid:1)

.

(95)

The ﬁrst terms on both sides of the equation cancel trivially. A small calculation shows
that the same applies to the last terms on both sides of the equation. It thus remains to
show that

2s/2σ3

~n u~n(x) =

(xµ

−

1

2(xµ)2) .

s

µ=1
Y

X~n

3

∞

2

2
π

(cid:18)

(cid:19)

n=0
X

This problem again factorizes for the diﬀerent coordinates (omitting indices):

1
(2n + 1)3 sin

(2n + 1) π

2 x

= x

1

2x2 ,

−

(cid:1)
which is nothing but stating that the lhs of Eq. (97) is the Fourier decomposition of the
rhs. To prove this, let f be the following periodic extension of x

(cid:0)

1

2x2 :

−

(96)

(97)

(98)

f (x) =

1

2x2
x

−

(

3x + 4 x
x

−
1
2x2

∈
∈

(2m
2, 2m]
−
(2m, 2m + 2]

where m is any integer. The function f is a parabolic approximation of 1
2 sin(4πx). It is
continuous and diﬀerentiable on R. Hence it can be written as a Fourier series, based on
a period of 4 rather than 1. An explicit calculation shows that the only non-zero terms
(n = 0, 1, 2, . . . ). The Fourier coeﬃcients
2 x
comes from the functions

(2n + 1) π

sin

1
√2

(cid:0)

(cid:1)

22

are given by 4

1
√2

4

0

Z

f (x) sin

(2n + 1) π

2 x

dx = 2√2

(cid:0)

(cid:1)

2
π

3

1
(2n + 1)3 .

(cid:18)

(cid:19)

Thus the Fourier series is exactly given by the lhs of Eq. (97).

(99)

(100)

(101)

(102)

Appendix D: The magnitude of Q

F (p)
Q

F (p)
Here we present the proofs of our various statements about the multiplicity function Q
of section 3.3.3. In the ﬁrst place, we know that its Dirichlet generating function, F (1)(x),
F (p) exceeded cpα an inﬁnite number of
converges for all x > 1. Now suppose that Q
times, with c > 0 and α > 1. The Dirichlet generating function would then contain an
inﬁnite number of terms all larger than c, for 1 < x < α, and therefore would diverge, in
contradiction with its convergence for all x > 1.

In the second place, consider the ‘standard’ generating function, F (2)

s (x). By inspecting
how many of the vector components nµ of ~n are zero, we see that we may write, for p > 1,

Q

Q

Q

F (p) =

Q

2tdt(p)

,

dt(p) =

s

s
t

t=1 (cid:18)
X

(cid:19)

θ

p =

 

nµ

,

!

0
X~n
≥

t

µ=1
Y

so that dt(p) counts in how many ways the integer p can be written as a product of t
factors, including ones; this function is discussed, for instance, in Ref. [16]. Now, for p
prime, we have dt(p) = t, and therefore

Q

F (p)

Q

≥

2s(3s

1)

−

,

equality for p prime .

The radius of convergence of F (2)
s (x) is therefore at most equal to unity. On the other
F (p) as follows. Since
hand, we can obtain a very crude, but suﬃcient, upper bound on Q
1)ds(p). Now let kp be
dt(p) is a nondecreasing function of t, we may bound Q
the number of prime factors in p; then kp cannot exceed log(p)/ log(2), and only is equal
to this when p is a pure power of 2. Also, the number of ways to distribute k object in s
groups (which may be empty) is at most sk, and is smaller if some of the objects are equal.
Therefore, ds(p) is at most skp, and we see that

F (p) by (3s

−

Q

Q

Q

F (p) < (3s

Q

−

1)plog(s)/ log(2)

,

or, in short, is bounded5 by a polynomial in p. Therefore, the radius of convergence of
F (2)

s (x) is also at least unity, and we have proven the assertion in Eq. 3.3.3.
4We take the functions normalized such that they form a orthonormal set on (0, 4], so the Fourier series

is in terms of the sine- and cosine functions divided by √2.

5Note that equality cannot occur in this case since the two requirements are mutually exclusive.

23

Finally, we consider the limit

2

F (2)

s (x3)

lim
β′
1
→

γ3 = lim
→

x

1 (cid:16)

3 .
(cid:17)

F (2)

s (x2)

(cid:16)

(cid:17)
The same reasoning that led us to the radius of convergence shows that, for x approaching
1 from below, the function F (2)
1. Therefore, γ3 will
F (p)
behave as (8(1
is extremely loose: but it is enough.

−
≥
1. Note that the upper bound on Q

x)/9)c, and approach zero as x

s (x) behaves as (1

c, with c

x)−

→

−

Q

(103)

References

[1] L. Kuipers and H. Niederreiter, Uniform distribution of Sequences, (John Wiley, 1974).
R.F. Tichy and M. Drmota, Sequences, Discrepancies and Applications, (Springer,
1997).

[2] H. Niederreiter, Random number generation and Quasi-Monte Carlo methods, (SIAM,

1992).

[3] P. Zinterhof, ¨Uber einige Absch¨atzungen bei der Approximation von Funktionen met
Gleichverteilungsmethoden, Sitzungsber. ¨Osterr. Akad. Wiss. Math.-Natur. Kl.II 185
(1976) 121-132;
P. Hellekalek, Correlations between pseudorandom numbers:
theory and numerical
practice, Proceedings of the 1st Salzburg Minisymposium on Pseudorandom Number
Generation and Quasi-Monte Carlo Methods, edited by P. Hellekalek, G. Larcher, and
P. Zinterhof, (Salzburg, 1994).

[4] R. Kleiss, Average-case complexity distributions: a generalization of the Wo´zniakowski
lemma for multidimensional numerical integration, Comp. Phys. Comm. 71 (1992) 39-
53.

[5] F. James, J. Hoogland, and R. Kleiss, Multidimensional sampling for simulation and
integration: measures, discrepancies and quasi-random numbers, Comp. Phys. Comm.
99 (1997) 180-220.

[6] H. Wo´zniakoski, Average-case complexity of multivariate integration, Bull. AMS 24

(1991) 185-194.

[7] S. Paskov, Average-case complexity of multivariate integration for smooth functions,

J. Complexity 9 (1993) 291-312.

[8] S. Tezuka, Polynomial arithmetic analogue of Halton sequences, ACM Trans. Modeling

and Computer Simulation 3 (1993) 99-107,
S. Ninomiya and S. Tezuka, Toward real-time pricing of complex ﬁnancial derivatives,
Applied Mathematical Finance 3 (1996) 1-20.

24

[9] J.K. Hoogland, Radiative corrections, Quasi-Monte Carlo and Discrepancy, (Ph.D.

thesis, University of Amsterdam, 1996).

[10] J. Hoogland and R. Kleiss, Discrepancy-based error estimates for Quasi-Monte Carlo.

I: General formalism, Comp. Phys. Comm. 98 (1996) 111-127.

[11] J. Hoogland and R. Kleiss, Discrepancy-based error estimates for Quasi-Monte Carlo.

II: Results for one dimension, Comp. Phys. Comm. 98 (1996) 128-136.

[12] J. Hoogland and R. Kleiss, Discrepancy-based error estimates for Quasi-Monte Carlo.
III: Error distributions and central limits, Comp. Phys. Comm. 101(1997) 21-30.

[13] H. Leeb, A weak limits for diaphony, Proceedings of the 2nd International Conference
on Monte Carlo and Quasi-Monte Carlo Methods in Scientiﬁc Computing, edited by
H. Niederreiter, P. Hellekalek, G. Larcher, and P. Zinterhof Lecture notes in statistics,
(Springer, to appear).

[14] M. Berblinger, Ch. Schlier, and T. Weiss, Monte Carlo integration with quasi-random
numbers: experience with discontinuous integrands, Comp. Phys. Comm. 99 (1997)
151-162.

[15] A. van Hameren, J. Hoogland, and R. Kleiss, Gaussian limits for discrepancies. II:

sub-leading corrections and the curse of dimensionality, (in preparation).

[16] G.H. Hardy and E.M. Wright, An Introduction to the Theory of Numbers, (Oxford,

1988).

[17] M. Lo`eve, Probability Theory (3rd Edition), (Van Nostrand, 1963).

25

