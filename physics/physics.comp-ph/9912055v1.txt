9
9
9
1
 
c
e
D
 
0
3
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
5
5
0
2
1
9
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A Second-Order Stochastic Leap-Frog Algorithm for Multiplicative Noise Brownian
Motion

Ji Qiang1,⋆ and Salman Habib2,†
1LANSCE-1, MS H817, Los Alamos National Laboratory, Los Alamos, NM 87545
2T-8, Theoretical Division, MS B285, Los Alamos National Laboratory, Los Alamos, NM 87545
(February 21, 2014)

A stochastic leap-frog algorithm for the numerical integration of Brownian motion stochastic diﬀer-
ential equations with multiplicative noise is proposed and tested. The algorithm has a second-order
convergence of moments in a ﬁnite time interval and requires the sampling of only one uniformly dis-
tributed random variable per time step. The noise may be white or colored. We apply the algorithm
to a study of the approach towards equilibrium of an oscillator coupled nonlinearly to a heat bath
and investigate the eﬀect of the multiplicative noise (arising from the nonlinear coupling) on the
relaxation time. This allows us to test the regime of validity of the energy-envelope approximation
method.

PACS Numbers : 11.15.Pg, 11.30.Qc, 05.70.Ln, 98.80.Cq 02.50-r

LAUR 99-5263

I. INTRODUCTION

Stochastic diﬀerential equations with multiplicative
noise have not only found many applications in physics
but also have interesting mathematical properties. Con-
sequently they have attracted substantial attention over
the years [1–11]. The key point lies in the fundamen-
tal diﬀerence between additive and multiplicative noises:
Additive noise does not couple directly to the system
variables and disappears from the noise-averaged form of
the dynamical equations. However, in the case of multi-
plicative noise, the system variables do couple directly to
the noise (alternatively, we may say that the noise am-
plitude depends on the system variables). This fact can
lead to dramatic changes of system behavior that cannot
occur in the presence of additive noise alone. Two classic
illustrations are the Kubo oscillator [12] and the existence
of long-time tails in transport theory [13]. In this paper
we will investigate another example, that of an oscillator
nonlinearly coupled to a heat bath, in which the eﬀects
of multiplicative noise can signiﬁcantly alter the qualita-
tive nature, as well as the rate [2], of the equilibration
process (relative to that of an oscillator subjected only
to additive noise).

The dynamical behavior of systems subjected to noise
can be studied in two diﬀerent ways: we may either solve
stochastic diﬀerential equations and average over realiza-
tions to obtain statistical information, or we may directly
solve the Fokker-Planck equation which describes the
evolution of the corresponding probability distribution
function. Both approaches have their share of advantages
and disadvantages. Fokker-Planck equations are partial
diﬀerential equations and their mathematical properties
are still not fully understood. Moreover, they are very
expensive to solve numerically even for dynamical sys-
tems possessing only a very modest number of degrees
of freedom. Truncation schemes or closures (such as cu-
mulant truncations) have had some success in extracting

the behavior of low-order moments, but the systematics
of these approximations remains to be elucidated. Com-
pared to the Fokker-Planck equation, stochastic diﬀer-
ential equations are not diﬃcult to solve, and with the
advent of modern supercomputers, it is possible to run
very large numbers of realizations in order to compute
low-order moments accurately. (We may mention that in
applications to ﬁeld theories it is essentially impossible to
solve the corresponding Fokker-Planck equation since the
probability distribution is now a functional.) However,
the extraction of the probability distribution function it-
self is very diﬃcult due to the sampling noise inherent in
a particle representation of a smooth distribution.

Numerical algorithms to solve stochastic diﬀerential
equations have been discussed extensively in the litera-
ture [14–19]. The simplest, fastest, and still widely-used,
is Euler’s method which yields ﬁrst-order convergence of
moments for a ﬁnite time interval. Depending on the
control over statistical errors arising from the necessarily
ﬁnite number of realizations, in the extraction of statis-
tical information it may or may not pay to use a higher
order algorithm especially if it is computationally expen-
sive. Because of this fact, it is rare to ﬁnd high-order
schemes being put to practical use for the solution of
stochastic diﬀerential equations, and second-order con-
vergence is usually considered a good compromise be-
tween eﬃciency and accuracy. A popular algorithm with
second-order convergence of moments for additive noise
but with only ﬁrst-order convergence of moments for mul-
tiplicative noise is Heun’s algorithm (also called stochas-
tic RK2 by some authors) [14,17,20]. A stochastic leap-
frog algorithm which has the same order convergence of
moments as Heun’s method was suggested in Ref. [21] to
study particle motion in a stochastic potential without
damping. Several other algorithms for particle motion in
a quasi-conservative stochastic system were proposed in
Ref. [16] and in the book by Allen and Tildesley [22]. At
every time step, these methods all require sampling two

1

Gaussian random variables which adds to the computa-
tional cost. A modiﬁed algorithm suggested in Ref. [19]
requires only one Gaussian random variable but applies
only to white Gaussian noise. In the following sections,
we present a new stochastic leap-frog algorithm for mul-
tiplicative Gaussian white noise and Ornstein-Uhlenbeck
colored noise which not only has second-order conver-
gence of moments but also requires the sampling of only
one random uniform variable per time step.

The organization of this paper is as follows: General
numerical integration of a system of stochastic diﬀer-
ential equations with Gaussian white noise is discussed
in Section II. The stochastic leap-frog algorithms for
Brownian motion with Gaussian white noise and colored
Ornstein-Uhlenbeck noise are given in Section III. Nu-
merical tests of these algorithms using a one-dimensional
harmonic oscillator are presented in Section IV. A phys-
ical application of the algorithm to the multiplicative-
noise Brownian oscillator is given in Section V. Section VI
contains the ﬁnal conclusions and and a short discussion.

II. NUMERICAL INTEGRATION OF
STOCHASTIC DIFFERENTIAL EQUATIONS

A general system of continuous-time stochastic diﬀer-
ential equations (Langevin equations) can be written as

˙xi = Fi(x1,

, xn) + σij (x1,

, xn)ξj (t)

(1)

· · ·
· · ·
, n and ξj(t) is a Gaussian white noise

where i = 1,
with

· · ·

−

t′)

h· · ·i

(2)
(3)

= 0
= δ(t

ξj(t)
i
h
ξj (t)ξj (t′)
i
h
and the symbol
represents an average over realiza-
tions of the inscribed variable (ensemble average). The
noise is said to be additive when σij is not a function
of the xi, otherwise it is said to be multiplicative.
In
the case of multiplicative noises, a mathematical subtlety
arises in interpreting stochastic integrals, the so-called
Ito-Stratonovich ambiguity [23].
It should be stressed
that this is a point of mathematics and not of physics.
Once it is clear how a particular Langevin equation has
been derived and what it is supposed to represent, it
should either be free of this ambiguity (as in the case of
the example we study later) or it should be clear that
there must exist two diﬀerent stochastic equations, one
written in the Ito form, the other in Stratonovich, both
representing the same physical process and hence yielding
identical answers for the variables of interest. (Another
way to state this is that there should be only one unique
Fokker-Planck equation.) It is important to note that the
vast majority of numerical update schemes for Langevin
equations use the Ito form of the equation.

The integral representation of the set of equations (1)

is

xi(t) = xi(0) +

dsFi(x1(s),

, xn(s))

· · ·

t

0

Z

t

+

dsσij (x1(s),

, xn(s))ξj (s)

(4)

0
Z

· · ·

where xi(0) is a given sharp initial condition at t = 0.
The inﬁnitesimal update form of this equation may be
derived by replacing t with an inﬁnitesimal time step h:

xi(h) = xi(0) +

dt′ Fi

xk(0) +

dsFk(x(s))

h

0
Z

"

′
t

0
Z

+

dsσkl(x(s))ξl(s)

′
t

0
Z

h

0
Z

′
t

0
Z

+

dt′ σij

xk(0) +

dsFk(x(s))

"

+

dsσkl(x(s))ξl(s)

ξj(t′)

(5)

#

′
t

0

Z

#

Since Fi and σij are smooth functions of the xi, they may
be expanded about their values at t = 0, in which case
we can write the exact solution for xi(h) as

xi(h) = Di(h) + Si(h)

(6)

where Di(h) and Si(h) denote the deterministic and
stochastic contributions respectively. The deterministic
contribution Di(h) is

Di(h) = xi(0) + hFi +

h2Fi,kFk + O(h3)

(7)

1
2

where Fi,k = ∂Fi/∂xk, the summation convention for the
repeated indices having being employed. The stochastic
contribution Si(h) is

Si(h) = σij Wj(h) + σij,kσklClj (h) + Fi,kσklZl(h)

+σij,kFk(hWj(h)

Zj(h)) +

σij,klσkmσlnHmnj(h)

−

1
2

+

Fi,klσksσltGst(h) +

Fkσij,klσlmKmj(h)

+

Flσij,klσkmKmj(h) +

σij,klmσknσloσmpInopj

1
2

1
6

1
2
1
2

+O(h5/2)

The quantities Wi, Cij , Hijk, Zi, Gij , Kij, and Iijkl
are random variables which can be written as stochastic
integrals over the Gaussian white noise ξ(t):

Wi(h) =

dtξi(t)

O(h1/2)

∼

Cij (h) =

dtWi(t)ξj (t)

O(h)

∼

Hijk(h) =

dtWi(t)Wj (t)ξk(t)

O(h3/2)

∼

h

0
Z

h

0
Z

h

0
Z

2

(8)

(9)

(10)

(11)

(12)

(13)

(14)

(16)

(17)

(21)
(22)

(23)

Zi(h) =

dtWi(t)

O(h3/2)

∼

Gij (h) =

dtWi(t)Wj (t)

Kij(h) =

tdtWi(t)ξj (t)

O(h2)

O(h2)

∼

∼

h

0
Z

h

0
Z

h

0
Z

h

0
Z

Iijkl(h) =

dtWi(t)Wj (t)Wk(t)ξl(t)

O(h2)

(15)

∼

Ito integration has been employed in the derivation of
the above equations.

The nth moment of the xi is

xi(h)n
h

i

(Di(h) + Si(h))n
=
h
= Di(h)n + nDi(h)n−1
nDi(h)n−2

+C2

i

Si(h)
h
i
(Si(h))2
+
· · ·
h

i

where

and

Ci

n =

=

i!(n

i)!

n!

−

(cid:18)

(cid:19)

i
n

1
4

Si(h)
i
h

=

,klσksσlsh2 + O(h3)
F i

(18)

Si(h)Sj (h)
i
h

= σilσjlh +

,p σplh2

1
2

σjlF i

,kσklh2 +

σim
,k σklσjm
1
2
1
σjlσil
2
,klσkmσlmh2

,kF kh2 +

,kσklh2

,kF kh2

,klσkmσlmh2 + O(h3) (19)
(20)

+

+

+

σilF j

σilσjl

σipσjp

1
2
1
2
1
4
1
4
= O(h3)
= 3(σii)4 + O(h3)
= O(h3)

σjpσip

+

Si(h)Sj(h)Sk(h)
i
h
Si(h)4
h
(Si(h))5
h

i
i

Suppose that the results from a numerical algorithm were
written as

¯xi(h) = ¯Di(h) + ¯Si(h)

where the ¯xi are approximations to the exact solutions
xi. The nth moment of ¯xi is

¯xi(h)n
h

i

( ¯Di(h) + ¯Si(h))n
=
h
= ¯Di(h)n + n ¯Di(h)n−1
¯Di(h)n−2

+C2
n

i

¯Si(h)
i
h
( ¯Si(h))2
+
· · ·
h

i

Comparing Eqns. (16) and (24), we see that if Di(h) and
¯Di(h), and Si(h) and ¯Si(h) coincide up to h2, we will
have

xi(h)

¯xi(h) = O(h3)

−

and for a ﬁnite time interval

xi(t)n
h

i − h

¯xi(t))n

= O(h2)

i

III. STOCHASTIC LEAP-FROG ALGORITHM
FOR BROWNIAN MOTION

The approach to modeling Brownian motion that we
consider here is that of a particle coupled to the environ-
ment through its position variable [1]. When this is the
case, noise terms enter only in the dynamical equations
for the particle momenta. In the case of three dimensions,
the dynamical equations take the general form:

˙x1 = F1(x1, x2, x3, x4, x5, x6) + σ11(x2, x4, x6)ξ1(t)
˙x2 = F2(x1)
˙x3 = F3(x1, x2, x3, x4, x5, x6) + σ33(x2, x4, x6)ξ3(t)
˙x4 = F4(x3)
˙x5 = F5(x1, x2, x3, x4, x5, x6) + σ55(x2, x4, x6)ξ5(t)
˙x6 = F6(x5)

(27)

The convention used here is that the odd indices corre-
spond to momenta, and the even indices to the spatial
coordinate. In the dynamical equations for the momenta,
the ﬁrst term on the right hand side is a systematic drift
term which includes the eﬀects due to external forces and
damping. The second term is stochastic in nature and
describes a noise force which, in general, is a function of
position. The noise ξ(t) is ﬁrst assumed to be Gaussian
and white as deﬁned by Eqns. (2)-(3). The stochastic
leap-frog algorithm for the Eqns. (27) is written as

¯xi(h) = ¯Di(h) + ¯Si(h)

(28)

The deterministic contribution ¯Di(h) can be obtained us-
ing the deterministic leap-frog algorithm. The stochastic
contribution ¯Si(h) can be obtained by applying Eq. (8) on
Eq. (27). The stochastic integration deﬁned by Eqs. (9)
to (15) can be approximated so that the moment rela-
tionships deﬁned by Eqs. (18) to (22) are satisﬁed. After
some calculation, the deterministic contribution ¯Di(h)
and the stochastic contribution ¯Si(h) of the above recur-
sion formula for one-step integration are found to be

¯Di(h) = ¯xi(0) + hFi(¯x∗

1, ¯x∗

2, ¯x∗

3, ¯x∗

4, ¯x∗

5, ¯x∗

6);

i = 1, 3, 5

{
¯Di(h) = ¯x∗
i
1
2
i = 2, 4, 6

+

{

}

}

hFi [xi−1 + hFi−1(¯x∗

1, ¯x∗

2, ¯x∗

3, ¯x∗

4, ¯x∗

5, ¯x∗

6)] ;

(24)

¯Si(h) = σii√hWi(h) +

Fi,kσkkh3/2 ˜Wi(h)

1
2

+

+

σii,j Fjh3/2 ˜Wi(h)

Fi,klσkkσllh2 ˜Wi(h) ˜Wi(h);

1
2
1
4
i = 1, 3, 5; j = 2, 4, 6; k, l = 1, 3, 5
1
√3

Fi,j σjj h3/2 ˜Wj (h)

{

}

¯Si(h) =

(25)

(26)

3

+

Fi,jj σ2

jj h2 ˜Wj(h) ˜Wj (h)

1
4
i = 2, 4, 6; j = 1, 3, 5

{
¯x∗
i = ¯xi(0) +

1
2
i = 1, 2, 3, 4, 5, 6

}
hFi(¯x1, ¯x2, ¯x3, ¯x4, ¯x5, ¯x6)

{

}
where ˜Wi(h) is a series of random numbers with the mo-
ments

˜Wi(h)
i
h
( ˜Wi(h))2
h

i

=

( ˜Wi(h))3
h
= 1,

( ˜Wi(h))5
=
h
i
( ˜Wi(h))4
= 3
h

i

i

= 0

This can not only be achieved by choosing true Gaus-
sian random numbers, but also by using the sequence of
random numbers following:

˜Wi(h) =

−

√3,
0,
√3,




R < 1/6

1/6

R < 5/6
R

≤
5/6

≤

where R is a uniformly distributed random number on
the interval (0,1). This trick signiﬁcantly reduces the
computational cost in generating random numbers.



Next we consider the case that the noise in Eqs. (27)

is a colored Ornstein-Uhlenbeck process which obeys

(29)

(30)

(31)

(32)

(33)

(34)

ξi(t)
i
h
ξi(t)ξi(t′)
i
h

= 0
ki
2

=

exp(

t
ki|

−

−

t′

)
|

where the correlation factor ki is the reciprocal of the
, the Ornstein-
correlation time. In the limit of ki → ∞
Uhlenbeck process reduces to Gaussian white noise. The
above process can be generated by using a white Gaussian
noise from a stochastic diﬀerential equation

˙ξi(t) =

kiξi(t) + kiζi(t)

−

(35)

where ζi(t) is a standard Gaussian white noise. The ini-
tial value ξi(0) is chosen to be a Gaussian random number
with

= 0 and

= ki/2.

For the stochastic process with colored noise, the leap-
frog algorithm for Eqns. (27) is of the same form as that
for white noise (Cf. Eqn. (29)), but with

ξi(0)2
h

i

ξi(0)
i
h

¯Di(h) = ¯xi(0) + hFi(¯x∗
4, ¯x∗

2, ¯x∗

1, ¯x∗
2, ¯x∗
6)ξ∗
i ;

3, ¯x∗

4, ¯x∗

5, ¯x∗
6)

+hσii(¯x∗
i = 1, 3, 5

}

{
¯Di(h) = ¯x∗
i
1
2

+

+hσi−1i−1(¯x∗
i = 2, 4, 6
}
{
¯Dξi (h) = ξi(0) exp(
kih);
−
i = 1, 3, 5
}

{

2, ¯x∗

4, ¯x∗

6)ξ∗

i−1

;

(cid:3)

hFi [¯xi−1 + hFi−1(¯x∗

1, ¯x2

∗, ¯x∗

3, ¯x4

∗, ¯x∗

5, ¯x6

∗)

<x^2>

2.16

2.24

2.22

2.2

2.18

2.14

2.12

2.1

2.08

0

2.095

2.09

2.085

2.08

<x^2>

2.075

2.07

2.065

2.06

0

¯Si(h) =

σii(¯x2, ¯x4, ¯x6)kih3/2 ˜Wi(h);

1
√3
i = 1, 3, 5

{
¯Si(h) = 0;

i = 2, 4, 6

{

}
¯Sξi = ki√h ˜Wi(h)

i = 1, 3, 5

{

}

}

where

1
2

−

i h3/2 ˜Wi(h);
k2

h(Fi(¯x1, ¯x2, ¯x3, ¯x4, ¯x5, ¯x6)

¯x∗
i = ¯xi(0) +

1
2
+σii(¯x2, ¯x4, ¯x6)ξi;
i = 1, 3, 5

{
¯x∗
i = ¯xi(0) +

}
hFi(¯x1, ¯x2, ¯x3, ¯x4, ¯x5, ¯x6);

1
2

i = 2, 4, 6

ξ∗
i = ξi(0) exp(

kih);

−
i = 1, 3, 5

}
1
2

}

{

{

(36)

(37)

0.1

0.2

0.3

0.4

0.5

0.6

0.7

h

0.05

0.1

0.2

0.25

0.3

0.15

h

FIG. 1. Zero damping convergence test. Top: hx2(t)i at
t = 6 as a function of step size with white Gaussian noise.
Bottom: hx2(t)i at t = 6 as a function of step size with colored
Ornstein-Uhlenbeck noise. Solid lines represent quadratic ﬁts
to the data points (diamonds).

IV. NUMERICAL TESTS

The above algorithms were tested on a one-dimensional
stochastic harmonic oscillator with a simple form of the
multiplicative noise. The equations of motion were

4

˙p = F1(p, x) + σ(x)ξ(t)
˙x = p

(38)

−

−

where F1(p, x) =

γp

η2x and σ(x) =
x2
h

i

αx.

−

i

i

x2
h

As a ﬁrst test, we computed

as a function of time
step size. To begin, we took the case of zero damping
x2
can be determined analyt-
constant (γ = 0), where
h
ically. The top curve in Fig. 1 shows
at t = 6.0 as
a function of time step size with white Gaussian noise.
Here, the parameters η and α are set to 1.0 and 0.1.
The ensemble averages were taken over 106 independent
x2
simulations. The analytically determined value of
i
h
at t = 6.0 is 2.095222 (The derivation of the analytical
results is given in the Appendix). The quadratic con-
vergence of the stochastic leap-frog algorithm is clearly
seen in the numerical results. We then considered the
case of colored Ornstein-Uhlenbeck noise as a function of
time step size using the same parameters as in the white
Gaussian noise case and with the correlation parameter
k = 0.16. The result is shown as the bottom curve in
Fig. 1 and the quadratic convergence is again apparent.

x2
gorithm, we computed
as a function of t using
i
h
100, 000 numerical realizations for a particle starting
from (0.0, 1.5) in the (x, p) phase space. The results along
with the analytical solution and a numerical solution us-
ing Heun’s algorithm are given in Fig. 3. Parameters
used were h = 0.1, η = 1.0, and α = 0.1. The ad-
vantage in accuracy of the stochastic leap-frog algorithm
over Heun’s algorithm is clearly displayed, both in terms
of error amplitude and lack of a systematic drift.

We note that while in general Heun’s algorithm is only
linear for multiplicative noise applications, for the partic-
ular problem at hand it turns out to be quadratic. This
is due to a coincidence: the stochastic term of x does
not contain W (h) but does posses a higher order term
hW (h). However, this higher order term has a larger
coeﬃcient compared with our stochastic leap-frog algo-
rithm, and this accounts for the larger errors observed in
Fig. 3.

<x^2>

0.5

0.54

0.53

0.52

0.51

0.49

0.48

0.47

0.46

0

0.454

0.452

0.45

0.448

0.444

0.442

0.44

0.438

0

<x^2>

0.446

0.1

0.2

0.3

0.4

0.5

0.6

0.7

h

<x^2>(t)

12

8

4

0

-2

0

Exact

Error: Heun

Error: Leapfrog

100

200

300

400

500

t

FIG. 3. Comparing stochastic leap-frog and the Heun al-
gorithm: hx2(t)i as a function of t. Errors are given relative
to the exact solution.

V. A PHYSICAL APPLICATION: THE
MECHANICAL OSCILLATOR

0.05

0.1

0.2

0.25

0.3

0.15

h

FIG. 2. Finite damping (γ = 0.1) convergence test. Top:
hx2(t)i at t = 12 as a function of step size with white Gaussian
noise. Bottom: hx2(t)i at t = 12 as a function of step size
with colored Ornstein-Uhlenbeck noise. Solid lines represent
quadratic ﬁts to the data points (diamonds).

We veriﬁed that the quadratic convergence is present
for nonzero damping (γ = 0.1). At t = 12.0, and with
x2
all other parameters as above, the convergence of
i
h
as a function of time step is shown by the top and bot-
tom curves in Fig. 2 (white Gaussian noise and colored
Ornstein-Uhlenbeck noise, respectively).

As a comparison against the conventional Heun’s al-

In this section, we apply our algorithm to studying the
approach to thermal equilibrium of an oscillator coupled
nonlinearly to a heat bath modeled by a set of noninter-
acting harmonic oscillators [1]. The nonlinear coupling
leads to the introduction of multiplicative noise into the
system dynamics. Lindenberg and Seshadri have pointed
out that, at weak coupling, multiplicative noise may sig-
niﬁcantly enhance the equilibration rate relative to the
rate for weak linear coupling (additive noise) [2]. We will
choose the same form of the coordinate couplings as in
Ref. [2], in which case the additive noise equations are

ω2
0x

−

˙p =
−
˙x = p

λ0p +

2D0ξ0(t)

p

(39)

5

λ0
ω0 ≪

kT λ2
ω3

0 ≪

1;

1;

additive noise

multiplicative noise

(45)

(46)

As a ﬁrst check, we performed simulations with ω0 = 1.0,
λ0 = λ2 = 0.01, and kT = 4.5, in which case both
the above conditions are satisﬁed. Moreover, with these
choices of parameter values, and within the energy en-
velope approximation, the relaxation time predicted for
multiplicative noise is substantially smaller than for the
case of additive noise. At the same time we also ran a
simulation at kT = 200 to see how the energy envelope
approximation for multiplicative noise breaks down at
high temperatures.

and for the system with multiplicative noise only:

ω2
0x

λ2x2p

−

˙p =
−
˙x = p

−

p

2D0xξ2(t)

(40)

where the diﬀusion coeﬃcients Di = λikT, i = 0, 2, λi is
the coupling constant, k is Boltzmann’s constant, T is the
heat bath temperature, and ω0 is the oscillator angular
frequency without damping. The approach to thermal
equilibrium is guaranteed for both sorts of noises by the
ﬂuctuation-dissipation relation

ξi(t)ξj (s)
i
h

= δij δ(t

s)

−

(41)

written here for the general case when both noises are
simultaneously present. While in all cases, it is clear
that the ﬁnal distribution is identical and has to be the
thermal distribution, the precise nature of the approach
to equilibrium can certainly be diﬀerent. We wish to
explore this issue in more detail. An important point to
keep in mind is that in this particular system of equations
there is no noise-induced drift in the Fokker-Planck equa-
tion obtained from the Stratonovich form of the Langevin
equation, i.e., there is no Ito-Stratonovich ambiguity.

It is a simple matter to solve the Langevin equations
given above applying the algorithm from Eqs. (29). As
our primary diagnostic, we computed the noise-averaged
energy
of the oscillator as a function of time t,
where

E(t)
i
h

II

III

<E(t)>/kT

I

1

1.2

0.8

0.6

0.4

0.2

E(t) =

p2 +

0x2.
ω2

1
2

1
2

(42)

0

0

50

100

150

250

300

350

400

200

t

In the weak coupling limit and employing orbit-averaging
(valid presumably when the dynamical time scale is much
smaller than the relaxation time scale), one ﬁnds [2]

E(t)
i
h

= kT

(kT

−

−

E0)e−λ0t

(43)

in the case of additive noise (a result which can also be
directly obtained as a limiting case from the known form
of the exact solution given, e.g., in Ref. [24]). The corre-
sponding form of the approximate solution in the case of
multiplicative noise is

E(t)
i
h

=

E0 + (kT

E0kT
E0) exp(

−

λ2kT t/ω2
0)

−

.

(44)

While in the case of additive noise, the exponential na-
ture of the relaxation is already clear from the form of the
exact solution (cf. Ref. [24]), the situation in the case of
multiplicative noise is not obviously apparent as no exact
solution is known to exist. The prediction of a relaxation
process controlled by a single exponential as found in (44)
is a consequence of the assumption
0 at
“late” times, this implying a constant damping coeﬃcient
in the Langevin equation (40).

x2(t)
h

kT /ω2

i ≃

The timescale separations necessary for the energy-
envelope method to be applicable are encoded in the fol-
lowing inequalities [2]:

FIG. 4. Temporal evolution of the scaled average energy
hE(t)i/kT with additive noise and multiplicative noise. The
dashed lines I and II are the predictions from Eqn. (44) for
kT = 200 and kT = 4.5 respectively. The dashed line III is
the theoretical prediction for additive noise with kT = 4.5.
As predicted, the relaxation proceeds much faster with multi-
plicative noise: The solid lines are numerical results for mul-
tiplicative noise at kT = 200 and kT = 4.5. It is clear that at
higher temperatures, the theory grossly underestimates the
relaxation time.

In Fig. 4, we display the time evolution of the aver-
age energy (scaled by kT for convenience) with additive
and multiplicative noise both from the simulations and
the approximate analytical calculations. In the case of
weak coupling to the environment (small λ0, λ2), the
rate at which the average energy approaches equilibrium
is signiﬁcantly greater for the case of multiplicative noise
relative to the case of additive noise more or less as ex-
pected. In addition, the analytic approximation result-
ing from the application of the energy-envelope method
(44) is seen to be in reasonable agreement with the nu-
merical simulations for kT = 4.5. The slightly higher
equlibration rate from the analytical calculation is due to
the truncation in the energy envelope equation using the
2 relation which yields an upper bound
E2(t)
E(t)
i
h
h

i ≈

2

6

on the rate of equilibration of the average energy [2].
Note that in the case of high temperature (kT = 200)
the relaxaton time computed from the energy envelope
method is much smaller than the numerical result, con-
sistent with the violation of the condition (46).

While the results shown in Fig. 4 do show that the
energy envelope approximation is qualitatively correct
within its putative domain of validity, it is clear that
the actual relaxation process is not of the precise form
(44). In Fig. 5 we illustrate this point by plotting

E0(kT
− h
(kT
E(t)
i
h

)
E(t)
i
E0)

−

= exp(

λ2kT t/ω2
0)

−

(47)

[equivalent to (44)] against time on a log scale: the re-
laxation is clearly nonexponential. The reason for the
failure of the approximation is that despite the fact that
equipartition of energy does take place on a relatively
x2(t)
short time scale, it is not true that
can be treated
i
h
as a constant even at relatively late times.

oscillator-heat-bath system in order to investigate the ef-
fect of multiplicative noise on the nature of the relaxation
process.

VII. ACKNOWLEDGMENTS

We acknowledge helpful discussions with Grant Lythe
and Robert Ryne. Partial support for this work came
from the DOE Grand Challenge in Computational Ac-
celerator Physics. Numerical simulations were performed
on the SGI Origin2000 systems at the Advanced Com-
puting Laboratory (ACL) at Los Alamos National Lab-
oratory, and on the Cray T3E at the National En-
ergy Research Scientiﬁc Computing Center (NERSC) at
Lawrence Berkeley National Laboratory.

1

0.1

0.01

Additive Noise

Multiplicative Noise

0.001

0

50

100

200

250

300

150

t

FIG. 5. The LHS of (47) as a function of time (straight line)
compared with numerical results for kT = 4.5. Also shown
is a numerical result for the case of additive noise which is in
excellent agreement with the predicted exponential relaxation
with the relaxation timescale = 1/λ0.

VI. CONCLUSIONS

We have presented a stochastic leap-frog algorithm
for single particle Brownian motion with multiplicative
noise. This method has the advantages of retaining the
symplectic property in the deterministic limit, ease of im-
plementation, and second-order convergence of moments
for multiplicative noise. Sampling a uniform distribution
instead of a Gaussian distribution helps to signiﬁcantly
reduce the computational cost. A comparison with the
conventional Heun’s algorithm highlights the gain in acu-
racy due to the new method. Finally, we have applied the
stochastic leap-frog algorithm to a nonlinearly coupled

7

⋆

†

Electronic address: jiqiang@lanl.gov
Electronic address: habib@lanl.gov

[1] R. Zwanzig, J. Stat. Phys. 9, 215 (1973).
[2] K. Lindenberg and V. Seshadri, Physica 109 A, 483

[3] A. Careta and F. Sagues, Phys. Rev. A 44, 2284 (1991).
[4] S. Habib and H. Kandrup, Phys. Rev. D 46, 5303 (1992).
[5] S. Habib, Ann. N.Y. Acad. Sci. 706, 111 (1993).
[6] G. Efremov, L. Mourokh, and A. Smirnov, Phys. Lett. A

175, 89 (1993).

[7] A. Becker and L. Kramer, Phys. Rev. Lett. 73, 955

[8] H. Leung, Physica A 221, 340 (1995).
[9] J. Bao, Y. Zhuo, and X. Wu, Phys. Lett. A 217, 241

(1981).

(1994).

(1996).

[10] S. Mangioni, R. Deza, H. Wio, and R. Toral, Phys. Rev.

[11] W. Genovese, M. Munoz, and J. Sancho, Phys. Rev. E

Lett. 79, 2389 (1997).

57, R2495 (1998).

[12] R. Kubo, J. Math. Phys 4, 174 (1963).
[13] R.W. Zwanzig, in Statistical mechanics; new concepts,
new problems, new applications edited by S.A. Rice,
K.F. Freed, and J.C. Light (University of Chicago Press,
Chicago, 1972).

[14] A. Greiner, W. Strittmatter, and J. Honerkamp, J. Stat.

[15] R. Mannella, and V. Palleschi, Phys. Rev. A 40, 3381

Phys. 51, 94 (1988).

(1989).

[16] R. Mannella, in Noise in Nonlinear Dynamical Systems,
vol. 3, F. Moss and P.V.E. McClintock, Eds. (Cambridge
University Press, Cambridge, 1989).

[17] R.L. Honeycutt, Phys. Rev. A 45, 600 (1992).
[18] P.E. Kloeden and E. Platen, Numerical Solution of
Stochastic Diﬀerential Equations (Springer, New York,
1992).

[19] R. Mannella, in Supercomputation in Nonlinear and Dis-

ordered Systems, L. Vazuez, F. Tirado, and I. Marun,
Eds., p. 101 (World Scientiﬁc, 1996).

[20] S. Habib, H.E. Kandrup, and M.E. Mahon, Phys. Rev.

which gives

2α2

4η2x

x3 = 0

−

−

(A6)

r1 =

64/27η6 + α4 + α2

1/3

64/27η6 + α4

1/3

(cid:17)
α2

−

r2 =

(cid:16)p
(1 + √3i)

(cid:17)

64/27η6 + α4

(cid:16)p
−
1
2

1/3

α2

−

1
2

(1

−

−
r3 = r∗
2

(cid:16)p

√3i)

(cid:17)
64/27η6 + α4 + α2

1/3

(cid:16)p

(cid:17)

(A7)

where the superscript
The positive real root r1 implies that
exponential growth in time.

represents complex conjugation.
x2(t)
will have an
i
h

∗

E 53, 5473 (1996).

[21] M. Seesselberg, H.P. Breuer, H. Mais, F. Petruccione,

and J. Honerkamp, Z. Phys. C 62, 63 (1994).

[22] M.P. Allen, and D.J. Tildesley, Computer Simulation of

Liquids (Clarendon Press, Oxford, 1987).

[23] C.W. Gardiner, Handbook of Stochastic Methods for
Physics, Chemistry, and the Natural Sciences (Springer,
New York, 1983).

[24] H. Risken, The Fokker-Planck Equation: Methods of So-
lution and Applications (Springer, New York, 1989).

APPENDIX A:

The analytic solution of Eqns. (38) for

(with
white Gaussian noise) as a function of time in the special
case of zero damping, i.e. γ = 0, can be obtained by
solving the equivalent Fokker-Planck equation [24] for the
probability density f (x, p, t):

x2(t)
i
h

f (x, p, t) =

∂
∂t

−

(cid:20)

p

∂
∂x −

∂F1(p, x)
∂p

+

σ2(x)

1
2

∂2
∂p2

(cid:21)

f (x, p, t)

(A1)

The expectation value of any function M (x, p; t) can be
written as

M (x, p)
i
h

=

+∞

−∞

Z

dxdpM (x, p)f (x, p, t)

(A2)

Equations (A1) and (A2) can be used to yield a BBGKY-
like heirarchy for the evolution of phase space moments.
Since the system we are considering is linear, this heirar-
chy truncates exactly and yields a group of coupled lin-
ear ordinary diﬀerential equations for the moments
,
i
. These equations can be written as a single
xp
h
i
third-order time evolution equation for

, and
i

x2
h

p2
h

x2
h

:
i

d3
x2
dt3 =
h
i
subject to the initial conditions

x2
4η2 d
h
dt

−

i

+ 2α2

x2
h

i

(A3)

x2(0)
h
i
˙x2(0)
h
i
¨x2(0)
i
h

= x2(0)
= 2x(0)p(0)
= 2p2(0)

−

2η2x2(0)

(A4)

This equation has an analytical solution written as

x2(t)
i
h

= c1 exp(r1t) + c2 exp(r2t) + c3 exp(r3t)

(A5)

where c1, c2, and c3 are constants depending on initial
conditions, and r1, r2 and r3 are the roots of a third order
alegbraic equation

8

