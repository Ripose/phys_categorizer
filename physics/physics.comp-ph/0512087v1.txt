5
0
0
2
 
c
e
D
 
9
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
7
8
0
2
1
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Minority game with local interactions due to the presence of herding behavior

Daniel Oliveira Cajueiro and Reinaldo Soares De Camargo
Department of Economics, Catholic University of Brasilia, 70790-160, Brasilia, DF, Brazil.

In this paper, we introduce a framework to study local interactions due to the presence of herding
behavior in a minority game. The idea behind this approach is to consider that some of the agents
who play the game believe that some of their neighbors are more informed than themselves. Thus,
in this way, these agents imitate their most informed neighbors. The notion of neighborhood here
is given by a regular network, a random network or a small world network. We show that under
herding behavior the cooperation between the agents is less eﬃcient than that one which arises in
the standard minority game. On the other hand, depending on the topology of the network, we show
that that the well known curve volatility versus memory, which caracterizes the minority game, is
a monotone decreasing curve.

Keywords: Complex networks, econophysics, herding behavior, minority games, phase transition.

PACS numbers: 02.50.Le, 05.65.+b, 05.70.Fh, 87.23.Ge, 89.65.Gh, 89.75.-Hc

I.

INTRODUCTION

In these last years, one of the most interesting contri-
butions of the statistical physics to the social sciences has
been to study the dynamics and the collective behavior of
populations of agents who compete for limited resources.
In particular, the so-called minority game (MG) intro-
duced in [1] as a simpliﬁcation of the Arthur’s El Farol
Bar [2] attendance problem is one of the simplest com-
plex systems that belong to this class. This game can
be described in the following way. At a given instant of
time, an agent who belongs to the population chooses
between two opposing actions namely a = ±1 [26]. Since
the resources are limited, the objective of each agent is
to choose the side shared by the minority of the popu-
lation. The diﬃculty is that each agent does not know
what the others will choose. The agent decides his/her
next action based only on a global information, which is
the sequence of the last M outcomes of the game, where
M is said to be the memory of the agents. Therefore,
there is no best solution for the problem, i.e., the agents
do not know what is the best strategy [27] to deal with
the game. Since there are only two possible choices, the
number of states is 2M and there are at all 22M
strategies.
In [1], each agent has a ﬁxed number of strategies that do
not change over time. Since agents have diﬀerent beliefs,
the strategies diﬀer from agent to agent. At every turn
of the game, the agents use their strategies with highest
scores[28].

This standard MG presented above has been very well-
studied – a revision of these attempts may be found for
instance in [3, 4, 5]. One of the most surprising prop-
erties presented ﬁrst in [6] is that if one plots the ratio
σ2/N as a function of α = 2M /N , one may conclude: (1)
For small values of α = 2M /N , the agents would perform
worse than if they had taken purely random decisions. (2)
For large values of α = 2M /N , the agents’ performance
approaches the random decision. (3) There is a critical
value of α = αc where the resources of the game are used
in the best way possible, i.e., the ratio σ2/N is the min-

imal possible – which suggests a non-equilibrium phase
transition from the so-called low-M phase to the high-M
phase. The low-M phase is characterized by a decrease
in σ2/N as α = 2M /N increases and the high-M phase
is characterized by a increase in σ2/N as α = 2M /N in-
creases. (4) The behavior of the MG does not depend on
the number of strategies available for each agent.

In this paper, we introduce a version of the standard
MG with local interactions and exchange of local infor-
mation. Actually, this is not the ﬁrst paper that presents
the exchange of local information and local interactions
in some version of the MG. As far as we know, the ﬁrst
attempt in this line was presented in [7] where was de-
veloped a version of the Kauﬀman network using some
rules of the minority game and each agent receives input
from a ﬁxed number of agents in the system. Other for-
mulations of MGs with local interactions may be found
in [8, 9, 10, 11, 12, 13, 14, 15, 16, 17].
In our paper,
diﬀerently of the others cited above, the exchange of lo-
cal interaction emerge from the imitation of the most
informed agents, i.e., some of the agents who play the
game believe that some of their neighbors are more in-
formed then themselves. This phenomenon called herd-
ing behavior happens when an agent blindly follows the
decision of other agent. The economic theory says that
it is rational even when the former agent’s signals sug-
gest a diﬀerent decision and it is ignored[29]. In the case
here, an agent follows another agent strategy, if he/she
believes that there is an agent more informed than hin-
self/herself, i.e., this most informed agent is more likely
to know the decision of the minority. Actually, one should
notice that if not one but many agents follow the most in-
formed agent of their neighborhood, then, in the future,
the most informed agent will be in the majority and he
will no be followed anymore.
In this paper, we inves-
tigate how this kind of policy performed by the agents
aﬀect the dynamics of the standard MG.

2

This can be easily interpreted. In the original MG [6], the
low-M phase is characterized by a crowded phase where
the number of strategies is small when compared to the
number of agents. The presence of herding behavior only
reinforces this fact. However, if the presence of herding
behavior is too strong as, for instance, in ﬁgure 4 where
there are simulations with a small world network with
parameters K = 16 and p = 0.5, part of the standard
low-M phase is replaced a horizontal line. This means
that the crowd is so strong that the additional number
of strategies introduced are not enough to reduce it.

On the other hand,

in all ﬁgures, when the phe-
nomenon of herding behavior emerges, the high-M phase
is strongly aﬀected. In spite of the number of strategies
is huge, this happens because the number of strategies
that the agents actually use is small when compared to
the number of agents.

Moreover, one should also notice that the value of αc is
almost the same in all simulations when herding behavior
is present. However, the value of αc in this situation is
larger than the value found in the standard MG.

V. FINAL REMARKS.

In this note, we have presented a new version of the
standard MG with local interactions that emerge due to
the presence of herding behavior. The herding behavior
here arises since the agents that play the game some-
times do not believe in their own strategies and prefer
to follow the most informed agents that belong to their
neighborhood. As it been already pointed out, this kind
of behavior is rational and justiﬁed by the economic the-
ory [24].

Using this framework, we have found that the presence
of herding behavior may aﬀect both the low-M phase and
the high-M phase. In particular, if one thinks the mi-
nority game as a model of ﬁnancial market[25], then the
results of this modiﬁed model agrees with the results also
found in the economics [22] and econophysics [23] liter-
ature. Finally, we show that that the well known curve
volatility versus memory, which caracterizes the phases
of a minority game, is a monotone decreasing curve.

II. THE MG WITH HERDING BEHAVIOR

The game considered here has a framework quite sim-
ilar to the standard one presented in [1]. The diﬀerence
is described bellow. In each time step, each agent looks
for the most informed agent located in his/her neighbor-
hood. The most informed agent here is the one that has
the highest scored strategy. Then, each agent compares
his/her highest scored strategy with the highest scored
strategy of his/her most informed neighbor. If the agent’s
highest scored strategy is higher scored than the highest
scored strategy of the most informed agent in his/her
neighborhood, then he/she follows his/her own strategy.
Otherwise, he/she follows his/her most informed neigh-
bor highest strategy.

III. THE NOTION OF NEIGHBORHOOD

. The notion of neighborhood is provided by one of the
following networks: (1) a regular network; (2) a random
network [18] or (3) a small world network [19, 20]. While
the regular network and the random network are chosen
to be used as references, the small world network is cho-
sen since it presents a topology that is likely to happen in
real situations of social interaction [21]. Then, using one
of these network structures, each agent of the minority
game is located in a node of the network.

IV. RESULTS.

Figures 1, 2, 3 and 4 present the main results of this pa-
per. In all ﬁgures, we have plotted σ2/N as a function of
α = 2M /N for the coin toss market, for the standard mi-
nority game and for the minority game with the presence
of herding behavior. The diﬀerence among them is the
structure of neighborhood where in each ﬁgure the neigh-
borhood is provided by a diﬀerent network. In these ﬁg-
ures, all simulations used the number of agents N = 101,
the number of strategies S = 2 and the time horizon
T = 10000. In ﬁgures 1, 2 and 4, K is the number of
“regular” neighbors – a parameter that arises in regular
and small world networks. In ﬁgures 2, 3 and 4, p is the
probability of two agents being connected – a parameter
that arises in random graphs and small world networks.
First of all, one may notice that in the presence of herd-
ing behavior, the volatility of the system is much larger
than the volatility of the standard MG. This happens be-
cause the presence of herding behavior generates a crowd
in the MG, i.e., a large groups of agents using the same
strategy. This fact has been studied in economic the-
ory [22] and econophysics [23], which show that herding
behavior may be a source of large price movements and
also crashes.

In all ﬁgures, up to a certain point of the presence
of herding behavior, the slope of the low-M phase is not
modiﬁed and this phase is clear in almost all simulations.

−1

10

−2

10

−1

10

2

0
10
2M/N

1
10

2
10

0
10
2M/N

1
10

2
10

−1

10

−2

10

−1

10

2

FIG. 1: The ratio σ
/N . We com-
pare here the standard MG with the modiﬁed MG presented
in this paper using regular networks.

/N as a function of α = 2

M

/N as a function of α = 2

FIG. 3: The ratio σ
/N . We com-
pare here the standard MG with the modiﬁed MG presented
in this paper using small world networks with the basic struc-
ture provided by a regular network with K = 2 neighbors.

M

3
10

2
10

0
10

/

N
2
σ

1
10

3
10

2
10

0
10

/

N
2
σ

1
10

Coin toss market
Standard MG
K=2
K=4
K=8
K=16
K=32

Coin toss market
Standard MG
p=0.1
p=0.2
p=0.3
p=0.4
p=0.5

3
10

2
10

0
10

/

N
2
σ

1
10

3
10

2
10

1
10

0
10

3

Coin toss market
Standard MG
K=2 and p=0.1
K=2 and p=0.2
K=2 and p=0.3
K=2 and p=0.4
K=2 and p=0.5

Coin toss market
Standard MG
K=16 and p=0.1
K=16 and p=0.2
K=16 and p=0.3
K=16 and p=0.4
K=16 and p=0.5

−1

10

−2

10

−1

10

2

0
10
2M/N

1
10

2
10

−1

10

−2

10

0
10

1
10

2
10

−1

10

2

/N . We com-
FIG. 2: The ratio σ
pare here the standard MG with the modiﬁed MG presented
in this paper using random networks.

/N as a function of α = 2

M

/N as a function of α = 2

/N . We com-
FIG. 4: The ratio σ
pare here the standard MG with the modiﬁed MG presented
in this paper using small world networks with the basic struc-
ture provided by a regular network with K = 16 neighbors.

M

4

[1] D. Challet and Y. C. Zhang, Physica A 246, 407 (1997).
[2] W. B. Arthur, American Economic Review 84, 406

(2005).

[15] L. Shang and X. F. Wang, Forthcoming in Physica A

(1994).

[3] N. F. Johnson, P. Jeﬀeries, and P. M. Hui, Financial mar-
ket complexity (Oxford University Press, Oxford, 2003).
[4] A. C. C. Coolen, The mathematical theory of minority

games (Oxford University Press, Oxford, 2005).

[5] D. C. abd M. Marsili and Y. C. Zhang, Minority games

(Oxford University Press, Oxford, 2005).

[6] R. Savit, R. Manuca, and R. Riolo, Physical Review Let-

ters 82, 2203 (1999).

[7] M. Paczuski, K. E. Bassler, and A. Corral, Physical Re-

view Letters 84, 3185 (2000).

[8] T. Kalinowski, H.-J. Schulz, and M. Briese, Physica A

277, 502 (2000).

[9] S. M. P. D. L. Rios, Physica A 303, 217 (2002).
[10] A. Galstyan and K. Lerman, Physical Review E 66,

015103 (2002).

A 321, 300 (2003).

483 (2004).

635 (2004).

[12] H. F. Chau, F. K. Chow, and K. H. Ho, Physica A 332,

[13] Y. Li and R. Savit, Physica A 335, 217 (2004).
[14] E. Burgos, H. Ceva, and R. P. J. Perazzo, Physica A 337,

[16] I. Caridi and H. Ceva, Physica A 339, 574 (2004).
[17] M. Kirley, Forthcoming Physica A (2005).
[18] P. Erd´os and A. R´enyi, Bulletin of the International Sta-

tistical Institute 38, 343 (1960).

[19] D. J. Watts and S. H. Strogatz, Nature 393, 440 (1998).
[20] D. J. Watts, Small worlds: the dynamics of networks be-
tween order and randomness (Princeton University Press,
Princeton, 1999).

[21] D. O. Cajueiro, Physical Review E 72, 047104 (2005).
[22] I. H. Lee, Review of Economic Studies 65, 395 (1998).
[23] D. Sornette and A. Johansen, Physica A 245, 411 (1997).
[24] A. Banerjee, Quartely Journal of Economics 107, 797

[25] D. Challet, M. Marsili, and Y. C. Zhang, Physica A 299,

(1992).

228 (2001).

[26] In a ﬁnancial market, for instance, this means to buy or

[27] A strategy deﬁnes which action to take in each state.
[28] The strategies with highest scores are those which were

successful in the previous turns of the game.

[29] For details, see, for instance, [24].

[11] h. J. Quan, B. H. Wang, P. M. Hui, and L. X. S, Physica

to sell an asset.

