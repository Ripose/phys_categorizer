6
0
0
2
 
l
u
J
 
2
1
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
3
0
1
7
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Routines for the diagonalization of complex matrices
T. Hahna

aMax-Planck-Institut f¨ur Physik
F¨ohringer Ring 6, D–80805 Munich, Germany

MPP-2006-85

Jacobi-type iterative algorithms for the eigenvalue decomposition, singular value decomposition, and Takagi
factorization of complex matrices are presented. They are implemented as compact Fortran 77 subroutines in a
freely available library.

1. Introduction

This note describes a set of routines for the
eigenvalue decomposition, singular value decom-
position, and Takagi factorization of a complex
matrix. Unlike many other implementations, the
current ones are all based on the Jacobi algo-
rithm, which makes the code very compact but
suitable only for small to medium-sized problems.
Although distributed as a library, the routines
are self-contained and can easily be taken out of
the library and included in own code, removing
yet another installation prerequisite. Owing to
the small size of the routines (each about 3 kBytes
source code) it is possible, in fact quite straight-
forward, to adapt the diagonalization routine to
one’s own conventions rather than vice versa.

2. Mathematical Background

∈

1

2.1. Eigenvalue Decomposition

The eigenvalue decomposition of a nonsingular
n takes the form

matrix A

Cn

×

U A U −

= diag(σ1, . . . , σn) , σi

C .

(1)

∈

The eigenvalues σi and transformation matrix U
can be further characterized if A possesses certain
properties:

A = A† (Hermitian): U −

1 = U †, σi

A = AT (symmetric): U −

1 = U T .

•

•

2.2. Singular Value Decomposition

The singular value decomposition (SVD) can
n,

be applied to an arbitrary matrix A

Cm

×

∈

where m > n is assumed (for m < n, substitute
AT for A in the following):

V ∗A W † = diag(σ1, . . . , σn) ,
Cn

1 = W †

m, W −

Cn

V

×

∈

n, σi

×

IR .

∈

∈

(2)

V consists of orthonormal row vectors, i.e. is also
unitary for m = n.

2.3. Takagi Factorization

The Takagi factorization [1,2] is a less known
diagonalization method for complex symmetric
n,
matrices A = AT

Cn

×

∈

U ∗A U † = diag(σ1, . . . , σn) ,

(3)

1

U −

= U † ,

σi > 0 .

Although outwardly similar to the eigenvalue de-
composition of a Hermitian matrix, it is really the
special case of an SVD with V = W ∗, as it applies
even to singular matrices. Note also that the left
and right factors, U ∗ and U †, are in general not
inverses of each other.

One might think that the Takagi factorization
is merely a scaled SVD. For example, the matrix

A =

1
2
(cid:18)

2
1
(cid:19)

IR,

∈

has the SVD

V T diag(σ1, σ2)W =
1
√2
1
√2 !

1
√2
1
√2 −

3
0
(cid:18)

 

T

0
1
(cid:19)  

1
√2
1
√2

−

1
√2
1
√2 !

1

(4)

(5)

2

T. Hahn

(6)

(7)

(8)

which can indeed be scaled to yield

T

U T diag(σ1, σ2)U =
1
√2
i
√2 !

1
√2
i
√2 −
But consider the matrix

3
0
(cid:18)

 

A =

1
0
(cid:19)
which has the SVD

0
1
(cid:18)

0
1

(cid:19)  

1
√2
i
√2 −

1
√2
i
√2 !

.

1
0
(cid:18)

T

0
1
(cid:19)

1 0
0 1

0 1
1 0

(cid:18)
whereas its Takagi factorization is

(cid:19) (cid:18)

(cid:19)

1
√2
i
√2

 

−

T

1
√2
i
√2 !

1
0
(cid:18)

0
1

(cid:19)  

−

1
√2
i
√2

1
√2
i
√2 !

.

(9)

Although occurring less frequently than the
eigenvalue decomposition, the Takagi factoriza-
tion does have real applications in physics, e.g. in
the diagonalization of mass matrices of Majorana
fermions.

3. Jacobi Algorithm

×

The Jacobi algorithm [3] consists of iteratively
2 diagonalization formula un-
applying a basic 2
×
til the entire n
n matrix is diagonal. It works
in several ‘sweeps’ until convergence is achieved.
In each sweep it rotates away the non-zero oﬀ-
2 algorithm. Ev-
diagonal elements using the 2
ery such rotation of course creates other non-zero
oﬀ-diagonal elements. It can be shown, however,
that the sum of the absolute values of the oﬀ-
diagonal elements is reduced in each sweep. More
precisely, the Jacobi method has quadratic con-
vergence [4].

×

−

×

−

Convergence is in most cases achieved in 6

10
n matrix translates into
sweeps, which for an n
20)n3 multiply–add operations to obtain the
(12
30)n3 operations in-
eigenvalues only and (18
cluding the eigenvectors [5]. This compares with
2
3 n3+30n2 operations for the Householder/QL al-
gorithm when just the eigenvalues are sought and
4
3 n3 + 3n3 when also the eigenvectors are needed.

−

For large n, the Jacobi algorithm is thus not
the most eﬃcient method. Nevertheless, for small
to medium-sized problems the Jacobi method is
a strong competitor, in particular as it has the
following advantages:

•

•

•

It is conceptually very simple and thus very
compact.

It delivers the eigenvectors at little extra
cost.

The diagonal values are accurate to ma-
chine precision and, in cases where this is
mathematically meaningful, the vectors of
the transformation matrix are always or-
thogonal, almost to machine precision.

For the various diagonalization problems dis-
cussed before, only the core 2
2 diagonalization
formula changes, whereas the surrounding Jacobi
algorithm stays essentially the same.

×

The famous Linear Algebra Handbook gives an
explicit implementation of the Jacobi algorithm
for real symmetric matrices [4], taking particular
care to minimize roundoﬀ errors through mathe-
matically equivalent variants of the rotation for-
mulas. The present routines are closely patterned
on this procedure. For the Takagi factorization,
the use of the Jacobi algorithm was ﬁrst advo-
cated in two conference papers [6,7] which give
only few details, however.

4. The 2

2 Formulas

×

4.1. Eigenvalue decomposition

Using the ansatz

U =

c1
t2c2

t1c1
c2

(cid:18)

−

(cid:19)

(10)

the equation U A = diag(σ1, σ2) U becomes

σ1 = A11 + t1A21 = A22 +

A12 ,

(11)

σ2 = A11

A21 = A22

t2A12 .

(12)

1
t2

−

1
t1

−

Solving for t1 and t2 yields

t1 =

A12
∆ + D

,

t2 =

A21
∆ + D

,

(13)

Routines for the diagonalization of complex matrices

∆ =

(A11

A22) ,

−

D =

∆2 + A12A21 .

1
2

±

(14)

(15)

p

For the numerical stability it is best to choose the
sign of D which gives t1,2 the larger denominator.
This corresponds to taking the smaller rotation
angle (< π/4). The diagonal values are

σ1 = A11 + δ ,

σ2 = A22

δ ,

−

δ =

A12A21
∆ + D

.

In order that U smoothly becomes unitary as A
becomes Hermitian, we choose

c1 = c2 =

1
√1 + t1t2

,

which guarantees a unit determinant.

4.2. Takagi Factorization

Substituting the unitary ansatz

U =

c
t c e−

iϕ

(cid:18)

−

t c eiϕ
c

(cid:19)

,

c, t

IR ,

(18)

∈

into U ∗A = diag(σ1, σ2) U and introducing

˜σ1 = e

˜σ2 = e−

iϕσ1 ,
iϕσ2 ,

˜A11 = e
˜A22 = e−

iϕA11 ,
iϕA22 ,

we arrive at

˜σ1 = ˜A11 + tA12 = ˜A22 +

A12 ,

˜σ2 = ˜A11

A12 = ˜A22

tA12 .

1
t

−

1
t

−

Comparing with Eqs. (11) and (12), the solution
can be read oﬀ easily:

,

A12
˜∆ + ˜D
1
( ˜A11
2

t =

˜∆ =

˜D =

±

q

˜A22) ,

−
˜∆2 + A2

12 .

Again it is best for numerical stability to choose
the sign of ˜D which gives the larger denominator
for t. The diagonal values become

σ1 = A11 + t A12 e−

iϕ,

(19)

(20)

(21)

(22)

(23)

(24)

(25)

(26)

σ2 = A22

t A12 eiϕ.

−

The assumption t
IR ﬁxes the phase ϕ. It re-
∈
quires that A12 and ˜∆ have the same phase, i.e.
A12. Since both eiϕ and its
˜∆ = (real number)
·
conjugate appear in ˜∆, we try the ansatz

eiϕ = αA12 + βA∗12

(16)

and choose coeﬃcients to make the A∗12 term in

˜∆

∝

(αA11

(βA11

β∗A22)A12+
α∗A22)A∗12

−

−

(17)

vanish. This is achieved by α = A∗11 and β = A22
which also makes the coeﬃcient of A12 real. Thus,

3

(27)

(28)

(29)

(30)

eiϕ =

A∗11A12 + A22A∗12
A∗11A12 + A22A∗12
|

|

.

5. Singular Value Decomposition

Even though there exists an algorithm known
as ‘One-Sided Jacobi’ [8] to perform an SVD, this
method is not employed here as there is a simpler
method with the same numerical characteristics.

Squaring the deﬁning Eq. (2) gives

W A†V T V ∗AW † = diag(σ2

1, . . . , σ2

n) .

(31)

As V has orthonormal rows, the σ2
i and the right-
transformation matrix W can be found from an
eigenvalue decomposition of the Hermitian ma-
trix A†A. The left-transformation matrix V is
obtained from

Vik =

(AW †)ki ,

σi

= 0 .

(32)

1
σi

Eq. (2) makes no statement about the vectors Vik
corresponding to σi = 0. For this subspace we
choose a basis which is orthonormal with respect
to the vectors for non-zero σi. Speciﬁcally, we
apply Gram–Schmidt to Vik = δij, where j counts
from m downward. Values of j for which the norm
of the resulting vector becomes too close to zero
are skipped.

6
4

6. Implementation

All routines described in the following include a
ﬁle diag.h in which the single preprocessor con-
stant MAXMAT is deﬁned. It is used for allocating
the space needed to hold intermediate results and
thereby eﬀectively determines the maximum size
the input and output matrices may have. This
is necessary because Fortran 77 has no dynamic
memory allocation.

When passing matrices as arguments, the con-
vention is generally that each matrix is followed
by its leading dimension in the argument list, i.e.
the m in A(m,n). In this way it is possible to
diagonalize submatrices with just a diﬀerent in-
vocation. Needless to add, the leading dimension
must be at least as large as the corresponding
matrix dimension.

6.1. Hermitian Eigenvalue Decomposition

Hermitian matrices are diagonalized with

subroutine Eigensystem(n, A,ldA,

d, U,ldU, sort)

integer n, ldA, ldU, sort
double complex A(ldA,n), U(ldU,n)
double precision d(n)

The arguments are as follows:

T. Hahn

6.2. Symmetric Eigenvalue Decomposition
The second special case is that of a complex

symmetric matrix:

subroutine SEigensystem(n, A,ldA,

d, U,ldU, sort)

integer n, ldA, ldU, sort
double complex A(ldA,n), U(ldU,n)
double complex d(n)

The arguments have the same meaning as for
Eigensystem, except that A’s diagonal elements
are not assumed real and sorting occurs with re-
spect to the real part only.

6.3. General Eigenvalue Decomposition

The general case of the eigenvalue decomposi-

tion is implemented in

subroutine CEigensystem(n, A,ldA,

d, U,ldU, sort)

integer n, ldA, ldU, sort
double complex A(ldA,n), U(ldU,n)
double complex d(n)

The arguments are as before, except that A has
to be ﬁlled completely.

6.4. Takagi Factorization

The Takagi factorization is invoked in almost

•

•

•

•

•

n (input), the matrix dimension.

the same way as SEigensystem:

A (input), the matrix to be diagonalized.
Only the upper triangle of A needs to be
ﬁlled and it is further assumed that the di-
agonal elements are real. Attention: the
contents of A are not preserved.

subroutine TakagiFactor(n, A,ldA,

d, U,ldU, sort)

integer n, ldA, ldU, sort
double complex A(ldA,n), U(ldU,n)
double precision d(n)

d (output), the eigenvalues.

U (output), the transformation matrix.

sort (input), a ﬂag that determines sorting
of the eigenvalues:

0 = do not sort,

1 = sort into ascending order,
1 = sort into descending order.

−

The ‘natural’ (unsorted) order is deter-
mined by the choice of the smaller rotation
angle in each Jacobi rotation.

The arguments are as for SEigensystem. Also
here only the upper triangle of A needs to be ﬁlled.

6.5. Singular Value Decomposition

The SVD routine has the form

subroutine SingularValues(m, n, A,ldA,

d, V,ldV, W,ldW, sort)

integer m, n, ldA, ldV, ldW, sort
double complex A(ldA,n)
double complex V(ldV,m), W(ldW,n)
double precision d(n)

with the arguments

Routines for the diagonalization of complex matrices

5

m, n (input), the dimensions of A, m > n.

7. X. Wang, S. Qiao, PDPTA 2002 conference

proceedings Vol. I,
http://www.dcss.mcmaster.ca/

qiao/publications/pdpta02.ps.gz
8. J.C. Nash, Computer J. 18 (1973) 74.

∼

•

•

•

•

•

•

A (input), the m
is sought.

×

n matrix of which the SVD

d (output), the singular values.

V (output), the left-transformation matrix
(n

m).

W (output), the right-transformation matrix
(n

n).

×

×

sort (input), the sorting ﬂag with values as
above.

7. Summary

The Fortran codes described here are avail-
able from http://www.feynarts.de/diag. Af-
ter downloading and unpacking the tar ﬁle, a li-
brary containing all routines can be built by typ-
ing “make.” Since the routines are self-contained
and quite compact, it should be straightforward
to use them outside of the library. All routines
are licensed under the LGPL.

Acknowledgements

TH thanks the National Center for Theoretical
Studies, Hsinchu, Taiwan, for warm hospitality
during the time this work was carried out.

REFERENCES

1. T. Takagi, Japanese J. Math. 1 (1927) 83.
2. R.A. Horn, C.A. Johnson, Matrix Analysis,
Cambridge University Press, 1990, p. 201 f.

3. C.G.J. Jacobi, Crelle J. 30 (1846) 51.
4. H. Rutishauser, Contribution II/1, in:

Handbook for Automatic Computation, ed.
J.H. Wilkinson, C. Reinsch, Springer, 1971.

5. W.H. Press et al., Numerical Recipes in
Fortran, 2nd ed., Cambridge University
Press, 1992, Chapter 11.

6. L. De Lathauwer, B. De Moor, EUSIPCO

2002 conference proceedings,
https://www.ensieta.fr/e3i2/intranet/
Confs/Eusipco02/articles/paper323.html

