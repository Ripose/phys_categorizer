Systematic Computational Inaccuracy in Free Energy Diﬀerences
and Other Nonlinear Quantities

Daniel M. Zuckerman∗ and Thomas B. Woolf∗†
∗Department of Physiology and †Department of Biophysics,
Johns Hopkins University School of Medicine, Baltimore, MD 21205
dmz@groucho.med.jhmi.edu, woolf@groucho.med.jhmi.edu
(January 26, 2013)

Abstract

Systematic inaccuracy is inherent in any computational estimate of a non-
linear average, such as the free energy diﬀerence ∆F between two states or
systems, because of the availability of only a ﬁnite number of data values,
N . In previous work, we outlined the fundamental statistical description of
this “ﬁnite-sampling error.” We now give a more complete presentation of
(i) rigorous general bounds on the free energy and other nonlinear averages,
which underscore the universality of the phenomenon; (ii) asymptotic N

→
expansions of the average behavior of the ﬁnite-sampling error in ∆F
∞
estimates; (iii) illustrative examples of large-N behavior, both in free-energy
and other calculations; and (iv) the universal, large-N relation between the
average ﬁnite-sampling error and the ﬂuctuation in the error. An explicit role
is played by L´evy and Gaussian limiting distributions.

2
0
0
2
 
g
u
A
 
3
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
5
1
0
8
0
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

1

I. INTRODUCTION

Because of the substantial interest in free energy diﬀerence ∆F calculations (e.g., [1–9]),
this report discusses the unavoidable error that arises from use of a ﬁnite amount of computer
time. There is a tremendous range of applications for computational ∆F estimates in phys-
ical, chemical, and biological systems. Examples include computations relating crystalline
lattices [3,4], the behavior of magnetic models [4,10], and biomolecular binding events —
of ligands to both DNA and proteins (e.g., [11–13,1]). Computations of ∆F , moreover, are
formally equivalent to calculating the temperature dependence F (T ) [4]. Most recently, it
has been pointed out that ∆F calculations are required to convert experimental data from
nonequilibrium single-molecule pulling measurements to free energy vs. extension proﬁles
[5,8]; see also [7].

For some time, it has been appreciated that computational estimates of ∆F are inher-
ently subject to “ﬁnite-sampling-error” [14,15] — that is, to bias whenever the computation
is of ﬁnite length. Figure 1 illustrates the phenomenon for a mathematical model and for a
biological system [16], emphasizing the universality of ﬁnite-sampling errors. Because these
inaccuracies can be many times kBT (see Fig. 1 and Ref. [9]) — especially in the important
context of biomolecular calculations where large system sizes limit the quantity of data avail-
able for analysis — there is a strong motivation to understand and overcome these errors.
Ferrenberg, Landau and Binder showed that ﬁnite-sampling errors accompanying suscepti-
bility computations can be understood on the basis of elementary statistical principles [17];
however, the errors in non-linear averages like ∆F apparently had remained without an
explicit theoretical basis until recently [18]. In a recent monograph, in fact, Landau and
Binder note that ﬁnite-sampling errors are “generally given inadequate attention” [19].

This report both provides fuller details of the theory outlined in [18], and also presents
new results. Our report includes (i) a rigorous proof that the expected value of a ﬁnite-
data ∆F estimate (∆Fn) bounds the true free energy — independent of the distribution of
underlying work values; (ii) full derivations of the asymptotic expressions for ∆Fn as n
→ ∞
for arbitrary — including long-tailed — distributions of the work (W ) data used to estimate
∆F . (iii) analogous derivations for the root-mean-square and related “geometric” non-linear
averages; (iv) derivation and numerical demonstration of the universal asymptotic relation
between ∆Fn and its ﬂuctuation. As in our brief report [18], the present discussion makes
use of mathematical results regarding the convergence — to “stable” limiting distributions
[20–22], also known as L´evy processes (e.g., [23]) — of the distributions of sums of variables.
In outline, the paper now proceeds to Sec. II where formal groundwork for the discussion
is laid. Section III rigorously proves the true free energy ∆F is bounded by ∆Fn, the
expected value of a free-energy estimate based on a ﬁnite quantity of data; analogous bounds
apply for arbitrary non-linear averages. Derivations of the asymptotic series for ∆Fn are
given in sections IV and V, while Section VI derives the universal relation between ∆Fn and
its ﬂuctuation. We conclude with a summary and discussion of the results in Section VII.

II. FREE-ENERGY ESTIMATES FROM FINITE SAMPLES

Since the work of Kirkwood [24], it has been appreciated that the free energy diﬀerence,
H1 is given by a non-linear average,

1, of switching from a Hamiltonian

H0 to

∆F0

≡

→

∆F

2

∆F =

kBT log [

exp (

W0

1/kBT )

−

h

−

→

i0 ] ,

(2.1)

H0 to

where kBT is the thermal unit of energy at temperature T and W0
1 is the work required
to switch the system from
H1. The angled brackets indicate an average over switches
starting from conﬁgurations drawn from the equilibrium distribution governed by
H0. In
− H0(x) for a start (and end)
instantaneous switching the work is deﬁned by W0
conﬁguration x. However, gradual switches requiring a “trajectory”-based work deﬁnition
may also be used, as was demonstrated by Jarzynski [2,15]. In this latter case, one requires
H0 and
a Hamiltonian which interpolates between
H1(x)

H1; a common choice is
− H0(x)] ,

≡ H0(x) + λ [

H1(x)

(λ; x)

(2.2)

1 =

H

→

→

where λ is a switching parameter that varies from zero to one. The work performed in
switching gradually from

H1 along a trajectory (λ(t); x(t)) is given by

[
H

(λi; xi
−

1)

− H

(λi

1; xi
−

−

1)] ,

(2.3)

H0 to
1 =

→

W0

Xi

1 is the (unique) ﬁnal conﬁguration for which λ =
1 — i.e., the last conﬁguration before λ is incremented to λi. In other words, the work is

where the subscripted conﬁguration xi
−
λi
computed as the sum of those energy increments resulting only from changes in λ.

−

Whenever a convex, nonlinear average such as (2.1) is estimated computationally, that
result will always be systematically biased [25] because one has only a ﬁnite amount of
data — say, N work values. The bias results from incomplete sampling of the smallest
(or most negative) W0
1 values: these values dominate the average (2.1) and cannot be
sampled perfectly for ﬁnite N, regardless of the W0
1 distribution. This is true even for a
rectangular distribution; the sole exception is the trivial δ function, single-point probability
density. Because of the undersampling of small work values, a running estimate of ∆F will
typically decline as data is gathered, as one sees in the “staircase” plots of Fig. 1. Such
considerations led Wood et al. [14] to consider the block-averaged n-data-point estimate of
the free energy based on N = mn total work values

, namely,

W (k)

→

→

∆Fn = lim
→∞

m

m

1
m

Xj=1 −

kBT log

1
n





Xk=(j
−

1)n+1

exp (

W (k)/kBT )

.

−





{

}

jn

It represents the expected value of a free energy estimate from n data points — that is, of

Fn =

−

kBT log

h (cid:16)

e−

W1/kB T +

+ e−

Wn/kB T

· · ·

.

n
i
as σ2

(cid:17).
∆F

w/2nkBT , where σ2
Wood et al. estimated the lowest order correction to ∆F
w
is the variance in the distribution of work values, W [14]. Ferrenberg, Landau and Binder
discussed analogous issues for the magnetic susceptibility [17,19].

≡

∞

The derivations below employ continuum expressions simpliﬁed by the deﬁnitions

w

W/kBT,

f

∆F/kBT,

≡

≡
In terms of the probability density ρw of work values, which is normalized by
the free energy is given by the continuum analog of (2.1),

fn ≡

∆Fn/kBT .

(2.6)

dwρw(w) = 1,

R

(2.4)

(2.5)

3

The ﬁnite-data average free energy, following (2.4) must apply the logarithm “before” the
average of the n Boltzmann factors, and one has

f = ∆F/kBT =

log

dw ρw(w) e−

w

.

−

(cid:20)Z

(cid:21)

fn =

[dwi ρw(wi)] log

n

− Z

Yi=1

1
n

"

n

Xi=1

wi

e−

.

#

III. BLOCK-AVERAGED ESTIMATES AS RIGOROUS BOUNDS

In reference [9], the authors observed that the free energy appeared to be bounded

according to

∆F

∆Fn ,

any n .

≤

∆F1 [10] for
Here we prove this inequality, which extends the previous bound ∆F
an arbitrary distribution of work values. That is, the bound applies when the probability
density is multimodal, unimodal, or simply rectangular.

≤ h

i ≡

W

In fact, our proof will show that (3.1) is a special case of a more general inequality that
depends solely on the convexity and monotonicity of the function used to form a nonlinear
average: in the case of ∆F the function is the exponential — see (2.1); the root-mean-square
is another example, when the function is g(x) = x2. In the remainder of this section, we
use the mathematical convention that upper-case letters (e.g., X) indicate random variables
whose particular values are speciﬁed by lower-case letters (e.g., x).

The new bounds are generalizations of Jensen’s inequality (see [26]), a fundamental
property of convex functions with a host of applications including in information theory
[27]. Jensen’s inequality relates the expected value of a convex function g of a random
variable to the same function of the expected value of its argument according to

i ≥
where the expectation value is deﬁned in the usual way for an arbitrary function A as

h

h

i

g(X)

g(

X

) ,

=

A(X)

=

dx ρ(x) A(x) ,

A
i

h

h

i

Z

and ρ is the probability density function. By applying g−
re-stated in terms of non-linear and linear averages, respectively,

1 to (3.2), the inequality can be

g

X

g−

1 (

g(X)

)

X

,

i
1 is unique). Note that the
with the additional constraint that g be increasing (so that g−
inequality (3.4) can easily be generalized by applying the inverse of a diﬀerent increasing
function (say, h−

1) to (3.2).

≥ h

≡

h

i

i

h

We now state and prove the new “generalized Jensen’s inequalities.”

Theorem:

4

(2.7)

(2.8)

(3.1)

(3.2)

(3.3)

(3.4)

{

Consider estimates
x1, x2, . . . , xn}
X

g
n =

h

i

Note that

X

g
1 =

h

i

and

X

h

i

∞

Z
X

h

i

· · · Z
g
=

for

the non-linear average
, the expectation of which may be written as

X

h

i

g based on samples of size n,

dx1 ρ(x1)

dxn ρ(xn) g−

1( [ g(x1) +

g(xn) ] / n) .

(3.5)

· · ·

X

g. Then the new inequalities, generalizing (3.4), are

h
X

i
g
n ≥ h

i

h

X

g
n

i

−

1 .

Strict inequality obtains whenever the random variable X is not limited to a single value
(i.e., whenever the probability density ρ is not a single Dirac delta function). The direction
of the inequality is reversed for decreasing convex functions, for instance yielding (3.1) for
g(x) = exp (

x/kBT ).

−

i

X

) =

xi}

Proof:
Note ﬁrst that
h
set” Sn of all possible n-samples
probability density ρn(
set Sn
in Sn, if one assigns equal weights ρn/n to each of the n available (n
x1, x3, x4, . . . , xn}
deletion of a single element — namely,
one arrives at Sn
the density ρn, and may be seen by considering the density of a particular (n
ˆx
}

g
n is deﬁned in (3.5) as the non-linear average based on the “weighted
. The weight of each n-sample is of course its
x1, . . . , xn}
{
n
i=1 ρ(xi). We will require an explicit construction of the
1 from Sn, which fortunately is straightforward: for every n-sample with weight ρn
1)-samples given by
, and so on —
1. The correctness of this construction follows from the factorizability of
1)-sample,

, which can be constructed from n diﬀerent deletions:

x2, x3, . . . , xn}

ˆx1, . . . , ˆxn

1}

−

−

=

Q

{

{

{

{

{

−

−

−

,

ρn

1(

−

ˆx

) =

{

}

dx ρn(x, ˆx1, . . . , ˆxn

1) +

dx ρn(ˆx1, x, ˆx2, . . . , ˆxn

1)

−

1
n (cid:20)Z
+

=

1
n "

n

Z

−

Z
dx ρn(ˆx1, . . . , ˆxn

+

· · ·

Z

dx ρ(x)

ρ(ˆxi)

=

ρ(ˆxi).

#

n

1

−

Yi=1

1, x)

(cid:21)

−
1

−

n

Yi=1

Because of this construction of Sn

1 from Sn, it is suﬃcient to show that the single-sample

non-linear average of an arbitrary n-sample, namely,

−

un(

xi}

{

) = g−

1

Xi=1
1 based on the n available (n

n

1
n

 

g(xi)

!

−

exceeds the average un
as above. Note that

−

{
which follows immediately from (3.5).

h

un(

)

xi}

in =

X

h

g
n ,

i

1)-samples constructed from deletions,

To complete the proof, observe that the single-sample non-linear average can be re-

written in terms of smaller samples:

(3.6)

(3.7)

(3.8)

(3.9)

5

un(

xi}

{

) = g−

1

n

Xj=1

1
n





1

−

n

1

n

=j
Xi

g(xi)

.





(3.10)

1 times (whenever
= 1), and hence is properly weighted as in (3.8). The expression may be further re-written
xi}[j] the original n-sample with the jth element deleted. To each of
xi}[j]).
1 into the right-hand-side

This identity may be illustrated by considering g(x1) which occurs n
j
if we denote by
these smaller samples, there corresponds a single-sample, non-linear average un
Applying g to both sides of (3.8) and substituting the result for n
of (3.10), we then have

1(

−

−

{

{

−

un(

xi}

) = g−

1

g

un

1(

xi}[j] )

.

{


i

If we now consider Un
1 to be a random variable with a discrete, n-point distribution,
we can apply the original non-linear-average inequality (3.4) to the right-hand side of (3.11),
and obtain the desired result

1 ↔

Xj=1

un





{

−

−

−

h

(3.11)

n

1
n

un(

)

xi}

{

un

1i[j] ,

−

≥ h

(3.12)

h· · ·i[j] is performed over the discrete distribution comprised of all un

where the average
values obtained from applying (3.8) to the n sets
when the left-hand-side is averaged as in (3.9), the construction of Sn
that the average over all n-samples on the right-hand side of (3.12) results in
hence (3.6).

xi}[j]. This completes the proof because
1 from Sn guarantees
X
1 and

g
n

{

i

h

−

−

−

1

The result applies to any probability density ρ because no assumptions were made re-

garding the distribution.

IV. ASYMPTOTIC BEHAVIOR: FINITE MOMENTS CASE

A. Formal Development of the Expansion

It is possible to generate a formal expansion for the ﬁnite-data estimate fn in terms of n−
for an arbitrary distribution of work values ρw. In this section we consider the case where
w distribution are ﬁnite. Motivated
the second and some higher moments of the z = e−
w variables, we
by the central and related limit theorems [28,20,22] for the sum of the e−
introduce a change of variables which will permit the development of a 1/n expansion for
fn. In particular, we deﬁne

1

y = (e−

w1 +

+ e−

wn

ne−

f ) / b1n1/α ,

· · ·

−

2 is an exponent characterizing the distribution of the variable
w. The requirement that ∆F be ﬁnite in (2.7) further implies α > 1. The ﬁnite-data free

where b1 is a constant and α
e−
energy diﬀerence can now be written

≤

(4.1)

(4.2)

fn =

∞

dy ρn(y) log

e−

f +

− Z
−

cna

b1
na y

,

!

 

6

6
6
(α
where c = exp (
−
y normalized appropriately via

f )/b1, a

≡

−

1)/α < 1/2, and ρn is the probability density of the variable

dy ρn(y) = 1 .

∞

cna

Z

−

Note that a is always positive because α > 1.

The expansion of fn proceeds by ﬁrst noting that the sum of any set of independent
random variables, suitably normalized as in (4.1), has a distribution which may be expressed
as a stable (L´evy) distribution function multiplied by a large-n asymptotic expansion [20,29].
In the case of a Gaussian limiting distribution (i.e., α = 2 or the central limit theorem),
f ,
assume the variable z = e−
variance ˆσ2 =
. The normalizing
constant in (4.1) is then b1 = ˆσ. The Boltzmann moments of course diﬀer from the moments
of the distribution of w.

w possesses ﬁnite “Boltzmann moments” — a mean ˆµ = e−

, and higher central moments ˆµp =

ˆµ)p

ˆµ)2

(z

(z

−

−

h

i

h

i

The so-called Edgeworth corrections to the central limit theorem indicate that the vari-

nˆµ)/√nˆσ [cf. (4.1)] is distributed according to [30,31]

able y = (

n
i=1 e−

wi

−

P

ρn(y) = ρG(y; 1)

1 + ν1(y)/√n + ν2(y)/n +
h

· · ·
i

,

for large n, where the remaining terms are higher integer powers of 1/√n and the Gaussian
density is

ρG(y; σ) = exp (

y2/2σ2)/√2πσ .

−

The functions νi, which are deﬁned based upon the Hermite polynomials [30,20], depend
In terms of the cumulants ˆκi (see, e.g., [30]) of the
on the original distribution of e−
distribution of z = e−

w and the Hermite polynomials deﬁned via

w.

dk
dxk ρG(x; 1) = (
−

1)kHk(x) ρG(x; 1) ,

the lowest-order Edgeworth functions are [30,31]

ν1(y) = (ˆκ3/6ˆσ3)H3(y) = (ˆµ3/6ˆσ3)
ν2(y) = (ˆκ4/24ˆσ4)H4(y) + (ˆκ2
ν3(y) = (ˆκ5/120ˆσ5)H5(y) + (ˆκ3ˆκ4/144ˆσ7)H7(y) + (ˆκ3

y3
3y
(cid:16)
3/72ˆσ6)H6(y)

−

(cid:17)

3/1296ˆσ9)H9(y) .

(4.3)

(4.4)

(4.5)

(4.6)

(4.7)

(4.8)
(4.9)

The νi functions are odd or even according to whether i is odd or even, in this α = 2 case.
Before the expansion for fn can be developed, the integral (4.2) must be considered

carefully by dividing it into three parts:

fn =

∞

dy ρn(y) log

e−

f +

−

b1
na y

!

 

f

e−
(cid:16)

cna

Z

−

∞

cna

Z
−
+

=

dy ρn(y) log

+cna

(cid:17)
dy ρn(y) log(1 + y/cna) +

cna
Z
−
f + I(

≡ −

−

cna, cna) + I(cna,

) ,

∞

7

∞

dy ρn(y) log(1 + y/cna)

+cna

Z

(4.10)

(4.11)

where the ﬁrst integral in (4.10) has been evaluated exactly using the normalization of ρn
(4.3) and I represents the latter integrals of (4.10). One can now proceed by using an
expansion for the logarithm in I(

cna, cna) and by bounding terms in I(cna,

).

It is possible to demonstrate rigorously that the second integral in (4.10), I(cna,

),
f for large n. Although, the logarithm cannot be
does not materially contribute to fn −
expanded in a power series for y > cna, the integral can be bounded by expressing the log
as the integral of its derivative:

∞

∞

−

I(cna,

) =

∞

+cna

Z

∞

∞

≤ Z

+cna

dy ρn(y)

dy ρn(y)

1
Z

1
Z

1+y/cna

1+y/cna

dx x−

1

dx x−

1+ǫ =

(4.12)

1
ǫ Z

∞

+cna

dy ρn(y)

1 +

1

,

(4.13)

ǫ

y
cna

−

(cid:19)

(cid:21)

(cid:20)(cid:18)

with 0 < ǫ
of ρn (4.4) and set ǫ = 1. Noting that a = 1/2, one obtains

1. To extract the leading behavior of this bound, one can use the expansion

≤

I(cna,

)

∞

≤

1
c√n Z

∞

+cna

dy ρG(y; 1)

1 + ν1(y)/√n + ν2(y)/n +
h

· · ·

i

y .

(4.14)

Using the asymptotic properties of the error function [30], one can show that the strongest
n dependence of I(cna,

) is no stronger than

∞

n exp (

c2n/2) .

−

The leading behavior of fn −
cna, cna). Noting again that a = 1/2 in this case, we may write
−

I(

f is thus expected to result from the ﬁrst integral in (4.10),

I(

c√n, c√n) =

dy ρG(y; 1)

−

+c√n

c√n

Z

−

1 + ν1(y)/√n + ν2(y)/n + ν3(y)/n3/2 +
h

· · ·

(y/c√n)2/2 + (y/c√n)3/3

×

y/c√n
h

−

i

.

(4.16)

− · · ·

i
1/2 raised to any odd
What are the leading terms? There are no terms proportional to n−
power because of symmetry considerations: the νi functions are even for even i. The lead-
1, and the expansion of the ﬁnite-data free-energy
ing terms are thus integer powers of n−
diﬀerence is of the form,

fn = f + ϕ1/n + ϕ2/n2 +

,

· · ·

where the ϕi are constants which depend on the distribution of z = e−

w.

The explicit correction terms to fn −

f may now be obtained. First note that asympo-
totic analysis of the integrals appearing in (4.16) in terms of the error function [30] indi-
cates that the limits of integration may be extended to (
) with errors proportional
c2n/2). Straightforward integration then yields the coeﬃcients of the expansion
to exp (
(4.17), namely,

−∞

, +

∞

−

(4.15)

(4.17)

(4.18)
(4.19)

ϕ1 = ˆσ2/2ˆµ2 ,
(4ˆµˆµ3 −
ϕ2 =
−

9ˆσ4)/12ˆµ4.

8

B. Coeﬃcients for the Gaussian case

When the distribution of work values is Gaussian, ρw(W ) = ρG(W, σw), the Boltzmann
moments and, hence the ϕ coeﬃcients of (4.17), may be computed analytically. Note that
w obeys a Gaussian distribution because z is always non-
one cannot assume that z = e−
negative. The moments follow from straightforward integration, which yields

zp
h

i

=

Z

dW ρw(W )e−

pW/kBT = exp

p2σ2

w / 2(kBT )2

.

(4.20)

h

i

The fn expansion coeﬃcients then follow trivially from substitution into (4.18) and (4.19).
Setting s = σw/kBT , one ﬁnds for the ﬁrst two coeﬃcents

ϕ1 =

ϕ2 =

es2
(cid:16)
−
(cid:16)

1
−
4e3s2

2 ,
(cid:17).
+ 9e2s2

6es2

+ 1

12 .

−

(cid:17).

(4.21)

(4.22)

To compare this with the ﬁnding of Wood et al. for fn −
σw. One ﬁnds ϕ1 ≈
[14].

f , one can expand (4.21) for small
σ2
w/2kBT , which is precisely the ﬁrst-order prediction of Wood et al.

This analytic calculation explicitly indicates the practical shortcomings of the expansion
f is linear in 1/n, the leading coeﬃcients are
(4.17). Although the leading term in fn −
exponential in the square of the distribution’s width. The asymptotic expression (4.17) thus
represents a viable approximation only for a very small window about 1/n = 0 when s
1;
see Fig. 2. When asymmetry is added to a Gaussian distribution via the ﬁrst Edgeworth
correction (see (4.4) and, e.g., [20]), one ﬁnds that the exponential dependence of the ϕi on
σw is only corrected linearly by the now non-zero third moment of the W distribution.

≫

C. Expansions for the root-mean-square and similar averages

The root-mean-square (or standard deviation) is perhaps the best known example of a
non-linear average. The full analysis carried out above carries over quite directly, and indeed
applies to any non-linear average. We will now brieﬂy consider general “root-mean-powers.”
To be speciﬁc, consider the non-linear average resulting from a general power q = 2, 4, . . .,

denoted

≡ h
where x is a variable distributed according to the (arbitrary) probability density ρx.
In direct analogy with (2.8) one can deﬁne the ﬁnite-data average for R(q) as

i

R(q)

xq

1/q ,

The asymptotic expansion follows from the same procedure as above. One ﬁnds that the
expansion

R(q)

n =

[dxi ρx(xi)]

n

Z

Yi=1

1
n

"

n

1/q

xq
i

#

.

Xi=1

R(q)

n = R(q) + ϕ(q)

1 /n + ϕ(q)

2 /n2 +

,

· · ·

9

(4.23)

(4.24)

(4.25)

has coeﬃcients

ϕ(q)
ϕ(q)

1 = (
2 =

−
q−
h

1/2q)(1
1(1

q−
−
1)(2
q−

−

−

1)R(q) ˜σ2/˜µ2

q−

1)R(q)/˜µ4

˜µ˜µ3/6

(3

−

−

q−

1)˜σ4/8

i

i h

(4.26)

(4.27)

where ˜µ, ˜σ2, and ˜µ3 denote the mean, variance, and third central moment — respectively
— of the distribution of the variable xq.

V. ASYMPTOTIC BEHAVIOR: DIVERGENT MOMENTS CASE

w

When the distribution ρz of the variable e−

z in (4.1) possesses a long-tail, the limiting
distribution is not a Gaussian and the results (4.4) and (4.17) no longer hold. In particular,
(1+α) with α < 2 (implying an inﬁnite Boltzmann
if one of the tails of ρz(z) decays as z−
variance, ˆσ2), then the distribution of the variable y in (4.1) approaches a non-Gaussian
“stable” (L´evy) law for large n [22]. Note that such power-law behavior in z corresponds to
simple exponential decay in the work distribution.

≡

ρ1 also alters the form of the asymptotic expansion of
A long-tailed z distribution ρz ≡
the distribution of the sum-variable (4.1) and, hence, the expansion of fn — which no longer
1, as in (4.17). Instead of (4.4), the y distribution now
includes solely integer powers of n−
takes the more complicated form [29]

1 +
h

ρn(y) = ρα(y)

∗νuv(y)/nθ(u,v)

,

(5.1)

X
where ρα is the appropriate stable probability density with exponent α [20–22]. The functions
w and
νuv, which are not available analytically, depend on the original distribution of e−
partial derivatives of the stable distribution. The exponents are given by θ(u, v) = (u +
αv)/α > 0, and the summation
denotes the
integer part of x.

, where
⌉

∗ includes u

0 and v

x
⌉
⌈

≥ −⌈

u/2

≥

i

To analyze the asymptotic behavior of fn in this case, the starting point is again equations
(4.1) - (4.3), which are fully general. It is useful to rewrite (4.2) by scaling the logarithm’s
f and by subtracting zero in the form of the mean of y; one
argument by the constant e−
obtains

P

fn =

f

−

∞

cna

Z

−

dy ρn(y)

log

1 +

(cid:20)

(cid:18)

y
cna

y
cna

(cid:19) −

(cid:21) ≡

ˆI(

cna,

−

) .

∞

One can now divide up the domain of integration in (5.2) into sub-parts appropriate for
expansions of the logarithm of ρn, in analogy with (4.10). Because no explicit forms for stable
distributions are known in the range 1 < α < 2 [22], we will require separate expansions
1 and y
of ρn for
to obtain appropriate convergent behavior. The required
breakdown of the integral is therefore

→ ±∞

<
∼

y

|

|

f

−

fn = ˆI(

cna,

1) + ˆI(

1, 1) + ˆI(1,

−

−

−

) .

∞

Each of the integrals in (5.3) requires a slightly diﬀerent procedure. The ﬁrst,
ˆI(
cna,
ex-
−
1, 1), uses simple convergent series
pansion of ρn ≈

1), requires an expansion of the logarithm along with the “short-tail” y

ρα (see below). The second integral, ˆI(

→ −∞

−

−

(5.2)

(5.3)

10

expansions of both the logarithm and ρα. Finally, ˆI(1,
y
extending the lower limit of integration to zero accrues a non-leading correction.

) requires primarily the “long-tail”
expansion of ρα; the series expansion of the logarithm is also used to show that

→ ∞
Because we will extract only the leading term of fn −

f , it is suﬃcient to use only the
leading contribution to ρn; that is, considering (5.1) we may use the asymptotically valid
ρα. (The leading behavior for fn in the ﬁnite-moments case
(n
ρG.) The required series expansions for ρα in the case of positive
arises, similarly, from ρn ≈
summands z = e−

) approximation ρn ≈
w are [20–22]

→ ∞

∞

where the “
on the sign of y — are given by

≈

” sign denotes an asympotic expansion, and the coeﬃcients — which depend

ρα(y; ξ) =

k

1 ,
∞k=1 C 0
y
−
k |
|
(kα+1) ,
∞k=1 C ∞k y−
P

≈

P

y
|
y

> 0

|
→ ∞

C 0

k(ξ) =

C ∞k =

1
π
1
π

(

(

−

−

1)k

−

1)k

−

1 Γ(1 + k/α)
k!
1 Γ(kα + 1)
k!

sin (kπξ/α) ,

sin (kπξ+) ,

≡

ξ(y > 0) = α

with ξ+
k(ξ−),
and in particular, C 0
1 . Because the summands considered here are
strictly positive, the left tail of the distribution does not exhibit power-law behavior; rather,
it may be termed “short” or “light” and, asymptotically, is given by [22]

ξ(y < 0) = 1. Note that C 0

1 and ξ−
1 (ξ−)

−
1 (ξ+) = C 0

k (ξ+) = (

≡
≡

1C 0

1)k

C 0

−

−

ρα(y

)

→ −∞

≈

1−α/2
α−1

1

2πα(α

y
α (cid:12)
(cid:12)
(cid:12)
(cid:12)

−

1) (cid:12)
(cid:12)
(cid:12)
(cid:12)

q

exp

(α

1)

(−

−

α
α−1

.

)

y
α (cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

We can now consider the terms in (5.3) using (5.4) - (5.8). For the sake of brevity we
quote only the leading terms, which result from straightforward integrations (after discarding
non-leading terms and corrections):

ˆI(

cna,

1)

−

−

≈ −

ˆI(
−
ˆI(1,

1, 1)

≈ −

)

∞

≈ −

α2 Γ

a + 3

2, αa(α

1
2

1)a+

2c2(α

(cid:16)
−
1 /3c2
(cid:17)
C ∞1 I †α/cα

C 0

(cid:16)

(cid:16)

(cid:17)

q
2a

n−

n1
−

α ,

−
2πα(α

1)
(cid:17)
1)
−

2a

n−

−

·

·

I †α =

∞

dx
x1+α [x

−

0
Z

log (1 + x)] <

.

∞

where 2a = 2(α

1)/α, Γ(

,

) is the incomplete gamma function [30], and

By comparing powers of n in (5.9) - (5.11) one sees that the leading behavior of the
ﬁnite-date free energy estimate, not surprisingly, results from the “heavy” power-law tail
(y

). Thus, using (5.11), one has

→ ∞

11

(5.4)
(5.5)

(5.6)

(5.7)

(5.8)

(5.9)

(5.10)

(5.11)

(5.12)

fn −

f

≈

ϕα

1/n(α
−

1) ,

−

(5.13)

−

1 =

C ∞1 I †α/cα

with ϕα
probability density ρz through c = e−
a useful estimate for fn −
for α <
∼

2.

(cid:17)

(cid:16)

> 0. Note that ϕα

1 depends on α and also on the original
f /b1. Furthermore, one should not expect (5.13) to be
1

1)/α is very close to α

−

f : the next leading exponent, 2(α

−

−

VI. UNIVERSAL ASYMPTOTIC FLUCTUATIONS

The ﬂuctuations in the ﬁnite-data free energy, fn = ∆Fn/kBT , as measured by the
Fn of (2.5), are of considerable interest because of their potential to provide
= ∆F/kBT [9]; see also [32]. The variance is

variance σn of
parameter-free extrapolative estimates of f
given by

∞

2

σn
kBT (cid:19)

(cid:18)

=

(

D

Fn −

∆Fn)2

=

∞

dy ρn(y) [log (1 + y/cna)]2

(fn −

−

f )2 .

(6.1)

cna

Z

−

E

→ ∞

f and
, it was pointed out in [18] that the simple, linear relation between fn −
For n
σ2
n was independent of the distribution of work values — that is, universal. Here, we sketch
the derivation for the long-tailed case when the second Boltzmann moment diverges.

To calculate the asymptotic behavior of the ﬂuctuations (6.1) note ﬁrst that second term
f . For the crucial integral of (6.1), one

f )2 is necessarily of higher order than fn −

(fn −
ﬁnds

∞

dy ρn(y) [log (1 + y/cna)]2

cna

Z

−

≈

I ‡α =

1
nα

−

∞

1

C ∞1
cα I ‡ ,
1
uα+1 [log (1 + u)]2 .
du

0
Z

Comparing (6.1) - (6.3) with (5.13) and (5.12), we see that as n

→ ∞

fn −

f

≈

2

I †α
I ‡α (cid:18)

σn
kBT (cid:19)

.

(6.2)

(6.3)

(6.4)

This is a linear relation that depends only on α, via the ratio I †α/I ‡α, but is otherwise in-
dependent of the initital distribution of work values (or Boltzmann factors). In the limit
2, the ratio I †α/I ‡α approaches 1/2, which is the ﬁnite-Boltzmann-moment result re-
α
ported in [18]. Because numerical evaluation of the integral ratio is non-trivial we note that
for α = 1.25, 1.5, 1.75, the corresponding values are I †α/I ‡α = 1.43, 0.81, 0.61.

→

Figure 3 illustrates the universal behavior for α = 1.5. The “simple” or regulated-power-
law distribution is deﬁned by ρrp(z) = α′/(1 + z)α′+1, with α′ = α = 1.5. The “power”
distribution is given by ρp(z) = z0/zα, with the choice z0 = 10−

4.

VII. SUMMARY AND DISCUSSION

This report has expanded upon the brief discussion of Ref. [18], giving a general statistical
theory describing the systematic error present in free-energy-diﬀerence ∆F estimates based

12

on a ﬁnite amount of data (N work values, W ). As in [18], our focus has been on the large-
N asymptotic behavior, motivated by the need to improve extrapolation procedures ﬁrst
explored in [9]. However, beyond simply giving further details of the derivations of previous
results, this report has made transparent the connection to general non-linear averages: the
bounds of Sec. III explicitly apply to a broad class of nonlinear computations in addition to
∆F estimates; and, Sec. IV gives asymptotic expansions for geometric averages, such as the
root-mean-square.

The universal, asymptotic relation (6.4) between the expected value of the biased ∆F
estimate based on N work values (∆FN ) and the ﬂuctuation in these estimtates (σN ) is one
of the more striking results. We have shown here, in Sec. VI, that the relation is universal
W/kBT ),
whether or not the second moment of the distribution of Boltzmann factors, exp (
is ﬁnite — that is, whether or not the central limit theorem applies. If not, the stable (L´evy)
distributions come into play, and the relation between ∆FN and σN depends only on the
exponent of the limiting stable distribution.

−

We hope our results will have practical application in the extrapolation process outlined
in [9], which suggested that dramatic increases in computational eﬃciency may be possible.
In this context, examination of Pad´e approximants to the asymptotic series, which can be
constructed to also exhibit suitable small-N behavior, may prove fruitful. We believe, ﬁnally,
that the statistical foundation laid in Ref. [18] and here provides a basis for the crucial but
non-trivial task of simply understanding convergence in estimates of free energy diﬀerences
and other non-linear averages.

ACKNOWLEDGMENTS

The authors have beneﬁtted greatly from discussions with Michael E. Fisher, Gerhard
Hummer, Chris Jarzynski, Hirsh Nanda, Lawrence Pratt, Attila Szabo, and David Zucker-
man. We gratefully acknowledge funding provided by the NIH (under grant GM54782), the
Bard Foundation, and the Department of Physiology. D.M.Z. is the recipient of a National
Research Service Award (GM20394) from the NIH.

13

REFERENCES

[1] S. B. Singh, Ajay, D. E. Wemmer, and P. A. Kollman, Proc. Nat. Acad. Sci. (USA) 91,

7673 (1994).

[2] C. Jarzynski, Phys. Rev. Lett. 78, 2690 (1997).
[3] A. D. Bruce, N. B. Wilding, and G. J. Ackland, Phys. Rev. Lett. 79, 3002 (1997).
[4] M. de Koning, A. Antonelli, and S. Yip, Phys. Rev. Lett. 83, 3973 (1999).
[5] G. Hummer and A. Szabo, Proc. Nat. Acad. Sci. (USA) 98, 3658 (2001).
[6] C. Jarzynski, Proc. Nat. Acad. Sci. (USA) 98, 3636 (2001).
[7] B. Isralewitz, M. Gao, and K. Schulten, Curr. Opin. Struc. Bio. 11, 224 (2001).
[8] J. Liphardt, S. Dumont, S. B. Smith, I. Tinoco, and C. Bustamante, Science 296, 1832

(2002).

(1991).

[9] D. M. Zuckerman and T. B. Woolf, Chem. Phys. Lett. 351, 445 (2002).
[10] W. P. Reinhardt and J. E. Hunter, J. Chem. Phys. 97, 1599 (1992).
[11] D. Beveridge and F. DiCapua, Ann. Rev. Biophys. Biophys. Chem. 18, 431 (1989).
[12] J. A. McCammon, Curr Opin. Struc. Bio. 2, 96 (1991).
[13] P. A. Kollman, Chemical Reviews 93, 2395 (1993).
[14] R. H. Wood, W. C. F. M¨uhlbauer, and P. T. Thompson, J. Phys. Chem. 95, 6670

[15] C. Jarzynski, Phys. Rev. E 56, 5018 (1997).
[16] H. Nanda and T. B. Woolf, in preparation. (unpublished).
[17] A. M. Ferrenberg, D. P. Landau, and K. Binder, J. Stat. Phys. 63, 867 (1991).
[18] D. M. Zuckerman and T. B. Woolf, submitted for publication; physics/0201046. (un-

[19] D. P. Landau and K. Binder, A Guide to Monte Carlo Simulations in Statistical Physics

(Cambridge University, Cambridge, 2000).

[20] W. Feller, An Introduction to Probability Theory and Its Applications (Wiley, New York,

[21] V. M. Zolotarev, One-dimensional Stable Distributions (American Mathematical Soc.,

[22] V. V. Uchaikin and V. M. Zolotarev, Chance and Stability: Stable Distributions and

[23] M. F. Shlesinger, G. M. Zaslavsky, and U. Frisch, L´evy Flights and Related Topics in

Their Applications (VSP, Utrecht, 1999).

Physics (Springer, Berlin, 1995).

[24] J. G. Kirkwood, J. Chem. Phys. 3, 300 (1935).
[25] A. D. Stone and J. D. Joannopoulos, Phys. Rev. E 25, 2400 (1982).
[26] G. H. Hardy, J. E. Littlewood, and G. P´olya, Inequalities (Cambridge University Press,

[27] T. M. Cover and J. A. Thomas, Elements of Information Theory (Wiley, New York,

[28] R. W. Ash, Basic Probability Theory (Wiley, New York, 1970).
[29] G. Christoph and W. Wolf, Convergence Theorems with a Stable Limit Law (Akadmie

[30] M. Abramowitz and I. A. Stegun, Handbook of Mathematical Functions (Dover, New

Cambridge, 1967).

1991).

Verlag, Berlin, 1992).

York, 1965).

published).

1971), vol. 2.

Providence, 1986).

14

[31] V. V. Petrov, Limit Theorems of Probability Theory (Oxford University Press, Oxford,

1995).

[32] H. Meirovitch, J. Chem. Phys. 111, 7215 (1999).

15

FIGURES

(a)

Running Estimate

Avg. Run. Est.

100

200
N      

300

Running Estimate

Avg. Run. Est.

0

−2

−4

−6

−8

40

30

20

T
B
k
/
F
∆

]
e
l
o
m

/
l
a
c
k
[
 

F
∆

−10

0

(b)

10

0

500

N      

1000

FIG. 1. Finite-sampling errors in ∆F estimates based on (a) Gaussian-distributed work values
and (b) work values generated in a molecular-mechanics solubility comparison between the fatty
acids palmitate and stearate. The irregular, staircase-shaped plots are the running estimates based
on N work values, while the smooth curves depict the average running estimates ∆FN (2.4) which
are independent of the order in which the work values were generated. The standard deviation of
the zero-mean Gaussian distribution in (a) is 4kBT , for which the true free energy diﬀerence is
∆F = ∆F
13 kcal/mole; note that
∞
1 kcal/mole = 1.7 kBT .

8kBT . For the fatty acid solvation case, ∆F = ∆F

∞ ≃

−

=

16

T
k
/
)

F
∆
−
n
F
∆
(

3

2

1

0

F
a

t
l

e
D

 
-
 
n
_
F
a

t
l

e
D

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
-0.1

0

0.2

0.4

0.6

0.8

1

1/n

FIG. 2. Finite-sampling error for Gaussian-distributed work values. The expected value of
∆F )/kBT for n data points is plotted as a
the dimensionless ﬁnite-sampling inaccuracy, (∆Fn −
function of 1/n. From top to bottom, the data sets represent numerical values of the error for
Gaussian distributions of work values with standard deviations, σw/kBT of 3, 2, 1.5, and 1. The
lines (dashed for σw/kBT = 1.5, solid for σw/kBT = 1) depict the asymptotic linear behavior for
the two smallest widths.

Universal Behavior for alpha<2   6/28/02

0.815*x
Power-1.5-ran2
Power-1.5-ran4
Simple-1.5-ran2
Simple-1.5-ran4
0.8

0.6

(sigma_n)^2

0

0.2

0.4

1

17

FIG. 3. The universal n

∆F and its ﬂuctuation σn for the case
relation between ∆Fn −
α = 1.5. The solid line depicts the universal slope I †α/I ‡α = 0.815 for α = 1.5, as given in (6.4) and
the succeeding text. The data for the “power” and “simple” distributions, described in the text,
are each shown for two diﬀerent random number generators.

→ ∞

