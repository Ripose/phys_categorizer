0
0
0
2

 
r
a

 

M
7
2

 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 

1
v
8
7
0
3
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

A fast algorithm for generating a

uniform distribution inside a

high-dimensional polytope

Andr´e van Hameren∗ and Ronald Kleiss†

University of Nijmegen, Nijmegen, the Netherlands

February 18, 2014

Abstract

We describe a uniformly fast algorithm for generating points ~x
uniformly in a hypercube with the restriction that the diﬀerence be-
tween each pair of coordinates is bounded. We discuss the quality of
the algorithm in the sense of its usage of pseudo-random source num-
bers, and present an interesting result on the correlation between the
coordinates.

∗andrevh@sci.kun.nl
†kleiss@sci.kun.nl

1 Introduction

In this paper we shall discuss the problem of generating sets of points ~x =
(x1, x2, . . . , xm) inside an m-dimensional hypercube with an additional re-
striction. The points ~x are required to satisfy the conditions

|xk| < 1 ,

|xk − xl| < 1 for all k, l .

(1)

These conditions deﬁne a m-dimensional convex polytope P . The reason for
tackling this problem is the following. In a recently developed Monte Carlo
algorithm, SARGE [1], we address the problem of generating conﬁgurations of
four-momenta pµ
i , i = 1, 2, . . . , n of n massless partons at high energy, with
a distribution that has, as much as possible, the form of a so-called QCD
antenna:

1

s12s23s34 · · · sn−1,nsn1

,

skl = (pk + pl)2 ,

where skl is the invariant mass squared of partons k and l, with the addi-
tional requirement that the total invariant mass squared of all the partons is
ﬁxed to s, and every skl (also those not occurring explicitly in the antenna)
exceeds some lower bound s0: in this way the singularities of the QCD matrix
elements are avoided. The SARGE algorithm has a structure that is, in part,
similar to the RAMBO algorithm [2], where generated momenta are scaled so
as to attain the correct overall invariant mass. Obviously, in SARGE this is
more problematic because of the s0 cut, but one should like to implement
this cut as far as possible. Note that out of the n(n − 1)/2 diﬀerent skl, n
occur in the antenna, and each of these must of course be bounded by s0
from below and some sM < s from above. The scale-invariant ratios of two
of these masses are therefore bounded by

s0
sM

≤

sij
skl

≤

sM
s0

,

(2)

The structure of the SARGE algorithm is such [1] that there are m = 2n − 4
of these ratios to be generated. By going over to variables

x(···) = log(sij/skl)/ log(sM /s0) ,

and inspecting all ratios that can be formed from the chosen m ones, we
arrive at the condition of Eq.(1). Note that, inside SARGE, a lot of internal
rejection is going on, and events satisfying Eq.(1) may still be discarded:
however, if Eq.(1) is not satisﬁed, the event is certainly discarded, and it
therefore pays to include this condition from the start.

1

2 The algorithm

The most straightforward way of implementing is of course the following:
generate xk, k = 1, . . . , m by xk ← 2ρ − 1, and reject if the conditions
are not met. Here and in the following, each occurrence of ρ stands for a
call to a source of iid uniform pseudo-random numbers between in [0, 1). The
drawback of this approach is that the eﬃciency, i.e. the probability of success
per try, is given by 2−mVm(P ) (where Vm(P ) is the volume of the polytope
P ) and becomes very small for large m, as we shall see.

To compute the volume Vm(P ) we ﬁrst realize that the condition |xk −
xl| < 1 is only relevant when xk and xl have opposite sign. Therefore, we
can divide the x variables in m − k positive and k negative ones, so that

1

m

Vm,k(P ) =

Vm(P ) =

dy1dy2 · · · dykdxk+1dxk+2 · · · dxmθ(cid:18)1 − max
Z0
Xk=0

k!(m − k)!

Vk(P ) ,

m!

i

xi − max

j

yj(cid:19) ,

(3)

where we have written yk = −xk. By symmetry we can always relabel the
indices such that xm = maxi xi and y1 = maxj yj. The integrals over the
other x’s and y’s can then easily be done, and we ﬁnd

Vm,k(P ) = k(m − k)

1

Z0

dy1yk−1

1

1−y1

Z0

dxmxm−k−1

m

= k

1

Z0

dy1yk−1

1

(1 − y1)m−k =

k!(m − k)!

m!

,

and hence

Vm(P ) = m + 1 .

(4)

(5)

The eﬃciency of the straightforward algorithm is therefore equal to (m +
1)/2m, which is less than 3% for n larger than 6.

We have given the above derivation explicitly since it allows us, by work-
ing backwards, to ﬁnd a rejection-free algorithm with unit eﬃciency. The
algorithm is as follows:

1. Choose a value for k. Since each k is exactly equally probably we simply

have

k ← ⌊(m + 1)ρ⌋ .

2

2. For k = 0 we can simply put

xi ← ρ , i = 1, . . . , m ,

while for k = m we put

xi ← −ρ , i = 1, . . . , m .

3. For 0 < k < m, y1 has the unnormalized density yk−1

(1 − y1)m−k
between 0 and 1. An eﬃcient algorithm to do this is Cheng’s rejection
algorithm BA for beta random variates (cf. [3])1, but the following also
works:

1

v1 ← − log  k
Yi=1

ρ! , v2 ← − log


m−k+1

Yj=1

ρ
 , y1 ←

v1

v1 + v2

.

The variable xm has unnormalized density xm−k−1
so that it is generated by

m

between 0 and 1−y1

xm ← (1 − y1)ρ1/(m−k)

.

The other x’s are now trivial:

x1 ← −y1

,

xi ← x1ρ,
xi ← xmρ,

i = 2, 3, . . . , k ,
i = k + 1, k + 2, . . . , m − 1 .

Finally, perform a random permutation of the whole set (x1, x2, . . . , xm).

3 Computational complexity

The number usage S, that is, the expected number of calls to the random
number source ρ per event can be derived easily. In the ﬁrst place, 1 number
is used to get k for every event. In a fraction 2/(m + 1) of the cases, only m
calls are made. In the remaining cases, there are k + (m − k + 1) = m + 1
calls to get y1, and 1 call for all the other x values. Finally, the simplest

1There is an error on page 438 of [3], where “V ← λ−1U1(1− U1)−1” should be replaced

by “V ← λ−1 log[U1(1 − U1)−1]”.

3

permutation algorithm calls m − 1 times [4]. The expected number of calls
is therefore

S = 1 +

2m

m + 1

+

m − 1
m + 1

(m + 1 + (m − 1) + (m − 1)) =

3m2 − m + 2

m + 1

. (6)

For large m this comes to about 3m − 1 calls per event. Using a more
sophisticated permutation algorithm would use at least 1 call, giving

S = 1 +

2m

m + 1

+

m − 1
m + 1

(m + 1 + (m − 1) + (1)) = 2m .

(7)

We observed that Cheng’s rejection algorithm to obtain y1 uses about 2 calls
per event. Denoting this number by C the expected number of calls becomes

S =

2m2 + (C − 1)m − C + 3

m + 1

∼ 2m + C − 1

(8)

for the simple permutation algorithm, while the more sophisticated one would
yield

m2 + (C + 2)m − C + 1

S =

m + 1

∼ m + C + 2 .

(9)

We see that in all these cases the algorithm is uniformly eﬃcient in the sense
that the needed number of calls is simply proportional to the problem’s
complexity m, as m becomes large. An ideal algorithm would of course
still need m calls, while the straightforward rejection algorithm rather has
S = m2m/(m + 1) ∼ 2m expected calls per event.

In the testing of algorithms such as this one, it is useful to study expec-
tation values of, and correlations between, the various xi. Inserting either xi
or xixj in the integral expression for V (P ), we found after some algebra the
following expectation values:

E(xi) = 0 , E(x2

i ) =

m + 3

6(m + 1)

, E(xixj) =

m + 3

12(m + 1)

(i 6= j) ,

(10)

so that the correlation coeﬃcient between two diﬀerent x’s is precisely 1/2
in all dimensions! This somewhat surprising fact allows for a simple but
powerful check on the correctness of the algorithm’s implementation.

4

4 Extension

Let us, ﬁnally, comment on one possible extension of this algorithm. Suppose
that the points ~x are distributed on the polytope P , but with an additional
(unnormalized) density given by

F (~x) =

m

Yi=1

cos(cid:18) πxi

2 (cid:19) ,

(11)

so that the density is suppressed near the edges. It is then still possible to
compute Vm,k(P ) for this new density:

Vk,m(P ) = k(m − k)

1

Z0

1

1−y1

xm


Z0


dy1 cos(cid:18) πy1
2 (cid:19)
k−1
2 (cid:19)
dy cos(cid:18) πy
Z0


π(cid:19)m 1
d sin(cid:18)πy1
= k(m − k)(cid:18) 2
Z0
d sin(cid:18)πxm
2 (cid:19)(cid:18)sin(cid:18)πxm
Z0

ds sk/2−1(1 − s)(m−k)/2

m−k−1

dxm cos(cid:18)πxm
2 (cid:19)

Z0
2 (cid:19)
dx cos(cid:18)πx

2 (cid:19)(cid:19)k−1
2 (cid:19)(cid:18)sin(cid:18)πy1
2 (cid:19)(cid:19)m−k−1

cos( πy1

2 )

2m−1k

πm

=

y1

Z0

= (cid:18) 2

π(cid:19)m Γ(1 + k/2)Γ(1 + (m − k)/2)

Γ(1 + m/2)

,

(12)

2 (cid:17)(cid:17)2

where we used s = (cid:16)sin(cid:16) πy1

. Therefore, a uniformly eﬃcient algorithm
can be constructed in this case as well, along the following lines. Using the
Vk,m, the relative weights for each k can be determined. Then s is generated
as a β distribution. The generation of the other x’s involves only manipula-
tions with sine and arcsine functions. Note that, for large m, the weighted
volume of the polytope P is

V (P ) =

m

Xk=0(cid:18) 2

π(cid:19)m (cid:16) k

2(cid:17)!(cid:16) m−k
2 (cid:17)!
(cid:16) m
2(cid:17)!

m!

k!(m − k)!

5

∼ mr π

8 (cid:18) 8

π2(cid:19)m/2

,

so that a straightforward rejection algorithm would have number usage

S ∼ s 8

π   π2

2 !m/2

,

(13)

(14)

and a correspondingly decreasing eﬃciency.

References

[1] P. Draggiotis, A. van Hameren and R. Kleiss, in preparation.

[2] S.D. Ellis, R. Kleiss and W.J. Stirling, A new Monte Carlo treatment
of multiparticle phase space at high energy, Comp. Phys. Comm. 40
(1986) 359.

[3] L. Devroye, Non-Uniform Random Variate Generation, (Springer,

1986).

[4] D.E. Knuth, The Art of Computer Programming, Vol.2. 2d ed. (Prince-

ton, 1991).

6

