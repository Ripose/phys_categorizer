Global Stationary Phase and the Sign Problem

Andr´e G. Moreira,1 Stephan A. Baeurle2 and Glenn H. Fredrickson1

1Materials Research Laboratory, University of California,

Santa Barbara, CA 93106, USA and

2Institut f¨ur Physikalische und Theoretische Chemie,

Universit¨at Regensburg, 93053 Regensburg, Germany

(Dated: December 22, 2013)

Abstract

We present a computational strategy for reducing the sign problem in the evaluation of high

dimensional integrals with non-positive deﬁnite weights. The method involves stochastic sampling

with a positive semideﬁnite weight that is adaptively and optimally determined during the course of

a simulation. The optimal criterion, which follows from a variational principle for analytic actions

S(z), is a global stationary phase condition that the average gradient of the phase ImS along the

sampling path vanishes. Numerical results are presented from simulations of a model adapted from

statistical ﬁeld theories of classical ﬂuids.

PACS numbers: 05.10.-a,02.70.-c,82.20.Wt

3
0
0
2
 
r
p
A
 
3
2
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
6
8
0
4
0
3
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

1

A familiar problem that arises in the context of lattice gauge theory[1], quantum

chemistry[2], correlated electron physics[3], and equilibrium ﬁeld theories of classical

ﬂuids[4], is the evaluation of integrals of the form

Z =

dx exp[−S(x)]

ZC1

(1)

where the path of integration C1 is the real axis and the action (or eﬀective Hamiltonian)

S(x) is complex. In the cases of primary interest x ∈ Rn is a n-vector representing a discrete

representation (lattice sites or spectral elements) of one or more classical or quantum ﬁelds.
The dimension n is typically large, of order 103 − 106. Here we shall use one-dimensional

notation, although the formalism is primarily intended for cases of n ≫ 1.

For real S(x), there are a variety of powerful methods available for evaluating Z, including

Monte Carlo and (real) Langevin simulations[5]. However, in the case of complex S = SR +

iSI, the integrand is not positive semideﬁnite, so the Monte Carlo method is not immediately

applicable. Simulations can be carried out using the positive semideﬁnite weight exp(−SR),

but then an oscillatory phase factor of exp(−iSI ) must be included in the computation of

averages[6]. The rapid oscillations in this factor (the “sign problem”), which become more

pronounced for large n, can dramatically slow convergence in such simulations. Alternatively,

a “complex Langevin” simulation technique has been devised in which the ﬁeld variables

x are extended to the complex plane and a Langevin trajectory prescribed for the purpose

of generating Markov chains of states[7]. Unfortunately this method is not guaranteed to

converge and pathological behavior has been noted for speciﬁc models[8, 9]. In the present

letter we describe a new simulation approach that is useful for reducing the sign problem in

integrals of the form of Eq. (1), where S(z) is an analytic function of the complex n-vector

z = x + iy.

We begin by considering a displacement of the original integration path along the real x

axis, C1 to a new parallel path Cy deﬁned by z = x + iy, xj ∈ (−∞, ∞), in which y ∈ Rn

is an arbitrary displacement of C1 along the imaginary axis. Note that the displacement yj

need not be uniform in j for the n > 1 case. Provided S(z) is analytic in the rectangular

strip bounded by C1 and Cy and | exp[−S(R + iy)]| → 0 for R → ±∞, it follows that

Z =

dz exp[−S(z)] =

dx exp[−S(x + iy)]

(2)

ZCy

ZCy

and the resulting Z is independent of the choice of y. Upon decomposing S into real and

2

(3)

(4)

(5)

imaginary parts SR(x, y) + iSI(x, y), Z can be rewritten as

Z = Zy ZCy

dx Py(x) exp[−iSI(x, y)]

where Zy ≡

dx exp[−SR(x, y)] and Py(x) is a normalized, positive semideﬁnite, proba-

bility distribution for a random variable x at the ﬁxed value of y:

Cy
R

Py(x) = exp[−SR(x, y)]/Zy

It follows that the average of an analytic observable f (x) can be evaluated alternatively from

the formulas

hf (x)i = Z −1

dx exp[−S(x)]f (x)

ZC1

=

hexp[−iSI (x, y)]f (x + iy)iy
hexp[−iSI(x, y)]iy

Cy
R

where hh(x)iy ≡

dx Py(x)h(x) denotes an average with probability weight Py(x).

It is the second expression in Eq. (5) that is of interest in the present letter. A poor

choice of y will lead to signiﬁcant oscillations in the phase factor exp[−iSI(x, y)] as x is

stochastically varied along the sampling path Cy in a simulation. This would drive both

numerator and denominator in Eq. (5) to zero and dramatically slow or prevent convergence

of average quantities of interest. One approach to alleviate this diﬃculty would be to choose
y = y∗, where y∗ is the imaginary component of a saddle point z∗ deﬁned by S′(z∗) = 0.

The deformed integration path Cy∗ would then be a line passing through the saddle point

parallel to the real axis. If this path happened to be a constant phase (steepest ascent) path

locally around the saddle point, then the phase oscillations would be reduced on trajectories

In general, however, path Cy∗ will not be a a
that remain close to the saddle point[10].
constant phase path, even in the close vicinity of z∗. A local analysis about each saddle
point, costing O(n2) in computational eﬀort, can be used to identify proper constant phase

paths. However, in typical problems where ﬁeld ﬂuctuations are strong, signiﬁcant weight

is given to trajectories that are not localized around saddle points.

The essence of our method is a global strategy for selecting an optimal displacement y,

denoted ¯y. To this end, we introduce a “generating” function (functional)

G(y) = ln

dx exp[−SR(x, y)]

(6)

ZCy

3

(7)

(8)

(9)

Invoking the Cauchy-Riemann (CR) equations, it is straightforward to show that the ﬁrst

derivative of G(y) is given by

∂G(y)
∂yj

∂
∂xj

= h

SI(x, y)iy

The second derivative follows from repeated application of the CR equations and an inte-

gration by parts

∂2G(y)
∂yj∂yk

= h[

SI − h

SIiy][

SI − h

SIiy]iy

∂
∂xk

∂
∂xk

∂
∂xj
∂
∂xj

∂
∂xj
∂
∂xk

+ h[

SR][

SR]iy,

which is the sum of two positive deﬁnite forms. It follows that G(y) is manifestly a convex

function for any y.

We now claim that the “optimal” choice y = ¯y is such that

∂G(y)
∂yj

∂
∂xj

|¯y = h

SI(x, ¯y)i¯y = 0

Evidently such a point would be a local minimum of G(y). Moreover, it implies that SI has

vanishing gradients on average along the sampling path C¯y. This condition can be viewed as

a global, rather than local[10], stationary phase criterion and would seem to be an excellent

way to minimize the eﬀect of phase ﬂuctuations. Since G(y) has a unique minimum, it

follows that ¯yj is homogeneous in j for bulk systems with translationally invariant actions.

The method evidently produces nontrivial inhomogeneous ¯y when applied to ﬁeld theories

in bounded geometries.

It remains to discuss how to incorporate this optimal choice of sampling path into a

simulation algorithm. We propose the following “optimal path sampling” (OPS) algorithm:

1. Initialize vectors x and y = yk with k = 0.

2. Carry out a stochastic simulation in x at ﬁxed yk to generate a Markov chain of x states

of length M. Pyk(x) should be used as a statistical weight for importance sampling.

The simulation method could be Metropolis Monte Carlo, its “smart” or “hybrid”

variants[11], or a real Langevin technique.

3. Evaluate G(yk) and ∂G(yk)/∂yk by averaging over the x conﬁgurations accumulated

in the M-state simulation. Update y to approach ¯y by making a steepest descent step

yk+1 = yk − λ

∂G(yk)
∂yk

4

1(cid:13)

0.5(cid:13)

0(cid:13)

-0.5(cid:13)

-1(cid:13)

-3(cid:13)

-2(cid:13)

-1(cid:13)

1(cid:13)

2(cid:13)

3(cid:13)

0(cid:13)
x

FIG. 1: Variation of the phase factor of the Airy integrand Re[exp(−iSI (x, y, 1))] with x for y = 0

(dashed) and y = ¯y = 1.19149 (solid).

where λ is an adjustable relaxation parameter. Alternatively, the accumulated infor-

mation on G(y) could be used to carry out approximate line minimizations, which
would permit conjugate gradient updates from yk to yk+1.

4. Repeat steps 2 and 3 for k = 1, 2, ... until the sequence of yk converges to within some

prescribed tolerance to ¯y. The simulation has now equilibrated.

5. Carry out a long stochastic simulation (“production run”) with statistical weight

P¯y(x).

6. Compute averages over the simulated states according to Eq. (5) with y = ¯y.

Evidently, the parameters M and λ can be adjusted to accelerate the “equilibration” period.

Our OPS method has some similarities to (and was inspired by) the complex Langevin

(CL) simulation technique. In that approach, one generates a Markov chain of states in the

complex plane by integrating the Langevin equations[7]

where η(t) is a real Gaussian white noise with hη(t)i = 0 and hηj(t)ηk(t′)i = 2δ(t − t′)δjk.

Ensemble averages hf (x)i are computed as time averages of f (x + iy) over the chain of

states. Under conditions where the CL method converges, we have observed that y drifts

(10)

(11)

∂x
∂t

= −Re

+ η(t)

dS
dz

∂y
∂t

= −Im

dS
dz

5

to a nearly constant value that is not associated with any saddle point y∗. Eq. (11) reduces

approximately in this case to hIm dS/dziy = 0, which is equivalent to the condition (9).

The OPS technique is also distinct from so-called “stationary phase Monte Carlo” methods,

which apply ﬁltering and sparse sampling methods to suppress phase oscillations[2, 12].

These methods are eﬀective but apparently have no variational basis.

Before providing a numerical example of the OPS method, it is illustrative to see how

our global stationary phase criterion works in a simple one dimensional example

Ai(t) =

dx exp[i(x3/3 + tx)],

(12)

1
2π Z

∞

−∞

which is a representation of the Airy function. In this case S(x, t) = −i(x3/3+tx) and Eq. (9)
leads to ¯y2 −hx2i¯y −t = 0. This equation has a single root, corresponding to the minimum of

G(y), that yields ¯y(t). For example, ¯y(1) = 1.19149. Of particular interest is the eﬀect of the

optimal displacement on phase oscillations. In Fig. 1 we plot Re[exp(−iSI (x, y, t))] verses

x at t = 1 for y = 0 (no shift) and y = ¯y (optimal). Clearly the optimal shift dramatically
suppresses phase oscillations over the interval −2 <

∼ 2. The global stationary phase
criterion has no eﬀect outside this interval, because P¯y(x) decays supra-exponentially there
as ∼ exp(−x2 ¯y) and so no statistical weight is given to |x| >

∼ x <

∼ 2.

As a numerical test of the OPS method, we have carried out simulations of the model

S(x) =

[αx2

j + (xj+1 − xj)2 − χ exp(−ixj)]

(13)

n

Xj=1

which can be viewed as a lattice ﬁeld theory for the one-dimensional classical Yukawa ﬂuid in

the grand canonical ensemble (α is a measure of interaction strength and χ is the activity).

For the case of n > 1, periodic boundary conditions are applied. The model has a saddle
point z∗

j that lies on the imaginary axis and is homogeneous in the index j (as well

j = iy∗

as an inhomogeneous “1d crystal-like” saddle point). Its location is given by the solution
of χ exp(y∗
j = 0. The optimal displaced path ¯yj is homogeneous in j and is given
by the solution of χ exp(¯yj)hcos xji¯y + 2α¯yj = 0. We see that y∗ and ¯y are coincident under

j ) + 2αy∗

conditions (α ≫ 1) where the random variable x ﬂuctuates closely about the saddle point
x∗ = 0. In the strongly ﬂuctuating regime (α ≪ 1), hcos xji¯y will be dramatically reduced,
resulting in a large shift of ¯y away from y∗. These expectations are borne out in numerical

simulations of the model.

6

>
 
z
 
<

0

-0.2

-0.4

-0.6

-0.8

I

>
)
 

S

i
-
(
p
x
e
<

0.5

1

0

exact

saddle point

0

0.2

0.4

0.6

0.8

1

(a)

(b)

0

0.2

0.4

0.6

0.8

1

a

FIG. 2: Comparison between OPS and CL simulations. (a): The average of z = x+iy as a function

of the parameter α for the model of Eq. (13) with n = 1 and χ = 1. Open and ﬁlled symbols

are results, respectively, from CL and OPS. Stars denote the average of the imaginary part y and

triangles the average of the real part x. The full line is the exact solution, the dashed line the

corresponding saddle point. (b): The average sign exp(−iSI ) for the same parameters as in (a).

The convention for the symbols is the same as in (a). Error bars are comparable to the symbol

sizes if not explicitly shown.

We have carried out conventional Metropolis Monte Carlo (MC)[i.e. Eq. (5) with y = 0],

OPS, and CL simulations of the model with action Eq. (13). The results were obtained
from runs with a total of 107 MC cycles or Langevin steps, a time step of 0.001 in the case

of CL, and parameters M = 1000, λ = 0.05 for OPS. In Fig. 2 we compare the results

obtained from OPS and CL simulations with n = 1 and χ = 1. The top panel (a) shows hzi

as a function of α, while the bottom panel (b) displays the real and imaginary parts of the

“sign” hexp(−iSI )i. In contrast to OPS, CL fails to converge, or converges very slowly, for
α <

∼ 0.15. Conventional MC also converges, but the average sign is approximately 0.8, as

opposed to ∼ 1 shown by the OPS.

It is often observed[3] that the sign in conventional MC simulations decreases exponen-

7

>
 
z
 
<

2

1

0

-1

-2

1

I

>
)
 

S

i
-
(
p
x
e
<

0.5

0

saddle point

0

0.2

0.4

0.6

0.8

1

(a)

(b)

0

0.2

0.4

0.6

0.8

1

a

FIG. 3: Comparison OPS and conventional MC. (a): The average of z = x + iy as a function of

the parameter α for the model of Eq. (13) with n = 10 and χ = 1. Open and ﬁlled symbols are

results, respectively, from MC and OPS. Stars, triangles, and dashed curve as in Fig. 2. (b): The

average sign exp(−iSI ) for the same parameters as in (a). At small α the real part of the sign in

MC rapidly approaches zero, and the averages fail to converge. Error bars are comparable to the

symbol sizes if not explicitly shown.

tially with n, causing a breakdown of the method. This is illustrated for the present model

in Fig. 3 with parameters n = 10 and χ = 1. The conventional MC method fails to converge
for α <

∼ 0.1 in contrast to OPS. Moreover, the real part of the sign is strongly suppressed in
the MC results, even at large values of α. The sign problem is evidently strongly suppressed,

if not eliminated entirely for this model in OPS.

The OPS method is applicable to any ﬁeld theory with an action S(z) that is analytic

throughout a domain of z relevant to numerical simulations. This includes the important

cases of classical ﬂuids in the grand canonical ensemble and path integral formulations

of time-dependent quantum chemical problems. Other situations including ﬂuids in the

canonical ensemble, strongly correlated electrons, and lattice gauge theories are characterized

by analytic exp(−S), but with zeros along the real axis and hence logarithmic singularities

8

in S. We believe that OPS will also be useful in such problems, however precautions should

be taken to avoid crossing branch cuts in the steepest descent approach to the optimal

displacement ¯y. Finally, we note that the displaced paths considered here were parallel to

the real axis. Generalization of the method to optimize both the displacement and shape of

the path could prove even more powerful.

In summary, we have identiﬁed a variational principle that permits a global stationary

phase analysis of integrals of arbitrary dimension with analytic integrands. We expect that

this technique will have important implications for analytical and numerical investigations

of ﬁeld theories in the complex plane.

This work was supported in part by the NSF under the MRSEC program award No.

DMR00-80034 and DMR98-70785. We are grateful to H. Metiu, C. Garcia-Cervera, R.

Sugar, J. S. Langer, M. P. A. Fisher, and D. Scalapino for helpful discussions.

[1] I. Montvay and G. M¨unster, Quantum Fields on the Lattice (Cambridge University Press,

Cambridge, 1994).

[2] V. S. Filinov, Nuclear Physics B 271, 717 (1986); J. D. Doll and D. L. Freedman, Adv. Chem.

Phys. 73, 289 (1988); N. Makri and W. H. Miller, Chem. Phys. Lett. 139, 10 (1987).

[3] E. Y. Loh Jr. et al., Physical Review B 41, 9301 (1990).

[4] G. H. Fredrickson, V. Ganesan, and F. Drolet, Macromolecules 35, 16 (2002); S. A. Baeurle,

Phys. Rev. Lett. 89, 080602 (2002).

[5] D. P. Landau and K. Binder, A Guide to Monte Carlo Simulations in Statistical Physics

(Cambridge University Press, New York, 2000).

[6] H. Q. Lin and J. E. Hirsch, Phys. Rev. B 34, 1964 (1986).

[7] G. Parisi, Phys. Lett. B 131, 393 (1983); J. R. Klauder, Phys. Rev. A 29, 2036 (1984).

[8] S. Lee, Nuclear Physics B 413, 827 (1994).

[9] W. J. Schoenmaker, Physical Review D 36, 1859 (1987).

[10] C. M. Bender and S. A. Orszag, Advanced Mathematical Methods for Scientists and Engineers

(McGraw-Hill Publishing Company, New York, 1978).

[11] A. D. Kennedy, Parallel Computing 25, 1311 (1999); P. J. Rossky and J. D. Doll, J. Chemical

Physics 69, 4628 (1978).

9

[12] D. Sabo, J. D. Doll, and D. L. Freedman, J. Chemical Physics 116, 3509 (2002).

10

