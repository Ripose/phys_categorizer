Fast Algorithm for Finding the Eigenvalue Distribution of Very

Large Matrices

Anthony HAMS and Hans De RAEDT

Institute for Theoretical Physics and Materials Science Centre,

University of Groningen, Nijenborgh 4, NL-9747 AG Groningen, The Netherlands

(DRAFT: February 12, 2008)

Abstract

A theoretical analysis is given of the equation of motion method, due to
Alben et al., to compute the eigenvalue distribution (density of states) of
very large matrices. The salient feature of this method is that for matrices of
the kind encountered in quantum physics the memory and CPU requirements
of this method scale linearly with the dimension of the matrix. We derive a
rigorous estimate of the statistical error, supporting earlier observations that
the computational eﬃciency of this approach increases with matrix size. We
use this method and an imaginary-time version of it to compute the energy
and the speciﬁc heat of three diﬀerent, exactly solvable, spin-1/2 models and
compare with the exact results to study the dependence of the statistical
errors on sample and matrix size.

PACS numbers: 05.10.-a, 05.30.-d, 0.3.67.Lx

0
0
0
2

 
r
p
A
0
1

 

 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 

1
v
6
1
0
4
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Typeset using REVTEX

1

I. INTRODUCTION

The calculation of the distribution of eigenvalues of very large matrices is a central
problem in quantum physics. This distribution determines the thermodynamic properties
of the system (see below). It is directly related to the single-particle density of states (DOS)
or Green’s function. In a one-particle (e.g., one-electron) description knowledge of the DOS
suﬃces to compute the transport properties [1].

The most direct method to compute the DOS, i.e. all the eigenvalues, is to diagonalize
the matrix H representing the Hamiltonian of the system. This approach has two obvious
limitations: The number of operations increases as the third power of the dimension D
of H and, perhaps most importantly, the amount of memory required by state-of-the-art
algorithms grows as D2 [2,3]. This scaling behavior limits the application of this approach
to matrices of dimension D = O(10000), which is too small for many problems of interest.
What is needed are methods that scale linearly with D.
There has been considerable interest in developing “fast” (i.e. O(D)) algorithms to
compute the DOS and other similar quantities. One such algorithm and an application
of it to electron motion in disordered alloy models was given by Alben et al. [4]. In this
approach the DOS is obtained by solving the time-dependent Schr¨odinger equation (TDSE)
of a particle moving on a lattice, followed by a Fourier transform of the retarded Green’s
function [4]. Using the unconditionally stable split-step Fast Fourier Transform (FFT)
method to solve the TDSE, it was shown that the eigenvalue spectrum of a particle moving
in continuum space can be computed in the same manner [5]. Fast algorithms of this
kind proved useful to study various aspects of localization of waves [6–8] and other one-
particle problems [9,10]. Application of these ideas to quantum many-body systems triggered
further development of ﬂexible and eﬃcient methods to solve the TDSE. Based on Suzuki’s
product formula approach, an unconditionally stable algorithm was developed and used to
compute the time-evolution of two-dimensional S=1/2 Heisenberg-like models [11]. Results
for the DOS of matrices of dimension D ≈ 1000000 where reported [11]. A potentially
interesting feature of these fast algorithms is that they may run very eﬃciently on a quantum
computer [12,13].

A common feature of these fast algorithms is that they solve the TDSE for a sample
of randomly chosen initial states. The eﬃciency of this approach as a whole relies on
the hypothesis (suggested by the central limit theorem) that satisfactory accuracy can be
achieved by using a small sample of initial states. Experience not only shows that this
hypothesis is correct, it strongly suggests that for a ﬁxed sample size the statistical error on
physical quantities such as the energy and speciﬁc heat decreases with the dimension D of
the Hilbert space [12].

In view of the general applicability of these fast algorithms to a wide variety of quantum
problems it seems warranted to analyze in detail their properties and the peculiar D depen-
dence in particular. In Sections II and III we recapitulate the essence of the approach. We
present a rigorous estimate for the mean square error (variance) on the trace of a matrix. In
Section IV we describe the imaginary-time version of the method. The statistical analysis of
the numerical data is discussed in Section V. Section VI describes the model systems that
are used in our numerical experiments. The algorithm used to solve the TDSE is reviewed
in Section VII. In Section VIII we derive rigorous bounds on the accuracy with which all

2

eigenvalues can be determined and demonstrate that this accuracy decreases linearly with
the time over which the TDSE is solved. The results of our numerical calculations are
presented in Section IX and our conclusions are given in Section X.

II. THEORY

The trace of a matrix A acting on a D-dimensional Hilbert-space spanned by an or-

thonormal set of states {|φni} is given by

Tr A =

DXn=1hφn|Aφni.

(1)

Note that according to (1) we have Tr 1 = D. If D is very large one might think of approx-
imating Eq. (1) by sampling over a subset of K (K ≪ D)“important” basis vectors. The
problem with this approach is that the notion “important” may be very model-dependent.
Therefore it is better to sample in a diﬀerent manner. We construct a random vector |ψi by
choosing D complex random numbers, cn ≡ fn + ign, with mean 0, for n = 1 . . . D, so

and calculate

|ψi =

DXn=1

cn|φni,

hψ|Aψi =

DXn,m=1

c∗
mcnhφm|Aφni.

(2)

(3)

If we now sample over S realizations of the random vectors {ψ} and calculate the average,
we obtain

1
S

SXp=1hψp|Aψpi =

1
S

SXp=1

DXn,m=1

c∗
m,pcn,phφm|Aφni.

(4)

Assuming that there is no correlation between the random numbers in diﬀerent realizations
and that the random numbers fn,p and gn,p are drawn from an even and symmetric (both
with respect to each variable) probability distribution (see Appendix A for more details),
we have

lim
S→∞

1
S

SXp=1

c∗

m,pcn,p = E(cid:16)|c|2(cid:17) δm,n,

(5)

where E (.) denotes the expectation value with respect to the probability distribution used
to generate the cn,p’s. In the r.h.s of (5) the subscripts of cn,p have been dropped to indicate
that the expectation value does not depend on n or p. It follows immediately that

lim
S→∞

1
S

SXp=1hψp|Aψpi = E(cid:16)|c|2(cid:17) Tr A = E(cid:16)|c|2(cid:17) DXn=1hφn|Aφni,

(6)

3

According to the central limit theorem, for a large but ﬁnite S we have

showing that we can compute the trace of A by sampling over random states {ψp}, provided
there is an eﬃcient algorithm to calculate hψp|Aψpi (see Section VII).
m,pcn,p = E(cid:16)|c|2(cid:17) δm,n + O  1
√S! ,

meaning that the statistical error on the trace vanishes like 1/√S, a result which is all but
surprising. What is surprising is that one can proof a much stronger result as follows. Let
us ﬁrst normalize the cn,p’s such that, for all p,

SXp=1

1
S

(7)

c∗

DXn=1|cn,p|2 = 1.

(8)

This innocent looking step has far reaching consequences, as we will see. First we note that
the normalization renders the method exact in (the rather trivial) case that the matrix A
is proportional to the unit matrix. The price we pay for this is that for ﬁxed p, the cn,p are
now correlated but that is not causing problems (see Appendix A). Second it follows that
E (|c|2) = 1/D.

Obviously the error can be written as

where

Tr A −

D
S

SXp=1hψp|Aψpi = Tr RA,

Rm,n ≡ δm,n −

D
S

SXp=1

c∗
m,pcn,p,

(9)

(10)

is a traceless (due to Eq. (8)) Hermitian matrix of random numbers. Invoking a generaliza-
tion of Markov’s inequality [14]

P(|X|2 ≥ a) ≤

E(|X|2)

a

;

∀ a > 0,

(11)

where P(Q) denotes the probability for the statement Q to be true, we put X = Tr RA and
compute E(|X|2) to obtain a rigorous estimate of the square of the error.
tion of the cn,p’s on the hyper-sphere deﬁned by PD

The result for the general case can be found in Appendix A. For a uniform distribu-
n=1 |cn,p|2 = 1 the expression simpliﬁes

considerably and we ﬁnd

E(cid:16)|Tr RA|2(cid:17) =

D Tr A†A − | Tr A|2

S(D + 1)

,

(12)

an exact expression for the variance in terms of the sample size S, the dimension D of the
matrix A and the (unknown) constants Tr A†A and | Tr A|.

The probability that | Tr RA|2 exceeds a fraction a of | Tr A|2 is bounded by
∀ a > 0,

P | Tr RA|2

D Tr A†A − | Tr A|2

| Tr A|2 ≥ a! ≤

| Tr A|2

a S (D + 1)

1

;

(13)

4

or, in other words, the relative statistical error eA on the estimator of the trace of A is given
by

eA ≡vuut D Tr A†A − | Tr A|2

S(D + 1)| Tr A|2

.

(14)

We see that eA = 0 if A is proportional to a unit matrix. From (14) it follows that, in general,
we may expect eA to vanish with the square root of SD. The prefactor is a measure for the
relative spread of the eigenvalues of A and is obviously model dependent. The dependence
of eA on S, D and the spectrum of A is corroborated by the numerical results presented
below.

It is also of interest to examine the eﬀect of not normalizing the cn,p’s. A calculation

similar to the one that lead to the above results yields

eA =vuut Tr A†A
S| Tr A|2 .

(15)

Clearly this bound is less sharp and does not vanish if A is proportional to a unit matrix.

III. REAL-TIME METHOD

The distribution of eigenvalues or density of states (DOS) of a quantum system is deﬁned

as

D(ǫ) =

DXn=1

δ(ǫ − En) =

1

2πZ ∞

−∞

eitǫ Tr e−itH dt,

(16)

where H is the Hamiltonian of the system and n runs over all the eigenvalues of H. The
DOS contains all the physical information about the equilibrium properties of the system.
For instance the partition function, the energy, and the heat capacity are given by

−∞
1

Z =Z ∞
Z Z ∞
C = β2(cid:18) 1

E =

−∞

dǫD(ǫ) e−β ǫ,

dǫ ǫD(ǫ) e−β ǫ,
Z Z ∞

dǫ ǫ2 D(ǫ) e−β ǫ − E2(cid:19) ,

−∞

(17)

(18)

(19)

respectively. Here β = 1/kBT and kB is Boltzmann’s constant (we put kB = 1 and  = 1
from now on).

As explained above the trace in the integral (16) can be estimated by sampling over
random vectors. For the statistical error analysis discussed below it is convenient to deﬁne
a DOS-per-sample by

dp(ǫ) ≡

1

2πZ ∞

−∞

eitǫ hψp|e−itH ψpidt,

(20)

5

where the subscript p labels the particular realization of the random state |ψpi. The DOS
is then given by

D(ǫ) = lim

S→∞

1
S

SXp=1

dp(ǫ).

(21)

Schematically the algorithm to compute dp(ǫ) consists of the following steps:

1. Generate a random state |ψp(0)i, set t = 0.
2. Copy this state to |ψp(t)i.
3. Solve the TDSE for a small time step τ , replacing |ψp(t)i by |ψp(t + τ )i (see Section VII

for model speciﬁc details).

4. Calculate hψ0|ψp(t)i and store the result.
5. Repeat N times from step 3.

6. Perform a Fourier transform on the tabulated result and store dp(ǫ).

In practice the Fourier transform in Eq. (16) is performed by the Fast Fourier Transform
(FFT). We use a Gaussian window to account for the ﬁnite time τ N used in the numerical
time-integration of the TDSE. The number of time step N determines the accuracy with
which the eigenvalues can be computed. In Section VIII we prove that this systematic error
in the eigenvalues vanishes as 1/τ N.

Since for any reasonable physical system (or ﬁnite matrix) the smallest eigenvalue E0
is ﬁnite, for all practical purposes dp(ǫ) = 0 for ǫ < ǫ0 < E0. The value of ǫ0 is easily
determined by examination of the bottom of spectrum. To compute Z, E, or C we simply
replace the interval [−∞, +∞] by [ǫ0, +∞].

IV. IMAGINARY-TIME METHOD

The real-time approach has the advantage that it yields information on all eigenvalues
and can be used to compute both dynamic and static properties without suﬀering from
numerical instabilities. However for the computation of the thermodynamic properties, the
imaginary-time version is more eﬃcient. We will use the imaginary-time method as an
independent check on the results obtained by the real-time algorithm.

Repeating the steps that lead to Eq. (17) we ﬁnd

Z = Tr exp(−βH)

= lim
S→∞

with similar expressions for E and C.

Furthermore we have

1
S

SXp=1hψp| exp(−βH)ψpi,

hψp|H ne−βHψpi = he−βH/2ψp|H ne−βH/2ψpi,

6

(22)

(23)

assuming H is Hermitian as usual. Therefore we only need to propagate the random state
for an imaginary time β/2 instead of β. Furthermore we do not need to perform an FFT.
Disregarding these minor diﬀerences, the algorithm is the same as in the real-time case with
τ replaced by −iτ .

V. ERROR ANALYSIS

Estimating the statistical error on the partition function Z is easy because it depends
linearly on the trace of the (imaginary) time evolution operator. However the error on E
and C depends on this trace in a more complicate manner and this fact has to be taken into
account.

First we deﬁne

ǫ0

zp ≡Z ∞
hp ≡Z ∞
wp ≡Z ∞

ǫ0

ǫ0

dǫ dp(ǫ) e−βǫ,

dǫ dp(ǫ) ǫ e−βǫ,

dǫ dp(ǫ) ǫ2 e−βǫ,

for the real-time method and

zp ≡ hψp|e−βHψpi,
hp ≡ hψp|He−βHψpi,
wp ≡ hψp|H 2e−βHψpi,

(24)

(25)

(26)

(27)

(28)

(29)

for the imaginary-time method.

For each value of β we generate the data {zp}, {hp}, and {wp}, for p = 1, . . . , S. For

both cases we have

where x ≡ S−1PS

p=1 xp. The standard deviations on z, h, and w are given by

Z = lim
S→∞

z,

E = lim
S→∞

h
z

,

C = lim
S→∞

2
h

z2 ,

w
z −

β2
δz =s var(z)
S − 1
δh =s var(h)
S − 1
δw =s var(w)
S − 1

,

,

,

7

(30)

(31)

(32)

(33)

(34)

(35)

where var(x) ≡ x2 − x2 denotes the variance on the data {xp}. However the sets of data
{zp}, {hp} and {wp} are correlated since they are calculated from the same set {|ψpi}.
These correlations in the data are accounted for by calculating the covariance matrix Mk,l
(k, l = 1, . . . , 3) the elements of which are given by xkxl − xk xl, where {x1}, {x2}, and {x3}
are a shorthand for {zp}, {hp}, and {wp} respectively. The estimates for the errors in Z, E
and C are given by

1

S − 1

1

S − 1

1

δZ 2 =

δE2 =

δC 2 =

δz2,

3Xk,l=1
3Xk,l=1

Mk,l

Mk,l

dE
d xk

dE
d xl

dC
d xk

dC
d xl

,

,

(36)

(37)

(38)

S − 1
where E = h/z and and C = β2(w/z − h

2

/z2).

VI. EXACTLY SOLVABLE SPIN 1/2 MODELS

The most direct way to assess the validity of the approach described above is to carry out
numerical experiments on exactly solvable models. In this paper we consider three diﬀerent
exactly solvable models, two spin-1/2 chains and a mean-ﬁeld spin-1/2 model. The former
have a complicated spectrum, the latter has a highly degenerate eigenvalue distribution.
These spin models diﬀer from those studied elsewhere [11,12] in that they belong to the
class of integrable systems.

Open spin chains of L sites described by the Hamiltonian

A. Spin chains

H = −J

L−1Xi=1

(σx

i σx

i+1 + ∆σy

i σy

i+1) − h

σz
i ,

LXi=1

(39)

i , σy

i , and σz

where σx
i denote the Pauli matrices and J, ∆ and h are model parameters, can
be solved exactly. They can be reduced to diagonal form by means of the Jordan-Wigner
transformation [15]. We have

H =

LXi,j=1(cid:20)c+

i Ai,jcj +

1

2(cid:16)c+

i Bi,jc+

j + cj B∗

j,ici (cid:17)(cid:21) + hL,

where c+

i and ci are spin-less fermion operators and

Ai,j = −J(1 + ∆)(δi,j−1 + δi−1,j) − 2hδi,j,
Bi,j = −J(1 − ∆)(δi,j−1 − δi−1,j),

8

(40)

(41)
(42)

are L× L matrices. By further canonical transformation this Hamiltonian can be written as

H =

Λk(cid:18)nk −

1

2(cid:19) +

1
2

LXk=1

Tr A + hL,

(43)

where nk is the number operator of state k and the Λk’s are given by the solution of the
eigenvalue equation

(A − B)(A + B)φk = Λ2

k φk.

(44)

In the general case this eigenvalue problem of the L × L Hermitian matrix (A − B)(A + B)
is most easily solved numerically. In the present paper we conﬁne ourselves to two limiting
cases: The XY model (∆ = 1) and the Ising model in a transverse ﬁeld (∆ = 0).

B. Mean ﬁeld model

The Hamiltonian of the mean-ﬁeld model reads

and can be rewritten as

with

H = −

J
L

LXi>j=1

~σi · ~σj − h

σz
i ,

LXi=1

H = −2

J
L

~S · ~S − 2hSz +

3
2

J,

~S =

1
2

LXi=1

~σi.

The single spin-L/2 Hamiltonian has eigenvalues

with degeneracy

El,m = −2Jl(l + 1)/L − 2hm +

3
2

J,

nl,m =

2l + 1

L/2 + l + 1 

L

L/2 − l! .

(45)

(46)

(47)

(48)

(49)

This rather trivial model serves as a test for the case of highly degenerate eigenvalues.

VII. TIME EVOLUTION

For the approach outlined in Sections III and IV to be of practical use it is necessary
that the matrix elements of the exponential of H can be calculated eﬃciently. The purpose
of this section is to describe how this can be done.

9

The general form of the Hamiltonians of the models we study is

H = −

LXi,j=1 Xα=x,y,z

J α
i,jσα

i σα

j −

LXi=1 Xα=x,y,z

i σα
hα
i ,

(50)

where the ﬁrst sum runs over all pairs P of spins, σα
i (α = x, y, z) denotes the α-th component
of the spin-1/2 operator representing the i-th spin. For both methods, we have to calculate
the evolution of a random state, i.e. U(τ )|ψi ≡ exp(−iτ H)|ψi or U(τ )|ψi ≡ exp(−τ H)|ψi
for the real and imaginary time method respectively. We will discuss the real-time case only,
the imaginary-time problem can be solved in the same manner.

Using the semi-group property of U(t) we write U(t) = U(τ )m where t = mτ , the main
step is to replace U(τ ) by a symmetrized product-formula approximation [17]. For the case
at hand it is expedient to take

U(τ ) ≈ eU (τ ) ≡e−iτ Hz/2e−iτ Hy/2e−iτ Hxe−iτ Hy/2e−iτ Hz/2,

where

Hα = −

LXi,j=1

J α
i,jσα

i σα

j −

hα
i σα
i

; α = x, y, z.

LXi=1

(51)

(52)

Other decompositions [11,18] work equally well but are somewhat less eﬃcient for the cases

stable [17] (also the imaginary-time method can be made unconditionally stable). It can

is correct to second order in the time step τ [17]. Usually it is not diﬃcult to choose τ so
small that for all practical purposes the results obtained can be considered as being “exact”.

at hand. In the real-time approach eU (τ ) is unitary and hence the method is unconditionally
be shown that kU(τ ) − eU (τ )k ≤ sτ 3 (s > 0 a constant) [19], implying that the algorithm
Moreover, if necessary, eU (τ ) can be used as a building block to construct higher-order
As basis states {|φni} we take the direct product of the eigenvectors of the Sz

algorithms [20–23]. In Appendix B we will derive bounds on the error in the eigenvalues
when they are calculated using a symmetric product formula.

i (i.e. spin-up
|↑ii and spin-down |↓ii). In this basis, e−iτ Hz/2 changes the input state by altering the phase
of each of the basis vectors. As Hz is a sum of pair interactions it is trivial to rewrite this
operation as a direct product of 4x4 diagonal matrices (containing the interaction-controlled
phase shifts) and 4x4 unit matrices. Still working in the same representation, the action of
e−iτ Hy/2 can be written in a similar manner but the matrices that contain the interaction-
controlled phase-shift have to be replaced by non-diagonal matrices. Although this does
not present a real problem it is more eﬃcient and systematic to proceed as follows. Let us
denote by X(Y ) the rotation by π/2 of each spin about the x(y)-axis. As

e−iτ Hy/2 = XX †e−iτ Hy/2XX † = Xe−iτ H ′

z/2X †,

(53)

it is clear that the action of e−iτ Hy/2 can be computed by applying to each spin, the inverse of
X followed by an interaction-controlled phase-shift and X itself. The prime in (53) indicates
that J z
i respectively. A similar procedure
is used to compute the action of e−iτ Hx. We only have to replace X by Y .

i in Hz have to be replaced by J y

i,j and hy

i,j and hz

10

VIII. ACCURACY OF THE COMPUTED EIGENVALUES

First we consider the problem of how to choose the number of time steps N to obtain
the DOS with acceptable accuracy. According to the Niquist sampling theorem employing
a sampling interval ∆t = π/ maxi |Ei| is suﬃcient to cover the full range of eigenvalues. On
the other hand the time step also determines the accuracy of the approximation eU (τ ). Let
us call the maximum value of τ which gives satisfactory accuracy τ0 (for the imaginary-time
method, this is the only parameter). For the examples treated here τ0 < ∆t), implying that
we have to use more steps to solve the TDSE than we actually use to compute the FFT.
Eigenvalues that diﬀer less than ∆ǫ = π/N∆t cannot be identiﬁed properly. However since
∆ǫ ∝ N −1 we only have to extend the length of the calculation by a factor of two to increase
the resolution by the same factor.
Indeed it ap-
parently overlooks the fact that if we integrate the TDSE over longer and longer times the
error on the wave function increases too (although it remains bounded because of the un-
conditional stability of the product formula algorithm). In fact it has been shown that in
general [17]

At ﬁrst glance the above reasoning may seem to be a little optimistic.

ke−itH|ψ(0)i − eU m(τ )|ψ(0)ik ≤ cτ 2t,

where t = mτ , suggesting that the loss in accuracy on the wave function may well com-
pensate for the gain in resolution that we get by using more data in the Fourier transform.
Fortunately this argument does not apply when we want to determine the eigenvalues as we
now show. As before we will discuss the real-time algorithm only because the same reasoning
(but diﬀerent mathematical proofs) holds for the imaginary-time case.

Consider the time-step operator (52). Using the fact that any unitary matrix can be

written as the matrix exponential of a Hermitian matrix we can write

(54)

(55)

eU (τ ) = e−iτ Hz/2e−iτ Hy/2e−iτ Hxe−iτ Hy/2e−iτ Hz/2 ≡ e−iτeH(τ ).

It is clear that in practice the real-time method yields the spectrum of fH(τ ), not the one
of H. Therefore the relevant question is: How much do the spectra of fH(τ ) and H diﬀer?
In Appendix B we give a rigorous proof that the diﬀerence between the eigenvalues of fH(τ )

and H vanishes as τ 2. In other words the value of m (or t = mτ ) has no eﬀect whatsoever
on the accuracy with which the spectrum can be determined. Therefore the ﬁnal conclusion
is that the error in the eigenvalues vanishes as τ 2/N where N is the number of data points

used in the Fourier transform of Tr e−iteH(τ ).

IX. RESULTS

In all our calculations we take J = 1 and h = 0, except for the Ising model in a
transverse ﬁeld, where we take h = 0.75. The random numbers cn,p are generated such that
the conditions Eqs. (A3) and (A4) are satisﬁed. We use two diﬀerent techniques to generate
these random numbers:

11

1. A uniform random number generator produces {fn,p} and {gn,p} with −1 ≤ fn,p, gn,p ≤

1. We then normalize the vector (see Eq. (8)).

2. The cn,p’s are obtained from a two-variable (real and imaginary part) Gaussian random

number generator and the resulting vector is normalized.

Both methods satisfy the basic requirements Eqs. (A3) and (A4) but because the ﬁrst picks
points out of a 2D-dimensional hypercube and subsequently projects the vector onto a
sphere, the points are not distributed uniformly over the surface of the unit hyper-sphere.
The second method is known to generate numbers which are distributed uniformly over the
hyper-surface. Although the ﬁrst method does not satisfy all the mathematical conditions
that lead to the error (14), our numerical experiments with both generators give identical
results, within statistical errors of course. Also within the statistical errors, the results
from the imaginary and real-time algorithm are the same. Therefore we only show some
representative results as obtained from the real-time algorithm.

In Fig. 1 we show a typical result for the DOS D(ǫ) of the XY model, the Ising model
in a transverse ﬁeld and the mean-ﬁeld model, all with L = 15 spins and using S = 20
samples. Because of the very high degeneracy we plotted the DOS for the mean-ﬁeld model
on a logarithmic scale.

In Fig. 2 we show the relative error δZ/Z based on Eq. (36) for the three models of various
size, as obtained from the simulation (symbols). For these ﬁgures we used the imaginary-
time algorithm, because then the statistical error can be related to eA directly (see Eq. (14)
with A = exp(−βH)). The theoretical results (lines) for the error estimate, obtained by a
direct exact numerical evaluation of (14) are shown too. We conclude that for all systems,
lattice sizes and temperatures there is very good agreement between numerical experiment
and theory.

Results for the energy E and speciﬁc heat C are presented in Fig. 3 (XY model), 4 (Ising
model in a transverse ﬁeld), and 5 (mean-ﬁeld model). The solid lines represent the exact
result for the case shown. Simulation data as obtained from S = 5 and S = 20 samples are
represented by symbols, the estimates of the statistical error by error bars. We see that the
data are in excellent agreement with the exact results and equally important, the estimate
for the error captures the deviation from the exact result very well. We also see that in
general the error decreases with the system size. Both the imaginary and real-time method
seem to work very well, yielding accurate results for the energy and speciﬁc heat of quantum
spin systems with modest amounts of computational eﬀort.

X. CONCLUSIONS

The theoretical analysis presented in this paper gives a solid justiﬁcation of the remark-
able eﬃciency of the real-time equation-of-motion method for computing the distribution of
all eigenvalues of very large matrices. The real-time method can be used whenever the more
conventional, Lanczos-like, sparse-matrix techniques can be applied: Memory and CPU re-
quirements for each iteration (time-step) are roughly the same (depending on the actual
implementation) for both approaches.

We do not recommend using the real-time method if one is interested in the smallest
(or largest) eigenvalue only. Then the Lanczos method is computationally more eﬃcient

12

because it needs less iterations (time-steps) than the real-time approach. However if one
needs information about all eigenvalues and direct diagonalization is not possible (because
of memory/CPU-time) there is as yet no alternative to the real-time method. The matrices
used in this example (up to 32768 × 32768) are not representative in this respect: The
real-time method has been used to compute the distribution of eigenvalues for matrices of
dimension 16777216 × 16777216 [11].
Once the eigenvalue distribution is known the thermodynamic quantities directly follow.
However if one is interested in the accurate determination of the temperature dependence
of thermodynamic (and static correlation functions) properties but not in the eigenvalue
distribution itself, the imaginary-time method is by far the most eﬃcient method to compute
these quantities. For instance the calculation of the thermodynamic properties for βJ =
0, . . . , 10 of a 15-site spin-1/2 system (i.e. implicitly solving the full 32768×32768 eigenvalue
problem) takes 1410 seconds per sample on a Mobile Pentium III 500 Mhz system.
Finally we remark that although we used quantum-spin models to illustrate various
aspects, there is nothing in the real or imaginary-time method that is speciﬁc to the models
used. The only requirement for these methods to be useful in practice is that the matrix is
sparse and (very) large.

ACKNOWLEDGMENTS

Support from the Dutch “Stichting Nationale Computer Faciliteiten (NCF)” and the
Dutch “Stichting voor Fundamenteel Onderzoek der Materie (FOM)” is gratefully acknowl-
edged.

APPENDIX A: EXPECTATION VALUE CALCULATION

In this appendix we calculate the expectation value of the error squared, as deﬁned in

Section II. By deﬁnition we have

1
S

E(cid:16)|Tr RA|2(cid:17) = E
2
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
m,pcn,p(cid:17) Am,n(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
DXm,n=1(cid:16)δm,n − D c∗
SXp=1
DXk,l,m,n=1(cid:16)δk,lδm,n − D δk,l E(c∗
SXp,p′=1
l,p′)(cid:17) A∗

−D δm,n E(ck,p′c∗

l,p′) + D2 E(c∗

m,p cn,p ck,p′ c∗

m,pcn,p)

=

1
S2

where p and p′ label the realization of the random numbers cn,p ≡ fn,p + ign,p.

First we assume that diﬀerent realizations p 6= p′ are independent implying that

E(c∗

m,p cn,p ck,p′ c∗

l,p′)p6=p′ = E(c∗

m,p cn,p)E(ck,p′ c∗

l,p′).

Second we assume that the random numbers are drawn from a probability distribution that

13

k,lAm,n,

(A1)

(A2)

is an even function of each variable

P (f1,p, g1,p, f2,p, g2,p, . . . , fk,p, gk,p, . . . , fD,p, gD,p)
= P (f1,p, g1,p, f2,p, g2,p, . . . ,−fk,p, gk,p, . . . , fD,p, gD,p)
= P (f1,p, g1,p, f2,p, g2,p, . . . , fk,p,−gk,p, . . . , fD,p, gD,p),

and symmetric under interchange of any two variables

P (f1,p, g1,p, . . . , fi,p, gi,p, . . . , fj,p, gj,p, . . . , fD,p, gD,p)
= P (f1,p, g1,p, . . . , fj,p, gi,p, . . . , fi,p, gj,p, . . . , fD,p, gD,p)
= P (f1,p, g1,p, . . . , gi,p, fi,p, . . . , fj,p, gj,p, . . . , fD,p, gD,p),

(A3)

(A4)

for all i, j, k = 1, . . . , D. This is most easily done by drawing individual numbers from the
same even probability distribution i.e.

P (f1,p, g1,p, . . . , fj,p, gi,p, . . . , fi,p, gj,p, . . . , fD,p, gD,p) =

DYn,m=1

P (fn,p)P (gn,p),

(A5)

where P (x) = P (−x).
PD
i=1 |cn,p|2 = 1 (for p = 1, . . . , S) does not aﬀect the basic requirements (A3) and (A4).
Making use of the above properties of P (f1, g1, . . . , fD, gD) we ﬁnd that

Normalizing the vector (f1,p, g1,p, . . . , fD,p, gD,p) such that

E(c∗

m,pcn,p) = δm,nE(|cm,p|2) = δm,nE(|c|2),

(A6)

where in the last equality we omitted the subscripts of cm,p to indicate that the expectation
value does not depend on m or p. An expectation value of a product of two c∗’s and two c’s
can be written as
E(c∗

m,p cn,p ck,p′ c∗

l,p′) =(1 − δp,p′)δm,nδk,lE(|cm,p|2)E(|cm,p′|2)
m cm ck c∗
k)
m cn cm c∗
n)
m cn cn c∗
m)

+ δp,p′δm,nδk,l(1 − δmk)E(c∗
+ δp,p′δm,kδn,l(1 − δm,n)E(c∗
+ δp,p′δm,lδn,k(1 − δm,n)E(c∗
+ δp,p′δm,lδn,kδm,nE(c∗
=(1 − δp,p′)δm,nδk,lE(|c|2)2

m cm cm c∗

m)

+ δp,p′δm,nδk,l(1 − δm,k)E(|cm,p|2 |ck,p|2)
+ δp,p′δm,kδn,l(1 − δm,n)E(|cm,p|2 |cn,p|2)
+ δp,p′δm,lδn,k(1 − δm,n)E(c∗
m,p cn,p cn,p c∗
+ δp,p′δm,lδn,kδm,nE(|cm,p|4).

m,p)

m,p − 2ifm,pgm,p − g2
m,pf 2

n,p) + 2iE(f 2

m,p)(f 2

n,p + 2ifn,pgn,p − g2

n,p))

m,pfn,pgn,p) − E(f 2

m,pg2

n,p)

n,p) + 4E(fm,pfn,pgm,pgn,p) + 2iE(fm,pgm,pg2

n,p)

m,pfn,pgn,p) + E(g2
n,p) − E(f 2

n,p)
n,p) + E(g2

m,pg2

m,pg2

m,pg2

n,p)

(A7)

(A8)

Furthermore for m 6= n we have
m,p) =E((f 2
=E(f 2

m,p cn,p cn,p c∗

E(c∗

− 2iE(fm,pgm,pf 2
− E(g2
m,pf 2

m,pf 2
n,p) − E(g2

n,p) − 2iE(g2
m,pf 2

=E(f 2
=0.

14

By symmetry E(|cm,p|2 |cn,p|2) does not depend on m, n or p and the same holds for
E(|cm,p|4).

The fact that the vector (c1,p, . . . , cD,p) is normalized yields the identities

DXn=1

E(|cn,p|2) = DE(|c|2) = E(1) = 1,

(A9)

and

E  DXn=1|cn,p|2! =
E  DXn=1|cn,p|2!2 =

DXm,n=1
DXn=1
(1 − δm,n)E(|cn|2|cm|2)
E(|cn,p|4) +
= DE(|c|4) + D(D − 1)E(|c|2|c′|2) = E(1) = 1,

E(|cn,p|2|cm,p|2)
DXm,n=1

=

(A10)

(A11)

(A12)

where c and c′ refer to two diﬀerent complex random variables. Therefore we have

and

Substitution into (A7) yields

E(|c|2) = 1/D,

E(|c|2|c′|2) =

1 − DE(|c|4)
D(D − 1)

.

E(c∗

m,p cn,p ck,p′ c∗

(δm,nδk,l(1 − δm,k) + δm,kδn,l(1 − δm,n))

l,p′) =(1 − δp,p′)δm,nδk,lD−2
1 − DE(|c|4)
D(D − 1)

+ δp,p′
+ δp,p′δm,lδn,kδm,nE(|c|4).
S   D − D2E(|c|4)
(D + 1)D2E(|c|4) − 2D

D − 1

+

1

D − 1

Tr A†A +

1 − D2E(|c|4)

D − 1

DXn=1|An,n|2! .

and the ﬁnal result for the variance reads

E(cid:16)|Tr RA|2(cid:17) =

(A13)

(A14)

| Tr A|2

An expression for the fourth moment E(|c|4) cannot be derived from general properties of
the probability distribution or normalization of random vector. We can only make progress
by specifying the former explicitly. As an example we take a probability distribution such
that for each realization p the random numbers fn,p and gn,p are distributed uniformly over
the surface of a 2D-dimensional sphere of radius 1. This probability distribution can be
written as

P (f1, g1, f2, g2, . . . , fD, gD) ∝ δ(f 2

1 + g2

1 + f 2

2 + g2

2 + . . . + f 2

D + g2

D − 1),

(A15)

15

n + g2

where we omitted the subscript p because it is irrelevant for what follows. The even moments
of |cn| = (f 2
E(|c|2M ) = R ∞

n)1/2 are deﬁned by
1 + g2

D + g2
D − 1)df1dg1 . . . dfDdgD

D − 1)df1dg1df2dg2 . . . dfDdgD
.
(A16)

2 + . . . + f 2

1 + . . . + f 2

1)M δ(f 2

−∞ δ(f 2

D + g2

−∞(f 2

1 + f 2

2 + g2

1 + g2

1 + g2

R ∞

It is expedient to introduce an auxiliary integration variable X by

E(|c|2M ) = R ∞

−∞ X M δ(f 2

1 + g2

1 − X)δ(f 2
R ∞
−∞ δ(f 2

2 + g2
1 + g2

2 + . . . + f 2
1 + . . . + f 2

D + g2
D + g2

D − (1 − X))dXdf1dg1df2dg2 . . . dfDdgD
.
D − 1)df1dg1 . . . dfDdgD
(A17)

We can perform the integration over X last and regard (A17) as the M-th moment of the
variable X with respect to the probability distribution
D + g2
D + g2

D − (1 − X))df1dg1df2dg2 . . . dfDdgD
.
D − 1)df1dg1 . . . dfDdgD
(A18)

P (X) = R ∞

2 + . . . + f 2
1 + . . . + f 2

2 + g2
1 + g2

−∞ δ(f 2

1 + g2

The calculation of P (X) amounts to computing integrals of the form

1 − X)δ(f 2
R ∞
−∞ δ(f 2
IN (X) =Z ∞

−∞

x2

δ  NXn=1
Γ(N/2)Z ∞

0

πN/2

Γ(N/2)

n − X! dx1dx2 . . . dxN .

rN −1δ(r2 − X)dr

X N/2−1θ(X),

Changing to spherical coordinates we have
2πN/2

IN (X) =

yielding

=

(A19)

(A20)

(A21)

(A22)

(A23)

P (X) =

I2(X)I2D−2(1 − X)

I2D(1)

= (D − 1)(1 − X)D−2θ(X) θ(1 − X).

E(|c|2M ) =Z ∞

−∞

X M P (X)dX

= (D − 1)Z 1

0

Γ(D)Γ(1 + M)

Γ(D + M)

,

X M (1 − X)D−2dX

The moments E(|c|2M ) are given by

and the values of interest to us are

=

E(|c|0) = 1, E(|c|2) =

1
D

, E(|c|4) =

2

D(D + 1)

,

where the ﬁrst two results provide some check on the procedure used. Substituting (A23)
into (A14) yields

E(cid:16)|Tr RA|2(cid:17) =

D Tr A†A − | Tr A|2

S(D + 1)

.

16

(A24)

APPENDIX B: ERROR BOUNDS

Here we prove that the diﬀerence between the eigenvalues of the Hermitian matrix A + B
and those obtained from the approximate time-evolution exp(zA/2) exp(zB) exp(zA/2) (z =
−iτ,−τ ) is bounded by τ 2. In the following we assume A and B are Hermitian matrices
and take τ a real, non-negative number. We start with the imaginary-time case.

We deﬁne the diﬀerence R(τ ) by

R(τ ) ≡eτ (A+B) − eτ A/2eτ Beτ A/2

=

1

dλZ λ

4Z τ
+ eνA/2[A, [A, B]]e−νA/2}eλA/2e(τ −λ)(A+B),

dνeλA/2eλB{e−νB[2B, [A, B]]eνB

dµZ µ

0

0

0

(B1)

a well-known result [21]. We have [23]

||R(τ )|| ≤

≤

0

0

0

0

0

1

1

+

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
4(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
dνeλA/2e(λ−ν)B[2B, [A, B]]eνBeλA/2e(τ −λ)(A+B)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Z τ
dλZ λ
dµZ µ
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
4(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
dνeλA/2eλBeνA/2[A, [A, B]]e(λ−ν)A/2e(τ −λ)(A+B)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Z τ
dλZ λ
dµZ µ
4Z τ
dλZ λ
dµZ µ
dνeλ||A||/2e(λ−ν)||B||||[2B, [A, B]]||eν||B||eλ||A||/2e(τ −λ)(||A||+||B||)
4Z τ
dλZ λ
dµZ µ
τ 3eτ (||A||+||B||) (||[A, [A, B]]|| + ||[2B, [A, B]]||) ,

dνeλ||A||/2eλ||B||eν||A||/2||[A, [A, B]]||e(λ−ν)||A||/2e(τ −λ)(||A||+||B||)
(B2)

1
24

0
1

+

=

1

0

0

0

0

0

0

and

||R(−τ )|| ≤

=

≤

=

0

0

0

0

0

0

0

0

0

1

1

1

+

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
4(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
dνeλA/2e(λ−ν)B[2B, [A, B]]eνBeλA/2e(−τ −λ)(A+B)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Z −τ
dλZ λ
dµZ µ
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
dνeλA/2eλBeνA/2[A, [A, B]]e(λ−ν)A/2e(−τ −λ)(A+B)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
4(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
dµZ µ
dλZ λ
Z −τ
dνe−λA/2e(−λ+ν)B[2B, [A, B]]e−νBe−λA/2e(−τ +λ)(A+B)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
4(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
dµZ µ
dλZ λ
Z τ
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
4(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
dνe−λA/2e−λBe−νA/2[A, [A, B]]e(−λ+ν)A/2e(−τ +λ)(A+B)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Z τ
dλZ λ
dµZ µ
4Z τ
dλZ λ
dµZ µ
dνeλ||A||/2e(λ−ν)||B||||[2B, [A, B]]||eν||B||eλ||A||/2e(τ −λ)(||A||+||B||)
dµZ µ
dλZ λ
4Z τ
τ 3eτ (||A||+||B||) (||[A, [A, B]]|| + ||[2B, [A, B]]||) .

dνeλ||A||/2eλ||B||eν||A||/2||[A, [A, B]]||e(λ−ν)||A||/2e(τ −λ)(||A||+||B||)
(B3)

1
24

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

0
1

+

+

1

1

0

0

0

0

0

0

0

0

Hence the bound in R(τ ) does not depend on the sign of τ so that we can write

||R(τ )|| ≤s|τ|3e|τ |(||A||+||B||),

17

(B4)

where

For real τ we have

1
24||[A, [A, B]]|| + ||[2B, [A, B]]||.

s ≡

where C(τ ) is Hermitian. Clearly we have

eτ A/2eτ Beτ A/2 ≡ eτ C(τ ),

eτ (A+B) − eτ C(τ ) = R(τ ).

(B5)

(B6)

(B7)

We already have an upperbound on R(τ ) and now want to use this knowledge to put an
upperbound on the diﬀerence in eigenvalues of C(τ ) and A+B. In general, for two Hermitian
matrices U and V with eigenvalues {un} and {vn} respectively, both sets sorted in non-
decreasing order, we have [2]

|un − vn| ≤ ||U − V ||,

∀ n.

(B8)

Denoting the eigenvalues of A + B and C(τ ) by xn(0) and xn(τ ) respectively, combining
Eq. (B4) and (B8) yields

|eτ xn(0) − eτ xn(τ )| ≤ s|τ|3e|τ |(||A||+||B||).

(B9)

To ﬁnd an upperbound on |xn(0) − xn(τ )| we ﬁrst assume that xn(0) ≤ xn(τ ) and take
τ ≥ 0. It follows from (B9) that

eτ (xn(τ )−xn(0)) − 1 ≤ sτ 3eτ (||A||+||B||)−τ xn(0),

For x ≥ 0, ex − 1 ≥ x and we have −xn(0) ≤ ||A + B|| ≤ ||A|| + ||B||. Hence we ﬁnd

xn(τ ) − xn(0) ≤ sτ 2e2τ (||A||+||B||).

(B10)

(B11)

An upperbound on the diﬀerence in the eigenvalues between C(τ ) and A + B can equally
well be derived by considering the inverse of the exact and approximate time-evolution
operator (B6). This is useful for the case xn(0) > xn(τ ): Instead of using (B7) we start
from exp(−τ (A + B)) − exp(−τ C(−τ )) = R(−τ ) (τ ≥ 0). Note that the set of eigenvalues
of a matrix and its inverse are the same and that the matrices we are considering here, i.e.
matrix exponentials, are nonsingular. Making use of Eq. (B4) for R(−τ ) gives

|e−τ xn(0) − e−τ xn(τ )| ≤ s|τ|3e|τ |(||A||+||B||),

and proceeding as before we ﬁnd

τ (xn(0) − xn(τ )) ≤ eτ (xn(0)−xn(τ )) − 1 ≤ sτ 3e2τ (||A||+||B||).

Putting the two cases together we ﬁnally have

|xn(τ ) − xn(0)| ≤ sτ 2e2τ (||A||+||B||).

18

(B12)

(B13)

(B14)

Clearly (B14) proves that the diﬀerences in the eigenvalues of A + B and C(τ ) vanish as τ 2.
We now consider the case of the real-time algorithm (z = −iτ ). For Hermitian matrices
A and B the matrix exponentials are unitary matrices and hence their norm equals one.
This simpliﬁes the derivation of the upperbound on R(−iτ ). One ﬁnds [17]

||R(−iτ )||E ≤ s|τ|3,

(B15)

E ≡ Tr A†A denotes the Euclidean norm of the matrix A [2].

where ||A||2
In general the
eigenvalues of a unitary matrix are complex valued and therefore the strategy adopted
above to use the bound on R(τ ) to set a bound on the diﬀerence of the eigenvalues no longer
works. Instead we invoke the Wielandt-Hoﬀman theorem [24]:
If U and V are normal matrices with eigenvalues ui and vi respectively, then there exists a
suitable rearrangement (a permutation ̺ of the numbers 1, . . . , n) of the eigenvalues so that

NXj=1|uj − v̺(j)|2 ≤ ||U − V ||2

E .

(B16)

Let U and V denote the exact and approximate real-time evolution operators respectively.
The eigenvalues of A+B and C(τ ) are xn(0) and xn(τ ) respectively. All the xn’s and xn(τ )’s
are real numbers. According to the Wielandt-Hoﬀman theorem

NXj=1|ei τ xj(0) − ei τ yj(τ )|2 ≤ ||R(−iτ )||2

E ≤ s2τ 6.

(B17)

where yj(τ ) = x̺(j)(τ ), ̺ being the permutation such that inequality (B17) is satisﬁed. We
see that Eq. (B17) only depends on (τ xj(0) mod 2π) and (τ yj(τ ) mod 2π), but so does
the DOS (see Eq. (16)). Since the inequality (B17) and the DOS only depend on these
“angles” modulo 2π, there is no loss of generality if we make the choice

Rewriting the sum in (B17) we have

0 ≤ |τ (xj(0) − yj(τ ))| ≤ π.

NXj=1|ei τ xj (0) − ei τ yj(τ )|2 =

= 4

NXj=1
(2 − 2 cos(τ (xj(0) − yj(τ ))))
NXj=1

sin2(τ /2 (xj(0) − yj(τ ))).

As we have

sin2 x ≤

4 x2
π2 , for 0 ≤ |x| ≤ π/2,

the restriction Eq. (B18) allows us to write

NXj=1
(xj(0) − yj(τ ))2 ≤

π2s2

4

τ 4,

19

(B18)

(B19)

(B20)

(B21)

implying

|xj(0) − yj(τ )| ≤

πs
2

τ 2.

(B22)

In summary, we have shown that in the real-time case there exists a permutation of the
approximate eigenvalues such that the diﬀerence with the exact ones vanishes as τ 2.

Finally we note that both upperbounds (B22) and (B14) hold for arbitrary Hermitian
matrices A and B and are therefore rather weak. Except for the fact that they provide
a sound theoretical justiﬁcation for the real and imaginary-time method, they are of little
practical value.

20

REFERENCES

[1] G.D. Mahan, Many-Particle Physics, (Plenum Press, New York, 1981).
[2] J.H. Wilkinson, The Algebraic Eigenvalue Problem, (Clarendon Press, Oxford, 1965).
[3] G.H. Golub and C.F. Van Loan, Matrix computations, (John Hopkins University Press,

Baltimore, 1983).

[4] R. Alben, M. Blume, H. Krakauer, and L. Schwartz, Phys. Rev. B 12, 4090 (1975).
[5] M.D. Feit, J.A. Fleck, and A. Steiger, J. Comput. Phys 47, 412 (1982).
[6] H. De Raedt and P. de Vries, Z. Phys. B 77, 243 (1989).
[7] T. Kawarabayashi and T. Ohtsuki, Phys. Rev. B 53, 6975 (1996).
[8] T. Ohtsuki and T. Kawarabayashi, J. Phys. Soc. Jap. 66, 314 (1997).
[9] T. Iitaka, RIKEN Rev. 19, 136 (1998).
[10] T. Iitaka and T. Ebisuzaki, Mic. Eng. 47, 321 (1999).
[11] P. de Vries and H. De Raedt, Phys. Rev. B 47, 7929 (1993).
[12] H. De Raedt, A. Hams, K. Michielsen, S. Miyashita, and K. Saito, Prog. Theor. Phys.,

in press.

[13] D.S. Abrams, and S. Lloyd, Phys. Rev. Lett. 83, 5162 (1999).
[14] G.R. Grimmet and D.R. Stirzaker, Probability and Random Processes, (Clarendon,

Oxford, 1992).

[15] E. Lieb, T. Schultz, and D.C. Mattis, Ann. of Phys. 16, 407 (1961).
[16] P. Shor, in Proc. 35th Annu. Symp. Foundations of Computer Science, S. Goldwasser

ed., 124 (IEEE Computer Soc., Los Alamitos CA, 1994).

[17] H. De Raedt, Comp. Phys. Rep. 7, 1 (1987).
[18] M. Suzuki, S. Miyashita, and A. Kuroda, Prog. Theor. Phys. 58, 1377 (1977).
[19] kXk denotes the spectral norm of the matrix X, see [2,3].
[20] H. De Raedt and B. De Raedt, Phys. Rev. A 28, 3575 (1983).
[21] M. Suzuki, J. Math. Phys. 26, 601 (1985).
[22] H. De Raedt and K. Michielsen, Comp. in Phys. 8, 600 (1994).
[23] M. Suzuki, J. Math. Phys. 61, 3015 (1995).
[24] A.J. Hoﬀman and H.W. Wielandt, Duke Math. J. 20, 37 (1953).

21

S
O
D

90

80

70

60

50

40

30

20

10

0

-15

-10

-5

0
ε

5

10

15

S
O
D

9

8

7

6

5

4

3

2

1

0

FIGURES

S
O
D

1

10-4

10-8

10-12

-15

-10

-5

0
ε

5

10

15

-7

-6

-5

-4

-3

ε

-2

-1

0

1

2

FIG. 1. The density of states (DOS) as obtained from the real-time algorithm for spin chains
of length L = 15 and for S = 20 random initial states. Left: XY model; middle: Ising model in a
transverse ﬁeld; right: Mean-ﬁeld model. For the mean-ﬁeld model a logarithmic scale was used
to show the highly-degenerate spectrum more clearly.

1

0.1

0.01

/

Z
Z
δ

1

0.1

0.01

/

Z
Z
δ

0.1

/

Z
Z
δ

0.01

0.001

0

1

2

3

4

5

0.001

0

0.5

1

T

1.5
T

2

2.5

3

0.001

0

0.5

1

1.5
T

2

2.5

3

FIG. 2. The relative error δZ/Z (see Eq. (36)) on a logarithmic scale as a function of temper-
ature T ≡ 1/β and for various system sizes. Left: XY model; middle: Ising model in a transverse
ﬁeld; right: Mean-ﬁeld model. Solid lines: eA (with A = e−βH, see Eq. (14)) for L = 6; dashed
lines: eA for L = 10; dash-dotted line: eA for L = 15. Crosses: Simulation data for S = 20 and
L = 6; squares: Simulation data for S = 20 and L = 10; circles: Simulation data for S = 20 and
L = 15.

22

-1

-2

-3

E

-4

-5

-6

-7

0

2.5

2

1.5

1

0.5

0

0

C

E

C

-3

-4

-5

-6

-7

-8

-9

-10

-11

-12

-13

0

3.5

3

2.5

2

1.5

1

0.5

0

0

-4

-6

-8

-10

E

-12

-14

-16

-18

-20

0

6

5

4

C

3

2

1

0

0

1

2

3

4

5

T

1

2

3

4

5

T

1

2

3

4

5

T

1

2

3

4

5

T

1

2

3

4

5

T

1

2

3

4

5

T

FIG. 3. Energy (top) and speciﬁc heat (bottom) of the XY-model (see (39)) with ∆ = 1,
h = 0 and J = 1. Left: L = 6; middle: L = 10; right: L = 15. Solid lines: Exact result. crosses:
Simulation data using S = 5 samples; squares: Simulation data using S = 20 samples. Error bars:
One standard deviation.

E

C

-2

-2.5

-3

-3.5

-4

-4.5

-5

-5.5

-6

-6.5

2.5

2

1.5

1

0.5

0

E

C

-4

-5

-6

-7

-8

-9

-10

-11

3.5

3

2.5

2

1.5

1

0.5

0

0.5

1

1.5
T

2

2.5

3

0.5

1

1.5
T

2

2.5

3

E

-6

-7

-8

-9

-10

-11

-12

-13

-14

-15

-16

-17

5

4.5

4

3.5

3

C

2.5

2

1.5

1

0.5

0

0.5

1

1.5
T

2

2.5

3

0.5

1

1.5
T

2

2.5

3

0.5

1

1.5
T

2

2.5

3

0.5

1

1.5
T

2

2.5

3

FIG. 4.

Energy (top) and speciﬁc heat (bottom) of the Ising model in a transverse ﬁeld
(see (39)) with ∆ = 0, h = 0.75 and J = 1. Left: L = 6; middle: L = 10; right: L = 15. Solid
lines: Exact result. crosses: Simulation data using S = 5 samples; squares: Simulation data using
S = 20 samples. Error bars: One standard deviation.

23

0

-0.5

-1

E

-1.5

-2

-2.5

-3

0

2

1.8

1.6

1.4

1.2

C

1

0.8

0.6

0.4

0.2

0

0

-0.5

-1

-1.5

-2

-2.5

-3

-3.5

-4

-4.5

E

0

-1

-2

-3

-4

-5

-6

E

0.5

1

1.5
T

2

2.5

3

-5

0

0.5

1

1.5
T

2

2.5

3

-7

0

0.5

1

1.5
T

2

2.5

3

4

3.5

3

2.5

C

2

1.5

1

0.5

0

0

0.5

1

1.5
T

2

2.5

3

8

7

6

5

C

4

3

2

1

0

0.5

1

1.5
T

2

2.5

3

0

0.5

1

1.5
T

2

2.5

3

FIG. 5. Energy (top) and speciﬁc heat (bottom) of the mean-ﬁeld model (see (45)) with J = 1
and h = 0. Left: L = 6; middle: L = 10; right: L = 15. Solid lines: Exact result. crosses:
Simulation data using S = 5 samples; squares: Simulation data using S = 20 samples. Error bars:
One standard deviation.

24

