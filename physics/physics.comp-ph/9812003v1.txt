8
9
9
1
 
c
e
D
 
2
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
3
0
0
2
1
8
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

One class of integrals evaluation in magnet
solitons theory

Zhmudsky A.A.

February 2, 2008

Abstract

An analytical-numeric calculation method of extremely compli-
cated integrals is presented. These integrals appear often in magnet
soliton theory.

The appropriate analytical continuation and a corresponding inte-
gration contour allow to reduce the calculation of wide class of inte-
grals to a numeric search of integrand denominator roots (in a com-
plex plane) and a subsequent residue calculations. The acceleration
of series convergence of residue sum allows to reach the high relative
accuracy limited only by roundoﬀ error in case when 10
15 terms
are taken into account.

÷

The circumscribed algorithm is realized in the C program and
tested on the example allowing analytical solution. The program was
also used to calculate some typical integrals that can not be expressed
through elementary functions. In this case the control of calculation
accuracy was made by means of one-dimensional numerical integration
procedure.

1 Introduction

Nonlinear excitations (topological solitons [1]) play an important role in the
physics of low-dimensional magnets [2, 3]. They contribute greatly to a heat
capacity, susceptibility, scattering cross-section and other physical charac-
teristics of magnets. In particular, for two-dimensional (2D) magnets with

1

discrete degeneracy it is important to take into account the localized stable
(with quite-long life time) 2D solitons [2, 3]. According to the experiments
[4], these solitons determine the relaxation of magnetic disturbance and can
produce peaks in the response functions.

The traditional model describes the magnet state in terms of the unit

magnetization vector ~m, ~m2 = 1 with the energy function in the form

W =

d2x

A(

~m)2 + w0( ~m)

,

Z

n

∇

o

(1)

where A is the nonuniform exchange constant and w0( ~m) - the anisotropy
energy.

In an anisotropic case the solution is multi-dimensional, that is why the
soliton structure is determined by the system of equations in partial deriva-
tives. There are no general methods of ﬁnding the localized solutions to such
equations and analyzing the stability of the solution. For this reason a direct
variational method is often used. Consequently, a choice of a trial function
plays a key role in such analysis [5, 6, 7]. In most cases a quite successful
choice of trial function is as follows:

tg

=

exp

(1 + C1 cos 2χ),

ϕ = χ + C2 sin 2χ + ϕ0,

(2)

θ
2

R
r

r
a (cid:19)

(cid:18)−

where r, χ are the polar coordinates in a magnetic plane, R, a, C1, C2 and
ϕ0 - variated parameters.

In papers [5, 6, 7] the iterative Newton method of solving the non-linear
system of algebraic equations [8] was used to ﬁnd the variated parameters
providing an energy minimum. The numerical algorithm mentioned above
results in the necessity of multiple calculation of two-dimensional integrals
(by the angle χ and radius r). Experience reveals that the calculation process
could be essentially accelerated (and the calculation precision improved) if
the analytical-numeric procedure for the integrals by radius are made before-
hand. The typical form of these integrals is:

∞

Z0

f (r) exp(mr)dr
n
[(r exp(r))2 + a2]

(3)

where n, m - integer numbers (m < 2n), f (r) - polynomial of degree k in
variable r. It is convenient to denote g(r)
f (r) exp(mr). Possible expres-
sions for g(r) are r exp(r), (1 + r) exp(r), r2 exp(r) and so on. Note, that a

≡

2

is essential parameter - no substitution exists to eliminate it. Below we shall
consider the case n = 1. From the one hand it is, practically, always possible
to reduce the calculation at n > 1 to a sum of integrals at n = 1. From the
other hand it is not diﬃcult to modify evaluation scheme if n > 1.

Further we show that the indicated type of integrals may be calculated
both analytically and numerically (by the use of joint analytical and numer-
ical methods). To obtain the desired accuracy one should ﬁnd integrand
residues (numerically) and build approximate expression (see below).

Main analytical expressions that allow to ﬁnd integrals like (3) are pre-
sented in Analytical Formulae and the C version of corresponding program
is given in Program Realization.

The theory of function of a complex variable gives the powerful method of
deﬁnite integrals calculation. In the considered case the algorithm realization
is quite problematical because the expressions for the roots in a complex plane
could not be written analytically. Correspondingly, one can not write down
and analytically summarize expressions for residues.

Present paper pays attention to the fact that numerical methods (roots
search in complex plane and calculation of residue sum) together with analyt-
ical ones allow to use the theory of complex variable with the same eﬃciency
like in the traditional consideration.

2 Analytical formulae

The usual way of integral (3) evaluation is to continue analytically the in-
tegrand function in some complex domain D.
In this case the evaluating
integral will be the part of the integral over the closed contour C in a com-
plex plane. This contour comprises the real axis interval and the arc S closing
the integration contour. So, the solution of the problem can be readily ob-
tained if integral value over arc S tends to the zero. The integral value over
contour C can be calculated with a help of the Residue Theorem. In some
cases the evaluating integral will be the real or imaginary part of a contour
integral.

Let’s consider the function of a complex variable

F (z) =

g(z)ln(z)
(z exp(z))2 + a2 ,

(4)

3

For this integrand function the conditions of Cauchy’s theorem and Jordan’s
lemma are fulﬁlled. So the integral along the arc of inﬁnite radius is vanishing
and g(z) have no branch point. Note that all the examples above meet these
conditions.

2.1

Integration contour

Since ln(z) is a multiple-valued function, it is necessary to use the cut plane.
Usual method (see, for example [9]) of dealing with integrals of this type is to
use a contour large circle C∞, center the origin, and radius R; but we must
cut the plane along the real axis from 0 to
and also enclose the branch
point z = 0 in a small circle c0 of radius r. The contour is illustrated in
Fig 1.

∞

Figure 1: Integration contour

Evidently, we may write down the Cauchy’s theorem in a form:

∞

Z0

g(x) ln(x)dx
(x exp(x))2 + a2 +

g(z) ln(z)dz
(z exp(z))2 + a2 +

g(x)(ln(x) + 2πi)dx
(x exp(x))2 + a2

ZC∞

0

Z∞

g(z) ln(z)dz
(z exp(z))2 + a2 = 2πi

+

Zc0

∞

k=0
X

resF (zk),

(5)

where C∞ is an arc of inﬁnitely great radius, c0 - an arc of an inﬁnitesimally
one. Integrals over these circles are vanishing. Also taking into account the

4

cancellation of integrals evaluated in opposite directions we obtain:

∞

Z0

g(x)dx
(x exp(x))2 + a2 =

∞

−

k=0
X

resF (zk).

(6)

Thus the evaluating integral is equal to a sum of integrand residues inside
the contour. The direct calculation of the residue sum in integrand poles leads
to extremely slow convergence of the partial sums. Nevertheless, we shall see
below that the convergence series acceleration (Euler’s transformation [12])
allows to take at most 10

15 terms into account.
Following the obvious method one must search the denominator roots and

÷

substitute the evaluated residues in series (6).

2.2 Denominator zeros

The denominator zeros are roots of two equations:

z exp(z)

ia = 0,

and z exp(z) + ia = 0.

(7)

−

Further we will consider only the ﬁrst equation of (7) as the solution of the
second one is complex conjugate to the ﬁrst one. Separating real (x = Rez)
and imaginary (y = Jmz) parts of equation (7) leads to a set (system) of
two nonlinear equations:

x cos y

y sin y = 0,

y cos y + x sin y

a exp(

x) = 0.

(8)

−

−

−

Simple algebraic transformations allow to reduce this system to:

sin y =

x exp(x)
a

,

x cos y

y sin y = 0

−

(9)

As it will be shown below some roots of equation (7) have the positive real
part (x > 0). Nevertheless, in this case the magnitude x exp(x)/a does not
exceed unit. For the roots with negative real part (x < 0) at a > 1/e always
< 1. At a < 1/e there exists a region of negative x values where
x exp(x)/a
|
|
x exp(x)/a <
1. But it’s easy to show that no roots of (7) meet this region.

Let’s write down the solution of the ﬁrst equation (9) in a form:

−

y = (

1)N arcsin

−

x exp(x)
a

+ Nπ,

N = 0,

1,

2,

3, . . . .

(10)

±

±

±

5

Integer number N separate diﬀerent branches of function arctg. The y value
for these branches lie in the limits:

(2N

1)

−

π
2 ≤

y

≤

π
2

(2N + 1)

, N = 0,

1,

2,

±

±

±

3, . . . .

(11)

After substitution expression (10) into the second equation of the system

(8), we obtain:

1)N arcsin

(

−

x exp(x)
a

+ Nπ =

a exp(

±

x exp(x)
a

!

2

.

−  

(12)

−

1

x)v
u
u
t

±

If N =

2m (m = 0, 1, 2, . . .) cos y > 0 and we chose the upper sign
(plus) in the right-hand side of equation (12). Contrary to this, cos y < 0 if
(2m + 1) and we must chose the lower sign (minus) in the right-hand
N =
side of equation (12). Thus at even N (N =

2m) we obtain:

±

arcsin

x exp(x)
a

+ Nπ = a exp(

x exp(x)
a

!

2

,

−  

and at odd N (N =

(2m + 1)) respectively:

±

arcsin

x exp(x)
a

−

Nπ = a exp(

x exp(x)
a

!

2

.

−  

(13)

(14)

±

−

1

x)v
u
u
t

−

1

x)v
u
u
t

It is easy to see, that equation (13) have solutions only at N

0, while
(14) one only at N < 0. Therefore, it is convenient to unite (13) and (14)
and write down:

≥

arcsin

x exp(x)
a

+ kπ

a exp(

−

2

x exp(x)
a

!

−  

−

1

x)v
u
u
t

(15)
The point to keep in mind, that cos y > 0 at k = 2m and cos y < 0
at k = 2m + 1. At even k = 2m and x < 0 it is not diﬃcult to build an
approximation for the real and imaginary parts of the root zk:

= 0,

k = 0, 1, 2, . . .

xk

≈ − "

1 +

ln kπ/a
2(kπ)2

ln

kπ
a

,

yk

kπ.

≈

(16)

#

6

As x < 0 and y > 0 the argument of the complex number is placed in the
second quarter (less than π, but greater than π/2) and is equal to:

Just note that complex conjugate number argument is placed in the third
quadrant (x < 0 and y < 0) and:

arg zk

+ arctg

π
2

≈

kπ
ln(kπ/a)

.

arg zk

3π
2 −

≈

arctg

kπ
ln(kπ/a)

.

The comparison of these solutions with exact numerical one will be given
below in Table 2.2.

Figure 2: Denominator zeroes in complex plane

At odd k = 2m + 1 > 0 the argument of the root and complex conjugate

value are equal respectively:

arg zk

arctg

3π
2 −
π
2

≈

≈

kπ
ln(kπ/a)
kπ
ln(kπ/a)

.

arg zk

+ arctg

7

(17)

(18)

(19)

The comparison of these solutions with exact numerical one will also be given
in Table 2.2.

Hence, evaluation of the complex roots of equation (7) is reduced to a real
part zk search (transcendental equation (15) solution) and further calculation
of imaginary part zk by (10). The graphs of the sum of the ﬁrst two terms
of (15) and the third term of the equation (15) are presented on Fig 2.

Intersection points of these curves marked by circles correspond to the
roots of equation (15). Any of the roots marked on Fig 2. can be evalu-
ated numerically with the help of Newton-Rafson method (e.g.
[10]). The
approximations (16) are used as an initial guess. Necessary explanation will
be made in the Program Realization. It is convenient to number these roots
by corresponding values of k as it is shown on the ﬁgure (the numeration is
used in the program).

Table 1: Relative error between exact value and approximation

for diﬀerent a

a=1/e

a=1.0

a=10

k
1
2
3
4
5
6
7
8
9
10

9.21835
2.40163
1.09204
6.21187
4.00030
2.78844
2.05364
1.57493
1.24585
1.01001

10−2
10−2
10−2
10−3
10−3
10−3
10−3
10−3
10−3
10−3

·
·
·
·
·
·
·
·
·
·

1.11473
2.52883
1.11533
6.27698
4.02305
2.79747
2.05747
1.57657
1.24651
1.01021

10−1
10−2
10−2
10−3
10−3
10−3
10−3
10−3
10−3
10−3

·
·
·
·
·
·
·
·
·
·

6.35174
4.06565
2.82172
2.07187
1.58551
1.25229
1.01407

10−3
10−3
10−3
10−3
10−3
10−3
10−3

·
·
·
·
·
·
·

In case Rez > 0 (it will be if a >

kπ
) it is more convenient to ﬁnd roots
|
by bisection because it is diﬃcult to get a necessary initial guess. At the
same time it is obvious from Fig 2 that at Rez > 0 each subsequent root lies
between zero and a root found before.

|

2.3 Residue Calculation

8

2.3.1 The test integral

Let’s consider the test example of an integral (3) when m = 1 and g(r) =
(1 + r) exp(r). Elementary analytic calculation yields 1
2π/a. On the other
hand function F (z) residue in the pole of ﬁrst order (at the same g(x)) is
equal:

resF (zk) =

(1 + z) exp(z) ln(z)
d
dz

[(z exp(z))2 + a2]

ln(z)
2z exp(z) (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

zk

=

∓

zk

,

zk

i ln(z)
2a (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(20)

where upper sign (minus) corresponds to the ﬁrst and lower (plus) to the
second of the equations (7).

Let’s take the equation (6) in a form:

∞

Z0

(1 + x) exp(x)dx
(x exp(x))2 + a2 =

=

i
2a

k=0
X

∞

−

k=0
X

−

resF (zk) =

[ln(zk)

ln(zk)]

i
2a

k=0
X

1
2a

k=0
X

−

−

[i arg(zk)

i arg(zk)] =

[arg(zk)

arg(zk)].

(21)

For the following evaluation it is important to determine root arguments
correctly. Here and below in this article the complex value argument will be
determined by principal value of arctg in order to use the library function
arctg within the limits of ﬁrst quadrant. The point to keep in mind is that
the quadrant of the complex value one have to deﬁne ”by hand”. It allows
to avoid mistakes connected with possible deﬁnitions of library functions of
negative argument, etc.

Let’s consider ﬁrst three terms of the series summarized:

1. If k = 0 the root z0 is placed in the ﬁrst quadrant and its’ argument
. Evidently, that the complex conjugate
|
ϕ0. Contribution of these two poles in the

is equal to ϕ0 = arctg
value has the argument 2π
right-hand side of equation (21) is:

y0/x0

−

|

2. The next root z1 (at k = 1) is placed in the third quadrant and its’ ar-
. Complex conjugate value

gument is equal to π + ϕ1 = π + arctg

y1/x1

arg(z0)

arg(z0) = 2π

2ϕ0

−

−

|

|

9

argument is π
these roots is:

−

ϕ1 = π

arctg

y1/x1

. Corresponding contribution of

−

|

|

arg(z1)

arg(z1) =

2ϕ1

−

−

3. Consider one root more at K = 2.

Its’ argument is equal to π

−
. For the complex conjugate value we obtain

ϕ2 = π
−
π + ϕ2 = π + arctg

arctg

|

y2/x2

|
y2/x2

. Thus, we ﬁnd:

|

|
arg(z2)

arg(z2) = 2ϕ2

−

Structure of each term is clear that is why we simply quote the result:

∞

Z0
1
2a
1
a

=

=

(1 + x) exp(x)dx
(x exp(x))2 + a2 =

1
2a

[arg(zk)

arg(zk)] =

[2π

2ϕ0

2ϕ1 + 2ϕ2

2ϕ3 + 2ϕ4

. . .]

−

−

[π

(ϕ0 + ϕ1

ϕ2 + ϕ3

ϕ4 + . . .)]

−

−

(22)

−

−

k=0
X

−

−

The sum ϕk is found numerically. This series is conventional convergent.
2.3 and converge very
Partial sums consecutively equal to
≃
slowly. Nevertheless, the program of convergence acceleration [8] found the
result π/2 with the relative error that does not exceed 10−8 (10
15 terms
of the series are taken into account).

0.81 and

≃

÷

2.3.2 First order pole

In this section we will consider integral (3) at m = 1 and g(r) = exp(r). The
residue of integrand function F (z) in the ﬁrst order pole is evidently equal
to:

d
dz

resF (zk) =

exp(z) ln(z)

[(z exp(z))2 + a2]

i ln(z)
2a(1 + z) (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(23)
As in the previous case the upper sign (minus) corresponds to the ﬁrst and
lower (plus) to the second of the equations (7).

ln(z)
2z exp(z)(1 + z) (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

±

=

=

zk

zk

zk

.

10

It is convenient to write down residue expression in a form:

∞

Z0

exp(x)dx
(x exp(x))2 + a2 =

−

∞

k=0
X
ln

resF (zk) =

i
2a

k=0 "
X

ln(zk)
1 + zk −

ln(zk)
1 + zk #

zk

|

+ i arg(zk)
|
1 + zk

ln

zk

|

+ i arg(zk)
|
1 + zk

.

#

−

(24)

=

i
2a

k=0 "
X

The argument value depends on denominator zeros placement. Obviously,

there are four possibilities.

For the complex roots lying in the ﬁrst quadrant (it will be if k =

0, 2, 4 . . ., at a > kπ) the ﬁrst term in (24) is equal to:

Second term (for the complex conjugate value) yields:

ln

+ iϕ0

z0
|
|
1 + z0

ln

z0

|

|

+ i(2π
1 + z0

−

ϕ0)

Subtracting the terms and separating real and imaginary parts (factor i/2a
is taken into account) we obtain:

y0 ln

z0

|

|

+ (1 + x0)(π
1 + z0
a
|

|

2

ϕ0)

−

+ i

πy0
1 + z0

2

|

a
|

Pay attention that the angle ϕ0 is determined as the principal value of arctg
in the limits [0, π/2].

Similary calculations for the second, third and fourth quadrants give re-

spectively:

y2 ln

y3 ln

|

|

(1 + x3)ϕ3

z2
+ (1 + x2)ϕ2
|
2
1 + z2
a
|
z3
| −
1 + z3
a
|
|
(1 + x1)(π
1 + z1

ϕ1)

−

2

2

|

|

+ i

+ i

+ i

πy2
1 + z2
πy3
1 + z3
πy1
1 + z1

a
|

a
|

a
|

2 ,

2 ,

2 ,

|

|

|

y1 ln

z1

|

| −
a
|

11

(25)

(26)

(27)

(28)

As if structure of each term is already clear then it is not hard to write

the sum of real residue parts (25-28) and all the subsequent ones.

exp(x)dx
(x exp(x))2 + a2 =
y0 ln

z0

+ (1 + x0)(π

−

∞

k=0
X

−

|

|

1 + z0

2

|

|
+ (1 + x2)ϕ2
2

|
1 + z2

∞

Z0
1
a "
y2 ln

y4 ln

+ (1 + x4)ϕ4
2

|
1 + z4

+ . . .
#

z2

|

|
z4

|

|

|

|

=

+

+

res(F (zk))

ϕ0)

y1 ln

z1

(1 + x1)ϕ1

+

|

| −
1 + z1
|
(1 + x3)ϕ3

|

2

y3 ln

z3

+

|

| −
1 + z3

|

2

|

Sum of not more than 15 terms of this series give right result for any a >
0.0006 if acceleration of series convergence is used. The partial sums of the
10−12).
imaginary parts also rapidly (

15 terms) tends to the zero (

10

∼

÷

∼

2.4 Approximation at a vanishing

At a vanishing it is convenient to write down the approximate expression for
integral (24). Let’s set m = 1 in (3) and make substitution:

x exp(x) = au,

where u is the new independent variable. Left-hand side of equation (30)
may be expanded in powers of the x:

Inversion [12] of this series gives:

x + x2 +

x3 + . . .

au

≈

x

au

≈

−

(au)2 +

(au)3

. . .

−

For the present purposes, it is suﬃcient to retain only one term in right-hand
side of equation (32). We will focus on the case discussed in the previous
section, namely, f (x) = exp(x). Simple integration leads to the following
result:

∞

Z0

exp(x)dx
(x exp(x))2 + a2 ≈

1
a(1 + a2) (cid:20)

π
2

+ a ln(a)

(cid:21)

(29)

(30)

(31)

(32)

(33)

1
2!

3
2

12

One more term taking into account yields:

∞

Z0

exp(x)dx
(x exp(x))2 + a2

1
(1 + a2)2 + a2

(

≈

(1 + a2)

+ ln(a) +

π
2a

3 + 2a2
2√5

ln

Quality of these approximations is presented in Table 2.

(34)

1 + √5
√5
1 (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

−

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

)

Table 2: Comparison of approximation and exact value of integral
relative error for
approximation (34)

relative error for
approximation (33)

a Integral value

(exact)

10−07
10−06
10−05
10−04
10−04

6

·

1.57079
1.57078
1.57069
1.56993
2.61115

107
106
105
104
103

·
·
·
·
·

10−8
10−7
10−6
10−5
10−4

3.67
3.68
3.67
3.68
2.21

·
·
·
·
·

10−9
10−8
10−7
10−6
10−5

4.35
4.35
4.35
4.36
2.62

·
·
·
·
·

As one can see the relative error given by approximation (34) is not worth
10−4 and smaller for other values. If it is necessary,
than 2.62
the approximation (34) can be improved.

10−5 at a = 6

·

·

3 Program Realization

Program text consists of the principal routine (main) and eight procedures:

Root - subroutine for searching real part of denominator zeros. Newton-
Rafson iteration method used for this purpose.

Fun - subroutine for left-hand side equation (15) evaluation.

Der - subroutine for left-hand side of equation (15) derivative evaluat-
ing.

Approximation - evaluate initial guess to the root according to the (16).

•

•

•

•

13

•

•

•

•

Eulsum - program of acceleration of series (29) convergence. The C
version of corresponding FORTRAN program [8] is used.

Bisection - recursive version of bisection root ﬁnding.

Right bound - auxiliary program. Determine the right bound of root
region.

Sign - auxiliary program for Bisection. Determine sign of variable x.

The demonstration version of the program is presented below. The ﬁrst four
statements declare the necessary functions that are used in the program.
#include <dos.h>
#include <stdio.h>
#include <math.h>
#include <alloc.h>
// Declaration of functions used below.
double Fun(double);
double Der(double);
double Bisection(double& ,double& ,double& ,double&);
double Root(double);
double Approximation_x(void);
double Right_bound(void);
void Eulsum(double&, double, int);
int Sign(double);

//
//
//

a can be deﬁned
Deﬁning of the global constants. Parameter A
in any other way. EPS - relative accuracy for root search; K - root
number; N - number of roots taking into account.

≡

double
A = 0.2, EPS = 1.0e-14;
long unsigned irec = 0, irecmax = 100;
int K, N = 20;

//
//
//

Deﬁnition of parameters used by procedures Root (x, y, yx, phi k,
den, argument) and Bisection (a, c, funa, func, xold, xk). See
below.
void main(void)
{ double x, y, yx, phi_k, den, argument;
double real_part = 0, imag_part = 0;
double a, c, funa, func, xold, xk;
double *real_term = (double*)calloc(N,sizeof(double));
double *imag_term = (double*)calloc(N,sizeof(double));

14

//
//

Two previous statements reserved memory for storaging denomina-
tor roots. Cycle on root numbers begins below.

xold = 0.99999*Right_bound();
for(int k = 0; k < N; k++)
{ K = (k%2) ? -k : k;

//
//
//

3, . . . while k =
Statements IF ELSE diﬀers three diﬀerent cases:

1, 2

−

Variable K (upper case) takes values 0,
0, 1, 2, 3, . . ..
Real(zk) = 0, Real(zk) > 0 and Real(zk) < 0.
if(A == fabs(K*M_PI)) x = 0.0;
else { if(A > fabs(K*M_PI))

−

{ a = 0.0; c = xold;

funa = Fun(a);
x = Bisection(a,c,funa,func);
xold = 0.99999999 * x;

func = Fun(c);

irec = 0;}

{ xk = Approximation_x();

x = Root(xk);

}

else

}

//
//

The following statements calculate argument of zk and store real
and imaginary parts of the term to be summarized.

y = pow(-1,k)*asin(x*exp(x)/A) + K*M PI;
if(x == 0) argument = M PI 2;
yx = fabs(y/x);
else
phi k = atan(yx);
argument = (x > 0) ?

{

den = (1+x)*(1+x)+y*y;
real term[k]=(0.5*y*log(x*x+y*y)+(1+x)* Sign(y)*argument)/den;
imag term[k]=y/den;

M PI - phi k :

phi k;

}

}

//
//
//
//

End cycle on root numbers. Accelerating the rate of a sequence of
partial sums performed by the procedure Eulsum. This is the C
version of Van Wijngaarden’s algorithm (see [8]). Then the result
is printed. The last two statements free the allocated memory.

for(int j = 0; j < N; j++) Eulsum(real_part,real_term[j],j);
j = 0; j < N; j++) Eulsum(imag_part,imag_term[j],j);
for(

15

printf("Real part =%12.5lf ",real_part/A);
printf("Imaginary part =%12.5le \n",imag_part);
free(real_term);
free(imag_term);

}

//
//

Initial guess for the Newton-Rafson iteration is chosen with respect
to parameter a value. The appointments of other statements are
evident.

double Root(double xk)
{ double xk1;

for(int it = 0; it < 30; it++)
{ xk1 = xk - Fun(xk)/Der(xk);

if(fabs(xk-xk1) <= fabs(xk1)*EPS) break;
xk = xk1;

}

}

return xk1;
// No comments.
double Fun(double x)
{ double px = x*exp(x)/A, arcsin = asin(px);

return arcsin + abs(K)*M_PI - A*sqrt(1-px*px)/exp(x);

}

// No comments.
double Der(double x)
{ double expa=exp(x), px = A/expa; //px = x*expa/A;

return (1 + x + px*px)/sqrt(px*px-x*x);

}

// Calculation of initial guess according to the expressions (16)
double Approximation_x(void)
{ double mu = abs(K)*M_PI, den = mu*mu, lnKPi = log(mu/A);

if(!K) return 0;
else return -lnKPi*(1+0.5*lnKPi/den);

}

// For details see [8].
void Eulsum(double& sum, double term, int jterm)
{ double static wksp[28], dum, tmp;

int static nterm;
if(jterm == 0) { nterm=0; wksp[0]=term; sum=0.5*term; }
else { tmp = wksp[0];

wksp[0] = term;

for(int j = 0; j < nterm; j++)

{ dum = wksp[j+1];

16

wksp[j+1] = 0.5*(wksp[j]+tmp);
tmp = dum;

}

wksp[nterm+1] = 0.5*(wksp[nterm]+tmp);
if(fabs(wksp[nterm+1]) <= fabs(wksp[nterm]))
nterm += 1; }

{ sum += 0.5*wksp[nterm+1];

else sum += wksp[nterm+1];

}

}
// Usual bisection algorithm realized by means of the recursion.
double Bisection(double& left, double& right,double& fun_left,

double& fun_right)

{ double center = 0.5*(left + right);

if(++irec < irecmax)
{if(fabs(left - right) < EPS*fabs(center)) return center;

double fun_c = Fun(center);
if(fabs(fun_left-fun_right)<EPS*fabs(fun_c)) return center;
if(Sign(fun_left) == Sign(fun_c))

{ left = center ; fun_left = fun_c;}

else { right = center;
center = Bisection(left,right,fun_left,fun_right);

fun_right = fun_c;

}

}

}

irec--;
return center;

//
//

Auxiliary program. Determine the right bound of the root region
(see Fig. 2).

double Right_bound(void)
{ double xn, xn1;

xn = (A > 1) ? log(A) : A;
for(int k = 0; k < 20; k++)
{ xn1 = xn + (A*exp(-xn) - xn)/(1.0 + xn);

if(fabs(xn1-xn) <= 1.0e-14*fabs(xn1)) break;
xn = xn1; }

return xn1;

}

17

// Auxiliary program for Bisection. Determine sign of variable x.

int Sign(double x)
{ if(!x) return 0;

return (x>0) ? 1 : -1;

}

The test result of this programm is presented in Table 3.

Table 3: Exact value of the integral and relative error

a

Exact

10−06
10−05
10−04
10−03
10−02
10−01
1
10
100
1000

107
106
105
107
106

integral value

·
·
·
·
·

1.57078308845
1.57068696938
1.56993298295
1.56446267294
1.53021971263
13.7465039696
1.00319691445
6.155174431518
3.83403357209
2.62958979905

10−2
·
10−3
10−4

·
·

relative error
for approximation

10−8
10−7
10−6
10−11
10−10
10−11
10−11
10−10
10−10
10−12

4.35
4.35
4.36
2.45
1.51
1.08
2.70
1.05
1.80
1.04

·
·
·
·
·
·
·
·
·
·

−

−

−
−

The second column in Table 3 was evaluated by program QUADREC (see
below) and also checked with the help of MATHEMATICA and MAPLE V.

4 Conclusion

Thus it was shown that suﬃciently complicated integrals (3) can be evaluated
with a given accuracy by means of residue calculations and further evaluation
of series sum.

Evidently, that analytical-numeric method like this one, presented in this
paper, with some restrictions caused by the theory of the function of the
complex variable may be used for evaluation of a wide class of deﬁnite inte-
grals.

18

5 Aknowledgements

I am grateful Dr. V.K.Basenko and Dr. A.N.Berlisov for helpful discussions
and advice.

A Appendix

A.1 Recursive adaptive quadrature program

The algorithm consists of two practically independent parts: namely adaptive
procedure and quadrature formula.

The adaptive part uses eﬀective recursive algorithm that implements stan-
dard bisection method. To reach desired relative accuracy of the integration
the integral estimation over subinterval is compared with the sum of inte-
grals over two subintervals. If the accuracy is not reached the adaptive part
is called recursively (calls itself) for both (left and right) subinterval.

Evaluation of integral sum on each step of bisection is performed by means
of quadrature formula. The construction of algorithm allows to choose which
type of quadrature to be used (should be used) throughout the integration.
Such possibility makes the code to be very ﬂexible and applicable to a wide
range of integration problems.

Program realization of the described algorithm is possible when the trans-
lator that (which) permits recursion is used. Here we propose a C++ version
of such a recursive adaptive code. The text of the recursive bisection func-
tion QUADREC (Quadrature used Adaptively and Recursively) is presented
below:

void quadrec (TYPE x, TYPE X, TYPE whole)

static int recursion;

{
if(++recursion < IP.recmax)
TYPE section = (x+X)/2;

// Recursive calls counter
// Increase and check recursion level
// Dividing the integration interval
{
TYPE left=IP.quadrature(x,section); // Integration over left subinterval
TYPE right=IP.quadrature(section,X);// Integration over right subinterval
IP.result += left+right-whole;
if((fabs(left+right-whole)>IP.epsilon*fabs(IP.result)))

// Modifying the integral value

quadrec(x,section,left);

{

// Checkup the accuracy
// Recursion to the left subinterval

19

quadrec(section,X,right);
else IP.rawint++;
recursion--;

} }

// Recursion to the right subinterval
// Increase raw interval counter
// Decrease recursion level counter

}

The form of the chosen comparison rule does not pretend on eﬀectiveness
rather on simplicity and generality. Really it seems to be be very common
and does not depend on the integrand as well as quadrature type. At the
same time the use of this form in some cases result in overestimation of the
calculated integral consequently leads to more integrand function calls. One
certainly can get some gains, for instance, deﬁnite quadratures with diﬀerent
number or/and equidistant points or Guass-Kronrod quadrature etc.

Global structure IP used in the QUADREC function has to contain the

following ﬁelds:

// Pointers on the integrand and

struct iip {
TYPE (*fintegrand)(TYPE);
TYPE (*quadrature)(TYPE,TYPE);// quadrature function
TYPE epsilon;
int recmax;
TYPE result;
int rawint;
} IP;

// Desired relative accuracy
// Maximum number of recursions
// Result of the integration
// Number of raw subintervals

The ﬁrst four ﬁelds specify the input information and have to be deﬁned
before calling the QUADREC function. The next two ﬁelds are the returned
values for the integration result and the number of unprocessed (raw) subin-
tervals. The static variable RECURSION in the QUADREC function is used
for controlling current recursion level. If the current level exceeds the spec-
iﬁed maximum number of recursions the RAWINT ﬁeld is increased so that
its returned value will indicate the number of raw subintervals. Here is the
template for integration of function f (x) over interval [Xmin, Xmax] with the
use of q(x1, x2) quadrature formula:

IP.fintegrand = f;
IP.quadrature = q;
IP.epsilon = 1e-10;
IP.recmax = 30;

20

IP.result = IP.quadrature(Xmin,Xmax);
quadrec(Xmin,Xmax,IP.result);

Crude estimation of the integral is evaluated by the quadrature function
and assigned to IP.result variable. Then it is transferred to QUADREC func-
tion. Note that the initial estimation of the integral can be set in principal
to arbitrary value that usually does not alter the result of the integration.

Further information about QUADREC: test results, using QUADREC in

MS Fortran source and so on, see [11].

References

[1] A.M.Kosevich, B.A.Ivanov and A.S.Kovalev. Phys. Rep. 194, 117 (1990).

[2] V.G.Bar’yakhtar, B.A.Ivanov. Soviet Scientiﬁk Rev. Sec. A - Phys.

(edited by I.M.Khalatnikov) 16, No. 3 (1992).

[3] B.A.Ivanov, A.K.Kolezhuk, Fiz. Nizk. Temp. 21, 355 (1995) [Low Temp.

Phys. 21, 275 (1995)].

(1986.)

[4] F.Waldner, J. Magn. Magn. Mater. 31-34, 1203 (1983); 54-57, 873

[5] A.A.Zhmudskii, B.A.Ivanov, Fiz. Nizk. Temp. 22, 446 (1996). [Low

Temp. Phys. 22, 347 (1996)];

[6] A.A.Zhmudskii, B.A.Ivanov. Pis’ma Zh. Eksp. Teor. Fiz. 65, No.12, 899-

903 (1997); [JETP Lett., vol. 65, No. 12, 945-950 (1997)];

[7] B.A.Ivanov, V.A.Stephanovich, A.A.Zhmudsky. J. Magn. Magn. Mater.,

88, 116, (1990).

[8] W.H.Press, S.A.Teukolsky, W.T.Vetterling, B.P.Flannery. Numerical

recipes in Fortran. University Press. Cambridge. 1990.

[9] M.A.Lavrentev, B.V.Shabat. The methods of complex function theory.

Nauka. Moskow. 1965.

[10] D.D.McCraken, W.S.Dorn. Numerical methods and Fortran program-

ming. John Wiley and Sons, Inc., New York
·

London
·

Sydney. 1965.

21

[11] A.N.Berlizov, A.A.Zhmudsky. The recursive one-dimensional adaptive
quadrature code. Preprint Institute for Nuclear Research. KINR. Kyiv.
1998.

[12] G.A.Korn, T.M.Korn. Mathematical Handbook for Scientists and Engi-

neers. 2nd ed. (New York: McGraw-Hill) , 1968,

4.8.
§

22

