8
9
9
1
 
r
a

M
 
0
1
 
 
]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[
 
 
1
v
1
1
0
3
0
8
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

The solution of multi-scale partial diﬀerential
equations using wavelets

Stefan Goedecker,
Max-Planck Institute for Solid State Research,
Stuttgart, Germany
goedeck@prr.mpi-stuttgart.mpg.de
Oleg Ivanov
P.N. Lebedev Physical Institute, Moscow, Russia
ivanov@td.lpi.ac.ru

February 2, 2008

1 Introduction

Wavelets are a powerful new mathematical tool which oﬀers the possibility to treat in a
natural way quantities characterized by several length scales. In this article we will show
how wavelets can be used to solve partial diﬀerential equations which are characterized by
widely varying length scales and which are therefore hardly accessible by other numerical
methods. The standard way to solve partial diﬀerential equations is to express the solution
as a linear combination of so-called basis functions. These basis functions can for instance
be plane waves, Gaussians or ﬁnite elements. Having discretized the diﬀerential equation
in this way makes it amenable to a numerical solution. Wavelets are just another basis
Its main
set which however oﬀers considerable advantages over alternative basis sets.
advantages are:

1. The basis set can be improved in a systematic way:

If one wants the solution of the diﬀerential equation with higher accuracy one can
just add more wavelets in the expansion of the solution. This will not lead to any
numerical instabilities.

2. Diﬀerent resolutions can be used in diﬀerent regions of space:

If the solution of the diﬀerential equation is varying particularly rapidly in a par-
ticular region of space one can increase the resolution in this region by adding more
high resolution wavelets centered around this region.

3. There are few topological constraints for increased resolution regions:

The regions of increased resolution can be chosen in arbitrarily, the only requirement

1

being that a region of higher resolution be contained in a region of the next lower
resolution.

4. The matrix elements of the diﬀerential operators are very easy to calculate

5. The numerical eﬀort scales linearly with respect to system size:

Three-dimensional problems of realistic size require usually a very large number
of basis functions. It is therefore of utmost importance, that the numerical eﬀort
scales only linearly (and not quadratically or cubically) with respect to the number
of basis functions. If one uses iterative matrix techniques, this requirement is equiv-
alent to the two requirements, namely that the matrix vector multiplications which
are necessary for all iterative methods can be done with linear scaling and that the
number of matrix vector multiplications is independent of the problem size. The
ﬁrst requirement is fulﬁlled since the matrix representing the diﬀerential operator
is sparse. The second requirement is related to the availability of a good precon-
ditioning scheme which can be easily found by analyzing the Fourier properties of
wavelets.

2 A ﬁrst tour of some wavelet families

Many families of wavelets have been proposed in the mathematical literature. If one wants
to use wavelets for the solution of diﬀerential equations, one therefore has to choose one
speciﬁc family which is most advantageous for the intended application. Within one family
there are also members of diﬀerent degree. We believe that the so-called bi-orthogonal
interpolating wavelets [6] are the most useful ones in the context of diﬀerential equations
and we will therefore mainly concentrate on this class. Each wavelet family is characterized
by two functions, the mother scaling function φ and the mother wavelet ψ. For the case
of a fourth order interpolating wavelet they are shown in Figure 1.

’scfunction’
’wavelet’

0.5

1

0

-0.5

-1

0
Figure 1: The interpolating scaling function and wavelet of degree 4

-2

-1

-3

3

2

1

Another family which will be introduced is the Haar wavelet family shown in Figure 2.
It is too crude to be useful for any numerical work, but its simplicity will help us to
illustrate some basic wavelet concepts.

2

φ 

0

1 

ψ 

0

1 

Figure 2: The Haar scaling function and wavelet.

To obtain a basis set at a certain resolution level k one can use all the integer trans-

lations of the mother scaling function of some wavelet family.

i (x) = φ(2kx − i)
φk
Note that with this convention higher resolution corresponds to larger values of k.
Exactly the same scaling and shifting operations can of course also be applied to the
wavelets.

(1)

i (x) = ψ(2kx − i)
ψk
This set of wavelet basis functions can be added as a basis to the scaling functions as will
be explained in the following for the case of the Haar wavelet family.

(2)

3 The Haar wavelet

In the case of the Haar family, any function which can exactly be represented at any level
of resolution is necessarily piecewise constant. One such function is shown in Figure 3.

φ

4 

 0

x 

  1

Figure 3:

function at resolution level 4.

Evidently this function can be written as a linear combination of the scaling functions

φ4
i (x)

f =

i φ4
s4

i (x)

16

Xi=0

3

(3)

i = f (i/16).

where s4
Another, more interesting, possibility consists of expanding a function with respect to
wavelets of diﬀerent resolution. This is possible because a scaling function (and wavelet)
at resolution level k is always a linear combination of a scaling function and a wavelet at
the next coarser level k − 1 as shown in Figure 4

φ 

1/2

φ 

1/2

1 

1 

0

0

ψ 

+1/2

ψ 

-1/2

1 

1 

0

0

φ 

 =

φ 

=

Figure 4: A skinny scaling function is a linear combination of a fat scaling function and
a wavelet.

0

1 

0

1 

Using this relation, we can write any linear combination of the two scaling functions

2i(x) and φk
φk

2i+1(x) as a linear combination of φk−1
Denoting the expansion coeﬃcients with respect to ψk

(x) and ψk−1

(x).
i
i (x) as dk

i

i , we obviously obtain

sk−1
i =

sk
2i +

sk
2i+1

;

dk−1
i =

sk
2i −

sk
2i+1

(4)

1
2

1
2

1
2

1
2

So to calculate the expansion coeﬃcients with respect to the scaling functions at the
next coarser level, we have to take an average over expansion coeﬃcients at the higher
resolution level. Because we have to take some weighted sum these coeﬃcients are denoted
by s. To get the expansion coeﬃcients with respect to the wavelet, we have to take some
weighted diﬀerence and the coeﬃcients are accordingly denoted by d. The wavelet part
contains mainly high frequency components and by doing this transformation we therefore
peel oﬀ the highly oscillatory parts of the function. The remaining part represented by
the coeﬃcients sk−1
is therefore smoother. For the case of our example in Figure 3 the
remaining scaling function part after one transformation step is shown in Figure 5.

i

For any data set whose size is a power of 2, we can now apply this transformation
repeatedly. In each step the number of s coeﬃcients will be cut into half. So we have to

4

φ

3 

 0

x 

  1

Figure 5: The function from Figure 3 at resolution level 3.

stop the procedure as soon as there is only one s coeﬃcient left. Such a series of trans-
formation steps is called a forward Haar wavelet transform. The wavelet representation
of the function in Equation 3 is then

f = s0

1φ0

1(x) + d0

1ψ0

1(x) +

i ψ1
d1

i (x) +

i ψ2
d2

i (x) +

i ψ3
d3

i (x) .

(5)

2

Xi=1

4

Xi=1

8

Xi=1

Note that in both cases we need exactly 16 coeﬃcients to represent the function.

Functional representations of this type will be the focus of this article.

By doing a backward wavelet transform, we can go back to the original expansion
of Equation 3. Starting at the lowest resolution level, we have to split up each scaling
function and wavelet on the coarse level into scaling functions at the ﬁner level.

sk+1
2i = sk

i + dk
i

;

sk+1
2i+1 = sk

i − dk
i

(6)

4 The concept of Multi-Resolution Analysis

In the previous sections a very intuitive introduction to wavelet theory was given. The
formal theory behind wavelets is called Multi-Resolution Analysis [2] (MRA). The reader
interested in the formal theory can consult Daubechies book. We will list here only a few
facts which are useful for numerical work.

A bi-orthogonal wavelet family of degree m is characterized by 4 ﬁnite ﬁlters denoted
by hj, ˜hj, gj, ˜gj. A ﬁlter is just a short vector which is used in convolutions. Those ﬁlters
satisfy certain orthogonality and symmetry relations. Scaling functions and wavelets at
a coarse level can be written as the linear combinations of scaling functions at a higher
resolution level. These important relations are called reﬁnement relations.

φ(x) =

hj φ(2x − j)

ψ(x) =

gj φ(2x − j)

˜φ(x) = 2

˜hj ˜φ(2x − j)

m

Xj=−m
m

Xj=−m
m

Xj=−m

5

(7)

(8)

(9)

˜ψ(x) = 2

˜gj

˜φ(2x − j)

m

Xj=−m

The expansion coeﬃcients at diﬀerent resolution levels are related by the wavelet

transform equations. The analysis (forward) transform is given by

sk−1
i =

˜hjsk

j+2i

;

dk−1
i =

˜gjsk

j+2i

m

Xj=−m

and a wavelet synthesis (backward) transform is given by

sk+1
2i =

h2j sk

i−j + g2j dk

i−j

;

sk+1
2i+1 =

h2j+1 sk

i−j + g2j+1 dk

i−j

(12)

m/2

Xj=−m/2

These two equations are generalizations of Equations (4) and (6) which we derived in an
intuitive way and with a diﬀerent normalization convention.

The fundamental functions satisfy the following orthogonality relations

m

Xj=−m

m/2

Xj=−m/2

˜φk
i (x)φk

j (x)dx = δi,j

˜ψk
i (x)φq

j(x)dx = 0 , k ≥ q

i (x) ˜φq
ψk

j(x)dx = 0 , k ≥ q

i (x) ˜ψq
ψk

j (x)dx = δk,qδi,j

Z

Z

Z

Z

φ(x)dx = 1

Z

The scaling function is usually normalized to 1

(10)

(11)

(13)

(14)

(15)

(16)

(17)

5 The fast wavelet transform

Let us ﬁrst look at the forward transform given by Equation 11 . The peeling oﬀ of the
high frequency components in the forward transform can be illustrated in the following
way:

s4 → s3 → s2 → s1 → s0
ց ց ց ց
d2

d1

d3

d0

We note that just two arrays of length n (where n is a power of 2) are necessary to do

the transform as shown below:

6

original data
Array 1: s4

after ﬁrst sweep
Array 2: s3
0 s3

after second sweep
1 s2
Array 1: s2

0 s2

after third sweep
1 d1
Array 2: s1

0 s1

ﬁnal data
Array 1: s0

0 s4

1 s4

2 s4

3 s4

4 s4

5 s4

6 s4

7 s4

8 s4

9 s4

10 s4

11 s4

12 s4

13 s4

14 s4
15

1 s3

2 s3

3 s3

4 s3

5 s3

6 s3

7 d3

0 d3

1 d3

2 d3

3 d3

4 d3

5 d3

6 d3
7

2 s2

3 d2

0 d2

1 d2

2 d2

3 d3

0 d3

1 d3

2 d3

3 d3

4 d3

5 d3

6 d3
7

0 d1

1 d2

0 d2

1 d2

2 d2

3 d3

0 d3

1 d3

2 d3

3 d3

4 d3

5 d3

6 d3
7

0 d0

0 d1

0 d1

1 d2

0 d2

1 d2

2 d2

3 d3

0 d3

1 d3

2 d3

3 d3

4 d3

5 d3

6 d3
7

Note that this transformation from the ”original data” to the ”ﬁnal data” corresponds
exactly to the transformation done in an intuitive way to get from Equation 3 to Equa-
tion 5. Just as in the case of a Fast Fourier transform we have Log2(n) sweeps to do
a full transform. However in the case of the wavelet transform the active data set (the
s coeﬃcients) is cut into half in each sweep. If our ﬁlters h and g have length 2m the
operation count is then given by 2m(n + n/2 + n/4 + ...). Replacing the ﬁnite geometric
series by its inﬁnite value, the total operation count is thus given by 4mn

The backward transform (Equation 12) can pictorially be represented by the following

diagram:

s4 ← s3 ← s2 ← s1 ← s0
տ տ տ տ
d2

d1

d3

d0

As can easily been seen the operation count is again 4mn and again it can be done
with 2 arrays of length n. Since each sweep in a wavelet transform is a linear operation it
can be represented by a matrix. Denoting the matrix for one sweep in a forward transform
by ˜F and in a backward transform by B we have

F T = ˜F −1 = B

;

˜BT = B−1 = ˜F

(18)

where the tilde on the matrix means that the ﬁlter coeﬃcients necessary to ﬁll the matrix
are replaced by their dual counterparts. Obviously all these matrices are sparse and
banded.

Backward wavelet transforms can also be used to make plots of scaling functions and
wavelets. To generate the scaling function we start with a data set where s0
0 = 1 and
dk
i = 0 for all possible i’s and k’s up to a maximum resolution level k = K. In the wavelet
case the initial data set is s0
1 = 1, and dk
i = 0 for all other values of i and k up
to the maximal resolution K. By doing repeated backward transform sweeps, we express
these two functions by skinnier and skinnier scaling functions and the s coeﬃcients will
ﬁnally be the functional values within the resolution of the eye.

0 = 0, d0

7

6 Interpolating wavelets

In addition to being advantageous as basis sets, interpolating wavelets are also conceptu-
ally the simplest wavelets and we will therefore brieﬂy describe their construction. The
construction of interpolating wavelets is closely connected to the question of how to con-
struct a continuous function f (x) if only its values fi on a ﬁnite number of grid points i are
known. One way to do this is by recursive interpolation. In a ﬁrst step we interpolate the
functional values on all the midpoints by using for instance the values of two grid points
to the right and of two grid points to the left of the midpoint. These four functional
values actually allow us to construct a third order polynomial and we can then evaluate
it at the midpoint. In the next step, we take this new data set, which is now twice as
large as the original one, as the input for a new midpoint interpolation procedure. This
can be done recursively ad inﬁnitum until we have a quasi continuous function.

Let us now show, how this interpolation prescription leads to a set of basis functions.
Denoting by the Kronecker δi−j a data set which has a nonzero entry only at the j-th
position, we can write any initial data set also as a linear combination of such Kronecker
j fjδi−j. Now the whole interpolation procedure is clearly linear, i.e. the
data sets: fi =
sum of two interpolated values of two functions is equal to the interpolated value of the
sum of these two functions. This means that we can instead also take all the Kronecker
data sets as the input for separate interpolation procedures, to obtain a set of functions
φ(x − j). The ﬁnal interpolated function is then identical to

P

f (x) =

fjφ(x − j)

Xj

(19)

If the initial grid values fi were the functional values of a polynomial of degree less
than four, we obviously will have exactly reconstructed the original function from its
values on the grid points. Since any smooth function can locally be well approximated
by a polynomial, these functions φ(x) are good basis functions also in the case where f is
not a polynomial and we will use them as scaling functions to construct a wavelet family.
The ﬁrst construction steps of an interpolating scaling function are shown below for
the case of linear interpolation. The initial Kronecker data set is denoted by the big
dots. The additional data points obtained after the ﬁrst interpolation step are denoted
by medium size dots and the additional data points obtained after the second step by
small dots.

-3

-2

-1

0

1

2

3

Continuing this process ad inﬁnitum will then result in the function shown in the left
panel of Figure 6. If an higher order interpolation scheme is used the function shown in

8

the right panel of Figure 6 is obtained.

’scf2’

’scf8’

1

0.8

0.6

0.4

0.2

0

1

0.8

0.6

0.4

0.2

0

-0.2

-6

-4

-2

0

2

4

6

-6

-4

-2

0

2

4

6

Figure 6: A Kronecker delta interpolated ad inﬁnitum with linear interpolation (left
panel) an 7-th order interpolation (right panel) .

By construction it is clear, that φ(x) has compact support. If an (m − 1)-th order
interpolation scheme is used, the ﬁlter length is (m − 1) and the support interval of the
scaling function is [−(m − 1); (m − 1)].

It is also not diﬃcult to see that the functions φ(x) satisfy the reﬁnement relation.
Let us again consider the interpolation ad inﬁnitum of a Kronecker data set which has
everywhere zero entries except at the origin. We can now split up this process into
the ﬁrst step, where we calculate the half-integer grid point values, and a remaining
series of separate ad inﬁnitum interpolations for all half-integer Kronecker data sets,
which are necessary to represent the data set obtained by the ﬁrst step. Doing the
ad-inﬁnitum interpolation for a half integer Kronecker data set with a unit entry at
position j, we obviously obtain the same scaling function, just compressed by a factor of
2, φ(2x − j). If we are using a (m − 1)-th order interpolation scheme (i.e. m input data
for the interpolation process) we thus get the relation

φ(x) =

φ(j/2) φ(2x − j)

(20)

m−1

Xj=−m+1

Comparing this equation with the reﬁnement relation Equation 7 we can identify the

ﬁrst ﬁlter h as

hj = φ(j/2) , j = −m + 1, m − 1

For the case of third order interpolation the numerical values of h follow from the
standard interpolation formula and are given by { -1/16 , 0 , 9/16 , 1 , 9/16 , 0 , -1/16 }.
Let us next determine the ﬁlter ˜h. Let us consider a function f (x) which is band-
limited in the wavelet sense, i.e which can exactly be represented by a superposition of
scaling functions at a certain resolution level K.

f (x) =

j φK
sK

j (x)

Xj

9

It then follows from the orthogonality relation Equation 13 that

sK
j =

Z

˜φK
j (x) f (x)dx

Now we have seen above that with respect to interpolating scaling functions, a band-
limited function is just any polynomial of degree less than or equal to m − 1, and that
in this case the expansion coeﬃcients sK
j are just the functional values at the grid points
(Equation 19). We therefore have

Z
which shows that the dual scaling function ˜φ is the delta function.

sK
j =

˜φK
j (x)f (x)dx = fj

˜φ(x) = δ(x)

(21)

(22)

(23)

Obviously the delta function satisﬁes a trivial reﬁnement relation δ(x) = 2δ(2x) and from
Equation 9 we conclude that ˜hj = δj From the symmetry relations for the ﬁlters the two
remaining ﬁlters ˜g(i) and g(i) can be determined and we have thus completely speciﬁed
our wavelet family.

Using these ﬁlters we can then determine the wavelet ψ and its dual counterpart ˜ψ

which turn out to be

ψ(x) = φ(2x − 1)

(24)

˜ψ(x) =

−1
16

1
2

9
16

1
2

δ((x−

)−3)+

δ((x−

)−1)−δ((x−

))+

δ((x−

)+1)+

δ((x−

)+3)

1
2

9
16

1
2

−1
16

1
2

(25)
We see that the interpolating wavelet is a very special case in that its scaling function
and wavelet have the same functional form and that the dual functions are related to the
delta function. The non-dual functions are shown in Figure 1.

Lifting [5] is a very useful technique to modify an existing family of wavelets to meet
speciﬁc needs. We can for instance lift the interpolating wavelets to obtain a new family
whose wavelet has more vanishing moments Ml.

which will for instance improve the frequency properties of the wavelet.

Ml =

Z

j (x) xldx
ψK

7 Expanding functions in a wavelet basis

As was demonstrated in the case of the Haar wavelet, there are two possible representa-
tions of a function within the framework of wavelet theory. The ﬁrst one is called scaling
function representation and involves only scaling functions. The second is called wavelet
representation and involves wavelets as well as scaling functions. Both representations
are completely equivalent and exactly the same number of coeﬃcients are needed in the
case where one has uniform resolution.

10

The scaling function representation is given by

f (x) =

sKmax
j

φKmax

j

(x)

Xj

(26)

(27)

(28)

The coeﬃcients sKmax

j

we have a set of coeﬃcients sKmax
the coeﬃcients of the wavelet representation

j

can be calculated by integration through Equation 22. Once
we can use a full forward wavelet transform to obtain

f (x) =

sKmin
j

φKmin
j

(x) +

j ψK
dK

j (x)

Xj

XK=Kmin Xj

Kmax

Alternatively, one could also directly calculate the d coeﬃcients by integration

dK
j =

Z

˜ψK

j (x) f (x)dx

Equation 28 follows from the orthogonality relations 14 to 16.
So we see that if we want to expand a function either in scaling functions or wavelets,
we have to perform integrations at some point to calculate the coeﬃcients. For general
wavelet families this integration can be fairly cumbersome [3] and require especially in 2
and 3 dimensions a substantial number of integration points. Furthermore it is not obvious
how to do the integration if the function is only given in tabulated form. The interpolating
wavelets discussed above are the glorious exception. Since the dual scaling function is a
delta function (23 ) and since the dual wavelet is a sum of delta functions (25 ), one or a
few data points are suﬃcient to do the integration exactly. One will therefore get exactly
the same number of coeﬃcients as one has data points and one has an invertible one-to-one
mapping between the functional values on the grid and the expansion coeﬃcients. This
is even true in the case of nonuniform data sets, where we necessarily have to calculate
the s and d coeﬃcients directly by integration using 28. As follows from Equation 23
and 25, one just needs the functional values at the data point at which the wavelet will
be centered and a few data points at one lower resolution level around this center.
If
one wants to calculate the interpolating wavelet center at the high resolution grid point
indicated by the fat arrow in the ﬁgure below, one needs in the case of the 4-th order
interpolating wavelets the 4 additional points indicated by thin arrows which belong to a
more coarse grid and are therefore always available even if the ﬁne grid does not extend
into this region.

In the case where one wants to represent functions with several length scales which
need inhomogeneous real space grid structure the wavelet representation allows a much
more compact representation than the scaling function representation, since on can neglect

11

all the tiny d coeﬃcients in the regions where one has little variation. To illustrate this
let us look at the function f

f (x) =

exp(−(xl)2)

8

Xl=1

Evidently this function exhibits 8 diﬀerent length scales. If one expands one simple Gaus-
sian exp(−x2) with respect to 4-th order interpolating scaling functions with a resolution
of 1/16, one gets a reasonably small error of 10−6. For the multi-scale function f , this
error increases to more than 10−2 with the same resolution. If one however uses a scheme
where one uses 32 wavelets on additional 5 resolution levels to improve the resolution as
one approaches the origin one can again represent the function with an error of roughly
10−6 ( it turns out that the expected 8 additional levels are not all needed). The total
number of coeﬃcients needed to represent the function in the interval [−2; 2] is then 4 ×
16 coeﬃcients for the equal resolution (1/16) scaling function part plus 5 × 32 coeﬃcients
for the resolution enhancement with the wavelets, which makes all together 224 coeﬃ-
cients. This has to be compared with the 1024 scaling function coeﬃcients which would
be needed to represent the function over the whole interval with the maximum resolution
of (1/256), which we have obtained around the origin with this data compression scheme.

8 Wavelets in 2 and 3 dimensions

The easiest way to construct a wavelet basis in higher dimensional spaces is by form-
ing product functions [2]. For simplicity of notation we will only consider here the 2-
dimensional case, the generalization to higher dimensional spaces being obvious.

The space of all scaling functions of resolution level k is given by

i1,i2(x, y) = φk
φk
The wavelets consist of three types of products

i1(x)φk

i2(y)

ψ[sd]k
ψ[ds]k
ψ[dd]k

i1,i2(x, y) = φk
i1,i2(x, y) = ψk
i1,i2(x, y) = ψk

i1(x)ψk
i1(x)φk
i1(x)ψk

i2(y)
i2(y)
i2(y)

(29)

(30)

(31)

(32)

A wavelet transform step in the 2-dimensional setting is done by ﬁrst transforming

along the x and then along the y direction (or vice versa).

9 The standard operator form

In a bi-orthogonal wavelet basis it is natural to solve a diﬀerential equation in the colloca-
tion sense. Let us recall that in the collocation method one has two functional spaces, the
space of the basis function which are used to represent the solution and the space of the
test functions which are used to multiply the diﬀerential equation from the left to obtain

12

a linear system of equations. In our case the expansion set are the scaling functions and
wavelets while the test set are their dual counterparts. Lets consider the case of Poisson’s
equation

Given the expansion of the charge density ρ in a wavelet basis

∇2V = −4πρ.

ρ(x) =

sKmin
j

φKmin
j

(x) +

j ψK
dK

j (x)

we are looking for the wavelet expansion coeﬃcients of the potential V .

V (x) =

SKmin
j

φKmin
j

(x) +

DK

j ψK

j (x)

Kmax

XK=Kmin Xj

Kmax

XK=Kmin Xj

Xj

Xj

Plugging in the expansion for ρ and V ( 34) and ( 35) in Poissons equation 33 and
multiplying from the left with the dual wavelet collocation test space we obtain a system
of equations

As~v = ~ρ

where ~v is the vector containing both the s and d coeﬃcients of the potential and ~ρ is
the same vector for the charge density ρ. The matrix As represents the Laplacian in this
wavelet basis and one says that it has standard form. This standard form is graphically
shown in Figure 7 .

S(0)

D(0)

D(-1)

D(-2)

(33)

(34)

(35)

(36)

S(0)

D(0)

D(-1)

D(-2)

Figure 7: The structure of a matrix in the standard form.

The problem with the standard form is that it is ﬁrst of all rather complicated. There
is coupling between all resolution levels and one has to calculate many diﬀerent types of

13

matrix elements corresponding to all possible products of wavelets and scaling functions
at diﬀerent resolution levels and positions. The second point is that there are many blocks
in that matrix which have no or only few zeroes. Let us look at the blocks representing
the coupling between the scaling functions at the highest resolution level and the wavelets
at the diﬀerent resolution. In general each scaling function will extend over the whole
computational volume and will therefore overlap with all the wavelets at any position. All
these blocks will consequently have nonzero entries only. So this standard matrix form
has more nonzero entries than we would like to have for optimal eﬃciency in the matrix
vector multiplications which are required for all iterative linear equation solvers.

10 The non-standard operator form

The so-called nonstandard [8] form gives a much easier and eﬃcient representation of our
matrix. To derive it let us ﬁrst assume, that our potential V and charge ρ are given in a
scaling function basis. The Laplacian is then represented by a matrix A whose elements
Ai,j are given by

˜φk
i (x)∇2φk

j (x)dx

The matrix equation

R

A~v = ~ρ

can graphically be represented in the following way:

<S| |S>

S

=

S

Now we can of course perform one step of a forward wavelet transform on all our
data, i.e. both on the vector to be multiplied with the matrix and on the vector which
is the result of this matrix times vector multiplication. Correspondingly we have then to
transform the matrix A using the matrices whose properties are given in Equation 18.

Graphically this gives:

˜F ~ρ = ( ˜F AF T )( ˜F~v)

<S| |S> <S| |D>

<D| |S><D| |D>

=

S

D

S

D

If we recursively applied wavelet transform to the upper S part we would obviously
obtain the standard operator form. To get the nonstandard form, we have to add another
step where we artiﬁcially enlarge our matrix A by putting in 5 blocks of zeroes as shown
below:

14

<S|S>

0

0

0

 <S|D>

=

0

0

 <D|S>

 <D|D>

S

S

D

S

S

D

We see that our input and output vectors ~v and ~ρ also have to be adapted to this

matrix structure leading to a redundant copy of the S data set.

We can now recursively apply this 2-step procedure on the < S|S > block of the result-
ing matrices. Doing this we obtain the so called non-standard form, which is graphically
visualized in Figure 8

(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)
(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)
(cid:0)(cid:0)
(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)

(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)
(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)
(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)

(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)

(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)

(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)

S

D

S

D

S

D

S

=

S

D

S

D

S

D

S

D

D

(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)

Figure 8: The structure of a matrix in the nonstandard form.

As we see, we have now completely decoupled diﬀerent resolution levels, since there
are no blocks in this matrix between diﬀerent levels. The coupling between diﬀerent
levels just enters trough the wavelet transforms which have to be interleaved with the
application of this nonstandard operator form. We also see that all the nonzero blocks
of this nonstandard matrix representation are strictly banded and the application of this
matrix to a vector scales therefore linearly.

The structure of the matrix in Figure 8 is primarily valid for the case of uniform
resolution where all the possible d coeﬃcients at the highest resolution level are nonzero.

15

It can however easily be seen that this nonstandard form retains its advantage in a case of
varying resolution where only some of the d coeﬃcients are nonzero. If the nonredundant
input data set is sparse, the redundant input data set will be sparse as well. Since all
the blocks are banded, the redundant output set will be sparse as well. Finally the
nonredundant output set will then be sparse as well.

11 Calculation of diﬀerential operators in a wavelet

basis

As we have seen in the preceeding chapter we need the matrix elements

˜φk
i (x)

˜ψk

i (x)

˜φk
i (x)

˜ψk
i (x)

∂l
∂xl φk
∂l
∂xl φk
∂l
∂xl ψk
∂l
∂xl ψk

Z

Z

Z

Z

j (x) dx

j (x) dx

j (x) dx

j (x) dx

for the application of an operator in the nonstandard form. Matrix elements on diﬀer-
ent resolution levels are related by simple scaling relations. So we just have to calculate
these 4 matrix elements for one resolution level. On a certain resolution level, we can
use the reﬁnement relations to express the matrix elements involving wavelets in terms of
matrix elements involving scaling functions (at a better resolution level) only. So we just
have to calculate the basic integral ai

ai =

Z

˜φ(x)

∂l
∂xl φ(x − i)dx

Using the reﬁnement relations Equations 7 and 9 for φ and ˜φ we obtain

ai =

˜φ(x)

Z

∂l
∂xl φ(x − i)dx
˜φ(2x − ν)

2˜hνhµ Z

∂l
∂xl φ(2x − 2i − µ)dx

2˜hνhµ2l−1

˜φ(y − ν)

Z

∂l
∂yl φ(y − 2i − µ)dy

∂l
∂yl φ(y − 2i − µ + ν)dy

˜hνhµ2l

˜φ(y)

Z
˜hνhµ 2l a2i−ν+µ

=

=

=

=

Xν,µ

Xν,µ

Xν,µ

Xν,µ

16

(37)

(38)

(39)

(40)

(41)

(42)

(43)

We thus have to ﬁnd the eigenvector ~a associated with the eigenvalue of 2−l.

where the matrix Ai,j is given by

Ai,j aj =

Xj

l

1
2 (cid:19)

(cid:18)

ai

Ai,j =

˜hνhµ δj,2i−ν+µ

Xν,µ

As it stands this eigensystem has a solution only if the rang of the matrix A − 2−lI
is less than its dimension. For a well deﬁned diﬀerential operator, i.e if l is less than the
degree of smoothness of the scaling function this will be the case.

The system of equations 44 determines the aj’s only up to a normalization factor.
For the case of interpolating wavelets the normalization condition is easily found from the
requirement that one obtains the correct result for the function xl. From the normalization
of the scaling function (17) and from elementary calculus, it follows that

φ(x)

∂l
∂xl xldx =

Z
On the other hand we know, that we can expand any polynomial of low enough degree
exactly with the interpolating polynomials. The expansion coeﬃcients are just il by
Equation 22. So we obtain

Z

φ(x)l!dx = l!

(46)

By comparing Equation 46 and 47 we thus obtain the normalization condition

φ(x)

Z

∂l
∂xl

Xi

ilφ(x − i) =

ilai

Xi

ilai = l!

Xi

The interpolating wavelet family oﬀers also an important advantage for the calcu-
lation of diﬀerential operators. Whereas in general derivative ﬁlters extend over the
interval [−2m; 2m] their eﬀective ﬁlter length is only [−m + 2; m − 2]. Since higher-
dimensional wavelets are products of one-dimensional ones diﬀerential operators in the
higher-dimensional case can easily be derived from the one-dimensional results.

The standard operator form can not only be used for the application of diﬀerential
operators, but also for other operations. If one want to transform for instance from one
wavelet family φ to another wavelet family Φ the basic integral becomes

ai =

Z

˜Φ(x)φ(x − i)dx =

˜Hνhµa2i−ν+µ

Another use is for scalar products where the fundamental integral is

ai =

Z

φ(x)φ(x − i)dx =

hνhµa2i−ν+µ

Xν,µ

1
2 Xν,µ

17

(44)

(45)

(47)

(48)

(49)

(50)

12 Solving Poisson’s equation for the U2 dimer

Poisson’s equation is a prototype diﬀerential equation and we want to solve it therefore
as an illustration of wavelet theory. To demonstrate the power of the wavelet method we
applied it to the most diﬃcult system we could think of in the area of electronic structure
calculations, namely the calculation of the electrostatic potential of a three dimensional
U2 dimer [10]. In this example, we clearly ﬁnd widely varying length scales. The valence
electrons have an extension of 5 atomic units, the 1s core electrons of 2/100 atomic units
and the nucleus itself was represented by a charge distribution with an extension of 1/2000
atomic units. So all together the length scales varied by 4 orders of magnitude and two
regions of increasing resolution (around each nucleus) were needed. In order to have quasi
perfect natural boundary conditions we embedded the molecule in a computational volume
of side length 104 atomic units. All together this necessitated 22 levels of resolution. Even
though the potential itself varies by many orders of magnitude, we were able to calculate
the solution with typically 7 digits of accuracy. We believe that it would not be possible
with any other method to solve this kind of benchmark problem.

The solution of Poisson’s equation consists of several steps. Initially we have to ﬁnd
the wavelet expansion for a data set on a nonuniform real space grid structure shown in
Figure 9 which represents the charge density. The resolution needed can in this exam-
ple be estimated from the known extension and variation of the diﬀerent atomic shells.
Analogously to the one-dimensional case, this expansion can also easily be obtained for
higher dimensional interpolating wavelets since all the dual function are related to delta
functions. Let us point out, that also in this case the mapping from real space represen-
tation to the wavelet representation is invertible, and we could thus get back exactly the
same real space values if we evaluate the wavelet expansion on the grid points.

Figure 9: A grid with two centers of increased resolution around the two nuclei. Only 3
of the 22 levels used in the calculation are shown in this projection on a plane.

Next we start a iteration loop for the potential. First we have to apply the Laplace
operator to an approximate potential using the non-standard operator form. Subtract-
ing from this result the charge density gives the residue vector which is the basis for all
iterative methods [4], such as steepest descent and conjugate gradient methods. Unfor-
tunately the condition number of the Laplace matrix worsens when more high resolution
levels are added and the number of iterations needed to obtain convergence would dramat-
ically increase if we used straightforward iterative methods. It this therefore absolutely

18

necessary to use a preconditioned iterative method which will give a condition number
which is independent of the maximal resolution.
In a preconditioning scheme one has
to ﬁnd an approximate inverse matrix of the Laplace matrix. If the Laplace matrix is
strongly diagonally dominant, then just the inverse of the diagonal part (which is again
diagonal) will be a good approximate inverse. Whether the Laplace matrix is strongly
diagonally dominant depends on the kind of wavelet family which is used. In a plane wave
representation the Laplace matrix is strictly diagonal. If therefore our wavelet family has
good frequency localization properties the resulting matrix will be strongly diagonally
dominant. Unfortunately our favorite interpolating wavelets have a very poor frequency
localization making an iterative solution practically impossible. It is therefore necessary to
do the preconditioning step within another family such as the lifted interpolating wavelets
which have much better frequency localization properties as shown in Figure 10. Their
improved frequence localization properties is related to the fact that several moments of
the wavelet vanish.

normal
skinny
fat

normal
skinny
fat

)
k
(
F

)
k
(
F

k

k

Figure 10:
The Fourier spectrum of a 4-th order unlifted Lazy wavelet (left panel)
and lifted wavelet (right panel). The spectrum is shown for 3 wavelets on neighboring
resolution levels. One has reasonable frequency separation in the lifted but not in the
unlifted case.

As discussed above the transformation into another wavelet family can also be done
with the help of the non-standard operator form. The preconditioned residue vector is then
used to update the potential and we go back to the beginning of the iteration. Using lifted
interpolating wavelets with 2 vanishing moments we were able to reduce the norm of the
residue vector by one order of magnitude with 3 iterations independent of the maximal
resolution. Despite their poor frequency localization properties, unlifted interpolating
wavelets have recently also been proposed for the solution of Poisson’s equation [9].

13 Outlook and conclusions

Since we used mainly interpolating wavelets, all we did was essentially interpolating,
which is one of the oldest technique in numerical analysis. However the framework pro-

19

vided by wavelet theory puts this whole interpolation procedure on the new and powerful
basis of multi-resolution analysis, expanding thus considerably the scope of interpolation
based techniques. In particular it assigns basis functions to certain interpolation schemes.
Wavelet based techniques allow us thus to solve diﬀerential equations which have several
length scales and to do this with linear scaling. It is thus to be expected, that wavelet
based techniques will catalyze progress in many ﬁelds of science and engineering, where
such problems exist. An detailed tutorial style book describing how to use wavelets for
the solution of partial diﬀerential equations will soon be published by the authors.

References

[1] Y. Meyer, “Ondelettes et op´erateurs” Hermann, Paris, 1990

[2] I. Daubechies, “Ten Lectures on Wavelets”, SIAM, Philadelphia (1992)

[3] W. Sweldens and R. Piessens, SIAM J. Numer. Anal. 31, 1240 (1994)

[4] W. H. Press, B. P. Flannery, S. A. Teukolsky and W. T. Vetterling, “Numerical
Recipes, The Art of Scientiﬁc Computing” Cambridge University Press, Cambridge,
England, 1986

[5] W. Sweldens, Appl. Comput. Harmon. Anal., 3, 186 (1996)

[6] G. Deslauriers and S. Dubuc Constr. Approx. , 5, 49 (1989); Similar wavelets have

been constructed by M. Teter, private communication

[7] G. Beylkin, SIAM J. on Numerical Analysis, 6, 1716 (1992)

[8] G. Beylkin, R. Coifman and V. Rokhlin, Comm. Pure and Appl. Math. 44, 141

(1991)

[9] R. A. Lippert, T. Arias and A. Edelman, to appear in J. Comp. Physics

[10] S. Goedecker, O. Ivanov, Sol. State Comm., 105, 665 (1998); and Los Alamos preprint

server, physics/9701024

20

