2
0
0
2
 
g
u
A
 
7
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
9
2
0
8
0
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Information Optimization in Coupled Audio–Visual Cortical Maps

Department of Physics, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139

Kavli Institute for Theoretical Physics, University of California, Santa Barbara, California 93106

Mehran Kardar

A. Zee

(Dated: February 2, 2008)

Barn owls hunt in the dark by using cues from both sight and sound to locate their prey. This
task is facilitated by topographic maps of the external space formed by neurons (e.g., in the
optic tectum) that respond to visual or aural signals from a speciﬁc direction. Plasticity of these
maps has been studied in owls forced to wear prismatic spectacles that shift their visual ﬁeld.
Adaptive behavior in young owls is accompanied by a compensating shift in the response of
(mapped) neurons to auditory signals. We model the receptive ﬁelds of such neurons by linear
ﬁlters that sample correlated audio–visual signals, and search for ﬁlters that maximize the gathered
information, while subject to the costs of rewiring neurons. Assuming a higher ﬁdelity of visual
information, we ﬁnd that the corresponding receptive ﬁelds are robust and unchanged by artiﬁcial
shifts. The shape of the aural receptive ﬁeld, however, is controlled by correlations between sight
and sound. In response to prismatic glasses, the aural receptive ﬁelds shift in the compensating
direction, although their shape is modiﬁed due to the costs of rewiring.

I. INTRODUCTION

In the struggle of biological organisms to survive and reproduce, processing of information is of central importance.
Sensory signals provide valuable information about the external world, such as the locations of predators and preys.
Localization of sources is facilitated by topographic maps of neurons to various parts of the brain[1], reﬂecting the
spatial arrangements of signals around the animal. The barn owl has to rely extensively on sounds to ﬁnd its prey in
the dark, and has consequently developed precise ‘auditory space maps.’

By extensive experiments, Knudsen and collaborators have shown that the optic tectum of the barn owl has both
visual and aural maps of space that are in close registry[2, 3]. The visual signal plays a crucial role in aligning the
aural map; experimental manipulations of the owl’s sensory experience reveal the plasticity of these maps in young
animals, and the instructive role played by the visual experience. (A recent review, with speciﬁc references can be
found in Ref. [4].) The current study was motivated by experiments in which owls are ﬁtted with prismatic spectacles
that shift the visual ﬁelds by a preset degree in the horizontal direction[5]. In young owls, the receptive auditory
maps were found to shift to remain in registry with the visual maps, which stayed unchanged.

There is at least one theoretical attempt to explain the registry of neural maps through a ‘value–dependent learning,’
where synaptic connections in a network are enhanced after ‘foveation towards an auditory stimulus’[6]. In this paper
we take a more abstract approach to the coupling of audio–visual maps, and search for neural connections (receptive
ﬁelds) that maximize the information gained from the sensory signals. In earlier studies[7, 8], Bialek and one of us
formulated an approach to optimization of information in the visual system, and in computations with neural spike
trains[9].

Here, we extend the methods of Ref. [7] for computing receptive ﬁelds in the visual system, to ﬁnding the optimal
connectivities in an audio-visual cortex, such as the owl’s optic tectum. We ﬁnd that the shape and registry of the
aural map is established by the correlations between the audio and visual signals. In response to an artiﬁcial shift of
the visual ﬁeld (as with the prismatic spectacles), the visual receptive ﬁeld is unchanged. While the aural receptive
ﬁeld shifts in the adaptive direction, its shape changes due to the costs of rewiring the neurons.

The general formalism for our calculations is set up in Sec. II.A, which reviews the methodology introduced in
Ref. [7]. The essence of this approach is the assumption that neural connections act as linear ﬁlters of the incoming
signals, and also introduce noise in the outputs. If the (correlated) input signals, and the random noise, are taken from
Gaussian probability distributions, the outputs are also Gaussian distributed. The Shannon[10] information content
of the resulting outputs is easily calculated. The task is to ﬁnd ﬁlter functions that maximize this information, subject
to biologically motivated costs, and for given correlations of the input signals. In Ref. [7] this approach was used to
obtain receptive ﬁelds in the visual system. In Sec. II.B, we generalize this formalism to coupled audio-visual signals.
A necessary input to the calculations is the correlations between the audio and visual signals, as discussed in
Sec. II.C. Since it is clearly much easier to localize objects by sight that sound, it is reasonable that the information
carried by the visual channel should far exceed the aural one. The two sources of information are however quite
likely to be correlated, resulting in couplings between the corresponding ﬁlters. In the experiments on barn owls, the

prismatic glasses shift the visual ﬁeld and hence modify the correlations between the signals. We examine how such
shifts change the ﬁlter functions (neural connectivities) that optimize the information content in the outputs.

As argued in Sec. II.D, the disparities in the strengths of visual and aural signals simplify the search for optimal
ﬁlters. In particular, we ﬁnd that the visual receptive ﬁelds are relatively robust and unchangeable, while the shape
of the aural receptive ﬁeld is the product of two terms: One reﬂects the correlations between sights and sounds, and
shifts along with external displacement of these signals; the second is associated with the costs of making connections
to distant neurons. This result is further interpreted in the ﬁnal section (Sec. III), where some implications for
experiments, as well as directions for future extensions and generalizations, are also discussed.

II. ANALYSIS OF INFORMATION

A. General Formalism

The processing of information by neural connections in the cortex is modelled in Ref. [7] as follows: After passing
through intermediate stations, sensory signals arrive as a set of inputs {sJ }. Further processing takes place by neurons
that sample the information from a subset of these inputs, and produce an appropriate output. For ease of calculation,
the outputs are represented as a linear transformation of the inputs, according to

Oi =

FiJ sJ + ηi

.

J
X

The ﬁltering of information is thus parameterized by the matrix {FiJ }, and is also assumed to introduce an unavoidable
noise ηi. There are of course many possible sensory inputs, which can be taken from a joint probability distribution
Pin[sJ ]. Equation (1) is thus a transformation from one set of random variables (the inputs) to another (the outputs);
the latter described by the joint probability distribution function Pout[Oi]. The amount of information associated
with a given probability distribution is quantiﬁed[10] (up to a baseline and units) by I[P ] ≡ − hln P i, where the
averages are taken with the corresponding probability. The task of ﬁnding optimal ﬁlters is thus to come up with the
matrix F that maximizes I[Pout] for speciﬁed input and noise probabilities.

The Shannon information can be calculated easily for Gaussian distributed random variables. Let us consider the

set of N random variables {xi}, taken from the probability

P [xi] =

det A
(2π)N exp

s

1
2

−

xiAij xj

,

(cid:21)

I[P ] = −

ln det A =

ln det [hxixji] ,

(cid:20)

1
2

where summation over the repeated indices is implicit, and det A indicates the determinant of the N × N matrix with
elements Aij . It is easy to check that, up to an unimportant additive constant of N/2,

−1
ij . A linear ﬁlter
where we have noted that the pairwise averages are related to the inverse matrix by hxixj i = A
as in Eq. (1), maps one set of Gaussian variables to new ones. Thus if we assume that the inputs {sJ }, and the
(independent) noise {ηi}, are Gaussian distributed, we can calculate the information content of the output using
Eq. (3), with

hOiOj i = FiJ FkL hsJ sLi + hηiηji .

We are interested in describing cortical maps related to visual or aural localization of objects. These locations
vary continuously in space, and are topographically mapped to positions on a two-dimensional cortex. As such, it is
convenient to promote the indices i and J, used above to label output and input neurons, to continuous vectors in
two dimensional space. For example, following Ref. [7], let us consider an image described by a scalar ﬁeld s(~x ) on a
2−dimensional surface with coordinates ~x. The image is sampled by an array of cells such that the output of the cell
located at ~x is given by

O (~x ) =

d2yF (~x − ~y ) s (~y ) + η (~x ) ,

where the function F (~r ) describes the receptive ﬁeld of the cell. Assuming uncorrelated neural noise, hη(~x )η(~x ′)i =
N δ2(~x − ~x ′), and signal correlations hs(~x )s(~x ′)i = S(~x − ~x ′), the ﬁlter-dependent part of the output information is

1
2

Z

2

(1)

(2)

(3)

(4)

(5)

given by

I =

ln det

δ2(~x − ~x

′

) +

d2y

′

d2y

F (~x − ~y ) F (~x

− ~y

′

1
2

(cid:20)

Z

Z

′

)

S (~y − ~y ′ )
N

.

(cid:21)

Note that we have assumed that the signal is translationally invariant, such that correlations only depend on
the relative distance between their sources. This allows us to change basis to the Fourier components, ˜s(~k ) ≡
d2x exp(−i~k · ~x )s(~x ), which are uncorrelated for diﬀerent wave-vectors ~k. The overall information is then obtained
~k → A

d2k/(2π)2 where A is the cortical area, equal to

from a sum of independent contributions, and using
R

I =

A
2

d2k
P
(2π)2 ln

R

1 +

2

F (~k )
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

,

S(~k )
(cid:21)

(cid:20)
where F (~k ) and ˜S(~k ) are Fourier transforms of the receptive ﬁeld F (~x ), and signal to noise correlations S(~x )/N ,
respectively.

Z

The task is to ﬁnd the function F (~k ) which maximizes the information I. Clearly, we need to impose certain
costs on this function, since otherwise the information gain can become enormous for F → ∞. This cost ultimately
originates from the diﬃculties of creating and maintaining neural connections that gather and transmit information
over some distance, and is hard to quantify. Following Ref. [7], we shall assume that the overall cost (in appropriate
‘information’ units) has the form

C =

2
d2xC (~x ) F (~x )

≈

d2x

2

F (~x )

=

λ + µx2
2

Z

Z

d2k
(2π)2

A
2

Z

λ

(cid:20)

F (~k )
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

2

+ µ

2

.

(cid:21)

~∇kF (~k )
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

This expression can be regarded as an expansion in powers of F and x, with the assumption that the cost is invariant
under changing the sign of F , and independent of the direction of the vector ~x. It imposes a penalty for creating
connections which increases quadratically with the length of the connection. Our central conclusion is in fact insensitive
to the form of C(~x ).

2

d2xF (~x )

If the costs are prohibitive, there will be no ﬁltering of signals. To avoid such cases, we compare only ﬁlters that are
constrained such that
= 1 (or any other constant). In the optimization process, this constraint can be
implemented via a Lagrange multiplier, resulting in an eﬀective cost similiar to the term proportional to λ in Eq. (8).
Thus, this term and the constraint can be used interchangably. In Ref. [7] it was shown that optimizing Eq. (7)
subject to the cost of Eq. (8), in the limit of low signal to noise, is equivalent to solving a Schr¨odinger equation with
F (~k ) playing the role of the wave function in a potential S(k), and the Lagrange multiplier taking the value of the
ground state energy. A potential of the form S(k) ∝ k−2 was there used to obtain receptive ﬁelds with on center/oﬀ
surround character. In the next section we generalize this approach by considering correlated visual and aural inputs.

R

B. Coupled Audio–Visual Inputs

In our idealized model, a neuron in the optic tectum of the owl ﬁlters input signals coming from both the visual

and auditory systems, and its output is given by the generalization of Eq. (5) to

O (~x ) =

d2yFα (~x − ~y ) sα (~y ) + η (~x ) ,

Z

where α is summed over A and V for audio and visual signals, respectively. Assuming as before that the signals sα
and the noise η are independent, correlations of the output are obtained as

hO (~x1)O(~x2)i =

d2y1

d2y2Fα (~x1 − ~y1) Fβ (~x2 − ~y2) Sαβ (~y1 − ~y2) + N δ2 (~x1 − ~x2) .

(10)

For translationally invariant signals, the output information is given by the generalization of Eq. (7) to

Z

Z

Z
where Sαβ(~k ) is a 2 × 2 matrix of (Fourier transformed) signal to noise correlations.

h

I =

A
2

d2k
(2π)2 ln

1 + Fα(~k )Sαβ (~k )Fβ(−~k )
i

,

Once more, we have to impose some constraints in order to make the maximization of the information in Eq. (11)
In principle, there could be diﬀerent costs for

with respect to the functions FV and FA biologically meaningful.

3

(6)

(7)

(8)

(9)

(11)

connections processing aural and visual signals. In the absence of concrete data, we make the simple choice of using
the same form as Eq. (8) for both sets of ﬁlters, so that the overall cost is

C =

d2k
(2π)2

A
2

Z

λFα(~k )Fα(−~k ) + µ~∇kFα(~k ) · ~∇kFα(−~k )
i
h

.

The ﬁrst term in the above cost function can again be interpreted as a Lagrange multiplier λ imposing a normalization
constraint

d2xFα(~x )2 = A

Z

Z

d2k
(2π)2 Fα(~k )Fα(−~k ) = 1.

C. Signal Correlations

To proceed further, we need the matrix of signal to noise correlations, which has the form

S(~k ) =

SV(k)
R(k)e−i~k·~c

 

R(k)ei~k·~c

SA(k)

.

!

The diagonal terms represent the self correlations of each signal. Since many sources generate both sight and sound,
the audio and visual signals will be correlated. These correlations are captured by the oﬀ-diagonal term R(k). In
the experiments on owls[5], the visual signal is artiﬁcially displaced by a ﬁxed angle in the horizontal direction. If we
indicate this angle by the vector ~c, an aural signal at location ~x becomes correlated with a visual signal at (~x + ~c ).
After Fourier transformation, this shift appears as the exponential factor exp(i~k · ~c ) in the oﬀ-diagonal terms of the
correlation matrix.

So far, we have treated sight and sound on the same footing. It is reasonable to assume that under most (well lit)
conditions the quality of visual information is much higher than the aural one. For ease of computation, we shall
further assume that the actual signal to noise ratio is quite small, resulting in the set of inequalities

SA(~k ) ≪ R(~k ) ≪ SV(~k ) ≪ 1.

In this limit of small signal to noise, the logarithm in Eq. (11) can be approximated by its argument (without the
one), resulting in a quadratic form in the ﬁlter functions. Our task then comes down to maximizing the function

W

Fα(~k )
i
h

≡ I − C =

d2k
(2π)2

A
2
Z
+R(~k )

SV(~k )
(cid:20)
FV(~k )F

FV(~k )
(cid:12)
−i~k·~c + F
(cid:12)
(cid:12)

(cid:12)
∗
(cid:12)
A(~k )e
(cid:12)

2

−λ

2

+

(cid:16)
FV(~k )
(cid:12)
(cid:12)
(cid:12)

(cid:18)(cid:12)
(cid:12)
(cid:12)

2

(cid:19)

FA(~k )
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

2

+ SA(~k )

FA(~k )
(cid:12)
(cid:12)
V(~k )FA(~k )ei~k·~c
(cid:12)
(cid:12)
(cid:12)
(cid:12)
2

∗

− µ

~∇kFV(~k )
(cid:12)
(cid:12)
(cid:12)

(cid:18)(cid:12)
(cid:12)
(cid:12)

(cid:17)
+

2

,

(cid:19)(cid:21)

~∇kFA(~k )
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

with respect to FV and FA.

D. Results

The optimal ﬁlters are obtained from functional derivatives of Eq. (16). Setting the variations with respect to
F ∗
V(~k ) to zero gives

while δW/δF ∗

A = 0, leads to

SV(~k ) + µ~∇2
k
h

i

λ − µ~∇2
k
h

i

FV(~k ) = λFV(~k ) −

R(~k )FA(~k )ei~k·~c

,

FA(~k ) = R(~k )FV(~k )e

−i~k·~c +

SA(~k )FA(~k )

.

n

n

o

o

In arranging the above equations, we have placed within curly brackets terms that are much smaller according to the
hierarchy of inequalities in Eq. (15). Note that in the absence of any correlations between the two signals (R = 0),

4

(12)

(13)

(14)

(15)

(16)

(17)

(18)

aural

receptive

field

-0.5

0.5

1

1.5

2

x

FIG. 1 An aural receptive with two peaks, obtained from Eq. (22) for l = 0.5, L = 0.1, and c = 1.1.

FA = 0, since the aural signal is assumed to be much weaker than the visual one. Any non-zero FA reduces FV due to
the normalization condition, resulting in a smaller value of W. It is indeed the correlations between the two signals
that lead to a ﬁnite value of FA, of the order of (R/SV). (Since λ ∼ O(SV) as shown below.)

To leading order, Eq. (17) is the Schr¨odinger equation obtained in Ref. [7] for the visual receptive ﬁeld. Without

further discussion, we shall indicate its solution by

FV(~x ) = F 0

V(~x ),

and λ = EV = O (SV) .

Note that we don’t imply that cells in the optic tectum should have a receptive ﬁeld for visual signals identical to
that in the visual cortex. The quality of signals, the costs of neural connections, and the response of the cells may
well vary from one cortical area to another. The eigenvalue EV is controlled by the strength of the visual correlations
and is of the order of SV.

To simplify the solution to Eq. (18), we ﬁrst assume that R(~k ) = R, a constant independent of ~k. This is quite
a reasonable assumption, corresponding to visual and aural signals that are correlated only if coming from the same
direction, i.e. with hsV(~x1)sA(~x2)i = Rδ2(~x1 − ~x2). We can then Fourier transform the two sides of this equation to
obtain

and quite generally, for an arbitrary form of the cost function in Eq. (8), the solution is

(cid:0)

(cid:1)

EV + µx2

FA(~x ) = RF 0

V(~x − ~c ),

FA(~x ) =

R
EV + CA(x)

F 0
V(~x − ~c ).

Due to the quadratic form of Eq. (16), the above result is the linear response of the system to the correlations between
signals.

The signiﬁcance of our result is that the aural receptive ﬁeld FA(~x ) is not simply the visual receptive ﬁeld shifted
by ~c, as one might have guessed. Rather, the shape of FA(~x ) could be signiﬁcantly distorted by the cost function
CA(x). At the moment, the data may be too crude to determine the shape of FA(~x ), but it is still worthwhile
to contemplate what sort of shape distortion may result in our simple model. For illustrative purposes, let us
take FV (~x ) ∝ exp
to be a Gaussian with l a length scale characteristic of the visual receptive ﬁeld and
CA(x) = µx2. Then we predict (with ~c = (c, 0) and ~x = (x, y))

−(x/l)2

(cid:2)

(cid:3)

FA(x, y) ∝

1 + (x2 + y2) /L2 exp

1

−

(x − c)2 + y2
l2

(cid:20)

,

(cid:21)

p

where L ≡
are three length scales L, l, and c inovlved, the shape of FA(x, y) depends only on the two ratios L/l and c/l.

EV /µ deﬁnes a length scale characteristic of the relative cost of connecting distant neurons. While there

We now qualitatively describe the change in the shape of the aural receptive ﬁled in Eq. (22), as the imposed shift
c is varied as in the experiments of Knudsen et al. (The exact analysis of the extremal points of Eq. (22) involves
the solution of a cubic equation which will not be given here.) Two types of behavior are possible depending on the
ratio l/L. For l ≪ L, where the cost of rewiring is negligible, the function FA(x, y) has a single maximum located at
x ≈ c (and y = 0), i.e. simply following the imposed shift. When l ≫ L, however, there is an intermediate range of
values of c, where the aural receptive ﬁeld has two peaks, one close to the origin, x− ≈ cL/l ≪ c, and another close
to x+ ≈ c. A typical proﬁle with two peaks is depicted in Fig. 1.

5

(19)

(20)

(21)

(22)

6

III. DISCUSSIONS

Equation (21) is the central result of our study. It provides the optimal linear ﬁlter for a weak signal correlated to

a stronger one. Some speciﬁc features of this result in connection with the coupled visual and aural maps are:

• The shape of the aural receptive ﬁeld is very much controlled by the visual information, modulated by the costs

associated with neural connectivities.

• Artiﬁcially displacing the two signal sources, as in the case of the prismatic spectacles used on the barn owls[5],
modiﬁes the aural receptive ﬁeld. However, the resulting receptive ﬁeld is not simply shifted (unless the costs
of neural wirings are negligible), but also changes its shape.

• Equation (21) is the product of two functions, one peaked at the origin and the other at ~x = ~c. Depending of
the relative strengths and widths of these two peaks, the receptive ﬁeld may be more sensitive to signals at the
original, or in the shifted location.

• The experiments ﬁnd, not surprisingly, that adaptation to the prismatic glasses depends strongly on the age of
the individual owl. This feature can be incorporated in our model with the reasonable assumption that the cost
of neural connections increases with age of the individual.

This work is small step towards providing a quantitative framework for deducing the workings of the brain, starting
from the tasks that it has to perform for the organism to function in its natural habitat. In this framework, the tasks
of the sensory systems are more apparent: to extract the relevant signals from the background of natural inputs,
and as a ﬁrst step to localize the source of the signal in the external world. It is possible to experimentally gather
information about the correlations of various signals in the natural world, and there are indeed several studies of the
statistics of various aspects of visual images[11]. Of course, such statistics are also speciﬁc to the instrument (e.g.
camera) used to obtain the image. More relevant are psycho-physical studies that probe how individuals parse the
visual information[12]. We are not aware of similar studies on the statistics of natural sounds in diﬀerent directions,
and their correlations with visual signals. Such studies may provide part of the material needed for a more detailed
study.

The outcome of the procedure outlined in this paper is a set of ﬁlter functions, which are hopefully related to the
actual connections between neurons. The shape and range of such connections can be studied directly by injection
of biocytin dye[13], and indirectly by mapping the receptive ﬁeld of a neuron via a microelectrode probe. Detailed
studies of this kind for the owls reared with prismatic spectacles, and their comparison with Eq. (21) may provide
insights about the cost of making neural connections, another necessary input to our general formalism.

The analytical formalism itself can be extended in several directions. Already, in Ref. [7] it was proposed that
colored images can be studied by considering a vector signal ~s ranging over the color wheel. In regards to diﬀerent
sensory inputs, we may can also ask if and when it is advantageous to segregate outputs to distinct cortical areas,
allowing for distinct maps {Oν}. A more ambitious goal is to extend the formalism to time dependent signals, allowing
for ﬁlters with appropriate time delays that attempt to take advantage of temporal patterns in the signals.

This work was supported in part by the NSF under grant numbers DMR-01-18213 (MK), PHY89-04035 and

Acknowledgments

PHY95-07065 (AZ).

References

[1] J.H. Kaas and T.A. Hackett, J. Comp. Neurol. 421, 143 (2000).
[2] E.I. Knudsen, J. Neurosci. 2, 1177(1982).
[3] E.I. Knudsen, Science 222, 939(1983).
[4] E.I. Knudsen, Nature 417, 322(2002).
[5] M.S. Brainard and E.I. Knudsen, J. Neurosci. 18, 3929(1998); E.I. Knudsen and M.S. Brainard, Science 253, 85(1991).
[6] M. Rucci, G. Tononi, and G.M. Edelman, J. Neurosci. 17, 334(1997).
[7] W. Bialek, D.L. Ruderman, and A. Zee, in Advances in Neural Information Processing Systems, edited by R. P. Lippman,

et al., (San Mateo, Morgan Kaufmann Publishers, 1991) page 363.

[8] W. Bialek and A. Zee, Phys. Rev. Lett. 61, 1512 (1988).
[9] W. Bialek and A. Zee, J. Stat. Phys. 59, 103 (1990).
[10] C.E. Shannon and W. Weaver, The Mathematical Theory of Computation, University of Illinois Press, Urbana, IL (1949).

[11] M. Sigman, G.A. Cecchi, C.D. Gilbert, and M.O. Magnasco, Proc. Nat. Acad. Sci. 98, 1935(2001).
[12] J. Malik, D. Martin, C. Fowlkes, and D. Tal, (A Database of Human Segmented Natural Images and its Application
to Evaluating Segmentation Algorithms and Measuring Ecological Statistics) submitted to International Conference on
Computer Vision, 2001. [Also avaliable as Technical Report No. UCB/CSD-1-1133, Computer Science Division, University
of California at Berkeley, January, 2001.]

[13] W.M. DeBello, D.E. Feldman, and E.I. Knudsen, J. Neurosci. 21, 3161(2001).

7

