DNA Segmentation as A Model Selection Process ∗

Wentian Li
Laboratory of Statistical Genetics
The Rockefeller University, Box 192
New York, NY 10021, USA
wli@linkage.rockefeller.edu
http://linkage.rockefeller.edu/wli/

1
0
0
2
 
r
p
A
 
5
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
7
2
0
4
0
1
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

ABSTRACT
Previous divide-and-conquer segmentation analyses of DNA
sequences do not provide a satisfactory stopping criterion
for the recursion. This paper proposes that segmentation
be considered as a model selection process. Using the tools
in model selection, a limit for the stopping criterion on the
relaxed end can be determined. The Bayesian information
criterion, in particular, provides a much more stringent stop-
ping criterion than what is currently used. Such a stringent
criterion can be used to delineate larger DNA domains. A
relationship between the stopping criterion and the average
domain size is empirically determined, which may aid in the
determination of isochore borders.

INTRODUCTION

1.
A typical DNA sequence is not homogeneous. There are
local regions with contrast: C+G rich versus C+G poor;
protein-coding regions with a strong signal of periodicity-
three versus non-coding regions lacking this periodicity; high
densities of 5’-CG-3’ dinucleotides (CpG island) versus low
density of this dinucleotide; etc. Finding the exact border
between these regions is an important task in DNA sequence
analysis. It is a common practice to use a moving window
to visually monitor the variation of the quantity of interest
(e.g. C+G density) along the sequence, and the border is
determined in an ad hoc way. With the sequence informa-
tion, it is actually possible to determine the border exactly
by certain mathematical criterion.

These mathematical approaches to delineate regional homo-
geneous domains are known as “segmentation” [21], “parti-
tioning”, or “change-point analysis” [11, 13, 14] in diﬀerent
ﬁelds ranging from image processing to statistics. There are
segmentation methods that require guessing the number of
homogeneous regions. There are also segmentation methods
that require speciﬁcation of the number of types of domains

∗

(e.g. C+G rich and C+G poor represent two types of do-
mains, whereas C+G high, intermediate, and low specify
three types). Segmentation analysis of DNA sequences can
be found in [18, 15, 9, 33].

One particularly attractive segmentation method is a divide-
and-conquer approach [4, 28] (similar recursion processes are
also discussed in statistics and machine learning under the
names of “classiﬁcation and regression tree” [10], “recursive
partitioning” [38], “decision tree induction” [30, 31], etc).
The DNA sequence is ﬁrst segmented into two subsequences
so that base compositions on two sides of the partition are
maximized. Then, the same procedure is carried out on
both the left and the right subsequences; and then on the
sub-subsequences, etc. Eventually, either the size of a sub-
sequence is too small to segment, or the diﬀerence between
the left and right subsequences is not big enough to be worth
further segmentation. Recursive segmentation oﬀers the fol-
lowing advantages: there is no need to specify the number
of homogeneous domains beforehand; the number of types
of domains need not to be speciﬁed (it is implied in the
stopping criterion); there is no constraint on the size distri-
bution of the domains (such a constraint exists in hidden-
Markov-model-based segmentations); and the computation
is eﬃcient.

This paper addresses one of the disadvantages of this seg-
mentation: the stopping criterion of the recursion. Another
disadvantage of this approach – the fact that the solution is
a local maximum with no guarantee of the global maximum
being obtained – is not addressed here. In principle, one can
set any stopping criterion, leading to domains of any sizes.
In the hypothesis testing framework of statistics, whether a
test is “signiﬁcant” or not (corresponding to a continuation,
or a termination, of the recursion in our case) is decided by
a pre-set “signiﬁcance level”. Usually, the signiﬁcance level
can be 0.05, 0.01, or 0.001. These levels are arbitrary and
will not guarantee objectivity [3].

We provide a stopping criterion based on the framework of
model selection (for a detailed discussion of the hypothesis
testing framework versus the model selection framework, see
[12]). This new stopping criterion oﬀers at a minimum con-
dition for the recursive segmentation to continue. On the
other hand, in the hypothesis testing framework, no such
minimum condition exists; for example, the 0.06 signiﬁcance
level is weaker than the 0.05 level, and 0.1 is even weaker
than 0.06, etc. In the model selection framework, there are

ˆE(

Nα

{

) = X
}

α=a,c,g,t

Nα
N

log

Nα
N

.

(1)

a model selection

two diﬀerent guiding principles. The ﬁrst is to choose a
model that most closely approximates the true model. The
second is to ﬁnd the true model among a list of candidate
models. The ﬁrst principle leads to a technique of Akaike
Information Criterion (AIC), and the second leads to the
technique of Bayesian Information Criterion (BIC). We will
show that BIC-based stopping criterion for segmentation is
practically more useful.

2. METHODS

2.1 The divide-and-conquer segmentation in

its original formulation

The original publication of this divide-and-conquer segmen-
tation method is called “entropic segmentation” [4, 28], be-
cause the quantities used in determining the partition point
are based on entropy, a statistical physics concept. The
entropy of a sequence with length N and number of bases
(b)
(α = a, c, g, t) is calculated as ( ˆ means that the
quantity is estimated from the data)

Nα

}

{

Given a partition point i (1 < i < N ), an entropy-based
quantity called Jensen-Shannon distance (divergence) [26]
is deﬁned as

ˆDJ S = ˆE(

Nα

)
}

−

i
N

ˆE(

Nα,l

{

)
}

−

N

−
N

i

ˆE(

Nα,r

)
}

{

{

(2)

}

{

and

Nα,l

Nα,r

where
are the base counts of the left
(from position 1 to i) and the right (from position i + 1 to
position N ) subsequences (with Pα Nα,l = i, Pα Nα,r =
i). The partition point i is chosen to maximize ˆDJ S.
N

{

}

−

2.2 The divide-and-conquer segmentation as

a likelihood ratio test

In fact, the above entropic description can be cast into a hy-
pothesis testing framework – the likelihood ratio test [17].
Likelihood is simply the probability of observing the data,
given a model, with emphasis on the functional dependence
on the model parameter (in other words, the normalization
coeﬃcient is not needed). To test whether a model is “sig-
niﬁcant”, the likelihood under the model (L2) is calculated,
and maximized over all possible parameters ( ˆL2). A similar
calculation is carried out on the null model (L1 and ˆL1).
If the null model is the correct model of the data, and if
the null model is nested in the alternative model, it can be
shown that in the large sample size limit [16]:

2 log

ˆL2
ˆL1 ∼

2
df =K2−K1

χ

(3)

−

2
df is the chi-squared distribution with degrees of
where χ
freedom df (i.e.
sum of df terms of squared unit normal
distribution), K2 and K1 are the number of free parameters
in maximizing L2 and L1.

In our divide-and-conquer segmentation, L1 is the likelihood
assuming the sequence being a random sequence, and L2 is

the likelihood assuming two random subsequences:

L1(

pα

{

) = Y
}
α

pNα
α ,

L2(

pα,l

{

pα,r

,
}

{

, i) = Y
}
α

p

Nα,l
α,l Y
α

Nα,r
α,r

p

(4)

}

{

}

{

}

pα

pα,l

and

pα,r

(α = a, c, g, t) is the base composition of the
where
whole sequence (here these are free parameters in the model
to be estimated),
are the similar base com-
{
positions of the left and right subsequences. The maximum
likelihood estimation of a base composition is simply the
percentage of the base: ˆpα = Nα/N . It can easily be shown
that 2 log( ˆL2/ ˆL1) is the same as 2N ˆDJ S . The number of pa-
rameters in the two models are K2 = 7 (the partition point
i is also a free parameter) and K1 = 3. So 2N ˆDJ S under
the null hypothesis should obey the χ2
df =4 distribution (the
same conclusion was reached before, see [6] and (I Grosse,
et al.
in preparation), only the df used there is 3, instead
4).

2.3 The divide-and-conquer segmentation as

There are many shortcomings in the hypothesis testing frame-
work [12]. The purpose of a test is to see how bad a descrip-
tion of the data L1 is, not how good a description L2 is.
For many circumstances, it is not really what we are in-
terested in. In the model selection framework, we directly
address the “merit” of a model. One measure of such a
“merit” is whether the model is close (a better approxima-
tion) to the true model. The closeness is measured by the
Kullback-Leibler distance (divergence) [20], and the Akaike
Information Criterion (AIC) is one approximation of this
distance (with the constant term removed, and multiplied
by a factor of 2) [2]:

AIC =

2 log( ˆL) + 2K + O(

−

1
N

).

(5)

where ˆL is the maximized likelihood of the model, K is
the number of free parameters in the model. A model with
the lowest AIC is closest to the true model, thus the best
approximating model.

Another “merit” of a model is how the data increases the
probability of the model (only in Bayesian statistics is it pos-
sible to extend the concept of probability to the model and
its parameters). The factor between the prior and posterior
probability of the model is the “integrated likelihood” [32].
An asymptotic approximation of minus-twice the logarithm
of the integrated likelihood is the Bayesian Information Cri-
terion (BIC) [36]:

BIC =

2 log( ˆL) + log(N )K + O(1) + O(

) + O(

),

1
√N

1
N

(6)

where N is the sample size. A model with the lowest BIC has
the largest integrated likelihood, and this translates to the
largest posterior probability if all models have the same prior
probability. Note that AIC emphasizes an approximation of
the true model, and BIC emphasizes the selection of the true
model from the space of all models. The high-order terms in
AIC are discussed in [37, 19], and the derivation of BIC can
be found in [32]. It can easily be seen that if log(N ) > 2 (or

lambda phage (N=48.5k)

BIC-based ACGT segmentation

6
.
0

5
.
0

4
.
0

3
.
0

2
.
0

%
G
C

BIC-based SW segmentation

1st

AIC-based ACGT segmentation

....

...

....

.. ...

. .... ..

.. .. . .......

.......

.........

....

............. .................... ....... ........ .....

.

..

. .....

............ ... . ..

strength of BIC-based

SW segmentation

3rd

2nd

3rd

0

10000

20000

30000

40000

50000

position

Figure 1: Lambda (λ) bacteriophage sequence.

)

%

(
 
h
t
g
n
e
r
t
s

0
0
0
3

0
0
0
2

0
0
0
1

0

N > 7.389), the penalty on the number of model parameters
(i.e. the second term in Eq.(5) and Eq.(6)) in BIC is more
severe than that in AIC. As a result, BIC tends to select
simpler models than AIC.

When the segmentation is viewed as a model selection pro-
cess, the model before the segmentation describes the se-
quence as a random sequence, whereas that after the seg-
mentation describes it as two random subsequences. Since
AIC/BIC must decrease for the segmentation to continue,
it can be shown that they lead to the two stopping criteria
as follows:

AIC-based

BIC-based

stopping criterion
1
N
stopping criterion

)

2N ˆDJ S > 8 + O(

2N ˆDJ S > 4 log(N ) + O(1) + O(

) + O(

).(7)

1
√N

1
N

It is interesting to compare these criteria with those in the
hypothesis testing framework. Setting the value of 8 to
2
df =4, the corresponding signiﬁcance level (p-value, tail-
the χ
area) is 0.091578. In the hypothesis testing framework, it is
allowed to set an even more relaxed signiﬁcance level such
as 0.1, but in the AIC-based model selection, 0.091578 is
the limit of allowed levels. Similarly, with a given sequence
length N , the limit of allowed levels can be determined by
a BIC-based model selection; for example, if N = 1Mb, the
signiﬁcance level is 2.8631
. Again, the signiﬁcance
10
level can not be more relaxed than these limits.

−11

×

Besides limits on the relaxed side of the stopping crite-
rion, there are no theoretical limits on the stringent side.
One model can be “marginally better” than another model,
“moderately better”, or “much better”, etc. We will show
that one can gradually make the stopping criterion more
stringent so that average domain size is increased. For con-
venience, we deﬁne the “strength” of a 1-to-2 segmentation
as the percentage increase of 2N ˆDJ S over the BIC-deﬁned

stopping threshold:

strength =

2N ˆDJ S

4 log(N )

−
4 log(N )

.

(8)

The strength has to be larger than 0, but it has no upper
limit.

3. RESULTS
Since the AIC-based stopping criterion is more relaxed than
the typical 0.01-signiﬁcance-level test, one will end up with
more domains than from the program discussed in [28]. The
BIC-based stopping criterion, however, is more interesting
for our purpose, because it provides a theoretical justiﬁ-
cation for using a much more stringent stopping criterion
than those typically used in the hypothesis testing frame-
work. We illustrate the BIC-based segmentation by three
DNA sequences with a wide range of sequence lengths.

3.1 Lambda phage
Fig.1 shows the result for λ bacteriophage (N = 48, 502 b)
[35]. This sequence has been tested with various segmenta-
tion methods in [9]. There are several pieces of information
displayed in Fig.1: the domain borders obtained by the BIC-
based segmentation on the original four-symbol sequence
(upper bars); the borders segmented by the two-symbol (CG
vs. AT) sequence (middle bars); the borders obtained by
the AIC-based segmentations (with higher-order terms in-
cluded) (dots; due to the limitation of resolution, individual
dots can be hard to see); a moving-window C+G content
along the sequence; the strength of the segmentations as de-
ﬁned in Eq.(8) (lower spikes); and the sequential order of
early-rounds of segmentations (e.g. the ﬁrst partition point
from the 1-to-2 segmentation is labeled “1st”). We note the
following: (1) Segmentation results from the four-symbol se-
quence and the two-symbol sequence are diﬀerent. (2) The
number of domains by segmenting the four-symbol sequence
is 6, which is the same as results from a two-state hidden
Markov segmentation as discussed in [9]. (3) Early-rounds
of 1-to-2 segmentations are usually the “strongest” (with
largest strengths). (4) Even without any tuning of param-

%
G
C

%
G
C

%
G
C

%
G
C

6
.
0

5
.
0

4
.
0

3
.
0

2
.
0

6
.
0

5
.
0

4
.
0

3
.
0

2
.
0

6
.
0

5
.
0

4
.
0

3
.
0

2
.
0

6
.
0

5
.
0

4
.
0

3
.
0

2
.
0

TEL <-

BIC-based ACGT segmentation (strength>100%)

MHC (N=3.67Mb)

BIC-based SW segmentation (strength>100%)

strength of BIC-based SW segmentation

[class-I]

3rd

0-1Mb

)

%

(
 
h
t
g
n
e
r
t
s

)

%

(
 
h
t
g
n
e
r
t
s

)

%

(
 
h
t
g
n
e
r
t
s

)

%

(
 
h
t
g
n
e
r
t
s

0
0
0
0
2

0
0
0
0
1

0
0
0
5

0

0
0
0
0
2

0
0
0
0
1

0
0
0
5

0

0
0
0
0
2

0
0
0
0
1

0
0
0
5

0

0
0
0
0
2

0
0
0
0
1

0
0
0
5

0

2nd

1-2Mb

2-3Mb

3-4Mb

[class-III]

3rd

1st

[class-II]

-> CEN

3rd

2nd

3rd

[class-II-extended]

Figure 2: Human major histocompatibility complex (MHC) sequence.

drosophila ch2 left arm (N=22M)

ACGT seg (strength >200%)

3rd

2nd
3rd

0

2

4

6

8

10

1st

%
G
C

%
G
C

4
4
.
0

0
4
.
0

6
3
.
0

4
4
.
0

0
4
.
0

6
3
.
0

)

%

(
 
h
t
g
n
e
r
t
s

)

%

(
 
h
t
g
n
e
r
t
s

0
0
0
0
1

0
0
0
5

0

0
0
0
0
1

0
0
0
5

0

12

14

16

18

20

22

3rd

2nd

3rd

Figure 3: Left arm of Drosophila melanogaster chromosome 2

eters (in contrast to tuning of the signiﬁcance level in the
hypothesis testing framework), the BIC-based segmentation
manages to obtain a reasonable number of domains (AIC-
based segmentation, on the other hand, leads to too many
domains).

3.2 MHC
Fig. 2 shows the result for the human major histocompat-
ibility complex (MHC) sequence (N = 3, 673, 778 b) [27].
The MHC sequence is a highly gene-rich region (with more
than 200 genes) that is located on the short-arm of chromo-
some 6 of the human genome. The segmentation result cap-
tures the complexity of this sequence. With so many domain
borders in Fig.2, we only show those that have strengths
larger than 100%. Historically, the MHC sequence is di-
vided into three domains (in the telomere-to-centromere di-
rection): class-I, class-III (C+G-rich), class-II (C+G-poor).
The MHC sequencing project added another C+G-rich do-
main to the end: extended-class-II. Interestingly, the bor-
der of these domains can be easily detected by segmen-
tation (these results are from the two-symbol segmenta-
tion): I/III: i= 1,841,871, strength= 23679.6%, III/II: i=
2,483,966, strength= 17084.7%, II/extended-II: i=3,384,907,
strength=28849%. These three 1-to-2 segmentations are the
strongest. With this segmentation result, the domain sizes
of class I, III, II, and extended-II are: 1.84 Mb, 0.64 Mb, 0.90
Mb and 0.29 Mb. The number of segmented domains in the
MHC sequence is very large (1260 from the BIC-based two-
symbol segmentation and 1828 from the BIC-based four-
symbol segmentation). Segmentation with the minimum re-
quirement (i.e. for BIC to decrease) not only leads to large,
100kb-plus domains, but also leads to smaller-scaled base
composition ﬂuctuation. This “domains-within-domains”
phenomenon has been discussed in [25, 4, 22, 23]. If one is
only interested in isochores, i.e., large DNA segments with
usually 300 kb or longer that have relatively homogeneous
base composition [7, 8], a more stringent criterion has to be
used (to be discussed later).

3.3 Left-arm of Drosophila chromosome 2
The last sequence to be segmented is the left arm of Drosophila
melanogaster chromosome 2 (N = 22, 075, 671 b)[1]. There
is 1.78% of the sequence that is not determined (symbol
“n” or “N ”). To preserve the location information, these
undetermined symbols are replaced randomly by the four
nucleotides (according to the actual base composition of
this sequence). Only the 1-to-2 segmentations with strength
larger than 200% are included in Fig.3, and only the result
for the four-symbol sequence is displayed. The segmenta-
tion of a four-symbol sequence is more likely to cut the
telomere (as well as centromere) at an earlier stage than
the corresponding two-symbol sequence; and this is shown
in Fig.3. This observation can be used to delineate complex
sequence patterns in telomere sequences (D Kessler and W
Li, in preparation).

Although the drosophila sequence is much longer than the
MHC sequence, there is only one 1-to-2 segmentation of the
drosophila’s left-arm of chromosome 2 that has a similar
strength as those of the MHC sequence leading to domain
borders. This occurs at position 6,959,803 with the strength
16768%. If we use a similar strength criterion as that used
in delineating three domain classes in the MHC sequence,
there is only one domain border in this sequence.

3.4 How stringent the stopping criterion has
to be to reach a certain domain size
Since the model selection framework only provides a limit on
the relaxed end of the stopping criterion, the stringent end
is in principle open. Nevertheless, we can empirically deter-
mine the typical domain size as a function of the stringency
of the stopping criterion. Fig.4 shows the average domain
sizes versus the threshold value for the strength, all based
on the four-symbol segmentation. Besides the three se-
quences used in Figs.1-3, results from Escherichia coli (N =
4, 639, 221 b), the right arm of Drosophila melanogaster chro-
mosome 2 (N = 20, 228, 487 b), and yeast Saccharomyces
cerevisiae chromosome 3 (N = 315, 341 b) are also included.

average domain size vs threshold for segmentation strength

D
d

d
D

e

m

m

D: drosophila 2R(20.2M)

d
D
e

y

m

d
D
e

y

m

yeast ch3(0.315M)

D
d

e

y

m

d
D

e

y

m

MHC (3.67M)

1 Mb

300 kb

l

)
e
a
c
s
 
g
o
l
 
n
i
(
 
)
b
M

i

i

(
 
e
z
s
 
n
a
m
o
d
 
e
v
a

0
0
5
.
0

0
5
0
.
0

5
0
0
.
0

d
e
D

y

m

l

d: drosophila 2L(22.1M)

e. coli (4.6M)

d
D
e

y

d
e
D

y

l
m

e

l

m

y

lambda phage(0.0485M)
m
l

e

y
l

0

200

400

600

800

1000

threshold for seg strength (%)

Figure 4: Average domain size vs. threshold for segmentation strength.

Fig.4 shows that for the drosophila sequence (not surpris-
ingly, the left and right arms of chromosome 2 behave simi-
larly), the segmented domains have an average size of 1 Mb
when the threshold of segmentation strength is set at 900%.
When the threshold of strength is set at 500%, the average
size of the segmented domains is around 300 kb – a rough
minimum size for an isochore [7]. Fig.4 also shows that dif-
ferent sequences behave diﬀerently. For the MHC sequence,
for example, it is very diﬃcult to delineate only the larger
domains. To reach the average size of 300 kB, the threshold
of strength has to be set at 1300%, and to reach 1 Mb, the
3200%. Another way
threshold has to be around 2800%
to state this diﬀerence is that the MHC is more “complex”
than other sequences in Fig.4, in the sense of the existence
of a huge number of domains.

∼

Plots like Fig.4 are similar to the “compositional complex-
ity” [34, 23, 5]. The diﬀerence is that in [34, 23, 5], not only
the number of domains, but also the base composition diﬀer-
ence between domains is part of the measure of complexity.
In Fig.4, it is purely the number of domains. Nevertheless,
the plot of Fig.4 is useful because it provides practical guid-
ance on the choice of stopping criterion at the stringent end.
This choice will subjectively depend on what length scales
are of interest to the investigator.

4. ACKNOWLEDGMENTS
The work is supported by the NIH grant K01HG00024. The
author acknowledges discussions/communications with J´ose
Oliver, Pedro Bernaola-Galv´an, Ivo Grosse, Ken Burnham,
and Yaning Yang.

5. REFERENCES

[1] MD Adams, et al. (2000), “The genome sequence of
Drosophila melanogaster”, Science, 287:2185-2195.

[2] H Akaike (1974), “A new look at the statistical model
identiﬁcation”, IEEE Transactions on Automatic
Control, 19:716-723.

[3] JO Berger, DA Berry (1988), “Analyzing data: is

objectivity possible?”, American Scientist, 76:159-165.

[4] P Bernaola-Galv´an, R Roman-Rold´an, JL Oliver

(1996), “Compositional segmentation and long-range
fractal correlations in DNA sequences”, Physical
Review E, 53(5):5181-5189.

[5] P Bernaola-Galv´an, P Carpena, R Roman-Rold´an, JL
Oliver (1999), “Decomposition of DNA sequence
complexity”, Physical Review Letters,
83(16):3336-3339.

[6] P Bernaola-Galv´an, I Grosse, P Carpena, JL Oliver, R

Roman-Rold´an, HE Stanley (2000), “Finding borders
between coding and noncoding DNA regions by an
entropic segmentation method”, Physical Review
Letters, 85:1342-1345.

[7] G Bernardi (1989), “The isochore organization of the

human genome”, Annual Review of Genetics,
23:637-661.

[8] G Bernardi (1995), “The human genome: organization
and evolutionary history”, Annual Review of Genetics,
29:445-476.

[9] JV Braun, HG M¨uller (1998), “Statistical methods for
DNA sequence segmentation”, Statistical Science,
13(2):142-162.

[10] L Breiman, JH Friedman, RA Olshen, CJ Stone
(1984), Classiﬁcation and Regression Trees
(Wadsworth).

[29] E Parzen, K Tanabe, G Kitagawa (1998), eds.
Selected Papers of Hirotugu Akaike (Springer).

[30] JR Quinlan (1986), “Induction of decision trees”,

[11] BE Brodsky, BS Darkhovsky (1993), Nonparametric

Machine Learning, 1:81-106.

[31] JR Quinlan (1993), C4.5: Programs for Machine

Learning (Morgan Kaufmann).

[32] AE Raftery (1995), “Bayesian model selection in

social research”, in Sociological Methodology, ed. PV
Marsden (Blackwells), pp.185-195.

[33] VE Ramensky, V Ju Markeev, MA Roytberg, VG

Tumanyan (2000), “DNA segmentation through the
Bayesian approach”, Journal of Computational
Biology, 7(1-2):215-231.

[34] R Roman-Rold´an, P Bernaola-Galv´an, JL Oliver

(1998), “Sequence compositional complexity of DNA
through an entropic segmentation method”, Physical
Review Letters, 80(6):1344-1347.

[35] F. Sanger, et al. (1982), “Nucleotide sequence of

bacteriophage λ DNA,” Journal of Molecular Biology,
162:729-773.

[36] G Schwarz (1978), “Estimating the dimension of a

model”, Annals of Statistics, 6:461-464.

[37] N Sugiura (1978), “Further analysis of the data by
Akaike’s information criterion and the ﬁnite
corrections”, Communications in Statistics, Theory
and Methods, A7:13-26.

[38] H Zhang, B Singer (1999), Recursive Partitioning in

the Health Sciences (Springer)

Methods in Change Point Problems (Kluwer
Academic).

[12] KP Burnham, DR Anderson (1998), Model Selection

and Inference (Springer).

[13] E Carlstein, HG M¨uller, D Siegmund (1994), eds.

Change-Point Problems (IMS).

[14] J Chen, AK Gupta (2000), Parametric Statistical

Change Point Analysis (Birkhauser).

[15] GA Churchill (1989), “Stochastic models for
heterogeneous DNA sequences”, Bulletin of
Mathematical Biology, 51:79-94.

[16] DR Cox, DV Hinkley (1974), Theoretical Statistics

(Chapman & Hill).

[17] AWF Edwards (1972), Likelihood (Cambridge Univ

Press).

[18] RA Elton (1974), “Theoretical models for

heterogeneity of base composition in DNA”, Journal
of Theoretical Biology, 45:533-553.

[19] CM Hurvich, CL Tsai (1989), “Regression and time
series model selection in small samples”, Biometrika,
76:297-307.

[20] S Kullback, RA Leibler (1951), “On information and
suﬃciency”, Annals of Mathematical Statistics,
22:79-86.

[21] J Li, RM Gray (2000), Image Segmentation and

Compression Using Hidden Karkov Models (Kluwer
Academic).

[22] W Li (1997), “The study of correlation structures of
DNA sequences – a critical review”, Computer &
Chemistry, 21(4):257-272.

[23] W Li (1997), “The complexity of DNA: the measure of
compositional heterogeneity in DNA sequences and
measures of complexity”, Complexity, 3(2):33-37.

[24] W Li (2001), “New stopping criteria for segmenting

DNA sequences”, preprint.

[25] W Li, T Marr, K Kaneko (1994), “Understanding

long-range correlations in DNA sequences”, Physica
D, 75:392-416 [erratum, 82, 217 (1995)].

[26] J Lin (1991), “Divergence measures based on the

Shannon entropy”, IEEE Transactions on Information
Theory, 37(1):145-151.

[27] MHC sequencing consortium (1999), “Complete
sequence and gene map of a human major
histocompatibility complex”, Nature, 401:921-923.

[28] JL Oliver, R Roman-Rold´an, J Perez, P

Bernaola-Galv´an (1999), “SEGMENT: identifying
compositional domains in DNA sequence”,
Bioinformatics, 15(12):974-979.

