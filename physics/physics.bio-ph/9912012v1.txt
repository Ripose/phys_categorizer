9
9
9
1
 
c
e
D
 
4
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
2
1
0
2
1
9
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Dynamic ﬁtness landscapes in the quasispecies
model

Claus O. Wilke∗, Christopher Ronnewinkel†and Thomas Martinetz‡
Institut f¨ur Neuro- und Bioinformatik
Medizinische Universit¨at zu L¨ubeck
Seelandstr. 1a, 23569 L¨ubeck, Germany

March 17, 2008

Abstract

The quasispecies model is studied for the special case of externally vary-
ing replication rates. Most emphasis is laid on periodic time dependencies,
but other cases are considered as well. For periodic time dependencies, the
behavior of the evolving system can be determined analytically in several
limiting cases. With that knowledge, the qualitative phase diagram in a
given time-periodic ﬁtness landscape can be predicted without almost any
calculations. Several example landscapes are analyzed in detail in order to
demonstrate the validity of this approach. For other, non-periodic time de-
pendencies, it is also possible to obtain results in some of the limiting cases,
so that there can be made predictions as well. Finally, the relationship
between the results from the inﬁnite population limit and the actual ﬁnite
population dynamics is discussed.

∗CO Wilke is on the leave to Caltech, Pasadena, CA. Email: claus.wilke@gmx.net
†C Ronnewinkel’s current postal address is: Institut f¨ur Neuroinformatik, Ruhr-Universit¨at

Bochum 44780 Bochum, Germany. Email: ronne@neuroinformatik.ruhr-uni-bochum.de

‡Email: martinetz@informatik.mu-luebeck.de

1

Contents

1 Introduction

2 Time-dependent replication rates

3 Periodic ﬁtness landscapes

8
8
3.1 Diﬀerential equation formalism . . . . . . . . . . . . . . . . . . . .
3.1.1 Neumann series for X . . . . . . . . . . . . . . . . . . . . .
9
3.1.2 Exact solutions for R = 0 and R = 0.5 . . . . . . . . . . . . 12
Schematic phase diagrams . . . . . . . . . . . . . . . . . . . 14
3.1.3
3.2 Discrete approximation . . . . . . . . . . . . . . . . . . . . . . . . . 16
3.3 Example landscapes . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
3.3.1 One oscillating peak . . . . . . . . . . . . . . . . . . . . . . 17
3.3.2 Two oscillating peaks . . . . . . . . . . . . . . . . . . . . . . 21
3.3.3 Two oscillating peaks with ﬂat average landscape . . . . . . 24

4 Aperiodic or stochastic ﬁtness landscapes

5 Finite Populations

31
5.1 Numerical results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
5.1.1 Loss of the master sequence . . . . . . . . . . . . . . . . . . 33
5.1.2 Persistency . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
5.2 A ﬁnite population on a simple periodic ﬁtness landscape . . . . . . 36
5.2.1 The probability to skip one period . . . . . . . . . . . . . . 40

6 Conclusions

A High-frequency expansion of X(t) for a landscape with two alter-

nating master sequences

3

5

27

46

48

2

1 Introduction

Eigen’s quasispecies model [7] has been the basis of a vivid branch of molecular
evolution theory ever since it has been put forward almost 30 years ago [31, 14,
12, 13, 8, 29, 17, 25, 15, 9, 28, 10, 20, 2, 36, 19, 3].
Its two main statements,
the formation of a quasispecies made up of several molecular species with well
deﬁned concentrations, and the existence of an error threshold above which all
information is lost because of accumulating erroneous mutations, have since then
been observed in a large number of experimental as well as theoretical studies (see,
e.g., [6] for the formation of a quasispecies in the RNA of the Qβ phage, [1] for the
observation of an error threshold in a system of self-replicating computer programs,
and, generally, the reviews [9, 10, 3] and the references therein). Recently, a
new aspect of the quasispecies model has been brought into consideration that
was almost completely absent in previous works, namely the aspect of a dynamic
ﬁtness landscape [36, 19]. With the notion “dynamic ﬁtness landscape”, we mean
all situations in which the replication and/or decay rates of the molecules change
over time. In the present work, we are only interested in situations where these
changes occur as an external inﬂuence for the evolving system, and where there is
no feedback from the system to the dynamics of the ﬁtness landscape. Dynamic
ﬁtness landscapes of that kind are important, since almost any biological system is
subject to external changes in the form of, e.g., daytime/nighttime, seasons, long-
term climatic changes, geographic changes due to tectonic movements, to name
just a few.

The main problem one encounters when dealing with dynamic landscapes is the
diﬃculty to ﬁnd a correct generalization of the quasispecies concept. In the origi-
nal work of Eigen, the quasispecies is the equilibrium distribution of the diﬀerent
molecular species. It is reached if the system is left undisturbed for a suﬃciently
long time. Since in a dynamic landscape, the system is being disturbed by the
landscape itself, the concept of a quasispecies is meaningless in the general case.
However, there are special cases in which a meaningful quasispecies can be de-
ﬁned. If, for example, the landscape changes on a much slower time scale than
what the system needs to reach the equilibrium, then the system is virtually in
equilibrium all the time, and the concentrations at time t are determined from the
landscape present at that time. Generally, certain symmetries in the dynamics of
the landscape can allow for the deﬁnition of a quasispecies. One example we treat
in this paper in detail is the case of time-periodic landscapes, which oﬀer a natural
quasispecies deﬁnition.

An early study of dynamic landscapes has been done by Jones [12, 13]. How-
ever, he has considered only cases in which all replication rates change by a com-
mon factor. Therefore, his approach excludes, among other cases, in particular

3

all situations in which the order of the molecules’ replication rates changes over
time, i.e., in which e.g. one of the faster replicating molecules becomes one of the
slower replicating molecules and vice versa. The more recent work on dynamic
ﬁtness landscapes allow for such changes. Wilke et al. [35, 36] have developed
a framework that allows to deﬁne and to calculate numerically a quasispecies in
time-periodic landscapes. Independent of them, Nilsson and Snoad [19] have stud-
ied the particular example of a stochastically jumping peak in an otherwise ﬂat
landscape. This work has been generalized and reﬁned by Ronnewinkel et al. [22],
who could also deﬁne a meaningful quasispecies for a deterministic version of the
jumping peak landscape and related landscapes. Finally, in the related ﬁeld of
genetic algorithms, there exist also some theoretical studies of dynamic ﬁtness
landscapes. Let us mention two of them. First of all, there is the work of Schmitt
et al. [27, 26]. These authors derive results for ﬁnite populations (note that most
results for the quasispecies model are only valid in the inﬁnite population limit) in
a relatively broad class of dynamic landscapes. However, they can only treat land-
scapes in which the ﬁtnesses get scaled, so that the same restriction applies here
that applied to Jone’s work. The order of the ﬁtnesses must never change. Second
of all, Rowe [24, 23] has studied genetic algorithms with time-periodic landscapes.
However, his approach has the caveat that it is tightly connected to the discrete
time used in genetic algorithms, and that the dimension of the transition matrices
grows in proportion to the period length T of the oscillation. This makes it hard
to derive analytical results, and in addition to that, it renders landscapes with
large T inaccessible to numerical calculations.

The remainder of this article is structured as follows. We begin our discussion in
Section 2 with a brief summary of the general aspects of dynamic ﬁtness landscapes
in the quasispecies equation. In Section 3, we will develop the main subject of this
work, a general theory of time-periodic ﬁtness landscapes. The theoretical part
thereof is presented in Section 3.1, in which we demonstrate how a time-dependent
quasispecies can be deﬁned by means of the monodromy matrix, and how this
monodromy matrix can be expanded in terms of the oscillation period T .
In
Section 3.2, we present an alternative approximation formula for the monodromy
matrix that is more suitable for numerical calculations, and in Section 3.3, we
compare, for several example landscapes, the results obtained from that formula
with the general theory developed in Section 3.1. The restriction of a time-periodic
ﬁtness landscape is weakened in Section 4, where we discuss the implications of our
ﬁndings for other, non-periodic ﬁtness landscapes. In that section, we are going to
see that the qualitative results of the study of Nilsson and Snoad [19] are a direct
consequence of the general theory for dynamic ﬁtness landscapes. Since our work
is based on Eigen’s deterministic approach with diﬀerential equations, all results

4

presented up to the end of Section 4 are only valid for inﬁnite population sizes.
In order to address this shortcoming, in Section 5 we give a brief introduction
into the problems involved when dealing with ﬁnite populations. In Section 5.1,
some simulation results are shown, demonstrating the relationship between the
results from the inﬁnite population limit and the actual ﬁnite population dynamics.
Finally, an approximative analytical description of a ﬁnite population evolving on
a simple periodic landscape is developed in Section 5.2. We close this paper with
some conclusions in Section 6.

2 Time-dependent replication rates

The quasispecies model describes the evolution of self-replicating macromolecules.
It assumes that there exists only a ﬁnite number of diﬀerent molecular species,
and that each species i is present in high abundance, such that it suﬃces to record
only the concentrations of the species, xi(t). The reaction dynamics is thought
of taking place in a well-stirred reactor, with some constant out-ﬂux of molecules
E(t), such that the total concentration of molecules
i xi(t) remains constant for
all t. The self-replication process may fail, leading to erroneously copied oﬀspring.
This is being described by a mutation matrix Qij that gives the probability with
which an oﬀspring molecule of type i is generated from a parent j. Often, it is
assumed that the molecules are RNA sequences, consisting of a string of letters
A, G, C, U, or even simpler, the molecules are represented as bitstrings. In that
case, one regularly makes the additional assumption that the replication process
copies the string letter by letter, and that therefore the probability of a wrongly
copied letter is independent of the letter’s position in the string, and also of the
type of the letter. In connection with that, it is useful to introduce the error rate
per letter, R. In case we conceive the molecules of bitstrings of ﬁxed length l, the
mutation matrix Qij then takes on the form

P

Qij = (1 − R)l

R
1 − R

d(i,j)

,

(cid:18)
where d(i, j) represents the Hamming distance between two sequences of type i
and j. All our examples in later sections are based on that assumption. Our
general results, however, do not depend on this assumption.

(cid:19)

In vector notation, i.e. x = (x1, x2, . . . ), the basic quasispecies equation reads

Here, 1 stands for the identity matrix, and W(t) is given by

˙x(t) = [W(t) − E(t)1]x(t) .

W(t) = Q(t)A(t) − D(t) ,

5

(1)

(2)

(3)

where the diagonal matrix A(t) contains the replication coeﬃcients, the diagonal
matrix D(t) contains the decay constants, and the matrix Q(t) is the above intro-
duced mutation matrix. In the most general case, all these three matrices can be
time dependent. The average excess production can be expressed in terms of the
matrices A(t) and D(t) as

E(t) = et · [A(t)x(t) − D(t)x(t)] ,

where et is a vector containing only entries of 1s, i.e. et = (1, . . . , 1).

Because of the x(t) dependence of E(t), Eq. (2) is nonlinear. However, as in

the case of constant W [31, 14], the introduction of new variables of the form

y(t) = exp

E(τ ) dτ

x(t)

t

0

(cid:18)Z

(cid:19)

removes this nonlinearity. The resulting equation reads

and the concentrations can be obtained from y(t) via

˙y(t) = W(t)y(t) ,

x(t) =

y(t)
et · y(t)

.

Note that if all decay constants are equal at all times, i.e. D(t) = diag(D(t), . . . , D(t)),
with a single scalar function D(t), then an extended transformation

y(t) = exp

[E(τ ) + D(t)] dτ

x(t)

(cid:19)

t

0
(cid:18)Z

leads to the even simpler equation

˙y(t) = Q(t)A(t)y(t) .

The concentration vector x(t) can again be obtained from Eq. (7).

The linearized quasispecies model, Eq. (6), has been studied in great detail
for constant W [9, 10]. Since the quasispecies is the equilibrium distribution of
the molecular concentrations, the main question in that context has been the
prediction of the system’s behavior for t → ∞. As a linear diﬀerential equation,
Eq. (6) displays exponential growth [exponential damping does not occur because
of the sign in front of the integral in Eq. (5)]. That growth may in principle
be accompanied by exponentially ampliﬁed/damped oscillations. Of course, an
equilibrium can only be deﬁned if there are either no oscillations at all, or all

6

(4)

(5)

(6)

(7)

(8)

(9)

oscillations die out for t → ∞. Fortunately, this is typically the case. First of
all, for symmetric Q, the whole spectrum of W is real [25], because W can be
transformed into a symmetric matrix by means of a similarity transformation,

W = QA − D → A1/2WA−1/2 = A1/2QA1/2 − D .

(10)

For non-symmetric Q, we can apply the Frobenius-Perron theorem if the decay
rates satisfy

(D)ii < (QA)ii

for all i.

(11)

The Frobenius-Perron theorem guarantees a real largest eigenvalue. Consequently,
we have at most exponentially damped oscillations as long as we obey (11). In
addition to that, the Frobenius-Perron theorem states that the eigenvector corre-
sponding to this largest eigenvalue has only strictly positive entries, and hence,
that this eigenvector can be interpreted as a vector of chemical concentrations if
normalized appropriately.

Now consider the case of a full time dependency. In that case, we can map the
quasispecies model onto a linear system with a symmetric matrix ˜W(t) if Q(t) is
symmetric for all t. This can be seen by introducing

(12)

(13)

(14)

Diﬀerentiation yields

z(t) = A1/2(t)y(t) .

˙z(t) = ˜W(t)z(t)

with

˜W(t) = A1/2(t)Q(t)A1/2(t) − D(t) +

A1/2(t)

A−1/2(t) .

d
dt

(cid:20)

(cid:21)

Nevertheless, we cannot write down a solution for Eq. (13) from the knowledge of
the eigensystem of ˜W(t) if ˜W(t) has an arbitrary time dependency. Therefore,
the symmetric quasispecies equation (13) does not help us in solving Eq. (6). As a
consequence, we have to focus on limiting cases for which general statements can
be made. The two most important limiting cases are very fast changes in W(t) on
the one hand, and very slow changes in W(t) on the other hand. We begin with
the case of very slow changes. For the rest of this work, we will assume that W(t)
has a real spectrum for all t. From Eq. (13), we know that this covers at least all
cases for which Q(t) is symmetric. To be on the safe side, we also assume that
(11) is satisﬁed for all t. In that way, the Perron eigenvector of W(t) can always
be interpreted as a vector of chemical concentrations.

7

For every time t0, we can deﬁne a relaxation time

τR(t0) =

1
λ0(t0) − λ1(t0)

,

(15)

where λ0(t)0 and λ1(t0) are the largest and the second largest eigenvalue of W(t0),
respectively. The time τR(t0) gives an estimate on how long a linear system with
matrix W(t0) needs to settle into equilibrium. Therefore, if the changes in W(t)
happen on a timescale much longer than τR(t), the system is virtually in equilib-
rium at any given point in time. Hence, for large enough t, the quasispecies will
be given by the Perron eigenvector of W(t). Strictly speaking, this is only true if
there is always some overlap between the largest eigenvector of W(t) and the one
of W(t + dt), but in all but some very pathological cases we can assume this to be
the case.

The situation of fast changes in W(t) is somewhat more diﬃcult, because, as
we are going to see later on, we have to deﬁne a suitable average over W(t) in
order to make a general statement. Therefore, we postpone that situation for a
moment. A detailed discussion of fast changes will be given for the particular case
of periodic ﬁtness landscapes in the next section, and later on, we will discuss fast
changing landscapes in general.

3 Periodic ﬁtness landscapes

3.1 Diﬀerential equation formalism

In this section, we are going to study periodic time dependencies in W(t), for
which we can demonstrate several general statements.

If the changes in W(t) are periodic, i.e., if there exists a T such that

W(t + T ) = W(t)

for all t,

(16)

then Eq. (6) turns into a system of linear diﬀerential equations with periodic
coeﬃcients. Several theorems are known for such systems [37]. Most notably, if
Y(t, t0) is the fundamental matrix, such that every solution to Eq. (6) can be
written in the form

then we can deﬁne a so-called monodromy matrix X(t0),

y(t) = Y(t, t0)y(t0) ,

X(t0) = Y(t0 + T, t0) ,

8

(17)

(18)

which simpliﬁes Eq. (17) to

y(t) = Y(t0 + φ, t0)Xm(t0)y(t0)

= Xm(t0 + φ)Y(t0 + φ, t0)y(t0) ,

for the decomposition t = mT + φ + t0 with the phase φ < T . In particular, we
have

y(φ + mT ) = Xm(φ)y(φ) ,

so that for every phase φ, we have a well deﬁned asymptotic solution, given by
the eigenvector to the largest eigenvalue of X(φ). In other words, periodic ﬁtness
landscapes allow the deﬁnition of a quasispecies, much in the same way as static
ﬁtness landscapes do. However, this quasispecies is time-dependent, and the time-
dependency is periodic with period T .

3.1.1 Neumann series for X

We can derive a formal expansion in T for the monodromy matrix. This formal
expansion is similar in spirit to the Neumann series which gives a formal solution to
an integral equation, and it is based on the Picard-Lindel¨of iteration for diﬀerential
equations. As the ﬁrst step, we have to rewrite Eq. (6) in the form of an integral
equation, i.e.

y(t0 + τ ) = y(t0) +

W(t0 + τ1)y(t0 + τ1)dτ1 .

(21)

Our goal is to solve this equation for y(t0 + τ ) by iteration. Our initial solution is

which we insert into Eq. (21). As a result, we obtain the 1st order approximation

y0(t0 + τ ) = y(t0) ,

y1(t0 + τ ) = y(t0) +

W(t0 + τ1)y(t0)dτ1 .

(19)

(20)

(22)

(23)

Further iteration yields

y2(t0 + τ ) = y(t0) +

W(t0 + τ1)y(t0)dτ1

τ

0

Z

+

W(t0 + τ1)

W(t0 + τ2)y(t0)dτ1dτ2 ,

(24)

τ

0

Z

τ1

0
Z

τ

0
Z

τ

0
Z

9

and so on. Now we deﬁne

W0(t0, τ ) = 1 ,
1
τ

W1(t0, τ ) =

τ

0
Z

W(t0 + τ1)dτ1 ,

and, in general

Wk(t0, τ ) =

W(t0 + τ1)

W(t0 + τ2) · · ·

W(t0 + τk)dτ1dτ2 · · · dτk ,

1
τ k

τ

0
Z

τ1

0
Z

τk−1

0
Z

and obtain the formal solution

y(t0 + τ ) =

τ kWk(t0, τ )y(t0) .

∞

Xk=0

For suitably small τ , the inﬁnite sum on the right-hand side is guaranteed to
converge. When we compare this equation for τ = T to the deﬁnition of the
monodromy matrix Eq. (18), we ﬁnd that [introducing Wk(t0) := Wk(t0, T )]

Xk=0
In particular, since W1(t0) is identical to the time-average over W(t), regardless
of t0, we have the high-frequency expansion

∞

X(t0) =

T kWk(t0) .

X(t0) = 1 + T W + O(T 2) ,

W =

W(t) dt .

1
T

T

0
Z

(25)

(26)

(27)

(28)

(29)

(30)

(31)

with

Equation (30) reveals that for very high frequency oscillations, the system behaves
as being in a static landscape. That static landscape is given by the dynamic
landscape’s average over one oscillation period.

The radius of convergence of the expansion Eq. (29) can be estimated as follows.

Since all entries of W(t) are positive, we have for the tensor

W iν1W ν1ν2 · · · W νk−1j(t0) :=

Wiν1(t0 + τ1)

Wν1ν2(t0 + τ2)

1
T k

T

0
Z

τ1

τk−1

0
Z

Wνk−1j(t0 + τk)dτ1dτ2 · · · dτk

(32)

· · ·

0

Z

10

the estimate

W iν1W ν1ν2 · · · W νk−1j(t0) ≤

Wiν1(t0 + τ )dτ

Wν1ν2(t0 + τ )dτ

1
T k

T

0

Z

Wνk−1j(t0 + τ )dτ ,

(33)

T

0
Z
· · ·

T

0
Z

ij

(cid:17)

i
X

from which follows

(cid:16)
The matrix norm induced by the sum norm

(cid:1)

(cid:0)

Wk(t0)

ij ≤

Wk

.

k(y1, y2, . . . , yn)k1 =

|yi|

is the column-sum norm

With that norm, we can with the aid of Eq. (34) estimate

Hence, the expansion Eq. (29) converges certainly for those T that satisfy

Since all entries in W are positive, we have further

W

1 = max
(cid:13)
(cid:13)

j (

i
X

(cid:13)
(cid:13)

|W ij|

.

)

Wk(t0)

(cid:13)
(cid:13)

≤

W

k
1 .
(cid:13)
(cid:13)

(cid:13)
(cid:13)

1 ≤
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)

T

W

(cid:13)
(cid:13)

Wk

1
(cid:13)
(cid:13)
(cid:13)
1 < 1 .
(cid:13)
(cid:13)

|AjQij − Djδij|

)

W

1 = max
(cid:13)
(cid:13)

= max

j (

j

(cid:13)
(cid:13)

i
X
Aj − Dj

,

(cid:8)

(cid:9)

where the bar in Aj and Dj indicates that these quantities represent averages over
one oscillation period. The second equality holds because of (11) and because of
i Qij = 1. Without loss of generality, we assume that the maximum is given by

A0 − D0. Then, Eq. (38) is satisﬁed for
P

(34)

(35)

(36)

(37)

(38)

(39)

(40)

T <

1
A0 − D0

.

11

It is interesting to compare this expression to the relaxation time of the time-
averaged ﬁtness landscape, τ R. To 0ths order, the principal eigenvalue of W is
given by W 00. The second largest eigenvalue is to the same order given by the
second largest diagonal element of W, which we assume to be W 11 without loss of
generality. Hence, the relaxation time is approximately given by
1
W 00 − W 11

1
A0 − D0

1
W 00

τ R =

(41)

≥

>

,

which is generally larger than the radius of convergence of Eq. (29). In particular, if
the largest and the second largest eigenvalue of W lie close together, the relaxation
time may be much larger than the largest oscillation period for which the expansion
is feasible. This restricts the usability of Eq. (29) to considerably high frequency
oscillations in the landscape. The interesting regime in which the changes in the
landscape happen on a time scale comparable to the relaxation time of the system
can unfortunately not be studied from Eq. (29).

3.1.2 Exact solutions for R = 0 and R = 0.5

The two extreme cases R = 0 (no replication errors) and R = 0.5 (random oﬀspring
sequences) allow for an exact analytic treatment. The second case is identical to
the situation in static landscapes, and therefore we will mention it only brieﬂy.
At the point of stochastic replication R = 0.5, the population dynamics becomes
independent of the details of the landscape. As a consequence, temporal changes
in the landscape must become less important as R approaches R = 0.5. However,
this is not very surprising, since in most cases, an error rate close to 0.5 implies
that the population has already passed the error threshold, which in turn implies
that it does not feel the changes in the landscape any more.

The case of R = 0, on the other hand, is more complex than the corresponding
case in a static landscape. Since the matrix Q becomes the identity matrix for
R = 0, Eq. (6) reduces to

˙y(t) = [A(t) − D(t)]y(t) .

The matrices A(t) and D(t) are diagonal by deﬁnition, and hence, a solution to
Eq. (42) is given by

y(t) = exp

[A(t′) − D(t′)]dt′

y(t0) .

(cid:18)Z
When we compare this expression to Eqs. (17) and (18), we ﬁnd

(cid:19)

Y(t, t0) = exp

[A(t′) − D(t′)]dt′

,

(cid:19)

t

t0

t

t0

(cid:18)Z

12

(42)

(43)

(44)

and, in particular,

X(φ) = exp

[A(t′) − D(t′)]dt′

.

(45)

φ+T

φ
(cid:18)Z

(cid:19)

The integral in the second expression is taken over a complete oscillation period,
and hence, it is independent of φ. Thus, we ﬁnd for arbitrary φ

X(φ) = exp(W)

for R = 0.

(46)

With a vanishing error rate, the monodromy matrix becomes the exponential of the
time-average over W(t). Since the exponential function only aﬀects the eigenval-
ues, but not the eigenvectors, of a matrix, the quasispecies is given by the principal
eigenvector of W, irrespective of the length of the oscillation period T . In other
words, under the absence of mutations will the sequence i with the highest average
value of Ai(t) − Di(t) take over the whole population after a suitable amount of
time, provided it existed already in the population at the beginning of the process.
By continuity, this property must extend to very small but positive error rates R.
So, similar to the case of R = 0.5, the temporal changes in the landscape loose
their importance when R approaches 0.

There is, however, a caveat to the above argument. In case the largest eigen-
value of W is degenerate, temporal changes in the landscape may continue to be
of importance for R = 0. A degeneracy of the largest eigenvalue of W is possible,
because the Frobenius-Perron theorem applies only to positive error rates. For
degenerate quasispecies, the initial condition y(t0) determines the composition of
the asymptotic population. In this context, let us consider the general solution for
periodic ﬁtness landscapes, Eq. (19). We have

with

y(t) = Xm(φ)y(t0 + φ)

y(t0 + φ) = Y(t0 + φ, t0)y(t0).

(47)

(48)

So even if X becomes independent of φ for R = 0, this need not be the case for
y(t0 + φ), because of Eq. (48). If the largest eigenvalue of W is degenerate, these
variations in y(t0+φ) will remain visible for arbitrarily large times t. Hence, we will
see oscillations among the diﬀerent quasispecies which correspond to the largest
eigenvalue. Clearly, this eﬀect is the more pronounced the larger the oscillation
period T .

13

3.1.3 Schematic phase diagrams

The results of the previous two subsections allow us to identify the general prop-
erties of the quasispecies model with a periodic ﬁtness landscape at the borders of
the parameter space. We have to consider only the two parameters error rate R
and oscillation period T , since all other parameters (replication rates, decay rates,
details of the matrix Q) do not inﬂuence the above results. In Fig. 1, we have
summarized our ﬁndings. Along the abscissa runs the oscillation period. For very
fast oscillations, the evolving population sees only the time-averaged landscape.
For very slow oscillations, on the other hand, the population is able to settle into
an equilibrium much faster than the changes in the landscape occur. Hence, the
population sees a quasistatic landscape. Along the ordinate, we have displayed
the error rate. For the error rate, we have disregarded the region above R = 0.5,
in which anti-correlations between parent and oﬀspring sequences are present. For
R = 0.5, all sequences have random oﬀspring, and hence, all sequences replicate
equally well. Therefore, for this error rate, the landscape becomes eﬀectively ﬂat.
On the other side, for R = 0, we have again the time-averaged landscape. However,
for large T , the fact that we see the average landscape does not mean that the
concentration variables are asymptotically constant. Degeneracies in the largest
eigenvalue may cause a remaining time dependency due to oscillations between
superposed quasispecies. The exact form of these oscillations is dependent on the
initial condition y(0). For small T , the oscillations disappear, because the ratio
of newly created sequences during one oscillation period and remaining sequences
from the previous oscillation period decays with T [Eq. (30)].

From the above observations, we can derive generic phase diagrams for periodic
ﬁtness landscapes. There are two main possibilities. The ﬁtness landscape may
average to a landscape that has a distinct quasispecies, or it may average to a ﬂat
landscape. These two cases are illustrated in Fig. 2. Note that the diagrams are
meant to illustrate the qualitative form and position of the diﬀerent phases. In
their exact appearance, they may diﬀer substantially from the exact phase diagram
of a particular landscape.

If a landscape averages to one with a distinct quasispecies, then for every
oscillation period T and every phase of the oscillation φ, we have a unique error
threshold R∗(T, φ). For small T , the error threshold converges towards the one of
the average ﬁtness landscape, R∗
av, irrespective of the phase φ. For larger T , the
hi = maxφ R∗(T, φ).
error threshold oscillates between R∗
In the limit of an inﬁnitely large oscillation period, R∗
max,
which is the largest error threshold of all the (static) landscapes W(φ). Similarly,
R∗
min is accordingly deﬁned as the
smallest error threshold of all landscapes W(φ). For a ﬁxed oscillation period T ,

lo = minφ R∗(T, φ) and R∗

min in that limit, where R∗

hi converges towards R∗

lo converges towards R∗

14

0.5

R

e
t
a
r

r
o
r
r
e

e
g
a
r
e
v
a
-
e
m

i
t

0

small T

disorder

c
i
t
a
t
s
-
i
s
a
u
q

large T

time-average
(degeneracies cause ﬂuctuations for large T )

oscillation period T

Figure 1: The appearance of a periodic ﬁtness landscape at the border regions of
the parameter space.

lo < R < R∗

hi , we have necessarily R > R∗(T, φ) for
and a ﬁxed error rate R with R∗
some phases φ, and R < R∗(T, φ) for the rest of the oscillation period. As a result,
a quasispecies will form whenever R > R∗(T, φ), but it will disappear again as soon
as R < R∗(T, φ). This phenomenon has for the ﬁrst time been observed in [36],
and there, the region of the parameter space in which it can be found has been
called the temporarily ordered phase. In this phase, whether we observe order or
disorder depends on the particular moment in time at which we study the system.
In correspondence to that, we will call a phase “ordered” only if order can be seen
for the whole oscillation period, and we will call a phase “disordered” if during
the whole oscillation period no order can be seen. The relationship between the
ordered phase, the disordered phase, and the temporarily ordered phase for the
ﬁrst type of landscapes is displayed in Fig. 2a). Compare also the phase diagram
of the oscillating Swetina-Schuster landscape in Fig. 3.

In a landscape that averages to a ﬂat one, on the other hand, the disordered
phase must extend over the whole range of R for suﬃciently small T . Order can
be observed only above a certain Tmin. However, slightly above that Tmin, no order
will be found for error rates R other than intermediate ones, since for R = 0 the
landscape averages again to a ﬂat one. Hence, what we will observe is an ordered
or temporarily ordered phase restricted from above and from below. Instead of a

15

¯W= non-ﬂat landscape

¯W= ﬂat landscape

disordered

disordered

temp. ordered

ordered

temp. ordered

ordered

0.5

R

e
t
a
r

r
o
r
r
e

0

b)

0.5

R

e
t
a
r

r
o
r
r
e

0

a)

small T

large T

small T

large T

oscillation period T

oscillation period T

If W(t)
Figure 2: The two possible phase diagrams of a periodic landscape.
averages to a non-ﬂat landscape, there will typically be a lower error threshold,
below which we always ﬁnd order, and a higher error threshold, above which the
If W(t) averages to a ﬂat landscape,
system is always in a disordered state.
however, the disordered phase extends to the whole range of R for suﬃciently
small T .

unique error threshold R∗(T, φ), we have for every phase φ a lower threshold that
marks the transition from disorder to order, and a higher threshold that marks
the transition back to disorder. For longer oscillation periods, the ﬂuctuations in
the degenerate quasispecies become important for R = 0, and this fact allows the
ordered regime to extend to much smaller values of R. Hence, the lower disordered
phase will fade out for T → ∞. A typical phase diagram for this type of landscapes
is displayed in Fig. 2b).

3.2 Discrete approximation

The diﬀerential equation formalism we have used so far allows for an elegant dis-
cussion of the system’s general properties. However, if we want to obtain numerical
solutions, this formalism does not help us very much, because we do not have a
general expression for the fundamental matrix Y(t, t0) from Eq. (17), nor for the
monodromy matrix X(t0) from Eq. (18). Therefore, for our numerical treatment
we will move over to the discretized quasispecies equation,

y(t + ∆t) = [∆tW(t) + 1]y(t) .

In the case of constant W, the quasispecies obtained from that equation is identical
to the one of Eq. (6), and it is also identical to the one of the equation

(49)

(50)

y(t + 1) = Wy(t) .

16

Equation (50) has been studied by Demetrius et al. [4], and has been employed by
Leuth¨ausser [15] for her mapping of the quasispecies model onto the Ising model.
In the general time-dependent case, however, the additional factor ∆t and the
identity matrix 1 of Eq. (49) are important, and cannot be left out. The analogue
of the fundamental matrix for Eq. (49) reads

Y(t0 + k∆t, t0) = T

[∆tW(t0 + ν∆t) + 1]

,

(51)

)

k−1

(

ν=0
Y

where T {·} indicates that the matrix product has to be evaluated with the proper
time ordering [35]. Similarly, the analogue of the monodromy matrix becomes

X(t0) = Y(t0 + T, t0)

n−1

(

ν=0
Y

= T

[∆tW(t0 + ν∆t) + 1]

,

(52)

)

where we have assumed that T is an integral multiple of ∆t, and have set n = T /∆t.
The inﬂuence of the size of ∆t on the quality of the approximation has been
investigated in [35]. A more in-depths discussion of the relationship between the
continuous and the discrete quasispecies model can also be found in [3].

3.3 Example landscapes

For the rest of this section, we are going to have a look at several example land-
scapes, in order to illustrate the implications of our general theory. In all cases
considered, we represent the molecules as bitstrings of ﬁxed length l. Moreover,
we assume that a single bit is copied erroneously with rate R, irrespective of the
bit’s type and of its position in the string.

3.3.1 One oscillating peak

In the previous works on the quasispecies model with periodic ﬁtness landscapes [35,
36], most emphasis has been laid on landscapes with a single oscillating sharp peak.
As a generalization of the work of Swetina and Schuster [29], the master sequence
has been given a replication rate A0(t) ≫ A, where A is the replication rate of all
other sequences. The replication rate A0(t) has been expressed as

A0(t) = A0,stat exp[ǫf (t)] ,

(53)

with a T -periodic function f (t). The parameter ǫ allows a smooth crossover from
a static landscape to one with considerable dynamics, and the exponential assures

17

that A0(t) is always positive. In order not to duplicate work, we will not repeat
the results of [35, 36] here. In short, it has been found that the behavior at the
border regions of the parameter space is indeed as it is depicted in Fig. 1, and
that a phase diagram of the form of Fig. 2a) correctly describes the relationship
of order and disorder in an oscillating Swetina-Schuster landscape. Here, our aim
is to show that the phase borders in such a phase diagram can, for an oscillating
Swetina-Schuster landscape, be calculated approximately.

For static landscapes with a single peak, the assumption of a vanishing mu-
tational backﬂow into the master sequence allows to derive an approximate ex-
pression for the error threshold [16, 9, 10]. A similar formula can be developed
to calculate the error threshold as a function of time in a landscape with a single
oscillating peak. But before we turn towards the dynamic landscape, we are going
to rederive the expression for the master’s concentration x0 in a static landscape,
based on the neglect of mutational backﬂow. The expression we are going to ﬁnd
is slightly more general than the one that was previously given, and it will be of
use for the periodic ﬁtness landscape as well.

The 0th component of the quasispecies equation (2) becomes, after neglecting

the mutational backﬂow,

˙x0(t) = W00x0(t) − E(t)x0(t) .

The average excess production E(t) can be expressed in terms of x(t) and W as

E(t) =

Wijxj(t) .

i,j
X
With that expression, the solution of Eq. (54) requires the knowledge of the sta-
tionary mutant concentrations xj, which are usually unknown. To circumvent this
problem, we make the somewhat extreme assumption that all mutant concentra-
tions are equal. Although this assumption, which is equivalent to the assumption
of equal excess productions Ei in the usual calculation without mutational back-
ﬂow, will generally not be true, it works ﬁne for Swetina-Schuster type landscapes.
With this additional assumption, Eq. (55) becomes

E(t) =

i "

X

j>0
X

Wij

1 − x0(t)
N − 1

+ Wi0x0(t)

,

#

where N is the number of diﬀerent sequences in the system. When we insert this
into Eq. (54) and solve for the steady state, we ﬁnd

(54)

(55)

(56)

(57)

x0 =

W00 − 1
N −1
i Wi0 − 1

j>0 Wij

i

.

j>0 Wij

N −1

P

P
i

P

P

P

18

The expressions involving sums over matrix elements in Eq. (57) can be identiﬁed
with the excess production of the master,

and with the average excess production without the master,

E0 =

Wi0

i
X

E−0 =

1
N − 1

Wij ,

i
X

j>0
X

x0 =

W00 − E−0
E0 − E−0

.

if W has the standard form QA − D. Therefore, Eq. (57) corresponds to the often
quoted result

However, Eq. (57) is more general in that it can be used even if W is not given as
QA − D.

Our idea here is to insert the monodromy matrix into Eq. (57) in order to
obtain an approximation for x0 in the case of periodic landscapes. But why can
we expect this to work? After all, Eq. (57) has been derived from an equation
with continuous time, Eq. (54), whereas the monodromy matrix advances the
system in discrete time steps, as can bee seen in Eq. (20). The important point
is here that we are only interested in the asymptotic state, which is given by the
normalized Perron vector of the monodromy matrix, whether we use discrete or
continuous time. Therefore, we are free to calculate the asymptotic state in a
periodic landscape for a given phase φ from

even if this equation does not have a direct physical meaning for ﬁnite times. The
asymptotic molecular concentrations are then given by the limit t → ∞ of

From diﬀerentiating Eq. (62) and inserting Eq. (61), we obtain

˙x(t) = X(φ)x(t) − x(t)

e · [X(φ)x(t)]

.

When we neglect the backﬂow onto the master sequence, the 0ths component of
that equation becomes identical to Eqs. (54) and (55), but with the matrix X(φ)

(cid:0)

(cid:1)

˙y(t) = X(φ)y(t) ,

x(t) =

y(t)
e · y(t)

.

19

(58)

(59)

(60)

(61)

(62)

(63)

0.4

0.3

0.2

0.1

R

e
t
a
r

r
o
r
r
e

0.0

0.1

disordered phase

R∗

hi(T )

R∗

lo(T )

ordered phase

temporarily ordered phase

R∗

max

R∗
av

R∗

min

1

10

100

oscillation period T

Figure 3: The phase diagram of an oscillating Swetina-Schuster landscape [A0(t) =
e2.4 exp(2 sin ωt)], numerically calculated from Eq. (57).

instead of W. This shows that we may indeed use Eq. (57) as an approximation for
the asymptotic concentration of x0. Of course, since we have neglected mutational
backﬂow, this approximation works only for landscapes in which a single sequence
has a signiﬁcant advantage over all others. But this restriction does similarly apply
to the static case. Numerically, we have found that Eq. (57) works well for a single
oscillating peak, and that it breaks down in other cases as expected.

av, R∗

lo and R∗

With the aid of Eq. (57), we are now in the position that we can calculate the
phase diagram of the oscillating Swetina-Schuster landscape. When we insert the
monodromy matrix X(φ) into Eq. (57), we are able to obtain (numerically) the
error rate at which x0 vanishes, R∗(T, φ). From that expression, we can calculate
R∗
hi. The results of the corresponding, numerically extensive calculations
are shown in Fig. 3, together with R∗
min, which have also been
determined from Eq. (57).
We ﬁnd that both R∗

av for T → 0, as predicted by
our general theory. For T → ∞, R∗
max, but
a slight discrepancy between the two values remains.
It has its origin in the
vast complexity of the numerical calculations involved for large T . We can only
approximate the monodromy matrix by means of Eq. (52), and we need ever more
factors ∆tW(t0 + ν∆t) + 1 for large T . The discrepancy between R∗
min,
on the other hand, has a diﬀerent origin. The main cause here is the fact that the
relaxation into equilibrium is generally slower for smaller error rates. Therefore,
R∗

hi grows quickly to the level of R∗

lo needs a much larger T to reach R∗

min than it is the case with R∗

hi approach R∗

max, and R∗

lo and R∗

lo and R∗

hi and R∗

max.

20

3.3.2 Two oscillating peaks

A single oscillating peak provides some initial insights into dynamic ﬁtness land-
scapes. It is more interesting, however, to study situations in which several se-
quences obtain the highest replication rate in diﬀerent phases of the oscillation
period. The simplest such case is a landscape in which two sequences become
in turn the master sequence. Here, we will assume that the two are located at
opposite corners of the boolean hypercube, i.e., that they are given by a certain
sequence and its inverse. In that way, it is possible to group sequences into error
classes according to their Hamming distance to one of the two possible master
sequences. As an example, we are going to study a landscape with the replication
coeﬃcients

A0(t) = A0,stat exp(ǫ sin ωt) ,
Al(t) = A0,stat exp(−ǫ sin ωt) ,
Ai(t) = 1

for 0 < i < l.

(64a)
(64b)
(64c)

The subscripts in the replication coeﬃcients stand for the Hamming distance to
the sequence 000 · · · 0.

For single peak landscapes, it is instructive to characterize the state of the

system at time t by the value of the order parameter

ms(t) =

xi(t)[l − 2i] ,

(65)

where xi(t) is the cumulative concentration of all sequences of Hamming distance
i to the master sequence [15, 30].
If the master sequence makes up the whole
population, we have ms(t) = 1. A completely disordered population, on the other
hand, yields ms(t) = 0. In principle, ms(t) can also be used for a landscape with
two alternating master sequences if they are each other’s inverse.
In that case,
the Hamming distance has to be measured with respect to one of the two master
sequences. If the population consists only of sequences of the type of the other
master sequence, we have ms(t) = −1. However, there is a small problem with
degenerate landscapes, in which the two peaks have the same replication rate.
In such landscapes, the sequence distribution becomes symmetric with respect to
the two peaks, i.e., x0 = xl, x1 = xl−1, and so on. Then, ms(t) becomes zero
because of this symmetry, although the population may be in an ordered state.
To distinguish between the case of true disorder and the case of an ordered, but

l

1
l

i=0
X

21

(66)

(67)

(68)

(70)

symmetrical population, we introduce the additional order parameters

and

⌊(l−1)/2⌋

m+

s (t) =

1
l

xi(t)[l − 2i] ,

i=0
X

l

m−

s (t) =

1
l

Xi=l−⌊(l−1)/2⌋

xi(t)[l − 2i] .

Here, ⌊x⌋ stands for the largest integer smaller than or equal to x.
s (t) is always positive, m−

The quantity m+

s (t) is always negative, and further-

more, we have

ms(t) = m+

s (t) + m−

s (t) .

If the population is uniformly distributed over the whole sequence space, we have

m+

s (t) = −m−

s (t) =

(l − 2i) .

(69)

1
l2l

⌊(l−1)/2⌋

l
i
(cid:19)
i=0 (cid:18)
X

This expression goes to 0 for l → ∞. If, on the other hand, only the two peaks
are populated, each with half of the total population, we ﬁnd

m+

s (t) = −m−

s (t) =

1
2

.

In the case that either m+
about the respective other peak.

s (t) or m−

s (t) equal to zero, the population is centered

In the following, when it is important to distinguish between true disordered
populations and symmetric populations, we will use m+
s (t). When the
situation is non-ambiguous, we will use ms(t) alone, in order to improve the clarity
of our plots.

s (t) and m−

s (t), m−

In Fig. 4, we have displayed m+

s (t) and ms(t) for the quasispecies in a
ﬁtness landscape of the type deﬁned in Eq. (64). For a large oscillation period,
T = 100, the quasispecies is at every point in time clearly centered around a
single peak. The switch from one peak to the other happens very fast. When
the landscape oscillates with a higher frequency, the transition time uses up a
larger proportion of the total oscillation period. This makes the transition from
one peak to the other appear softer in the plots for smaller oscillation periods.
For extremely small oscillations, the system sees the average ﬁtness landscape,

22

r
e
t
e
m
a
r
a
p

r
e
d
r
o

r
e
t
e
m
a
r
a
p

r
e
d
r
o

1.0

1.0

T = 100

T = 1

0.6

0.6

0.2

0.2

-0.2

-0.2

-0.6

-0.6

-1.0

-1.0

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

0.6

0.8

1.0

phase (cid:30)

phase (cid:30)

1.0

1.0

T = 0:1

T = 0:01

0.6

0.6

0.2

0.2

-0.2

-0.2

-0.6

-0.6

m

((cid:30))

+

s

m

((cid:30))

s

m

((cid:30))

(cid:0)

s

-1.0

-1.0

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

0.6

0.8

1.0

phase (cid:30)

phase (cid:30)

s (t), m−

Figure 4: Order parameters ms(t), m+
s (t) as a function of the oscillation
phase φ = (t mod T )/T in a landscape with two alternating peaks. The upper
dashed line represents m+
s (t), and the solid
line represents ms(t). The sequence length is l = 10, and we have used R = 0.05
and n = T /∆t = 100 in all four examples. The parameters of the ﬁtness landscape
are A0,stat = e2.4, ǫ = 2.

s (t), the lower dashed line represents m−

which is a degenerate landscape with two peaks of equal height. As noted above,
the quasispecies becomes symmetric in such a landscape. In the lower right plot
of Fig. 4, for T = 0.01, we can identify this limiting behavior. Both m+
s (t) and
m−
s (t) are nearly constant over the whole oscillation period with an absolute value
close to 0.5. The deviation from 0.5 stems from the ﬁnite value of the error rate,
R = 0.05 in this example. We observe further that ms(t) lies very close to zero,
thus wrongly indicating a disordered state. Note that the absolute value of m±
s (t)
for a uniformly spread population lies for the parameters of this example at 0.12
according to Eq. (69).

The observations from the landscape with two oscillating peaks have to be
interpreted in the light of the results of Schuster and Swetina on static landscapes

r
e
t
e
m
a
r
a
p

r
e
d
r
o

r
e
t
e
m
a
r
a
p

r
e
d
r
o

23

with two peaks [28]. They have found that if the peaks are far away in Hamming
distance (which is the case here), a quasispecies is generally unable to occupy both
peaks at the same time, unless they are of exactly the same height and with the
same neighborhood.1 For two peaks with diﬀerent heights, the quasispecies will
for small R generally form around the higher peak. For larger R, however, the
quasispecies moves to the lower peak if this one has a higher mutational backﬂow
from mutants, which is the case, for example, if the second peak is broader than the
ﬁrst one. The transition from the higher peak to the lower one with increasing R
is very sharp, and can be considered as a phase transition. In a dynamic landscape
with relatively slow changes, the quasispecies therefore switches the peak quickly
when the higher peak becomes the lower one and vice versa.

The exact time at which the switch occurs depends of course on the error rate.
The lower the error rate, the longer does the population remain centered around
the previously higher peak until it actually moves on to the new higher peak.
Therefore, if we look at the system at a ﬁxed phase, and change the error rate,
the quasispecies does, for certain phases φ, undergo a transition similar to the one
found in [28] for static landscapes. This is illustrated in Fig. 5, where we display
the order parameter ms as a function of the error rate R. At the beginning of the
oscillation period, for φ = 0, the quasispecies is, for all error rates R below the
error threshold, dominated by the peak corresponding to ms = −1. This must be
the case, as the replication coeﬃcients of the two peaks intersect at φ = 0, so up
to this point the quasispecies has not had a chance to build up around the other
peak. For phases shortly after φ = 0, the quasispecies gains weight around the
other peak, starting from the error threshold on downwards. For φ = 0.15, for
example, we observe a relatively sharp transition from the peak corresponding to
ms = −1 to the peak corresponding to ms + 1 at R ≈ 0.05. The transition then
moves quickly towards R = 0, until the peak corresponding to ms = 1 dominates
the quasispecies for all R. For φ = 0.5, the replication coeﬃcients intersect again,
and the quasispecies is exactly the inverse of the one for φ = 0.

3.3.3 Two oscillating peaks with ﬂat average landscape

In Sec. 3.1.3, we have predicted a special phase diagram for landscapes whose
time average is completely ﬂat. A particular realization of such a landscape is
obtained if all replication coeﬃcients are either set to a constant a or to a function
a + bi sin(ωt + δi), with arbitrary δi and bi < a. In comparison to the previous
subsection, here we choose again a landscape in which a sequence and its inverse
1This is only true for inﬁnite populations, however. For ﬁnite populations, one of the two

peaks will always get lost eventually due to sampling ﬂuctuations.

24

(cid:30) = 0:00

(cid:30) = 0:10

(cid:30) = 0:15

(cid:30) = 0:50

s

m
r
e
t
e
m
a
r
a
p

r
e
d
r
o

1.0

0.6

0.2

-0.2

-0.6

-1.0

0.0

0.1

0.2

0.3

0.4

0.5

error rate R

Figure 5: The order parameter ms as a function of the error rate R for various
oscillation phases φ = (t mod T )/T . The ﬁtness landscape is identical to the one
of Fig. 4, and the oscillation period is T = 100. Note that for φ = 0.10, the error
threshold seems to have moved towards lower R, which is not the case. What we
have instead is a symmetric population, as explained on page 22. A plot of m+
s or
m−
s reveals this immediately. However, we have not displayed such a plot here in
order to enhance the clarity of this ﬁgure.

are alternating, while all others remain constant. We set the replication rates to

A0(t) = 1 − b sin ωt ,
Al(t) = 1 + b sin ωt ,
Ai(t) = 1 for 0 < i < l.

(71a)
(71b)
(71c)

The order parameter of the quasispecies in such a landscape is displayed in
Fig. 6 as a function of R for various oscillation periods T . What is immediately
apparent from the plot is the existence of a lower error threshold in addition to
the normal upper error threshold. This is in perfect agreement with the phase
diagram in Fig. 2b), which predicts such a lower error threshold for landscapes
with a ﬂat average. With decreasing length T of the oscillation period, the two
thresholds approximate each other, reducing the region in which order can be seen.
For T = 20, the order parameter does not even reach the value ms = 0.1 anymore,
and for T = 10, it would be indistinguishable from the R-axis in this plot.

To be able to study the region of small T in more detail, we have done an
expansion of X in terms of T as given in Eq. (29), up to second order. The

25

1.0

0.8

0.6

0.4

0.2

s

m
r
e
t
e
m
a
r
a
p

r
e
d
r
o

T = 90

T = 40

T = 30

T = 20

0.0

10−6

10−5

10−4

10−3

error rate R

10−2

10−1

Figure 6: The order parameter ms as a function of R in a landscape with two
alternating peaks that average to a ﬂat landscape [Eq. (71)]. In this case, ms = 0
corresponds always to true disorder, and therefore, we have refrained from display-
ing m+
s in addition to ms, in order to enhance the clarity of the plot. The
other parameters were l = 10, b = 9/10, φ = 0 and n = T /∆t = 100.

s and m−

corresponding integrals can be taken relatively easy for this particular landscape.
The details of the calculation are given in Appendix A. By comparing the results
from this expansion with the results from the discrete approximation Eq. (52), this
serves also as a test of the validity of Eq. (29).

In Fig. 7, we have displayed the order parameter ms obtained from the expan-
sion of X in terms of T and from the discrete approximation of X as a function of
the phase φ for four diﬀerent oscillation periods T .

First of all, the order parameter clearly ﬂattens out for T → 0 (note that the
ordinates are scaled diﬀerently in the four plots, which may obsfucate this fact on
ﬁrst glance). However, since the T 2 term in the expansion gives a time-dependent
contribution for arbitrarily small T [Eq. (128)], we cannot deﬁne the transition
point to complete disorder with rigor. But this is nothing new. The same applies
to the standard error threshold in a static landscape. Analytically, the order
parameter never reaches zero for a ﬁnite string length l and for R < 0.5. This is
related to the fact that the error transition is a surface transition with complete
wetting [30]. Since the surface is ﬁnite, the order parameter indicating this surface
transition remains always ﬁnite. Hence, the exact transition point can only be
determined from the corresponding transition in the bulk. For our purposes here,
it suﬃces to note that for a ﬁnite oscillation period, here about T = 10, the order

26

s

s

m

r
e
t
e
m
a
r
a
p

r
e
d
r
o

m

r
e
t
e
m
a
r
a
p

r
e
d
r
o

T = 0:01

T = 0:1

3 (cid:2) 10

3 (cid:2) 10

(cid:0)6

(cid:0)5

2 (cid:2) 10

2 (cid:2) 10

(cid:0)6

(cid:0)5

1 (cid:2) 10

1 (cid:2) 10

(cid:0)6

(cid:0)5

0 (cid:2) 10

0 (cid:2) 10

(cid:0)6

(cid:0)5

(cid:0)1 (cid:2) 10

(cid:0)1 (cid:2) 10

(cid:0)6

(cid:0)5

(cid:0)2 (cid:2) 10

(cid:0)2 (cid:2) 10

(cid:0)6

(cid:0)5

(cid:0)3 (cid:2) 10

(cid:0)3 (cid:2) 10

(cid:0)6

(cid:0)5

0.0 0.2 0.4 0.6 0.8 1.0

0.0 0.2 0.4 0.6 0.8 1.0

phase (cid:30)

phase (cid:30)

3 (cid:2) 10

4 (cid:2) 10

(cid:0)4

(cid:0)3

T = 1

T = 10

2 (cid:2) 10

1 (cid:2) 10

(cid:0)1 (cid:2) 10

(cid:0)2 (cid:2) 10

(cid:0)4

(cid:0)4

(cid:0)4

(cid:0)4

0 (cid:2) 10

0 (cid:2) 10

(cid:0)4

(cid:0)3

2 (cid:2) 10

(cid:0)3

(cid:0)2 (cid:2) 10

(cid:0)3

(cid:0)3 (cid:2) 10

(cid:0)4 (cid:2) 10

(cid:0)4

(cid:0)3

0.0 0.2 0.4 0.6 0.8 1.0

0.0 0.2 0.4 0.6 0.8 1.0

phase (cid:30)

phase (cid:30)

s

s

m

r
e
t
e
m
a
r
a
p

r
e
d
r
o

m

r
e
t
e
m
a
r
a
p

r
e
d
r
o

Figure 7: The order parameter ms for a landscape in which a sequence and its
inverse become alternatingly the master sequence. The error rate is R = 0.01. The
solid lines give stem from the discrete approximation, the dotted lines stem from
the expansion in terms of T , Eq. (29), evaluated up to second order. Clearly, the
expansion Eq. (29) is only of use for relatively short oscillation periods.

parameter is almost zero for all replication rates R. This demonstrates that the
phase diagram Fig. 2b) is indeed correct.

Second of all, we observe that the expansion in terms of T breaks down for T
larger than ≈ 1. This agrees well with our estimate for the radius of convergence
of the expansion given in Eq. (40), which guarantees convergence only for T < 1
in the present case.

4 Aperiodic or stochastic ﬁtness landscapes

Periodic ﬁtness landscapes can be treated rather elegantly. We have been able
to deﬁne a meaningful quasispecies, as well as we have been able to determine
the general dynamics in the border regions of the parameter space. It would be
desirable to obtain similar results for arbitrary dynamic landscapes. After all,
an aperiodic or stochastic change is much more realistic than an exactly periodic
change. However, the deﬁnition of a time-dependent quasispecies is tightly con-
nected to periodic ﬁtness landscapes. For arbitrary changes, it does not make sense

27

(72)

(73)

(74)

to speak of an asymptotic state. Regardless of that, we can derive some results for
the border regions of the parameter space. In Section 3.1, we derived the formal
solution to Eq. (6),

To ﬁrst order in τ , the formal solution reads

y(t0 + τ ) =

τ kWk(t0, τ )y(t0) .

∞

Xk=0

y(t0 + τ ) = y(t0) + τW1(t0, τ )y(t0) .

Obviously, the composition of the sequence distribution changes very little over
the interval [t0, t0 + τ ] if the condition

τ

W1(t0, τ )

1 ≪ 1
(cid:13)
(cid:13)

is satisﬁed. This observation allows us to establish a general result for quickly
changing ﬁtness landscapes. If the landscape changes in such a way that for every
interval of length τ beginning at time t0, the average

(cid:13)
(cid:13)

τ

1
τ

W1(t0, τ ) =

W(t0 + τ1)dτ1

(75)

0
Z
is approximately the same for every t0, and the condition kW1(t0, τ )k ≪ 1/τ
holds, then the system develops a quasispecies given by the normalized principal
eigenvector of the average matrix W1(t0, τ ). With “approximately the same” we
mean that for two times t0 and t1, the components of the averaged matrices satisfy

W1(t0, τ )

−

W1(t1, τ )

< ǫ

for all i, j, t0, t1,

(76)

(cid:12)
(cid:16)
(cid:12)
(cid:12)
(cid:12)

ij

(cid:17)

(cid:16)

(cid:17)

ij(cid:12)
(cid:12)
(cid:12)
(cid:12)

with a suitably small ǫ. In other words, if the ﬁtness landscape changes very fast,
but in stationary way, then the evolving population sees only the time-averaged
ﬁtness landscape.

For the special case of R = 0, we can, as in Eq. (43), write the solution for the

quasispecies equation as

y(t) = exp

[A(t′) − D(t′)]dt′

y(t0) .

(77)

t

t0

(cid:18)Z

(cid:19)

Unlike in the case of a periodic landscape, however, this does not tell us the general
behavior at R = 0, apart from the fact that for fast changes, the system sees the
average ﬁtness landscape. But we knew that already from Eq. (73). If we have the

28

disorder

0.5

R

e
t
a
r

r
o
r
r
e

e
g
a
r
e
v
a
-
e
m

i
t

0

fast

quality of changes

slow

Figure 8: The appearance of a stochastic ﬁtness landscape at the border regions
of the parameter space.

situation of a stochastic landscape with long time correlations, on the other hand,
it is hard to make general statements. The reason for this is that from long time
correlations, we cannot generally deduce that the system must be in a quasistatic
state. It may be the case if, for example, the landscape changes only rarely, but
then drastically. On the other hand, one can easily come up with landscapes
that are in a constant ﬂux, and still display long time correlations. Hence, there
exists no direct equivalent to the large oscillation period case of periodic ﬁtness
landscapes for general stochastic landscapes. Nevertheless, we can draw a diagram
similar to Fig. 1, where on the x-axis we use the qualitative description “slow”
and “fast” changes. Under “fast”, we subsume everything that satisﬁes the above
stated conditions under which the system sees the average ﬁtness landscape, and
under “slow” we subsume everything else, assuming that a parameter exists that
allows a smooth transition from the “fast” regime to the “slow” regime. Then,
the analogue to Fig. 1 is Fig. 8. Although this ﬁgure contains considerably less
information than Fig. 1, the implications for actual landscapes are more or less the
same. Most real landscapes will have a regime that can be associated with slow
changes, and hence, we will typically observe phase diagrams of the type of either
Fig. 2a) or b).

29

As an example, consider the work of Nilsson and Snoad [19], and its subsequent
extension by Ronnewinkel et al. [22]. Nilsson and Snoad have studied a landscape
in which a single peak performs a random walk through the sequence space. The
peak jumps to a random neighboring position of hamming distance 1 whenever a
time interval of length τ has elapsed. Ronnewinkel et al. have studied a very similar
ﬁtness landscape, but they have mainly been interested in deterministic movements
of the peak that allow for the formal deﬁnition of a quasispecies, similarly to the
situation of periodic ﬁtness landscapes in Section 3.1. Ronnewinkel et al. could
verify the results of Nilsson and Snoad on more fundamental theoretical grounds.
The parameter τ in the jumping peak landscape determines whether the changes
happen on a short or on a long time scale. If τ is very large, the landscape is static
most of the time, and the population has enough time to settle into equilibrium
before the peak jumps to a new position. If τ is very small, on the other hand, the
peak has moved away long before the population has had the time to form a stable
quasispecies. Nilsson and Snoad have found that, in addition to the common error
threshold at which the mutation rate becomes too high to allow for quasispecies
formation, another error threshold can be found at which the mutation rate be-
comes too low to allow the population to adapt to the changing landscape. The
region of the lower disordered phase grows with decreasing τ , until the lower and
the higher error threshold coincide and no selection can take place anymore. This
is clear from an intuitive point of view. The faster the peak moves, the higher must
the error rate be in order to allow the population to track the peak. Once the error
rate needed to track the peak exceeds the highest error rate for which selection is
possible, everything breaks down and the population does not feel any selective
pressure any more. Nilsson and Snoad concluded therefore that “dynamic land-
scapes have strong constraints on evolvability”. However, this conclusion is not so
straightforward if we reconsider their landscape from the viewpoint of the general
theory developed here. As we have pointed out several times so far, the authorita-
tive ﬁtness landscape in the region of fast changes is the time averaged landscape.
Thus, selection does not break down because of a fast changing landscape itself,
but it breaks down due to the neutrality of the time-averaged landscape in this
particular case. If there was a region in the sequence space in which the peak would
assume a higher level than in the remaining sequence space, or if the peak’s move-
ments were conﬁned to a small portion of the sequence space, we would clearly see
selection in these particular regions. This suggests the viewpoint that the time-
averaged landscape gives the “regions of robustness” in the landscape, the regions
in which even fast changes in the landscape do not destroy the quasispecies.

30

5 Finite Populations

In the previous sections, we have been studying inﬁnite populations exclusively.
However, the huge genotype spaces that are generated even by moderately long
sequences (there are already 1030 diﬀerent sequences of length 100, for example),
will be almost empty for any realistic ﬁnite population. When most of the possible
sequences are not present in the population, the concentration variables become
useless, and the outcome of the diﬀerential equation formalism may be completely
diﬀerent from the actual behavior of the population. For static ﬁtness landscapes,
the eﬀects of a ﬁnite population size are reasonably well understood. If the ﬁtness
landscape is very simple (a single peak landscape), the population is reasonably
well described by ﬁnite stochastic sampling from the inﬁnite population concen-
trations. Moreover, the error threshold generally moves towards smaller R with
decreasing population size [20]. In a multi peak landscape, the ﬁnite population
localizes relatively fast around one peak, and there it remains, with a dynamics
similar to that in a single peak landscape. In the rare case that a mutant discovers
a higher peak, the population moves over to that peak, where it remains again.
The main diﬀerence between a ﬁnite and an inﬁnite population on a landscape
with many peaks is given by the fact that the inﬁnite population will always build
a quasispecies around the highest peak, whereas the ﬁnite population may get
stuck on a suboptimal peak. Above the error threshold, a ﬁnite population starts
to drift through the genotype space, irrespective of the landscape.

A ﬁnite population on a dynamic landscape will of course show a similar behav-
ior, but in addition to that, other eﬀects come into play that are tightly connected
to the dynamics of the landscape. The most important diﬀerence between static
and dynamic landscapes is the possible existence of a temporarily ordered phase
in the latter case, and there we should expect the major new dynamic eﬀects.

In the inﬁnite population limit, the temporarily ordered phase generates an
alternating pattern of a fully developed quasispecies and a homogeneous sequence
distribution. What changes if a ﬁnite population evolves in that phase? At those
points in time when a quasispecies is developed, the ﬁnite population’s sequence
concentrations are given by stochastic sampling from the inﬁnite population result,
similarly to static landscapes. As soon as the quasispecies breaks down (and this
may happen earlier than the inﬁnite population equations predict, because of the
error threshold’s shift to a lower error rate for a ﬁnite population), the population
starts to disperse over the landscape. Because of that, the population may loose
track of the peak it was centered about previously. Therefore, when it enters again
a time interval in which order should be seen, the population may not be able to
form a quasispecies, thus eﬀectively staying in the disordered regime, or it may
form a quasispecies at a diﬀerent peak. In that way, the temporarily ordered phase

31

can open up a third possibility for a population to leave a local peak, in addition
to the escape via neutral paths or to entropy-barrier crossing, which are present
exclusively in static landscapes [32].

5.1 Numerical results

The numerical results presented below have been obtained from a genetic algo-
rithm with N sequences per generation. We have used the following mutation and
selection scheme in order to stay as closely as possible with the Eigen model:

1. To all sequences i in time step t, we assign a probability to be selected and

mutated,

pi,mutate(t) =

Ai(t)
i[1/∆t + Ai(t) − Di(t)]ni(t)

,

and a probability to be selected but not mutated,

P

pi,select(t) =

1/∆t − Di(t)
i[1/∆t + Ai(t) − Di(t)]ni(t)

.

Here, ∆t is the length of one time step, and ni(t) is the number of sequences
of type i.

P

2. From the set of probabilities {pi,mutate(t), pi,select(t)}, we choose N sequences
at random. These N sequences are going to form the population in time
step t + ∆t. A sequence j that is determined to be mutated is subsequently
converted into sequence i according to the mutation matrix Qij.

Note that we assume generally

so that pi,select(t) deﬁned in Eq. (79) is always positive.

For an inﬁnite population, the above described genetic algorithm evolves ac-

cording to the equation

Di(t) <

for all i, t,

1
∆t

x(t + ∆t) = G

x(t), t

,

where x(t) is the vector of concentrations at time t, and G(x, t) is the operator
that maps a population at time t onto a population at time t + 1,

(cid:0)

(cid:1)

(78)

(79)

(80)

(81)

(82)

G(x, t) =

[∆tW(t) + 1]x

et ·

[∆tA(t) − ∆tD(t) + 1]x

.

(cid:1)

(cid:0)

32

(83)

(84)

(85)

Since we can replace the non-linear operator G(x, t) with a linear operator ˜G(y, t),

˜G(y, t) = [∆tW(t) + 1]y ,

in Eq. (81), if we recover the true concentrations x via

x(t) =

y(t)
et · y(t)

,

we have a direct correspondence between the genetic algorithm for an inﬁnite
population and the discrete quasispecies model, as can be seen by comparing
Eq. (83) with Eq. (49). This implies in particular that for periodic landscapes,
the expression for the monodromy matrix X(t0), Eq. (52), is exact. There is no
approximation involved.

For a ﬁnite population, it is still the operator G(x, t) that determines the
dynamics. However, the deterministic description Eq. (81) has to be replaced by
If Gi(x, t)
a probabilistic one, namely Wright-Fisher or multinomial sampling.
denotes the iths component of the concentration vector in the next time step,
the probability that a population x1 = (m1, m2, . . . )/N,
i mi = N, produces a
population x2 = (n1, n2, . . . )/N,

i ni = N, in the next time step, is given by

P
P (x1 → x2, t) = N!

P

Gi(x1, t)ni
ni!

.

i
Y

A proof that the stochastic process described by Eq. (85) does indeed converge
to the deterministic process Eq. (81) in the limit N → ∞ has been given by van
Nimwegen et al. [33].

5.1.1 Loss of the master sequence

Our ﬁrst example of a ﬁnite population in a dynamic ﬁtness landscape demon-
strates what happens if in the temporarily ordered phase the master sequence is
lost due to sampling ﬂuctuations. In Fig. 9, we have presented a run of a ﬁnite
population consisting of N = 1000 sequences of length l = 15, initialized ran-
domly at t = 0, in an oscillating Swetina-Schuster landscape. For a comparison,
we have also plotted the theoretical result for an inﬁnite population. The inﬁnite
population is always in an ordered state, the order parameter ms never takes on
values smaller than 0.2. Nevertheless, the ﬁnite population is likely to loose the
master sequence whenever the order parameter of the inﬁnite population reaches
its minimum, since the error threshold is shifted towards lower error rates for ﬁ-
nite populations. In our example run, the master sequence was lost at the end of

33

inﬁnite population

ﬁnite population

s

m
r
e
t
e
m
a
r
a
p

r
e
d
r
o

1.0

0.8

0.6

0.4

0.2

0.0

0

200

400

600

800

1000

time t

Figure 9: A single run of a population of N = 1000 sequences in the oscillating
Swetina-Schuster landscape. The sequences had length l = 15. The other param-
eters were A0(t) = e2.4 exp(2 sin ωt), Ai = 1 for i > 0, R = 0.06, T = 100, ∆t = 1.
The dashed line indicates the theoretical result for an inﬁnite population.

the ﬁrst oscillation period, but it was rediscovered shortly afterwards, so that the
population could follow the inﬁnite population dynamics for most of the second
oscillation period as well. Right after a loss of the master sequence, the probability
to rediscover the master has its highest value, because the population is still cen-
tered around the master sequence. Once the population has had the time to drift
away from the position of the master sequence, the probability of a rediscovery
drops rapidly. This is what happened at the end of the second oscillation period.
The population completely lost track of the master sequence, and it took the pop-
ulation more than 4 oscillation periods to rediscover it. This is the main diﬀerence
between a ﬁnite and an inﬁnite population in the temporarily ordered phase. For
an inﬁnite population, the interval of disorder has the same well deﬁned length
in each oscillation period, whereas for a ﬁnite population, once the population
has entered the disordered state, it may take a long time until an ordered state
is reached again. In fact, for the case of a single peak in a very large sequence
space and a small population, the peak may eﬀectively be lost forever once it has
disappeared from the population.

This can be seen as a dynamic version of Muller’s ratchet [18]. A trait whose
advantageous inﬂuence on the overall ﬁtness of an individual is reduced at some
point (it is not necessary that the trait becomes completely neutral or even dele-
terious) may get lost from the population due to sampling ﬂuctuations. If then at

34

1.0

0.6

0.2

-0.2

-0.6

s

m
r
e
t
e
m
a
r
a
p

r
e
d
r
o

-1.0

0

500

1000
time t

1500

2000

Figure 10: A single run of a population of N = 1000 sequences in a landscape as
given in Eq. (64). All parameters were identical to the setup of Fig. 9. The dashed
line again indicates the theoretical result for an inﬁnite population.

a later stage this trait becomes again very advantageous, it is not available to the
population anymore, until it is rediscovered independently. However, a rediscovery
may be very unlikely.

5.1.2 Persistency

A second aspect of a ﬁnite population in a dynamic landscape is persistency. This
means, a ﬁnite population may not be able to follow the changes in the landscape,
although the inﬁnite population limit predicts this. An example of that eﬀect is
given in Fig. 10. There, we have two alternating peaks at opposite corners of the
boolean hypercube, as given by Eq. (64). Note that the peaks’ minimal height is
relatively small, but still larger than the rest of the landscape’s height. In fact, all
parameters are identical to the situation shown in Fig. 9, so that this ﬁgure can
be seen as an example of the dynamics around one of the peaks in Fig. 10. The
inﬁnite population result in Fig. 10 predicts that the population should move on
to the other peak whenever this peak becomes the higher one. However, the ﬁnite
population does not follow this scheme. It stays localized around one of the two
peaks for a long time. A ﬁnite population does not, unlike an inﬁnite population,
occupy all possible points in the sequence space at the same time. Therefore, if a
peak grows at a distance too far from the currently occupied peak, no sequence in
the population is there to exploit the advantage, and hence the new opportunity

35

goes undetected. Only if the population looses track of the ﬁrst peak, which is
possible because of the temporarily ordered phase, it can discover the second peak
during its random drift. In the run of Fig. 10, this has happened two times. The
ﬁrst time, the population had discovered the alternative peak at the end of the
drift, and the second time, it had again rediscovered this same peak.

The situation of a ﬁnite population in a dynamic landscape with several growing
and shrinking peaks can be compared to its situation in a rugged, but static
landscape. In the latter case, once the population has reached a local optimum it
remains there, unless a rare mutation opens the possibility to move to a new, higher
peak. The same applies to the dynamic situation. But in addition, the ﬂuctuations
and oscillations of the ﬁtness values destabilize the population on local optima, and
allow it to continue its search for other local optima. If the landscape’s dynamics is
such that the population, by following the local optima, moves into regions of low
average ﬁtness (observed e.g. in [35]), the landscape might be called “deceptive”,
and in the opposite case, it might be called “well-behaved”.

5.2 A ﬁnite population on a simple periodic ﬁtness land-

scape

In the above examples, we saw that the time it takes until the master is rediscov-
ered, once it has been lost in the temporarily ordered phase, may be much larger
than the period length of the landscape. Hence, for several periods, the popula-
tion does not follow the inﬁnite population results, but remains in a disordered
state. It would be desirable to have an analytic description of this behavior, and,
in particular, to have an estimate of the probability with which a complete period
is skipped, i.e., with which the master sequence is missed for a whole oscillation
period. Unfortunately, the continuous time dependency of the master sequence’s
replication rate employed in Sec. 5.1,

A0(t) = A0,stat exp(ǫ sin ωt) ,

(86)

renders the corresponding calculations very complicated. Therefore, in order not
to get too distracted by technical details in the calculation, we study in this section
a simpliﬁed ﬁtness landscape that displays a temporarily ordered phase similar to
Fig. 9, but that is much easier to handle analytically. For a ﬁtness landscape such
as Eq. (86), we can—for suﬃciently high error rate R—divide the oscillation period
into two intervals. During the ﬁrst interval I1, of length T1, the population is in
an ordered state provided that the master sequence is present in the population,
and during the second interval I2, of length T2, the population is in a disordered
state, even if the master sequence is present. The beginning of the ﬁrst interval

36

need not coincide with the beginning of the oscillation period, but after a suitable
shift of the time origin, this is always the case. Note that for a ﬁnite population,
the second interval is larger than predicted by the inﬁnite population limit, and it
may exist even if the inﬁnite population limit predicts a length T2 = 0, because the
error threshold is shifted towards smaller error rates for ﬁnite populations [20, 34].
This can be seen clearly in Fig. 9, where the inﬁnite population limit predicts
T2 = 0, but the master is lost anyway because of sampling ﬂuctuations.

Our approximation here is to keep the ﬁtness landscape constant during the
intervals I1 and I2. During the interval I1, we let the master replicate with rate
A0 ≫ 1, while all other sequences replicate with A = 1. During the second interval
on the other hand, the ﬁtness landscape becomes ﬂat. Then, all sequences replicate
with A = 1. We continue to study the discrete process and set ∆t = 1, so that
T1 and T2 give the number of time steps spent in each interval. In summary, the
replication rate A0(t) satisﬁes

A0(t) =

a:
1:

(cid:26)

φ ≤ T1
else .

In order to get expressions that can be easily treated even for a ﬁnite popula-
tion, we use the error tail approximation introduced in [20]. In that approximation,
the state of the system is fully described by the concentration of the master se-
quence. All other sequences are assumed to be uniformly spread over the remaining
genotype space. This approximation underestimates the mutational backﬂow into
the master sequence, and hence it underestimates the concentration of the mas-
ter itself, but this small deviation can be accepted in the light of the enormous
simpliﬁcations in the calculations.

Before we have a look at the ﬁnite population dynamics, let us quickly study
the inﬁnite population limit. We express the state of the system at time t by
a vector x(t) = (x0(t), x1(t))t, where x0(t) gives the concentration of the master
sequence, and x1(t) = 1 −x0(t) gives the total concentration of all other sequences.
The generation operator G(x, t) maps the population at time t into the population
at time t + 1, i.e.,

Here, G(x, t) is given by

Q is the 2 × 2 matrix

x(t + 1) = G

x(t), t

.

G(x, t) =

(cid:0)

(cid:1)
[QA(t) + 1]x
A0(t)x0 + x1 + 1

.

(1 − R)l

1−(1−R)l
2l−1

Q =

1 − (1 − R)l 1 − 1−(1−R)l

2l−1 !

 

,

37

(87)

(88)

(89)

(90)

and A(t) = diag(A0(t), 1). The linear operator ˜G(t) = QA(t) + 1 describes the
evolution of the variables y(t),

y(t + 1) = ˜G(t)y(t) ,

which map into the original variables via

x(t) =

y(t)
et · y(t)

,

et = (1, 1) .

Hence, the eigensystem of ˜G fully describes the time evolution of x(t). For the
eigenvalues of ˜G, we ﬁnd

λ0,1 =

1
2

˜G00 + ˜G11 ±
(cid:20)

q

( ˜G00 − ˜G11)2 + 4 ˜G01 ˜G10

,

(93)

(cid:21)

where the plus sign corresponds to the index 0, and the minus sign corresponds to
the index 1. The eigenvectors are

φ0,1 =

1
1 + ξ±

(1, ξ±)t ,

±

˜G00 − ˜G11
2 ˜G01

with ξ± =

1
˜G01 r
Of course, the eigenvalues and the eigenvectors are diﬀerent for the two intervals
I1 and I2. For the ﬁrst interval, inserting the explicit expressions of ˜Gij into
Eqs. (93)–(95) does not lead to a substantial simpliﬁcation of the expressions, so
we leave this out here. For the second interval, however, we ﬁnd for the eigenvalues

( ˜G00 − ˜G11)2 + ˜G01 ˜G10 .

(95)

1
4

and for the eigenvectors

λ(2)
0 = 2 ,

λ(2)
1 = 2 −

1 − (1 − R)l
1 − 2−l

,

φ(2)
φ(2)

0 = (2−l, 1 − 2−l)t ,
1 = (1, −1)t .

38

The superscript (2) indicates that these results are only valid for the interval I2.
From the above expressions, we get a simple formula for the evolution of the
master’s concentration during the interval I2. Let the interval start at time t, and

(91)

(92)

(94)

(96a)

(96b)

(97a)

(97b)

(98)

(99)

(100)

let the concentration of the master at that moment in time be x0(t). Then we ﬁnd
n time steps later

x0(t + n) =

α0φ(2)

0 + α1

α0(et · φ(2)

0 ) + α1

0

1 /λ(2)
λ(2)
1 /λ(2)
λ(2)

0

(cid:16)

n

φ(2)
1

,

(et · φ(2)
1 )

n

(cid:17)

(cid:17)

(cid:16)
where α0 and α1 have to be chosen such that

x0(t) = α0φ(2)

0 + α1φ(2)

1

.

After solving Eq. (99) for α0 and α1 and inserting everything back into Eq. (98),
we end up with

x0(t + n) = 2−l +

x0(t) − 2−l

1 −

(cid:2)

(cid:18)

(cid:3)

1 − (1 − R)l
2(1 − 2−l)

n

.

(cid:19)

This formula is suﬃciently close to the solution obtained from diagonalization
of the full 2l × 2l matrix Q in a ﬂat landscape, and can be considered a good
approximation to the actual inﬁnite population dynamics [21].
In principle, a
similar formula can be derived for the interval I1, but again, the expressions become
very complicated, and do not lead to any new insight, so we leave this out here.

Equation (100) demonstrates that a macroscopic proportion of the master se-
quence that may have built up during the interval I1 quickly decays to the expected
concentration in a ﬂat landscape, 2−l.

Now we address ﬁnite populations. We assume the duration of the interval I1
is long enough so that the quasispecies can form. The asymptotic concentration
of the master sequence can then be calculated from a birth and death process as
done in [20]. The alternative diﬀusion approximation used in [34] is of no use here
because it allows only replication rates A0 of the form A0 = 1 + ǫ with a small
In [20], the probabilities pk to ﬁnd the master sequence k times in the
ǫ [11].
asymptotic distribution are given by

pk =

with ˜pk =

˜pk−1 and ˜p0 = 1.

(101)

˜pk
N
i=0 ˜pi

The probabilities µ+

i and µ−
P

i read here

and

µ+

i =

N − i
N

(cid:18)h

˜G(1)

00 − 1

+ ˜G(1)
01

N − i
N

(cid:19)

µ−

i =

˜G(1)
10

+

˜G(1)

11 − 1

i
N

(cid:18)

i
N

N − i
N

.

(cid:19)

i

(102)

(103)

µ+
k−1
−
µ
k

i
N

i

h

39

The expected asymptotic concentration becomes

x0(∞) =

k pk .

(104)

1
N

N

Xk=0

Unfortunately, there exists no analytic expression for x0(∞). However, its value
is easily computed numerically. By our above assumption on the length of the
interval I1, we can suppose that at the end of I1, the concentration of x0 is given
by x0(∞). During the interval I2, the concentration of the master will then decay.

5.2.1 The probability to skip one period

If at the end of the interval I2 the master sequence has been lost because of
sampling ﬂuctuations, and if in addition to that the correlations in the population
have decayed so far that we can assume maximum entropy, what is the probability
that the master sequence is rediscovered in the following interval I1? The process
of rediscovering the master consists of two steps. The master sequence has to
be generated through mutation, and then it has to be ﬁxated in the population,
i.e., it must not get lost again due to sampling ﬂuctuations. First of all, we
calculate the probability Pmiss that the master is not generated in one time step.
This corresponds to the probability that the multinomial sampling of the operator
G(1)(x) maps a population x = (0, 1)t into itself. Hence, we have

Pmiss = N!

1

G(1)

i (x)ni
ni!

i=0
Y
Q11 + 1
2

=

(cid:18)

N

=

1 −

1 − (1 − R)l
2l+1 − 2

(cid:19)

(cid:20)

N

.

(cid:21)

(105)

G(1)

i (x) stands for the iths component of the outcome of G(1)(x).

The probability that the master sequence gets ﬁxated needs more work. Let
π(x, t) denote the probability that the master sequence has reached its asymptotic
concentration at time t, given that it had the initial concentration x at time t = 0.
The asymptotic concentration is given by x0(∞) deﬁned in Eq. (104). Then, the
probability π(x, t) satisﬁes to second order the backward Fokker-Planck equation

∂π(x, t)
∂t

= hdx0i

∂π(x, t)
∂x

+

h(dx0)2i
2

∂2π(x, t)
∂x2

.

(106)

The moments hdx0i and h(dx0)2i can be calculated similarly to the calculations

40

in [33], and we ﬁnd

The solution to Eq. (106) for t → ∞ is then obtained as in [33], and we ﬁnd

hdx0i =

λ(1)
0 − 1

x0 =: γx0 ,

1
2

h(dx0)2i =

(cid:18)
x0(1 − x0)
N

(cid:19)
.

1
N

π∞ := π

, ∞

=

(cid:18)
≈ 1 − e−2γ .

(cid:19)

2N γ+1

1 −

1 − 1
N
1 − (1 − x0(∞))2N γ+1

(cid:0)

(cid:1)

(107)

(108)

(109)

(110)

As the initial concentration of x0, we have used 1/N, since it is—for the param-
eter settings we are interested in—extremely unlikely that more than one master
sequence is generated in one time step. The approximation in the second line is
only valid for large population sizes. It generally underestimates the true value of
π∞.

Note that the expression for π∞ given in Eq. (109) reaches the value 1 for
the (relatively large) error rate R close to the error threshold for which x0(∞) =
1/N. Naively, one would assume that π∞ decays with increasing error rate, since
mutations increase the risk that good traits are lost, and indeed the approximate
expression in Eq. (110) decays with increasing error rate. However, since π∞ is the
probability that the master sequence reaches its equilibrium concentration, and
the equilibrium concentration vanishes close to the error threshold, π∞ must rise
to 1 at the error threshold.

We have done some measurements with a ﬁnite population to test the validity
of Eq. (109). For a number of runs, we have initialized the population at random,
but with exactly one instance of the master sequence, and have counted how often
the master’s concentration reached x0(∞) and how often it reached 0. The results
of these measurements are shown in Fig. 11. Clearly, numerical and analytical
results are in good agreement.

Finally, we need an estimate of the time τ it takes from the time step the master
sequence is discovered to the time step in which the equilibrium concentration is
reached for the ﬁrst time. We follow again the calculations in [33], and assume
that the process of ﬁxation can be treated in the inﬁnite population limit. From
Eq. (89), we obtain for the change in the variable x0(t) during one time step in
the interval I1

x0(t + 1) − x0(t) =

−(a − 1)x0(t)2 + (Q00a − Q01 − 1)x0(t) + Q01
(a − 1)x0(t) + 2

.

(111)

41

1.0

0.8

0.6

0.4

0.2

∞
π

y
t
i
l
i
b
a
b
o
r
p

n
o
i
t
a
x
ﬁ

A0 = 4

A0 = 2

0.0

0.0

0.02

0.04

0.06
0.08
error rate R

A0 = 10

N = 500, l = 15

0.1

0.12

0.14

Figure 11: The ﬁxation probability π∞ as a function of the error rate R for three
diﬀerent heights of the peak. The solid lines stem from the analytic expression
Eq. (109), and the dotted lines stem from measurements on a ﬁnite population
consisting of N = 500 sequences.

We approximate this with a diﬀerential equation,

dx0(t)
dt

≈ x0(t + 1) − x0(t) ,

(112)

which we can solve for t as a function of x0, and obtain

t =

b + 4
z

Atanh

b − 2sx0
z

− Atanh

(cid:18)

b − 2s/N
z

(cid:19)

−

ln

1
2

−sx2

0 + bx0 + Q01
−s/N 2 + b/N + Q01

,

with

and

s = a − 1 ,
b = Q00a − Q01 − 1 ,

z =

4sQ01 + b2 .

τ = t

x0(∞)

,

(cid:0)

42

(cid:1)

Therefore, for the estimated time it takes until the master sequence gets ﬁxated
we will use in the following

p

(113)

(114)
(115)

(116)

(117)

with x0(∞) given in Eq. (104).

Hence, we can now calculate the probability that the population skips a whole
period, i.e., that it does not ﬁnd and ﬁxate the master during one interval I1. The
probability that the master sequence has concentration zero at the beginning of
the interval I1 is (1 − 1/2l)N . Therefore, the probability that the master sequence
is not ﬁxated in the ﬁrst time step reads

The probability that the master sequence does not get found and subsequently
ﬁxated in a subsequent time step is given by

1 −

1 −

1 −

π∞ .

"

(cid:18)

#

(cid:19)

N

1
2l

1 − (1 − Pmiss)π∞ .

(118)

(119)

Now, if the master sequence is found, it will roughly take the time τ given in
Eq. (117) until the equilibrium concentration is reached. Therefore, if the master
sequence is not found during the ﬁrst T1 − τ time steps, it normally will not
reach the equilibrium concentration anymore in that period. Therefore, in order
to calculate the probability Pskip(T1) that the whole interval I1 is skipped, we have
to consider only the ﬁrst T1 − τ time steps of I1. In case that T1 < τ , we have
Pskip(T1) ≈ 1. We have only approximate equality because τ is the average time
until ﬁxation occurs. In rare cases, the ﬁxation may happen much faster.

Of the T1 − τ time steps, the ﬁrst one is diﬀerent because in that time step
we do not know whether the master sequence is present or not, whereas for the
remaining T1 − τ − 1 time steps, we may assume that the master sequence is not
present if ﬁxation has not occurred. Therefore, we ﬁnd

Pskip(T1) =

1 −

1 −

1 −

π∞

[1 − (1 − Pmiss) π∞]T1−τ −1

(120)

1
2l

N

N

#

(cid:19)

π∞

!

 

"

1 −

1 −

(cid:18)
1 − 1
2l

≈

h

i
1 − (1 − Pmiss) π∞

(cid:0)

(cid:1)

exp [−(T1 − τ ) (1 − Pmiss) π∞] .

(121)

Figure 12 shows a comparison between this result and numerical measure-
ments. The measurements were taken by letting a randomly initialized population
evolve in a ﬂat landscape for 100 generations, and then recording the time it took
the population to ﬁnd and ﬁxate a peak that was switched on in generation 101.
We observe that the analytic expression for Pskip(T1) predicts the right order of
magnitude and the right functional dependency on T1, but that it generally un-
derestimates the exact value. Since Eq. (120) contains three quantities for which

43

error rate R = 0.05

N = 100

N = 400

N = 1000

measured
analytic
analytic with num. π∞

0.01

0

100

200
400
300
length of on-period T1

500

600

error rate R = 0.08

N = 100

N = 400

N = 1000

1

0.1

1

0.1

)
1
T
(
p
i
k
s
P

y
t
i
l
i
b
a
b
o
r
p

)
1
T
(
p
i
k
s
P

y
t
i
l
i
b
a
b
o
r
p

measured
analytic
analytic with num. π∞

0.01

0

100

400
300
200
length of on-period T1

500

600

Figure 12: The probability Pskip(T1) that the population skips a whole period
without ﬁxating the master sequence, as a function of the length of the interval
I1, for several diﬀerent settings of N and R. The string length is l = 15.

44

we have only approximative expressions, namely Pmiss, π∞, and τ , at ﬁrst it is not
clear from where these discrepancies arise. However, a systematic check quickly
reveals the main cause of the discrepancies. First of all, note that τ merely shifts
the curve to the right. Since the measured and the analytic curves reach the value
1 at very much the same positions in Fig. 12, we can assume that τ , as given by
Eq. (117), is accurate enough for our purposes here. Now consider the quantity
π∞. In Fig. 11, we saw that our expression for π∞ generally gives a good estimate
of the true value, but that there are some deviations. To check whether these
deviations are responsible for the discrepancies visible in Fig. 12, we have addi-
tionally displayed Pskip(T1) with π∞ determined from measurements. We ﬁnd that
the usage of the true value of π∞ enhances the quality of Eq. (120), in particular
for larger error rates. For small error rates, however, it does not help much. More-
over, the analytic expression is generally getting worse for smaller error rates. As
a conclusion, the main problems arise from the expression for Pmiss, Eq. (105). We
have derived Pmiss under a maximum entropy assumption, i.e., we have assumed
that all mutants are distributed homogeneously over the sequence space. Under
this assumption, the probability to ﬁnd the master is exactly the same in every
time step. But in reality, the population collapses very rapidly, even in a neu-
tral landscape, and then moves about as a cluster whose radius is determined by
the error rate. This introduces very long range time correlations in a population
evolving in a ﬂat landscape [5]. In particular for small error rates, the cluster is
very small, and this can increase the probability Pmiss substantially. Note that this
eﬀect corresponds to the underestimation of epoch durations that van Nimwegen
et al. found in their analysis of the Royal Road genetic algorithm [33]. An exact
treatment of this eﬀect would probably have to be done along the lines of [5].
Unfortunately, we cannot simply use their expressions here, because of the term
+1 present in our deﬁnition of the operator G(x, t) [Eq. (89)].

In order to check the hypothesis that the violation of the maximum entropy
condition causes the main discrepancies shown in Fig. 12, we did some additional
measurements in which we dispersed the population “by hand” over the complete
sequence space except the master in every time step in which the master sequence
was not discovered. With this setup, we found a very good agreement between the
numerical and the analytical results.

Since it is the population’s collapse into a small cluster that causes the de-
viations between Eq. (120) and the measured Pskip(T1), it is clear that the true
Pskip(T1) must always be larger than predicted by Eq. (120). Therefore, we can
use that equation as a lower bound on the true value.

We notice that Pskip(T1) decays exponentially. This means that the probability

45

to ﬁnd the peak in one oscillation period,

Pﬁnd(T1) = 1 − Pskip(T1),

(122)

approaches 1 for large T1. This is due to the fact that the peak will certainly be
rediscovered if only we wait long enough. However, the model we are studying here
is that of a peak that gets switched on and oﬀ alternatingly, and for which each
“on”-period is of ﬁxed length T1. In that case, the probability to rediscover the
peak within one oscillation period can be extremely small, as we are going to see
now. Pskip(T1) decays with a rate of (1 − Pmiss)π∞. We can neglect π∞ here, as it is
of the order of one. Then, the decay rate is for ﬁxed N and large l approximately
given by

1 − Pmiss ≈ N

1 − (1 − R)l
2l+1

,

(123)

i.e., it decays as 2−l. This implies in turn that already for string lengths of 50–60
(which can be considered a rough lower bound for typical DNA sequence lengths)
and moderate N and R, we have Pﬁnd(T1) ≈ 0 for moderate T1. Hence, in many
cases it is extremely unlikely that the peak is rediscovered at all.

The above conclusion is of course tightly connected to the fact that we have
studied a landscape with a single advantageous sequence. In the other extreme
of a mount Fujiama landscape, in which the population can sense the peak from
every position in the sequence space, the conclusions would look diﬀerently. Note,
however, that neither the single sharp peak landscape nor the mount Fujiama
landscape are realistic landscapes. In a realistic, high-dimensional rugged land-
scape, it is probably valid to assume that local optima, once they are lost from the
population, are never rediscovered. In such situations, dynamic ﬁtness landscapes
can induce the loss of a local optimum, and thus, they can accelerate Muller’s
ratchet[18] like eﬀects.

6 Conclusions

In this paper, we have been able to derive several very general results on landscapes
with periodic time dependency. First of all, a quasispecies can be deﬁned by means
of the monodromy matrix. This means that after a suﬃciently long time, the state
of the system depends only on the phase φ = (t mod T )/T of the oscillation, but
it does not depend on the absolute time t any more. Therefore, in periodic ﬁtness
landscapes, the quasispecies is not a ﬁxed mixture of sequence concentrations.
Instead, it is a T -periodic function of mixtures of sequence concentrations. We

46

have given an expansion of the monodromy matrix in terms of the oscillation
period T , which leads to an extremely simple description of the system for very
high oscillation frequencies. Namely—if we assume the mutation matrix remains
constant all the time—the time-averaged ﬁtness landscape completely determines
the behavior of the system; the system becomes indistinguishable from one in a
static landscape. This leads to the important conclusion that selection never ceases
to exist, no matter how fast the landscape changes. The only exception to this
rule is generated by dynamic landscapes that have a completely ﬂat average. In
that case, the system behaves for very fast changes as being in a ﬂat landscape,
which is indistinguishable from the behavior of a system above the error threshold.
Therefore, if the average landscape is ﬂat, selection will break down if the changes
occur with a frequency higher than some critical frequency ω∗ = 2π/T ∗. For
very slow changes, on the other hand, the system is virtually in equilibrium all
the time. This leads generally to a time dependent error threshold R∗(t). For
mutation rates R such that mint R∗(t) < R < maxt R∗(t), the system is below
the error threshold for some times t, and it is past the error threshold for other
times. We have dubbed this region of the parameter space the temporarily ordered
phase, as we see alternating patterns of order and disorder in that phase (in the
inﬁnite population limit). We found these general considerations to be in complete
agreement with all example landscapes that we studied.

For the case of non-periodic landscapes, we have argued that the main conclu-
sions remain valid, even if our mathematical formalism is not generally applicable
in that case. Fast changes in the landscape will average out, whereas slow changes
lead to a quasistatic adaption of the quasispecies to the current landscape. With
these concepts, it has been possible to give an explanation for the occurrence of a
lower error threshold in the work of Nilsson and Snoad [19].

While the molecular concentrations become T -periodic for t → ∞ in the in-
ﬁnite population limit, this is not necessarily the case when we consider ﬁnite
populations. In the temporarily ordered phase, after a population has made the
transition to the disordered state, it is not said that it transitions back to order the
same moment the inﬁnite population would. Rather the opposite is the case. Once
the population has lost the ordered state, it is often hard for it to return there.
From a very simple analytical model, we have found that the probability that the
ordered state is not rediscovered in one oscillation period decays exponentially in
the length of the interval in which order is possible at all. The decay constant,
however, is extremely small for large l, and therefore the rediscovery can become
very unlikely.
In more complex landscapes, this can lead to an acceleration of
Muller’s ratchet.

Throughout this paper, we have assumed that mutations arise in the copy pro-

47

cess. An equally valid assumption is that of mutations arising on a per-unit-time
basis (cosmic ray mutations), as opposed to the per generation basis implied by
copy mutations. With the latter assumption, one has to study the parallel muta-
tion and selection equations [3] instead of Eigen’s equations. Since these equations
can be linearized in the same way as the quasispecies equations, the formalism
we developed applies also for these equations. The only diﬀerence between the
two types of equations is that in the parallel case, the mutation matrix Q and
the replication matrix A are added, whereas in the quasispecies case they are
multiplied.

In future work, it should be tried to obtain an improved understanding of the
properties of the monodromy matrix. In particular, an expansion of that matrix
in the error rate R would certainly be valuable.

A High-frequency expansion of X(t) for a land-
scape with two alternating master sequences

With Eq. (29), we have given an expansion of the monodromy matrix for periodic
landscapes, X(t0), in terms of the period length T . Here, we want to calculate
the expansion explicitly up to second order for an example landscape.
In that
landscape, there are two sequences (without loss of generalization, we assume
them to be i = 0 and i = 1) that become alternatingly the master sequence. The
replication rates are

A0(t) = a + b sin(ωt) ,
A1(t) = c + d sin(ωt) ,
Ai(t) = 1

for all i > 1 .

(124a)
(124b)
(124c)

The decay rates are set to zero. With vanishing decay rates, the matrix W(t)
reduces to QA(t), and as a consequence, we can write the nths average Wk(t) as

Wk(t)

ij =

ν1

ν2 · · ·

νk−1Qiν1Qν1ν2 · · · Qνk−1jAν1,ν2,...νk−1,j(t)

(125)

with the generalized replication coeﬃcients

X

X

X

(cid:0)

(cid:1)

Aν1,ν2,...νk−1,j(t) =

Aiν1(t0 + τ1)

Aν2(t0 + τ2)

1
T k

T

0
Z
τk−2

· · ·

0
Z

0
Z

τk−1

τ1

0
Z

48

Aνk−1(t0 + τk−1)

Aj(t0 + τk)dτ1dτ2 · · · dτk .

(126)

For the landscape given in Eq. (124), the ﬁrst order tensor of the generalized
replication coeﬃcients has three independent elements, which are (assuming i > 1)

The second order tensor has already 9 independent entries. After some algebra,
we obtain (assuming again i > 1)

A0(t) = a ,
A1(t) = c ,
Ai(t) = 1 .

A00(t) =

,

A01(t) =

+

cos(ωt) ,

A0i(t) =

−

cos(ωt) ,

A10(t) =

−

cos(ωt) ,

ad − bc
2π

b
2π
ad − bc
2π

A11(t) =

,

A1i(t) =

cos(ωt) ,

Ai0(t) =

cos(ωt) ,

Ai1(t) =

cos(ωt) ,

−

+

+

d
2π
b
2π
d
2π

Aii(t) =

.

a2
2
ac
2
a
2
ac
2
c2
2
c
2
a
2
c
2
1
2

(127a)

(127b)

(127c)

(128a)

(128b)

(128c)

(128d)

(128e)

(128f)

(128g)

(128h)

(128i)

In principle, the generalized replication coeﬃcients Aν1,ν2,...νk−1,j(t) can be calcu-
lated to arbitrary order for the landscape given in Eq. (124). However, the third
order tensor has already 27 independent entries, and with every higher order, the
number of independent entries triples.

References

[1] Chris Adami and C. Titus Brown. Evolutionary learning in the 2D Artiﬁcial
Life system ’Avida’. In Rodney A. Brooks and Pattie Maes, editors, Artiﬁcial
Life IV, pages 372–381, Cambridge, MA, 1994. MIT Press.

49

[2] D. Alves and J. F. Fontanari. Error threshold in ﬁnite populations. Phys.

Rev. E, 57:7008–7013, 1998.

[3] Ellen Baake and Wilfried Gabriel. Biological evolution through mutation,
selection and drift: An introductory review. Ann. Rev. Comp. Phys., 7, 1999.
in press.

[4] Lloyd Demetrius, Peter Schuster, and Karl Sigmund. Polynucleotide evolution

and branching processes. Bull. Math. Biol., 47:239–262, 1985.

[5] Bernard Derrida and Luca Peliti. Evolution in a ﬂat ﬁtness landscape. Bull.

Math. Biol., 53:355–382, 1991.

[6] Esteban Domingo, Donna Sabo, Tadatsugu Taniguchi, and Charles Weiss-
mann. Nucleotide sequence heterogeneity of an RNA phage population. Cell,
13:735–744, 1978.

[7] M. Eigen. Selforganization of matter and the evolution of biological macro-

molecules. Naturwissenschaften, 58:465–523, 1971.

[8] M. Eigen and P. Schuster. The Hypercycle—A Principle of Natural Self-

Organization. Springer-Verlag, Berlin, 1979.

[9] Manfred Eigen, John McCaskill, and Peter Schuster. Molecular quasi-species.

J. Phys. Chem., 92:6881–6891, 1988.

[10] Manfred Eigen, John McCaskill, and Peter Schuster. The molecular quasi-

species. Adv. Chem. Phys., 75:149–263, 1989.

[11] Warren J. Ewens. Mathematical Population Genetics. Springer-Verlag, New

York, 1979.

[12] B. L. Jones. Selection in systems of self-reproducing macromolecules under
the constraint of controlled energy ﬂuxes. Bull. Math. Biol., 41:761–766, 1979.

[13] B. L. Jones. Some models for election of biological macromolecules with time

varying constants. Bull. Math. Biol., 41:849–859, 1979.

[14] B. L. Jones, R. H. Enns, and S. S. Rangnekar. On the theory of selection of

coupled macromolecular systems. Bull. Math. Biol., 38:15–28, 1976.

[15] Ira Leuth¨ausser. Statistical mechanics of Eigen’s evolution model. J. Stat.

Phys., 48:343–360, 1987.

50

[16] J. Maynard Smith. Models of evolution. Proc. R. Soc. London B, 219:315–325,

1983.

[17] J. S. McCaskill. A localization threshold for macromolecular quasispecies from
continuously distributed replication rates. J. Chem. Phys., 80:5194, 1984.

[18] H. J. Muller. The relation of recombination to mutational advance. Mutat.

Res., 1:2, 1964.

[19] Martin Nilsson and Nigel Snoad. Error thresholds on dynamic ﬁttness-

landscapes. eprint physics/9904023, 1999.

[20] Martin Nowak and Peter Schuster. Error thresholds of replication in ﬁnite
populations—mutation frequencies and the onset of Muller’s ratchet. J. theor.
Biol., 137:375–395, 1989.

[21] C. Ronnewinkel. unpublished, 1999.

[22] C. Ronnewinkel, C. O. Wilke, and T. Martinetz. Genetic algorithms in time-
In Proceedings of the 2nd Evonet Summerschool,

dependent environments.
New York, 1999. Springer-Verlag. in press.

[23] J. E. Rowe. Cyclic attractors and quasispecies adaptability. In Proceedings of
the 2nd Evonet Summerschool, New York, 1999. Springer-Verlag. in press.

[24] J. E. Rowe. Finding attractors for periodic ﬁtness functions. In W. Banzhaf
et al., editors, Proceedings of GECCO 1999, page 557, San Mateo, 1999.
Morgan Kaufmann.

[25] David S. Rumschitzki. Spectral properties of Eigen evolution matrices. J.

Math. Biol., 24:667–680, 1987.

[26] L. Schmitt and C. L. Nehaniv. The linear geometry of genetic operators with
applications to the analysis of genetic drift and genetic algorithms using tour-
nament selection. In C. L. Nehaniv, editor, Mathematical & Computational
Biology: Computational Morphogenesis, Hierarchical Complexity, and Digi-
tal Evolution, Lectures on Mathematics in the Life Sciences, pages 147–166.
American Mathematical Society, 1999.

[27] L. Schmitt, C. L. Nehaniv, and R. H. Fujii. Linear analysis of genetic algo-

rithms. Theor. Comp. Sci., 200:101–134, 1998.

[28] Peter Schuster and J¨org Swetina. Stationary mutant distributions and evolu-

tionary optimization. Bull. Math. Biol., 50:635–660, 1988.

51

[29] J¨org Swetina and Peter Schuster. Self-replication with errors—A model for

polynucleotide replication. Biophys. Chem., 16:329–345, 1982.

[30] P. Tarazona. Error thresholds for molecular quasispecies as phase transitions:
From simple landscapes to spin-glass models. Phys. Rev. E, 45:6038–6050,
1992.

[31] Colin J. Thompson and John L. McBride. On Eigen’s theory of self-
organization of matter and the evolution of biological macromolecules. Math.
Biosci., 21:127–142, 1974.

[32] Erik van Nimwegen and James P. Crutchﬁeld. Metastable evolutionary dy-
namics: Crossing ﬁtness barriers or escaping via neutral paths? eprint adap-
org/9907002, 1999.

[33] Erik van Nimwegen, James P. Crutchﬁeld, and Melanie Mitchell. Statistical
dynamics of the royal road genetic algorithm. Theoretical Computer Science,
1997. to appear, SFI working paper 97-04-035.

[34] Thomas Wiehe, Ellen Baake, and Peter Schuster. Error propagation in repro-

duction of diploid organisms. J. theor. Biol., 177:1–15, 1995.

[35] Claus O. Wilke. Evolutionary Dynamics in Time-Dependent Environments.

Shaker Verlag, Aachen, 1999. PhD thesis Ruhr-Universit¨at Bochum.

[36] Claus O. Wilke, Christopher Ronnewinkel, and Thomas Martinetz. Molec-
In Dario Floreano, Jean-
ular evolution in time dependent environments.
Daniel Nicoud, and Francesco Mondada, editors, Advances in Artiﬁcial Life,
Proceedings of ECAL’99, Lausanne, Switzerland, Lecture Notes in Artiﬁcial
Intelligence, pages 417–421, New York, 1999. Springer-Verlag.

[37] Y. A. Yakubovich and V. M. Starzhinskii. Linear Diﬀerential Equations with
Periodic Coeﬃcients, volume 1. John Wiley & Sons, New York, 1975.

52

