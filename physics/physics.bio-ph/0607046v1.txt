A Global Algorithm for Training Multilayer Neural Networks

Hong Zhao∗ and Tao Jin
Physics Department of Xiamen University,
and the Institute of Theoretical Physics and Astrophysics of Xiamen
University,
Xiamen 361005, China

6
0
0
2
 
l
u
J
 
6
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
6
4
0
7
0
6
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

We present a global algorithm for training multilayer neural networks in this Letter. The algo-
rithm is focused on controlling the local ﬁelds of neurons induced by the input of samples by random
adaptations of the synaptic weights. Unlike the backpropagation algorithm, the networks may have
discrete-state weights, and may apply either diﬀerentiable or nondiﬀerentiable neural transfer func-
tions. A two-layer network is trained as an example to separate a linearly inseparable set of samples
into two categories, and its powerful generalization capacity is emphasized. The extension to more
general cases is straightforward.

The multilayer neural network, trained by the backpropagation(BP) algorithm, is currently the most widely used
neural network since it can solve linearly inseparable classiﬁcation problems [1,2]. The BP algorithm is responsible
for the rebirth of neural networks.

However, the BP algorithm has several limitations. Firstly, it requires the neural transfer functions to be diﬀer-
entiable in order to calculate the derivatives with respect to the synaptic weights. Secondly, the performance index
to be minimized is constantly to be mean square error, because a non-quadratic performance index may result in
very complex performance surface. Finally, the synaptic weights obtained by this algorithm are continuous as a
consequence of its updating equation of synaptic weights. These limitations are also inherent in variations of the BP
algorithm. The last is indeed also a limitation for most of the learning rules for training single-layer neural networks.
Discrete synaptic states have not only the advantage for digital hardware realization but also an experimental reality.
Recent experiments have shown that the synaptic states in certain real neural network systems may be discrete [3–5].
The BP algorithm is a local learning rule. Most of the learning rules for training single-layer neural networks, such
as the perceptron rule, the Hebb rule, and the Widrow-Hoﬀ rule, are local rules. When training a network using
a local rule, one inputs the samples into the network one by one, and each time the synaptic weights are updated
independently on other samples. A step of update of synaptic weights induced by the input of a sample is an optimal
solution for this sample, but not for other samples.

In principle, it is more favorable if each step of the update is an optimal solution for all the samples. This requires
the consideriation of the whole set of samples globally. An inﬂuential example of global rules is the Pseudoinverse
rule [1,6] used for training single-layer networks.

One of the present authors has recently proposed another global learning rule, called the Monte Carlo adaptation
algorithm (shorten as MCA algorithm hereafter) [7]. The basic idea is to make an adaptation to a randomly chosen
synaptic weight, and accept the adaptation if it improves the network performance globally. A realization of the MCA
algorithm had been used to train single-layer feedback neural networks with binary-state synaptic weights [7,8].

The purpose of this Letter is to present a general version of the MCA algorithm which is applicable to train multilayer
neural networks with either continuous or discrete synaptic states, and with either diﬀerentiable or nondiﬀerentiable
neural transfer functions. Based on the observation that the network performance is determined by the local ﬁelds
of neurons induced by the input of the samples (shorten as LFNIIS), our algorithm is focused on controlling the
distributions of LFNIIS by continuously adapting the synaptic weights. Two steps are applied to perform the control.
The ﬁrst one is to determine the target distribution of the LFNIIS, deﬁne the states of synaptic weights, and chose
the transfer function of neurons for each layer respectively. The second one is to randomly select a synaptic weight,
and randomly adapt it to a new state, then make a decision whether or not to accept this adaptation by a criterion.
This step is repeated till the distributions overlap with the target ones. The criterion for acceptable adaptations is
crucial for the algorithm. In principle, we accept an adaptation if the distributions of LFNIIS induced by it does not
diverge away from the target distributions statistically. This guarantees the distributions of LFNIIS evolving towards
the targets in a one-way manner.

As a realization example of the above framework, we train a two-layer neural network to separate a set of linearly
inseparable samples into two categories. In order to demonstrate the network not only overcomes the limitations of
BP networks but also improves the network performance, we emphasize its powerful generalization capacity over a
two-layer BP network. The generalization capacity is essential for a neural network. This is because the sample set is

∗To whow the correspondings should be addressed. Email: zhaoh@xmu.edu.cn.

1

normally representative of a much larger class of patterns. It is particularly important that the network successfully
generalize what it has learned to the total population [1,9,10]. In our example, when we input an unlearned pattern
having higher similarity with one sample, it is naturally desirable that the network can classify it into the same
category that the sample belongs to. The degree of the average divergency of the pattern from the sample below
which the network can correctly categorize measures the generalization capacity.

Suppose there are M samples available for the training, and the µth sample is represented by an N -dimensional
binary vector ξµ ≡ {ξµ
i = ±1. It has been proved [11] that the maximum amount of samples
that can be linearly separable is M ≤ 2N if the samples have no correlations, and a single-layer neural network
trained by the perceptron rule can fulﬁl this task. To solve linearly inseparable classiﬁcation problems, one has to
apply multilayer neural networks.

i , i = 1, ..., N } with ξµ

Let J(l) represent the weight matrix and v(l−1) represent the input vector of the lth layer of a multilayer neural

network. The output of the lth layer is determined by the equations:

h(l)
i =

ij v(l−1)
J (l)

j

,

N (l−1)

X
j=1

i = σ(l)(h(l)
v(l)
i ),

(1)

(2)

where h(l)
i
represents the number of neurons in the lth layer with N (0) ≡ N .

is the local ﬁeld of the ith neuron in the lth layer and σ(l) is its transfer function. In the equation, N (l)

A two-layer neural network has a hidden layer and a output layer. When the µth sample ξµ is inputted into the
iµ ), of the ith neuron in the

j , and the output, v(1)

iµ = σ(1)(h(1)

j=1 J (1)

ij ξµ

iµ =

N

network one obtains the local ﬁeld, h(1)
hidden layer.

P

For the output layer, because we want the network to separate the samples into only two categories, one neuron in
this layer is enough. In this case, the weight matrix will be a 1 × N (1) matrix, whose elements will be denoted by J (2)
1j .
Here N (1) is the number of neurons in the hidden layer. Inputting the vector v(1)
µ to the output layer one obtains the
jµ , and the output, v(2)
local ﬁeld, h(2)
µ ), of the neuron.

µ = σ(2)(h(2)

N (1)
j=1 J (2)

1j v(1)

µ =

Let Σ1 and Σ2 represent the two categories of samples. Our goal is to establish the connections, v(2)

µ = 1 if ξµ ∈ Σ1
µ = −1 if ξµ ∈ Σ2, by the proper solution of J(l) and σ(l). To fulﬁl this goal, the transfer function of the

and v(2)
neuron in the output layer must be the step function: σ(2)(x) = 1 for x ≥ 0 and σ(2)(x) = −1 for x < 0.

P

The establishment of the connections implies the satisfaction of the condition tµh(2)

µ ≥ 0 in terms of the local ﬁelds,
where tµ = 1 for ξµ ∈ Σ1 and tµ = −1 for ξµ ∈ Σ2. However, this is not enough for the generalization. When
inputting a vector which has a set of elements, denoted by {k}, diﬀerent from, say, the µth sample, then the local
j , where the sum
and leads to
jµ for the neuron in the output layer, where the sum is over {k′}. The generalization capacity
iµ and h(2)
µ under as many mutations as possible of
µ but also h(1)

ﬁelds of the neurons in the hidden layer induced by this input should be h
is over the set of {k}. This in turn results in a set of elements, denoted by {k′}, diﬀerent from v(1)
µ
(2)
µ = h(2)
h
is thus determined by the capability of conserving the sign of h(1)
the sample ξµ, which requires the absolute values of not only h(2)

iµ = h(1)

1j v(1)
J (2)

J (1)
ij ξµ

iµ − 2

iµ as big as possible.

µ − 2

P

P

(1)

Thus, to gain better generalization capacity we should expect the distribution of h(2)

where c is a positive parameter. For the hidden layer, there is no restriction on the sign of a speciﬁc h(1)
deﬁne di =
capacity we expect di to be as large as possible.

µ ≥ c,
iµ , we thus
iµ | to roughly measure the mean absolute value of the local ﬁelds. To gain better generalization

µ satisfy the condition tµh(2)

µ=1 |h(1)

µ=M

P

We apply the following procedure to train the network to ﬁnd a set of solution of synaptic weights that gurantees

the desired distributions of h(1)

iµ and h(2)

µ be satisﬁed.

(1) Initialize J (l)

ij with J (l)
is a state of J (l)
ij .

Here θ(l)
k

ij ∈ {θ(l)

k , k = 1, ..., p} randomly with equal probability; calculate h(1)

iµ , v(1)

iµ , h(2)

µ and di.

(2) Randomly select a J (l)

ij and randomly adapt it to a new state θ(l)

; if l = 1 calculate

k

− θ(1)

e
k )ξµ
j ,

iµ + (θ(1)
iµ = h(1)
h(1)
k
e
h(1)
v(1)
iµ = σ(1)(
iµ ),
e
e
e

2

if l = 2 calculate

Then calculate

where

h(2)
µ =
e

N (1)

X
q=1

M

J (2)
1q

v(1)
qµ ,
e

di =
e

X
µ=1

h(1)
iµ |;
|
e

h(2)
µ = h(2)
e

µ + (θ(2)

− θ(2)

k )v(1)
jµ .

k

e

n =

nµ,

X
{µ}

nµ =

µ − h(2)
h(2)
0, tµ(
µ − h(2)
h(2)
e
1, tµ(
µ − h(2)
h(2)
e
−1, tµ(
e

µ ) = 0
µ ) > 0
µ ) < 0






,

and the sum is just over those index set {µ} of µ satisfying tµh(2)
h(2)
µ < c or tµ
µ < c.
v(1)
iµ , v(1)
h(1)
di ≥ di and n ≥ 0, renew the parameters, i.e., h(1)
e
iµ ,etc., otherwise remain the old ones;
iµ ←−
e
e
e

µ ≥ c is achieved and di can not be further enlarged.

return to step (2) till the condition tµh(2)

iµ ←−

(3) If

With a set of parameters N = 1000, N (1) = 1000, M = 2400, c = 30, and applying the binary weights J (l)
ij ∈
{+1, −1} while adopting the step transfer function for each neuron, we tested the above training procedure by
separating the samples into two sets with equal samples. Without loss of the generality, we suppose ξµ ∈ Σ1 for
µ = 1, ..., M/2 and ξµ ∈ Σ2 for µ = M/2 + 1, ..., M . Note that the samples are linearly inseparable since M > 2N .
µ respectively. It can be seen that h(2)
In Fig. 1(a) and 1(b) the up-triangles show the distributions of h(1)
µ
distributes in the region of tµh(2)

µ ≥ 30 correctly, and the distribution of h(1)

iµ shows a two-peak structure.

iµ and h(2)

iµ by restricting

The two-peak structure is a consequence of controlling the distribution of h(1)

adaptations. If merely employ n ≥ 0 as the criterion for acceptable adaptations, the distribution of h(2)
condition tµh(2)
1(b) show the distributions of h(1)
a single-peak structure, while the distribution of h(2)
criterion.

di ≥ di for acceptable
e
µ can fulﬁl the
iµ will be out of control. The open stars in Fig. 1(a) and
iµ distributes around the origin with
di ≥ di as the
e

µ ≥ 30 easily. However, the distribution of h(1)
iµ and h(2)

µ respectively. It can be seen that h(1)

µ is similar to that obtained by using n ≥ 0 and

For the generalization, the distribution of h(1)

iµ with the two-peak structure is obviously preferable than that with
the single-peak structure, since the amount of elements of h(1)
iµ with small absolute values in the former case is much
less than that in the latter case. Figure 2 conﬁrms this prediction. In the ﬁgure, the triangles and stars show the
generalization capacity of the networks obtained with the criterion
di ≥ di and n ≥ 0, and with merely the criterion
n ≥ 0, respectively. The horizontal axis is the mean percentage of the diﬀerence between an input vector and one of
e
the samples. The vertical axis is the rate of correct classiﬁcation. It is clear that the former network has much higher
generalization capacity than the later one. Note that an input vector with no correlation with any sample has equal
probability to be classiﬁed into either category, a rate of 0.5 therefore indicates the total loss of the generalization
capacity.

By adopting the mean square error < (h(2)

µ − c)2 > as the performance index and the analog function σ(1)(x) =
tanh(x) as the transfer function for each neuron in the hidden layer, one can obtain a two-layer network capable of
categorizing the same set of samples using the BP algorithm. In order to make comparison with our network, we
apply c = 34 and stop the learning procedure after the condition tµh(2)
µ ≥ 30 is satisﬁed for all samples. The weights
are normalized to satisfy < J (l)
ij >= 1. The dot-lines in Fig. 1 show the distributions of the LFNIIS for the BP
network. It can be found that h(2)
iµ distributes around the
origin. Clearly, the distribution of the LFNIIS for the hidden layer is out of the control of the algorithm since h(1)
iµ

µ distributes around ±c as two Guassian-like peaks, and h(1)

3

is not included in the performance index, and the two peaks in the distribution of h(2)
µ is induced by the operation
of minimizing the mean square error. The minimization operation drives the local ﬁelds not only with smaller value
but also with larger value of tµh(2)
µ concentrated towards c synchronously, while the larger values are favorable for the
generalization capacity as explained earlier. Thus, the generalization capacity of the BP network would be even worse
than that of our network obtained with merely the criterion n ≥ 0. The rate of correct generalization represented by
the dots in Fig. 2 conﬁrms this prediction.

Our procedure can be directly extended to train neural networks with synaptic weights having more discrete states.
It can be found easily that when the states are extended to inﬁnite, e.g., J (l)
ij ∈ {±1, ±3, ±5, ..., }, the weights indeed
become continuous (after been normalized). We have observed that the network performance can be further improved
by increasing the discrete states. To show this, we made, between the networks with J (1)
ij ∈ {±1} and the networks
with J (1)
ij ∈ {±1, ±3}, a comparison of the maximum capacity of separating no-correlation samples into two sets with
equal members. The weights in the output layer are ﬁxed at J (2)
1i ∈ {±1} for both networks. The results are shown in
Fig.3, where M/N is the normalized maximum amount of the samples that can be separated into two sets correctly
within 0.01M N N (1) times of repeat of the steps (2)-(3), and N (1)/N is the normalized number of neurons in the hidden
layer. The up- and down-triangles represent the results for networks with J (1)
ij ∈ {±1, ±3}
respectively. In the calculation we ﬁx N = 500. One can see from the ﬁgure that the maximum capacity increases as
the increase of the neurons in the hidden layer, and increases with the increase of the discrete states of weights.

ij ∈ {±1} and with J (1)

In summary, unlike the BP algorithm, the improved MCA algorithm puts no restriction to the neural transfer
function and is applicable to train neural networks with either discrete or continuous synaptic weights. Another
key diﬀerence is that we implement the desired network performance by controlling the distributions of the LFNIIS,
while the BP algorithm approaches this goal by minimizing the performance index deﬁned constantly as the mean
square error. It is obvious that one has a much wider freedom to improve the network performance by controlling the
distributions of the LFNIIS. This is because one has freedom not only to control the distribution for the output layer
but also to control the distributions for the hidden layers. The good generalization capacity of the two-layer network
trained with the criterion
di ≥ di and n ≥ 0 is just beneﬁted from the control of the distribution of the LFNIIS for
the hidden layer.
e

The application of the algorithm described in this Letter to the problem of separating a set of samples into several
categories is straightforward by involving more neurons in the output layer. The algorithm is directly applicable to
train single-layer networks, and can be extended straightforwardly to train networks with three or more layers.

We want to emphasize that the MCA algorithm has capability for practical applications. For example, it takes
about one hour of evolution time for a personal computer to train the network satisfy the condition tµh(2)
µ ≥ 30 by
applying the criterion n ≥ 0. To fulﬁl the same condition using the BP algorithm with optimal learning rate it takes
about 6 computer hours.

It is necessary to point out that the training procedure is sensitive to technical details. For example, if one replaces
the criterion n ≥ 0 simply with n > 0 in the related training preocedures above, it may need double the time to
approach the same goals. On the other hand, certain treatments, such as adjusting the constant c gradually to its
target value, can dramatically decrease the training time. In addition, introducing temperature to the criterion for
acceptable adaptations can aﬀect the eﬃciency of training process in a complex way. These facts imply that there is
a big possibility to further improve the training procedure.

Finally we brieﬂy report an interesting phenomenon which may share lights on the role of diﬀerent layers in a
network. We have performed the MCA algorithm in two ways. One is to ﬁx the wights in the output layer by some
random realizations and merely adjust the weights in the hidden layer. The another is to adjust the weights in both
layers. It was found that both ways can achieve the same goal of classiﬁcation, but the training time used in the ﬁrst
way was dramatically less than that used in the second way. This implies that the role of the output layer is merely
to span out the space. Each speciﬁc realization of weights for the output layer has a set of optimal realizations of the
weights for the hidden layer, and every realization leads to the same target distributions of h(1)

iµ and (b) h(2)
µ .

Particular thanks are given to Professor Schuster from whom I got a lot of useful ideas and suggestions related to
this work. This work is supported in part by the National Natural Science Foundation of China under Grant No.
10475067, and the Doctor Education Fund of the Educational Department of China.

FIGURE CAPTIONS

Fig.1 The distributions of LFNIS of (a) h(1)

iµ and (b) h(2)
µ .

Fig.2. The generalization capacity of the networks.
Fig.3. The maximum capacity of classiﬁcation as functions of the neuron number in the hidden layer for J (1)

ij ∈ {±1}

and for J (1)

ij ∈ {±3, ±1}.

4

[1] M. Hagan, H. Demuth, and M. Beale, Neural Network Design, Boston, MA: PWS Publishing, 1996.
[2] D. E. Rumelhart and J. L. McClelland, eds., Parallel Distributed Processing: Exlporations in the Microstructure of

Cognition, Vol. 1, Cambridge, MA: MIT Press, 1986.
[3] C. C. H. Petersen, R. C. Malenka, R. A. Nicoll, and J. J.
Hopﬁeld, Proc. Natl. Acad. Sci. U.S.A. 95, 4732(1998).

[4] D. H. O’Connor, G. M. Wittenberg, and S. S.-H. Wang, Proc.

Natl. Acad. Sci. U.S.A. 102, 9679(2005); G. M. Wittenberg and S. S.-H. Wang, J. Neurosci. 26, 6610(2006).

[5] H. D. I. Abarbanel, S. S. Talathi, L. Gibb, and M. I. Rabinovich, Phys. Rev. E 72, 031914(2005).
[6] C. M. Marcus, F. R. Waugh, and R. M. Westervelt, Phys. Rev. A 41, 3355(1990)
[7] H. Zhao, Phys. Rev. E 70, 066137(2004).
[8] T. Jin and H. zhao, Phys. Rev. E 72, 086512(2005).
[9] D. A. Stariolo and F. A. Tamarit, Phys. Rev. A 46, 5249(1992)
[10] H. Sompolinsky and N. Tishby, Phys. Rev. Lett. 65, 1683(1990)
[11] E. Gardner, J. Phys. A: Meth. Gen. 21, 257(1988).

5

(a)

(b)

zhao-fig1

0.04

0.02

S

I
I

N
F
L

 
f

 

o
n
o

i
t

u
b
i
r
t
s
D

i

0.2

0.1

0.00

0.0

-100

0

100

-60 -30

0

30

60

(1)

(2)

h

i

h

zhao-fig2

n
o

i
t

l

a
c
i
f
i
s
s
a
c
 
t
c
e
r
r
o
c
 
f

o

 

e

t

a
R

1.0

0.9

0.8

0.7

0.6

0.5

0.00

0.05

0.10

0.15

0.20

percentage of error

Zhao-fig3

/

N
M

10

8

6

4

2

0

0.0

0.4

0.8

1.2

1.6

(1)

N

/N

