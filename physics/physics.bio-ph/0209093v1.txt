2
0
0
2
 
p
e
S
 
6
2
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
3
9
0
9
0
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Subthreshold dynamics of the neural membrane potential
driven by stochastic synaptic input

Ulrich Hillenbrand∗
Institute of Robotics and Mechatronics
German Aerospace Center
Oberpfaﬀenhofen, 82234 Wessling, Germany

In the cerebral cortex, neurons are subject to a continuous bombardment of synaptic inputs
originating from the network’s background activity. This leads to ongoing, mostly subthreshold
membrane dynamics that depends on the statistics of the background activity and of the synapses
made on a neuron. Subthreshold membrane polarization is, in turn, a potent modulator of neural
responses. The present paper analyzes the subthreshold dynamics of the neural membrane po-
tential driven by synaptic inputs of stationary statistics. Synaptic inputs are considered in linear
interaction. The analysis identiﬁes regimes of input statistics which give rise to stationary, ﬂuctu-
ating, oscillatory, and unstable dynamics. In particular, I show that (i) mere noise inputs can drive
the membrane potential into sustained, quasiperiodic oscillations (noise-driven oscillations), in the
absence of a stimulus-derived, intraneural, or network pacemaker; (ii) adding hyperpolarizing to
depolarizing synaptic input can increase neural activity (hyperpolarization-induced activity), in the
absence of hyperpolarization-activated currents.

PACS numbers: 87.19.La, 87.10.+e, 02.50.-r.
Keywords: neural networks, cerebral cortex, membrane potential, synapses, stochastic process.

Published as Physical Review E 66, 021909 (2002).

I.

INTRODUCTION

Cortical pyramidal cells ﬁre action potentials at an average spontaneous rate of about 10 spikes/s in waking animals
[27, 28]. At such a low spike rate, it is clear that most cortical neurons spend a signiﬁcant amount of time with their
membrane potential well below the threshold for spike activation. On the other hand, a cortical pyramidal cell receives
roughly 10000 synapses [8], mostly from other cortical neurons. Since individual postsynaptic events cause transient
increases in membrane conductance, it follows that the dynamics of membrane potentials is largely controlled by
subthreshold stimulation from the continuous network activity. Subthreshold membrane polarization is, in turn, a
potent modulator of stimulus-driven spike activity [3, 23].

In this paper, I analyze the subthreshold dynamics of the membrane potential driven by stochastic synaptic activity
of general stationary statistics. Such conditions are given in neurons that do not respond to an external stimulus,
but are exposed to the network’s spontaneous or stimulus-driven background activity. The generation of postsynaptic
potentials (PSPs) and their propagation along the dendrites of a neuron are modeled in a rather simple way to
allow for a thorough analytical treatment. Accordingly, the focus is on generic patterns of behavior rather than on
quantitative results. Some of the conclusions are discussed in relation to the experimental literature.

II. MODELING SYNAPTIC RESPONSES

The potential V across a local patch of passive membrane is described by

d
dt

V =

V +

1
τm

−

1
τm gm

I ,

where τm and gm are the passive membrane time constant and leak conductance, respectively, and I is the current
passed along the dendrites from other parts of the cell. The membrane’s resting potential is set to zero. After a
synaptic input has been received on the considered patch of membrane, the potential obeys

d
dt

V =

V +

1
τm

−

1
τm gm

I +

gs
τm gm

(Vs −

V ) ,

(1)

(2)

∗Ulrich.Hillenbrand@dlr.de

where Vs and gs are the synaptic reversal potential and conductance, respectively. Let V0(t) and Vin(t) be solutions to
τm
Eqs. (1) and (2), respectively, with V0(0) = Vin(0) = V (0). Synaptic ion channels are open for a brief period δs ≪
[31]. At time t = δs, when synaptic channels close, the deﬂection of the membrane potential due to the synaptic input
is

Vin(δs)

V0(δs) =

−

δs
τm

gs
gm

[Vs −

V (0)] + O

2

δs
τm (cid:19)

#

.

"(cid:18)

This deﬂection propagates along the cell’s dendrites. Far away from its point of origin, I model the synaptic response
as a PSP. In a passive cable, the rise time and amplitude of a PSP depend on the time course of the synaptic current,
and the relative locations of the synapse and the point on the membrane at which the PSP is observed; the decay-time
constant approaches τm for long times [24, 25, 26, 30]. However, computer-simulation studies involving realistic cell
morphologies [7, 19] and voltage-dependent dendritic conductances [9] have revealed that PSPs in real neurons may
be less variable than suggested by a cylindrical passive-cable model. A coarse but, for the present analysis, suﬃcient
approximation to a PSP is given by the impulse response of a second-order low-pass ﬁlter,

Λ(γ, Vs, t0; t) := γ [Vs −

V (t0)]

t

t0

−
τ

exp

1
(cid:18)

−

t

t0

−
τ

(cid:19)

Θ(t

t0) ,

−

with the unit-step function

The PSP’s amplitude is γ [Vs −

V (t0)], with the factor

Thus, the PSP is initiated at time t0, has a rise time and decay-time constant τ , is attenuated or ampliﬁed by a factor
a [cf. Eq. (3)], and is assumed to propagate instantaneously. It qualitatively captures the basic properties of real PSPs
of having a ﬁnite rise time and an exponential decay phase. It is chosen here for its convenience for analysis.

Postsynaptic conductance changes are very local compared to the extended dendritic trees on which synapses make
contacts. It is therefore a reasonable approximation to treat them as noninteracting. The total membrane potential
under synaptic control is hence given by the sum

Θ(t) :=

(cid:26)

0,
0 for t
1 for t > 0.

≤

γ := a

> 0 .

δs
τm

gs
gm

V (t) =

Λ(γi, si, ti; t)

∞

i=1
X

. . . are the times of synaptic input received by a neuron; γi and si are the
for the whole cell. Here t1 ≤
amplitude-related factor deﬁned in Eq. (6) and the reversal potential of the ith synaptic input, respectively. In Sec.
III E, I will address eﬀects of delays in the propagation of PSPs.

t2 ≤

III. ANALYSIS AND RESULTS

Upon inspection of Eqs. (4) and (7), it is clear that there is an equivalence relation between the statistics of the γi
ti
and of the pairs (si, ti). Higher values of γi have the same eﬀect on the dynamics of V (t) as shorter intervals ti+1 −
between successive stimuli with si = si+1. In order to simplify the analysis, without limiting the dynamic repertoire
γi. In this section, I shall thus derive analytical results on the
of V (t), it is preferable to restrict to one value γ
dynamics

≡

V (t) = γ

[si −

V (ti)]

t

ti

−
τ

exp

1
(cid:18)

−

t

ti

−
τ

(cid:19)

Θ(t

ti) .

−

∞

i=1
X

Moreover, the results will be illustrated by computer simulations where appropriate.

Arguably, the “obvious” approach to the problem is to specify the distribution functions for the point process that
models the times ti of stimulus events and write down integral equations for the moments of V (t). However, we
shall take a diﬀerent approach. We will start by casting the dynamics in the form of a Markov chain. There are
two signiﬁcant advantages proceeding this way. First, it will allow us to go quite far with the analysis without being
speciﬁc about the stimulus process. Only at some later point will it be proﬁtable to specify the statistics of stimulus
times. Second, making use of the Markov property, we will gain insight not only into the dynamics of moments of the
membrane potential, but also into the temporal pattern of individual trajectories V (t).

2

(3)

(4)

(5)

(6)

(7)

(8)

A. Markov formulation of the dynamics of the membrane potential

Introducing the notation

xj

:= V (tj) = γ

j−1

i=1
X

[si −

V (ti)]

ti

tj −
τ

exp

1
(cid:18)

−

ti

tj −
τ

,

(cid:19)

j−1

yj

:= γ

V (ti)] exp

[si −
tj ,

rj

i=1
X
:= tj+1 −

ti

tj −
τ

,

(cid:19)

−

(cid:18)

xj
yj (cid:19)

(cid:18)

=

(rj−1)

(sj−1)

R

◦ S

,

x1 = y1 = 0 ,

xj−1
yj−1(cid:19)

(cid:18)

(s) :

S

(r) :

R

x
y

x
y

(cid:18)

(cid:19)

7→

(cid:18)

7→

x
y + γ (s
−
x + ey r
τ
ye−r/τ
(cid:1)

,

x)
(cid:19)
e−r/τ

.

we can reformulate the dynamics of Eq. (8) for the discrete times t = tj as an iteration of a combination of two
stochastic maps

(r) and

(s),

R

S

(cid:18)(cid:0)
The interstimulus times rj and the synaptic reversal potentials sj are stochastic variables, drawn independently from
densities u(r) on R+ and v(s) on R, respectively. These densities are determined by the neural network activity
and the number and types of synapses on the neuron considered. Note that although there may well be statistical
= j′) as sampled at one individual synapse, these do not
dependences between rj and sj, and (rj , sj) and (rj′ , sj′ ) (j
show up in the sequences rj and sj for all synaptic inputs to a cortical neuron.

(cid:19)

(cid:18)

(cid:19)

In the present formulation of the dynamics, the synaptic input times tj are, like xj and yj, stimulus-driven stochastic

variables and may be incorporated by extending the system (12) with the equation

This equation can be solved independently of Eq. (12). In particular,

tj = tj−1 + rj−1 .

= (j

tji
h

1)

r
h

i

−

+ t1 .

Here and in the following, we encounter mean values of the types

f (s)
i

h

:=

∞

−∞

Z

ds′ v(s′) f (s′) ,

dr′ u(r′) f (r′) ,

f (r)
i
h

:=

∞

0

Z

with f being some function on the real numbers for which the integrals are deﬁned.

The dynamics (12) is a Markov chain. The transition probability corresponding to

(s) is

S

pS(x, y

x′, y′) =
|

ds v(s) δ(x

x′) δ[y

y′

γ(s

x′)] ,

−

−

−

−

∞

−∞

Z

and the one corresponding to

(r) is

R

pR(x, y

x′, y′) =
|

dr u(r) δ

x

∞

0
Z

x′ + ey′ r
τ
(cid:16)

(cid:17)

−

e−r/τ

δ

y

y′e−r/τ

.

i

(cid:16)

(cid:17)

Here δ is the Dirac delta function. Let p(x, y) be a joint probability density for x and y. Then

h

∞

xnym
h

i

:=

∞

dx′

−∞

Z

−∞

Z

dy′ p(x′, y′) x′ny′m , n, m

N ,

−

∈

3

(9)

(10)

(11)

(12)

(13)

(14)

(15)

(16)

(17)

(18)

(19)

(20)

6
are the moments of x and y. We want to know how the moments change under the action of
action of

(s), we get

(r)

R

◦ S

(s). For the

S

xnym
h

iS =

∞

∞

∞

∞

d¯x

d¯y

dx′

−∞

Z

−∞

Z

−∞

Z

−∞

Z

x′, y′) p(x′, y′) ¯xn ¯ym
dy′ pS(¯x, ¯y
|

=

h+i+j=m (cid:18)
h,i,j∈N
X

m
h, i, j

(
−
(cid:19)

1)iγh+i

sh

xn+iyj

,

(21)

(cid:10)

(cid:11) (cid:10)

(cid:11)

with polynomial coeﬃcients

m
h, i, j

(cid:18)

(cid:19)

:=

m!
h! i! j!

,

h + i + j = m .

(22)

The action of

(r) yields

R

xnym
h

iR =

∞

∞

∞

∞

d¯x

d¯y

dx′

−∞

Z

−∞

Z

−∞

Z

−∞

Z

x′, y′) p(x′, y′) ¯xn ¯ym
dy′ pR(¯x, ¯y
|

Let pj(x, y) be the joint probability density of x and y at time tj. By combining Eqs. (21) and (23), we can write
down iteration equations for the moments,

n

=

n
k

k

er
τ

Xk=0 (cid:18)

(cid:19) (cid:28)(cid:16)

(cid:17)

e−(n+m)r/τ

xn−kym+k

.

(23)

(cid:29)

(cid:10)

(cid:11)

xnym
h

ij :=

−∞

Z

−∞

Z

∞

∞

dx′

dy′ pj(x′, y′) x′ny′m .

The iterations can be solved successively for all n and m, starting with the ﬁrst moments. We shall solve for the
y2
ij. Note that the ensemble averages (24) are not taken at
ﬁrst two moments, i.e., for
h
constant time t, but rather at a constant number j of synaptic inputs received, irrespective of the time tj of the jth
input. As mentioned above, the times of synaptic inputs are additional random variables obeying Eq. (15).

ij , and

ij ,
x
h

x2
h

xy
h

ij,

ij,

y
h

The iteration dynamics of the mean values obtained from Eqs. (21) and (23) is

B. Mean membrane potential

x
ij
y
ij (cid:19)

h
(cid:18)
h

=

γb1 b1
a1

γa1

a1 −
−

(cid:18)

x
ij−1
h
y
ij−1(cid:19)
(cid:18)
h

+ γ

s
h

i

b1
a1(cid:19)
(cid:18)

,

i1 =
x

h

y

i1 = 0 ,

h

with the stimulus parameters

=:M1

{z

|
and

s
h

i

(cid:19)

}

a1 :=
b1 :=

e−r/τ
r
τ e1−r/τ
(cid:11)

(cid:10)
(cid:10)

∈

(cid:27)

(cid:11)

(0, 1) .

λ1/2 := a1 −

γb1
2 ±

1
2

γ2b2

1 −

4γa1b1 .

q

λ1/2

< 1

⇐⇒

γb1 < (a1 + 1)2 .

The dynamics of
eigenvalues are

ij and
x

h

y

ij depend on the eigenvalues of M1, and thus on the stimulus parameters a1 and b1. The

h

For convergence of the dynamics, we require that

Figure 1 shows the parameter regions of convergence and divergence. In this parameter space, the vicinity of the
point a1 = 1, b1 = 0 is occupied by high-frequency stimuli, i.e., with short interstimulus times r. A very low network
activity, on the other hand, lies close to the point a1 = 0, b1 = 0. It turns out that for any input statistics, the mean

(cid:12)
(cid:12)

(cid:12)
(cid:12)

4

(24)

(25)

(26)

(27)

(28)

5

Unstable

γb1

4

3

2

1

0

0

0.2

0.4

0.6

0.8

1
a1

γ = 3.7

γb1

4

3

2

1

γ = 0.2

0

0

hxi∞ / hsi

1

γ = 3.7

0.8

0.6

0.4

0.2

γ = 0.2

1
a1

FIG. 1: Space of stimulus parameters a1 and b1 that determine the dynamics of the mean membrane potential. The dynamics
converges for (a1 + 1)2 > γb1. For γb1 < 4a1, the two eigenvalues given by Eq. (27) are complex conjugate. For (a1 + 1)2 >
γb1 > 4a1, they are real and negative. The corresponding type of mean dynamics is depicted for these two regimes.

0.2

0.4

0.6

0.8

0.2

0.4

0.6

0.8

1
a1

FIG. 2: Left: Contour plot of the asymptotic mean membrane potential hxi∞. Dashed lines delimit the regions of diﬀerent
mean dynamics shown in Fig. 1. Assuming Poisson statistics for stimulus times, the stimulus parameters a1 and b1 lie on
parabolas, here plotted for γ = 0.2, 0.7, . . . , 3.7. Right: Plot of hxi∞/hsi for Poissonian stimulus times and the same values of
γ as on the left. The curves are interrupted where (a1 + 1)2 < γb1 such that the mean dynamics is divergent; cf. Fig. 1.

of the membrane potential V converges, if the factor γ, controlling PSP amplitudes, is suﬃciently small. For γb1 > 4,
on the other hand, the mean dynamics will never converge.

From Eq. (25) we obtain the asymptotic values

lim
t→∞ h

V (t)
i

=

i∞ =
x
h

γb1
γb1 + (1
γ(1
−
γb1 + (1

s
a1)2 h

i

,

−
a1)a1

−

s
a1)2 h

i

y
h

i∞ =

(29)

(30)

for the regime of convergence. A contour plot of
i∞ as a function of a1 and γb1 is shown in the left graph of Fig.
x
h
2. For the times tj of synaptic input being consistent with a Poisson process, it is shown in the Appendix that the
s
stimulus parameters a1, b1 lie on a parabola, plotted in the left graph of Fig. 2 for diﬀerent γ. The ratio
i
h
behaves then as shown in the right graph of the ﬁgure. Not surprisingly, the mean membrane potential is pulled closer
to the mean synaptic reversal potential
with increasing a1, that is, with increasing stimulus frequency, and with
increasing PSP amplitude γ.

i∞/
x
h

s
h

i

For γb1 < 4a1, the eigenvalues λ1/2 are complex conjugate. In Sec. III C, I will show that only then will the variance
converges in a damped oscillation. The dynamics is
V (t)
i
h

of V (t) converge. As depicted in Fig. 1, in this regime

solved straightforwardly. Let L be the matrix that diagonalizes M1, i.e., LM1L−1 is diagonal. Furthermore, let

Then the matrix KL is real and we can write the powers of M1 as

K :=

1 1
i

i

(cid:18)

−

(cid:19)

.

M j

1 = aj

1L−1K −1

cos(jφ)
sin(jφ)

sin(jφ)
−
cos(jφ)

(cid:18)

(cid:19)

KL , with φ := arg(λ1) .

The iteration dynamics (25) is solved by

x
i∞
h
y
i∞(cid:19)
(cid:18)
h
i∞ ,
x
that is, a spiral motion around the attractive focus (
h
synaptic input events,

x
ij
h
y
ij (cid:19)
(cid:18)
h

=

M j−1
1

−

x
i∞
h
y
i∞(cid:19)
(cid:18)
h

,

y
h

i∞). Its angular period is, measured in the number of

and averages in real time to

P =

2π
arg(λ1)

,

= P

T
h

i

.

r
h

i

T
Thus
i
h
function,

is the mean period of

. Moreover, it may be shown easily that P is the period of the covariance
V (t)
i
h

cov(xj , xj+k) :=

x
xj − h
ij
∞
(cid:17) (cid:16)
=

x
xj+k − h
ij+k
∞
dx
dy

∞

(cid:17)E
dx′

D(cid:16)

∞

−∞

Z

−∞

Z

−∞

Z

−∞

Z

where

dy′ pk(x, y

x′, y′) pj(x′, y′)
|

x

x
ij+k

− h

x′

x
ij

− h

,

(36)

(cid:16)

(cid:17) (cid:16)

(cid:17)

p1(x, y

x′, y′) :=
|

pk(x, y

x′, y′) :=
|

∞

∞

d¯x

d¯x

Z

−∞
∞

Z

−∞
∞

−∞

Z

−∞

Z

d¯y pR(x, y

x′, y′) ,
¯x, ¯y) pS (¯x, ¯y
|
|

d¯y p1(x, y

x′, y′)
¯x, ¯y) pk−1(¯x, ¯y
|
|

for k > 1.

In particular, the asymptotic covariance function limj→∞ cov(xj, xj+k) alternates between phases of correlation and
anticorrelation with period P . In Sec. III D, I will show that under certain stimulus conditions these oscillations of
the membrane potential never die out for individual realizations of the stochastic process. The damping of the mean
oscillation is then due to a loss of phase coherence with time.

For Poissonian stimulus times tj, the mean oscillation period is given by

T
τ

(cid:28)

(cid:29)

2π

2π

r
τ

r
τ

(cid:10)

(cid:10)

= 



(cid:11) . (cid:26)

arctan

√eγhr/τ i[(4−eγ)hr/τ i+4]
(2−eγ)hr/τ i+2

(cid:11) .

(cid:20)
π + arctan

√eγhr/τ i[(4−eγ)hr/τ i+4]
(2−eγ)hr/τ i+2

(cid:21)

for (2

eγ)

+ 2 > 0,

−

elsewhere;

r
τ

(cid:10)

(cid:11)

(cid:21)(cid:27)

(cid:20)
T /τ
h

cf. the Appendix. Figure 3 shows plots of
4/(eγ
4) or, equivalently, a1 < 1
mean period ends up on the curve

−

−

>
4/(eγ), the stimulus enters the regime where λ1/2 are real and negative, and the

for diﬀerent γ, both as a function of

and a1. For

r/τ
h

r/τ
h

i

i

i

(cid:28)
plotted with the dashed lines in Fig. 3. For
In particular,

(cid:29)
r/τ
h

(cid:18)

E

D
0 or, equivalently, a1 →

i →

can be much shorter than the rise time τ of PSPs.

T
h

i

T
τ

= 2

= 2

r
τ

1
a1 −

1

,

(cid:19)

1, we ﬁnd that

approaches zero.

T /τ
h

i

6

(31)

(32)

(33)

(34)

(35)

(37)

(38)

(39)

7

γ = 0.2

hT /τ i

20

hT /τ i

20

17.5

15

12.5

10

7.5

5

2.5

γ = 0.2

γ = 3.7

17.5

15

12.5

10

7.5

5

2.5

0.2

0.4

0.6

0.8

1

2

3

4

1
a1

γ = 3.7

5
hr/τ i

FIG. 3: Mean oscillation period hT i of the membrane potential in units of the rise time τ of PSPs [cf. Eq. (4)], plotted as
a function of the stimulus parameters a1 (left) and hr/τ i (right). For the curves we assume Poisson statistics for stimulus
times and γ = 0.2, 0.7, . . . , 3.7. The mean oscillation period lies on the dashed curves for a1 < 1 − 4/(eγ) or, equivalently,
hr/τ i > 4/(eγ − 4).

C. Variance of the membrane potential

To estimate whether the trajectories V (t) stay bounded when their mean converges to a ﬁnite value, we have to
check whether their variance converges as well. We will now analyze the dynamic map for the second moments of x
and y deﬁned in Sec. III A. From Eqs. (21) and (23), we obtain

x2
xy
(cid:10)
h
y2

(cid:10)

j
ij
(cid:11)
j

(cid:11)






=






a2 −
−

γb2 + γ2c2 b2 −
γa2 + γ2
a2 −
2 b2
γ2a2
−

2γc2
γb2
2γa2

c2
1
2 b2
a2

=:M2

x2
xy
(cid:10)
h
y2

j−1
ij−1
(cid:11)
j−1

(cid:10)

(cid:11)










uj−1
vj−1
wj−1

,





+














|

with the stimulus parameters

and

{z
1 =
(cid:11)

x2

(cid:10)

xy
h

i1 =

y2

}
1 = 0 ,
(cid:11)

(cid:10)

a2 :=
b2 :=
c2 :=

e−2r/τ
2r
τ e1−2r/τ

2

(cid:11)
e2−2r/τ
(cid:11)

r
τ

(cid:10)
(cid:10)
D(cid:0)

(cid:1)






E

(0, 1) ,

∈

uj

:=

vj

:=

wj

:=

2γ2c2

γb2 −
(cid:0)
γa2 −
2γ2a2 h
(cid:0)
s
−

y

ij + γ2c2
s
s
ij + 2γc2 h
x
h
i h
i h
1
(cid:1)
γ2b2
s
s
ij + γb2 h
x
ij +
y
2
h
i h
i h
ij + γ2a2
(cid:1)
y
s
ij + 2γa2 h
x
i h
i h

s2

γ2b2

s2

,

(cid:10)
s2

(cid:11)

,

(cid:10)
.

(cid:11)

ij and
x
h

The
ij converge to the values given in Eqs. (29) and (30) such that (uj, vj, wj) will become constant. To
check convergence of the second moments, it is thus necessary and suﬃcient to consider the eigenvalues of M2. These
are the roots of the characteristic polynomial

y
h

(cid:10)

(cid:11)

ν3

−

3a2 −
(cid:0)

2γb2 + γ2c2

ν2 +

3a2

2 −

γ2a2c2 −

2γa2b2 +

(cid:18)

(cid:1)

1
2

γ2b2
2

ν

−

(cid:19)

a3
2 = 0 ,

and are rather lengthy expressions which need not be spelled out here. Depending on the stimulus parameters a2, b2,
and c2, there are one real and two complex conjugate eigenvalues, or three real eigenvalues. Let ν1 be the eigenvalue
that is always real and ν2/3 the other two that may be complex conjugate or real. Stimulus parameters a2, b2, c2 that
yield a convergent second moment of V (t) are those that obey the constraints

ν1|
|

=: f1(a2, γb2, γ2c2) < 1 , max (
ν2|
|

,

ν3|
|

) =: f2(a2, γb2, γ2c2) < 1 ,

(40)

(41)

(42)

(43)

(44)

(45)

(46)

with continuous functions f1 and f2. The two surfaces deﬁned by

f1(a2, γb2, γ2c2) = 1 ,

f2(a2, γb2, γ2c2) = 1

are shown in Fig. 4. Since convergence is obviously ensured for γ = 0, which yields xj ≡
0 [cf. Eq. (12)], the
parameter region that results in convergence of the second moments is the space between the two surfaces that includes
the axis (a2, γb2, γ2c2) = (a2, 0, 0), a2 ∈
(0, 1). In the region beyond the intersection of the surfaces, i.e., for roughly
γ2c2 > 9, there are no combinations of parameters that yield convergent second moments.

yj ≡

For Poisson statistics of the stimulus times tj, the stimulus parameters a2, b2, c2 lie on the curves plotted in Fig.
4 for diﬀerent values of γ; cf. the Appendix. The curves run from (a2, γb2, γ2c2) = (0, 0, 0), the limiting point for
low input activity (
= 0). For γ
r
h
suﬃciently small, the curves lie completely within the region of convergence. For larger γ, they are in the region of
divergence except near the point (a2, γb2, γ2c2) = (0, 0, 0). For
1, which is the realistic regime for cortical
neurons, the eigenvalues ν2/3 are complex conjugate and we get

), to (a2, γb2, γ2c2) = (1, 0, 0), the limit of high-frequency stimulation (
r
h

r/τ
h

i ≪

∞

=

i

i

ν1 = 1

ν2/3

= 1

(cid:12)
(cid:12)

(cid:12)
(cid:12)

eγ
2
eγ
4

2

−

2 +

−

−

(cid:16)

(cid:16)

3/2

(cid:17) D

E

(cid:18)D

(cid:19)

E

3/2

r
τ
r
τ

+ O

+ O

r
τ
r
τ

(cid:17) D

E

(cid:18)D

E

(cid:19)

,

.

It follows that for
Fig. 4 shows that at least for γ
curves running between (a2, γb2, γ2c2) = (0, 0, 0) and (a2, γb2, γ2c2) = (1, 0, 0) in the parameter space.

1, it is necessary and suﬃcient for the second moments to converge that γ < 4/e. In fact,
, corresponding to the entire

1.2 the second moments converge for all 0 <

r/τ
h

r/τ
h

i ≪

∞

≤

<

i

As shown in the Appendix, the condition γ < 4/e is for Poisson statistics of the times tj equivalent to 4a1 > γb1
(0, 1). In the following, we will assume this condition to hold. The system is thus always in the regime of

for all a1 ∈
damped oscillations of

; cf. Fig. 1.
V (t)
i
h

After some lengthy but straightforward algebra, we ﬁnd for the asymptotic variance of x, and hence of V (t),

with coeﬃcients

lim
t→∞

var[V (t)] = var∞(x) :=

x2

(cid:10)

∞ − h
(cid:11)

2
∞ =
x
i

s2

ρ1 − h

s

2 ρ2 ,
i

2 + 2c2 −
a2) b2 + γ2b2

2a2c2
2

2γ2 (1 + a2) c2

(cid:1)
−

(cid:10)

(cid:11)

,

b2

γ2
a2)3 + 4γ (1
(cid:0)
−
2
γ2b1
a1)2 + γb1

2

ρ1 =

ρ2 =

2(1

−

(1

−

h

−

i
2γ2
a1 (1
a1)2 + γb1
(cid:2)

−

a1)

b2

2(1
(cid:0)
−

i h

(1

−

h

2a2c2

2 + 2c2 −
a2)3 + 4γ (1

+ b1 (b2 −
a2) b2 + γ2b2
(cid:1)

−

a2b2 −
−

2

2γc2)

2γ2 (1 + a2) c2

(cid:3)

.

i

For Poisson statistics of the stimulus times tj, the coeﬃcients ρ1/2 simplify to

ρ1 =

ρ2 =

(eγ)2
(eγ)2 + 4

r/τ
i
h
(eγ)3 (eγ + 2
r/τ
h

(eγ)2 + 4

i

4eγ

−

[4eγ

−

> 0 ,

)

r/τ
h
] (eγ +

i

)2 > 0 ;

r/τ
h

i

cf. the Appendix.

8

(47)

(48)

(49)

(50)

(51)

(52)

(53)

(54)

D. Stationary states, ﬂuctuations, and noise-driven oscillations

We have seen in the two previous sections that there is a region of stimulus parameters where the mean and variance
of V (t) converge to ﬁnite values. Averages do not tell us, however, what individual trajectories V (t) look like. In this
section we want to gain insight into the temporal pattern of individual trajectories.

9

FIG. 4: Three diﬀerent views of the two surfaces
deﬁned in Eq. (47) in the space of stimulus param-
eters a2, b2, and c2. The region of parameters that
result in convergence of the second moment of the
membrane potential is the space between the two
surfaces that includes the a2 axis. Parameters for
Poissonian stimulus times lie on the thick curves
for γ = 0.2, 0.7, . . . , 3.7. The graphs show that
convergence is ensured for all Poissonian stimuli,
if γ ≤ 1.2.

hr/τ i = 0.001

hr/τ i = 0.01

hr/τ i = 0.1

10

(55)

(56)

(57)

∆s = 0.1 hsi

∆s = hsi

∆s = 10 hsi

2

4

6

2

4

6

2

4

6

5

10

15

5

10

15

5

10

15

V

hsi

0

20

40

20

40

60

20

40

60

60

t/τ

FIG. 5: Typical trajectories of the membrane potential V (t), simulated for various stimulus conditions as indicated by the row
and column labels of the array of graphs. The unit of time is the rise time τ of PSPs [cf. Eq. (4)]. Synaptic reversal potentials
are uniformly distributed in the intervals [hsi − ∆s, hsi + ∆s]. The membrane potentials V = 0 (resting potential) and V = hsi
are indicated in each graph by the solid and dashed lines, respectively. The graphs show the transitions between stationary,
ﬂuctuating, and oscillatory dynamics of V (t) as discussed in the main text. The PSP-amplitude factor γ = 0.1 for all graphs.

Let us ﬁrst deal with the short-time behavior of individual trajectories (xj , yj). We ask what they look like for the

ﬁrst few j, that is, the ﬁrst few synaptic inputs. The variances

are zero initially. They increase to ﬁnite values no faster than the fastest-growing linear combination of second
moments, i.e., like e−j/Q with

varj(x) :=

x2

2
j ,

x
i

j − h
(cid:11)

(cid:10)

varj(y) :=

y2

y

2
j
i

j − h
(cid:11)

(cid:10)

.

Q =

1

−

ln

(cid:30)

(cid:18)

min
i=1,2,3 |

νi|
(cid:19)

ij ,
x
We have to compare Q to the period P of the oscillation of the mean values (
h
oscillation shows up in individual realizations (xj , yj). From Eqs. (34), (48), and (49) we obtain

ij) in order to see whether this

y
h

P
Q

=

(8 + eγ)π
2(eγ)1/2

r
τ

1/2

+ O

r
τ

.

D

(cid:16)D
1 and the oscillation of the means

E(cid:17)

E

i

r/τ
h

suﬃciently small, we get P/Q

Thus for
ij is fast as compared
to the growth time of the ﬂuctuations varj(x), varj(y) around the means. Individual realizations (xj, yj) are then
well described by their means for several periods of the oscillation. Put diﬀerently, an oscillation with a mean period
, ﬂuctuations
given by Eq. (38) then shows up in individual realizations V (t). With longer interstimulus times
i
increasingly interfere with the oscillation. The transition from an oscillation-dominated to a ﬂuctuation-dominated
dynamics of V (t) is depicted in Fig. 5.

ij ,
x
h

r/τ
h

y
h

≪

It remains to establish the long-time behavior of trajectories (xj, yj). The dynamics (33) of their mean value
i∞). Without damping of the oscillation, the trajectories would lie on orbits deﬁned

y
h

i∞,
x
spirals into the point (
h
i∞) = const, with the quadratic form
i∞, y
x
by q(x
(ξ, η), (KL)†KL(ξ, η)

q(ξ, η) :=

y
− h

− h

4γa1ξη + 4a1η2 .

(58)

(cid:10)

=

4γa2

1ξ2
b1 −

(cid:11)

To estimate the true degree of damping of individual trajectories (xj , yj), we calculate the mean asymptotic ratio
i∞) of the quadratic form q. From Eq. (40) we obtain the three
i∞,
x
q/q0i∞ with the initial value q0 := q(
h
h
y2
x2
i∞. After some lengthy but
i∞ which are needed for the calculation of
i∞,
second moments
h
h
straightforward algebra, we ﬁnd

i∞, and

xy
h

y
h

q
h

where the coeﬃcients are for Poisson statistics of synaptic input times tj,

q
q0 (cid:29)∞

(cid:28)

s2

=

2 ¯ρ1 −
s
(cid:11)h
(cid:10)
i

¯ρ2 ,

¯ρ1 =

¯ρ2 =

2 (eγ +

)2
r/τ
i
h
(eγ)2 + 4
r/τ
h
)
r/τ
i
h
r/τ
h

(eγ)2 + 4

i

i

4eγ

4eγ

−

−

2eγ(eγ + 2

> 0 ,

> 0 ;

cf. the Appendix. For var(s) =

s2
h

s
i − h

2 = 0, it follows that
i

q
q0 (cid:29)∞

(cid:28)

= ¯ρ1 −

¯ρ2 =

4eγ

2

2
r/τ
h
(eγ)2 + 4

i

−

<

1
2

r
τ

D

E

1 .

≪

r/τ
h

i

q/q0i∞ ≫
h

Hence there is strong damping, and individual trajectories (xj , yj) converge close to the steady mean state, if synaptic
currents have all the same reversal potential. On the other hand, for var(s)/
1, we
get
1 and there is no damping of individual trajectories (xj , yj). Since the dynamics is a temporally
homogeneous Markov chain, at any time we then ﬁnd qualitatively the same situation as at the start of the process.
Thus there is no qualitative change in the trajectories (xj , yj) on a long time scale, and the pattern of evolution, random
ﬂuctuations or oscillations, that dominates initially (see above) will also prevail at all times. Figure 5 summarizes the
types of dynamics of V (t), illustrating our results on short- and long-time behavior by computer simulations.

1, hence

s2
h

/
i

s
h

s
h

2
i

2
i

≫

≫

With synaptic reversal potentials sj having a high variance, we have seen individual trajectories V (t) to oscillate or
i∞. It is interesting to compare the mean of the intervals
x
h

ﬂuctuate persistently around the value limt→∞h
∆ = t

V (t)
i
t′ between successive times t > t′ deﬁned by

=

−

V (t) = V (t′) =

V (t) > 0 ,

V (t′) > 0 ,

i∞ ,
x

h

d
dt

d
dt

the mean “jitter period”, with the mean oscillation period
. I have measured jitter periods
V (t)
T
i
h
h
in computer simulations of V (t). As can be seen in Fig. 6, the match between the two periods is perfect for small
, when the
r/τ
h
i
random-walk component of membrane dynamics grows stronger (cf. Fig. 5), the mean jitter period drops below the
mean oscillation period, indicating that ﬂuctuations cause V (t) to jitter around its asymptotic mean value faster than
the oscillatory component of the dynamics alone.

, that is, in the regime where oscillations are rather regular. For increasing interstimulus times
i

[cf. Eq. (38)] of

r/τ
h

i

The conduction of synaptic currents in neuronal dendrites leads to delays relative to the time of the synaptic input.
Let us assume here that we can assign a delay di > 0 to a PSP initiated at time ti, such that at time ti + di the
response is spread out across the whole neuron. Of course, such a delay does not properly describe gradual PSP
propagation. In a sense, it is the opposite extreme of the instantaneous PSP propagation that we have considered so
far. The dynamics of the membrane potential with such delayed PSPs is given by

E. Delays

V (t) =

Λ(γi, si, ti; t

di) ;

−

∞

i=1
X

cf. Eq. (7). A reformulation as a Markov chain as in Sec. III A is now not possible. This fact calls for a reconsideration
of our previous results. Here I am concerned with proving structural stability of the dynamics analyzed above with
respect to small delay perturbations. To this end, we may extend the previous dynamics to incorporate ﬁrst-order
delay eﬀects. The issue of delays is covered in detail in [15] for a slightly more general class of dynamical system. In
this paper, I only sketch the way to proceed.

11

(59)

(60)

(61)

(62)

(63)

(64)

hT /τ i

h∆/τ i

4

3

2

1

0.02

0.04

0.06

0.08

0.1

hr/τ i

FIG. 6: Comparison of the mean oscillation period hT i of the membrane potential as given by Eq. (38) (solid line; cf. Fig. 3)
with the mean jitter period h∆i deﬁned in Eq. (63) as observed in computer simulations (box symbols; bars indicate standard
errors). The unit of time is the rise time τ of PSPs [cf. Eq. (4)]. The match between the two periods is perfect for small
hr/τ i, when oscillations are rather regular. As oscillations are increasingly degraded by ﬂuctuations for larger hr/τ i (cf. Fig. 5),
the mean jitter period drops below the mean oscillation period. In the simulations, synaptic reversal potentials are uniformly
distributed in an interval with hsi = 0; the PSP-amplitude factor γ = 0.1.

Expanding Eq. (64) to ﬁrst order in the delays di/τ , we have to note that Λ(γi, si, ti; t) is not diﬀerentiable at t = ti;

cf. Eq. (4). We can take advantage of the fact, however, that di > 0 and write

that is, we take the derivative of Λ(γi, si, ti; t) from lower values of t. Equation (65) is substituted into the dynamic
γi to obtain a model with a minimal
Eq. (64) and only terms up to ﬁrst order in di/τ are kept. As before, we use γ
set of variables. We can now transform to new dynamic variables xj := V (tj), yj, and zj that obey the stochastic
iteration

≡

Λ(γi, si, ti; t

di)

−

= Λ(γi, si, ti; t) + di

lim
d→0+

Λ(γi, si, ti; t)

−

Λ(γi, si, ti; t
d

+ O(d2
i )

= Λ(γi, si, ti; t) +

di
τ

1
(cid:18)

−

t
τ

(cid:19)

e1−t/τ Θ(t

ti) + O

−

,

"(cid:18)

#

(cid:19)

d)

2

−

di
τ

xj
yj
zj









=

R

′(rj−1)

′(sj−1, dj−1)

◦ S

,

x1 = y1 = z1 = 0 ,

xj−1
yj−1
zj−1









x
x)

′(s, d) :

S

′(r) :

R

x
y
z 


x
y
z 










7→ 

y + γ(s

−
z + γ(s



x + ey r

1 + d
τ
x) d
τ
(cid:1)
(cid:0)
−
e−r/τ
ez
τ −
ye−r/τ
ze−r/τ

(cid:1)

,

.









7→ 

(cid:0)



The dimension of the stochastic dynamic map is increased by one compared to the case without delays; cf. Eq. (12).
Treating Eq. (66) analogous to Eq. (12), we can derive dynamic maps for the moments of x, y, and z. These will have
accordingly higher dimensions than those for the moments of x and y without delays. This underlines the necessity
to check the structural stability of the dynamics derived previously.

It can be shown [15] that the dynamics for the ﬁrst and second moments of x and y is stable with respect to small

delay perturbations, provided that

γb2 < 2(a2 + 1)2 .

In general, this is a condition for convergence in the delayed system that is additional to those derived for the
undelayed system. For Poisson statistics of synaptic input times, however, we know that a2 and b2 lie on the parabola

12

(65)

(66)

(67)

(68)

(69)

13

b2 = ea2(1
the variance of V (t), this implies condition (69).

−

a2); see the Appendix. Together with the condition γ < 4/e derived in Sec. III C for the convergence of

By continuity of eigenvalues and asymptotic values in the delays within the extended model, it follows that for
small delays there is only a small quantitative and no qualitative change in membrane dynamics. All that has been
concluded on patterns of the dynamics hence remains true for small delays. Moreover, it can be shown that small
delays decrease the asymptotic attraction of
and increase the mean
of membrane oscillations [15].
period

to the mean synaptic reversal potential

V (t)
i
h

s
h

i

T /τ
h

i

IV. SUMMARY AND DISCUSSION

In this paper, I have analyzed the subthreshold dynamics of the neural membrane potential driven by stochastic
synaptic input of stationary statistics. Conditions on the input statistics for stability of the dynamics have been
derived. Regimes of input statistics for stationary, ﬂuctuating, and oscillatory dynamics have been identiﬁed. For the
case of Poissonian stimulus times, that is, temporal noise, it has turned out that persistent oscillations can develop
with a mean period that depends nontrivially on the mean interstimulus time. In particular, noise-driven oscillations
occur in the absence of any pace-making mechanism in the stimulus, in the intrinsic neural dynamics, or in a recurrent
neural network.

What does it mean for a real neuron, if its membrane potential is “unstable” under stimulation by the network’s
synaptic input? As the analysis has shown, instability of the ﬁrst or second moments implies excursions of V (t) with
growing positive and negative amplitudes. After some stochastic period of time, therefore, the membrane potential
will certainly cross the threshold for ﬁring. The neuron will then be set to a post-spike potential that depends in
some way on the stimulus history and the process will resume.

I have neglected many eﬀects in the modeling for the sake of analytical feasibility. Most notably, PSPs have been
given a shape that does not properly reﬂect conduction in neuronal dendrites. One shortcoming is a lack of variability
of PSP shape; see, however, [7, 9, 19]. Another is that real neuronal membranes contain ionic conductances which are
voltage-gated [14]. Their eﬀect is to modify the shape of PSPs in a voltage-dependent manner as they are propagated
along a dendrite; see, e.g., [1]. Moreover, with voltage-gated channels, PSPs do not simply add up but interact
nonlinearly. The conclusions drawn in the present paper, therefore, can only be on qualitative system behavior and
should not be understood quantitatively.

In the analyzed model, there is no representation of the spatial dimensions of a neuron. For a neuron where spatial
conduction times are signiﬁcant, the present results suggest that spatiotemporal waves of membrane potential develop
in the regime of noise-driven oscillations. For the generation of action potentials, however, all that matters is the
potential at the cell’s soma.

A. Oscillations in stochastic systems

It is a common example in textbooks on stochastic dynamical systems to calculate stationary densities for a
damped harmonic oscillator subject to an external stochastic force; see, e.g., [17]. If the damped oscillator is in the
periodic regime, the intrinsic oscillations are sustained by the stochastic force. In the context of biological systems,
stochastically sustained oscillations have been analyzed, somewhat heuristically, for the population dynamics of an
epidemic model [2]. This system is autonomous and an intrinsic oscillator. The stochastic nature of the dynamics
prevents asymptotic convergence to a steady state.

It is thus a known generic property of periodic relaxation systems to exhibit oscillations at their intrinsic frequency,
sustained by some stochastic inﬂuence. The dynamics analyzed in this paper, however, represents a diﬀerent type
of phenomenon. The system studied is not an intrinsic oscillator but exhibits oscillations at a mean period that is,
up to a temporal scale, determined by the stochastic drive alone. The system can be formally viewed as a control
loop where a sequence of brief signals (the synaptic reversal potentials sj) controls via a slow response (the PSPs) a
dynamic variable [the membrane potential V (t)]. The theme of the control loop is fully developed in [15, 16].

B. Oscillations in neural systems

Oscillations of membrane potential and spiking activity are quite ordinary in the neural systems of the brain. They
arise under various conditions, with varying degree of correlation between neurons, and in a wide range of frequencies.
Their functional implications may be equally various and are much debated today.

V

V

14

V

sdep

0

shyp

1000

1500

t/τ

1000

1500

t/τ

1000

1500

t/τ

FIG. 7: Demonstration of hyperpolarization-induced activity. The three graphs show long-time simulations of the membrane
potential V (t). Transients at the start of the simulation are cut oﬀ. The unit of time is the rise time τ of PSPs [cf. Eq. (4)].
Depolarizing synaptic input is applied with mean interstimulus time hr/τ i = 0.1 and reversal potential sdep > 0 as indicated
by the upper dashed line in each graph. There is no hyperpolarizing synaptic input for the left graph; for the central graph
there is hyperpolarization with hr/τ i = 0.5; for the right graph with hr/τ i = 0.1. The hyperpolarizing reversal potential is
shyp = −sdep < 0 as indicated by the lower dashed line in each graph. If the threshold for spike generation is assumed close
to sdep, there will be no spikes for the case without hyperpolarizing input (left), a few spikes for weak hyperpolarizing input
(center), and again no spikes for equal hyperpolarizing and depolarizing input (right). The PSP-amplitude factor γ = 0.1 for
all graphs.

Explanations of oscillations have been basically of two kinds. One is in terms of intrinsic oscillator cells that act
as a pacemaker for rhythmic activity in the network [12, 29]. The other makes reference to the fact that recurrent
neural networks have a natural tendency to produce rhythmic and synchronized activity [5, 11].

Some of neural oscillations are most probably generated by the intrinsic neural dynamics of ion channels. Others
are propagated by synaptic potentials and are of less certain origin. A prominent example of the latter kind are
cortical oscillations in the gamma frequency band (roughly 20–90 Hz). Cortical gamma oscillations are mostly evoked
by a sensory stimulus. Thus, spontaneous activity in the visual cortex of awake cats and primates is rarely oscillatory,
whereas visual stimuli of increasing speed of motion produce subthreshold and suprathreshold oscillations of increasing
frequency [4, 6, 10, 13, 20, 21].

The results presented here suggest that oscillations of the neural membrane potential can arise from the network’s
background activity. Let us assume that a stimulus evokes responses in neurons of a coupled system at a rate that
increases with stimulus speed, because more neurons in the network are stimulated per time at higher speeds [32].
The observed dependence of oscillations on a stimulus is then predicted by Sec. III D, the relation between oscillation
period and stimulus speed by Eq. (38). Note that the conditions
1 for the development
of noise-driven oscillations are probably fulﬁlled under external stimulation of a network of cortical neurons, each
receiving roughly 10000 synapses of both an excitatory and inhibitory kind [8]. The degree of correlation between
neurons that is to be expected from noise-driven oscillations increases with the extent to which they share common
input from the network’s background activity. Correlations should, therefore, decrease with distance between neurons,
in agreement with what is generally observed. In a network of spike-exchanging neurons, however, correlations can
even arise between neurons that do not share any input.

1 and var(s)/

r/τ
h

i ≪

s
h

2
i

≫

The present analysis draws attention to a phenomenon, noise-driven oscillations, that should be very common in

neural systems and may be the cause of some of the observed membrane-potential oscillations.

C. Hyperpolarization-induced activity

There is an interesting consequence of the analytical results. It is, at ﬁrst sight, somewhat counterintuitive. Consider
a neuron that receives depolarizing synaptic input at a ﬁxed average rate. Let us assume that at this level of
depolarization the membrane potential remains mostly below the threshold for spike generation. Now, if we add
some hyperpolarizing synaptic input, it turns out that the neuron may actually start spiking. Further increase of the
hyperpolarizing input rate eventually shuts neural activity oﬀ. This scenario is demonstrated in computer simulations
shown in Fig. 7.

The eﬀect seems to be at odds with the usual notion of hyperpolarizing synapses to inhibit neural activity rather than
promote it. Exceptions have only been reported for cases where a hyperpolarization-activated current repolarizes the
cell, giving rise to a rebound burst of action potentials; see, e.g., [18, 22]. The eﬀect demonstrated here is of a diﬀerent
nature. It results from an increase of membrane ﬂuctuations with the addition of hyperpolarizing synaptic input; cf.
Eq. (50). For a range of hyperpolarizing input rates, increased ﬂuctuations are likely to spontaneously overcome the
associated drop in mean membrane potential; cf. Eq. (29). The result is ﬂuctuation-driven spike generation.

15

(A1)

(A4)

(A5)

The phenomenon of hyperpolarization-induced activity oﬀers a subtle way in which neural spiking may be controlled.

Whether it is actually used in the brain is unexplored today.

APPENDIX A

u(r) =

e−r/hri
r
h

i

.

It is reasonable to assume the times tj at which synaptic inputs are received by a cortical neuron from other cortical

neurons to obey Poisson statistics. For the density u of interstimulus times r this means

In order to transform the stimulus parameters ai, bi, ci introduced in Eqs. (26) and (41), and to reveal dependences
between them, we calculate the mean values

k

r
τ

(cid:28)(cid:16)

(cid:17)

e−r/τ

=

(cid:29)

−

(cid:18)

k

∂
∂α

(cid:19)

D

e−αr/τ

k

∞

∂
∂α

=

−

(cid:18)

(cid:19)

0
Z

dr u(r) e−αr/τ

α=1

E

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Hence the stimulus parameters turn out to be

a1 =

1 +

1
r/τ
h

i

,

b1 =

e

r/τ
h
(1 +

i
r/τ
h

i

)2 ,

(cid:12)
α=1
(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

k

∂
∂α

(cid:19)

−

(cid:18)

1
1 + α

.

(A2)

r/τ

h

α=1

i (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(A3)

a2 =

1
1 + 2

r/τ
h

i

,

b2 =

2e

r/τ
h
(1 + 2

i
r/τ
h

i

)2 ,

c2 =

2e2
r/τ
h
(1 + 2

i
r/τ
h

2

i

)3 .

Dependences between these parameters are now explicit. In particular, we have

In Sec. III C, we have established that for Poisson statistics and small

the necessary and suﬃcient condition

for the second moment of V (t) to converge is γ < 4/e. Multiplying Eq. (A4) by γ, we see that this bound implies

r/τ
h

i

bi = e ai (1

ai) ,

i = 1, 2 .

−

Conversely, γbi < 4ai for all ai ∈

γbi < 4 ai (1

ai) < 4 ai

−

for ai ∈

(0, 1), i = 1, 2.

(0, 1) together with Eq. (A4) implies γ < 4/e.

[1] M Andreasen and J D Lambert. Somatic ampliﬁcation of distally generated subthreshold EPSPs in rat hippocampal

pyramidal neurones. J. Physiol. (London), 519:85–100, 1999.

[2] J P Aparicio and H G Solari. Sustained oscillations in stochastic systems. Math. Biosci., 169:15–25, 2001.
[3] R Azouz and C M Gray. Cellular mechanisms contributing to response variability of cortical neurons in vivo. J. Neurosci.,

19:2209–2223, 1999.

[4] V Bringuier, Y Fregnac, A Baranyi, D Debanne, and D E Shulz. Synaptic origin and stimulus dependency of neuronal

oscillatory activity in the primary visual cortex of the cat. J. Physiol. (London), 500:751–774, 1997.

[5] N Brunel and V Hakim. Fast global oscillations in networks of integrate-and-ﬁre neurons with low ﬁring rates. Neural

Comput., 11:1621–1671, 1999.

[6] M Castelo-Branco, S Neuenschwander, and W Singer. Synchronization of visual responses between the cortex, lateral

geniculate nucleus, and retina in the anesthetized cat. J. Neurosci., 18:6395–6410, 1998.

[7] R A Chitwood, A Hubbard, and D B Jaﬀe. Passive electrotonic properties of rat hippocampal CA3 interneurones. J.

[8] J Defelipe and I Fari˜nas. The pyramidal neuron of the cerebral cortex: morphological and chemical characteristics of the

[9] A Destexhe and D Pare. Impact of network activity on the integrative properties of neocortical pyramidal neurons in vivo.

Physiol. (London), 515:743–756, 1999.

synaptic inputs. Prog. Neurobiol., 39:563–607, 1992.

J. Neurophysiol., 81:1531–1547, 1999.

16

Neurosci., 17:107–118, 2000.

J. Neurophysiol., 68:1373–1383, 1992.

Neurophysiol., 82:3268–3285, 1999.

Science, 257:552–554, 1992.

[10] S Friedman-Hill, P E Maldonado, and C M Gray. Dynamics of striate cortical activity in the alert macaque: I. incidence

and stimulus-dependence of gamma-band neuronal oscillations. Cereb. Cortex, 10:1105–1116, 2000.

[11] W Gerstner, J L van Hemmen, and J D Cowan. What matters in neuronal locking? Neural Comput., 8:1653–1676, 1996.
[12] C M Gray and D A McCormick. Chattering cells: superﬁcial pyramidal neurons contributing to the generation of syn-

chronous oscillations in the visual cortex. Science, 274:109–113, 1996.

[13] C M Gray and G Viana Di Prisco. Stimulus-dependent neuronal oscillations and local synchronization in striate cortex of

the alert cat. J. Neurosci., 17:3239–3253, 1997.

[14] B Hille. Ionic Channels of Excitable Membranes. Sinauer Associates Inc., Sunderland, MA, 1992.
[15] U Hillenbrand. Spatiotemporal Adaptation in the Corticogeniculate Loop. Doctoral thesis, Technische Universit¨at M¨unchen,

2001, http://tumb1.biblio.tu-muenchen.de/publ/diss/ph/2001/hillenbrand.pdf.

[16] U Hillenbrand and J L van Hemmen. Spatiotemporal adaptation through corticothalamic loops: A hypothesis. Vis.

[17] J Honerkamp. Stochastic Dynamical Systems: Concepts, Numerical Methods, Data Analysis. Wiley, New York, NY, 1994.
[18] J R Huguenard and D A McCormick. Simulation of the currents involved in rythmic oscillations in thalamic relay neurons.

[19] D B Jaﬀe and N T Carnevale. Passive normalization of synaptic integration inﬂuenced by dendritic architecture. J.

[20] B Jagadeesh, C M Gray, and D Ferster. Visually evoked oscillations of membrane potential in cells of cat visual cortex.

[21] P E Maldonado, S Friedman-Hill, and C M Gray. Dynamics of striate cortical activity in the alert macaque: II. fast time

scale synchronization. Cereb. Cortex, 10:1117–1131, 2000.

[22] D A McCormick and J R Huguenard. A model of the electrophysiological properties of thalamocortical relay neurons. J.

Neurophysiol., 68:1384–1400, 1992.

[23] D Par´e, E Shink, H Gaudreau, A Destexhe, and E J Lang. Impact of spontaneous synaptic activity on the resting properties

of cat neocortical pyramidal neurons in vivo. J. Neurophysiol., 79:1450–1460, 1998.

[24] W Rall. Theory of physiological properties of dendrites. Ann. NY Acad. Sci., 96:1071–1092, 1962.
[25] W Rall. Cable properties of dendrites and eﬀects of synaptic location. In P Andersen and J K S Jansen, editors, Excitatory

Synaptic Mechanisms, pages 175–187. Universitetsforlaget, Oslo, Norway, 1970.

[26] W Rall. Core conductor theory and cable properties of neurons. In Handbook of Physiology. The Nervous System. Cellular

Biology of Neurons, volume 1, pages 39–97. Am. Physiol. Soc., Bethesda, MD, 1977.

[27] M Steriade. Cortical long-axoned cells and putative interneurons during the sleep-waking cycle. Behav. Brain Sci., 3:465–

514, 1978.

[28] M Steriade, M Deschˆenes, and G Oakson. Inhibitory processes and interneuronal apparatus in motor cortex during sleep
and waking. I. Background ﬁring and responsiveness of pyramidal tract neurons and interneurons. J. Neurophysiol.,
37:1065–1092, 1974.

[29] M Steriade, D A McCormick, and T J Sejnowski. Thalamocortical oscillations in the sleeping and aroused brain. Science,

[30] H C Tuckwell. Introduction to Theoretical Neurobiology, Volume 1: Linear Cable Theory and Dendritic Structure. Cam-

262:679–685, 1993.

bridge University Press, Cambridge, 1988.

[31] Conduction times of ionotropic synapses are roughly 1 ms, while the membrane time constant is usually several 10 ms [14].
The other type of synapse, the metabotropic synapse, modulates the membrane potential on a much longer time scale of
seconds [14] and is not considered here.

[32] Diﬀerent individual neurons respond best at diﬀerent stimulus speeds, a property called speed tuning. For the complete

coupled system, however, we may neglect eﬀects of speed tuning.

