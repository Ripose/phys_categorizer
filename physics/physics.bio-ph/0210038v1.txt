2
0
0
2
 
t
c
O
 
8
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
8
3
0
0
1
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

The Iterative Signature Algorithm for the analysis of
large scale gene expression data

Sven Bergmann, Jan Ihmels and Naama Barkai∗

Department of Molecular Genetics, Weizmann Institute of Science, Rehovot 76100, Israel

February 2, 2008

Abstract

We present a new approach for the analysis of genome-wide expression data. Our
method is designed to overcome the limitations of traditional techniques, when ap-
plied to large-scale data. Rather than alloting each gene to a single cluster, we assign
both genes and conditions to context-dependent and potentially overlapping tran-
scription modules. We provide a rigorous deﬁnition of a transcription module as the
object to be retrieved from the expression data. An eﬃcient algorithm, that searches
for the modules encoded in the data by iteratively reﬁning sets of genes and conditions
until they match this deﬁnition, is established. Each iteration involves a linear map,
induced by the normalized expression matrix, followed by the application of a thresh-
old function. We argue that our method is in fact a generalization of Singular Value
Decomposition, which corresponds to the special case where no threshold is applied.
We show analytically that for noisy expression data our approach leads to better
classiﬁcation due to the implementation of the threshold. This result is conﬁrmed
by numerical analyses based on in-silico expression data. We discuss brieﬂy results
obtained by applying our algorithm to expression data from the yeast S. cerevisiae.

∗Correspondence should be addressed to: Naama.Barkai@weizmann.ac.il

1

1 Introduction

DNA microarray experiments monitor the expression levels of thousands of genes simul-
taneously [1, 2, 3, 4]. Using this technology, large sets of genome-wide expression data
have been accumulated [5]. For example, the expression levels of the entire yeast genome
(comprising
6200 genes) have been measured for more than 1000 diﬀerent experimental
conditions [6]. A large number of DNA chip experiments have also been carried out for
higher eukaryotes, such as the nematode C. elegans and the fruit ﬂy Drosophila, as well as
for a variety of both normal and malignant human tissues.

∼

While large scale expression data have the potential to reveal new insights into the
transcriptional network that controls gene expression, they also give rise to a major com-
putational challenge: How can one make sense of the massive expression data containing
millions of numbers? The classiﬁcation of the genes and the experimental conditions is an
essential ﬁrst step in reducing the complexity of such data. However, while standard tools,
like clustering algorithms [7, 8, 9, 10, 11, 12, 13, 14] (see [15, 16] for reviews) and Singular
Value Decomposition (SVD) [17, 18], provide interesting results when applied to relatively
small data sets, typically containing tens of experimental conditions and at most several
In
hundred genes, these methods are of limited use for the analysis of large data sets.
particular, a well-recognized drawback of commonly used clustering algorithms is the fact
that they assign each gene to a single cluster, while in fact genes that participate in several
functions should be included in multiple clusters [19, 20, 21, 22]. Moreover, both in stan-
dard clustering methods and SVD, genes are analyzed based on their expression under all
experimental conditions. This is problematic, since cellular processes are usually aﬀected
only by a small subset of these conditions, such that most conditions do not contribute
relevant information but rather increase the level of background noise.

In a recent paper [23] we introduced a new method for the analysis of large-scale
gene expression data that was designed to overcome the above-mentioned problems (see
Refs. [21, 22] for other recent approaches). A central idea of this work was to integrate
prior biological information, like the function or sequence of known genes, into the analysis
of the gene expression data. In the present article we present a complementary method
for the analysis of large-scale data that does not require any prior knowledge beyond the
expression data. We start by providing a rigorous deﬁnition of the type of information
we aim to extract from the expression data by introducing the notion of a transcription
module (TM). A TM contains both a set of genes and a set of experimental conditions.
The conditions of the TM induce a co-regulated expression of the genes belonging to this
TM. That is, the expression proﬁles of the genes in the TM are the most similar to each
other when compared over the conditions of the TM. Conversely, the patterns of gene
expression obtained under the conditions of the TM are the most similar to each other
when compared only over the genes of the TM. The degree of similarity is determined
by a pair of threshold parameters. The gene threshold constrains the gene set, while
the condition threshold constrains the condition set. Importantly, distinct transcription

2

modules may share common genes and conditions.

The precise deﬁnition of a TM as the object to be retrieved from the expression data
allows us to establish an eﬃcient algorithm that searches for the modules encoded in the
data. Starting from a set of randomly selected genes (or conditions) one iteratively reﬁnes
the genes and conditions until they match the deﬁnition of a TM. Using a suﬃciently
large number of initial sets it is possible to determine all the modules corresponding to a
particular pair of thresholds. Scanning through a range of thresholds decomposes the data
into modules at diﬀerent resolutions.

This paper is organized as follows: In section 2 we provide a mathematical deﬁnition
of a transcription module. In section 3 we introduce our algorithm that searches for such
modules and compare our method with SVD. In section 4 we discuss the normalization of
the expression data. In section 5 we present analytical insight into the role of the threshold
in our algorithm. We show that for noisy expression data the application of a threshold
improves signiﬁcantly the identiﬁcation of transcription modules. We provide an estimate
for the maximal amount of noise for which a successful identiﬁcation is still possible. In
section 6 we compare our method with other standard tools using in-silico expression data.
In section 7 we discuss brieﬂy results obtained by applying our algorithm to real expression
data from the yeast S. cerevisiae. We conclude in section 8.

2 Formalism

2.1 The Expression Matrix

We consider data from microarray experiments given in terms of a gene expression ma-
trix E. The matrix element Ecg denotes the log-fold expression-change of gene g
≡
, where NG and NC refer to
1, ..., NG}
{
∈
the total number of genes and conditions, respectively. The matrix E may be viewed as a
collection of NC row vectors:

at the experimental condition c

1, ..., NC}

≡ {

G

C

∈

c = (g(1)
c

Each vector gT
the expression levels g(g)
Alternatively the expression matrix can be viewed as a collection of NG column vectors:

, g(2)
) describes the gene-proﬁle for condition c, containing
c
c = Ecg of all the genes that were monitored under this condition.

, ..., g(NG)
c

Here each vector cg = (c(1)
g , c(2)
taining the expression levels c(c)
set.

g , ..., c(NC )
)T describes the condition-proﬁle for gene g, con-
g = Ecg of this gene under all the conditions of the data

g

(1)

(2)

gT
1
gT
2
...
gT

NC

.









E = 






E = ( c1, c2, . . . , cNG ) .

3

We deﬁne two normalized expression matrices (c.f. section 4)

EG ≡

ˆgT
1
ˆgT
2
...
ˆgT

NC

















EC ≡

(ˆc1, ˆc2, ..., ˆcNG) .

(3)

(4)

and

The rows of EG and the columns of EC are given in terms of the normalized gene- and
condition-vectors

,

|

=

and

ˆcg|

ˆcg ≡

ˆgc ≡

gc − h
gc − h

gcig∈G
gcig∈G|

cgic∈C
cgic∈C|

= 1). This normalization implies that

cg − h
cg − h
|
ˆgcig∈G =
ˆcgic∈C = 0) and unit length
respectively. These vectors have zero mean (
h
h
ˆEcg
G )2 = 1 for each
ˆgc|
G = 0,
(
|
|
C )2 = 1 for each gene g. Centering and re-scaling
condition c and
the rows in EG allows for a meaningful comparison between any two conditions c and c′
through their associated gene-proﬁles ˆgc and ˆgc′. Similarly, centering and re-scaling the
columns in EC allows for the comparison of any two genes g and g′ through their associated
condition-proﬁles ˆcg and ˆcg′. Note that the normalized matrices EG and EC in general
are not equal.

C = 0,

g( ˆEcg

c( ˆEcg

ˆEcg

(5)

P

P

P

P

g

c

2.2 Transcription Modules

Gm, Cm}

G, together with the relevant experi-
Our goal is to ﬁnd sets of co-regulated genes Gm ⊂
C that induce their co-regulation. We refer to such a combined
mental conditions Cm ⊂
, as a transcription module (TM). Here the index m ranges between
set, Mm =
{
one and the number of transcription modules, NM . Biologically a TM may be associated
with a particular cellular function. Ideally each TM would correspond to a transcription
factor that regulates the genes in Gm and that is activated under the conditions in Cm.
Of course, a one-to-one correspondence between transcription modules and transcription
factors is an over-simpliﬁcation, but it can still provide useful insight into the nature of
the expression data. First, the total number of transcription factors, NT F , is much smaller
NG. Thus we expect also the number of transcription
than the number of genes: NT F ≪
modules, and therefore the eﬀective dimensionality of the expression matrix to be rela-
tively small: NM ≪
NG. Second, the number of genes activated by a single transcription
factor, N (m)
NG. Third, diﬀerent transcription factors
G ≪
can regulate the same gene and can be activated under the same experimental conditions.
Hence distinct modules may share common genes and conditions.

G , is known to be limited: N (m)

4

Mathematically a TM can be deﬁned as follows:

,

h

o

o

∈

∈



(6)

C :

G :

Gm(Cm) =

Cm(Gm) =

(TC, TG) : 
∃


Ecg
G ig∈Gm > TC
Ecg
C ic∈Cm > TG
h

c
n
g
n
where TC and TG are two threshold parameters. The above deﬁnition states that for each
Ecg
condition c in the TM the average expression level of the genes in the TM,
G ig∈Gm, is
above a certain threshold TC. Conversely, for each gene g in the TM the average expression
Ecg
C ic∈Cm, is also above some threshold TG. This
level over the conditions of the TM,
h
reciprocal dependence between the genes and the conditions associated with a TM implies
that, considering only the genes of the module, the conditions of the module are exactly
those for which the co-expression is the most stringent. Similarly, considering only the
conditions of the module, the genes of the module are the most tightly co-regulated. Note
that our deﬁnition of a TM is symmetric with respect to genes and conditions, such that
no preference is given to either of them. In particular, we use the expression matrix EG
(normalized with respect to genes) in order to specify the conditions of the module (Cm),
given the genes of the module (Gm). Similarly we use EC (normalized with respect to
conditions) to specify the genes in Gm, given the conditions in Cm.

h

We would like to reformulate and somewhat generalize the deﬁnition of a TM in eq. (6)
by introducing vector notation. To this end we represent the genes and the conditions of
m )T and a condition-vector cm =
a TM by a pair of a gene-vector gm = (g(1)
m , g(2)
(c(1)
m )T . A non-zero component g(g)
m ) implies that the gene g (condition
c) is associated with the module m. Consider the linear transformations

m , ..., g(NG)
m (c(c)

m , ..., c(NC )

m , c(2)

cproj
m ≡

EG gm = 






ˆgT
1 gm
ˆgT
2 gm
...
ˆgT
NC gm









and

gproj
m ≡

ET

ˆcT
1 cm
ˆcT
2 cm
...
ˆcT
NGcm

.









Ccm = 






The resulting vectors contain the projections of the vectors gm and cm, that specify the
, deﬁned
TM, onto the set of the (normalized) gene-proﬁles
in eq. (5), that describe the expression data. For a binary vector gm the components of
cproj
m are just the expression levels summed over the genes of the TM for each condition in
the data set. Likewise for a binary vector cm the components of gproj
m are the expression
levels summed over the conditions of the module for each gene.

and condition-proﬁles

ˆgc}

ˆcg}

{

{

The consistency requirement in eq. (6) can then be written as

(7)

(8)

where tC and tG are the condition- and the gene-threshold, related to TC and TG, respec-

(tC, tG) :

∃

cm = ftC (cproj
m )
gm = ftG(gproj
m )

(

,

5

tively. The threshold function

ft(x)

w(x1)

≡ 



w(xNx)

t)

Θ(˜x1 −
...
Θ(˜xNx −

·

·

t)






(9)

i

h

Nx

qP

acts separately on each of the Nx components xi of the vector x and yields the prod-
ucts of a weight-function w(x) and a step-function Θ(x) as output. The arguments of
µ(x))/σ(x), have been centered and re-scaled. We use
the step-function, ˜xi = (xi −
the mean as center, µ(x) =
x
, and the expected or measured standard deviation,
i
σ(x) =
x
)2/Nx, as scale-factor. The step-function sets to zero all elements
i (xi − h
of the vector x that do not exceed µ(x) by at least t
σ(x). (Down-regulation can be
in eq. (9).) Using w(x) = 1 as weight-function all the sig-
captured by replacing ˜xi → |
niﬁcant elements are set to unity. This binary formulation corresponds to the consistency
requirement in eq. (6). (To capture down-regulation one uses sign(x) as weight-function.)
It is straightforward to extend our formalism using diﬀerent weight-functions. In this case
the entries of the gene- and condition-vector become continuous, and their value deter-
mines the signiﬁcance of a particular gene or condition, respectively. As we shall see, a
particularly relevant choice is w(x) = x in which case ft(x) is semi-linear.

˜xi|

·

m results in a non-zero component c(c)

The compact deﬁnition of a TM in eq. (8) can be understood as follows: Applying
the threshold function ftC to cproj
m of the module’s
condition-vector cm, if the corresponding gene-proﬁle ˆgc is suﬃciently aligned with the
gene-vector gm of the module. Biologically this means that a signiﬁcant fraction of the
genes in the module are co-regulated under condition c. Similarly, the application of
ftG to gproj
m in the module’s gene-vector gm, if the
corresponding condition-proﬁle ˆcg is suﬃciently aligned with the condition-vector cm of
the module. Biologically this implies that a signiﬁcant fraction of the conditions in the
module induce a co-regulated expression of gene g.

m results in a non-zero component g(g)

It is important to note that the content of a particular module Mm =

depends
on the pair of thresholds (tG, tC). In many cases for slightly larger thresholds there exists
a related module M up
Mm. Similarly, for somewhat smaller thresholds
there usually exists a module M down
m . Thus there are nested sets
of modules, M top
that persist over a ﬁnite range of the thresholds. This
hierarchical structure resembles the tree structures obtained from clustering. However, in
our case distinct branches may share common genes or conditions.

m , such that Mm ⊂

m , such that M up

Gm, Cm}

M bottom
m

M down

m ⊂

m ⊂

...

⊂

{

3 The Iterative Signature Algorithm

The rigorous deﬁnition of a transcription module in principle allows us to determine the
for their
modules encoded in the expression matrix by testing all possible sets
compliance with eq. (8). However, since the number of such sets scales exponentially with

Gm, Cm}

{

6

the number of genes and conditions, such an approach is completely infeasible computa-
tionally. We therefore suggest a diﬀerent approach. Our principle idea is to search for
solutions of the consistency equation in (8) through the map deﬁned by

c(n+1) = ftC (EG g(n)) ,
g(n+1) = ftG(ET

C c(n+1)) .

(10)

(11)

c

The ﬁrst equation assigns a condition-vector c(n+1) to a given gene-vector g(n). We refer
to the component c(n+1)
of this vector as a condition score. This score is non-zero only if
the corresponding gene-proﬁle ˆgc, deﬁned in eq. (5), is suﬃciently aligned with the gene-
m . In the subsequent step in eq. (11) the component (or gene score) g(n+1)
vector g(n)
of the
gene-vector g(n+1)
is assigned a non-zero value only if the corresponding condition-proﬁle
ˆcg is suﬃciently aligned with the condition-vector c(n+1)

m

.

g

m

{

g(0)
i }

In a recent work [23] we have applied the map in eqs. (10) and (11) to a variety of
assembled according to prior knowledge of the
biologically motivated input-sets
regulatory sequence or function of the genes. Sets of co-regulated genes and co-regulating
conditions were constructed from recurrent realizations of the output-sets deﬁned by g(1)
and c(1). In this work we pursue a diﬀerent strategy, namely we apply the maps in eqs. (10)
and (11) iteratively by re-using the gene-vector g(1) as input for eqs. (10) and (11) in
order to obtain new output-sets deﬁned by c(2) and g(2). Repeating this procedure we
rapidly
obtain
converges to a “ﬁxed point” gene-vector g(∗). In general the series
g(0), g(1), g(2), g(3), ...
}
rapidly converges and we can deﬁne a “ﬁxed point” gene-vector g(n∗) which satisﬁes

from g(2) and so on. In general, the series

g(0), g(1), g(2), g(3), ...
}

g(3), c(3)

{

{

{

}

g(∗)
g(n)
−
g(∗) + g(n)

|
|

< ε

|
|

(12)

for all n above a certain number of iterations. The parameter ε determines the accuracy of
the ﬁxed point. g(∗) depends both on the “seed” g(0) and the thresholds tG and tC, which
are ﬁxed parameters. Together with the associated condition-vector c(∗) it deﬁnes a TM,
since (g(∗), c(∗)) by deﬁnition solve eq. (8). We call this procedure the Iterative Signature
Algorithm (ISA).

m , c(∗)

Although the set of possible input seeds is huge, usually there exist only a rather limited
number of ﬁxed points for a given set of thresholds (tG, tC). Therefore, in general the ISA
, (2) ﬁnd
is applied as follows: (1) generate a (suﬃciently large) sample of input seeds
the ﬁxed points (g(∗)
m ) corresponding to each seed through iterations and (3) collect
the distinct ﬁxed points in order to decompose the expression data into modules. The
structure of this decomposition depends on the choice of thresholds (tG, tC). Scanning over
diﬀerent values for (tG, tC) reveals the modular structure at diﬀerent resolutions: Lower
thresholds yield larger units whose co-regulation is relatively loose, while higher thresholds
lead to smaller, tightly co-regulated modules. Each ﬁxed point (g(∗)
m ) has its “basin of
attraction”, i.e. the set of seeds that converge to it under the iterative scheme in eqs. (10)

m , c(∗)

g(0)
m }

{

7

and (11). The size of this set is a measure of the “convergence radius”, while the average
number of iterations, that is needed until eq. (12) is satisﬁed, characterizes the “depth” of
this basin.

N 2

comp ∝

GNC + N 2

The computation time of any algorithm, designed for the analysis of large scale ex-
pression data, is of crucial importance. For algorithms that require the full correlation
matrices (like clustering or SVD), already the computation of these two matrices can be
very intensive, since its computation time scales like tcorr
CNG. However,
the ISA is not based on this kind of information. Rather than squaring the expression
matrix, only multiplications of the expression matrix with sparse matrices (of size NG ×
NI
NI), where NI is the number of input sets, have to be performed. Due to the
or NC ×
NiterNI(NC ˜NG + NG ˜NC),
sparseness, the computation time of the ISA goes like tISA
where ˜NG and ˜NC refer to the average number of genes and condition, respectively, whose
scores are above the threshold, and Niter is the number of iterations until convergence.
Thus the computation time of the ISA scales linearly with NG and NC. In general only
very few iterations Niter are needed to ﬁnd the ﬁxed points. A large number of input sets
NI increases the chances to ﬁnd the ﬁxed points with a small convergence radius. However,
for practical purposes it is useful to accumulate progressively sets a ﬁxed points by running
the ISA repeatedly with a moderate value for NI, thus increasing gradually the accuracy
of the ﬁxed point decomposition. Importantly, ˜NG and ˜NC are much smaller than NG and
NC as long as the respective thresholds are high enough. Finally, we note that tISA
comp could
be further improved by choosing the input seeds not completely at random, but using the
information of previous runs (e.g. those at a diﬀerent threshold).

comp ∝

3.1 Comparison with Singular Value Decomposition

For w(x) = x, in the absence of thresholds and neglecting the two diﬀerent normalizations
of the expression data, the iterative scheme reads

ˆc(n) =

|
ˆg(n) =

E ˆg(n−1)
Eˆg(n−1)
|
ET ˆc(n)
ET ˆc(n)

,

.

|

|

(13)

(14)

|

|

cm|

gm|

and ˆcm = cm/

The ﬁxed points of the above equations correspond to the pairs of vectors (ˆgm, ˆcm), where
are the normalized eigenvectors of ET E and EET , re-
ˆgm = gm/
spectively. Both eigenvectors are associated with the common eigenvalue µ2
2 =
ET ˆcm|
2. It is interesting to note that a Singular Value Decomposition (SVD) of the ex-
|
pression matrix yields exactly those eigenvectors and eigenvalues [24,25] (see appendix A.1
for brief review of SVD). This decomposition is usually performed in a sequential manner.
In this case one determines ﬁrst the pair (ˆg1, ˆc1) associated with the largest eigenvalue µ2
1.
In fact this pair emerges as a ﬁxed point of the above equations for any seed g(0) that is

Eˆgm|

m =

|

8

not perpendicular to ˆg1. It can be shown that the matrix

E1 = µ1ˆc1 ˆgT
1 .

provides the best rank-1 approximation to E = E1 + R1, where R1 denotes the residual
term. A subsequent diagonalization of R1 yields the (orthogonal) pair (ˆg2, ˆc2) associated
with the second largest eigenvalue µ2. Continuing this procedure eventually decomposes
the expression matrix into a sum

(15)

(16)

E =

Em + RNM

NM

m
X

of the rank-1 matrices Em = µmˆcm ˆgT
as a special kind of transcription modules.

m with µm =

cm||

gm|

|

. These matrices can be viewed

One of the advantages of SVD is that the signiﬁcance of each modular component Em
can be determined simply according to the magnitude of the associated eigenvalue. The
components associated with small eigenvalues are likely to reveal no real information and
to contain only noise. Thus the spectrum of eigenvalues can give some indication of the
dimensionality of the data: The existence of NM eigenvalues that are signiﬁcantly larger
than the remaining eigenvalues suggests that there are NM dominant components. Similar
to SVD the lengths of the ﬁxed point vectors of the ISA provide a measure of the relative
g∈Gm(g(∗)
g )2 reﬂects the size of the
importance of the associated TM. Speciﬁcally,
c )2
gene set and (for w(x) = x) the strength of its co-regulation, while
reﬂects the size of the condition set and the strength of the co-regulation induced by this
set.

c∈Cm(c(∗)

g(∗)
m |

c(∗)
m |

2 =

2 =

P

P

|

|

While the similarity between the ISA and SVD is instructive, there are several important

diﬀerences:

•

•

Applying the threshold functions in eqs. (10) and (11) yields a diﬀerent spectrum
of ﬁxed points: Sets of genes that are ﬁxed points of the iterative scheme for a
particular choice of the threshold, in general do not correspond to the eigenvectors
of the expression matrix.

The thresholds aﬀect the stability of the ﬁxed points: While the iterations in eqs. (13)
and (14) have only a single stable ﬁxed point (ˆg1, ˆc1), the ISA in eqs. (10) and (11)
usually possesses several stable ﬁxed points. This is essentially because the thresholds
induce an “eﬀective orthogonality” by setting the small scalar products in eq. (7) to
zero. Consequently input sets that are almost (but not exactly) orthogonal to the
strongest ﬁxed point, do not ﬂow towards this point under the iterations, but converge
to a diﬀerent ﬁxed-point.

•

SVD is very sensitive to the (unavoidable) noise in the expression data. This noise
induces mixing between modules that would be orthogonal to each other in the

9

•

•

•

absence of noise. In the ISA the threshold function provides an eﬃcient way to deal
with such noise. Excluding the bulk of the genes and conditions from the expression
data at each step of the iterative procedure allows to pick up co-regulated units that
would otherwise be masked by the noise.

For SVD distinct eigenvectors ˆgm and ˆgm′ as well as ˆcm and ˆcm′ are orthogonal to each
other, since they diagonalize a symmetric matrix. The constraint of orthogonality is
not present in the ISA.

SVD only reveals one single decomposition of the expression matrix into modules.
As for the ISA, changing the values of the thresholds allows to analyze the modular
structure recorded in the expression matrix at diﬀerent resolutions.

For SVD the expression data has to be normalized either according to genes or con-
ditions. The choice of data normalization in general follows from the interpretation
of the data. Demanding maximal variance among the principal components, one is
led to center the data either as in EG or EC (see appendix A.1 on SVD for details).
Thus the symmetry between the genes and the conditions is explicitly broken when
committing to either EC or EG. In contrast, the ISA avoids this bias by alternating
between the two possible normalizations at each step of the iterative procedure in
eqs. (10) and (11).

We will discuss now some of these points in more detail.

4 The proper data normalization

Given the “raw” expression data contained it is diﬃcult to compare two experiments (gc
and gc′) or two genes (cg and cg′). This is because diﬀerent experiments may aﬀect the
expression levels at a diﬀerent scale. For example one condition may change the expression
of many genes by a very large factor (
1) while another condition aﬀects mainly the
same genes, but shifts their expression level by a much smaller amount. Although the
two conditions are related, this relation is not explicit in the expression data. Moreover,
recording the expression levels with diﬀerent microarray techniques as well as variations in
the sample preparation can change the scale of the results. Similarly the dynamic range
of two distinct genes could diﬀer greatly even though the shape of their condition proﬁles
might be similar. To overcome this diﬃculty we have introduced the normalized matrices
EG and EC (c.f. eqs. (3) and (4)).

≫

In order to study the impact of the normalization on our algorithm we generated an
in-silico expression matrix E corresponding to two overlapping modules of equal size and
strength (see section 6 for more details on the model used to generate these data). We
[0, 1] for each gene g and condition c from a uniform
selected random scale factors sg, sc ∈
distribution and transformed the elements of the expression matrix according to Ecg

→

10

S ≡

Ecg
Ecgsgsc. Unlike the original expression matrix E, the re-scaled expression matrix ES
(shown in Fig. 1a) corresponds to the realistic scenario where the entities of the expression
data have been recorded at diﬀerent scales. From ES we calculated the normalized matrices
EC and EG.

The question we ask is which normalization has to be employed in order to reveal the
“correct” genes from the conditions associated with the underlying module, and which
normalization leads to the “correct” conditions, given the genes of the module. To answer
this question we deﬁned the vectors g1 and c1 by assigning non-zero components only for the
genes and conditions of one of the modules, respectively. Using these vectors we computed
cS = ESg1, cC = ECg1 and cG = EGg1 as well as gS = ET
Cc1 and gG =
ET
Gc1. The components of the resulting gene- and condition-vectors are plotted in Fig. 1b
and c, respectively.

S c1, gC = ET

One can see that only for gC and cG (corresponding to the the “correct” normalizations
as used in the ISA, c.f. eqs. (10) and (11)) all the components associated with the genes
and conditions of the module (speciﬁed by (g1, c1)) are signiﬁcantly larger than the oth-
ers. For missing or “wrong” normalization there are large ﬂuctuations among the vector
components. Hence applying a threshold would only capture part of the relevant genes or
conditions in this case. Thus EC is best suited to identify the genes of a module from a set
of conditions that is a good approximation of Cm, while EG is the proper normalization
to obtain the conditions of a module from a set of genes close to Gm. Note that using
these “correct” normalizations, it is even possible to distinguish the genes and conditions
associated exclusively with the speciﬁed module from those that belong also to the other
module, because the latter obtain a somewhat lower score.

5 Analysis of the ISA

The fundamental issue is how well the ISA can reveal relatively small, noisy, and possibly
overlapping modules from the expression matrix.
In this section we address this ques-
tion by considering a simple model where the expression matrix corresponds to a single
transcription module. Our idea is to consider the gene-vector that undergoes iterations
as a stochastic entity and to study how its distribution evolves under the iterations. This
approach allows us to quantify how the eﬃciency of our algorithm depends on the size of
the module and the noise in the expression data.

5.1 Linear recursions

In the following we consider a slightly simpliﬁed iterative scheme, where no threshold
function is applied to the condition vector. In this case one can write an iterative equation
If, moreover, no gene threshold is applied the
that depends only on the gene vector.

11

iterations are deﬁned through the linear equation (c.f. eq. (48) in the Appendix)

ˆg(n) =

Cg(n−1)
Cg(n−1)

.

(17)

(18)

|
Here the matrix C = ET E emerges from applying ﬁrst eq. (13) and then eq. (14). As we
mentioned before the ﬁxed points of this linear recursion are the eigenvectors of C.

|

G whose co-regulation is triggered by the conditions in C1 ⊂

Let us consider the simplest scenario corresponding to a single set of co-regulated genes
C. Speciﬁcally, we
G1 ⊂
assume that all the genes in G1 are equally important, such that a noise-free measurement
would result in identical condition proﬁles for these genes. In this ideal case the matrix
would equal some constant if both g and g′ belong to G1 and be zero otherwise.
elements
In order to model the eﬀect of noisy data we consider the elements of C as random variables
with mean value

gg′

C

gg′

hC

i

=

µC
0

(

g, g′
G1
∈
otherwise

,

and variance VC for all g, g′
G. In the absence of noise (i.e. VC = 0) the matrix C possesses
only a single (non-trivial) eigenvector g(0), whose non-zero components specify the genes
of the TM. However, for VC > 0 this is not true anymore.

∈

Assume we knew the eigenvector of C for VC = 0 and use it as a (binary) seed g(0) for
eq. (17) with a noisy realization of C (i.e. VC > 0). The question is whether the ﬁxed-
point resulting from g(0) still characterizes the genes of the module. In general the vector
ˆg(1) obtained by the ﬁrst iteration does not coincide with ˆg(0). Due to the probabilistic
description of C we can only determine the mean and the variance of the components of
g(1) = Cg(0). The mean of g(1)
is equal to the number of genes in the module,
N (m)
G VC. Here
we only used the additivity of the mean and the variance. However, already for g(2)
in the
next iteration we need to deal with products of random variables. To this end we note that
for two independent random variables a and b we have (see appendix A.2 for proof)

G1, and zero otherwise. Similarly the variance of g(1)

G , times µC if g

is N (m)

g =

g(0)
g′

gg′

P

∈

C

g′

g

g

ab
i

h

=

a
h

ih

b
i

and

V (ab) = V (a) V (b) + V (a)

2 + V (b)

b
i
h

2 .

a
i
h

(19)

Using these results we ﬁnd that the mean values of the components of the vector g(n) =
Cg(n−1) are given by

g(n)
g i

=

∈
6∈
denotes the mean of the components g(n−1)

(

h

G µC µ(n−1)
N (m)
0

G

µ(n)
G ≡

g
g

G1
G1

,

G

where µ(n−1)
(g
constructively to

∈

G1). Only for the genes in G1 there are N (m)

. Similarly, the variances of g(n)

g(n)
g i
h
∆NGVC ˜V (n−1)
∆NGVC ˜V (n−1)

G

G

V (n)
G ≡
˜V (n)
G ≡

+ N (m)
G
+ N (m)
(cid:16)
G VC

VCV (n−1)
V (n−1)

G

G

associated with the module
G matrix elements in C that contribute

g

g

are
+ VC(µ(n−1)
+ (µ(n−1)
)2

G

G

(cid:17)

)2 + V (n−1)

G

µ2
C

(cid:17)

g

g

∈

6∈

,

G1
G1
(21)

(20)

V (g(n)

g ) =






(cid:16)

12

G has an additional term with respect to ˜V (n)

G denotes the number of genes that do not belong to the module.
G , due to the contribution of the

In order to assess whether the iterations improve the separability between distributions
G1) the module, we introduce the re-scaled

G1) and outside (g

where ∆NG ≡
Note that V (n)
non-zero mean values in C.

NG −

N (m)

of the genes within (g
variances

∈

v(n)
G ≡

V (n)
G
(µ(n)
G )2

˜v(n)
G ≡

˜V (n)
G
(µ(n)
G )2

.

6∈

and

G and ˜v(n)
G ≪

Note that v(n)
G are dimensionless and invariant under the normalization of the gene-
vectors. v(n)
1 implies that the distribution of the genes associated with the module is
well separated from the distribution of the genes that do not belong to the module. Using
eqs. (20) and (21) we obtain the following recursive equations

˜v(n)
G =

∆NGvC
(N (m)
G )2

˜v(n−1)

G

+

vC
N (m)

G (cid:16)

v(n−1)

G

+ 1

,

(cid:17)

G = ˜v(n)
v(n)

G +

v(n−1)
G
N (m)
G

,

where vC

VC/µ2

≡
If N (m)
G ≫

ence between v(n)
recursive equation

C is the (ﬁxed) noise-to-signal ratio of the expression matrix.

1 the second term in eq. (24) is negligible and we can ignore the small diﬀer-
G and ˜v(n)
G in eq. (23) leads to the approximate

G . Then, setting ˜v(n)

G = v(n)

This equation converges to

provided that

For further reference we state this result also for the signal-to-noise ratio

The corresponding ﬁxed-point value equals to

v(n)
G =

NGvC
(N (m)
G )2

v(n−1)

G

+

vC
N (m)
G

.

N (m)
G
vC −

NG
N (m)
G

v(∗)
G ≡ 


−1

,





vC < vcrit

C ≡

(N (m)
G )2
NG

.

ρ(n)
G ≡

µ(n)
G
V (n)
G

q

= (v(n)

G )−1/2 .

ρ(∗)
G =

N (m)
G

ρ2
C

(ρcrit
C

)2

1/2

,

h

(cid:16)

(cid:17)i

−

13

(22)

(23)

(24)

(25)

(26)

(27)

(28)

(29)

if

ρC

≡

µC
√σC

> ρcrit
C

√NG
N (m)
G

,

≡

(30)

and is zero otherwise.

C

The interpretation of the critical value vcrit

for the noise in the expression data is
straightforward: Only sets of genes that are suﬃciently large and whose co-regulation
is recorded in the expression matrix with relatively low noise (i.e. vC < vcrit
) can be
captured by the iterative procedure without threshold in eq. (17). Actually eq. (30) is only
a necessary condition for the identiﬁcation of a module, since for a reliable separation of
the distributions of the gene-scores associated with the module, we need ρ(∗)
0. As
we mentioned before, the number of genes associated with cellular functions is expected
to be rather limited, N (m)
NG. Therefore we conclude that eq. (30) presents a serious
limitation for the extraction of biologically relevant modules through the analysis of the
eigenvectors of C (as in SVD).

G ≪

G ≫

C

5.2 Noise reduction by the threshold function

As discussed in the previous section the noise in the expression data may obstruct the
identiﬁcation of a TM. A fundamental aspect of the threshold functions in the ISA is to
reduce the eﬀect of such noise by excluding the bulk of the genes and conditions that do
not contribute information but rather increase the level of background noise.

To illustrate this point, let us repeat the study of noise propagation presented above
for the simpliﬁed iterative scheme like in eq. (17), but with the linear map followed by a
threshold function:

g(n) = ft(Cˆg(n−1)) ,

where ft is deﬁned in eq. (9) and we use a linear weight-function w(x) = x. Let us assume
(x; µ, σ), where µ
that the gene scores are distributed according to normal distributions
and σ refer to the mean and the standard deviation of the random variable x. As a result
of the threshold function only

N

genes from the module contribute constructively to the mean in eq. (20). Similarly, only
˜N (m)

G genes from the module and

genes outside the module contribute to the variance of g(n)
G is the expected
number of genes in the module, whose score has not been set to zero by the threshold
function. Similarly, ∆ ˜NG is the expected number of genes that do not belong to the

in eq. (21). ˜N (m)

g

˜N (m)

G = N (m)

G

(ρ; ρ(n−1)

G

, 1) dρ

∞

t N
Z

∆ ˜NG = ∆NG

(ρ; 0, 1) dρ

∞

t N

Z

14

(31)

(32)

(33)

module, but have a non-zero score. The crucial point is that, because of the diﬀerent mean
values of the two distributions, the threshold function excludes more genes that do not
belong to the module than genes that do belong to the module. For example, if ρ(0)
G = 3
for the initial (normal) distribution, then a threshold t = 2 would remove almost 98%
of the genes outside the module (∆ ˜NG ≃
∆NG), but less than 16% of the genes
0.023
associated with the module ( ˜N (m)
0.841
G ). We note that the precise shape of the
distribution function is in fact not crucial, since our derivation relies only on the additivity
of the mean values and variances, and eq. (19).

×
N (m)

G ≃

×

It follows that the mean values and variances of the components of the vector g(n) are
given by the same expression as in eqs. (20) and (21), respectively, except that we have
to replace N (m)
G and
∆ ˜NG into eqs. (20) and (21) the argument leading to the expression for the ﬁxed-point
signal-to-noise ratio in eq. (29) is essentially unchanged, and we have

G and ∆NG by ∆ ˜NG. Substituting the eﬀective numbers ˜N (m)

G by ˜N (m)

with

ρ(∗)
G =

˜N (m)
G

ρ2
C

(˜ρcrit
C

)2

1/2

,

h

(cid:16)

(cid:17)i

−

˜ρcrit
C ≡ q

˜N (m)

G + ∆ ˜NG
˜N (m)
G

.

(34)

(35)

G . Therefore eq. (34) is an integral equation for ρ(∗)

Note that unlike for eq. (29), the right-hand side of eq. (34) still depends on ρ(∗)
G through
˜N (m)
G which can be solved numerically.
A graphical solution of this equation is provided in Fig. 2 for diﬀerent thresholds and a
speciﬁc choice of the parameters NG, N (m)

G and vC (see caption for details).

As can be seen in Fig. 3a applying a threshold function improves signiﬁcantly the
identiﬁcation of the module. We show the ﬁxed point value of the signal-to-noise ratio, ρ(∗)
G ,
as a function of both the threshold t and the (ﬁxed) signal-to-noise ratio ρC of the expression
data. In the absence of a threshold function ρ(n)
G converges to zero if ρC is below some critical
. Applying a threshold, ρ(n)
value ρcrit
(but
C
ρC > ˜ρcrit
), indicating the identiﬁcation of the module. Moreover, one can see from Fig. 3a
that there is an optimal regime for the threshold t, where ρ(∗)
G (t, ρC) is (nearly) maximal.
Within this regime ρ(∗)
G (t, ρC) depends only weakly on t, so the convergence is robust with
respect to the exact choice of the threshold. The size of this regime increases with ρC.

G converges to a ﬁnite value, even if ρC < ρcrit

C

C

In order to quantify the relative increase of the ﬁxed point value of the signal-to-noise

ratio ρ(∗)

G (t, ρC) due to the application of the threshold function we deﬁne the ratio

r(t, ρC)

ρ(∗)
ρ(∗)
G (t, ρC)
G (ρC)
−
ρ(∗)
G (t, ρC)

,

≡

(36)

where ρ(∗)
G (ρC) refers to the value to which the signal-to-noise ratio converges when no
threshold is applied. For ρ(∗)
G (t, ρC) = 0 we set r(t, ρC) to zero. We show r(t, ρC) as a
function of t and ρC in Fig. 3b. The ﬁgure shows that there exists a large region in the

15

C

parameter space of t and ρC < ρcrit
, where the iterations only converge to a positive value
due to the threshold. Moreover, even for ρC > ρcrit
, where the iterative schemes converges
to a positive value also without a threshold, there exists a large region, where ρ(∗)
G (t, ρC)
is signiﬁcantly larger than ρ(∗)
G (t). Thus we conclude that the threshold function improves
signiﬁcantly (and in certain cases makes at all possible) the convergence of a noisy input
set to a gene-vector that speciﬁes the TM.

C

We have also performed numerical simulations of the iterative scheme in eq. (31). To
this end we employed in-silico expression data that were generated according to eq. (18)
and superimposed with a certain level of noise. The initial gene sets were composed such
that only the distribution of the genes scores associated with the module had a non-zero
mean value, while the distribution of the remaining genes was centered around zero. The
simulation allowed us to trace the evolution of the two distributions under the iterations.
The results indicate a good agreement between the numerical and the analytical results.
Details of this analysis are presented in Fig. 4. In particular, in Fig. 4d we show an example
where only the application of a proper threshold leads to a separation between the two
distributions.

6 Beyond the single module

In order to study the ISA in a more realistic scenario, we have performed further numerical
simulations based on in-silico expression data encoding several, possibly overlapping tran-
scription modules. These data were generated according to the following simple model:
Each module Mm is governed by a single (virtual) transcription factor whose activity is
m of the gene-vector
described by a pair of vectors
gm specify the genes that are transcribed if the transcription factor m is active, while the
non-zero components c(c)
m of the condition-vector cm specify the conditions that activate
this transcription factor. Then for NM modules the log expression of gene g at condition c
is deﬁned as Ecg =
m . The ﬁnal expression matrix is obtained by adding noise
to these matrix elements.

. The non-zero components g(g)

gm, cm}

NM
m=1 g(g)

m c(c)

{

P

6.1 Expression data corresponding to two modules

m and g(g)

As initial example we consider in-silico expression data based on two transcription factors.
We deﬁned the components c(c)
m for m = 1, 2 such that there are two overlapping
transcription modules M1 and M2 (see Fig. 5 for details). We applied the ISA to a collection
of input sets composed of randomly chosen genes. We found that the structure of the
resulting ﬁxed points depends strongly on the threshold tG. Fig. 5b shows the corresponding
output sets for a discrete choice thresholds: For a very low threshold (t
2) the output
≃ −
sets contain essentially all the genes. Applying a somewhat higher threshold (t
1) yields
output sets containing all the genes that are associated with either of the two modules.

≃ −

16

≃

For a moderate threshold (t
0) there are two types of output sets, comprising either the
genes of M1 or M2. For a high threshold (t
1) all the output set contain only those
genes that belong to both modules. Finally, for a very high threshold (t
2) the output
sets are empty. For intermediate values of the threshold value one observes relatively
sharp transitions between these well-deﬁned ﬁxed points (Fig. 5c). At these transitions
the correspondence between the output sets and the modular structure of the data is less
precise.

≃

≃

We have also varied the condition threshold tC.

Interestingly, for not too large a
threshold (tC <
2) the resulting gene output sets are almost independent of the choice of
∼
tC. However, the condition output sets depend critically on the value of tC and exhibit
a similar behavior as the gene output sets in terms of structure (not shown). This is
not surprising, since the ISA is symmetric with respect to genes and conditions. We
conclude that scanning over diﬀerent values of tG and tC reveals the modular structure
M1, over its overlapping
of the expression data, starting from the “supermodule” M1
components M1 and M2, to the “submodule” M1

M1.

S

6.2 Expression data corresponding to many modules

T

The above example shows that the ISA can identify overlapping modules. However, for
NM = 2 there exist only 22 = 4 possible transcriptional states, so the 100 conditions of the
expression data are highly redundant. For real data the situation is reverse: The number
of experimental conditions is much smaller than the possible number of transcriptional
states.
In order to study how the ISA deals with such a scenario we considered a set
of more realistic models based on many transcription modules. We investigated to what
extend the ISA, as well as hierarchical clustering and SVD, were able to reconstruct these
modules from the respective in-silico expression data.

In the ﬁrst numerical experiment we studied how the diﬀerent algorithms handle noisy
data. To this end we generated expression matrices corresponding to 1050 genes and
1000 experimental conditions that belong to 25 modules of diﬀerent sizes, each associated
with a transcription factor. In order to focus on the eﬀect of noise we considered only non-
overlapping modules that do not share any genes or conditions. Onto the binary expression
data we superimposed noise from a random distribution. We varied the width σ of this
distribution, simulating diﬀerent levels of noise.

In order to quantify how well the modules were identiﬁed by the diﬀerent methods we
proceeded as follows: For SVD we collected the 25 eigenvectors of the gene-gene correlation
matrix that were associated with the largest eigenvalues. For each of the 25 modules we
selected the eigenvector that had the largest overlap with the gene-vector characterizing
the module, and in Fig. 6 we show the average Pearson coeﬃcient between these two
vectors (triangles). For hierarchical clustering we used the matlab implementation for
average linkage to compute the complete hierarchical cluster tree. Using this cluster tree we
partitioned the expression matrix using diﬀerent cutoﬀs such that the resultant partitions

17

contained at least 15 and at most 40 clusters. From all these partitions we selected the one
whose clusters had the highest average overlap with the gene content of the modules. This
overlap is shown in Fig. 6 (squares). Finally, for the ISA we re-constructed the modules
from the ﬁxed points that occurred repeatedly. Namely, in order to avoid artifacts due to
distinct, but very similar ﬁxed points, we “fused” these solution using a procedure that
resembles agglomerative clustering, albeit for modules rather than genes (see Ref. [23]
for details). The fraction of correctly identiﬁed genes per module (circles) as well as the
fraction of correctly identiﬁed modules (asterisks) is shown in Fig. 6. We conclude that for
noisy data the identiﬁcation capability of the ISA is superior to that of SVD and clustering.
In particular, SVD is very sensitive to the addition of noise and fails to identify the modules
accurately, even for a small level of noise. Clustering can handle a moderate amount of
noise, but not as much as the ISA.

A second numerical experiment was designed to study quantitatively the ability to
identify overlapping modules. We specify the regulatory complexity by the the number
of transcription factors per gene nT F . Only if each gene (and condition) is associated
with exactly one transcription factor (nT F = 1) the expression matrix can be written
in block-diagonal form. For larger values of nT F distinct modules share common genes
and conditions and the expression matrix cannot be reorganized into in block-diagonal
shape. We applied the SVD, hierarchical clustering and the ISA to the expression matrices
generated for nT F = 1, ..., 6 and evaluated the outputs in the same manner as described
above (see Ref. [23] for related results). The results are shown in Fig. 7. One can see that
the ISA could successfully identify all the transcription modules even in the case of highly
overlapping modules. In contrast, for nT F > 1 the identiﬁcation capabilities of SVD and
clustering rapidly decrease. This is because the clustering algorithm does not allow for
multiple assignments of one gene to diﬀerent modules and therefore usually captures only
small, incomplete fractions of the overlapping modules. Similarly, if the expression matrix
cannot be reorganized into block-diagonal shape due to the overlap between the modules,
the eigenvectors identiﬁed by SVD fail to characterize the modules properly.

7 Applying the ISA to yeast expression data

The analytical and numerical studies presented above indicate that the ISA is well-suited for
the analysis of expression data. In this section we give a brief presentation of the biological
insight that can be obtained from applying our method to real data. We analyzed a diverse
set of more than 1000 DNA-chip experiments that were obtained by diﬀerent groups [6].
The yeast S. cerevisiae is an ideal model organism to test our algorithm, due to the wealth
of expression data and the large amount additional biological knowledge that exists for
this organism.

We have applied the ISA to the yeast expression data using diﬀerent values for the
gene-threshold tG = 1.8, 1.9, ..., 4.0, while the condition-threshold was ﬁxed to tC = 2.0.

18

(As we pointed out previously the gene-content of the modules depends only weakly on the
exact choice for tC.) For each value of tG we employed
20, 000 randomly composed initial
gene sets of various sizes in the search for ﬁxed points. The modules were reconstructed
from the recurrent ﬁxed points using a similar algorithm as for the in-silico expression
data. Indeed such a processing of the “raw” ﬁxed points is needed to avoid many similar
modules that biologically correspond to the same co-regulated unit.

∼

∼

The number of modules increases with tG, ranging between ﬁve at the lowest level
100 at the highest resolution (tG = 4). In contrast, the typical module size
(tG = 1.8) to
declines rapidly as a function of tG. The step-wise increasing of tG exposed many chains
G ]. Increasing tG,
of closely related modules that persist for ﬁnite ranges tG ∈
the number of genes assigned to each element of the chain decreases until the size of the
module declines sharply at tG = ttop
G and either disappears completely or splits into two or
more sub-modules. Likewise decreasing tG beyond tbottom
destabilizes the ﬁxed point, since
many unrelated genes are added to the module that pull the module towards a diﬀerent
ﬁxed point. In this case the module may either ‘merge’ with another module or ﬂow into
a completely diﬀerent ﬁxed point.

[tbottom
G

, ttop

G

The ﬁve stable ﬁxed points identiﬁed for tG = 1.8 correspond to the central functions
of the yeast organism: protein synthesis, cell-cycle (G1), mating, amino-acid biosynthesis
and stress response. Each module contains between 100 and 300 genes. Protein synthesis
and stress are the most dominant modules and comprise most of the experimental con-
ditions of the data set. In fact, these modules remain ﬁxed points throughout the entire
range of thresholds considered here, and therefore can be considered the backbone of the
transcriptional network.

A visualization of this network is presented in Fig. 8a. For each threshold the corre-
sponding modules are displayed in a plane, such that their distance reﬂects their correlation
with respect to conditions. Moving to a higher threshold, nested sets of modules are kept
in the same position in each plane, while the “new” modules are placed such that their
position reﬂects best their correlation with the other modules. This organization of the
chains of nested modules is somewhat similar to the data presentation by hierarchical trees
commonly produced by cluster algorithms. However, in our case, chains of modules may
extend over a ﬁnite range of tG and distinct chains can contain common genes. Additional
information, such as the number of input seeds that converged to the same ﬁxed pointed
(shown as pie charts in Fig. 8b), provide further inside into the transcriptional network.

In a previous analysis of the same data [23] we applied the map in eqs. (10) and (11) to a
g(0)
assembled according to prior knowledge
variety of biologically motivated input-sets
i }
{
of the regulatory sequence or function of the genes, and reconstructed the modules from
recurrent realizations of the output-sets deﬁned by g(1) and c(1). Remarkably, the ISA
(which requires no information beyond the expression data whatsoever) revealed essentially
all the co-regulated units that we found in this analysis, as well as several new transcription
modules that had not been identiﬁed previously. Moreover, the ISA provides additional

19

insight into the modular organization through the evolution of the modules over diﬀerent
threshold values. Studying the functional annotations of the genes assigned to the modules,
we observed a strong coherence for the genes that have been annotated in most of these
modules. This suggests that the ISA provides a biologically meaningful decomposition
into co-regulated units. A comprehensive discussion of the biological implications of this
analysis is beyond the scope of this work and will be pursued elsewhere [26].

8 Conclusions

We have presented a novel method for the analysis of gene expression data. The innovation
of our approach is twofold: On the conceptual level we provide a rigorous deﬁnition of what
we want to extract from the expression data by introducing the notion of a transcription
module (TM). Our deﬁnition in eq. (6) assigns to a TM both a set of co-regulated genes
and the set of experimental conditions under which this co-regulation is the most stringent.
The size of a TM depends critically on the associated set of two thresholds that determine
the similarity between the genes and conditions of the module, respectively. The genes
and conditions of a TM are mutually consistent implying that the latter can be obtained
from the former and vice versa. The notion of a TM is well motivated biologically. Ideally
the genes and conditions can be associated with a transcription factor or a (fraction of) a
pathway. Importantly distinct modules may share both common genes and conditions.

On the computational level our deﬁnition of a TM provides the basis for simple, but ef-
ﬁcient algorithm to obtain the modules encoded in the expression data. Starting from a set
of randomly selected genes (or conditions) one reﬁnes iteratively the genes and conditions
until they are mutually consistent and match the deﬁnition of a TM. The important point
is that at each step of the iterations we apply a threshold function, thus maintaining only
signiﬁcantly co-regulated genes and the associated co-regulating conditions. The threshold
stabilizes compact sets of co-regulated genes and prevents the introduction of noise from
unrelated genes and conditions. Using a suﬃciently large number of initial random sets
it is possible to determine all the ﬁxed points of the iterative scheme for a given pair of
thresholds. Scanning through a range of values for these thresholds decomposes the data
into modules at diﬀerent resolutions. Since the computation time for each iteration of our
algorithm scales only linearly with the total number of genes it is particularly well-suited
for the analysis of large scale expression data.

Considering a simpliﬁed scenario of a single transcription module embedded in a noisy
background of unrelated genes, we showed analytically that the application of a threshold
improves the convergence properties of the iterative scheme. Speciﬁcally, we considered
the gene-vector that undergoes iterations as a stochastic entity and studied the evolution
of its distribution under the iterations for a given threshold. This allowed us to quantify
how the successful identiﬁcation of the module depends on the size of the module and the
noise in the expression data.

20

Our analytical insights were conﬁrmed numerically using computer-generated expres-
sion data. More complex gene regulation were also simulated in-silico. Considering a
model with two overlapping transcription modules, we showed that applying the ISA using
a range of threshold values reveals the structure of the expression data at diﬀerent resolu-
tions. Depending on the value of the threshold our algorithm can reveal each of the two
modules, as well as their union and intersection. Using large computer-generated expres-
sion matrices we studied the capability of the ISA to reveal a large number of overlapping
transcription modules from noisy expression data. We ﬁnd that our method is signiﬁcantly
more eﬃcient at this task than standard tools, like SVD and clustering.

The threshold functions as a resolution parameter in our analysis of real expression data.
Using genome-wide expression data gathered in more than 1000 experimental conditions,
we decomposed the yeast genome into sets of transcription modules at diﬀerent resolutions.
The modular decomposition reveals a hierarchical structure of the regulatory network.
At the lowest resolution we identiﬁed ﬁve transcription modules that correspond to the
central functions of the yeast organism. Increasing the threshold the number of modules
increases while their size decreases. The functional coherence of these modules indicates
both the reliability of our approach and the strong correlation between co-function and co-
regulation at the transcriptional level in yeast. A comprehensive discussion of the biological
implications of this analysis will be presented elsewhere [26].

Finally we note that our formalism can be applied to analyze any data set that consists
of multi-component measurements. While we presented our method in the context of
gene-expression data, it is clear that our approach is well-suited to reveal the modular
organization encoded in any data matrix. Applications of the ISA could include the analysis
of biological data on protein-protein interactions or cell growth assays, as well as other large
scale data, where a meaningful reduction of complexity is needed.

Acknowledgements: We thank J. Doyle for bringing our attention to the similarity
between SVD and the ISA. We thank E. Domany, Y. Kafri and S. Shnider for discussions
and comments on the manuscript. This work was supported by the NIH grant #A150562,
the Israeli Science Ministry and the Benoziyo center. S. B. is a Koshland fellow. N. B. is
the incumbent of the Soretta and Henry Shapiro career development chair.

A Appendix

A.1 Singular Value Decomposition

This appendix reviews Singular Value Decomposition (SVD), which is a common tool
for the analysis of expression data. We use notations that make the similarities with
the Iterative Signature Algorithm (ISA) the most apparent. SVD is used to reduce the
dimensionality of the data by projecting it onto a subspace in such a way that as little

21

information is lost as possible. To this end consider the following matrix:

Em = cm gT

m ,

m c(c)

m = g(g)

whose elements Ecg
m are simply the products of the components of a given gene-
vector gm and condition-vectors cm. For two binary vectors gm and cm (whose elements
are either zero or one) Ecg
m is unity if the module m contains the gene g and the condition c
IRNG
(i.e. the relevant vector components are g(g)
and cm ∈

IRNC it is useful to rewrite the matrix in eq. (37) as

m = 1). For real vectors gm ∈

m = 1 and c(c)

Em = µmˆcm ˆgT

m ,

and ˆcm = cm/

in terms of the normalized vectors ˆgm = gm/
. This normalization
|
removes the ambiguity in the choice of gm and cm due to the invariance of Em under the
transformation gm →
= 0 is an arbitrary real number.
is just the product of the lengths of gm and cm. Then
The prefactor µm =
each module is associated with a triple (µm, ˆgm, ˆcm) of a real number and two normalized
vectors. Comparing the magnitude of any two matrix elements Ecg
m reveals the
relative importance between the gene-condition pairs (g, c) and (g′, c′) for module m.

gm|
cm/φ, where φ

φ gm and cm →
gm| |

m and Eg′c′

cm|

cm|

|

|

Multiplying Em with an arbitrary gene-vector g gives

while multiplication of ET

m = µm ˆgm ˆcT

m with any condition-vector c gives

Em g = α ˆcm with α = µm ˆgT

m g ,

ET

m c = β ˆgm with β = µm ˆcT

m c .

Thus Em and ET
ˆgm and ˆcm, respectively. Consequently theses matrices have rank 1.

m are projection operators onto the one-dimensional spaces spanned by

Now the basic idea of SVD is to reduce the complexity of the data by expressing E in

terms of a relatively small number NM (

NG, NC) of such rank 1 matrices:

≪
NM

m
X

E =

Em + RNM .

Here R denotes the residual term whose euklidean norm
minimized in order to optimize the decomposition into modules in the above equation.
It is instructive to consider ﬁrst the minimization for the case NM = 1. We have

g,c(Rcg)2 has to be

qP

R

=

|

|

(37)

(38)

(39)

(40)

(41)

(42)

(43)

R

2 =

|

|

=

(Ecg

−
(Ecg)2

−

g,c
X

g,c
X

Ecg

m )2 =

(Ecg

µmˆc(c)

m ˆg(g)

m )2

g,c
X
2µmEcgˆc(c)

−
m + µ2

m ˆg(g)

m(ˆc(c)

m ˆg(g)

m )2 .

22

6
Setting the derivative of

2 with respect to the component ˆc(c)
m ,

|
∂

R

|
R
|
|
ˆc(c)
m

2

=

g −
X

2µmEcgg(g)

m + 2µ2

m(ˆg(g)

m )2ˆc(c)
m ,

to zero we ﬁnd that that µmˆc(c)
ˆgm and switching to vector notation:
P

m =

g Ecgg(g)
m /

g(g(g)

m )2 or, recalling the normalization of

Similarly equating ∂

R

2/ˆg(g)

m to zero it follows that

|

|

This remarkable result implies that Em can be determined simply by solving simultaneously
the linear equations in eqs. (45) and (46). The latter is equivalent to a singular value
decomposition (SVD) of the matrix E:

where G = (ˆg1, ˆg2, ..., ˆgr) and C = (ˆc1, ˆc2, ..., ˆcr) are orthogonal matrices. M is a diagonal
matrix of the same dimensions as E whose non-zero elements are given by µm and ordered
µ2
such that µ2
min(NG, NC) is the rank of the expression matrix E.
2 ≥
Combining eqs. (45) and (46) one ﬁnds

r. r

1 ≥

µ2

...

≤

≥

P

µmˆcm = E ˆgm .

µmˆgm = ET ˆcm .

GT EC = M ,

ET Eˆgm = µ2ˆgm ,
EET ˆcm = µ2ˆcm ,

(44)

(45)

(46)

(47)

(48)

(49)

implying that G is composed of the eigenvectors ˆgm of ET E and C consist of the eigen-
vectors ˆcm of EET . One way to solve the above equations is start with some initial
Eˆg(0)
gene-vector ˆg(0), obtain the corresponding condition-vector via ˆc(1) = E ˆg(0)/
ac-
cording to eq. (45), and use the result to compute ˆg(1) = ET ˆc(1)/
using eq. (46).
Iterating this alternating procedure as in eqs. (13) and (14) converges to the pair (ˆg1, ˆc1)
2 provided that the initial vector ˆg(0) was not
associated with largest eigenvalue µ2
orthogonal to ˆg1. Thus the predominant module emerges as the “ﬁxed point” of the above
coupled equations.

Eˆg1|

ET ˆc(1)

1 =

|

|

|

|

|

|

|

|

|

R

R

2 =

g,c(Ecg)2

From eq. (42) it follows that

µ2
m. Hence for NM = 1 the norm of
2, is minimized exactly by the triple (µ1, ˆg1, ˆc1). It is straightforward
the residual term,
to extend this approach to the expansion of the expression matrix in terms of several
modules as in eq. (41). To this end one ﬁrst computes E1 = µ1ˆc1ˆgT
1 as described above
E1. This yields E2 = µ2ˆc2ˆgT
and applies the same scheme to the residual term R1 = E
2
associated with the second largest eigenvalue µ2. Repeating this procedure sequentially
yields eventually the complete SVD of the matrix E. However, for practical purposes

−

−

P

23

it is usually suﬃcient to compute only a limited numbers of triples (µm, ˆgm, ˆcm) with
m = 1, ..., NM until the norm of the residual term
m is below
a certain threshold. Thus, approximating the expression matrix in terms of a relatively
small number of modules, NM ≪
There are two interpretations for the expansion in eq. (41) that depend on the way the
expression data is viewed. If we consider the data as a collection of gene-vectors gc as in
eq. (1), then eq. (41) translates into an expansion of these vectors in terms of a collection
of gene-vectors, i.e.

RNM |
r reduces the complexity of the data.

g,c(Ecg)2

NM
m=1 µ2

2 =

−

P

P

|

NM

Xm=1

NM

Xm=1

gc =

µmˆc(c)

m ˆgm + gR
c

(c = 1, ..., NC) ,

(50)

{

ˆgm}

is the basis (one for all gc), and the expansion coeﬃcients are given by µmˆc(c)
where
m
(one for each gc). Moreover, for each gc there is a residual gene-vector gR
c , that determines
how well gc is approximated by the sum. Conversely, if we consider the data as a collection
of condition-vectors cg as in eq. (2), then the expansion in eq. (41) can be read as

cg =

µmˆg(g)

m ˆcm + cR
g

(g = 1, ..., NG) ,

(51)

g denotes the residual condition-vector. In this case the condition-vectors of the
, provide the basis of expansion, while the expansion coeﬃcients for each cg

where cR
modules,
{
are given by µmˆg(g)
m .

ˆcm}

So far we have left the normalization of E unspeciﬁed. In fact the choice of normaliza-
tion follows from the interpretation of the data, if, instead of a minimal residual term in
eq. (42), one demands maximal variance among the principal components (the projections
of the data rows or columns onto the eigenvectors associated with the largest eigenvalues).
For example, if the expression data is viewed as a collection of gene-vectors, one would like
to ﬁnd the vector ˆg1 that maximizes the variance of the principal components c(c)
c ˆg1,
i.e.

1 = gT

NC

V g
1 =

1
NC

c(c)
1 − h

c(c)
1 ic

2

=

1
NC

ˆgT
1 Sg ˆg1 .

Xc=1 (cid:16)
Here the bilinear term has been written in terms of the scatter matrix

(cid:17)

1 under the constraint that ˆgT

Maximizing V g
1 ˆg1 = 1 is equivalent to ﬁnding the eigenvector
of Sg associated with the largest eigenvalue. For normalized data, Sg coincides with the
gene-gene correlation matrix

Sg ≡

(gc − h

gcic) (gc − h

gcic)T .

NC

Xc=1

Cg = ET

C EC with

gg′
g = ˆcT
C

g ˆcg′ .

24

(52)

(53)

(54)

Conversely, if the expression data is viewed as a collection of condition-vectors, the vector
ˆc1 that maximizes the variance of the components g(g)
g ˆc1, is the eigenvector associated
with the largest eigenvalue of the scatter matrix

1 = cT

For normalized data, Sc equals to the condition-condition correlation matrix

Sc ≡

cg − h

cgig

cg − h

cgig

(cid:17) (cid:16)

T

.

(cid:17)

NG

Xg=1 (cid:16)

Cc = EG ET

G with

cc′
c = ˆgT
C

c ˆgc′ .

Note, however, that since EG 6
Cc and Cg, and do not represent correlation matrices.

= EC, the matrices EC ET

C and ET

G EG are diﬀerent from

A.2 The variance of a product of random variables

By deﬁnition the mean of the product of two independent random variables a and b is the
product of their mean values, i.e.

h
Since the expression for the variance of the product ab in eq. (19) may be somewhat less
obvious, we give its derivation here. From the deﬁnition of the variance

ih

h

=

a

ab
i

.

b
i

V (a)

(a

≡ h

− h

)2

a
i

i

=

a2

h

i − h

2 ,

a
i

we obtain

V (a)V (b) =

a2

h
(cid:16)
a2
h

2

a
i

2

b2

b
i
i − h
a2

i − h

h
(cid:17) (cid:16)
2
b2
a
h
i

i − h
b2

ih

i − h

=

2 +

(cid:17)
b
i
ih

2

a
i
h

b
i
h

2 .

Then using eqs. (57)-(60) it follows that

V (ab) =

a2b2
h
a2
h

i − h
b2

i − h
ih
= V (a)V (b) +

=

= V (a)V (b) +

2

2

2

ab
i
a
i
a
h
i
a2

b
i
h
2
b2

h

= V (a)V (b) + V (a)

h

(cid:16)

i

+

a2
h
2

ih
b
a
i
i
(cid:17)
2 + V (b)

h

2

b
−
i
2 +
h
(cid:16)
2 .

a
i

h

i − h
b
i

h

2

h

a
2
i
h
b2

2

b
i
b
i

2

i − h

2

a
i

h

(cid:17)

(55)

(56)

(57)

(58)

(59)

(60)

(61)

(62)

(63)

(64)

(65)

A.3 Accurate treatment of the noise propagation

In order to simplify our presentation of the propagation of the noise under the iterative
scheme in eq. (17) we used the approximate recursive equation in eq. (25) to derive the

25

ﬁxed point noise-to-signal ratio in eq. (26). Here we give an accurate treatment that is
valid even if N (m)

1 is not satisﬁed.

First, note that if the iterative scheme converges, then for n
= ˜v(∗)

G =
G . In this case we can write two ﬁxed-point equations

G = ˜v(n−1)

= v(∗)

→ ∞

G

v(n−1)

G

we have v(n)

G ≫
G and ˜v(n)

˜v(∗)

G

1
 

−

v(∗)

G

1

 

∆NGvC
(N (m)
G )2 !
1
N (m)

G !

−

=

vC
N (m)
G

= ˜v(∗)
G .

(v(∗)

G + 1) ,

Solving eqs. (66) and (67) for v(∗)

G we get:

−1

−1

N (m)
G
vC −



−

1
 

v(∗)
G =

1
N (m)
G ! 


Here, the approximation on the right-hand-side neglects the 1/N (m)
G term and yields exactly
the same result as obtained from the simpliﬁed iterative scheme in eq. (25) that ignores
the diﬀerence between v(n)

∆NG
N (m)
G

NG
N (m)
G

≃ 


(68)

G and ˜v(n)
G .

−







1







.

N (m)
G
vC −

Interestingly, a necessary condition for convergence can be derived also without any
approximation directly from eqs. (23) and (24). To this end note that eq. (24) implies
trivially that v(n)

˜v(n)
G . Then it follows that

G ≥

Thus if

v(n)
G ≤

NGvC + N (m)
G
(N (m)
G )2

v(n−1)

G

+

vC
N (m)
G

.

vcrit
C

vC

≤

≡

N (m)

G (N (m)
NG

G −

1)

the noise-to-signal ratio v(n)

G converges to a ﬁnite value.

(66)

(67)

(69)

(70)

26

References

[1] Schena M., Shalon D., Davis R.W., Brown P.O., Quantitative monitoring of gene expression
patterns with a complementary DNA microarray, Science 20; 270(5235): 467-70 (1995).

[2] DeRisi J.L., Iyer V.R., Brown P.O., Exploring the metabolic and genetic control of gene

expression on a genomic scale, Science 24; 278(5338): 680-6 (1997).

[3] Lander E., Array of hope, Nat Genet 21(1 Suppl.): 3-4 (1999). (See also other articles in this

issue.)

[4] Schulze A. and Downward J., Navigating gene expression using microarrays–a technology

review, Nat Cell Biol 3(8): E190-5 (2001).

[5] A comprehensive database for expression data from various organisms has been established

by:
Sherlock G. et al., The Stanford Microarray Database, Nucleic Acids Res 29(1): 152-155
(2001). See also: http://genome-www.stanford.edu/microarray .

[6] A complete list of the references used to compile the yeast expression data studied in this

paper can be found at: http://www.weizmann.ac.il/∼jan/NG/MainFrames.html .

[7] Eisen M.B., Spellman P.T., Brown P.O. and Botstein D., Cluster analysis and display of

genome-wide expression patterns, Proc Natl Acad Sci U S A 95: 14863-14868 (1998).

[8] Spellman P.T., et al., Comprehensive identiﬁcation of cell cycle-regulated genes of the yeast
Saccharomyces cerevisiae by microarray hybridization, Mol Biol Cell 9(12): 3273-97 (1998).

[9] Alon U. et al, Broad patterns of gene expression revealed by clustering analysis of tumor
and normal colon tissues probed by oligonucleotide arrays, Proc Natl Acad Sci U S A 96:
6745-6750 (1999).

[10] Tavazoie S., Hughes J.D., Campbell M.J., Cho R.J., Church G.M., Systematic determination

of genetic network architecture, Nat Genet 22(3): 281-5 (1999).

[11] Perou C.M., et al., Distinctive gene expression patterns in human mammary epithelial cells

and breast cancers, Proc Natl Acad Sci U S A 96: 9212-9217 (1999).

[12] Bittner M., et al., Molecular classiﬁcation of cutaneous malignant melanoma by gene expres-

sion proﬁling, Nature 3, 406(6795): 536-40 (2000)

[13] Scherf U. et al., A gene expression database for the molecular pharmacology of cancer, Nat

Genet 24: 236-244 (2000).

[14] Staunton J.E., et al., Chemosensitivity prediction by transcriptional proﬁling, Proc Natl Acad

Sci U S A 98: 10787-10792 (2001).

[15] Brazma A. and Vilo J., Gene expression data analysis, FEBS Lett 480: 17-24 (2000).

27

[16] Altman R.B., Raychaudhuri S., Whole-genome expression analysis: challenges beyond clus-

tering, Curr Opin Struct Biol 11(3): 340-7 (2001).

[17] Holter N.S. et al., Fundamental Patterns underlying gene expression proﬁles: Simplicity from

complexity, Proc Natl Acad Sci U S A 97: 8409-8414 (2000).

[18] Alter O., Brown P.O., Botsein, D., Singular value decomosition for genome-wide expression

data processing and modeling, Proc Natl Acad Sci U S A 97: 10101-10106 (2000).

[19] Tamayo P. et al., Interpreting patterns of gene expression with self-organizing maps: methods
and application to hematopoietic diﬀerentiation, Proc Natl Acad Sci U S A 96: 2907-2912
(1999).

[20] Bittner M., Meltzer P. and Trent J., Data analysis and integration: of steps and arrows, Nat

Genet 22: 213-215 (1999).

Biol 8: 93-103 (2000).

[21] Cheng Y. and Church G. M., Biclustering of expression data, Proc Int Conf Intell Syst Mol

[22] Getz G., Levine E. and Domany E., Coupled two-way clustering analysis of gene microarray

data, Proc Natl Acad Sci U S A 97: 12079-12084 (2000).

[23] Ihmels J., Friedlander G., Bergmann S., Sarig O., Ziv Y. and Barkai N., Revealing modular

organization in the yeast transcriptional network, Nat Genet 31(4): 370-377 (2002).

[24] Duda R.O., Hart P.E. and Stork D.G., Pattern Classiﬁcation, John Wiley & Sons, Inc., New

[25] Golub G. H. and Van Loan C. F., Matrix Computation, Johns Hopkins Univ. Press, Baltimore

York, 2nd edition (2001).

(1996).

[26] Bergmann S., Ihmels J. and Barkai N., in preparation.

28

(a)

100

s
e
n
e
g

200

300

400

500

(c)

s
e
r
o
c
s
 
n
o
i
t
i
d
n
o
c

expression data

(b)

gene scores

s
e
n
e
g

100

200

300

400

500

c

(c)
S

c

(c)
C

c

(c)
G

20

60
40
conditions

80

100

g

(g)
S

g

(g)
C

g

(g)
G

no normalization
condition normalization
gene normalization

20

60
40
conditions

80

100

S ≡

[0, 1] and sc ∈

Figure 1: How to properly normalize the expression matrix. (a) An in-silico expression
matrix, corresponding to two overlapping modules of equal size and strength, was generated
according to the model described in the text. The elements of the original expression
matrix Ecg, were scaled to Ecg
Ecgsgsc, where sg ∈
[0, 1] are random
scale factors selected from a uniform distribution for each gene g and condition c. From
ES we calculated the normalized expression matrices EG and EC according to eqs. (3)
and (4). (b) From the vector c1, whose non-zero components c(c)
specify the conditions
1
S c1, gC = ET
of the upper-left module in (a) we calculated the vectors gS = ET
Cc1 and
Gc1. We plot their components (horizontal axes) g(g)
gG = ET
C (dark gray) and
g(g)
G (light gray) as a function of the gene index (vertical axis). Only for gC, obtained
according to normalization used in the ISA, all the components associated with the genes
of the module are signiﬁcantly larger than the others. (c) From the vector g1, whose non-
zero components g(g)
specify the genes of the upper-left module in (a) we calculated the
1
vectors cS = ESg1, cC = ECg1 and gG = EGc1. We plot their components (horizontal
axes) c(c)
G (light gray) as a function of the condition index
(vertical axis). Only for cG, obtained according to normalization used in the ISA, all the
components associated with the conditions of the module are signiﬁcantly larger than the
others.

C (dark gray) and c(c)

S (black), c(c)

(black), g(g)

S

29

(a)

(b)

)

5
G
ρ
4
(
)
G(
*
ρ
3

8

7

6

2

1

0

t = 0
t = 1
t = 2
t = 3
t = 4
t = 5
t = 6
t = 7
t = 8

)
t
4
(
)
G(
*
ρ

8

7

6

5

3

2

1

0

1

0

(c)

0.5

0 1 2 3 4 5 6 7 8 9 10 11
ρ

G

0

1

2

3

4

5

6

7

8

(m)
(m)(t) / N
N
G
G
∆ N
(t) / ∆ N
G
N

G

(m)(t)+∆ N
(m)(t) / [N
G
G

G

(t)]

0

2

6

8

t

4

t

i

G

1/2

≡

C −

G ρ2

→ q

( ˜N (m)

˜N (m)
h

G + ∆ ˜NG)/ ˜N (m)

G (t). For ρG ≫

t, the eﬀective number ˜N (m)

Figure 2: Finding the ﬁxed point value of the signal-to-noise ratio. (a) The ﬁxed point value
of the signal-to-noise ratio ρ(∗)
G (t) is found by solving eq. (34) (c.f. section 5). We plot its
right-hand-side RHS(ρG, t)
as a function of ρG for
several values of the threshold t as indicated in the legend (setting NG = 6000, N (m)
G = 60,
ρC = 1). RHS(ρG, t) depends on ρG and t through the eﬀective numbers ˜N (m)
G (t, ρG) and
∆ ˜NG(t) (deﬁned in eqs. (32) and (33)) that denote the expected number of genes inside and
outside the module that passed the threshold. Each curve increases monotonically from
G approaches N (m)
zero to its maximal value ρmax
G .
G (t) depends on t only through ∆ ˜Ng, which goes to zero for t
In this limit ρmax
1. Thus
N (m)
ρmax
G ρ2
G (t)
1 asymptotically. According to eq. (34) the ﬁxed-point solutions for
the signal-to-noise ratio ρ(∗)
G (t) are given by ρG = RHS(ρG, t) and therefore correspond to
the intersections (indicated by the big dots) of these curves with the diagonal (shown as a
dashed line). (b) The solutions in (a) are plotted as a function of the threshold t. For a
relatively small threshold (t <
G (ρG, t) increases rapidly as a function of t, saturates to
∼
ρmax
6). This behavior
G
can be understood from (a): For a low threshold the intersection of curves for RHS(ρG, t)
with the diagonal appears at small values of ρG. For larger t the intersections occur in the
ρmax
G (t). However, if t is too large the
saturated regime of RHS(ρG, t), such that ρG ≃
G (t)/N (m)
curves do not intersect with the diagonal and there is no solution. (c) ˜N (m)
G (dark
gray) as well as ∆ ˜NG(t)/∆NG (light gray) and ̺(t)
G (t) + ∆ ˜NG(t)) (black)
are shown as a function of t. ̺(t)
t < 6, indicating the optimal regime for the
threshold.

2 and suddenly falls oﬀ to zero at a certain threshold ttrans(

1 for 3 <
∼

G (t)/( ˜N (m)

for t >
∼

2) ρ(∗)

˜N (m)

C −

≫

≃

≈

≡

30

(a)

(*)(t,ρ
ρ
)
C
G

(b)(b)

r(t,ρ
)
C

C

ρ

0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
2.2
2.4

15

5

10

C

ρ

0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
2.2
2.4

−2 −1 0 1 2 3 4 5 6 7 8
t

−2 −1 0 1 2 3 4 5 6 7 8
t

1

0.8

0.6

0.4

0.2

0

C >
∼

0.5). There is an optimal regime for the threshold t, where ρ(∗)

Figure 3: Properties of the ﬁxed point value of the signal-to-noise ratio.
(a) The ﬁxed
point value of the signal-to-noise ratio, ρ(∗)
G (t, ρC), characterizes the separability between
the gene score distributions for the genes inside and outside the single module (c.f. sec-
tion 5 for details). The plot shows ρ(∗)
G (t, ρC) as a function of both the threshold t and
the (ﬁxed) signal-to-noise ratio in the expression matrix ρC. For very small thresholds
ρ(∗)
G (t, ρC) vanishes if ρC is below some critical value ρcrit
1.3. However, increasing the
C ≈
threshold the iterations converge to a ﬁnite ﬁxed-point, ρ(∗)
G (t, ρC) > 0, even if ρC < ρcrit
(but ρC > ˜ρcrit
G (t, ρC) is
(near to) maximal. Within this regime ρ(∗)
G (t, ρC) depends only weakly on t, so the conver-
gence is robust with respect to the exact choice of the threshold. The size of this regime
(ρ(∗)
increases with ρC. (b) The ratio r(t, ρC)
G (t, ρC) characterizes
≡
the improvement in the identiﬁcation of transcription modules that is achieved by the
application of the threshold function. (ρ(∗)
G (ρC) denotes the ﬁxed-point value of the signal-
to-noise ratio in the absence of a threshold, and r(t, ρC) is set to zero for ρ(∗)
G (t, ρC) = 0.)
We show r(t, ρC) as function of t and ρC. The regime where ρC < ρcrit
is subdivided into a
white region (r(t, ρC) = 1), where the iterative scheme only converges to a positive value,
ρ(∗)
G (t, ρC) > 0, due to the threshold and a black area (r(t, ρC) = 0), where the iterative
schemes does not converge to a positive value implying that the module cannot be iden-
tiﬁed in this regime. Note that also for ρC > ρcrit
, where the iterative schemes converges
to a positive value even without a threshold, there exists a large region in the parameter
space of t and ρC (the light gray area for r(t, ρC)), where ρ(∗)
G (t, ρC) is signiﬁcantly larger
than ρ(∗)

G (ρC))/ρ(∗)
ρ(∗)

G (t, ρC)

−

C

C

C

G (t).

31

(a)

0.2

0.1

n
o
i
t
c
a
r
f

0
−0.1

(b)

)
n
(
 
n
o
i
t
a
r
e
t
i

1

2

3

4

5

6

7

8

9

6

2

0

10

−0.1

(d)

4
)
n
G(
ρ

initial input set distribution

genes not in module
genes in module

−0.05

0

0.1

0.15

iterations w/o threshold

iterations with threshold

score

0.05

(c)

)
n
(
 
n
o
i
t
a
r
e
t
i

1

2

3

4

5

6

7

8

9

10

32

−0.05

0

0.05

0
signal−to−noise evolution

0.1

0.05

0.1

0.15

0.2

init

1

2

3

7

8

9

10

4

5
iteration (n)

6

numeric simulation
(without t)
theor. prediction
(without t)
analytic fixed point

−

Figure 4: Evolution of the score distributions under the ISA. (a) The distributions of the
gene scores of 100 input sets which serve as seeds for the iterations of our algorithm: The
distribution of the genes that are not part of the TM (light gray) has a vanishing mean
value. The genes belonging to the module (black) are distributed with a positive mean
value. Note that the two initial distributions cannot be distinguished from each other
c) Evolution of the two distributions under the iterative scheme deﬁned by
accurately. (b
eq. (17). (b) Without applying a threshold, the mean of the signal-distribution decreases
in each iteration and the separability of the two distributions does not improve. (c) When
a threshold (t = 1) is applied the mean of the signal distribution increases in each step
until it saturates at a value where the two distributions are well separated. (d) The signal-
to-noise ratio ρ(n)
G characterizes the separability between the gene score distributions for
the genes within and outside the module (c.f. section 5 for details). We plot ρ(n)
G as a
function of the number of iterations n. The evolution of ρ(n)
G under the iterations scheme
with (squares) and without (circles) a threshold obtained from the numerical simulation
(gray) are in good agreement with the theoretical predictions (black) according to eq. (25).
We used NG = 1700, N (m)

G = 40 and ρC = 1 for this ﬁgure.

(a) expression data

(b) converged gene sets

 = −2

t
G

 = −1

t
G

 = 0

t
G

 = 1

t
G

 = 2

t
G

s
e
n
e
g

s
e
n
e
g

s
e
n
e
g

s
e
n
e
g

s
e
n
e
g

1
::
500

1
::
500

1
::
500

1
::
500

1
::
500

1000

s
t
e
s

500

0
−2

1 .... 100
conditions
(c) set distribution

i=1

i=2

i=3

i=4

i=5

i=6

i=7

i=8

i=9

i=10

set index 

 ∪ M
M
2
1

 ∩ M
M
2
1

M
1

M
2

−1.5

−1

−0.5

0
gene threshold t

0.5

G

1

1.5

2

−

Figure 5: Identiﬁcation of overlapping modules. An in-silico expression matrix describing
500 genes under 100 experimental conditions was generated according to the model intro-
duced in the text. The data corresponds to two overlapping transcription modules M1 and
M2, each containing 250 genes and 50 conditions. (a) The expression matrix is shown for
c) Using this matrix we applied the ISA to 1000
comparison on the left of each row. (b
input sets composed of randomly chosen genes. Iterations were performed using diﬀerent
choices of the threshold tG. (b) The boxes in each row represent 10 of the resulting con-
verged gene sets, that were obtained for tG as indicated on the left. Each box i = 1, ..., 10
is composed of 500 lines that specify the genes which appear in the corresponding ﬁxed
point. Genes that belong to the converged set are represented by a dark gray line, while
the remaining genes are shown in light gray. For tG ≃ −
2 the output sets contain all the
genes, tG ≃ −
1 yields output sets containing the genes that are associated with either of
the two modules, for tG ≃
0 there are two types of output sets, comprising either the genes
of M1 or of M2, for tG ≃
1 all the output set contain only those genes that belong to both
modules and for tG ≃
2 the output sets are essentially empty. (c) The number of sets
that converged (within 95% accuracy) to M1
M1 (solid), M1 (dotted), M2 (dashed) or
M1
M1 (dash-dotted) are plotted as a function of tG. Scanning over diﬀerent thresholds
S
reveals the modular structure of the expression data (M1

M1).

M1

T

M1 →

M1, M2 →

S

T

33

]

%

l

[
 
)
s
e
u
d
o
m

(
 
s
e
n
e
g

 

d
e

i
f
i
t

n
e
d

i
 
y
l
t
c
e
r
r
o
c
 
f
o
 
n
o
i
t
c
a
r
F

100

90

80

70

60

50

40

30

20

10

0
0

Signature Approach

Clustering

ISA: identified genes per module
ISA: identified modules
Clustering: identified genes per cluster
SVD: overlap with largest eigenvectors

SVD

1

2
σ (added noise)

3

4

Figure 6: Module identiﬁcation from noisy expression data. In-silico expression matrices
for 1050 genes under 1000 conditions, corresponding to 25 non-overlapping transcription
modules of diﬀerent sizes, were generated according to the model described in the text.
Noise from a uniform distribution was superimposed onto this expression data. The width
σ of this noise distribution was varied, simulating diﬀerent levels of noise. We quantiﬁed
the eﬃciency of diﬀerent algorithms to retrieve the modules from the expression data
as described in the text. We show the fraction of correctly identiﬁed genes for the ISA
(circles), hierarchical clustering (squares) and SVD (triangles). For the ISA we also the
fraction of correctly identiﬁed modules are indicated (asterisks). SVD is very sensitive to
the addition of noise and fails to identify the modules accurately, even for a small level of
noise. Clustering can handle a moderate amount of noise, but not as much as the ISA.

34

]

%

l

[
 
)
s
e
u
d
o
m

(
 
s
e
n
e
g
 
d
e
i
f
i
t
n
e
d
i
 
y
l
t
c
e
r
r
o
c
 
f
o
 
n
o
i
t
c
a
r
F

100

90

80

70

60

50

40

30

20

10

0
1

ISA

ISA: identified genes per module
ISA: identified modules
Clustering: identified genes per cluster
Clustering: identified clusters
SVD: overlap with largest eigenvectors

Clustering

SVD

2

3

4

5

6

n

TF

Figure 7: Module identiﬁcation in the presence of combinatorial regulation. In-silico ex-
pression matrices corresponding to 25 overlapping modules were generated according to a
model that allows for combinatorial regulation (see text for details). The degree of overlap
between the modules is speciﬁed by the average number of transcription factors involved
in the regulation of each gene (nT F ). Only for nT F = 1 each gene is associated with ex-
actly one transcription factor. For larger values of nT F distinct modules share common
genes. We applied the SVD, hierarchical clustering (see Ref. [23] for related results) and
the ISA to the expression matrices generated for nT F = 1, ..., 6 and evaluated the outputs
as described in the text. The ISA could successfully identify all the transcription mod-
ules even in the case of highly overlapping modules (asterisks), The fraction of correctly
identiﬁed genes per module only decreases slightly as a function of nT F (circles). In con-
trast, for nT F > 1 the identiﬁcation capabilities of clustering (squares/crosses) and SVD
(triangles) rapidly decrease. This is because the clustering algorithm does not allow for
multiple assignments of one gene to diﬀerent modules and therefore usually captures only
small, incomplete fractions of the overlapping modules. Similarly, if the expression matrix
cannot be reorganized into block-diagonal shape due to the overlap between the modules,
the eigenvectors identiﬁed by SVD fail to characterize the modules properly.

35

1 Protein synthesis

5 Cell cycle (G1)

2 Mating

4 Amino acid synthesis

3 Stress

=1.8

t
G

5

4

1

3

2

=2.1

t
G

=2.4

t
G

{

}

1.8, 2.1, 2.4

Figure 8: Modular organization of yeast expression data. The iterative signature algorithm
was applied to genome wide yeast expression data gathered by more than 1000 DNA-chip
experiments. (a) The ﬁgure shows the identiﬁed modules at three diﬀerent gene-thresholds
tG =
. For each threshold the corresponding modules are displayed in a plane,
such that their distance reﬂects their correlation with respect to conditions. Moving to a
higher threshold, corresponding of modules are kept in the same position in each plane,
while the “new” modules are placed such that their position reﬂects best their correlation
with the other modules. The left-most plane corresponds to the lowest threshold (tG = 1.8),
where only ﬁve ﬁxed points exist. The corresponding modules can be associated with
central functions of the yeast organism: protein synthesis, cell-cycle (G1), mating, amino-
acid biosynthesis and stress response. We use color coding to indicate which of the ﬁxed
points that emerge at higher thresholds are related to these ﬁve central modules (i.e. they
would convergence to the respective module at the lowest threshold). b) The pie charts
show for the number of random input sets that converged to the respective ﬁxed point.
The color coding is as in (a).

36

