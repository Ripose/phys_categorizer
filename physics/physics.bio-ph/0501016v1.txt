5
0
0
2
 
n
a
J
 
5
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
6
1
0
1
0
5
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

APS/123-QED

Molecular recognition in a lattice model: An enumeration study

Thorsten Bogner, Andreas Degenhard, Friederike Schmid
Condensed Matter Theory Group, Fakult¨at f¨ur Physik, Universit¨at Bielefeld
(Dated: January 8, 2013)

We investigate the mechanisms underlying selective molecular recognition of single heteropolymers
at chemically structured planar surfaces. To this end, we study systems with two-letter (HP) lattice
heteropolymers by exact enumeration techniques. Selectivity for a particular surface is deﬁned by
an adsorption energy criterium. We analyze the distributions of selective sequences and the role of
mutations. A particularly important factor for molecular recognition is the small-scale structure on
the polymers.

PACS numbers: 87.15.Aa, 87.14.Ee, 46.65.+g, 68.35.Md

Selective molecular recognition governs many biolog-
ical processes such as DNA-protein binding1 or cell-
mediated recognition2. Biotechnological applications
range from the development of biosensoric materials3 to
cell-speciﬁc drug-targeting4. The speciﬁcity in these pro-
cesses results from the interplay of a few unspeciﬁc inter-
actions (van der Waals forces, electrostatic forces, hydro-
gen bonds, and the hydrophobic force)5 and a hetero-
geneous composition of the polymer chain. Selectivity
is a genuinely cooperative eﬀect. The question how it
emerges in a complex system is therefore very interest-
ing from the point of view of statistical physics, and the
study of idealized models can provide insight into general
principles6,7,8,9.

Previous theoretical studies have mostly considered
heteropolymer adsorption in either regular10 or ran-
dom6,8,11,12 systems. The interplay of cluster sizes on
random heteropolymers and random surfaces and its in-
ﬂuence on the adsorption thermodynamics and kinet-
ics was studied analytically and with computer simula-
tions8,12,13. Concepts from the statistical physics of spin
glasses were used to study the adsorption of polymers on
a “native” surface compared with that on an arbitrary
random surface6,8,14.

In the present paper, we focus on a diﬀerent question:
We investigate mechanisms by which speciﬁc heteropoly-
mers distinguish between given surfaces. To this end, we
adopt an approach which has proven highly rewarding
in the context of the closely related problem of protein
folding15,16,17,18: We enumerate exactly all polymer con-
formations within a lattice model. The protein is de-
scribed as a heteropolymer chain consisting of two types
of monomers, hydrophobic (H) and polar (P), which oc-
cupy each one site on the lattice. Empty sites are au-
tomatically assumed to contain solvent. The protein is
exposed to an impenetrable ﬂat surface covered with sites
of either type H or type P, which form a particular surface
pattern. It may adsorb there and change its conforma-
tion during the adsorption process. However, we require
that both the free and the adsorbed chain are compactly
folded in a cube17,18.

Nearest neighbour particles interact with ﬁxed, type
dependent interaction energies. Surface sites H and P
are considered to be equivalent to monomer sites H and

P. The total energy is then given by:
i τ β
τ α

Etot = X
<i,j>

X
α,β

j Eαβ

(1)

Here the sum < i, j > runs over nearest neighbour pairs,
the sums α and β run over the types hydrophobic (H),
polar (P), or solvent (S), and τ γ
is an occupation number
i
which takes the value one if the site i is occupied with
type γ, and zero otherwise. The interaction parameters
were chosen EHP = 0.1, EP S = E0, EHS = E0 + 1, and
zero otherwise, where E0 is arbitrary, but large enough
to ensure compact folding. These parameters are almost
equivalent to those used in Ref.18.

We consider two-dimensional and three-dimensional
systems with system sizes up to 6×6 (in 2D) and 3×3×3
(in 3D), respectively. For each system, a set of se-
quences was picked randomly (uncorrelated monomers,
equal probability for H and P). For each sequence, we
then evaluated the energies for all possible compact chain
conformations in contact with all possible surfaces. This
allowed to determine exactly the ground-state adsorption
energy on every surface. We call a sequence selective, if
there exists one unique surface with highest adsorption
energy, i.e., if the diﬀerence

Egap = E1st

ad − E2nd
ad .

(2)

between the adsorption energies on the two most favor-
able surfaces is nonzero. The lowest-energy structure of
the chain on its favorite surface (the “selected” surface)
is not necessarily unique.

We note that this selectivity criterion is a “zero-
temperature” criterion. Entropic contributions to the
adsorption free energy are not accounted for. Further-
more, we disregard dynamic and kinetic factors19, which
presumably also play a role in molecular recognition pro-
cesses.

The fraction of selective sequences is summarized for
diﬀerent lattice sizes in Table I.
It was always higher
than 90%. The distribution of these sequences on the
diﬀerent surfaces turns out to be highly inhomogeneous
(see Fig. 1). In the case of the 6 × 6 lattice, the relative
fractions range from 1.5510−4 to 0.2378. In three dimen-
sions, approximately half of all surfaces were not selected
by any sequence in our sample.

0.2

0.15

0.1

0.05

y
c
n
e
u
q
e
r
f
 
e
v
i
t
a
l
e
R

TABLE I: Fraction of sequences selecting a unique surface.

Lattice
5 × 5
6 × 5
6 × 6
3 × 3 × 3

Fraction of selective sequences
0.9211
0.976561
0.956666
0.91361

Size of sample
100.000
50.000
60.000
100.000

A closer inspection reveals that two main factors con-
tribute to the frequency with which sequences select a
particular surface pattern: A high number of hydropho-
bic sites inside the pattern is beneﬁcial, whereas hy-
drophobic sites at the border are unfavorable. The fre-
quency distribution could be ﬁtted remarkably well by
the simple formula

N =

Anm
core + B
nborder + 1

,

(3)

where ncore denotes the number of hydrophobic core
sites, nborder the number of hydrophobic border sites,
m the total number of core sites, and A and B are ﬁt
parameters. For the 5 × 5 system, such a ﬁt is illustrated
in Fig. 1. The functional form of Eq. (3) was guessed
empirically, with no underlying theory, and should not
be over-interpreted. Nevertheless, we can conclude that
the relative frequency of surface patterns is mostly deter-
mined by a few, unspeciﬁc surface characteristics.

The previous analysis raises the question how se-
quences which are selective for diﬀerent surfaces dif-
fer from one another, or, conversely, which features se-
quences belonging to the same surface have in common.

Estimation
100 000 randomly sampled sequences
reduced set of 326 sequences

y
c
n
e
u
q
e
r
f
 
e
v
i
t
a
e
r

l

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

P

H

Surface structures (one dimensional)

FIG. 1: Relative frequency of sequences selective for diﬀerent
surfaces on the 5 × 5 lattice. The black bars show the result
for a random sample, the gray bars for a sample based on a
“master sequence”. Also shown are the values obtained with
a least-square ﬁt to Eq. (3) (see text for explanation).

several surfaces
 

5000 random sequences

 

2

0

2

4

6

8

10

12

16

14
8
Hamming distance

18

6

4

10

12

14

16

18

FIG. 2: Histograms showing the distribution of Hamming
distances for the 5 × 5 (left) and the 3 × 3 × 3 (right) lattice.

We have used diﬀerent approaches to address this prob-
lem.

The ﬁrst approach was motivated by the biological
principle of mutation. A similarity measure between two
chain sequences can be deﬁned by counting the mini-
mum number of point mutations required to construct
one sequence, starting from the other. For our two-letter
sequences, this is quantiﬁed using the Hamming distance

d(s, s′

) :=

|si − s′

i| ,

(4)

1
2 X

i

between sequences s and s′. The sum i runs over all
monomers along the chain, and the variables si, s′
i are
taken to be si, s′
i = 1 if the ith monomer of the sequence
s is hydrophobic, and si, s′
i = −1 otherwise. Two se-
quences that have a Hamming distance of n are thus sep-
arated by n point mutations. Since sequences can be read
in both directions, Eq. (4) usually yields two values for a
pair of sequences. We have always used the smaller one.
Based on this deﬁnition, we can now study whether
sequences belonging to the same surface are “close” in
sequence space. Examples of distributions of Hamming
distances for diﬀerent surfaces are shown in Fig. 2. The
distributions for diﬀerent surfaces, and even for diﬀerent
system sizes, are very similar. The number of mutations
with the highest occurrence is nearly half the total num-
ber of monomers in the polymer chain. Moreover, the
distribution is not very diﬀerent from that of a totally
random set of sequences, which is also shown in Fig. 2
for comparison. Hence we conclude that the sequences
selective for a particular surface are widely distributed
over the sequence space, and that proximity in sequence
space is not a relevant factor for molecular recognition.
This result has interesting practical consequences. An
important issue for many cell-surface recognition pro-
cesses is the question how eﬃciently nature distinguishes
between diﬀerent surfaces20, i.e., how many mutations
are required to change a polymer sequence that is selec-
tive for a particular surface to make it selective to an-

other surface or a whole class of diﬀerent surfaces.
In
our model, the observation that sequences selective to
the same surface appear to be widely spread in sequence
space suggests that one might ﬁnd sequences which are
selective to very diﬀerent surfaces at close vicinity in se-
quence space.

In order to test this idea, we have attempted to
compute subsets of sequences, which are close in se-
quence space and nevertheless “recognize” all surfaces,
i.e., which contain at least one selective sequence for each
surface. Such sets were constructed following a two-step
procedure. First, we identiﬁed a center or master se-
quence, which was a suitable initial point for the mu-
tation process. This was done mainly by trial and er-
ror, starting from the sequences belonging to the least
favorable surfaces. Second, we evaluated the number of
mutations necessary to provide a subset of sequences rec-
ognizing all surfaces. This analysis was carried out for
diﬀerent two-dimensional systems. The results are shown
in table II. In spite of the exponential growth in the num-
ber of possible polymer chain conformations and possible
sequence realizations, the number of necessary mutations
r in table II increases only slightly with the surface size.
The distribution of the sequences on the surfaces is shown
for one of these reduced subsets in Fig. 1, and can be com-
pared with the full distribution. The general features are
comparable.

We note that the values r for the minimum number
of mutations required to recognize all surfaces, as given
in table II, are upper limits and can possibly be reduced
further with more eﬃcient master sequences. Even so,
r is in some cases smaller than the minimum number
of mutations necessary to generate all surfaces (starting
from a common master surface). Hence only a few point
mutations can alter the adsorption characteristics pro-
foundly. This result matches with experimental results
obtained from binding force measurements on antibod-
ies21. Experimentally, it was observed that the wild-type
antibody and a mutant in which an amino acid at one
position in the chain has been exchanged diﬀer in the
measured aﬃnity by roughly one order of magnitude.

We return to the problem of determining common
features of sequences which are selective for the same
surface. First, we must clarify whether there are any
such features at all. To answer this question, we have
trained an artiﬁcial neural network (ANN) with a set of
sequences, of which half were selective for a given surface,

TABLE II: Number of mutations r necessary to generate a
subset of sequences which recognize all surfaces, together with
the corresponding subset size for various lattice sizes.

Lattice
5 × 4
5 × 5
6 × 5
6 × 6

surface size
5
5
6
6

r
2
2
3
4

size of set
209
326
466
7807

3

1

0.8

0.6

0.4

0.2

y
t
i
c
i
f
i
c
e
p
S

several surfaces for the 3x3x3 lattice
several surfaces for the 6x6 lattice
several surfaces for the 5x5 lattice

0

0

0.2

0.4

Sensitivity

0.6

0.8

1

FIG. 3: Performance of the two-layer perceptron trained for
several surface structures on the 5 × 5 and 3 × 3 × 3 lattice
displayed in a sensitivity versus speciﬁcity plot. For the 6 × 6
system the corresponding results obtained by a three-layer
perceptron with 16 hidden units are shown.

and the other half were selective for a diﬀerent surface or
not selective at all. Then the performance of the ANN
was tested with a second, disjoint set. This analysis was
performed for all surfaces with at least 100 selective se-
quences.

More speciﬁcally, we used a fully-connected three-layer
perceptron22. Prior to being presented to the ANN, the
sequences were transformed to Fourier space by a dis-
crete Fourier transform. The ANN was trained using
a backpropagation algorithm, and the training was ter-
minated at the previously determined ’early stopping’
point22. The performance of the ANN was characterized
by two measures, the sensitivity and the speciﬁcity: The
sensitivity gives the rate at which sequences which are
selective for the surface under consideration are classi-
ﬁed correctly (true positive), whereas the speciﬁcity cor-
responds to the rate with which non-selective sequences
are identiﬁed (true negative). The arithmetic mean of
these two values, the “correct classiﬁcation rate”, can be
used to quantify the performance of the ANN. It is 50 %
in random systems, and higher if the ANN has learned
something.

In our analysis, the ANN was in all cases able to gen-
eralize from the provided training sets. Moreover, we
found that an equally good performance could already be
achieved with a linear classiﬁer, i.e., a perceptron com-
posed of two layers, in the case of the 5 × 5 system and
the 3 × 3 × 3 system. In the 6 × 6 system, the complexity
of the nonlinear three-layer perceptron was necessary to
achieve a learning eﬀect. The results are plotted as sen-
sitivity versus speciﬁcity maps in Fig. 3. All points are
located in the upper right triangle, indicating that the
correct classiﬁcation rate is higher than 0.5. This proves
that sequences selecting a particular surface do indeed
have common features, which can be learned by a neural
network.

The next question is: What does the ANN learn? In
the case of a two-layer perceptron, the answer is rela-

4

We have carried out PCAs for various surfaces in the
5 × 5-, the 6 × 6-, and the 3 × 3 × 3 system. The results
revealed an unexpected common feature: For all surfaces
in the 5 × 5- and the 3 × 3 × 3 system, two particular
components turned out to be especially meaningful, with
variances which were considerably smaller than those of
all other components. These components correspond al-
most exactly to the highest frequency modes (real and
imaginary part). In the 6 × 6 system, the result was not
as simple, yet the high-frequency components were still
among the signiﬁcant components. A useful visualization
of sequence distributions for diﬀerent surfaces can there-
fore be obtained from projecting the sequence space onto
the high-frequency plane. Indeed, Fig. 4 illustrates for
the 3 × 3 × 3 system that sets of sequences belonging to
diﬀerent surfaces tend to occupy diﬀerent regions in this
plane.

To summarize, we have studied the recognition of
chemically structured surfaces by single polymer chains
comprising hydrophilic and hydrophobic monomer units.
Starting from already folded conformations, we investi-
gated distributions of selective sequences and the role of
point mutations. We found that sequences recognizing
the same surface are widely distributed in sequence space,
i.e., they are separated by many mutations. Conversely,
it was in many cases possible to construct a subset of
sequences which recognize all surfaces and nevertheless
diﬀer from one another by only a few mutations. Despite
their wide distribution, sequences recognizing the same
surface have features in common, which can be learned
by a neural network. One factor which turned out to be
particularly important in this recognition process is the
local, small-scale structure on the polymers.

We thank Alexey Polotsky for useful discussions and
the german science foundation (DFG) for partial support.

FIG. 4: Projection of sequences on the highest frequency (ω)
plane for the 3 × 3 × 3 lattice and various surface structures.
Some of the sets are completely separated in this plane.

tively simple22: The ANN classiﬁes by dividing the se-
quence space of dimension N into two parts by a N − 1
dimensional hyperplane. The fact that this classiﬁcation
is successful suggests that insight might be gained from
re-inspecting the distributions in sequence space of se-
quences belonging to the same surface. We have already
established that the characterization by the mere mu-
tual (Hamming) distances is not helpful. A more general
method is the “Principal Component Analysis” (PCA)22.
In this approach, the distribution is characterized by an
N × N covariance matrix which is then diagonalized.
Components with low variance correspond to meaning-
ful degrees of freedom, which presumably dominate the
recognition process.

1 K. Zakrzewska, Biopolymers 70, 414 (2003).
2 B. Alberts, D. Bray, J. Lewis, M. Raﬀ, K. Roberts, and
J. Watson, Molecular biology of the cell (Garland Publish-
ing, Inc. New York & London, 1994), 3rd ed.

3 E. Nakata, T. Nagase, S. Shinkai, and I. Hamachi, J. Am.

Chem. Soc. 126, 490 (2004).

4 Y. Christi, Biotechn. Adv. 22, 313 (2004).
5 J. Israelachvili, Intermolecular and surface forces (Aca-

demic Press, 1991).

6 J. Janin, Proteins 25, 438 (1996).
7 M. Muthukumar, Proc. Nat. Ac. Sci: USA 96, 11690

8 A. K. Chakraborty, Phys. Rep. 342, 1 (2001).
9 N.-K. Lee and T. A. Vilgis, Phys. Rev. E 67, 050901

(1999).

(2003).

10 M. Muthukumar, J. Chem. Phys. 103, 4723 (1995).
11 A. Polotsky, F. Schmid, and A. Degenhard, J. Chem. Phys.

12 A. Polotsky, F. Schmid, and A. Degenhard, J. Chem. Phys.

120, 6246 (2004).

(submitted).

13 A. J. Golumbfskie, V. S. Pande, and A. K. Chakraborty,

Proc. Nat. Ac. Sci: USA 96, 11707 (1999).

14 S. Srebnik, A. K. Chakraborty, and E. L. Shaknovich,

Phys. Rev. Lett. 77, 3157 (1996).

15 K. A. Dill, Biochemistry 24, 1501 (1985).
16 K. F. Lau and K. A. Dill, Macromolecules 22, 3986 (1989).
17 H. Li, R. Helling, C. Tang, and N. S. Wingreen, Science

18 H. Li, C. Tang, and N. S. Wingreen, Phys. Rev. Lett. 79,

273, 666 (1996).

765 (1997).

19 J.-U. Sommer, Eur. Phys. J. E 9, 417 (2002).
20 M. Davis, M. Krogsgaard, J. Huppa, C. Sumen, M. Purb-
hoo, D. Irvine, L. Wu, and L. Ehrlich, Ann. Rev. Bioch.
72, 717 (2003).

21 R. Ros, F. Schwesinger, D. Anselmetti, M. Kubon,
R. Sch¨afer, and A. Pl¨uckthum, Proc. Nat. Ac. Sci: USA
95, 7402 (1998).

22 C. M. Bishop, Neural Networks for Pattern Recognition

(Clarendon Press; Oxford University Press, 1995).

