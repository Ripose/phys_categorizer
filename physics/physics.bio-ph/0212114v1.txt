2
0
0
2
 
c
e
D
 
1
3
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
4
1
1
2
1
2
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

An information theoretic approach to the
functional classiﬁcation of neurons

Elad Schneidman,1,2 William Bialek,1 and Michael J. Berry II2
1Department of Physics and 2Department of Molecular Biology
Princeton University, Princeton NJ 08544, USA
{elads,wbialek,berry}@princeton.edu

February 2, 2008

Abstract

A population of neurons typically exhibits a broad diversity of
responses to sensory inputs. The intuitive notion of functional clas-
siﬁcation is that cells can be clustered so that most of the diversity
is captured in the identity of the clusters rather than by individuals
within clusters. We show how this intuition can be made precise us-
ing information theory, without any need to introduce a metric on
the space of stimuli or responses. Applied to the retinal ganglion
cells of the salamander, this approach recovers classical results, but
also provides clear evidence for subclasses beyond those identiﬁed
previously. Further, we ﬁnd that each of the ganglion cells is func-
tionally unique, and that even within the same subclass only a few
spikes are needed to reliably distinguish between cells.

1 Introduction

Neurons exhibit an enormous variety of shapes and molecular composi-
tions. Already in his classical work, Cajal [1] recognized that the shapes
of cells can be classiﬁed, and he identiﬁed many of the cell types that we
recognize today. Such classiﬁcation is fundamentally important, because
it implies that instead of having to describe ∼1012 individual neurons, a

1

mature neuroscience might need to deal only with a few thousand differ-
ent classes of nominally identical neurons. There are three broad methods
of classiﬁcation: morphological, molecular, and functional. Morpholog-
ical and molecular classiﬁcation are appealing because they deal with a
relatively ﬁxed property, but ultimately the functional properties of neu-
rons are the most important, and neurons that share the same morphology
or molecular markers need not embody the same function. With attention
to arbitrary detail, every neuron will be individual, while a coarser view
might overlook an important distinction; a quantitative formulation of the
classiﬁcation problem is essential.

The vertebrate retina is an attractive example: its anatomy is well stud-
ied and highly ordered, containing repeated micro-circuits that look out at
different angles in visual space [1, 2]; its overall function (vision) is clear,
giving the experimenter better intuition about relevant stimuli; and re-
sponses of many of its output neurons, ganglion cells, can be recorded
simultaneously using a multi–electrode array, allowing greater control of
experimental variables than possible with serial recordings [4]. Here we
exploit this favorable experimental situation to highlight the mathematical
questions that must lie behind any attempt at classiﬁcation.

Functional classiﬁcation of retinal ganglion cells typically has consisted
of ﬁnding qualitatively different responses to simple stimuli. Classes are
deﬁned by whether ganglion cells ﬁre spikes at the onset or offset of a step
of light or both (ON, OFF, ON/OFF cells in frog [5]) or whether they ﬁre
once or twice per cycle of a drifting grating (X, Y cells in cat [6]). Further
elaborations exist. In the frog, the literature reports 1 class of ON-type gan-
glion cell and 4 or 5 classes of OFF-type [7]. The salamander has been re-
ported to have only 3 of these OFF-type ganglion cells [8]. The classes have
been distinguished using stimuli such as diffuse ﬂashes of light, moving
bars, and moving spots. The results are similar to earlier work using more
exotic stimuli [9]. In some cases, there is very close agreement between
anatomical and functional classes, such as the (α,β) and (Y,X) cells in the
cat. However, the link between anatomy and function is not always so
clear.

Here we show how information theory allows us to deﬁne the problem
of classiﬁcation without any a priori assumptions regarding which fea-
tures of visual stimulus or neural response are most signiﬁcant, and with-
out imposing a metric on these variables. All notions of similarity emerge
from the joint statistics of neurons in a population as they respond to com-

2

mon stimuli. To the extent that we identify the function of retinal ganglion
cells as providing the brain with information about the visual world, then
our approach ﬁnds exactly the classiﬁcation which captures this function-
ality in a maximally efﬁcient manner. Applied to experiments on the tiger
salamander retina, this method identiﬁes the major types of ganglion cells
in agreement with traditional methods, but on a ﬁner level we ﬁnd clear
structure within a group of 19 fast OFF cells that suggests at least 5 func-
tional subclasses. More profoundly, even cells within a subclass are very
different from one another, so that on average the ganglion cell responses
to the simpliﬁed visual stimuli we have used provide ∼6 bits/sec of in-
formation about cell identity within our cell population. This is sufﬁcient
to identify uniquely each neuron in an “elementary patch” of the retina
within one second, and a typical pair of cells can be distinguished reliably
by observing an average of just two or three spikes.

2 Theory

Suppose that we could give a complete characterization, for each neuron
i = 1, 2, · · · , N in a population, of the probability P (r|~s, i) that a stimulus
~s will generate the response r. Traditional approaches to functional classi-
ﬁcation introduce (implicitly or explicitly) a parametric representation for
the distributions P (r|~s, i) and then search for clusters in parameter space.
For visual neurons we might assume that responses are determined by
the projection of the stimulus movie ~s onto a single template or receptive
ﬁeld, P (r|~s, i) = F (r;~fi·~s); classifying neurons then amounts to clustering
the receptive ﬁelds ~fi. But it is not possible to cluster without specifying
what it means for these vectors to be similar; in this case, since the vectors
come from the space of stimuli, we need a metric or distortion measure on
the stimuli themselves. It seems strange that classifying the responses of
visual neurons requires us to say in advance what it means for images or
movies to be similar.1

1If all cells are selective for a small number of commensurate features, then the set
of vectors ~fi must lie on a low dimensional manifold, and we can use this selectivity to
guide the clustering. But we still face the problem of deﬁning similarity: even if all the
receptive ﬁelds in the retina can be summarized meaningfully by the diameters of the
center and surround (for example), why should we believe that Euclidean distance in
this two dimensional space is a sensible metric?

3

(1)

(2)

Information theory suggests a formulation that does not require us to
measure similarity among either stimuli or responses. Imagine that we
present a stimulus ~s and record the response r from a single neuron in the
population, but we don’t know which one. This response tells us some-
thing about the identity of the cell, and on average this can be quantiﬁed
as the mutual information between responses and identity (conditional on
the stimulus),

I(r; i|~s) =

P (r|~s, i) log2

P (r|~s, i)
P (r|~s) #

"

bits,

N

1
N

r
Xi=1 X
N

P

where P (r|~s) = (1/N)
i=1 P (r|~s, i). The mutual information I(r; i|~s) mea-
sures the extent to which different cells in the population produce reliably
distinguishable responses to the same stimulus; from Shannon’s classical
arguments [10] this is the unique measure of these correlations which is
consistent with simple and plausible constraints. It is natural to ask this
question on average in an ensemble of stimuli P (~s) (ideally the natural
ensemble),

hI(r; i|~s)i~s =

[d~s]P (~s)P (r|~s, i) log2

N

1
N

Xi=1 Z

P (r|~s, i)
P (r|~s) #

;

"

hI(r; i|~s)i~s is invariant under all invertible transformations of r or ~s.

Because information is mutual, we also can think of hI(r; i|~s)i~s as the
information that cellular identity provides about the responses we will
record. But now it is clear what we mean by classifying the cells: If there
are clear classes, then we can predict the responses to a stimulus just by
knowing the class to which a neuron belongs rather than knowing its
unique identity. Thus we should be able to ﬁnd a mapping i → C of
cells into classes C = 1, 2, · · · , K such that hI(r; C|~s)i~s is almost as large as
hI(r; i|~s)i~s, despite the fact that the number of classes K is much less than
the number of cells N.

Optimal classiﬁcations are those which use the K different class labels
to capture as much information as possible about the stimulus-response
relation, maximizing hI(r; C|~s)i~s at ﬁxed K. More generally we can con-
sider soft classiﬁcations, described by probabilities P (C|i) of assigning
each cell to a class, in which case we would like to capture as much infor-
mation as possible about the stimulus-response relation while constrain-
ing the amount of information that class labels provide directly about

4

(3)

(4)

identity, I(C; i). In this case our optimization problem becomes, with T
as a Lagrange multiplier,

[hI(r; C|~s)i~s − T I(C; i)] .

max
P (C|i)

This is a generalization of the information bottleneck problem [11].

Here we conﬁne ourselves to hard classiﬁcations, and use a greedy ag-
glomerative algorithm [12] which starts with K = N and makes mergers
which at every step provide the smallest reduction in I(r; C|~s). This infor-
mation loss on merging cells (or clusters) i and j is given by

D(i, j) ≡ ∆Iij(r; C|~s) = hDJS[P (r|~s, i)||P (r|~s, j)]i~s,

where DJS is the Jensen–Shannon divergence [13] between the two distri-
butions, or equivalently the information that one sample provides about
its source distribution in the case of just these two alternatives. The matrix
of “distances” ∆Iij characterizes the similarities among neurons in pair-
wise fashion.

Finally, if cells belong to clear classes, then we ought to be able to re-
place each cell by a typical or average member of the class without sac-
riﬁcing function. In this case function is quantiﬁed by asking how much
information cells provide about the visual scene. There is a strict com-
plementarity of the information measures:
information that the stimu-
lus/response relation provides about the identity of the cell is exactly in-
formation about the visual scene which will be lost if we don’t know the
identity of the cells [14]. Our information theoretic approach to classiﬁ-
cation of neurons thus produces classes such that replacing cells with av-
erage class members provides the smallest loss of information about the
sensory inputs.

3 The responses of retinal ganglion cells to iden-

tical stimuli

We recorded simultaneously from 21 retinal ganglion cells from the sala-
mander using a multi-electrode array.2 The visual stimulus consisted of

2The retina is isolated from the eye of the larval tiger salamander (Ambystoma tigrinum
tigrinum) and perfused in Ringer’s medium. Action potentials were measured extra-

5

100 repeats of a 20 s segment of spatially uniform ﬂicker (see ﬁg. 1a), in
which light intensity values were randomly selected every 30 ms from a
Gaussian distribution having a mean of 4 mW/mm2 and an RMS contrast
of 18%. Thus, the photoreceptors were presented with exactly the same vi-
sual stimulus, and the movie is many correlation times in duration, so we
can replace averages over stimuli by averages over time (ergodicity). A 3 s
sample of the ganglion cell’s responses to the visual stimulus is shown in
Fig. 1b. There are times when many of the cells ﬁre together, while at other
times only a subset of these cells is active. Importantly, the same neuron
may be part of different active groups at different times. On a ﬁner time
scale than shown here, the latency of the responses of the single neurons
and their spiking patterns differ across time. To analyze the responses of
the different neurons, we discretize the spike trains into time bins of size
∆t. We examine the response in windows of time having length T , so that
an individual neural response r becomes a binary ‘word’ W with T /∆t
‘letters’.3

cellularly using a multi-electrode array [4], while light was projected from a computer
monitor onto the photoreceptor layer. Because erroneously sorted spikes would strongly
effect our results, we were very conservative in our identiﬁcation of cleanly isolated cells.
3As any ﬁxed choice of T and ∆t is arbitrary, we explore a range of these parameters.

6

Figure 1: Responses of salamander ganglion cells to modulated uniform ﬁeld
intensity. a: The retina is presented with a series of uniform intensity “images”.
The intensity modulation is Gaussian white noise distributed. b: A 3 sec segment
of the (concurrent) responses of 21 ganglion cells to repeated presentation of the
stimulus. The rasters are ordered from bottom to top according to the average
ﬁring rate of the neurons (over the whole movie). c: Firing rate and Information
rates of the different cells as a function of their rank, ordered by their ﬁring rate.
d: The average stimulus pattern preceding a spike for each of the different cells.
Traditionally, these would be classiﬁed as 1 ON cell, 1 slow-OFF cell and 19 fast-
OFF cells.

Since the cells in Fig. 1b are ordered according to their average ﬁring
rate, it is clear that there is no ‘simple’ grouping of the cells’ responses
with respect to this response parameter; ﬁring rates range continuously
from 1 to 7 spikes per second (Fig. 1c). Similarly, the rate of information
(estimated according to [15]) that the cells encode about the same stimu-
lus also ranges continuously from 3 to 20 bits/s. We estimate the average
stimulus pattern preceding a spike for each of the cells, the spike triggered
average (STA), shown in Fig. 1d. According to traditional classiﬁcation
based on the STA, one of the cells is an ON cell, one is a slow OFF cells
and 19 belong to the fast OFF class [16]. While it may be possible to sep-
arate the 19 waveforms of the fast OFF cells into subgroups, this requires
assumptions about what stimulus features are important. Furthermore,
there is no clear standard for ending such subclassiﬁcation.

7

4 Clustering of the ganglion cells responses into

functional types

To classify these ganglion cells we solved the information theoretic op-
timization problem described above. Figure 2a shows the pairwise dis-
tances D(i, j) among the 21 cells, ordered by their average ﬁring rates;
again, ﬁring rate alone does not cluster the cells. The result of the greedy
clustering of the cells is shown by a binary dendrogram in Fig. 2b.

Figure 2: Clustering ganglion cell responses. a: Average distances between the
cells responses; cells are ordered by their average ﬁring rate. b: Dendrogram of
cell clustering. Cell names correspond to their ﬁring rate rank. The height of a
merge reﬂects the distance between merged elements. c: The information that the
cells’ responses convey about the clusters in every stage of the clustering in (b),
normalized to the total information that the responses convey about cell identity.
Using different response segment parameters or clustering method (e.g., nearest
neighbor) result in very similar behavior. d: reordering of the distance matrix in
(a) according to the tree structure given in (b).

8

The greedy agglomerative approximation [12] starts from every cell as
a single cluster. We iteratively merge the clusters ci and cj which have the
minimal value of D(ci, cj) and display this distance or information loss as
the height of the merger in Fig. 2b. We pool their spike trains together as
the responses of the new cell class. We now re-estimate the distances be-
tween clusters and repeat the procedure, until we get a single cluster that
contains all cells. Fig. 2c shows the compression in information achieved
by each of the mergers: for each number of clusters, we plot the mutual in-
formation between the clusters and the responses, hI(r; C|~s)i~s, normalized
by the information that the response conveys about the full set of cells,
hI(r; i|~s)i~s. The clustering structure and the information curve in Fig. 2c
are robust (up to one cell difference in the ﬁnal dendrogram) to changes
in the word size and bin size used; we even obtain the same results with a
nearest neighbor clustering based on D(i, j). This suggests that the top 7
mergers in Fig. 2b (which correspond to the bottom 7 points in panel c) are
of signiﬁcantly different subgroups. Two of these mergers, which corre-
spond to the rightmost branches of the dendrogram, separate out the ON
and slow OFF cells. The remaining 5 clusters are subclasses of fast OFF
cells. However, Fig. 2d which shows the dissimilarity matrix from panel
a, reordered by the result of the clustering, demonstrates that while there
is clear structure within the cell population, the subclasses there are not
sharply distinct.

How many types are there?

While one might be happy with classifying the fast OFF cells into 5 sub-
classes, we further asked whether the cells within a subclass are reliably
distinguishable from one another; that is, are the bottom mergers in Fig. 2b-
c signiﬁcant? We therefore randomly split each of the 21 cells into 2 halves
(of 50 repeats each), or ‘siblings’, and re-clustered. Figure 3a shows the re-
sulting dendrogram of this clustering, indicating that the cells are reliably
distinguishable from one another: The nearest neighbor of each new half–
cell is its own sibling, and (almost) all of the ﬁrst layer mergers are of the
corresponding siblings (the only mismatch is of a sibling merging with a
neighboring full cell and then with the other sibling). Figure 3b shows the
very different cumulative probability distributions of pairwise distances
among the parent cells and that of the distances between siblings.

9

Figure 3: Every cell is different than the others. a: Clustering of cell responses
after randomly splitting every cell into 2 “siblings”. The nearest neighbor of each
of the new cells is his sibling and (except for one case) so is the ﬁrst merge. From
the second level upwards, the tree is identical to Fig. 2b (up to symmetry of tree
plotting). b: Cumulative distribution of pairwise distances between cells. The
distances between siblings are easily discriminated from the continuous distribu-
tion of values of all the (real) cells.

How signiﬁcant are the differences between the cells?

It might be that cells are distinguishable, but only after observing their re-
sponses for very long times. Since 1 bit is needed to reliably distinguish
between a pair of cells, Fig. 3b shows that more than 90% of the pairs are
reliably distinguishable within 2 seconds or less. This result is especially
striking given the low mean spike rate of these cells; clearly, at times where
none of the cells is spiking, it is impossible to distinguish between them.
To place the information about identity on an absolute scale, we compare
it to the entropy of the responses at each time, using 10 ms segments of the
responses at each time during the stimulus (Fig. 4a). Most of the points
lie close to the origin, but many of them reﬂect discrete times when the
responses of the neurons are very different and hence highly informative
about cell identity: under the conditions of our experiment, roughly 30%
of the response variability among cells is informative about their identity.4
On average observing a single neural response gives about 6 bits/s about

4Since the cells receive the same stimulus and often possess shared circuitry, an efﬁ-

ciency as high as 100% is very unlikely.

10

the identity of the cells within this population. We also compute the av-
erage number of spikes per cell which we need to observe to distinguish
reliably between cells i and j,

nd(i, j) =

1
2 ( ¯ri + ¯rj)
D(i, j)

.

(5)

where ¯ri is the average spike rate of cell i in the experiment. Figure 4b
shows the cumulative probability distribution of the values of nd. Evi-
dently, more than 80% of the pairs are reliably distinguishable after ob-
serving, on average, only 3 spikes from one of the neurons. Since ganglion
cells ﬁre in bursts, this suggest that most cells are reliably distinguishable
based on a single ﬁring ‘event’! We also show that for the 11 most similar
cells (those in the left subtree in Fig. 2b) only a few more spikes, or one
extra ﬁring event, are required to reliably distinguish them.

Figure 4: Diversity is high a: The average information that a response segment
conveys about the identity of the cell as a function of the entropy of the responses.
Every point stands for a time point along the stimulus. Results shown are for 2-
letter words of 5 ms bins; similar behavior is observed for different word sizes
and bins b: Cumulative distribution of the average number of spikes that are
needed to distinguish between pair of cells.

5 Discussion

We have identiﬁed a diversity of functional types of retinal ganglion cells
by clustering them to preserve information about their identity. Beyond

11

the easy classiﬁcation of the major types of salamander ganglion cells –
fast OFF, slow OFF, and ON – in agreement with traditional methods, we
have found clear structure within the fast OFF cells that suggests at least 5
more functional classes. Furthermore, we found evidence that each cell is
functionally unique. Even under this relatively simple stimulus, the anal-
ysis revealed that the cell responses convey ∼6 bits/s of information about
cell identity within this population of 21 cells. Ganglion cells in the sala-
mander interact with each other and collect information from a ∼250 µm
radius; given the density of ganglion cells, the observed rate implies that
a single ganglion cell can be discriminated from all the cells in this “ele-
mentary patch” within 1 s. This is a surprising degree of diversity, given
that 19 cells in our sample would be traditionally viewed as nominally the
same.

One might wonder if our choice of uniform ﬂicker limits the results of
our classiﬁcation. However, we found that this stimulus was rich enough
to distinguish every ganglion cell in our data set. It is likely that stim-
uli with spatial structure would reveal further differences. Using a larger
collection of cells will enable us to explore the possibility that there is a
continuum of unique functional units in the retina.

How might the brain make use of this diversity? Several alternatives
are conceivable. By comparing the spiking of closely related cells, it might
be possible to achieve much ﬁner discrimination among stimuli that tend
to activate both cells. Diversity also can improve the robustness of retinal
signalling: as the retina is constantly setting its adaptive state in response
to statistics of the environment that it cannot estimate without some noise,
maintaining functional diversity can guard against adaptation that over-
shoots its optimum. Finally, great functional diversity opens up additional
possibilities for learning strategies, in which downstream neurons select
the most useful of its inputs rather than merely summing over identi-
cal inputs to reduce their noise. The example of the invertebrate retina
demonstrates that nature can construct neural circuits with almost crys-
talline reproducibility from synapse to synapse. This suggests that the
extreme diversity found here in the vertebrate retina may not be the result
of some inevitable sloppiness of neural development but rather as evolu-
tionary selection of a different strategy for representing the visual world.

12

References

oine (1911).

Belknap Press (1987).

(2001).

[1] Cajal, S.R., Histologie du systeme nerveux de l’homme et des vertebres., Paris: Mal-

[2] Dowling, J., The Retina: An Approachable Part of the Brain. Cambridge, MA:

[3] Masland, R.H., The fundamental plan of the retina. Nat. Neurosci., 4: 877-886

[4] Meister, M., Pine, J. & Baylor, D.A., Multi-neuronal signals from the retina:

acquisition and analysis. J. Neurosci. Methods. 51: 95-106 (1994).

[5] Hartline, H.K., The response of single optic nerve ﬁbers of the vertebrate eye

to illumination of the retina. Am. J. Physiol., 121: 400-415 (1937).

[6] Hochstein, S. & Shapley, R.M., Linear and nonlinear spatial subunits in Y cat

retinal ganglion cells. J. Physiol., 262: 265-84 (1976).

[7] Grosser, O.-J. & Grosser-Cornehls, U., Neurophysiology of the Anuran Vi-
sual System, in Frog Neurobiology, ed: R. Llinas, Precht, W.: 297-385, Springer-
Verlag: New York (1976).

[8] Grosser-Cornehls, U. & Himstedt, W., Responses of retinal and tectal neurons
of the salamander (Salamandra salamandra) to moving visual stimuli. Brain Be-
hav. Evol. 7: 145-168 (1973).

[9] Lettvin, J.Y., Maturana, H.R., McCulloch, W.S. & Pitts, W.H., What the frog’s

eye tells the frog’s brain. Proc. I.R.E., 47: 1940-1951 (1959).

[10] Shannon, C. E. & Weaver W. Mathematical theory of communication Univ. of

Illinois (1949).

[11] Tishby, N., Pereira, F. & Bialek, W., The Information Bottleneck Method, in
Proceedings of The 37th Allerton conference on communication, control & comput-
ing, Univ. of Illinois (1999). see also arXiv: physics/0004057.

[12] Slonim, N. & Tishby, N., Agglomerative information bottleneck, NIPS 12,

[13] Lin, J., Divergence measures based on the Shannon entropy, IEEE IT, 37,

617–623 (2000).

145–151 (1991).

13

[14] Schneidman, E., Brenner, N., Tishby N., de Ruyter van Steveninck, R. &
Bialek, W. Universality and individuality in a neural code, NIPS 13: 159-165
(2001). see also arXiv: physics/0005043.

[15] Strong, S.P., Koberle, R., de Ruyter van Steveninck, R. & Bialek, W. Entropy
and information in neural spike trains, Phys. Rev. Lett. 80, 197–200 (1998). see
also arXiv: cond-mat/9603127.

[16] Keat, J., Reinagel, P., Reid, R.C. & Meister, M., Predicting Every Spike: A
Model for the Responses of Visual Neurons. Neuron 30, 803-817 (2001).

14

