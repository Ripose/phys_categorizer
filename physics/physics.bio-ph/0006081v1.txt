0
0
0
2

 

n
u
J
 

0
3

 
 
]
h
p
-
o
i
b

.
s
c
i
s
y
h
p
[
 
 

1
v
1
8
0
6
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Synchronisation, binding and the role of

correlated ﬁring in fast information transmission

Simon R. Schultz1, Huw D. R. Golledge2, and Stefano Panzeri2

1 Howard Hughes Medical Institute & Center for Neural Science, New York

University, New York, NY 10003, USA

2 Department of Psychology, Ridley Building,

University of Newcastle upon Tyne, Newcastle NE1 7RU, UK

stefano.panzeri@ncl.ac.uk

http://www.staff.ncl.ac.uk/stefano.panzeri/

Abstract. Does synchronization between action potentials from diﬀer-
ent neurons in the visual system play a substantial role in solving the
binding problem? The binding problem can be studied quantitatively in
the broader framework of the information contained in neural spike trains
about some external correlate, which in this case is object conﬁgurations
in the visual ﬁeld. We approach this problem by using a mathematical
formalism that quantiﬁes the impact of correlated ﬁring in short time
scales. Using a power series expansion, the mutual information an ensem-
ble of neurons conveys about external stimuli is broken down into ﬁring
rate and correlation components. This leads to a new quantiﬁcation pro-
cedure directly applicable to simultaneous multiple neuron recordings. It
theoretically constrains the neural code, showing that correlations con-
tribute less signiﬁcantly than ﬁring rates to rapid information processing.
By using this approach to study the limits upon the amount of informa-
tion that an ideal observer is able to extract from a synchrony code,
it may be possible to determine whether the available amount of infor-
mation is suﬃcient to support computational processes such as feature
binding.

1 Introduction

Does synchronization (or more generally temporal correlations) between action
potentials from diﬀerent cells in the central visual system play a substantial role
in solving crucial computational problems, such as binding of visual features
or ﬁgure/ground segmentation? One theory suggests that synchrony between
members of neuronal assemblies is the mechanism used by the cerebral cortex
for associating the features of a coherent single object [1].

Although several groups have reported compelling experimental evidence
from the visual system in support of this theory (for a review see [2]), the role
played by synchronous ﬁring in visual feature binding is still highly controversial
[3,4,5,6], and far from being understood. In our view, it is possible that one or
more methodological factors contribute to the continuing uncertainty about this

issue. In fact, almost all the reported neurophysiological evidence in favor or
against the temporal binding hypothesis relies upon the assessment of the sig-
niﬁcance of peaks in cross-correlograms (CCG, [7]) and of their modulation with
respect to stimulus conﬁguration. While investigating stimulus modulation of
peaks (or of other features) of CCGs can clearly bear some evidence on the role
of synchrony in binding, it does not address the crucial issue of how much syn-
chrony tells the brain about the conﬁguration of objects in the visual ﬁeld. This
question is particularly important as it is well known that ﬁring rates of individ-
ual cells are commonly related to features of the sensory world [8], and even to
perceptual judgements (see e.g. [9,10]). Firing rate modulations can potentially
contribute to association of features through the use of population codes, or also
in other ways[3]. Therefore the speciﬁc contribution of synchrony (or in general
of correlations between ﬁring of cells) as a coding mechanism for binding should
be assessed against the contribution of independent ﬁring rate modulation to
the encoding of object conﬁgurations in the visual ﬁeld.

To address these issues, a pure analysis of CCG characteristics is insuﬃcient.
In addition to CCG quantiﬁcation, information theory can be used to address
the speciﬁc contribution of synchronized or correlated ﬁring to visual feature
binding, and to compare the contribution of synchrony against that of ﬁring
rates. In fact, Information theory [11] allows one to take the point of view of an
ideal observer trying to reconstruct the stimulus conﬁguration just based on the
observation of the activity of neuronal population, and to determine how much
the presence of correlated ﬁring helps in identifying the stimulus.

In this paper we present and develop a rigorous information theoretic frame-
work to investigate the role of temporal correlations between spikes. We ﬁrst
discuss how information theory could overcome the limitations of the pure CCG
analysis. We then present a mathematical formalism that allows us to divide the
information into components which represent the information encoding mecha-
nisms used by neuronal populations – i.e. it determines how many bits of infor-
mation were present in the ﬁring rates, how many in coincident ﬁring by pairs
of neurons, etc., with all of these adding up to the overall available information.
The mathematical approach developed here is valid for timescales which are
shorter than or of the order of a typical interval between spike emissions, and it
makes use of a Taylor series approximation to the information, keeping terms up
to the second order in the time window length. This approximation is not merely
mathematically convenient; short timescales are likely to be of direct relevance to
information processing by the brain, as there is substantial evidence that much
sensory information is transmitted by neuronal activity in very short periods of
time [12,13,14]. Therefore the mathematical analysis is relevant to the study of
the computations underlying perceptual processes. In particular, it enables the
quantitative study of the rapidly appearing correlational assemblies that have
been suggested to underlie feature binding and ﬁgure/ground segmentation.

2 Problems with conventional Cross-Correlogram

analysis

The CCG represents a histogram of the probability of a spike from one neu-
ron at a given time relative to a reference spike of a second neuron [7]. Whilst
cross-correlation is capable of identifying synchrony between neurons, several
aspects of the analysis of CCGs present problems or are incomplete. First, CCG
analysis itself does not provide a criterion to choose which periods of a response
epoch should be analysed. Since, in many cases, moving stimuli are employed,
the response varies with time and it may be that correlations are present or are
stimulus modulated for only a short part of the response [15]. This short period
is not necessarily related simply to the response peak, although some studies
have analysed only the period in which the peak of the response is made to a
moving stimulus [16]. Second, the width of the time window over which corre-
lations should be assessed is arbitrary. CCG analysis does not entirely address
over which time scales correlations contribute most information about object
conﬁguration. Using long windows (e.g. much larger than the width of CCG
peaks) may “wash out” transient correlations. Narrow windows centered upon
the PSTH peak may ignore the part of the responses that contains most of
the information about the stimuli (e.g. in ﬁring rate modulations). Third, if
the window length used to assess correlations is varied between stimulus condi-
tions (e.g [16]) then an undesirable extra source of variation is introduced when
the stimulus conditions are compared. Information theory can mitigate some of
these problems by providing a criterion for the selection of time windows, by
identifying the windows in which most information is actually transmitted.

Many previous studies also diﬀer in the methods used to quantify the tempo-
ral structure in CCGs. Some studies rely on the ﬁtting of a damped sine wave to
the CCG (e.g. [5,17]). Other methods quantify solely the likelihood that the peak
in the CCG did not arise by chance [18]. Analysis of the signiﬁcance of a peak,
or of structure in the CCG must be made in relation to the ﬂanks of the CCG.
What length of ﬂank is chosen will aﬀect the signiﬁcance of peaks. However,
downstream neurons are unlikely to be able to compare the likelihoods of spikes
occurring at lags of tens of milliseconds against the likelihood of simultaneous
spikes.

The parameters of a CCG do not themselves quantify the informational con-
tribution of synchronous ﬁring. Conventional CCG analysis techniques attempt
to assess correlation in a manner independent of the ﬁring rate in order to dis-
ambiguate synchronous modulations from ﬁring rate variations. It is unlikely,
though, that any downstream detector of the synchronous discharge of neurons
would be capable of assessing the signiﬁcance of correlation independent of the
ﬁring rate. It is more likely that it would make use of the actual number of coinci-
dent spikes available in its integration time window. Therefore cross-correlation
peaks and ﬁring rate modulation are probably intrinsically linked in transmit-
ting information to downstream neurons, and an analysis of the functional role
of synchrony should be able to take this into account. Most studies that ap-
pear to show stimulus-dependent synchrony have employed relatively strongly

stimulated cells. An important prediction of the temporal correlation hypothesis
is that synchrony should encompass the responses of sub-optimally stimulated
neurons [19]. A thorough test of this hypothesis requires the study of cells that
ﬁre very few spikes. The number of spikes included in the calculation of a CCG
of course aﬀects the precision with which correlations can be detected [20]. Vari-
ations in the number of evoked spikes, rather than a true change in correlation
between the neurons, could thus aﬀect comparisons between optimal and sub-
optimal stimuli. While analysing cells ﬁring at low rates may be a challenge for
CCG analysis, it is tractable for analyses developed from information theory, as
we shall see in Section 4.

3 Information Theory and Neuronal Responses

We believe that the methodological ambiguities that attend studies purely based
on quantiﬁcation of spike train correlograms can be greatly reduced by employing
in addition methods based upon information theory [11], as we describe in this
Section.

Information theory [11] measures the statistical signiﬁcance of how neuronal
responses co-vary with the diﬀerent stimuli presented at the sensory periphery.
Therefore it determines how much information neuronal responses carry about
the particular set of stimuli presented during an experiment. Unlike other sim-
pler measures, like those of signal detection theory, which take into account only
the mean response and its standard deviation, information theory allows one to
consider the role of the entire probability distributions. A measure of information
thus requires sampling experimentally the probabilities P (r|s) of a neuronal pop-
ulation response r to all stimuli s in the set, as well as designing the experimental
frequencies of presentation P (s) of each stimulus. The information measure is
performed by computing the distance between the joint stimulus-response prob-
abilities P (r, s) = P (r|s)P (s) and the product of the two probabilities P (r)P (s),
(P (r) being the unconditional response probability) as follows:

I(S; R) = Xs Xr

P (s, r) log2

P (s, r)

P (s)P (r)

(1)

If there is a statistical relationship between stimuli and responses (i.e. if
P (r, s) is dissimilar from P (r)P (s)) , our knowledge about what stimulus was
presented increases after the observation of one neuronal spike train. Eq. (1)
quantiﬁes this fact. The stronger the statistical relationship between stimuli and
responses, the higher is the information value. Eq. (1) thus quantiﬁes how well an
ideal observer could discriminate between diﬀerent stimulus conditions, based on
a single response trial. There are several advantages in using information theory
to quantify how reliably the activity of a set of neurons encodes the events in
the sensory periphery [21,22]. First, information theory puts the performance
of neuronal responses on a scale deﬁned at the ratio level of measurement. For
example, an increase of 30% of on the peak height of a cross-correlogram does not
tell us how this relates to synchrony-based stimulus discrimination, but values of

information carried by synchronous ﬁring have a precise meaning. Information
theory measures the reduction of uncertainty about the stimulus following the
observation of a neuronal response on a logarithmic scale. One bit of information
corresponds to a reduction by a factor of two in the stimulus uncertainty. A
second advantage of information theory in this context is that it does not require
any speciﬁc assumption about the distance between responses or the stationarity
of the processes, and it can therefore lead to objective assessments of some of
the hypotheses.

In the above discussion we have mentioned that we are calculating informa-
tion ‘about a stimulus’. In fact, more generally it can be information ‘about’ any
quantiﬁable external correlate, but we shall continue to use the word stimulus
in an extended sense. If we were studying information about the orientation of
a grating, we would deﬁne our stimulus to be which of a number of diﬀerent ori-
entations the grating appeared at on any given experimental trial. If we wish to
study problems such as binding or ﬁgure-ground segregation within this frame-
work, we have to specify our stimulus description accordingly. An illustration of
this is shown in the scene of Fig. 1, which contains two objects in front of a back-
ground. Also shown are a number of receptive ﬁelds, which are taken to be those
of cells from which we are simultaneously recording the activity (‘spike trains’).
We can deﬁne our stimulus, or external correlate, as a multidimensional variable
representing the object to which each receptive ﬁeld is associated. The dimen-
sionality of our stimulus is in this case the number of cells from which we are
recording at once. By quantifying the information contained in the spike trains
about this variable, and breaking it down into individual components reﬂecting
ﬁring rates and correlations (or synchronisation), we can determine the aspects
of the spike train which best encode the ﬁgure-ground (or object-object-ground)
segregation. Furthermore, by examining how this relationship scales with the
stimulus dimensionality (number of receptive ﬁelds recorded from), it may be
possible to determine whether enough information is present in correlations to
support binding in perceptually realistic environments.

It is worth noticing that information values are always relative to the stimu-
lus set used, and that testing a neuron with diﬀerent stimuli may lead to rather
diﬀerent information values. This has some interesting implications. On the one
hand, it allows us to characterise neuronal selectivity by searching for a stimulus
set that maximises the neuronal information transfer, a more rational charac-
terisation strategy than searching for stimuli eliciting sustained responses. On
the other hand, the intrinsic dependency of mutual information values on the
nature of stimulus set allows us to test whether diﬀerent encoding strategies are
used by visual cortical neurons when dealing with external correlates of a dif-
ferent nature. The last property is of interest because one of the predictions of
the binding-by-synchrony hypothesis is that synchrony is particularly important
when stimulus conﬁgurations requiring some kind of associations are included,
and less important in other situations. Information theory thus provides a nat-
ural framework to test this theory.

s0

s1

s2

Fig. 1. An illustrative segregation problem in which there are two objects in
front of a background. The background is labeled by s0, and the objects by s1
and s2 respectively. The dashed ellipses represent the receptive ﬁelds of visual
cortical cells which we are recording the responses of simultaneously. This situa-
tion can be examined in the framework of information theory by considering the
‘stimulus’ to be a multidimensional variable indicating which object (s0, s1 or s2)
is associated with each receptive ﬁeld. The problem is thus to determine which
response characteristics are most informative about the visual conﬁguration.

4 Series expansion of the mutual information

Although information theory is, as explained, a natural framework to address the
role of correlated ﬁring on e.g. binding of visual features, some work is needed to
separate out of the total information contained in a population response r into
components, each reﬂecting the speciﬁc contribution of an encoding mechanism.
We perform this separation in the limit in which the relevant window for infor-
mation encoding is short enough that the population typically emits few action
potentials in response to a stimulus. As discussed in the introduction and in
[23], there is evidence that this is a relevant limit for studying the computations
underlying perception, as cortical areas in several cases perform their computa-
tions within a time frame which is shorter than one typical interspike interval
[13,14].

We examine a period of time of duration t, in which a stimulus s is present.
The neuronal population response r during this time is taken to be described by
the number of spikes ﬁred by each cell1 in the window t. We study the informa-
tion carried by the responses of a neuronal population about which stimulus is
presented. It can be approximated by a power series

I(t) = t It +

1
2

t2 Itt + O(t3).

(2)

The problem is thus to compute the ﬁrst two time derivatives of the information,
It and Itt, which are all that survive at short timescales.

Two kinds of correlations inﬂuence the information. These are the “signal”
(mean response to each stimulus) correlation and the “noise” (variability from
the mean across diﬀerent trials with the same stimulus) correlation between cells.
In the short timescale limit the noise correlation can be quantiﬁed as

γij (s) =

ni(s)nj(s)
(ni(s)nj(s))

− 1, (i 6= j)

γii(s) =

(ni(s)2 − ni(s))

2

ni(s)

− 1,

(3)

where ni(s) is the number of spikes emitted by cell i in a given trial in response
to stimulus s, and the bar denotes an average across experimental trials to the
same stimulus. The signal correlation can be measured as

νij =

< ri(s)rj(s) >s

< ri(s) >s< rj(s) >s

− 1,

(4)

where ri(s) is the mean ﬁring rate of cell i to stimulus s, and < · · · >s denotes
an average across stimuli. These are scaled correlation densities ranging from -1
to inﬁnity, which remain ﬁnite as t → 0. Positive values of the correlation coeﬃ-
cients indicate positive correlation, and negative values indicate anti-correlation.
Under the assumption that the probabilities of neuronal ﬁring conditional
upon the ﬁring of other neurons are non-divergent, the t expansion of response

1 The additional temporal information contained in the spike times is studied in [24]

probabilities becomes an expansion in the total number of spikes emitted by the
population in response to a stimulus. The probabilities of up to two spikes being
emitted are calculated and inserted into the expression for information. This
yields for the information derivatives

It =

C

Xi=1

(cid:28)ri(s) log2

ri(s)

hri(s′)is′ (cid:29)s

C

C

Itt =

1
ln 2

+

+

C

Xi=1

C

Xi=1

C

Xj=1

C

Xj=1

1

)(cid:21)

1 + νij

hri(s)is hrj(s)is(cid:20)νij + (1 + νij) ln(

Xj=1
Xi=1
(cid:20)hri(s)rj(s)γij (s)is(cid:21) log2(
(cid:28)ri(s)rj(s)(1 + γij (s)) log2(cid:20) (1 + γij (s)) hri(s′)rj(s′)is′

hri(s′)rj(s′)(1 + γij(s′))is′(cid:21)(cid:29)s

1 + νij

1

)

(5)

. (6)

The ﬁrst of these terms is all that survives if there is no noise correlation at all.
Thus the rate component of the information is given by the sum of It (which
is always greater than or equal to zero) and of the ﬁrst term of Itt (which is
instead always less than or equal to zero). The second term is non-zero if there
is some correlation in the variance to a given stimulus, even if it is independent of
which stimulus is present; this term thus represents the contribution of stimulus-
independent noise correlation to the information. The third component of Itt
is non-negative, and it represents the contribution of stimulus-modulated noise
correlation, as it becomes non-zero only for stimulus-dependent correlations. We
refer to these last two terms of Itt together as the correlational components of
the information.

In any practical measurement of these formulae, estimates of ﬁnite sampling
bias must be subtracted from the individual components. Analytical expressions
for the bias of each component are derived in the online appendix of [23].

5 Correlations and fast information processing

The results reported above for the information derivatives show that the in-
stantaneous rate of information transmission (related to the leading order con-
tribution to the information) depends only upon the ﬁring rates. Correlations
contribute to information transmission, but they play only a second order role.
This has interesting implications for the neural code, that we develop further
here.

It was argued [25] that, since the response of cortical neurons is so variable,
rapid information transmission must imply redundancy (i.e. transmitting several
copies of the same message). In other words, it should necessary to average away
the large observed variability of individual interspike intervals s by replicating
the signal through many similar neurons in order to ensure reliability in short

times. Our result, eq. (6), shows that to have a high information rate, it is
enough that each cell conveys some information about the stimuli (because the
rate of the information transmitted by the population is the sum of all single cell
contributions); therefore we conclude that it is not necessary to transmit many
copies of the same signal to ensure rapidity.

Also, since ﬁring rates convey the main component of information, corre-
lations are likely to play a minor role in timescales of the order of 20-50 ms,
in which much information is transmitted in the cortex. As an example, Fig.
2 shows the information conveyed by a population of simulated Integrate and
Fire neurons, which share a large proportion (30%) of their aﬀerents (see [23]
for details of the neuronal model used). It can be seen that, despite the strong
correlations between the cells in the ensemble correlations play only a minor role
with respect to ﬁring rates.

To model a situation where stimulus dependent correlations conveyed in-
formation, we generated simulated data using the Integrate-and-Fire model for
another quintuplet of cells which had a stimulus dependent fraction of common
input. This might correspond to a situation where transiently participate in dif-
ferent neuronal assemblies, depending on stimulus condition. This is therefore a
case that might be found if the binding-by-synchrony theory is correct. There
were ten stimuli in the sample. The spike emission rate was constant (20 Hz)
across stimuli. One of the stimuli resulted in independent input to each of the
model cell, whereas each of the other nine stimuli resulted in an increase (to
90%) in the amount of shared input between one pair of cells. The pair was
chosen at random from the ensemble such that each stimulus resulted in a dif-
ferent pair being correlated The change in responses of one such pair of cells to
changes in the amount of common input is shown in Fig. 3a. The upper panel
of Fig. 3a shows the fraction of shared connections as a function of time; the
central and lower panel of Fig. 3a show the resulting membrane potentials and
spike trains from the pair of neurons. This cross-correlation is also evident in the
cross-correlograms shown in Fig. 3b. The results for the information are given
in Fig. 3c: all terms but the third of Itt are essentially zero, and information
transmission is in this case almost entirely due to stimulus-dependent correla-
tions. This shows that the short time window series expansion pursued here is
able to pick up the right encoding mechanisms used by the set of cells. Therefore
it is a reliable method for quantifying the information carried by the correlation
of ﬁring of small populations of cells recorded from the central nervous system
in vivo. Another point that is worth observing is that Fig. 3c also shows that
the total amount of information that could be conveyed, even with this much
shared input, was modest in comparison to that conveyed by rates dependent on
the stimuli, at the same mean ﬁring rate. This again illustrates that correlations
typically convey less information than what can be normally achieved by rate
modulations only. Therefore they are likely to be a secondary coding mecha-
nism when information is processed in time scales of the order of one interspike
interval.

Total information         
Rate only                 
Correlation (stim. indep.)
Correlation (stim. dep.)  

1.5

1

0.5

)
s
t
i
b
(
 
n
o
i
t
a
m
r
o

f

n

I

40

60

Time window (ms)

80

100

a

0
0

580

20

s
t

n
e
v
e

 
.

o
N

0
−50

b

0

Lag (ms)

50

(a) The short-timescale information components for a set of 5 simu-
Fig. 2.
lated neurons sharing 30% of their inputs. (b) A typical example of the cross-
correlogram between two of the simulated neurons. Despite of the strong cor-
relation between neurons, the impact of the cross correlations on information
transmission is minimal.

1

0

V
m
 
0
2

V
m
 
0
2

200

0

640

s
t
n
e
v
e

 
.

o
N

s
t

n
e
v
e

 
.

o
N

0

200

400
600
Time (ms)

800

1000

a

0
−50

b

0

Lag (ms)

50

0.1

)
s
t
i

b
(
 
n
o

0.05

i
t

a
m
r
o
n

f

I

c

0

0

20

40

Time window (ms)

60

80

100

Fig. 3. A situation in which the stimulus dependent correlational component
dominates: with a ﬁxed mean ﬁring rate, two of the ﬁve simulated cells (chosen
randomly for that stimulus) increase their correlation by increasing the number
of shared connections while the other two remained randomly correlated. The
eﬀect of this on cell spiking activity is shown in (a): upper panel shows the
fraction of shared connections, while central and lower panels of (a) show the
membrane potential and spike emission of the simulated cells. (b) shows the
cross-correlograms corresponding to the low and high correlation states. The
result of this is seen in (c): information due to correlations, although modest in
magnitude, in this demonstration dominates the total information.

6 Optimality of correlational encoding

In the preceding sections we have shown that the correlational component is
only second order in the short time limit, essentially because the probability of
emission of pairs of spikes, and the reliability of this process, are much smaller
than the corresponding quantities for single spikes. For this reason, one can
expect a correlational code to carry appreciable information only when it is
eﬃcient, i.e. when each correlated spike pair carries as much information as
possible.

In this section we investigate the statistical conditions that have to be satis-
ﬁed by a correlational code in order to be eﬃcient in the short time limit. If the
population code is purely correlational (i.e. the ﬁring rates are not modulated
at all by the stimuli), then it is possible to show that the mean information per
coincidence Ψ carried by a pair of cells (obtained dividing the total information
by the mean number of observed coincidences) is bounded only by the sparseness
of the distribution of coincident ﬁring across stimuli α:

0 ≤ Ψ ≤ log2(1/α)

(7)

The maximal (most eﬃcient) value of information per coincidence Ψmax =
log2(1/α) is reached by a binary distribution of correlations across stimuli, with
a fraction of stimuli α eliciting positively correlated ﬁring, and the other 1 − α
stimuli eliciting fully anti-correlated ﬁring (i.e. coincident ﬁring is never observed
when presenting one of the latter stimuli). Nearly uniform, or strongly unimodal
distributions of correlations across stimuli would give poor information, Ψ ∼ 0.
By analyzing Eq. (7), it is easy to realize that there are two statistical require-
ments that are necessary to achieve high values of information per coincidence.
The ﬁrst one is that the correlational code should be em sparse (i.e. the frac-
tion of stimuli leading to a “high correlation state” should be low). The sparser
the code, the more information per coincidence can be transmitted. The second
important factor for fast and eﬃcient transmission of correlational information,
is that the low correlational state must be strongly anti-correlated in order to
achieve an information per coincidence close to its maximum log2(1/α). In fact
correlations in short times have ﬂuctuations that may be big compared with their
mean value, and therefore for any observer it is diﬃcult to understand in less
than one ISI if an observed coincidence is due to chance or neuronal interaction.
This is why low correlational states with no coincidences are so helpful in trans-
mitting information. We note here that states of nearly complete anticorrelation
have never been observed in the brain. Therefore the “low state correlational
state” of a realistic correlational assembly should be the “random correlation
state” (i.e. the state in which the number of coincident spikes is on average that
expected by chance).

We have quantiﬁed the reduction in the information per coincidence, com-
pared to its maximum Ψmax, that arises as a consequence of the presence of
the random correlation state. Fig. 4 plots the ratio between the information per
coincidence carried when the “low correlation state” is random and the optimal

amount of information per coincidence log2(1/α) obtained when the low correla-
tion state is totally anticorrelated. The plot is shown as a function of the fraction
α of stimuli eliciting a “highly correlated state”. Fig. 4 shows clearly that, if the
“low correlation state” of the assembly elicits uncorrelated ﬁring, then the in-
formation per coincidence is far from its maximum, unless the correlation in the
“high state” is extremely high and the correlational code is not sparse at all.
However, in which case the information per coincidence is very low anyway (see
eq. (7)).

Therefore correlational assemblies in the brain, if any, are likely to be ineﬃ-
cient in the short time limit. This consideration further limits the possible role
played by correlations in fast information encoding.

correlational assembly

γ = 0.5
γ = 1
γ = 3
γ = 10

1

0.8

0.6

0.4

i

g
n
d
o
c
n
e

 
f

o

 
y
c
n
e
c
i
f
f

i

0.2

e

0
0

0.2

0.4

0.6

0.8

fraction of positively corr. stimuli

1

Fig. 4. The ratio between the information per coincidence carried by a binary
correlational encoder with a fraction of stimuli eliciting positive correlation γ
and the other stimuli eliciting no correlation, and the optimal information per
coincidence carried in the same situation, but with full anticorrelation in the
“low correlation state”. This ratio is plotted, for diﬀerent values of the strength
γ of the “high correlation state”, as a function of the fraction of stimuli eliciting
positive correlation.

7 Discussion

If cells participate in context-dependent correlational assemblies [2], then a signif-
icant amount of information should be found in the third component of Itt when
analysing data obtained from the appropriate experiments. The series expansion
approach thus enables the testing of hypotheses about the role of correlations in
solving the binding problem, as opposed to other solutions, and about informa-
tion coding in general. Data analyses based on the time-expansion approach have

the potential to elucidate the role of correlations in the encoding of information
by cortical neurons.

It is worth noticing that the formalism presented here evaluates the the in-
formation contained in the neuronal responses themselves, it does not make
assumptions about the system that is going to read the code. For this reason,
the information computed “directly” from neuronal responses is an upper bound
to what any type of decoder can extract from the responses themselves. There-
fore it is termed the information that an “ideal observer” can extract [22]. Of
course, the relative contribution of rate and synchrony modulations to infor-
mation transmission will depend on the speciﬁc read-out mechanism used by
a downstream neural system that listens to the neuronal code. However, if the
information that an ideal observer is able to extract from the synchrony code is
small, as the mathematical analysis indicates for the fast information processing
limit, one can be sure that any decoding device cannot extract more information
in the synchrony than that small amount evaluated from the responses.

Whether this small amount is suﬃcient to support computational processes
such as ﬁgure-ground segregation remains to be seen, and depends upon how
it scales empirically with the number of receptive ﬁelds examined. Ultimately,
as suggested by [3], the only way we will achieve any degree of conﬁdence in
a proposed solution to the binding problem will be to study recordings made
from a monkey trained to make behavioural responses according to whether
individual features are bound to particular objects. The information theoretic
approach described here would be a natural way to analyse such data.

In conclusion, the methodology presented here can provide interesting and
reliable bounds on the role of synchrony on cortical information encoding, and
we believe that its application to neurophysiological experiments will advance
our understanding of the functional interpretation of synchronous activity in the
cerebral cortex.

8 Acknowledgements

We would particularly like to thank Alessandro Treves and Malcolm Young for
useful discussions relating to this work.

References

1. C. von der Malsburg. Binding in models of perception and brain function. Current

Opinion in Neurobiology, 5:520–526, 1995.

2. W. Singer, A. K. Engel, A. K. Kreiter, M. H. J. Munk, S. Neuenschwander, and
P. Roelfsema. Neuronal assemblies: necessity, signature and detectability. Trends
in Cognitive Sciences, 1:252–261, 1997.

3. M. N. Shadlen and J. A. Movshon. Synchrony unbound: a critical evaluation of

the temporal binding hypothesis. Neuron, 24(1):67–77, 111–25, September 1999.

4. G. M. Ghose and J. Maunsell. Specialized representations in visual cortex: a role

for binding? Neuron, 24(1):79–85, 111–25, September 1999.

5. M. P. Young and S. Yamane. Sparse population coding of faces in the inferotem-

poral cortex. Science, 256:1327–1331, 1992.

6. H. D. R. Golledge, C. C. Hilgetag, and M. J. Tovee. A solution to the binding

problem? information processing. Curr Biol, 6(9):1092–5, Sep 1 1996.

7. A. M. H. J. Aertsen, G. L. Gerstein, M. K. Habib, and G. Palm. Dynamics
of neuronal ﬁring correlation: modulation of “eﬀective connectivity”. Journal of
Neurophysiology, 61:900–917, 1989.

8. E. D. Adrian. The impulses produced by sensory nerve endings: Part I. J. Physiol.

(Lond.), 61:49–72, 1926.

9. K.H. Britten, M. N. Shadlen, W. T. Newsome, and J. A. Movshon. The analysis
of visual-motion - a comparison of neuronal and psychophysical performance. J.
Neurosci., 12:4745–4765, 1988.

10. M. N. Shadlen and W. T. Newsome. Motion perception: seeing and deciding. Proc

Natl Acad Sci U S A, 93(2):628–33, Jan 23 1996.

11. C. E. Shannon. A mathematical theory of communication. AT&T Bell Labs. Tech.

J., 27:379–423, 1948.

12. M. J. Tov´ee, E. T. Rolls, A. Treves, and R. P. Bellis. Information encoding and the
response of single neurons in the primate temporal visual cortex. J. Neurophysiol.,
70:640–654, 1993.

13. S. Thorpe, D. Fize, and C. Marlot. Speed of processing in the human visual system.

Nature, 381:520–522, 1996.

14. E. T. Rolls, M.J. Tovee, and S. Panzeri. The neurophysiology of backward visual

masking: Information analysis. J. Cognitive Neurosci., 11:335–346, 1999.

15. C. M. Gray, A. K. Engel, P. K¨onig, and W. Singer. Synchronization of oscillatory
neuronal responses in cat striate cortex: Temporal properties. Visual Neuroscience,
8:337–347, 1992.

16. A. K. Kreiter and W. Singer. Stimulus-dependent synchronization of neuronal re-
sponses in the visual cortex of the awake macaque monkey. J Neurosci, 16(7):2381–
96, Apr 1 1996.

17. P. K¨onig, A. K. Engel, and W. Singer. Relation between oscillatory activity
and long-range synchronization in cat visual cortex. Proc. Natl. Acad. Sci. USA,
92:290–294, 1995.

18. S. C. de Oliveira, A. Thiele, and K. P. Hoﬀmann. Synchronization of neuronal
activity during stimulus expectation in a direction discrimination task. J Neurosci,
17(23):9248–60, Dec 1 1997.

19. P. Konig, A. K. Engel, and W. Singer. Relation between oscillatory activity
and long-range synchronization in cat visual cortex. Proc Natl Acad Sci U S A,
92(1):290–4, Jan 3 1995.

20. Y. Hata, T. Tsumoto, H. Sato, and H. Tamura. Horizontal interactions between
visual cortical neurones studied by cross-correlation analysis in the cat. J Physiol
(Lond), 441:593–614, September 1991.

21. F. Rieke, D. Warland, R. R. de Ruyter van Steveninck, and W. Bialek. Spikes:

exploring the neural code. MIT Press, Cambridge, MA, 1996.

22. A. Borst and F. E. Theunissen. Information theory and neural coding. Nat Neu-

rosci, 2(11):947–57, November 1999.

23. S. Panzeri, S. R. Schultz, A. Treves, and E. T. Rolls. Correlations and the encoding
of information in the nervous system. Proc. R. Soc. Lond. B, 266:1001–1012, 1999.
24. S. Panzeri and S. R. Schultz. A uniﬁed approach to the study of temporal, corre-

lational and rate coding. Neural Computation, in press, 2000.

25. M. N. Shadlen and W. T. Newsome. The variable discharge of cortical neurons:
implications for connectivity, computation and coding. J. Neurosci., 18(10):3870–
3896, 1998.

