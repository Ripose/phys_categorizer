8
9
9
1
 
l
u
J
 
1
3
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
9
5
0
7
0
8
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Oligopeptides’ frequencies in the classiﬁcation of
proteins’ primary structures.

Paolo Sirabella †‡, Alessandro Giuliani § , Alfredo Colosimo †
† University of Rome ”La Sapienza” - Dept. of Biochemical Sciences
P.le A. Moro, 5 - 00185 Roma - Italy

§ Istituto Superiore di Sanit´a - TCE Lab.
V.le Regina Elena,199 - 00161 Roma -Italy

‡ To whom correspondence should be addressed.

Email: p.sirabella@caspur.it - Fax: ++39 06 49910957

Running title: Oligopeptides in the classiﬁcation of proteins.

Keywords: Proteins’ classiﬁcation, SOM algorithm, Aminoacids’ coding

Abbreviations used in the text:
AAs: aminoacids; PCA: Principal Component Analysis;
SOM: Self Organizing Maps; SMH: Set Mean Homology; MMH: Map Mean Homology.

June 21, 2011

Abstract

This paper reports about an approach to the classiﬁcation of proteins’
primary structures taking advantage of the Self Organizing Maps algorithm
and of a numerical coding of the aminoacids based upon their physico-
chemical properties.

Hydrophobicity, volume, surface area, hydrophilicity, bulkiness, refrac-
tivity and polarity were subjected to a Principal Component Analysis and
the ﬁrst two principal components, explaining 84.8 % of the total observed
variability, were used to cluster the aminoacids into 4 or 5 classes through
a k-means algorithm. This leads to an economical representation of the
primary structures which, in the construction of the input vectors for the
Self Organizing Maps algorithm, allows the consideration of up to tri- and
tetrapeptides’ frequency matrices with minimal computational overload.

In comparison with previously explored conditions, namely symbolic cod-
ing of aminoacids and dipeptides frequencies, no signiﬁcant improvement
was observed in the classiﬁcation of 69 cytochromes of the c type, char-
acterized by a high degree of structural and functional similarity, while a
substantial improvement occurred in the case of a data set including quite
heterogeneous primary structures.

1

Introduction

Coding the primary structure of proteins by lists of numbers related to
the physico-chemical properties of the aminoacids (AAs) in the polypeptide
chains should provide substantial help in the study of the correlations be-
tween primary and tridimensional structures (Eisenhaber et al. 1995; Rost
and Sander 1993; Reyes et al. 1994), and hopefully shade some light on
the intricacies of the rules governing proteins’ folding (Fedorov and Baldwin
1997).

Although the issue is in the literature since a long time (Argos 1987;
Schneider and Wrede 1993), the vast majority of the software tools devoted
to the analysis of the primary structure (Thompson et al. 1994; Wishart
et al. 1994) utilize the symbolic coding of AAs, the main reason being the
successful drawing of phylogenetic trees on the basis of homologous proteins
of diﬀerent species after proper alignment (Page 1996).

Numerical coding of aminoacidic residues on solid physico-chemical and
statistical grounds, however, allows to take advantage of a manifold of nu-
merical multivariate data-analysis techniques and, in particular, to fully
exploit the euristic power of automatic classiﬁcation based upon Self Orga-
nizing Maps (SOMs), introduced by Kohonen several years ago (Kohonen
1984) as a general purpose tool for classifying the elements of a multivariate
set. The only strict requirement of their unsupervised learning mechanism,
i.e. the same number of variables for each element of the set, can be easily
met even if the primary structures to be classiﬁed are of diﬀerent length. To
any protein, in fact, can be associated a frequency matrix of nd elements,
where each element is the number of occurrences of each of the possible
oligopeptides of length d within the primary structure (n = 20 in the case
of the natural AAs). On the basis of this approach, assuming a diﬀerent
symbol for each of the 20 natural aminoacids and d = 2, i.e. generating
frequency matrices of 202 elements, it was possible to carry out both ﬁne
classiﬁcations within sets of structurally similar proteins (Ferr´an and Fer-
rara 1991,1992), and coarser classiﬁcations over much larger sets (Ferr´an et
al. 1992).

If, on one hand, increasing the length d of the oligopeptide accounts with
higher and higher precision for the ﬁne details of each individual primary
structure, the exponential increase in the number of the possible d-plets in
the nd matrix poses some practical and theoretical limitations. The former
ones obviously refer to the computational load, while the latter are related
to the linearly decreasing number of oligopeptides (N − d + 1) with wich
a sequence of length N may contribute to the non-zero, i.e.
signiﬁcant,
elements of the frequency matrix.

In this paper two exemplary cases of proteins’ primary structure clas-
siﬁcation will be described in which an appropriate balance between the n
and d values in the frequency matrices feeding the SOM algorithm allows

1

to: i) use oligopeptides longer than dipeptides as descriptors of the primary
structures, and ii) minimize the ensuing computational load by lowering the
size of n with no (or minimal) loss of the statistically signiﬁcant informa-
tion, through the combined use of principal component and cluster analysis
techniques.

2 Methods

2.1 Self Organizing Maps (SOM)

The SOM algorithm, proposed by Teuvo Kohonen in the ﬁrst 80s (Kohonen
1984), is a fully automatic algorithm that drastically reduces the dimension-
ality of a highly multivariate data set still preserving the mutual correlations
between its elements. The most recent implementation of such algorithm
(SOMPAK 3.1, free software available, together with a rich bibliography,
at the Web site http://www.cis.hut.fi/nnrc/) has been used throughout
the present paper.

In our case the input of the algorithm is a set of numerical vectors ob-
tained by an appropriate recoding of the primary structures of proteins, and
the output is a bidimensional map where the mutual locations of the pri-
mary structures reﬂect their intrinsic similarities. An extensive and clear
description of the algorithm’s working machinery is available in the litera-
ture (Kohonen 1995), where an estimate of the distorsion introduced in the
original structure of the data set by reducing their dimensionality is given
in the form of a stress factor. As a more speciﬁc index of the goodness of
the classiﬁcation obtained in the case of proteins, the Map Mean Homology
(M M H) index (see below) has been used throughout this paper.

2.2 Calculation of the MMH (Map Mean Homology) index

To evaluate the goodness of the clustering provided by the SOM algorithm,
the Map Mean Homology (M M H) index has been used, along the same line
followed by Ferr´an and Ferrara (1991). Such index can be deﬁned as

n

X
i=1

Clusters

QRi

M M H =

n

(1)

Clusters values) associated
i.e. the average of the Quality Ratio values (QRi
to the n clusters present on the map. A cluster is deﬁned by the presence
in a cell of at least two elements, and is extended to its ﬁrst neighbours,
counted only once. Thus, the QRi

Clusters for the ith cluster is deﬁned as

2

QRi

Clusters =

(2)

m

X
j=1

WjQRi,j

Couples

m

X
j=1

Wj

where j runs over the m couples associated to the ith cluster and to its ﬁrst
neighbours, weighted by Wj values of 1 and 0.5 in the former and latter
case, respectively.

2.3 Principal Component Analysis of AAs’ physico-chemical

properties.

The Principal Component Analysis (PCA), introduced by Pearson in 1901,
is a method of decomposing a correlation or covariance matrix in order to
ﬁnd the best association of points in space (Jolliﬀe 1986).

The ﬁrst goal of the principal components is to summarize a multivariate
data set as accurately as possible using fewer uncorrelated variables. This
can be achieved since the principal components are orthogonal to each other,
thus removing any redundancy in the available information. The relation
between the original variables and the principal components is expressed in
terms of component loadings, i.e. the correlation coeﬃcients of the original
variables with the new ones (principal components).

In this paper PCA has been carried out over seven physico-chemical
properties of the 20 natural AAs, namely hydrophobicity, volume, surface
area, hydrophilicity, bulkiness, refractivity index and polarity which, ac-
cording to Schneider and Wrede (1993), are relevant in the identiﬁcation
of speciﬁc patterns along proteins’ sequences. Among these properties, hy-
drophobicity has been recently conﬁrmed as by far the most important one
in protein folding (Weiss and Herzel 1998). In Table 1 our PCA results are
reported in terms of the components’ loadings and of the percent variabil-
ity explained by each component. The ﬁrst and second components (PC1,
PC2) explain 84.8% of the total variability and hence have been considered
as reliable and non redundant representatives of the whole set of properties.

2.4 k-means clusterization of AAs.

The k-means algorithm is a semi-automatic procedure to identify classes
within a given set of elements described by one or many variables (Everitt
1980). Clusters emerge here from the structural characteristics of the data
set, by maximizing the interclass variance and minimizing the intraclass vari-
ance. For n units described by m variables, the procedure can be schema-
tized as follows:

1. a non-trivial number of classes, k, is deﬁned, being 1 < k < n;

3

2. k aggregation points in an m-dimensional space are arbitrarily chosen;

3. each of the n units is assigned to the nearest aggregation point;

4. a new set of aggregation points are reckoned as barycentres of the

classes deﬁned in the previous step;

5. go back to the 3rd step until no further change occurs in the classes’

composition.

The external factor which makes the procedure non fully automatic, is

the a priori deﬁnition of k.

In the present case, the algorithm has been used to group into k classes
the 20 AAs on the basis of their hydrophobicity (m = 1), as well as the
values of the ﬁrst and second principal components (m = 2) extracted from
their main physico-chemical properties.

The relative optimality of the k value can be chosen by means of the
relation between the fraction of explained variability (EV ) relative to the
classiﬁcation, and the value of k: reaching a plateau of k can be considered
the result of a structurally optimal classiﬁcation (see also the legend to Table
4).

3 Results

3.1 Data sets used in this paper

The leading criterium in the choice of the two data sets used in this work
reﬂects the aim to test the performance of a numerical coding of the AA and
of a variable length of the oligopeptides’ describing the primary structures
under two diﬀerent conditions, namely a high and a low value of a global
similarity index (see below).

For Data Set I, shown in Table 2, were chosen 69 cytochromes of the c
type, which are known to share a high level of both structural and functional
similarity. To impose some rational constraint in the choice of Data Set II,
where a high similarity in the primary structures was not a prerequisite, our
attention focussed over a group of proteins in which, as shown by Alexandrov
and Fisher (1996), a signiﬁcant similarity in the tridimensional arrangements
was unparalleled by any homology in the primary structures. The elements
of Data Set II are listed in Table 3.

It is worth stressing that the two data sets should be considered from

two complementary viewpoints:

i) since the diﬀerences between the elements in Data Set I consist in
a number of gaps/point-mutations over essentially the same basic primary
structure, any source of variability (information) related to structural and/or
functional features, is expected to be minimal. Under these conditions even

4

the simplest symbolic coding blind to physico-chemical features can be ap-
propriate;

ii) the high heterogeneity within the elements of Data Set II, related to
their quite diﬀerent length, composition, function and primary structure,
should be in favour of any classiﬁcation task based on a numerical coding
of the sequences. This introduces, however, new problems about choosing
the optimal physico-chemical descriptors of the AAs, or about how to group
them into clusters, on which heavily depends the classiﬁcation’s goodness.
A quantitative estimate of the Set Mean Homology (SM H) among the

n elements (in couples) within a set is given by

n−1

n

QRij

X
i=1

X
j=i+1
n(n − 1)/2

SM H =

(3)

where the QRij are the QualityRatio values, i.e. correspond to the ele-
ments of a triangular matrix generated as an intermediate result by the
PILEUP program in the GCG suite of programs for the analysis of biose-
quences (Doelz 1994). More precisely, each QRij is given by an estimate of
the goodness of the alignment between the i, j elements in the data set as
provided by : i) the Needleman-Wunsch algorithm (1969), and ii) a substitu-
tion matrix of the BLOSUM type (Henikoﬀ and Henikoﬀ 1992), normalized
by the number of residues of the shortest sequence between i and j. Notice
that the procedure used in reckoning QRij refers to a symbolic coding of the
natural AAs, i. e. matches the condition used as a reference (black bars) in
Figure 2. However, high-quality classiﬁcations of primary structures can also
be obtained upon clustering the AAs into 4 or 5 groups through a k-means
algorithm, after an appropriate numerical coding provided by PCA.

3.2 Classiﬁcation of the data sets‘ elements.

Figure 1 shows the map generated by the SOM algorithm in the case of Data
Set I. This data set, due to the high level of similarity between the primary
structures, constitutes a signiﬁcant benchmark to test the ﬁne discrimina-
tion power of the algorithm. A very similar data set has been successfully
analyzed by Ferr´an and Ferrara (1992) using a symbolic coding of the 20
natural AAs and dipeptide frequencies, i.e. a vector of (202) components
for each primary structure. At diﬀerence with these authors, we used a
numeric coding for the AAs in the aim to: i) exploit the physico-chemical
information characterizing each single residue; ii) increase the length of the
oligopeptides; iii) minimize the computational burden by reducing the num-
ber of classes in which the residues can be clustered. The main goal was to
provide a more direct correlation between primary and tertiary structures’
similarities.

5

A glance at Figure 1 indicates that even using vectors of 53 components,
corresponding to tripeptides’ frequencies and to clustering the AAs into
ﬁve groups, in the description of the primary structures, the phylogenetic
relationships within cytochromes are very well preserved.

A quantitative estimate of the classiﬁcation goodness obtained by the
SOM algorithm is provided in Figure 2 in terms of the Map Mean Homology
(M M H, see methods) score for both Data Sets I and II. In each panel of
Figure 2 is also indicated (dotted line) the Set Mean Homology (SM H, see
Methods), i.e. an estimate of the overall similarity between all the couples of
elements in the set. Under all conditions the bars’ heigth exceeds the dotted
line of an amount indicating the performance of the classiﬁer algorithm. The
bars in Figure 2 represent the values of the M M H for various combinations
of: i) the coding criteria for the AAs; ii) the number of groups in which the
AAs are clusterized; iii) the length of the oligopeptides whose frequencies
constitute the vectors associated to each sequence.

The most interesting result provided by our analysis is the striking dif-
ference in the eﬃciency of the adopted coding scheme for the AAs, between
the two data sets. Taking as a reference the previously used symbolic cod-
ing coupled to dipeptide frequencies (black bars in Figure 2), substantially
identical results have been obtained under all conditions when the data set
included elements of high SM H (Figure 2A). Upon collapsing the latter
constraint, however, a numerical coding based upon a PCA of their main
physico-chemical properties (Table 1), and the ensuing techniques of cluster-
ing the AAs (Table 4) into 4 or 5 groups, provided a worse performance and a
better one in the case of, respectively, dipeptides and tripeptides frequencies
(Figure 2B).

To rationalize these results two basic points should be taken into account:
ﬁrst of all, it is quite obvious that, in very general terms, the ability of the
SOM algorithm in ﬁnding peaks of similarity over a background of globally
low similarity in the map is exalted. Such an eﬀect is independent from the
coding criteria of the residues and only deals with the speciﬁc features of
the elements to be classiﬁed. It can be described by the expression:

< M M H > −SM H
SM H
which, for the data shown in Figure 2A and B, gives the average values of
0.19 ± 0.03 and 1.83 ± 0.97, respectively.

(4)

Second, the much higher relative variance associated to the results in
Figure 2B clearly indicates that the role of the coding criteria, namely i)
oligopeptide length, and ii) optimized (through PCA) physico-chemical in-
formation, is only emerging in the case of Data Set II.

Finally, special consideration deserves the diﬀerence observed between
the two data sets when the classiﬁcation occurs after a random clustering of
the AAs in 4, 5 or 10 groups (white columns in Figure 2). Such a condition

6

has been included in our analysis to clarify the relative importance of the
symbolic coding of AAs (see Discussion).

4 Discussion

In classifying proteins of diﬀerent length on the basis of their polypeptide
sequences a crucial problem consists in the appropriate coding of the AAs,
since the appropriate statistical and connectionist procedures usually re-
quire as an input numerical vectors of identical dimension. To overcome the
problem a ”units-variables” matrix may be worked out, where the rows are
associated to the proteins and the columns contain, for example, the relative
frequencies of the 20 natural AAs, or of dipeptides, tripeptides, etc., thus
providing a more and more accurate (although longer) global description of
the primary structures. In particular, such an approach has been applied
in the use of a neural classifying algorithm, the SOM (see Materials), en-
dowed with an automatic features’ extraction ability in the absence of any
indipendent information (unsupervised learning), with a minimum number
of adjustable parameters.

In this paper we showed that a synergic use of multivariate statistical
techniques and of the SOM algorithm is very eﬀective, mainly in the case of
heterogeneous data sets, given an appropriate choice of the coding criteria
for the AAs and of the length of the oligopeptides used to represent the
primary structures. This clearly appears from the comparison of the upper
and lower panels in Figure 2, referring to data sets of high and low mean
homology, respectively. Under the former condition, as indicated by the high
value of the SM H, all the explored criteria for primary structures’s coding
look almost equivalent. The improvement obtained with reference to the
more traditional symbolic representation of AAs and dipeptides’ frequencies
is evident in the lower panel, where the data set includes elements of much
lower SM H.

This poses the question whether a further improvement could be ob-
tained by further increasing the oligopeptides length, d. For both data sets
used in this work this was actually not the case (not reported). The main
reason is related to the exponential increase, with increasing d, of the size
of the frequency matrices, coupled to a linear decrease in the number of
oligopeptides associated to each primary structure of length N described
over an alphabet of n diﬀerent symbols (n = 20 for an unreduced symbolic
representation of the 20 natural AAs). In other words, the ratio

N − d + 1
nd
which represents the fraction of the non-zero elements in the frequency ma-
trix for each polypeptide sequence, tends very rapidly to zero with increasing
d. Thus, the sparsity of the cumulative matrix related the whole data set,

(5)

7

obtained from the element by element sum of the individual frequency ma-
trices, should be considered as the main factor aﬀecting the eﬃciency of
the SOM classiﬁer. Reducing to more favourable values expression 5 by
reducing n, i.e. clustering the AAs residues into relatively homogeneous
groups, needs the adoption of a numerical coding for the residues, on the
basis of their hydrophobicity (Cid 1982; Reyes 1993) or, even better, of the
principal components extracted from a bulk of physico-chemical properties.
The optimal number of such groups can be deﬁned, in any case, through
the Explained Variability index (see the legend to Table 4). A complemen-
tary approach obviously consists in an appropriate ﬁltering of the sparse
matrices.

A possible objection to the above sketched strategy could invoke the
observed insensitivity to the various coding schemes in the classiﬁcation of
the primary structures included into Data Set I. This focusses our attention
on the peculiar features of the elements of this data set, namely on their
structural (at the tridimensional level) and functional homogeneity, which
seems to pose an intrinsic limit to any substantial improvement in the classi-
ﬁcation, even by increasing the oligopeptides’ length. It was not possible in
fact, under the explored conditions, to outperform the traditional symbolic
coding of the residues coupled to dipeptide frequency matrices. A crucial
observation in that respect, however, is that even after random grouping the
residues into 4 or 5 classes the quality of the classiﬁcation, as judged by the
M M H index, was not decreased. This points to the conclusion that even a
relatively poor symbolic coding is able to capture the only relevant source of
information in this peculiar data set, which could be associated to a variabil-
ity of syntactic type, i.e. related to local diﬀerences between the elements
of the set (relatively) independent from their macroscopic function, since all
of them share a common structural and functional backbone (Yockey 1977).
In the absence of such common backbone, like in the case of Data Set II,
where the substantial diﬀerences between the primary structures, give rise
to a more semantic (i. e.
related to macroscopic functional diﬀerences)
variability, the numeric coding of AAs should be preferred to the symbolic
one. It makes easier, in fact, by getting rid of the redundant information, to
increase the length of the oligopeptides describing the primary structures,
and hence a more accurate description of their global architecture, with
substantial savings in terms of computational requirements.

Up to what extent it is really worth to extend such length remains an
open question. On the basis of a symbolic coding of the AAs, Strait and
Dewey argued recently (1996) that the Conditional Information Entropy
(Ik) of k-tuples of AAs, used to estimate the Information Entropy (I) of
proteins’ primary structures through the expression

I = lim
k→∞

Ik

8

(6)

already reaches a limiting value for k equal to four. Among other things,
these authors are also able to work out a ﬁgure for the fraction of the In-
formation Entropy related to the tridimensional structure. Thus, it seem
of great interest to check their theoretical conclusions against the results of
an empirical approach based on the performance of SOM classiﬁers and a
physico-chemical coding of the AAs.

5 Acknowledgements

Prof. Ernesto Capanna and dr. Stefano Pascarella, both from the Univer-
sity of Rome ”La Sapienza”, are gratefully acknowledged for many useful
discussions. This work has been partly supported by funds from the italian
M.U.R.S.T. (40% and 60%).

9

References

Alexandrov NN, Fischer D (1996) Analysis of topological and nontopological struc-
tural similiarities in the PDB: new examples with old structures. Proteins Struct.
Funct. Genet. 25:354-365

Argos P (1987) A sensitive procedure to compare Amino Acid Sequences. J.Mol.Biol.
193:385-396.

Bryant SH, Altschul SF (1995) Statistic of sequence-structure threading. Curr.
Opin. Struct. Biol. 5:236-244

Cid H et al.
hydrophobicity proﬁles. FEBS Lett. 150:247-254

(1982) Prediction of secondary structure of proteins by means of

Doelz R (1994) Computer analysis of sequence data, part I (In) Methods in molec-
ular biology, Vol. 24, Griﬃn AM, Griﬃn HG Eds. Humana Press, Totowa pp:9-171

Eisenhaber F et al. (1995) Protein structure prediction: recognition of primary,
secondary, and tertiary structural features from amino acid sequence. Crit. Rev.
Biochem. Mol. Bio. 30:1-94

Everitt B (1980) Cluster Analysis. Halsted press, New York

Fedorov AN, Baldwin TO (1997) Cotranslational protein folding. J. Biol. Chem.
272:32715-32718

Ferr´an EA, Ferrara P (1991) Topological Maps of Protein Sequences. Biol.Cybern.
65:451-458.

Ferr´an EA, Ferrara P (1992) Clustering proteins into families using artiﬁcial neural
networks. Comput. Appl. BioSci. 8:39-44

Ferr´an EA et al. (1992) Large scale application of neural network to protein clas-
siﬁcation. Art. Neur. Net., Vol. II, North-Holland, pp:1521-1524

Henikoﬀ S, Henikoﬀ JG (1992) Amino acid substitution matrices from protein
blocks. Proc. Natl. Acad. Sci. U.S.A. 89:10915-10919

Jolliﬀe IT (1986) Principal Components Analysis. Springer-Verlag, New York, USA

Kohonen T (1984) Self-organization and associative memory. Springer-Verlag,
Berlin

Kohonen T (1995) Self-organizing maps. Springer-Verlag, Heidelberg

Needlemann SB, Wunsch CD (1969) A general method to the search for similarities
in the amino acid sequences of two proteins. J. Mol. Biol. 48:443-453

Page RDM (1996) TreeView: an application to display phylogenetic trees on per-
sonal computers. Comput. Appl. BioSci. 12:357-358

Reyes VE et al. (1994) Prediction of structural helices with the strip-of-helix algo-
rithm. J. Biol. Chem. 264:12854-12858

Rost B, Sander C (1993) Improved prediction of protein secondary structure by
use of sequences proﬁles and neural networks. Proc. Natl. Acad. Sci. USA.
90:7558-7562

Schneider G, Wrede P (1993) Development of artiﬁcial neural ﬁlters for pattern
recognition in protein sequences. J. Mol. Evol. 36:586-595

Strait BJ, Dewey TG (1996) The Shannon information entropy of protein sequences.
Biophys. J. 71:148-155

Thompson JD et al. (1994) CLUSTAL W: improving the sensitivity of progres-
sive multiple sequence alignment through sequence weighting, position-speciﬁc gap
penalties and weight matrix choice. Nucleic Acid. Res. 22:4673-4680

10

Weiss O, Herzel H (1998) Correlations in protein sequences and property codes. J.
Theor. Biol. 190:341-353

Wishart DS et al.
sequence analysis. Comput. Appl. BioSci. 10:121-132

(1994) SEQSEE: a comprehensive program suite for protein

Yockey HP (1977) On the information content of cytochromes c. J. Theor. Biol.
67:347-376

11

Legends to tables and ﬁgures

Figure 1: Classiﬁcation of cytochromes of the c type by a SOM

algorithm.

The map is a graphical rearrangement of the output provided by the
SOMPAK 1.3 program (see the text) on the cytochromes listed in Table 2.
The input vectors, containing 53 = 125 components, have been constructed:
i) grouping the AAs into 5 classes by a k-means algorithm on the basis of
the ﬁrst and second principal components extracted from 7 physico-chemical
properties (see the text), and ii) using the tripeptides‘ frequency matrices.
The hexagonal lattice of the map and its overall size (6x7 cells) are a
compromise between the conditions used by Ferr´an and Ferrara (1992) and
the Kohonen’s suggestion to use diﬀerent sizes for the map’s axes. The
working parameters of the SOMPAK program are the following:

Lattice topology: hexagonal; Neighborood: bubble
First ordering phase:
learning rate = 0.05, 1000 epochs, starting radius 7
Fine tuning phase:
learning rate = 0.02, 10000 epochs, starting radius 2.
The maps refers to the best results obtained, in terms of the internal dis-
tortion parameter, over 40 diﬀerent choices of the random initial conditions
(see the Kohonen refs. for details)

Figure 2: Performance of the SOM algorithm for proteins’

classiﬁcation under various conditions.

Panels A and B refer to the proteins in Data Sets I and II (listed in
Table 2 and Table 3) and the histograms represent the M M H (Map Mean
Homology) score as deﬁned in the text. The working parameters of the
SOMPAK program are the same listed in Figure 1 except that, in the case
of Data Set II, the dimension of the maps was 5x4 due to the lower number
of elements.

The black, and white, bars refer to the unclustered natural, and ran-
domly clustered AAs, respectively. The darker and lighter grey bars refer
to clustering by hydrophobicity and, respectively, the PC1 + PC2 extracted
from physico-chemical properties (see the text). In the case of random clus-
tering each bar is the average of ten randomizations and the error bars
indicate one standard deviation.

12

Table 1: PCA on seven physico-chemical properties of the nat-

ural AAs.

The table shows the correlations (loadings) between seven physico-chemical

properties taken from Schenider and Wrede (1993) and the principal com-
ponents extracted from them. The ﬁrst row reports the percent of the total
variability (EV %) of the whole set of properties explained by each compo-
nent.

Table 2: Cytochromes of the c type used as Data Set I.
Column 1 is a numeric identiﬁer for the corresponding entrance, without
the cytc preﬁx, in the SwissProt data-base (column 2). Columns 3 and 4
refer, respectively, to the biological origin and the number of residues of
each protein. The used family abbreviations are the following: Amphibia
(Am), Angiosperm (Ap), Asteroidea (As), Birds (Av), Gastropoda (Ga),
Chlophyceae (Ch), Euglenoid algae (Eu), Ascomycetes (Fa), Basidiomycetes
(Fb), Deuteromycetes (Fd), Gymnosperm (Gp), Insects (In), Mammals
(Ma), Oligochaeta (Ol), Agnatha (Pa), Chondrichthyes (Pc), Osteichthyes
(Po), Protozoa (Pr), Reptiles (Re).

Table 3: Immunoglobulin-like fold proteins used as Data Set

II.

The ﬁrst four columns contain the same type of information as in Table
2. Notice that the primary structures have been obtained from the PDB
data-bank in this case. The full proteins names are listed in column 5.

Table 4: Clustering of the 20 natural AAs according to diﬀerent

criteria.

The ﬁrst two columns refer to the variable(s) upon which the clustering
into 4, 5 or 10 classes has been carried out by the k-means algorithm. In
each case the value of the percent of the explained variability (EV %) has
V arBetw+V arW ith , where
been calculated as the following ratio : EV % =
V arBetw and V arW ith are, respectively, the variability between the bari-
centers of the classes and the mean variability within each class. The last
column provides an example of a ”random clustering” of the 20 AAs into
the same number of classes.

V arBetw

13

Table 1: PCA on seven physico-chemical properties of the natural AAs.

EV%

Hydrophobicity
Volume
Surface Area
Hydrophilicity
Bulkiness
Refractivity
Polarity

PC1

PC2

50.04

34.73

0.231
-0.940
-0.209
0.052
0.023
0.120
0.030

0.953
0.239
0.025
0.067
-0.142
0.068
-0.063

PC3

7.43

0.865
0.466
0.020
-0.023
-0.172
-0.012
0.067

PC4

5.29

-0.560
0.736
0.357
-0.017
0.064
0.113
0.015

PC5

1.90

0.857
-0.146
0.285
0.362
0.180
-0.028
0.007

PC6

0.47

0.863
0.188
-0.071
-0.423
0.192
0.006
-0.003

PC7

0.14

-0.047
0.821
-0.512
0.229
0.096
0.016
0.003

14

Table 2: Cytochromes of the c type used as Data Set I.

Id

Code

Species Fam.

Length

Id Code

Species Fam.

Length

Sambucus Nig. Ap
Cann. Sativa Ap
Abutil. Theophr. Ap
Nigel. Damasc. Ap
Allium Porrum Ap
Zea Mays Ap
Phaseolus Au. Ap
Tropaeol. Majus Ap
Pastin. Sativa Ap
Solanum Tuber. Ap

Rana Catesb. Am
ranca
1
Acer Negun. Ap
acene
2
Fagopyrum Escul. Ap
fages
3
Ricinus Comm. Ap
ricco
4
Brassica Oler. Ap
braol
5
aruma Arum Macul. Ap
6
samni
7
cansa
8
abuth
9
nigda
10
11
allpo
12 maize
phaau
13
troma
14
passa
15
soltu
16
cucma Cucurb. Max. Ap
17
orysa
18
sesin
19
gosba
20
spiol
21
helan
22
23
lyces
24 wheat
astru
25
chick
26
anapl
27
drono
28
strca
29
aptpa
30
colli
31
helas
32
chlre
33
entin
34
euggr
35

Oryza Sativa Ap
Sesamum Indic. Ap
Gossypium Barbad. Ap
Spinacia Oler. Ap
Helianth. Ann. Ap
Lycopersicon Escul. Ap
Triticum Aestiv. Ap
Asterias Rub. As
Gallus Gallus Av
Anas Platyrhyn. Av
Dromaius N.-Holl. Av
Struthio Camel. Av
Aptenodytes Patag. Av
Columba Livia Av
Helix Aspersa Ga
Chlamydom. Reinh. Ch
Enterom. Intest. Ch
Euglena Gracil. Eu

schpo
hanan
issor
neucr
torha
ustsp
thela
ginbi
samcy
schgr
boepe
luccu
apime
haeir

Schizosac. Pombe Fa
36
Hansen. Anom. Fa
37
Issatchen. Ori. Fa
38
Neurosp. Cr. Fa
39
Torulasp. Hans. Fa
40
Ustilago Sphaer. Fb
41
Thermomy. Lan. Fd
42
Ginkgo Biloba Gp
43
Samia Cynthia In
44
Schistoc. Greg. In
45
Boettch. Per. In
46
Lucilia Cupr. In
47
Apis Mell. In
48
Haematob. Irrit. In
49
50 macma Macrobrac. Mal. In
51 manse Manduca Sexta In
52
53
54
55
56 minsc
57 macmu Macaca Mulat. Ma
58
atesp
59 mirle
eisfo
60
enttr
61
squsu
62
cypca
63
katpe
64
crifa
65
crion
66
tetpy
67
croat
68
chese
69

Ateles Sp. Ma
Mirounga Leon. Ma
Eisenia Foetida Ol
Entosphen. Trident. Pa
Squalus Sucklii Pc
Cyprin. Carpio Po
Katsuwon. Pelamis Pr
Crithidia Fasc. Pr
Crithidia Oncop. Pr
Tetrahymena Pyr. Pr
Crotalus Atrox Re
Chelydra Serp. Re

Canis Famil. Ma
canfa
Equus Asinus Ma
equas
Equus Caball. Ma
horse
human Homo Sapiens Ma

Miniopt. Schreib. Ma

104
112
109
107
111
109
111
104
108
101
105
109
111
109
107
111
111
111
108
108
111
111
111
112
103
104
104
104
104
104
104
98
111
100
102

108
109
109
107
109
107
111
107
107
107
107
107
107
107
104
107
104
104
104
104
104
104
104
104
108
104
104
94
103
113
112
109
104
104

15

Table 3: Immunoglobulin-like fold proteins used as Data Set II.

No

PDB Id

Source

Length Protein’s name

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23

Actinomyces globisporus
1ACX
Bovine erythrocytes
1COB(A)
Turnip - Brassica rapa
1CTM
Human
1TEN
Human
3HHR(B)
Escherichia coli
3DPA
Human
2RHE
2MCG(1)
Human
1MCO(L) Human
Mouse
1FAI(L)
Human
2FB4(H)
Human
8FAB(B)
Mouse
2FBJ(H)
Mouse
1CDB
Turkey gizzard
1TLK
1MCO(H) Human
Human
2IGE(A)
Guinea pig serum
1PFC
Rat
1CID
Human
3CD4
Human
1DLH(A)
Human
1DLH(B)
Human
3HLA(A)

108 Actinoxanthin
151
250 Cytochrome f

Superoxide dismutase

90 Tenascin

Immunoglobulin lambda
Immunoglobulin g1
Fab fragment
Immunoglobulin fab
Fab fragment
Ig A fab fragment

197 Human growth hormone
218 Pap D
114 Bence-Jones protein
216
216
214
229
215
220
105 T lymphocyte adesion glycoprotein
103 Telokin
428
320
111
177 T-cell surface glycoprotein Cd4
178 T-cell surface glycoprotein Cd4
180 Histocompatibility antigen Hla-dr1
188 Histocompatibility antigen Hla-dr1
270 Histocompatibility antigen Hla-a2

Immunoglobulin g1
Fc fragment (theoretical model)
Ig g1 P F c(prime) fragment

16

Table 4: Clustering of the 20 natural AAs according to diﬀerent criteria.

Hydrophobicity

PC1 + PC2

Random

4 Clusters

1 A C G I L M F P S T W V C I L M P T V
2 D E K
3 N Q H Y
4 R

R N D Q E H K N A S Y G H
A G S
F W Y

L M D F C W Q E
I V K P T

R

EV :

94%

5 Clusters

84%

—

1 A C I L M F W V
2 D E K
3 N Q H
4 R
5 G P S T Y

C I L M P T V M N
N D Q E H
A G S
F W Y
R K

D F Y P W E
L V A K T H
S R C
I G Q

EV :

98%

90%

—

10 Clusters

I L V

1
2 D K
3 N Q
4 R
5 A C W
6 P Y
7 H
8 G S T
9 M F

10 E

EV :

99.9%

I L M V
N D
A S
F Y
R K
C P T
W
G
Q H
E

98%

K
M D P
Q
L N G
V T
E
A F
I Y H
R C W
S

—

17

Figure 1

Av-26
Av-27
Av-28
Av-29

Av-30
Av-31
Re-69

Ma-55
Ma-57
Ma-58
Re-68

Eu-35
Fa-36
Fa-39
Fd-42

Ma-52
Ma-53
Ma-54
Ma-56
Ma-59

In-44
In-46
In-47
In-49
In-51

Pr-67

As-25
In-48
Pc-62

Ga-32

Ap-10
Ch-34

In-45

Ol-60

Gp-43

Ap-8
Ap-15
Ch-33

In-40

Ap-24

Ap-3
Ap-16

Ap-6

Am-1
Pa-61
Po-63
Po-64

Fa-38
Fb-41

Fa-37
Fa-40

Pr-65
Pr-66

Ap-2
Ap-4
Ap-9

Ap-20
Ap-21
Ap-22

Ap-19
Ap-23

Ap-5
Ap-7
Ap-11
Ap-12

Ap-13
Ap-14
Ap-17
Ap-18

Figure 2

Dipeptides

Tripeptides

20

10

10

10

4

5

4

5

4

5

# of classes

Dipeptides

Tripeptides

20

10

10

10

4

5

4

5

4

5

# of classes

A

e
r
o
c
s
 
H
M
M

5

4

3

2

1

0

1.2

B

e
r
o
c
s
 
H
M
M

1

0.8

0.6

0.4

0.2

0

