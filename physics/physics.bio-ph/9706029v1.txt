Distributions of Triplets in Genetic Sequences

Yu Shi∗, Ido Kanter and David Kessler

Minerva Center and Department of Physics, Bar-Ilan University, Ramat Gan 52900, Israel

Abstract

Distributions of triplets in some genetic sequences are examined and found

to be well described by a 2-parameter Markov process with a sparse transition

matrix. The variances of all the relevant parameters are not large, indicating

that most sequences gather in a small region in the parameter space. Diﬀer-

ent sequences have very near values of the entropy calculated directly from

the data and the two parameters characterizing the Markov process ﬁtting

the sequence. No relevance with taxonomy or coding/noncoding is clearly

observed.

87.10.+e, 02.50.Ga, 05.40.+j

7
9
9
1
 
n
u
J
 
0
2
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
9
2
0
6
0
7
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Typeset using REVTEX

∗corresponding author

1

I. INTRODUCTION

In recent years, methods of statistical mechanics are applied in other ﬁelds of research

based on mapping the quantities under study to physical or numerical quantities, e.g. spins

or binary numbers “0” and “1”, from which various measures can be calculated and analysed

[1,2]. Such is the case in the recent investigations on the statistical properties of DNA

sequences and human languages [2–8], as well as music [9,10]. The observation that local

grammar-like rules aﬀect the global statistical nature of sequences is in accordance with the

philosophy of statistical mechanics.

An interesting issue concerns the distribution of semantic units “words”; words in a

languange and the 64 triplets (3-tuples) in genetic sequences. The frequency of the occurence

of each semantic unit is calculated, and the units are ordered in a the decreasing order of

frequency, P (1) ≥ P (2) ≥ · · · ≥ P (N), where N is the size of the vocabulary. For

languages, there was a so-called Zipf’s law that

P (k) ∝ k−ρ

(1)

with ρ ∼ 1.0 [11]. In DNA sequences, triplets in coding regions are the “words”, since the

coding regions are transcribed to RNA, where the nonoverlapping triplets code the amino

acids. It is unknown whether there are “words” in noncoding regions. Recently, distributions

of n-tuples (n ranges from 3 to 8) were analysed and it was claimed that Zipf’s law holds and

that ρ is consistently larger for the noncoding sequences than coding sequences and therefore

the former are more similar to languages [5]. This conclusion was heavily criticized [12]. In

fact, though it was appealing due to the earlier attempts to relate it to the structure of

language [13], Zipf’s law had been acknowledged as “linguistic shallowness” since it can be

generated from random text [14] [15] [12], it was claimed recently that an inverse power

upper tail in the distribution can be obtained under quite general conditions [16]. On the

other hand, it was pointed out that ρ = −d ln(P )/d ln(k) is, in fact, a increasing function

of k, there is no macroscopic regime where ρ is a constant, consequently any attempt to ﬁt

the data with a single ρ is sensitive to the details of the ﬁtting [8].

2

For the occurrence of letters over the alphabet in biological sequences as well as in over

100 human languages, it was claimed that the ordering of frequencies approximates [6]

P (k) = A − D ln(k),

(2)

where A and D are constants, the normalization condition reduces the independent parame-

ter to only one. An exception was found to be Chinese, where the corresponding distribution

is nearer to Zipf’s law. This can be understood; there is no letter in Chinese unless it is

transformed to the alphabetic system according to the pronounciation, while the character,

which had been considered to be the letter since it is the basic unit, also embeds meanings.

The characterization and explanation of the distributions demands a model beyond the

Zipf’s law. A 2-parameter random Markov Process (MP) was proposed for the generation

of these sequences [8], with the observations mentioned above being natural consequences.

Can the distributions of 3-tuples in various diﬀerent genetic sequences be well described by

the MP model? The positive answer is given by showing that the distributions for each

sequence that is long enough can be ﬁtted very well by a MP with certain parameters, while

the features for short sequence are consequences of ﬁnite Markov chain. But no relevance

with taxonomy or coding/nocoding issue is clearly observed.

The MP model is explained in Sec. II; the analysis on genetic sequences is reported in

Sec. III; Sec. IV contains the conclusions.

II. THE TWO-PARAMETER MARKOV PROCESS

A Markov process is the simplest algorithm for the stochastic production of sequences.

Consider the generation of a sequence composed of “words” or states chosen from N possi-

bilities. If the probability distribution for choosing the next “word” is only a function of the

current last one, then this process can be considered as a MP. The transition probability

from state i to j is denoted as W (i, j). There is the normalization condition

Pj W (i, j) = 1.
The probability of occurrence of each “word” in the sequence which is long enough is the

stationary solution of MP. The ingredients of this model are as follows:

3

(a) Number of states. For simplicity, N is ﬁxed to be equal to 2L with L an integer,

each state is identiﬁed by an L-bit binary number between 0 and N − 1. For the genetic

sequences, N = 64 and thus L = 6.

(b) Sparseness of W . Reﬂecting the grammatical rule, the transition matrix W (i, j) is

assumed to be sparse, i.e. the number of nonvanishing elements in each row, C, is ﬁnite and

does not scale with N. The simplest nontrivial case is C = 2.

(c) Permissible connectivity. The cornerstone of the discussed MP is that the transi-

tion matrix diﬀers from a random graph.

In a language, for instance, the semantic and

grammatical rules require that a word is not haphazardly followed by a random selection of

other words. Rather, the choice of the successive word is strongly constrained. This fact is

modeled in the following manner. The two states m0 and m1 connected to the state m are

given by

to 2.

m0 = (2m)mod(N); m1 = (2m)mod(N) + 1,

(3)

where m = 0, 1, ..., 2L − 1. In words, the L − 1 rightmost bits of state m are shifted one bit

to the left, and the rightmost bit is set equal to either 0 or 1. Thus each successive word is

closely related to the one before, the outword and inword connectivity of each state is equal

(d) Strength of transition probabilities. The two weights, transition probabilities, going

from each state take the value x and 1 − x.

(e) Bias. Another parameter, the bias, is introduced to distinguish the two options.

We pick W (m, m0) = 1 − x and W (m, m1) = x with probability B, and vice versa with

probability 1 − B.

The bias can be thought to be related to some global constraints by the “meaning” of

the text in addition to those reﬂected by the local rules. When B = 0.5, i.e. there is no

bias, this MP was found [8] to lead to a distribution approximating log-normal rule, Eq. (2),

which is held quite well by the distribution of letters. This can be understood through the

fact that the sequence of letters is only restricted by local phonetic preferences.

4

Because of global inversion symmetries x → 1 − x and B → 1 − B, the interesting

regime in the unit square of (x, B) may only be (0.5 − 1, 0.5 − 1). Furthermore, changing

only x to 1 − x, or B to 1 − B is only changing the role between 0 and 1.

An important variable is the average drift towards 1, xef f = xB + (1 − x)(1 − B). It

was found that a function obtained by rescaling the local slop of the distribution function

only depends on xef f in addition to the rank order [8]. For x = 0.5, we have xef f = 0.5

independent of B. Another interesting quantity is the Markov entropy

Sm = −x ln x − (1 − x) ln(1 − x),

(4)

which is independent of B.

The feature of this type of MP model have been found to be robust for many modiﬁca-

tions. For example, the qualitative feature does not change if dependence of the next state

on more former states than the current last is introduced, or higher but still ﬁnite connectiv-

ities are allowed. It was also found that all the distributions resulting from these extended

models could be readily mapped to the simplest one [17]. Therefore this two-parameter

model can serve as a prototypical model even for less sparse matrix, which might possess

many parameters.

III. GENETIC SEQUENCES

Genetic sequences of diﬀerent taxonomic divisions are randomly selected from GenBank

Release No. 97 [18]. First, for short sequences there are, of course, many platforms in the

ordered distribution of triples, and cannot be ﬁtted by the stationary solutions of the MP

process. This is a ﬁnite-size eﬀect and just a support for the validity of this model. As

an example, compare the ordered distributions for bacteriophage P1 gene10 with 1127 bp

as shown in Figure 1 (a) with the ordered distribution generated by a MP with x = 0.69,

B = 0.62 after 500 steps as shown in Figure 1 (b).

We analysed in detail 22 long sequences: the longest one being s. cerevisiae chrosome III

complete DNA sequence with 315341 bp; the shortest one comprises 6061 bp; 6 sequences

5

are complete DNA genome-s; 5 are complete cds-s, i.e., sequences coding for amino acids in

protein; 3 RNA sequences, 2 of them are complete genome. Diﬀerent sequences are listed

and numbered in Table I.

We ﬁt the data of the distributions in terms of that generated by the MP model. For each

sequence, the distribution of triplets is calculated and ordered in decreasing order. Then

the parameters x and B are found for the best ﬁtting MP with the least value of the cost

function deﬁned as

where

Cost = v
u
u
t

1
64

64

X
k=1

D2(k),

D(k) =

Ps(k) − Pm(k)
Ps(i)

,

Ps(k) is the rank-ordered distribution of triplets for a genetic sequence, Pm(k) is the rank-

ordered distribution of 6−bit binary numbers for a MP. In the two dimensional lattice

parameter space (x, B) = (0.5 − 1, 0.5 − 1) with lattice constant 0.01, we search for the

MP which ﬁts each sequence with minimal cost. Three examples of the distribution and its

ﬁtting to MP are shown in Figure 2. It can be seen that the ﬁtting is quite good. Such is the

case for 16 sequences. For the remaining 6, there is a discontinuous decrease at a high rank

k = 54 or 56. Those ﬂuctuations in the tail , which is of the order of 10−3 or smaller, are

obviously due to the fact that these sequences are not so long that the corresponding Markov

process become stationary (rf. Table I). A satisfactory ﬁtting can be found eliminating the

last several points. See Figure 3 for an illustration.

Note that our ﬁtting is global instead of being part of the data, i.e., the contributions to

the cost function do not come mainly from the tail, as shown in Figure 4.

The quantitative results are summarized in TABLE 2 for all the sequences we analyzed.

We present the values of the cost, x and B. From x and B we calculate xef f and the Markov

entropy Sm of the corresponding Markov process, and the Shannon entropy

(5)

(6)

(7)

S = −

Ps(k) ln Ps(k)

X
k

6

calculated directly from the original data of each sequence. For a completely random se-

quence, P (k) = 1/64, thus S = ln(64) ≈ 4.1589.

It is clear that the costs are very small; the largest one is 0.0807 while the least is

0.0273. The average and variance of the results over all sequences are presented in Table

III, in addition, the average of costs is 0.0555. It is remarkable that the relative variance,

i.e. variance divided by the average for each quantity, is not large.

In particular, that

for xef f is only 0.0485, implicating that xef f is a very special quantity, while that for S,

which is model-irrelevant, is only 0.0179. The relative variances for x, B and Sm are either

not large, though larger than those for S and xef f . It can be seen that the statistics are

diﬀerent but not far from each other, and that most sequences ocuppy a small region in

the parameter space, which is distinct but not very far from the complete randomness with

x = xef f = 0.5, Sm = 0.6931 and S = 4.1589.

A problem is whether there is a distinction in quantities discussed here between coding

and noncoding sequences. To examine this possibility, we calculate the average values over

sequences No. 7, 8, 9. 10, 12, 13, 19, 20. These sequences are complete coding sequences or

RNA. Both are 100% coding. Comparing Table IV with Table III, it can be seen that x is

larger than the average over all sequences, and Sm and S are smaller, clearly in contrast to

the claim that noncoding regions are more similar to languages than coding regions [2]. But

the diﬀerence is so small that no deﬁnite conclusion can be drawn. On the other hand, the

diﬀerences with those of the language are still very large, since values of x and B were found

both to be 0.92 [8], a very large value. Similar investigations are made on whether there

is relevance between the quantities characterizing sequences and the diﬀerent taxonomic

divisons. We calculate the averages and variances for each division, as listed in Table V.

It can be seen that there is no monotonic trend with the evolution. To examine whether

sequences in the same division are closer to each other compared with all sequences, we

compare the overall variances in Table III and the variances for viral and primate in Table

V, since for other divisions only one or two sequences are analysed. It can be seen that some

are larger while some are smaller than those for all the sequences. Therefore, in our result

7

there is no sign of relevance between these quantities and taxonomy.

The distribution of triplets remains nearly unchanged if the starting nucleotide shifts 1

or 2 behind. This can be seen from Figure 5 showing the distributions for the original s.

cerevisiae chrosome III complete DNA sequence, and those shifted 1 and 2 behind. This

result holds for all sequences.

IV. CONCLUSIONS

(1) Statistics of examined genetic sequences are well described by the 2-parameter Markov

(2) Most sequences gather in a small region in the parameter (x, B) space. The entropy

S of the data and xef f measured in the MP model are very near to each other for diﬀerent

(3) No relevance of the quantities studied here with coding/noncoding issue or with

process.

sequences.

taxonomy is observed.

(4) The distribution of triplets remains unchanged if the sequence is shifted.

More biologically relevant information might be exposed when the distribution and tran-

sition matrix are analysed according to the real triplets instead of to the rank order. In this

way, the transition matrix varies from sequence to sequence, determined by the diﬀerent

biochemical enviornments.

ACKNOWLEDGMENTS

Y.S. thanks BIU for hospitality.

8

REFERENCES

[1] This trend in modern statistical mechanics seems to be consistent with some ancient

philosophy. In an ancient Chinese philosophy book Yi Jing (Principle of change) written

about 3000 years ago, there is a symbolic system called “Eightfold Diagrams” consisting

of symbols stacked by 6 broken or whole lines representing respectively two opposite

elements “Yin” (-) and “Yang” (+). It was claimed that everything can be explained by

mapping to this system. It is amusing to note that the number of symbols is 26 = 64,

the same as the number of triplets in genetic sequences. Maybe this is not accidental

from the viewpoint of information carriers.

[2] C.K. Peng et. al., Nature 356, 168 (1992).

[3] W. Li and K. Kaneko, Europhys. Lett. 17, 655 (1992).

[4] A. Schenkel, J. Zhang, and Y. Zhang, Fractals, 1, 47 (1993).

[5] R.N. Mantegna et. al, Phys. Rev. Lett. 73, 3169 (1994); 76, 1979 (1996).

[6] S. Shtrikman, J. Information Sci. 20 2 (1994).

[7] W. Ebeling, A. Neiman, and T. P¨oschel, in Coherent Approach to Fluctuations, edited

by M. Suzuki, (World Scientiﬁc, Singapore, 1995), and references therein.

[8] I. Kanter and D.A. Kessler, Phys. Rev. Lett. 74, 4559 (1995).

[9] J. P. Boon and O. Decroly, Chaos 5 501 (1995).

[10] Y. Shi, Fractals 4, 547 (1996).

[11] G.K. Zipf, Human Behavior and the Principle of Least Eﬀort, (Addison-Wesley, Read-

ing, 1949).

[12] N.E. Israeloﬀ, M. Kagalenko, and K. Chan, Phys. Rev. Lett. 76, 1976 (1996); S. Bon-

hoeﬀer et. al, ibid, 76, 1977 (1996); R. F. Voss, ibid, 76, 1978 (1996).

9

[13] B. Mandelbrot, Word 10, 1 (1954).

[14] B. Mandelbrot, Fractals, Form, Chance, and Dimension, (Freeman, New York, 1977);

B. Mandelbrot, in Structure of Language, edited by R. Jacobson (AMS, New York,

[15] G. Miller, Am. J. Psychol. 70, 311 (1957); G. Miller and N. Chomsky, in Handbook of

Mathematical Psychology II, edited by R. Luce, R. Bush, and E. Galanter (Wiley, New

1961).

York, 1963).

[16] R. Perline, Phys. Rev. E 54, 220 (1996).

[17] M. Harlibard and I. Kanter, Physica (in press); M. Harlibard, M. S. thesis, Bar-Ilan

University (1996).

[18] D. Bensen et. al., Nucl. Acids Res. 24, 1 (1996).

10

FIG. 1. (a) Rank-ordered distributions of triplets for bacteriophage P1 gene10 with 1127 bp.

(b) Rank-ordered distributions resulted from the 2-parameter Markov process with x = 0.69,

FIGURES

B = 0.62 after 500 steps.

FIG. 2. Rank-ordered distributions of triplets for genetic sequences and of the 6-bit binary

numbers for the 2-parameter Markov process which best ﬁt the sequences. (a) No. 1, (b) No. 15,

(c) No. 17.

neglected.

FIG. 3. There is a discontinuity at k = 54 in the distribution of triplets for sequence No. 10.

A 2−parameter Markov process can be found to give a satisfactory ﬁt if the last 10 points are

FIG. 4. The relative diﬀerence between the rank-ordered distribution of triplets in sequence

No. 1 (Bacteriophage lambda) and that of 6-bit binary numbers in the 2-parameter Markov process

giving the best ﬁt D(k) = [Ps(k) − Pm(k)]/Ps(i).

FIG. 5. Rank-ordered distributions of triplets for (a) original s. cerevisiae chrosome III com-

plete DNA sequence, (b) shifted 1 behind, (c) shifted 1 behind. They are very near to each other.

11

complete genome

complete genome

complete genome

complete genome

RNA genome

TABLES

TABLE I. Information on the 22 sequences analysed in this paper, they are numbered for the

convenience of presenting the results. No. 7, 8, 9 are RNA; all others are DNA.

No. Locus name

Deﬁnition

Taxonomic division Length (bp)

1

LAMCG

Bacteriophage lambda

phage

48502

2 MYP4CG

Bacteriophage P4

phage

11624

3 HSECOMGEN Equine herpesvirus,

viral

150223

4 VACRHF

Vaccinia virus genomic DNA

5 ASFV55KB

African swine fever virus

6 HEHCMVCG Human Cytomegalovirus Strain AD169

viral

viral

viral

viral

viral

42090

55098

229354

9468

8000

7161

7568

7 TOEAV

Equine arteritis virus (EAV)

viral

12687

8 WNFCG

West Nile virus RNA

viral

10960

9

FIVPPR

Feline immunodeﬁciency virus

complete genome (RNA)

complete genome (RNA)

10 RTUORFS

Rice tungro bacilliform virus

11 CSHCG

Cacao swollen shoot virus polyprotein gene

viral

12 SBVORFS

Sugarcane bacilliform virus

viral

13 ANAAZNIF

Anabaena azollae nifB operon

bacterial

6061

complete cds

complete circular genome

complete cds

12

complete cds

14 SCCHRIII

S.cerevisiae chromosome III

plant

315341

complete DNA sequence

15 TGDNAPRRA T.godoii (strain P)

16 TGDNARH

T.gondii (RH)

invertebrate

invertebrate

17 MMCOL3A1

M.musculus COL3A1 gene for collagen alpha-I

rodent

18 PTMITG

P.troglodytes mitochondrial DNA

primate

complete genome (isolate Jenny)

19 HUMCFVII

Human blood coagulation factor VII gene

primate

12850

20 HUMRETBLAS Human retinoblastoma susceptibility gene

primate

180388

complete cds

complete cds

21 HUMHBB

Human beta globin region on chromosome 11

primate

22 HSP53G

Human p53 gene

primate

8350

8352

43601

16561

73308

20303

13

TABLE II. Quantitative results on the 22 sequences. S is the entropy of the sequences, cost

is a measure of the ﬁtting, x and B characterize the Markov process giving least cost, xef f is a

function of x and B, the Markov entropy Sm is a function of x. See the text for deﬁnitions.

No.

1

2

3

4

5

6

7

8a

9a

10a

11

12

13

14

15

16

17a

18

19

20a

21a

22

cost

0.0689

0.0491

0.0273

0.0654

0.0807

0.0441

0.0737

0.0355

0.0643

0.0726

0.0646

0.0543

0.0484

0.0404

0.0322

0.0309

0.0630

0.0716

0.0673

0.0590

0.0638

0.0709

x

0.6100

0.6900

0.6000

0.7600

0.6200

0.6100

0.7000

0.7500

0.7100

0.8100

0.7400

0.7400

0.6800

0.7000

0.6000

0.6100

0.7200

0.7900

0.7600

0.7000

0.6600

0.6700

B

0.6800

0.5100

0.7000

0.6100

0.8300

0.7700

0.5400

0.5900

0.7400

0.5600

0.5200

0.6500

0.6200

0.5200

0.7400

0.6800

0.5100

0.5300

0.6100

0.5300

0.5700

0.6700

14

xef f

0.5396

0.5038

0.5400

0.5572

0.5792

0.5594

0.5160

0.5450

0.6008

0.5372

0.5096

0.5720

0.5432

0.5080

0.5480

0.5396

0.5044

0.5173

0.5572

0.5120

0.5224

0.5578

Sm

0.6687

0.6191

0.6730

0.5511

0.6640

0.6687

0.6109

0.5623

0.6022

0.4862

0.5731

0.5731

0.6269

0.6109

0.6730

0.6687

0.5930

0.5140

0.5511

0.6109

0.6410

0.6342

S

4.1225

4.0891

4.1201

3.9591

4.0475

4.1073

4.0949

4.0005

3.9256

3.8553

4.0356

3.9616

4.0545

4.0629

4.1131

4.1139

3.9761

3.9838

3.9829

3.9991

4.0181

4.0774

aThere is a discontinuity at rank order k = 54 in the rank-ordered distribution of triplets for

sequence No. 10, and at k = 56 for sequences No. 8, 9, 17, 20, 21. A Markov process ﬁtting each

of them satisfactorily can be found if the points after the discontinuity are neglected.

TABLE III. The average value, variance and relative variance of the ﬁve quantities calculated

over all the 22 sequences analysed.

quantity

average

variance

variance/average

x

B

xef f

Sm

S

x

B

xef f

Sm

S

20.

quantity

0.6923

0.6218

0.5395

0.6080

4.0319

0.7312

0.6050

0.5479

0.5779

3.984

TABLE IV. The average value, variance and relative variance of the ﬁve quantities calculated

over the RNA sequences No. 7, 8, 9, and the complete coding DNA sequences No. 10, 12, 13, 19,

average

variance

variance/average

0.0924

0.1515

0.0485

0.0878

0.0179

0.0578

0.1128

0.0531

0.0789

0.0186

0.0640

0.0942

0.0261

0.0534

0.0720

0.0422

0.0682

0.0291

0.0456

0.0739

15

TABLE V. The average value of the ﬁve quantities calculated over each taxonomic division, the

variances and the relative variances are also given for the divisions with more than one sequence

analysed here. The number within the parentheses after each division name is that of the analysed

sequences belonging to this division.

quantity

average

variance

variance/average

0.0566

0.1202

0.0253

0.0351

0.0236

0.0714

0.1052

0.0281

0.0600

0.0862

0.0870

0.2020

0.0485

0.0545

0.0057

0.1014

0.1617

0.0509

0.1005

0.0215

division

phage (2)

viral (10)

bacteria (1)

plant (1)

xef f

Sm

xef f

Sm

xef f

Sm

x

B

S

x

B

S

x

B

S

x

B

S

x

B

xef f

Sm

0.6500

0.5950

0.5217

0.6439

4.1058

0.7040

0.6510

0.5516

0.5965

4.0107

0.6800

0.6200

0.5432

0.6269

4.0545

0.7000

0.5200

0.5080

0.6109

4.0629

0.6050

0.7100

16

invertebrate (2)

0.0071

0.0424

0.0117

0.0598

rodent (1)

primate (5)

xef f

Sm

xef f

Sm

S

x

B

S

x

B

xef f

Sm

S

0.0059

0.0030

0.0005

0.0568

0.0593

0.0223

0.0554

0.0391

0.0109

0.0045

0.0001

0.0794

0.1019

0.0419

0.0939

0.0097

0.5438

0.6709

4.1135

0.7200

0.5100

0.5044

0.5930

3.9761

0.7160

0.5820

0.5334

0.5902

4.0123

17

(a)

0.1

)
k
(
P

0.01

0.001

1

10
k

100

(b)

0.1

)
k
(
P

0.01

0.001

1

10
k

100

0.1

)
k
(
P

0.01

sequence
MP

(a)

10
k

0.001

1

100

0.1

)
k
(
P

0.01

sequence
MP

(b)

10
k

0.001

1

100

0.1

)
k
(
P

0.01

sequence
MP

(c)

10
k

0.001

1

100

0.1

0.01

)
k
(
P

0.001

0.0001

1

sequence
MP

10
k

100

)
k
(
D

-0.5

0.5

1

0

-1

-1.5

-2

0

10

20

30

40

50

60

70

k

0.1

)
k
(
P

0.01

original
shifted 1
shifted 2

0.001

1

10
k

100

