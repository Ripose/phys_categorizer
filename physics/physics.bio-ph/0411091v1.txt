4
0
0
2
 
v
o
N
 
9
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
1
9
0
1
1
4
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Spatial snowdrift game with myopi agents

Marko Sysi-Aho

, Jari Saramäki

, János Kertész

1

1
1, 2, and Kimmo Kaski

1

1

2

Laboratory of Computational Engineering

Helsinki University of Tehnology, Espoo, Finland

Department of Theoretial Physis

Budapest University of Tehnology and Eonomis, Budapest, Hungary

We have studied a spatially extended snowdrift game, in whih the players are loated on the sites

of two-dimensional square latties and repeatedly have to hoose one of the two strategies, either

ooperation (C) or defetion (D). A player interats with its nearest neighbors only, and aims at

playing a strategy whih maximizes its instant pay-o(cid:27), assuming that the neighboring agents retain

their strategies. If a player is not ontent with its urrent strategy, it will hange it to the opposite

one with probability p next round. Here we show through simulations and analytial approah that

these rules result in ooperation levels, whih di(cid:27)er to large extent from those obtained using the

repliator dynamis.

I.

INTRODUCTION

the population proportionally to the payo(cid:27)s. This meh-

anism an be viewed as depiting Darwinian evolution,

where the (cid:28)ttest have the largest hane of survival and

Understanding the emergene and persistene of o-

reprodution. Overall, the fators in(cid:29)uening the out-

operation is one of the entral problems in evolution-

omes of these spatially strutured games are (i) the rules

ary biology and soioeonomis [1, 2℄.

In investigating

determining the payo(cid:27)s (e.g. Ref. [21℄), (ii) the topology

this problem the standard framework utilized is evolu-

of the spatial struture (e.g. Ref. [17℄), and (iii) the rules

tionary game theory [2, 3, 4℄. Espeially two models,

determining the evolution of eah player's strategy (e.g.

the Prisoner's Dilemma [5, 6, 7℄ and its variation, the

Ref. [22, 23℄). We have studied the e(cid:27)et of hanging

snowdrift game [3, 8℄, have attrated most attention. In

the strategy evolution rules (iii) in the two-dimensional

both games, the players an either ooperate for om-

snowdrift game similar to that disussed in Ref. [12℄. In

mon good, or defet and exploit other players in attempt

our version, the rules have been de(cid:28)ned in suh a way

to gain bene(cid:28)ts individually. In the Prisoner's Dilemma,

that hanges in the players' strategies represent player

the preondition is that it pays o(cid:27) to be non-ooperative.

deisions instead of di(cid:27)erent strategy genotypes in the

Beause of this, defetion is the only evolutionarily sta-

next evolutionary generation of players. Thus, the time

ble strategy (ESS) in populations whih are fully mixed,

sale of the population dynamis in our model an be

i.e. where eah player interats with any other player

viewed to be muh shorter than evolutionary time sales.

[9℄. However, several models whih are extensions of the

Instead of utilizing the evolution-inspired repliator dy-

Prisoner's Dilemma have proved to sustain ooperation.

namis, we have endowed the players with primitive (cid:16)in-

These models inlude those in whih the players are as-

telligene(cid:17) in the form of loal deision-making rules de-

sumed to have memory of the previous interations [10℄,

termining their strategies. We show with simulations and

or harateristis that allow ooperators and defetors to

analyti approah that these rules result in ooperation

distinguish eah other [11℄, or players are spatially dis-

levels whih di(cid:27)er largely from those obtained using the

tributed [12, 13, 14℄.

repliator dynamis.

A typial spatial game is suh where player-player

In this study we will onentrate on an adaptive snow-

interations only take plae within restrited neighbor-

drift game, with agents interating with their nearest

hoods on regular latties [14, 15, 16, 17℄ or on omplex

neighbor agents on a two-dimensional square lattie. In

networks [18℄. These games have been found to generate

what follows we (cid:28)rst desribe our spatial snowdrift model

highly omplex behavior and enable the persistene of

and then analyze its equilibrium states. Next we present

ooperation. Regarding the latter, the opposite was re-

our simulation results and (cid:28)nally draw some onlusions.

ently seen in the ase of the snowdrift game played on a

two-dimensional lattie [12℄, where the spatial struture

resulted in dereased ooperator densities ompared to

II. SPATIAL SNOWDRIFT MODEL

the fully mixed (cid:16)mean-(cid:28)eld(cid:17) ase. This result was sur-

prising, as intermediate levels of ooperation persist in

The snowdrift model[27℄ an be illustrated with a situ-

unstrutured snowdrift games, and the ommon belief

ation in whih two ars are aught in a blizzard and there

has been that spatial struture is usually bene(cid:28)ial for

is a snowdrift bloking their way. The ars are equipped

sustained levels of ooperation.

with shovels, and the drivers have two hoies: either

In these studies the viewpoint has largely been that

start shoveling the road open or remain in the ar.

If

of biologial evolution, as represented by the so-alled

the road is leared, both drivers gain the bene(cid:28)t b of get-

repliator dynamis [4, 19, 20℄, where the fration of play-

ting home. On the other hand, learing the road requires

ers who use high-payo(cid:27)-strategies grow (stohastially) in

some work, and ost c an be assigned to it (b > c > 0).

Table I: Snowdrift game. Player 1 hooses an ation from

the rows and player 2 from the olumns. By onvention, the

payo(cid:27) to the row player is the (cid:28)rst payo(cid:27) given, followed by

the payo(cid:27) of the olumn player.

D

C

D P, P T, S

C S, T R, R

neighborhood in whih ase eah agent has n = 4 neigh-

bors, in N,E,S and W ompass diretions [26℄. We require

that an agent plays simultaneously with all its n neigh-
bors, and de(cid:28)ne the payo(cid:27)s for this (n+ 1)− player game
suh that an agent i who interats with ni
c + ni
and ni

d = n, gains a bene(cid:28)t of

d defetors, ni

c ooperators

ui(si = 0) = ni
ui(si = 1) = ni

cT + ni
cR + ni

dP
dS,

2

(2)

(3)

from defeting or ooperating, respetively.

For determining their strategies, the agents are en-

dowed with primitive deision-making apabilities. The

If both drivers are ooperative and willing to shovel, this

agents retain no memory of the past, and are not able to

workload is shared between them, and both of them gain

total bene(cid:28)t of R = c − b/2. If both hoose to defet,

i.e. remain in their ars, neither one gets home and thus

both obtain zero bene(cid:28)t P = 0. If only one of the drivers

shovels, both get home, but the defetor avoids the ost

and gains bene(cid:28)t T = b, whereas the ooperator's bene(cid:28)t
is redued by the workload, i.e. S = b − c.

The above desribed situation an be presented with

predit how the strategies of the neighboring agents will

hange. Every agent simply assumes that the strategies

of other agents within its neighborhood remain (cid:28)xed, and

hooses an ation that maximizes its own payo(cid:27). In this

sense the agents are myopi. The payo(cid:27) is maximized,

if an agent (a) defets when ui(0) > ui(1), and (b) o-
If () ui(0) = ui(1) the
operates when ui(1) > ui(0).

situation is indi(cid:27)erent. Using Eqs. (2) and (3) we an

the bi-matrix [24℄ (Table I), where

onnet the preferable hoie of an agent and the payo(cid:27)s

T > R > S > P.

of the game. Let us denote

(1)

1
r

= 1 +

S − P
T − R

.

In ase of the so alled one-shot game, eah player has

(4)

two available strategies, namely defet (D) or ooperate

(C). The players hoose their strategies simultaneously,

Then, if

and their individual payo(cid:27)s are given by the appropriate

ell of the bi-matrix. By onvention, the payo(cid:27) to the

so-alled row player is the (cid:28)rst payo(cid:27) given, followed by

the payo(cid:27) of the olumn player. Thus, if for example

player 1 hooses D and player 2 hooses C, then player 1

reeives the payo(cid:27) T and player 2 the payo(cid:27) S.

The best ation depends on the ation of the o-player

suh that defet if the other player ooperates and oop-

ni
c
n
ni
c
n
ni
c
n

> 1 − r defeting is pro(cid:28)table, or if

(5)

< 1 − r ooperating is pro(cid:28)table, or if

(6)

= 1 − r hoies are indi(cid:27)erent.

(7)

erate if the other defets. A simple analysis shows that

Thus, for eah individual agent, the ratio r determines

the game does not have stable evolutionary strategy [19℄,

a following deision-boundary

snowdrift game, we set the players on a regular two-

de(cid:28)ne the following rules for the agents:

if the agents use only pure strategies, i.e., they an hoose

either to ooperate or to defet with probability one, but

they are not allowed to use a strategy whih mixes either

of these ations with some probability q ∈ (0, 1). This

leads to stable existene of ooperators and defetors in

well-mixed populations [12℄.

In order to study the e(cid:27)et of spatial struture on the

dimensional square lattie onsisting of m ells. We

adopt the notation of Ref. ([25℄) and identify eah ell by

an index i = 1, . . . , m whih also refers to its spatial posi-

tion. Eah ell, representing a player, is haraterized by

its strategy si , whih an be either to ooperate (si = 1)
or to defet (si = 0). The spatio-temporal distribution of
the players is then desribed by S = (s1, . . . , sm) whih is
an element of a 2m

dimensional hyperube. Then every

player (cid:21) heneforth alled an agent (cid:21) interats with their

n nearest neighbors. We use either the Moore neigh-
borhood in whih ase eah agent has n = 8 neighbors,

θ = n(1 − r),

(8)

whih depends on the neighborhood size n and the (cid:16)temp-
tation(cid:17) parameter r. Beause r is determined only by the
di(cid:27)erenes T − R and S − P , we an (cid:28)x two of the payo(cid:27)
values, say R = 1 and P = 0. Based on the above, we

1. If an agent i plays at time t a strategy si(t) ∈ {0, 1}
for whih ui(si) ≥ ui(1 − si), then at time t + 1 the
agent plays si(t + 1) = si(t).

2. If an agent i plays at time t a strategy si(t) ∈ {0, 1}
for whih ui(si) < ui(1 − si), then at time t + 1 the
agent plays si(t + 1) = 1 − si(t) with probability p,
and si(t + 1) = si(t) with probability 1 − p.

in N,NE,E,SE,S,SW,W and NW, or the von Neumann

determined by the urrent strategies of the other agents

Hene, the strategy evolution of an individual agent is

Without detailed knowledge of loal equilibrium on-

the lines do not pass through the shaded area.

within its neighborhood, with the parameter p ating as

a (cid:16)regulator(cid:17) whih moderates the rate of hanges.

III. EQUILIBRIUM STATES

A spatial game is in stable state or equilibrium if

retaining the urrent strategy is bene(cid:28)ial for all the

agents [4℄. There an be numerous equilibrium on(cid:28)g-

urations, depending on the temptation parameter r, ge-
ometry and size of the n-neighborhood, and the size and

boundary onditions of the lattie upon whih the game

is played. An aggregate quantity of partiular interest

is the fration of ooperators Fc in the whole population
(or, equivalently, that of the defetors Fd ). Below, we
derive limits for Fc , (cid:28)rst in a (cid:16)mean-(cid:28)eld(cid:17) piture based

ooperator densities within neighborhoods and then by

investigating loal neighborhood on(cid:28)gurations.

A. Mean-(cid:28)eld limits for ooperator density

(cid:28)gurations we an already derive some limits for the fra-

tion of ooperators in equilibrium. Let us onsider a

square lattie with m = L × L ells with periodi bound-
ary onditions, where L is the linear size of the lattie,
and assume that k ells are oupied by ooperators. We
denote by aj the number of those agents who have j
ooperators eah in their n-neighborhood, exluding the

agents themselves, and denote the loal density of oop-

erators in suh neighborhoods by fc = j/n. Hene, the
total amount of ooperators k an be written in terms of

3

<f   >
c|d

1

1−r

k<f   > + (m−k)<f   >

c|d

c|c

0

1−r

1

<f   >
c|c

Figure 1: In equilibrium the average density of ooperators

in the nearest neighborhood of defetors must be 1 − r ≤
(cid:10)fc|d(cid:11) ≤ 1 and in the nearest neighborhood of ooperators
0 ≤ (cid:10)fc|c(cid:11) ≤ 1−r (shaded area). If the total number of players
in the lattie is m, the lines k (cid:10)fc|c(cid:11)+(m−k) (cid:10)fc|d(cid:11) = k depit
the identity of k ooperators in the lattie. Equilibrium is not
possible, if the fration of ooperators Fc = k/m is suh that

density. Similarly, the density of ooperators around eah

defetor fc|d an be at most 1 and is at least (1 − r), and
thus the average density 1 − r ≤ (cid:10)fc|d(cid:11) ≤ 1. Using these

relations together with Eq. (10) we obtain the following

limits for the density of ooperators Fc = k/m in the

whole agent population (see also Fig. 1):

1 − r
2 − r

≤ Fc ≤

1
r + 1

.

the densities as follows

(11)

k =

ajfc =

n

X
j=0

n

X
j=0

aj

j
n

.

(9)

B. Loal equilibrium on(cid:28)gurations

From Eqs. (5)-(7) we an infer that a ooperator will

In the above derivation we ignore how the strategies

retain its urrent strategy, if it has at most c ooperators
in its n-neighborhood, where c is the integer part of θ =
n(1 − r). Similarly, a defetor will remain a defetor
if it has more than c ooperators in its neighborhood.
Thus, in equilibrium, all agents having j ≤ c ooperators

an atually be distributed in the lattie. Hene, it is of

interest to examine possible loal equilibrium on(cid:28)gura-

tions of the player strategies. Again, Eqs. (5)-(7) tell us

how many ooperative neighbors eah defetor or oop-

erator an have in the equilibrium state. The number of

in their neighborhood are likewise ooperators, and thus

c

j=0 aj = k . We denote by (cid:10)fc|c(cid:11) = 1

c
j=0 aj
k P

P

j
n the

ooperators around eah agent depends on the value of

the temptation parameter r, and for a given value of r the

average density of ooperators as the nearest neighbors of

lattie has to be (cid:28)lled suh that these onditions hold for

ooperators. Similarly, (cid:10)fc|d(cid:11) denotes the average density
(cid:10)fc|d(cid:11) = 1

j
n . Then we an write Eq. (9) as

n
j=c+1 aj

m−k P

of ooperators as the nearest neighbors of defetors, i.e.

the neighborhood of eah agent. In a lattie with periodi

boundary onditions, the lattie size m = LX × LY and
the neighborhood size n obviously have an e(cid:27)et on the

elementary on(cid:28)gurations. Hene, we restrit ourselves

to in(cid:28)nite-sized latties, (cid:28)lled by repeating elementary

k = k (cid:10)fc|c(cid:11) + (m − k) (cid:10)fc|d(cid:11) .

The density fc|c of ooperators around eah ooperator
is bounded: fc|c ≥ 0, fc|c ≤ c/n, and as c ≤ θ = n(1 − r),
the relation 0 ≤ (cid:10)fc|c(cid:11) ≤ 1 − r holds for the average

(10)

on(cid:28)guration bloks, and look for the resulting limits on

the ooperator density Fc . Note that these onlusions

also hold for (cid:28)nite latties with periodi boundary on-

ditions, if LX and LY are integer multiples of X and Y ,
respetively, where X × Y is the elementary blok size.

Table II: Limits for the equilibrium fration of ooperators

based on repeating elementary on(cid:28)guration bloks. When

rl < r < ru , the number of ooperators in eah defetor's
neighborhood Nc|d must be at least 9 − i and the number of
ooperators in eah ooperator's neighborhood Nc|c at most
8 − i. Considering possible repeating on(cid:28)guration bloks
whih ful(cid:28)ll these onditions, we obtain lower limits Fc,L and
upper limits Fc,U for the density of ooperators.

i rl

ru Nc|d ≥ Nc|c ≤ Fc,L Fc,U

blok.

1 0
1/8
2 1/8 2/8
3 2/8 3/8
4 3/8 4/8
5 4/8 5/8
6 5/8 6/8
7 6/8 7/8
8 7/8 8/8

8

7

7

6

6

5

5

4

4

3

3

2

2

1

1

0

3/4 8/9
2/3 4/5
1/2 2/3
1/2 2/3
4/9 1/2
1/3 1/2
2/9 1/3
1/9 1/4

X

X

X

1

X

X

X

X
X

X

2

X

X

3

X

4

X
X

X
X
X

X
X

X

X
X

5

X
X

6

X

X
X
X

X
X
X X

X
X
X X

7

XX
X
X
X
X X X

XX
X

8

4

i.e. they should have at most c = 7 ooperators in their

Moore neighborhood. The smallest repeated elementary

blok ful(cid:28)lling both onditions is a 2 × 2-square with one

defetor (cid:21) when the lattie is (cid:28)lled with these bloks, the

ooperator density equals Fc = 3/4 (see Fig. (2), ase 1,

left blok). On the other hand, both requirements are

likewise ful(cid:28)lled with a repeated 3 × 3-square, where the

entral ell is a defetor and the rest are ooperators,

resulting in the ooperator density of Fc = 8/9. This

on(cid:28)guration is illustrated in Fig. (2), as ase 1, right

By ontinuing the analysis of elementary on(cid:28)guration

bloks in similar fashion for di(cid:27)erent values of r, we ob-

tain lower and upper limits for the fration of ooper-

ators, whih are listed in Table II. The orresponding

elementary on(cid:28)guration bloks are depited in Fig. (2).

The table is read so that when the value of the temp-

tation parameter is within the interval rl < r < ru , the

number of ooperators in eah defetor's neighborhood

Nc|d must be at least 9 − i and the number of ooper-
ators in eah ooperator's neighborhood Nc|c an be at
most 8 − i. Here rl = (i − 1)/8, ru = i/8 and i = 1, . . . , 8

These onditions are those of Eqs. (5)-(7) and they are

ful(cid:28)lled by the on(cid:28)guration bloks depited in Fig. (2),

for whih the minimum and maximum densities of oop-

erators are Fc,L and Fc,U .

IV. SIMULATION RESULTS

We have studied the above desribed spatial snow-

drift model with disrete time-step simulations on a

m = 100 × 100-lattie with periodi boundary ondi-

tions. We have spei(cid:28)ally analyzed the behavior of the

ooperator density Fc , and equilibrium lattie on(cid:28)gura-

tions.

In the simulations, the lattie is initialized ran-

domly so that eah ell ontains a ooperator or defetor

Figure 2: Examples of elementary on(cid:28)guration bloks whih

with equal probability. However, biasing the initial den-

an be repeated without overlap to (cid:28)ll an in(cid:28)nite lattie, for

various values of r . The numbering refers to i in Table II.

A blak ell denotes a defetor while an empty ell denotes a

sities toward ooperators or defetors was found to have

no onsiderable e(cid:27)et on the outome of the game. We

ooperator. For a partiular number the lower limit of density

is obtained by (cid:28)lling the lattie with the bloks on the left,

have simulated the game using both the Moore and the

von Neumann neighborhoods with n = 8 and n = 4

and the upper by using the bloks on the right.

nearest neighbors, respetively.

In the simulations we

update strategies of the agents asynhronously [26℄ with

the random sequential update sheme, so that during one

simulation round, every agent's strategies are updated in

Here, we will restrit the analysis to the ase of the Moore

random order. In the following, the time sale is de(cid:28)ned

neighborhood with n = 8.

in terms of these simulation rounds.

As an example, onsider the loal on(cid:28)gurations when

First, we have studied the development of the ooper-

r = 0.1, and hene the deision boundary value θ =
n(1 − r) = 7.2. Thus, from Eqs. (5)-(7) one an infer that
in equilibrium all defetors should have more than 7.2

ooperators in their Moore neighborhoods. Beause the

number of ooperating neighbors an take only integer

values, this means that every one of the n = 8 neighbors

of a defetor should be a ooperator. On the other hand,

from Eqs. (5)-(7) we see that the density fc|c of ooper-
ators around eah ooperator should be less than 1 − r,

ator density Fc as a funtion of time. As expeted, the
probability p of disontent agents hanging their strate-

gies plays the role of de(cid:28)ning the onvergene time sale

only[28℄, as in the long run Fc onverges to a stable value
irrespetive of p. This is depited in Fig. 3, whih shows
Fc as funtion of time for several values of p and two
di(cid:27)erent values of the temptation r. In these runs, we
have used the Moore neighborhood, i.e. n = 8. In all the
studied ases, Fc turns out to onverge quite rapidly to

5

s
r
o
t
a
r
e
p
o
o
c
 
f
o
 
n
o
i
t
c
a
r
F

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0
0
10

p=1 

p=0.1 

p=0.01 

p=0.001 

p=1 

p=0.1 

p=0.01 

p=0.001 

c

>

 

F
<

 

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

1
10

2
10

Simulation round

3
10

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Temptation r

Figure 3: Dynamis of the fration of ooperators Fc . The
upper urves that onverge to Fc ∼ 0.7 are for r = 0.2, and
the lower urves that onverge to Fc ∼ 0.3 are for r = 0.8.

Figure 4: Average fration of ooperators hFci versus the
temptation r (squares), simulated on a 100 × 100 lattie with
p = 0.1 using the von Neumann neighborhood. The values
for hFci are averages over 500 simulation rounds, where the

In both ases the probability of being disontent is varied as

averaging was started after 500 initial rounds to guarantee

p = 1, 0.1, 0.01, 0.001 from left to right, and the lattie size is
m = 100x100.

onvergene. The dotted lines depit the upper and lower

limits for Fc of Eq. (11). The dashed diagonal line is 1 − r .

a onstant value, Fc ∼ 0.7 for r = 0.2 and Fc ∼ 0.3 for
r = 0.8.

It should be noted that Fc does not have to onverge
to exatly the same stable value for the same r; even if

ator dynamis [12℄, where the fration of ooperators

vanished at some ritial rc . Hene, we argue that no

onlusions on the e(cid:27)et of spatiality on the snowdrift

game an be drawn without taking into onsideration the

the game is onsidered to be in equilibrium, there an

strategy evolution mehanism; loal deision-making in a

be some variane in Fc , whih is also visible in Fig. 3.
However, the value of Fc was found to eventually remain

restrited neighborhood yields results whih are di(cid:27)erent

from those resulting from the evolutionary repliator dy-

stable during individual runs, i.e. no osillations were

namis.

deteted.

We have also studied the equilibrium lattie on(cid:28)gura-

Next, we have studied the average equilibrium fration

of ooperators hFci in the agent population as funtion
of the temptation parameter r. We let the simulations
run for 500 rounds (with p = 0.1), and averaged the fra-

tion of ooperators for the subsequent 500 rounds. In all

ases, the fration had already onverged before the aver-

tions for various values of r. Fig. (5) depits the entral
part of the 100 × 100-lattie after 1000 simulation rounds
using the Moore neighborhood and p = 0.1, with white

pixels orresponding to ooperators and blak pixels to

defetors. The values of r have been seleted so that the
equilibrium situation orresponds to eah plateau of hFci

aging rounds. Fig. (4) shows the results for the von Neu-

illustrated in the entral panel.

mann neighborhood (n = 4), illustrated as the squares.

The observed on(cid:28)gurations are rather polymorphi,

The dotted lines indiate the upper and lower limits of

and repeating elementary patterns like those in Fig. (2)

Eq. (11), and the dashed diagonal line is Fc = 1 − r,

are not seen. This re(cid:29)ets the fat that the loal equi-

orresponding to the fration of ooperators in the fully

librium onditions an be satis(cid:28)ed by various on(cid:28)gu-

mixed ase [4, 12, 19℄. The fration of ooperators hFci

rations; the random initial on(cid:28)guration and the asyn-

is seen to follow a stepped urve, with steps orrespond-

hronous update then lead to irregular-looking equilib-

ing to r = i/n, where i = 0, . . . , n. This is a natural

onsequene of Eqs. (5)-(7), where the deision bound-

ary θ = n(1 − r) an take only disrete values. A similar
piture is given for the Moore neighborhood (n = 8) in

the middle panel of Fig. (5). Furthermore, in the middle

panel of Fig. (5) the values of Fc fall between the limits
given in Table II for all r as shown with solid lines.

In both ases (i.e. with Moore and von Neumann

rium patterns, whih vary between simulation runs. The

patterns seem to be most irregular when r is around 0.5;

this is beause then the equilibrium numbers of ooper-

ators and defetors are lose to eah other, and the ways

to assign strategies within loal neighborhoods are most

8
numerous. To be more exat, there are (cid:0)
i(cid:1) ways to dis-
tribute i ooperators in the 8-neighborhood, and if e.g.
3/8 < r < 4/8, i is at least 4 and at most 5, maximizing

neighborhoods) ooperation is seen to persist during the

the value of the binomial oe(cid:30)ient. Hene, the ways of

whole range r = [0, 1]. This result di(cid:27)ers largely from
the Fc(r)-urves of the spatial snowdrift game with repli-

(cid:28)lling the lattie with these neighborhoods in suh a way

that the equilibrium onditions are satis(cid:28)ed everywhere

6

are most numerous as well.

ties di(cid:27)er largely from those resulting from applying the

repliator dynamis [12℄. With our strategy evolution

rules, ooperation persists through the whole temptation

V. SUMMARY AND CONCLUSIONS

parameter range. This illustrates that one annot draw

general onlusions on the e(cid:27)et of spatiality on the snow-

We have presented a variant of the two-dimensional

drift game without taking the strategy evolution meha-

snowdrift game, where the strategy evolution is deter-

nisms into onsideration (cid:21) this should, in priniple, apply

mined by agent deisions based on the strategies of other

for other spatial games as well. Care should espeially be

players within its loal neighborhood. We have ana-

taken when interpreting the results of investigations on

lyzed the lower and upper bounds for equilibrium o-

suh games: the utilized strategy evolution mehanism

operator densities with a mean-(cid:28)eld approah as well as

should re(cid:29)et the system under study. We argue that es-

onsidering possible lattie-(cid:28)lling elementary on(cid:28)gura-

peially when modeling soial or eonomi systems, there

tion bloks. We have also shown with simulations that

is no a priori reason to assume that generalized onlu-

this game onverges to equilibrium on(cid:28)gurations with

sions an be drawn based on results using the evolution

onstant ooperator density depending on the payo(cid:27) pa-

inspired repliator dynamis approah, where high-payo(cid:27)

rameters, and that these densities fall within the derived

strategies get opied and (cid:16)breed(cid:17) in proportion to their

limits. Furthermore, the strategy on(cid:28)gurations in the

(cid:28)tness. As we have shown here, loal deision-making

equilibrium state display interesting patterns, espeially

with limited information (neighbor strategies are known

for intermediate temptation parameter values.

payo(cid:27)s are not) an result in di(cid:27)erent outome.

Most interestingly, the equilibrium ooperator densi-

[1℄ J. Maynard Smith and E. Szathmáry, The Major Tran-

[16℄ G. Szabó and C. Toke, Phys. Rev. E 58 (1998) 69-73.

sitions in Evolution (W.H. Freeman, Oxford, UK, 1995).

[17℄ G. Szabó and C. Toke, Phys. Rev. E 62 (2000) 1095-1103.

[2℄ J. von Neumann and O. Morgenstern, Theory of Games

[18℄ M. G. Zimmermann, V. M. Eguíluz and M. San Miguel,

and Eonomi Behaviour (Prineton University Press,

Phys. Rev. E 69 (2004) 065102.

1944).

[19℄ J. Hofbauer and K. Sigmund, Evolutionary games and

[3℄ J. Maynard Smith and G. Prie, Nature 246 (1973) 15-

population dynamis, (Cambridge University Press, Cam-

18.

bridge, UK, 1998).

[4℄ D. Fudenberg and D. K. Levine, The Theory of Learning

[20℄ M. A. Nowak and K. Sigmund, Siene 303 (2004) 793-

in Games (The MIT Press, 1998).

799.

[5℄ A. Rapoport and A. Chammah, Prisoner's Dilemma

[21℄ H. Fort, Phys. Rev. E (2003) 68 026118.

(University of Mihigan Press, Ann Arbor, 1965).

[22℄ D. A. Meyer, Phys.Rev.Lett. 82 (1999) 1052-1055.

[6℄ R. Axelrod and W.D. Hamilton, Siene 211, (1981)

[23℄ A. Traulsen, T. Röhl and H.G.Shuster, Phys.Rev.Lett.

1390-1396.

93 (2004) 028701.

[7℄ R. Axelrod and D. Dion, Siene 242, (1988) 1385-1390.

[24℄ R. Gibbons, Game Theory for Applied Eonomists,

[8℄ R. Sugden, The Eonomis of Rights, Co-operation and

(Prineton University Press, 1992).

Welfare (Blakwell, Oxford, UK, 1986).

[25℄ F. Shweitzer, L. Behera and H. Mühlenbein, Advanes

[9℄ J.M. Smith, Evolution and the theory of games (Cam-

in Complex Systems 5 (2002) 269-299.

bridge University Press, Cambridge, UK, 1982).

[26℄ S. Adahi, F. Peper and J. Lee, Journal of Statistial

[10℄ R. Axelrod, The evolution of ooperation, (Basi Books,

Physis 114 (2004) 261-289.

New Yourk, 1984).

[27℄ Commonly known as hawk-dove or hiken game also.

[11℄ J. N. Epstein, Complexity 4(2), (1998) 36-48.

[12℄ C. Hauert and M. Doebell, Nature 428, (2004) 643-646.

[28℄ The role of p would be more important if synhronous
update rules were used. In that ase p = 1 orresponds

[13℄ K. Lindgren, Evolutionary Dynamis in Game-Theoreti

to a situation where eah disontent agent simultaneously

Models in The Eonomy as an Evolving Complex System

hanges its strategy to the opposite. This, then, ould

II (Addison-Wesley, 1997) 337-367.

result in a frustrated situation with osillating ooperator

[14℄ M. A. Nowak and R. May, Nature 359 (1992) 826-829.

density. However, small enough values of p should damp

[15℄ M. Doebeli and N. Knowlton, Pro. Natl Aad. Si USA

these osillations, resulting in stati equilibrium.

95 (1998) 8676-8680.

7

r = 0.100

r = 0.975

r = 0.850

1

0.8

>

 

0.6

c

F
<

 

0.4

0.2

r = 0.225

0

0

0.5
Temptation r

1

r = 0.725

r = 0.350

r = 0.475

r = 0.600

Figure 5: Example equilibrium on(cid:28)gurations of defetors and ooperators on a m = 100 × 100 lattie for various values of r
when the Moore neighborhood is used. The on(cid:28)gurations were reorded after T = 1000 simulation rounds. Only the middle
part of the lattie is shown for the sake of larity. The middle panel depits the average fration of ooperators hFci in the
whole population as a funtion of the temptation r (squares), together with the upper and lower limits of Eq. (11) (dotted
lines) and the limits of Table II (solid lines). The values of hFci are averages over the last 500 simulation rounds and the dashed
diagonal line is Fc = 1 − r , orresponding to the fration of ooperators in the fully mixed ase [4, 12, 19℄.

