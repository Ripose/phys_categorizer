6
9
9
1
 
v
o
N
 
9
1
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
4
1
0
1
1
6
9
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Stochastic resonance in a model neuron with
reset

H. E. Plesser 1,2 and S. Tanaka 3

Laboratory for Neural Modeling, Frontier Research Program, RIKEN,
2-1 Hirosawa, Wako-shi, Saitama 351-01, Japan

Abstract

The response of a noisy integrate-and-ﬁre neuron with reset to periodic input is
investigated. We numerically obtain the ﬁrst-passage-time density of the pertain-
ing Ornstein–Uhlenbeck process and show how the power spectral density of the
resulting spike train can be determined via Fourier transform. The neuron’s output
clearly exhibits stochastic resonance.

integrate-and-ﬁre neuron, Ornstein–Uhlenbeck process, stochastic

Key words:
resonance, renewal process
PACS: 87.10.+e, 05.40.+j

1 Introduction

Neurons are inherently stochastic information processing devices, whence the
study of the inﬂuence of noise on neuronal signal transmission and computa-
tion is of great interest. Since the ﬁrst evidence for the enhancement of signals
by noise was presented about 15 years ago [1], the phenomenon of stochastic
resonance has been demonstrated in a number of physical [2,3] and biological
systems, especially in sensory neurons [4–6]. In the wake of these experiments,
the theory of stochastic resonance for dynamic systems has been well devel-
oped [7,8], and was recently extended to aperiodic signals [9].

As neurons in higher centers of the brain need to maintain a high signal-to-
noise ratio as well as peripheral ones, it is plausible to presume that stochastic

1 Corresponding author
2 E-mail: plesser@prairie.riken.go.jp
3 E-mail: shigeru@postman.riken.go.jp

Preprint submitted to Elsevier Preprint

30 October 1996

resonance is a general principle of biological information processing. Indeed,
models describing neurons as bistable elements have been discussed in de-
tail [10,11]. For quantitative comparison with neurophysiological data, though,
model neurons closer to biological reality need to be investigated. To this end,
we study in this letter the response to a sinusoidal stimulus with superimposed
white noise of a widely used model neuron, the leaky integrate-and-ﬁre neuron
which is reset upon ﬁring [12]. In this model, the development over time of the
membrane potential is given by the solution of the Fokker–Planck equation
describing the overdamped limit of the Ornstein–Uhlenbeck process with an
absorbing boundary.

Unfortunately, no analytic solution to this boundary value problem is known [13],
while existing approximate solutions are limited to particular parameter ranges;
in particular, they require suﬃciently strong input noise [14]. Therefore, we
numerically solve for the ﬁrst-passage-time density (FPTD), i.e. the mathe-
matical equivalent of the inter-spike-interval distribution (ISI), using a com-
putationally eﬃcient integral equation approach. From the FPTD, we then
calculate the power spectral density (PSD) of the spike train generated by the
model neuron via fast Fourier transform, employing results from the theory
of point processes. Finally, we determine the signal-to-noise ratio (SNR) of
the neuron’s output, which clearly exhibits stochastic resonance, i.e. SNR is
maximal for a ﬁnite strength of input noise.

Note the crucial diﬀerence between the model studied here and the threshold
detector model that has been studied by several authors in recent years [15–
17]. The former is reset after each ﬁring, whence individual threshold crossings
are uncorrelated and the entire spike train constitutes a renewal process. The
latter, to which we shall refer as continuous-mode model, does not include a
reset mechanism, but assigns one spike to each threshold crossing in positive
direction. Thus, individual crossings are correlated and the membrane voltage
is governed by the same Fokker–Planck equation as our model, but with natu-
, permitting analytical treatment. Indeed, Jung [18] has
ral boundaries at
given a theory of stochastic resonance in continuous-mode threshold detectors
based on the periodic asymptotic solution of this Fokker–Planck problem.

±∞

2 The model

The membrane voltage x(t) of the model neuron is governed by the Langevin
equation of the overdamped Ornstein–Uhlenbeck process [12,19,20]

τm ˙x(t) =

x(t) + µ + q cos(ωt + ϕ) + ξ(t) ,

(1)

−

2

where we have set the resting potential to x = 0. The membrane time-constant
τm and the drift term µ are positive constants, while q, ω and ϕ are arbitrary
real constants, and ξ(t) is Gaussian white noise with zero mean and autocor-
t′). The initial condition is x(0) = 0, and the
relation
neuron ﬁres upon reaching the threshold voltage x(t) = xth: both x and the
phase of the input stimulus ωt + ϕ are reset to their values at t = 0.

ξ(t)ξ(t′)

= 2Dδ(t

−

i

h

To normalize variable values, we scale time as ¯t = t/τm and voltage as ¯x(¯t) =
x(t)/xth, so that time constant and threshold become 1, whence ¯µ = µ/xth,
¯q = q/xth, ¯ω = τmω, ¯ϕ = ϕ and ¯D = Dτm/x2
th. Thus we obtain the the
dimensionless equation

˙x(t) =

x(t) + µ + q cos(ωt + ϕ) + ξ(t) ,

(2)

−

where we have dropped the bars immediately for compactness of notation.

As mentioned above, each approach to the threshold is independent of the
past, because of the reset upon ﬁring. Therefore, assuming a spike train of
inﬁnite duration, the ﬁring process is a stationary renewal process [21]. We
will solve the FPT problem in the next section before examining the spike
train as a whole in sections 4 and 5.

3 First-Passage-Time Density

In this section, we present an eﬃcient numerical method for the computation
of the FPTD

ρ(t) dt = Pr

x(t) = xth = 1 in [t, t + dt) if x(t = 0) = 0

,

(3)

{

}

the theoretical counterpart of the ISI distribution.

The Fokker–Planck equation corresponding to the Langevin equation (2) is [22]

∂
∂t P

|

(x, t

x0, t0) =

(

x + µ + q cos(ωt + ϕ))

(x, t

x0, t0)

P

|

(4)

∂
∂x

−

+ D

−
∂2
∂x2 P

(x, t

x0, t0) ,

|

|

P

(x, t

x0, t0) is the probability density that the voltage is x at time t if
where
it was x0 at time t0 < t. The model is thus speciﬁed by the initial and bound-
0, 0) = 0,
Pr (1, t
Pr (
ary conditions
−∞
|
, 1]. No analytic solution is
where the index r indicates restriction to x
known for this boundary value problem and an approximation based on the
method of images is valid for a limited range of parameters only [14].

0, 0) = 0 and

0, 0) = δ(x),

Pr (x, t

−∞

, t

∈

|
(

|

3

(5)

(6)

(7)

(8)

Following Schr¨odinger [23], we thus construct an integral equation equivalent
x0, t0)
to the above boundary value problem, utilizing the solution
of (4) for the unrestricted Ornstein–Uhlenbeck process on the entire real axis,
, t
i.e. with boundary conditions

Pf (x, t
x0, t0) = 0. The solution is [8]

|

Pf (

±∞

|

Pf (x, t

|

x0, t0) =

1

2πσ2(t)

exp

(x

)2

x(t)
− h
2σ2(t)

i

#

,

"−

q
where the mean and variance of x(t) are (writing η = cot-1 ω)

x(t)

= µ +

h

i

sin(ωt + ϕ + η)

q
√1 + ω2
x0 −
e−2(t−t0)

(cid:20)

+ e−(t−t0)

σ2(t) = D

1
(cid:16)

−

q
√1 + ω2

sin(ωt0 + ϕ + η)

,

(cid:21)

Then, the FPTD ρ(t) is given by the Volterra integral equation [22]

Pf (1, t

|

0, 0) =

ds

Pf (1, t

|

1, s) ρ(s) .

1, s) of the above equation
Pf (1, t
Due to the sine terms in (6), the kernel
cannot be rewritten as a function of t
s alone and a solution by Laplace
transform is not possible. A description of the FPTD via its moments cannot
be obtained either, since such methods are based on the Laplace transform of
the kernel [24,25].

−

|

We thus solve for ρ(t) using standard computational techniques. Since the
kernel has an integrable square-root singularity at t = s, we rewrite (8) as

0, 0) = r(t)ρ(t) +

1, s) [ρ(s)

ρ(t)] ,

(9)

t

0
Z

ds

Pf (1, t

|

−

Pf (1, t

|

t

with r(t) =
1, s) ds. This integral can be evaluated numerically
0 Pf (1, t
and, discretizing time as tj = jh with stepsize h > 0, we obtain the following
algorithm for calculating the FPTD [26]

R

|

ρ0 = 0 ,

ρm =

, m = 1, 2, . . .

(10)

m−1

j=1 Km,jρj −

h
h
2 Km,0 + h
P

m−1

gm
j=1 Km,j −
Pf (1, mh

|

rm

where Km,j =
follows from the initial conditions.

Pf (1, mh

|

P
1, jh), gm =

0, 0), rm = r(mh). ρ0 = ρ(0)

The algorithm deﬁned by (10) has proven to be stable and reliable. Over a
wide range of parameter values, the calculated FPTDs ρm are strictly non-
negative (if numerical noise of the order of machine accuracy is excluded)

−
.

µ

(cid:17)

t

0
Z

4

and the norm of the distributions approaches 1 from below as the range of
calculation is extended towards larger t.

We found a diﬀerent integral-equation approach [27,28] to be slightly less
stable for some interesting parameter values. In regions where both algorithms
are stable, results agree well.

4 Power Spectral Density

To calculate the power spectral density (PSD) of the neuron’s output, let us
ﬁrst consider a train of M δ-spikes with inter-spike-intervals τj distributed
according to the FPTD ρ(τj):

fM (t) =

δ(t

tm) ,

tm =

τj ,

t1 = 0 .

(11)

M

Xm=1

−

m

Xj=1

Neglecting the exact shape of the spikes amounts merely to dropping a form
factor from the spectrum, while all statistically relevant information is con-
tained in the ﬁring times tm (see also [18]).

→ ∞

For M
, this process is a stationary renewal process, the spectra of which
have been extensively discussed in mathematical literature [29,21], where they
are known as Bartlett spectra [30]. Applications to neuronal systems have been
rare to our knowledge [31].

The one-sided power spectral density of the spike train fM (t) is given by

SM (Ω) = ˜fM (

Ω) ˜fM (

Ω) + ˜fM (Ω) ˜fM (Ω) = 2 ˜fM (Ω) ˜fM (Ω)

(12)

−

−

where the bar indicates complex conjugation and

˜fM (Ω) =

tM

1
√2πtM Z

0

dt fM (t) e−iΩt

is the Fourier transform. Inserting (11) and (13) into (12) yields [21]

SM (Ω) =

e−iΩ(tm−tk)

M

1
πtM
M
1
tM (cid:26)
π

Xm,k=1
1 +

=

∞

0
Z

dt hM (t) e−iΩt +

dt hM (t) eiΩt

(cid:27)

∞

0
Z

(13)

(14)

5

where we have deﬁned

hM (t) =

δ(tj+k −

tj −

t) .

1
M

M −1

Xj,k=1

Integrating hM (t) over non-overlapping intervals would give the autocorrela-
tion histogram of the neuron ﬁring times. In the limit of an inﬁnite spike train,
we obtain

hM (t)

h(t)

and tM /M

τ

(M

) ,

→

→ h
where h(t) is the renewal density and
the mean ﬁrst-passage-time. Note
h
that the renewal density h(t) is not a probability density, but h(t) dt is the
probability for a spike to occur in [t, t + dt).

→ ∞

τ

i

i

(16)

From the theory of renewal processes [21] we have for Ω

= 0

(15)

(17)

∞

0
Z

dt h(t) eiΩt =

˜ρ(Ω)

1

˜ρ(Ω)

−

.

Here, ˜ρ(Ω) is the Fourier transform of the FPTD ρ(τ ). Performing the limit
in (14) and inserting (17), we obtain the one-sided PSD of the inﬁnite spike
train

S(Ω) =

1
τ

h

π

(

i

1 +

˜ρ(Ω)

1

˜ρ(Ω)

−

˜ρ(

Ω)

+

1

−
˜ρ(

−

−

Ω) )

(Ω > 0).

(18)

Using this result, we can compute the PSD directly from the FPTD by means
of a discrete Fourier transform.

λτ ),
For white shot noise, i.e. the Poisson process with FPTD ρ(τ ) = λ exp(
the terms in ˜ρ(Ω) in (18) cancel and a white spectrum SP = 1/π
results.
Any deviation of S(Ω) from SP indicates the presence of a signal. For the
Ornstein–Uhlenbeck process studied here, the spectra approach SP quickly
for large Ω (Fig. 1). We will therefore employ SP as the reference noise level
in section 5.

−

τ

i

h

5 Stochastic resonance

Having set the mathematical stage, we may now explore the response of our
model neuron to sinusoidal input. A single parameter characterizing the input
signal is the distance-from-threshold of the deterministic trajectory

x(t)

ǫ = 1

sup
t≥0 h

−

x(t)

= 1

µ +

i

− (cid:18)

q
√1 + ω2

.

(cid:19)

h

i

(19)

6

6
D = 2.78e−06

D = 4.50e−03

D = 2.50e−02

0.6

)

Ω
(
S

1.2

1

0.8

0.4

0.2

0

0

2

4
Ω

6

8

Fig. 1. Power spectral density for µ = 0.97, q = 0.03, ω = 0.1π, ǫ = 0.0014 for three
diﬀerent noise levels, corresponding to Dmax, medium and high noise. The vertical
dotted lines mark the input frequency ω and its ﬁrst harmonic.

In deﬁning the signal-to-noise ratio, the following diﬃculty arises. The reset
mechanism introduces a second timescale into the system besides the one given
by the input frequency. Therefore, the output spectrum instead of spikes will
have maxima of ﬁnite width, and the locations Ωs of these are shifted away
from the input frequency ω (Fig. 1). We thus search a neighborhood of the
input frequency for the signal peak and deﬁne

max

S(Ω)

(1

α) ω < Ω < (1 + α) ω

SNR =

{

|

−

}

SP

= π

τ

max

S(Ω)

(1

α) ω < Ω < (1 + α) ω

.

h

i

{

|

−

}

(20)

As discussed above, we use the uniform spectral density SP of the Poissonian
spike train with ﬁring rate 1/
as noise reference level. Note that no SNR is
calculated if the spectrum is monotonous in [(1

α) ω, (1 + α) ω].

τ

h

i

−

≥

ρ(t) dt

For all data shown, we have calculated the FPTD ρ(t) up to t = tmax such that
tmax
0.99. Unless stated otherwise below, we employed a stepsize of
0
h = 0.1 and set the initial phase of the stimulus to ϕ = 0. Parameter sets
R
for which ρ(t) assumed negative values were discarded unless the latter could
clearly be identiﬁed as numerical noise. PSDs were calculated at increasing
frequency resolutions until results became consistent. The interval width for
searching the signal was chosen as α = 0.07.

As the central result of our work, we show in Figs. 2 and 3 the dependence
of the signal-to-noise ratio on the input noise strength for various values of
drift term µ, modulation amplitude q and frequency ω, which correspond to
distances-from-threshold 0.001 < ǫ < 0.01. All data clearly show stochastic

7

102

101

R
N
S

100

102

R
N
S

µ=0.97, q=0.03, ω=0.1π
µ=0.95, q=0.05, ω=0.1π
µ=0.97, q=0.03, ω=0.2π
µ=0.95, q=0.05, ω=0.2π

10−6

10−4

D

Fig. 2. Signal-to-noise ratio vs. input noise strength for signals with small dis-
tance-to-threshold. From top to bottom in the legend: ǫ = 0.0014, 0.0023, 0.0046,
0.0077.

10−6

10−4

Fig. 3. Signal-to-noise ratio vs. input noise strength for diﬀerent input frequen-
cies but the same distance-from-threshold ǫ = 0.0014. Here, µ = 0.95 and
q = 0.05

cot-1 ω, h = 0.1

ω1/ω, ω1 = 0.1π.

√1 + ω2/

1 + ω2

1, ϕ = cot-1 ω1 −

×

×

resonance, i.e. attain the maximal signal-to-noise ratio SNRmax at a noise
strength Dmax > 0.

p

To explain why the SNR peaks, we best turn to the properties of the deter-
and the FPTD ρ(t), which are shown in Fig. 4 for
ministic solution
ω = 0.1π, µ = 0.97, q = 0.03 (ǫ
0.0014); this parameter set corresponds to
the solid line in Fig. 2 and to the spectra shown in Fig. 1. For strong noise,

x(t)

≈

i

h

ω=1.0π
ω=0.6π
ω=0.3π
ω=0.1π

D

8

 D = 5.00e−07

 D = 2.78e−06

 D = 8.56e−05

 D = 2.50e−02

0.5

0.4

0.3

0.2

0.1

0

−0.1

0

)
t
(
ρ

1
−
>
)
t
(
x
<

10

20

30

40

50

t

Fig. 4. Deterministic solution and ﬁrst-passage-time density for µ = 0.97, q = 0.03,
ω = 0.1π and ǫ = 0.0014 as in Fig. 1. The noise levels correspond to (from top to
bottom): below Dmax, at Dmax, at Dc and at high noise. The vertical dotted lines
mark the ﬁrst and second period of the input signal.
has been shifted for
clarity.

x(t)
h

i

h

i

x(t)

becomes virtually negligible and the threshold cross-
the modulation of
ing probability is concentrated in a “drift peak” at small t. This drift peak
shifts towards t = 0 and sharpens as the noise strength is increased, becom-
ing similar to a Γ-distribution (data not shown). In the spectrum, this peak
corresponds to a widening hump shifting towards higher frequencies (Fig. 1)
and no signal peak is left in the vicinity of the input frequency ω. As the
input noise strength D decreases, threshold crossings become concentrated
, and ﬁring events are synchronized to the input
around the maxima of
stimulus, with the ﬁrst peak of ρ(t) dominating the distribution for Dmax. As
D is reduced beyond Dmax, the peak at the ﬁrst period shrinks and the ﬁr-
.
ing probability is more evenly distributed over subsequent maxima of
i
Therefore, a variable number of maxima is skipped before the threshold is
reached, resulting in erratic ﬁring and thus a decrease in SNR (Fig. 4).

x(t)

x(t)

h

h

i

Obviously, we cannot expect stochastic resonance for ǫ
0 in this system,
≤
for if the deterministic solution
reaches the threshold, spikes will be
i
perfectly synchronized for D = 0, although the ﬁring frequency may be far
from the frequency of the input signal.

x(t)

h

For small distances-from-threshold (ǫ < 0.003) and low frequency (ω = 0.1π),
we observe stochastic resonance at very small noise strengths Dmax, and the
SNR decays algebraically as D is increased beyond Dmax (Fig. 2). Furthermore,
this decay exhibits a crossover between two regimes at an intermediate noise
strength Dc. For D < Dc, the loss in SNR is due to the widening of the peaks

9

µ = 0.90, q = 0.07
µ = 0.90, q = 0.07
µ = 0.90, q = 0.09
µ = 0.90, q = 0.09
µ = 0.92, q = 0.05
µ = 0.92, q = 0.05
µ = 0.95, q = 0.03
µ = 0.95, q = 0.03

10−3

10−4

x
a
m
D

10−5

µ = 0.95, q = 0.05
µ = 0.95, q = 0.05
µ = 0.95, q = 0.07
µ = 0.95, q = 0.07
µ = 0.97, q = 0.03
µ = 0.97, q = 0.03

10−3

10−2
ε

10−1

Fig. 5. Position of SNR maximum vs. distance-from-threshold. Data pertaining to
identical values of µ and q but diﬀerent ω are connected by lines. Note that Dmax
was chosen from the set of noise strengths for which calculations were performed,
leading to discretization eﬀects along the ordinate.

, while for D > Dc,
in the FPTD, which are located at the maxima of
the drift peak becomes clearly discernible, corresponding to the onset of ﬁring
not synchronized with the input stimulus, see Fig. 4.

x(t)

h

i

i

h

x(t)

remains further from thresold, either due to reduced q or increased
If
ω, stochastic resonance occurs at higher input noise strengths Dmax and yields
smaller maximum values of SNR, see the lower two curves in Fig. 2. This is to
be expected, because as the deterministic solution remains smaller, the noise
contribution to threshold crossing must increase, reducing the synchronization
.
of ﬁring events with maxima of

x(t)

h

i

The input noise strength Dmax at which SNR attains its maximum depends
strongly on the distance-from-threshold ǫ, as is demonstrated in Fig. 5. Here,
we have plotted Dmax vs. ǫ on a double-logarithmic scale. Indeed, the location
ǫγ. A least squares
of the SNR maximum roughly obeys a power law Dmax ∼
1.5. The detailed dependency of Dmax on ǫ is quite complex,
ﬁt yields γ
though, and not yet well understood.

≈

On the other hand, Dmax hardly depends on the input frequency ω if the input
amplitude q is adjusted so as to obtain the same distance-from-threshold for
all frequencies, see Fig. 3. This behavior is to be expected from the mecha-
nism suggested above: the maximal SNR is reached as the ﬁring probability
is concentrated at the maxima of

x(t)

.

h

i

10

6 Conclusions and Perspectives

In this letter, we have investigated the response of a model neuron with re-
set mechanism to sinusoidal input with additive white noise. The inter-spike-
interval was determined by an eﬃcient numerical method and power spectral
densities were obtained by exploiting the renewal properties of the spike train
generated. These techniques permitted us to study the behavior of the model
neuron over a wide range of parameters, especially at very low noise strengths.
We found clear evidence for stochastic resonance, i.e. the signal-to-noise ratio
of the neuron’s output shows a distinct maximum at non-vanishing input noise.
Further, we have proposed a mechanism underlying this eﬀect. The results sug-
gest that nature does indeed employ stochastic resonance to obtain optimal
signal-to-noise ratios in an inherently noisy information processing system. A
detailed comparison with neurophysiological data will be given elsewhere.

In future work, two questions need to be addressed. The dependence of the
neuron’s response on the phase ϕ of the input stimulus has yet to be studied
in detail. We expect such work to shed more light on the detailed structure
of the dependencies of the signal-to-noise ratio on the input noise strength
and of the position of the SNR maximum on the distance-from-threshold.
More importantly, though, our model shares a weakness with other studies
of integrate-and-ﬁre neurons [14,32]: the presumed phase reset of the input
stimulus is not very plausible from the viewpoint of neurophysiology. Work on
an extended model overcoming this diﬃculty is currently in progress.

The authors thank M. Katakame for inspiring discussions. H. E. Plesser re-
ceived partial support from Studienstiftung des deutschen Volkes.

Acknowledgements

References

[1] R. Benzi, A. Sutera, and A. Vulpiani. The mechanism of stochastic resonance.

J. Phys. A, 14:L453–L457, 1981.

[2] S. Fauve and F. Heslot. Stochastic resonance in a bistable system. Phys. Lett. A,

97:5–7, 1983.

[3] B. McNamara, K. Wiesenfeld, and R. Roy. Observation of stochastic resonance

in a ring laser. Phys. Rev. Lett., 60:2626–2629, 1988.

11

[4] A. Longtin, A. Bulsara, and F. Moss. Time-interval sequences in bistable
systems and the noise-induced transmission of information by sensory neurons.
Phys. Rev. Lett., 67:656–659, 1991.

[5] J. E. Levin and J. P. Miller. Broadband neural encoding in the cricket cercal
sensory system enhanced by stochastic resonance. Nature, 380:165–168, 1996.

[6] K. Wiesenfeld and F. Moss. Stochastic resonance and the beneﬁts of noise: from

ice ages to crayﬁsh and SQUIDs. Nature, 373:33–36, 1995.

[7] B. McNamara and K. Wiesenfeld. Theory of stochastic resonance. Phys. Rev. A,

39:4854–4869, 1989.

1993.

[8] P. Jung. Periodically driven stochastic systems. Physics Reports, 234:175–295,

[9] J. J. Collins, C. C. Chow, and T. T. Imhoﬀ. Aperiodic stochastic resonance in

excitable systems. Phys. Rev. E, 52:R3321–R3324, 1995.

[10] T. Zhou, F. Moss, and P. Jung. Escape-time distributions of a periodically
modulated bistable system with noise. Phys. Rev. A, 42:3161–3169, 1990.

[11] A. Bulsara, E. W. Jacobs, T. Zhou, F. Moss, and L. Kiss. Stochastic resonance
in a single neuron model: theory and analog simulation. J. theor. Biol., 152:531–
555, 1991.

[12] H. C. Tuckwell. Stochastic Processes in the Neurosciences. SIAM, Philadelphia,

1989.

[13] P. L´ansk´y and J. P. Rospars. Ornstein–Uhlenbeck model neuron revisited.

Biol. Cybern., 72:397–406, 1995.

[14] A. R. Bulsara, T. C. Elston, C. R. Doering, S. B. Lowen, and K. Lindenberg.
Cooperative behavior in periodically driven noisy integrate-ﬁre models of
neuronal dynamics. Phys. Rev. E, 53:3958–3969, 1996.

[15] K. Wiesenfeld, D. Pierson, E. Pantazelou, and F. Moss. Stochastic resonance

on a circle. Phys. Rev. Lett., 72:2125–2129, 1994.

[16] P. Jung. Threshold devices: fractal noise and neural talk. Phys. Rev. E, 50:2513–

2522, 1994.

[17] Z. Gingl, L. B. Kiss, and F. Moss. Non-dynamical stochastic resonance: theory
and experiments with white and arbitrarily coloured noise. Europhys. Lett.,
29:191–196, 1995.

[18] P. Jung. Stochastic resonance and optimal design of threshold detectors.

Phys. Lett. A, 207:93–104, 1995.

[19] P. L´ansk´y, L. Sacerdote, and F. Tomassetti. On the comparison of Feller and
Ornstein–Uhlenbeck models of neural activity. Biol. Cybern., 73:457–465, 1995.

[20] J. Inoue, S. Sato, and L. M. Ricciardi. On the parameter estimation for diﬀusion

models of single neuron’s activities. Biol. Cybern., 73:209–221, 1995.

12

[21] D. R. Cox and P. A. W. Lewis. The Statistical Analysis of Series of Events.

Methuen, London, 1966.

[22] N. G. van Kampen. Stochastic Processes in Physics and Chemistry. North-

Holland, Amsterdam, second edition, 1992.

[23] E. Schr¨odinger. Zur Theorie der Fall- und Steigversuche an Teilchen mit

Brownscher Bewegung. Physikalische Zeitschrift, 16:289–295, 1915.

[24] L. M. Ricciardi and S. Sato. First-passage-time density and moments of the

Ornstein–Uhlenbeck process. J. Appl. Prob., 25:43–57, 1988.

[25] A. J. F. Siegert. On the ﬁrst passage time probability problem. Phys. Rev.,

81:617–623, 1951.

[26] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. Numerical
Recipes in C. Cambridge University Press, Cambridge, GB, second edition,
1992.

[27] A. Buonocore, A. G. Nobile, and L. M. Ricciardi. A new integral equation
for the evaluation of ﬁrst-passage-time probability densities. Adv. Appl. Prob.,
19:784–800, 1987.

[28] V. Giorno, A. G. Nobile, L. M. Ricciardi, and S. Sato. On the evaluation
of ﬁrst-passage-time probability densities via non-singular integral equations.
Adv. Appl. Prob., 21:20–36, 1989.

[29] M. S. Bartlett. The spectral analysis of point processes. J. R. Statist. Soc.

Ser. B, 29:264–296, 1963.

[30] D. J. Daley and D. Vere-Jones. An Introduction to the Theory of Point

Processes. Springer, New York, 1988.

[31] D. H. Perkel, G. L. Gerstein, and G. P. Moore. Neuronal spike trains and

stochastic point processes. Biophys J, 7:391–418, 1967.

[32] A. R. Bulsara, S. B. Lowen, and C. D. Rees. Cooperative behavior in the
periodically modulated Wiener process: noise-induced complexity in a model
neutron [sic]. Phys. Rev. E, 49:4989–5000, 1994.

13

