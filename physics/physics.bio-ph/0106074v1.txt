1
0
0
2
 
n
u
J
 
2
2
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
4
7
0
6
0
1
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Entropic Approach for Reduction of Amino Acid Alphabets

Wei-Mou Zheng
Institute of Theoretical Physics, Academia Sinica, Beijing 100080, China

Abstract

The primitive data for deducing the Miyazawa-Jernigan contact energy or BLOSUM score metrix
is the pair frequency counts. Each amino acid corresponds to a distribution. Taking the Kullback-
Leibler distance of two probability distributions as resemblance coeﬃcient and relating cluster to mixed
population, we perform cluster analysis of amino acids based on the frequecy counts data. Furthermore,
Ward’s clustering is also obtained by adopting the average score as an objective function. An ordinal
cophenetic is introduced to compare results from diﬀerent clustering methods.

Introduction

Experimental investigation has strongly suggested that protein folding can be achieved with fewer letters
than the 20 naturally occuring amino acids (Chan, 1999; Plaxco et al., 1998). The native structure and
physical properties of protein Rop is maintained when its 32-residue hydrophobic core is formed with only
Ala and Leu residues (Munson et al., 1994). Another example is the ﬁve-letter alphabet of Baker’s group for
38 out of 40 selected sites of SH3 chain (Riddle et al., 1997). The mutational tolerance can be high in many
regions of protein sequences. Heterogeneity or diversity in interaction must be present for polypeptides to
have protein-like properties. However, physics and chemistry for polypeptide chain consisting of fewer than
20 letters may be suﬃciently simpliﬁed for a thorough understanding of the protein folding.

A central task of protein sequence analysis is to uncover the exact nature of the information encoded in
the primary structure. We still cannor read the language describing the ﬁnal 3D fold of an active biological
macromolecule. Compared with DNA sequence, protein sequence is generally much shorter, but the size of
the alphabet ﬁve times larger. A proper coarse graining of the 20 amino acids into fewer clusters is important
for improving the signal-to-noise ratio when extracting information by statistical means.

Based on Miyazawa-Jernigan’s (MJ) residue-residue statistical potential (Miyazawa and Jernigan, 1996),
Wang and Wang (1999) (WW) reduced the alphabet. They introduced a ‘minimal mismatch’ principle to
ensure that all interactions between amino acids belonging to any two given groups are as similar to one
another as possible. The knowledge-based MJ potential is derived from the frequencies of contacts between
diﬀerent amino acid residues in a set of known native protein structure database. Murphy, Wallqvist and
Levy (2000) (MWL) approached the same problem using the BLOSUM metrix derived by Henikoﬀ and
Henikoﬀ (1992). The metrix is deduced from amino acid pair frequencies in aligned blocks of a protein
sequence database, and widely used for sequence alignment and comparison.

The problem of alphabet reduction may be viewed as cluster analysis, which is a well developed topic
(Romesburg, 1984; Sp¨ath, 1985). WW used the mismatch as an objective function without any resemblance
measure. MWL adopted a cosine-like resemblance coeﬃcient (with a non-standard normalization) from the
BLOSUM score metrix without any objective function, and took the arithmetic mean of scores to deﬁne
the cluster center. It is our purpose to propose an entropic algorithm for selecting reduced alphabet in a
consistent and systematic way.
Materials and methods

Either the MJ contact energies or BLOSUM score metrices are deduced from the primitive frequency
counts of amino acid pairs. Taking the BLOSUM metrix as an example for speciﬁcity, following Henikoﬀ and
Henikoﬀ (1992), we denote the total number of amino acid i, j pairs (1 ≤ i, j ≤ 20) by fij . It is convenient
to introduce another set of f ′
ii = fii, which deﬁnes a joint probability for

ij = fij/2 for i 6= j and f ′

ij with f ′

1

(1)

(2)

(3)

(4)

(5)

(6)

(7)

each i, j pair

The probability for the amino acid i to occur is then

′
ij = f
q

′
ij/f,

f =

20

20

X
i=1

X
j=1

′
ij.

f

pi =

20

X
j=1

′
ij .
q

sij = log2[q

′
ij /(pipj)].

The BLOSUM score corresponds to the logarithm of odds

Each Amino acid i may be described by the conditional probability vector {p(j|i)}20
In the language of cluster analysis, the objects are the 20 amino acids, and the attributes are p(j|i).

j=1 with p(j|i) ≡ q′

ij/pi.

A ruler to measure the similarity between the distributions {pi} and {qi} is the Kullback-Leibler distance
D (also called relative entropy) of the probability distributions q from p (Kullback, 1959; Kullback et al.,
1987; Sakamoto et al, 1986):

D(p, q) = X
i

pi log(pi/qi).

This distance is always non-negative, and not symmetric in general. We may make symmetrization to use
D = [D(p, q) + D(q, p)]/2.
It will be used as the resemblace coeﬃcient or distance for clustering. For
frequancy counts, clustering two amino aids is just merging or summing up their counts. A cluster then
corresponds to a mixed population. That is, the cluster center of amino acid i and j is described by

′
q
i&j,k = q

′
ik + q

′
jk,

pi&j = pi + pj.

With the resemblance coeﬃcient and cluster center deﬁned, routine cluster algorithms, such as the centroid
method, may be applied.

Henikoﬀ and Henikoﬀ (1992) deﬁned the average mutual information or the average score:

H =

20

20

X
i=1

X
j=1

′
ij sij =
q

20

20

X
i=1

X
j=1

′
ij log2
q

q′
ij
pipj

,

which is again a Kullback-Leibler distance. The diﬀerence between H after and before clustering of i and j
is related to terms like

(qik + qjk) log

− qik log

− qjk log

qik + qjk
(pi + pj)pk

qik
pipk

qjk
pjpk

,

which, by introducing xi = qik/pi, xj = qjk/pj, ωi = pi/(pi + pj), ωj = pj/(pi + pk) and hf (x)i =
ωif (xi) + ωjf (xj ), is proportional to f (hxi) − hf (x)i with f (x) = x log x. From the Jessen theorem for
convex function (x log x here) (Rassias, 2000; Rassias and Srivastava, 1999), H never increases after each
step of clustering. To make the average score as closer to that before a coarse-graining as possible, we should
maximize H. This average mutual information H can be chosen as the objective function for clustering
with respect to scores. Compared with the above approach based on the conditional probability p(j|i),
this objective function also takes abundance of amino acids into account. We shall use Ward’s methord
(Romesburg, 1984) to perform clustering.
Results

By means of the entropic Kullback-Leibler distance, deﬁning the center of cluster by the distribution of
the mixed population, we conduct cluster analysis on the MJ frequency counts with the centroid method. The
result of the hierachical steps of clustering is shown in Table I. This will be refered to as the MJ-clustering.

2

We do see Baker’s ﬁve representative letters (AIGEK) at step 14, which ends at 6 clusters including the
cluster consisting of the extraordinary sigle member Cys.

Our most cluster analysis is done based on the BLOSUM 62 frequency counts. The counterpart of Table
I for BLOSUM is Table II. Taking the average score H as the objective function for maximization, the
clustering result of Ward’s method is given in Table III. These two clusterings will be referred to as the
HH- and BL-clustering, respectively. For the BL-clustering, when number of clusters becomes smaller, the
average score decreases faster as shown in Fig. 1. When the total number of clusters is three, the score drops
to about the half of its original value.

Clustering result can be represented by a tree. The cophenetic metrix built by tracing distances along
the tree is equivalent to the tree. The correlation between the cophenetic matrix and resemblance matrix is
often used to measure the quality of clustering. We introduce the ordinal cophenetic metrix by taking the
clustering depth as the distance. For example, Y and Q group together at step 5 in Table I. The YQ element
of the ordinal cophenetic metrix is 5 as shown in Table IV, where the lower and upper matrices correspond
to Tables I and II, respectively. In this way we ignore some numerical details, and focus on the order of
the nodes in the tree. We compare the BL-clustering with the MJ- and HH-clusterings by calculating the
diﬀerence between their ordinal cophenetic matrices. As shown in Table 5, the two clusterings HH and BL
are closer to each other than MJ and BL are. Large positive and negative values of entries indicate main
diﬀerences. The MJ-clustering prefers F to group with M, and Q with Y, while the BL-or HH-clustering
prefers F to group with Y, and Q with E. In all the three clusterings the separation of hydrophobic and
hydrophilic groups is rather clear.
Discussion

We have done cluster analysis also based on the BLOSUM 50 and 90. The results are very close to those

obtained for the BLOSUM 62.

The clustering based on MJ shows avident discrepency from that based on BLOSUM. From the way
obtaining the frequency acounts, the BLOSUM data is more relavent to evolutional diﬀerence of residues,
while the MJ data to structure diﬀerence. There are many amino acid diﬀerence formulas (Grantham, 1974).
From composition c (deﬁned as the atomic weight ratio of noncarbon elements in end groups to carbons in
the side chain), polarity p and volume v Grantham (1974) derived an amino acid deﬀerence matrix, which
exhibits stronger correlation with evolution than the method of minimum base changes between codons.
This diﬀerence metrix is also a good candidate of resemblance metrix for clustering. To least disturb the
data, we perform the UPGMA (unweighted pair-group method using arithmetic average) clustering (referred
to as GR) on the data. The diﬀerence in the ordinal cophenetic metrices is shown in Table VI. Compared
with MJ, BL is close to GR derived from physicochemical properties of amino acids. The average absolute
diﬀerence of 190 entries are 1.84 and 2.84 for BL − GR and HH − GR, respectively. Since diﬀerent structure
regularities prefer certain residues, residue clustering should not be identical in all structure subclasses.
Structure subclass speciﬁc clustering would give us more insight.

For the BLOSUM data, the direct use of pair frequency counts provides us a consistent way to derive
coarse-grained scores from mixed population. We think for the MJ data the natural objective function should
be the average contact energy, which is the counterpart of the BLOSUM H by replacing the logarithm of odds
sij with the contact energy eij. The coarse-grained contact energy can be deduced from mixed population.
This will furnishe us a consistent way for cluster analysis.

This work was ﬁnished during the author’s visit to the Bartol Research Institute, University
of Delaware. The author thanks Dr. S.T. Chui for the warm hospitality and fruitful discussions.
This work was supported in part by the Special Funds for Major National Basic Research Projects,
the National Natural Science Foundation of China and Research Project 248 of Beijing.

References
Chan,H.S. (1999) Nature Struct. Biol., 6, 994–996.
Grantham,R. (1974) Science, 185, 862–864.
Henikoﬀ,S. and Henikoﬀ,J.G. (1992) Proc. Natl. Acad. Sci. USA, 89, 10915–10919.
Kullback,S., Keegel,J.C. and Kullback,J.H. (1959) Information Theory and Statistics, Wiley, New York.
Kullback,S. (1987) Topics in Statistical Information Theory, Springer, Berlin.

3

Miyazawa,S. and Jernigan,R.L. (1996) J. Mol. Biol., 256, 623–644.
Munson,M., O’Brien,R., Sturtevant,J.M. and Regan,L. (1994) Protein Sci., 3, 2015–2022.
Murphy,L.R., Wallqvist,A. and Levy,R.M. (2000) Protein Eng., 3, 149–152.
Plaxco,K.W., Riddle,D.S., Grantcharova,V.P. and Baker,D. (1998) Curr. Opin. Struct. Biol., 8, 80–85.
Rassias,T.M. (eds) (2000) Survey on Classical Inequalities, Kluwer Academic, Dordrecht.
Rassias,T.M. and Srivastava,H.M. (eds) (1999) Analytic and Geometric Inequalities and Applications, Kluwer
Academic, Dordrecht.
Riddle,D.S., Santiago,J.V., Bray-Hall,S.T., Doshi,N., Grantcharova,V.P., Yi,Q. and Baker,D. (1997) Nature
Struct. Biol., 4, 805–809.
Romesburg,H.C. (1984) Cluster Analysis for Researchers, Lifetime Learning Publications, Belmont.
Sakamoto,T., Ishiguro,M. and Kitagawa,G. (1986) Akaike Information Criterion Statistics, KTK Scientiﬁc,
Tokyo.
Sp¨ath,H. (1985) Cluster Dissection and Analysis: Theory, FORTRAN Program, Examples, Ellis Horwood,
New York.
Wang,J. and Wang,W. (1999) Nature Struct. Biol., 6, 1033–1038.

Table I. Clustering based on the MJ pair frequency counts with the centroid method. The ﬁrst column

Table II. Clustering based on the BLOSUM62 frequency counts with the centroid method.

indicates the step in the hierachical clustering.

0
1
2
3
4
5
6
7
8
9

C A V I L M F Y Q P W N S T G H D E R K
M F Y Q P W N S T G H D E R K
C A V IL
MF Y Q P W N S T G H D E R K
C A V IL
MF Y Q P W N S T G H D E R K
C A VIL
MF Y Q P W N ST G H D E R K
C A VIL
MF YQ P W N ST G H D E R K
C A VIL
W N ST G H D E R K
MF YQP
C A VIL
W N ST G H D E RK
MF YQP
C A VIL
W N ST G H D E RK
YQP
C A VILMF
G H D E RK
W NST
YQP
C A VILMF
G H D E RK
NST
YQPW
10 C A VILMF
H D E RK
NSTG
YQPW
11 C A VILMF
H DE RK
YQPW
12 C A VILMF
NSTG
H DE RK
YQPWNSTG
13 C A VILMF
DE RK
YQPWNSTGH
14 C A VILMF
DE RK
YQPWNSTGH
15 C AVILMF
DE RK
16 CAVILMF
YQPWNSTGH
DE RK
17 CAVILMFYQPWNSTGH
18 CAVILMFYQPWNSTGHDE
RK
19 CAVILMFYQPWNSTGHDERK

0
1
2
3
4
5
6
7
8
9

W F Y L M I V H N D R K Q E S T A G P C
I V H N D R K Q E S T A G P C
W F Y LM
IV H N D R K Q E S T A G P C
W F Y LM
IV H N D RK Q E S T A G P C
W F Y LM
H N D RK Q E S T A G P C
W F Y LMIV
H N D RK QE S T A G P C
W F Y LMIV
A G P C
H N D RK QE ST
W F Y LMIV
G P C
H N D RK QE STA
W F Y LMIV
G P C
H N D RK QE STA
W FY LMIV
G P C
STA
H N D RKQE
W FY LMIV
G P C
STA
H ND
10 W FY LMIV
RKQE
G P C
H NDRKQE
11 W FY LMIV
STA
G P C
H NDRKQESTA
12 W FY LMIV
G P C
HNDRKQESTA
13 W FY LMIV
P C
HNDRKQESTAG
14 W FY LMIV
P C
HNDRKQESTAG
15 W FYLMIV
C
16 W FYLMIV
HNDRKQESTAGP
17 W FYLMIVHNDRKQESTAGP
C
18 W FYLMIVHNDRKQESTAGPC
19 WFYLMIVHNDRKQESTAGPC

4

Table IV. Ordinal cophenetic matrices of the MJ-clustering (lower) and HH-clustering (upper).

Table III. Clustering based on the BLOSUM62 frequency counts with Ward’s method.

0
1
2
3
4
5
6
7
8
9

W F Y L M I V H N D R K Q E S T A G P C
I V H N D R K Q E S T A G P C
W F Y LM
I V H N D RK Q E S T A G P C
W F Y LM
I V H N D RK QE S T A G P C
W F Y LM
IV H N D RK QE S T A G P C
W F Y LM
IV H N D RK QE S T A G P C
W FY LM
A G P C
IV H N D RK QE ST
W FY LM
G P C
IV H N D RK QE STA
W FY LM
G P C
H N D RK QE STA
W FY LMIV
G P C
RK QE STA
H ND
W FY LMIV
G P C
STA
RKQE
H ND
10 W FY LMIV
G P C
STA
RKQE
H ND
LMIV
11 WFY
G P C
STA
RKQE
HND
LMIV
12 WFY
G PC
STA
HND
LMIV
13 WFY
RKQE
G PC
STA
HNDRKQE
LMIV
14 WFY
STAG
HNDRKQE
LMIV
15 WFY
PC
STAGPC
HNDRKQE
16 WFY
LMIV
HNDRKQE
17 WFYLMIV
STAGPC
HNDRKQESTAGPC
18 WFYLMIV
19 WFYLMIVHNDRKQESTAGPC

H

M

1

3

W

F

E

G

S

8
8

8
1
3

I V

K Q

T A

Y L

N D

8 17
2 17
8 17
8 17

P C
R
19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19
8 15 15 15 15 17 17 17 17 17 17 17 17 17 17 17 17 18
15 15 15 15 17 17 17 17 17 17 17 17 17 17 17 17 18
4 4 17 17 17 17 17 17 17 17 17 17 17 17 18
4 4 17 17 17 17 17 17 17 17 17 17 17 17 18
2 17 17 17 17 17 17 17 17 17 17 17 17 18
17 17 17 17 17 17 17 17 17 17 17 17 18
13 13 13 13 13 13 13 13 13 14 16 18
10 11 11 11 11 12 12 12 14 16 18
11 11 11 11 12 12 12 14 16 18
9 12 12 12 14 16 18
9 12 12 12 14 16 18
5 12 12 12 14 16 18
12 12 12 14 16 18
6 7 14 16 18
8 14 16 18
14 16 18
16 18
18

W
F 17
Y 10 17
L 17
M 17
I 17
V 17
H 14 17 14 17 17 17 17
N 13 17 13 17 17 17 17 14
D 18 18 18 18 18 18 18 18 18
R 19 19 19 19 19 19 19 19 19 19
K 19 19 19 19 19 19 19 19 19 19
Q 10 17
E 18 18 18 18 18 18 18 18 18 12 19 19 18
S 13 17 13 17 17 17 17 14
T 13 17 13 17 17 17 17 14
A 17 15 17 15 15 15 15 17 17 18 19 19 17 18 17 17
G 13 17 13 17 17 17 17 14 11 18 19 19 13 18 11 11 17
P 10 17
C 17 16 17 16 16 16 16 17 17 18 19 19 17 18 17 17 16 17 17

6 17 17 17 17 14 13 18 19 19 6 18 13 13 17 13

9 18 19 19 13 18
9 18 19 19 13 18

5 17 17 17 17 14 13 18 19 19

3 9
9

4

7

5

Table V. Diﬀerence of the BL ordinal cophenetic metrix from those of the MJ- (lower) and HH-clustering

Table VI. Diﬀerence of the MJ- (lower) and BL-clustering (upper) ordinal cophenetic metrices from that

of the GR-clustering.

M

F

Y L

I V
-8 -8 -2 -2 -2 -2
2 2
2 2
4 4
4 4
2

2
2
0

(upper).

W

-3

2
2

W
F -6
Y 1-12
L 0
9
M 0 15
9
I 0
9
V 0
2
H 5
2
N 6
1
D 1
0
R 0
0
K 0
2 14
Q 9
1
E 1
2
S 6
2
T 6
4
A 2
2
G 6
2 13
P 9
3
C 2

0
0 -7
0 7
0 5
5 2
6 2
1 1
0 0
0 0
2
1 1
6 2
6 2
2 4
6 2
2
2 3

H
0
2
2
2
2
2
2

N D
0 0
2 2
2 2
2 2
2 2
2 2
2 2
-1 0
-1

R
0
2
2
2
2
2
2
1
3
3

K Q
0 0
2 2
2 2
2 2
2 2
2 2
2 2
1 1
3 3
3 3
-1 1
1

E
0
2
2
2
2
2
2
1
3
3
1
1
-2

S
0
2
2
2
2
2
2
5
6
6
6
6
6
6

G
0
2
2
2
2
2
2
4
4
4
4
4
4
4
1
1
1

T A
0 0
2 2
2 2
2 2
2 2
2 2
2 2
5 5
6 6
6 6
6 6
6 6
6 6
6 6
0 0
-1

4 -2
3 -1

P C
0 0
2 1
2 1
2 1
2 1
2 1
2 1
2 0
2 0
2 0
2 0
2 0
2 0
2 0
0 -2
0 -2
0 -2
0 -2
-5

0
0
2
0-10-10
4
0
0
3
0 -1 -1

3
0 -1 -4

0

1
2 2
2 2 -2
1 1 -5 -9
0 0 -5 -5 -5
0 0 -5 -5 -5 -5
2 2
1 1 -4 -4 2 -9 -9-15
9 0 -1 -1 5
2 2
9 0 -1 -1 5
2 2
1 0 -1 -1 1
4 4
7 0 -1 -1 5
2 2
5 0 -1 -1 12
2 2
1 0 -1 -1 1
3 3

1 -4 -9 -9

4
4
1
4
4
1

0
0
2
2
1
0
0
2
1
2
2
4
2
2
3

W

F

-4 -4

6
0 -5

H
1
1
1
1
1
1
1

M
2
7
7
-1

Y L
2
2 7
7

I V
1 1
7 7
7 7
0 0
6 0
-4

N D
1 1
1 1
1 1
1 1
1 1
1 1
1 1
-4 -3

W
F 2
Y -5 14
7
L 2 -2
7 6
M 2 -8
7 0
I 2 -2
V 2 -2
7 -5
H -4 -1 -4 -1 -1 -1 -1
N -5 -1 -5 -1 -1 -1 -1 -2
2 14
0 0
0 0
D 0
3 3
8
1 1
1 1
R 1
8
3 3
K 1
1 1
1 1
9 -3 2
Q -8 -1-13 -1 -1 -1 -1
E 0
2 -4
9
0 0
0
0 0
S -5 -1 -5 -1 -1 -1 -1 -2 -5 4
T -5 -1 -5 -1 -1 -1 -1 -3 -8 1
A -1 -3 -1 -3 -3 -3 -3
0 1
G -5 -1 -5 -1 -1 -1 -1 -3 -6 1
P -8 -1-12 -1 -1 -1 -1 -3 -4 1
C -2 -3 -2 -3 -3 -3 -3 -2 -2 -1

0
1
1

0
1
1

0

0

R
1
1
1
1
1
1
1
3

K Q
1 1
1 1
1 1
1 1
1 1
1 1
1 1
3 9

E
1
1
1
1
1
1
1
5
5 -2 -2 -2 -2
-2 -2 -2 -2
-4 -1 -1
-1 -1
-6

S
1
1
1
1
1
1
1
2
4
4
2
2
2
2

G
1
1
1
1
1
1
1
1
1
1
1
1
1
1

T A
1 1
1 1
1 1
1 1
1 1
1 1
1 1
1 1
1 1
1 1
1 1
1 1
1 1
1 1

P C
1 0
1 0
1 0
1 0
1 0
1 0
1 0
1 -1
1 -1
1 -1
1 -1
1 -1
1 -1
1 -1
-11-10 -2 -1 -3
4 -3
9 -3
3 -3
-6

2
2

-5

0

8
8 9
3 -3
2 -4
2 0
2 -4
2-11
0 -2 -1 -2 -2 -3 -2 -2

2
1-13
1
5
0
1 -6 -2
1 -4

4
1 10

1
8
8
3
2
2
2
2
0

6

Fig. 1 Relationship between everage score and number of clusters.

(Here the score is in the natural

logarithm instead of taking base 2.)

H
 
e
r
o
c
S
 
e
g
a
r
e
v
A

0.25

0.2

0.15

0.1

0.05

0

2

4

6

8

10 12 14 16 18 20

Number of Letters n

