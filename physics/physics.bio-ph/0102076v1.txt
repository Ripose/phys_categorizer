1
0
0
2
 
b
e
F
 
3
2
 
 
]
h
p
-
o
i
b
.
s
c
i
s
y
h
p
[
 
 
1
v
6
7
0
2
0
1
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Errors drive the evolution of biological

signalling to costly codes

Gonzalo G. de Polavieja

Dept. Zoology, Downing St.

University of Cambridge, CB2 3EJ, UK.

gg234@cus.cam.ac.uk

1

Abstract

Reduction of costs in biological signalling seems an evo-

lutionary advantage, but recent experiments have shown sig-

nalling codes shifted to signals of high cost with a under-

utilisation of low cost signals. Here I show that errors in

the eﬃcient translation of biological states into signals shift

codes to higher costs, eﬀectively performing a quality con-

trol. The statistical structure of signal usage is predicted

to be of a generalised Boltzmann form that penalises sig-

nals that are costly and sensitive to errors. This predicted

distribution of signal usage against signal cost has two main

features: an exponential tail required for cost eﬃciency and

an underutilisation of the low cost signals required to pro-

tect the signalling quality from the errors. These predictions

are shown to correspond quantitatively to the experiments in

which gathering signal statistics is feasible as in visual cortex

neurons.

KEYWORDS: signalling, cost, noise, neuron , information theory

SHORT TITLE: Errors drive signalling to costly codes

2

1 Introduction

Cells, groups of cells and multicellular organisms communicate their states

using signals. The types of signals and encoding mechanisms used can be

very diﬀerent but, irrespectively of the mechanism, signal transmission should

have a high eﬃciency within biological constraints. A universal constraint

is the signalling cost. Have biological signalling codes evolved to minimise

cost? Cost reduction seems advantageous (??????) but signalling systems

might be simultaneously optimal not only respect to cost but also to other

constraints resulting in signalling codes very diﬀerent to the cost eﬃcient

ones. A second universal constraint is communication errors. Here I consider

the extension of information theory (??) to include errors and cost together

as constraints of signalling systems and ﬁnd the optimal signal usage under

these constraints. For clarity of exposition and because the best data sets for

statistical analysis are in neural signals, I will particularise the discussion to

cell signalling and discuss the relevance of results to other signalling systems

afterwards.

Neurons provide an experimentally tractable case of cell signalling. The

experimental evidence in neurons is counterintuitive. Neurons codes can un-

derutilise low cost signals. For neurons using diﬀerent spike rates as signals,

3

it has been found that low rates that take lesser metabolic cost to produce are

typically underutilised (?). Similarly, neurons using spike bursts as signals

underutilise the bursts of one spike that would take lesser production cost

(??). Theories of cost eﬃciency cannot explain these experimental results.

According to these theories of cost eﬃciency, signalling systems should max-

imise their capacity to represent diﬀerent states given a cost constraint or

maximise the ratio of this representational capacity and the cost (??). The

optimal distribution for these theories is an exponential decaying with signal

cost. In this way the most probable signals are those of lowest cost in clear

contrast to the underutilisation of the low cost signals observed experimen-

tally. For this reason I consider here the evolution of biological signalling

codes towards eﬃciency of transmission within the biological constraints of

both cost and errors.

This paper is organised as follows. Section 2 gives the theoretical frame-

work and the general result of optimal signal usage when both costs and errors

constrain the signalling system. To ﬁnd this optimal signal usage an iterative

algorithm that can be easily implemented is given. Section 3 shows that the

optimal solutions found predict quantitatively the experimental results for

signal usage in visual cortex neurons. Section 4 gives the conclusions and

4

discusses the application to a variety of biological signalling systems includ-

ing animal communication for which it is shown that cheaters shift eﬃcient

codes to high cost.

2 Theoretical treatment

For signal transmission between a signaller and a receiver to work, the

signaller must use encoding rules that correlate its signalling states C =

{c1, c2, ..., cN } with the signals S = {s1, s2, ..., sN }. For intercellular sig-

nalling, the signals S can be diﬀerent values of concentration of the same

chemical, diﬀerent mixtures of several chemicals, diﬀerent time patterns (say,

diﬀerent frequencies of spike generation or bursts of diﬀerent sizes), diﬀerent

spatial patterns or even diﬀerent patterns of activation of a group of cells.

The cellular states C are the internal variables representing the ideal sig-

nals without errors. Experimentally, identical stimulations of the cell will

produce a distribution of signals were the peak is the ideal noiseless signal

corresponding to the cellular state and the variance comes from the errors.

The correlation of states and signals is subject to the constraints imposed

by cost and errors. We characterise these errors with the error matrix of

5

conditional probabilities Qkj ≡ p(ck|sj), a matrix given by the probability

that the signal sj comes from the state ck. When there are no errors present

each signal comes from a single state, and the error matrix Q is diagonal.

When there are errors present, there are nonzero nondiagonal elements. The

costs can be in molecular machinery (a convenient parameter can be the

number of ATP molecules), in transmission times (for example, bursts of

many spikes take longer times to transmit than of fewer spikes) and in risks

(for example by the use of chemicals that can be toxic). We can formally

write the costs of producing the signals as ǫkj with for example ǫ12 the cost for

the conversion of the ﬁrst state into the second signal. As we are interested

in the signal usage, we refer the costs to the signals as ǫj =

k Qkjǫkj. We

always label the signals in order of increasing cost, ǫ1 ≤ ǫ2 ≤ ... ≤ ǫN .

P

We also need to formalise the notion of correlation between the signallers

states and the signals in order to consider the consequences of cost and errors

for this correlation. We require a general measure of correlation that is valid

for any nonlinear dependencies, unlike correlation functions (?), and that

does not use a metric that measures correlation in an arbitrary manner. The

averaged distance between the actual joint distribution p(ci, sj) and the dis-

tribution corresponding to complete decorrelation p(ci, sj)decorr ≡ p(ci)p(sj)

6

gives such a general measure of correlation of the form

I(C; S) =

p(ci, sj) log

Xi,j

p(ci, sj)
p(ci)p(sj) (cid:19)

,

(cid:18)

(1)

that is zero for the completely decorrelated case and increases with increasing

correlation. This is the standard measure of statistical correlation used in

communication theory where it is known as mutual information (?). The

mutual information I takes care of the errors as a constraint. To see this, we

can write its expression in (1) in terms of the error matrix Q by separating

it into the signal variability and the signal uncertainty terms as I(C; S) =

H(S) − H(S|C) , with H(S) = −

j p(sj) log p(sj) and H(S|C) =

j pjξj

P

with

ξj = −

Qkj log Pjk

(2)

a measure of the signal uncertainty for signal sj and Pjk ≡ p(sj|ck) the

probability that the state ck produces the signal sj. We can express Pkj in

terms of Qjk using Bayes’ theorem as Pjk = (p(sj)Qkj)/(

j p(sj)Qkj). With

these relations we see that the mutual information can be written as the

P

diﬀerence of a term H(S) that measures the variability of the signal and a

P

Xk

7

term H(S|C) that measures the signal uncertainty as the variability of the

signal that comes from the errors in Q. This second term H(S|C) is the

constraint given by the errors.

Using the mutual information I as the measure of correlation between

states and signals, that includes the constraint given by the errors, together

with the cost constraint, we can now formulate precisely our problem. With

which frequencies p(si) should the signals S be used to have a high mutual

information I between states C and signals S given the errors Q and the

average cost E =

i p(si)ǫi as the biological constraints? To answer this

question we use the method of Lagrange multipliers. The solution of the

P

equations obtained by this method can be found using diﬀerent numerical

methods and we have chosen the one given in Algorithm 1 based on the

Blahut-Arimoto algorithm (??), commonly used in rate distortion theory

(?), because it is particularly transparent as to the form of the solution.

From Algorithm 1, we obtain that the optimal signal usage taking errors and

cost as constraints is of the form in (4)

p(sj) =

Z −1 exp

−

βǫj −

ξj

,

b

b

(cid:16)

b

(cid:17)

b

(6)

8

Algorithm 1 Optimal signal usage

Initialise the signal usage to a random vector p1.
for t = 1, 2,...until convergence do

P t

jk =

pt(sj)Qkj
j pt(sj)Qkj

P

(3)

(4)

(5)

pt+1(sj) =

exp −
(cid:0)
j exp −

βtǫj −

P
βtǫj −

k Qkj log P t
jk
(cid:1)
k Qkj log P t
jk

,

(cid:0)
where βt in (4) has to be evaluated for each t from the cost constraint

P

P

(cid:1)

j ǫj exp −
j exp −

βtǫj −
(cid:0)
βtǫj −

k Qjk log P t
jk
P
k Qjk log P t
jk

(cid:1)

= E.

(cid:0)

P

(cid:1)

P

P

end for

where the hat on p, Z, β and ξ is a reminder that their values are obtained

using the iterative Algorithm 1. The expression for ξ is given in (2) and Z is

the normalisation constant. This solution has a number of interesting charac-

teristics. Both signal cost, through the term βǫj, and the signal uncertainty

from the errors ξj, penalise the usage of the signal sj in an exponential form.

With no errors present the signal usage is a decaying exponential with the

signal cost ǫ. And with no cost constraint the signal usage is an exponen-

tial against the signal uncertainty from the errors ξ. The distribution for the

error-free case coincides with the one obtained in Statistical Mechanics where

9

it is known as the Boltzmann distribution. We name the general distribution

including the eﬀect of the errors in (6) as a generalised Boltzmann distribu-

tion. To obtain the general relationship between statistical correlation I and

average cost E, substitute the distribution in (6) in the expression for I in

(1) to obtain

I =

βE + log

Z, where the parameter

β given in (5) and the

normalisation constant

Z are nonlinear functions of the average cost E. This

b

b

b

b

expression is the most general relationship between mutual information and

b

cost for eﬃcient signalling.

Given the error matrix Q, an average energy E and signals costs ǫ, that

can be obtained either experimentally or from theoretical models, Algorithm

1 gives the optimal signal usage that maximizes signal quality while max-

imizing cost-eﬃciency. We can advance some characteristics of the signal

usage for optimal communication. In biological systems we expect that the

errors produced with highest probability are those with the lowest amplitude.

Two examples illustrate this point. Consider ﬁrst a cell that translates some

states into signals but that when it is in a nonsignalling state, spontaneously

produces signals by error. The most probable signals to be produced by error

are those of lowest amplitude and therefore lowest cost. This is the case in

neurons when diﬀerent values of spike rates are used as diﬀerent signals and

10

spontaneous signalling, say following a Poisson distribution, produces the

highest rates with very low probability. The signals of lower rate have then a

higher signal uncertainty and according to expression in (6) are then under-

utilized. As a second example consider animal communication. According

to the present framework, cheaters that can produce low-cost signals enter

as errors in the communication between healthy animals. These errors make

the low-cost signals to have higher uncertainty and, as in the case of neuronal

signalling, according to (6) the low-cost signals should be underutilized.

3 Comparison with experiments

The signal usage of a small percentage of neurons, 16% in the case of neurons

in the visual cortex area MT of macaques (?), can be explained with a theory

of cost-eﬃcient signalling (??). To explain the signal usage for the totality of

visual cortex neurons we use the formalism presented in the previous section

that not only requires signal eﬃciency but signal quality. As in (?), I assume

maximum signal variability with an energy constraint, the novelty here is

to require signal quality by minimizing signal uncertainty. We also assume

that the spike rates are the symbols that the visual cortex neurons use to

11

communicate (???) and that the costs of each symbol in ATP molecules can

be taken to be linearly proportional to the rate value. As a simple model

to the main contribution from noise we assume spontaneous signalling when

the cell should be in a nonsignalling state. This random spike production

is modelled by a Poisson distribution, with the average number of spikes

produced by error in an interval as the single parameter that distinguishes

diﬀerent cells. When this number is low, the optimal signal usage obtained

from the Algorithm 1 can be approximated as

p(Rate) = Z−1 exp (− exp (−Rate/α) − βRate) ,

(7)

where Z is the normalization constant. Cost eﬃciency is assured by the term

−βRate that penalizes signals by their cost. Signal quality is assured by the

term exp (−Rate/α) that penalizes signals by their signal uncertainty, that

increases with α. The predictions made by the optimal signalling in (7) are:

(a) For high rate values the term required for signal quality in (7) is negligible,

so optimal signal usage reduces to an exponential decaying with rate. (b)

Low rate values are expected to be underutilized respect to the straight line

in (a). Speciﬁcally, the diﬀerence between the straight line and the logarithm

12

of the probability, −βRate − log(p) must be a decreasing exponential. We

compare these predictions to the rate distributions of inferior temporal cortex

neurons of two rhesus macaques responding to video scenes that have been

recently reported (?). The experimental distribution of rates for two of the

cells (labelled as ba001 − 01 and ay102 − 02 in (?)) are given in Figure 1

using a 400 ms window. As seen in Figure 1 the two predictions correspond

to the experimental data. Cost-eﬃciency is responsible for signal usage at

high rates and both cost-eﬃciency and signal quality for the lower values of

rate. Diﬀerent neurons may have diﬀerent values of the average cost and

diﬀerent noise properties but the signal usage seems to be adapted to the

optimal values for each cell.

4 Discussion

We have seen that the eﬀect of errors in the evolution of signalling sys-

tems towards eﬃciency is to shift signalling codes to higher cost to minimize

signal uncertainty. The optimal signal usage for a communication system

constrained by errors and cost has been shown to have a generalised Boltz-

mann form in equation (6) that penalises signals that are costly and that are

13

sensitive to errors. The two main features of this optimal signal usage are an

exponential tail at high cost signals needed for cost eﬃciency and an under-

utilisation of the low cost signals required to protect the signal quality against

errors while maintaining the cost eﬃciency. The predictions made by this

optimal signal usage have been shown to correspond to the the experimental

measurements in visual cortex neurons.

We have so far discussed cell signalling, but as we noticed already in the

Introduction we have chosen this particular type of signalling for concrete-

ness. The theoretical framework here proposed does not require knowledge of

the underlying mechanisms of signalling. The theory only uses the notion of

statistical correlation of states and signals without the need to make concrete

how this correlation is physically established and without any description of

the types of signals except for the costs and errors. This is enough to un-

derstand the optimal signal usage with cost and error constraints. For this

reason, the results apply generally to biological communication and also to

non-biological communication.

Intracellular communication and machine-

machine communication are two possible domains of application. Another

important case is animal communication for which game-theoretical models

have predicted that the evolutionary incentive to deceit is overcame increas-

14

ing the cost of signals (???). These costly signals are called handicaps and

make the communication reliable in the sense of being honest. A diﬀerent

perspective is gained from the formalism presented here. Cheaters enter as

errors in the communication between healthy animals and as they are only

able to produce low cost signals, the signal uncertainty of the low cost signals

is higher. According to the general result in (6) these low cost signals should

be underutilized. This means that signal quality requires a shift to high cost

signals, as we saw in the case of neurons. In this case, cost can be metabolic,

times or risks. In this way we obtain a statement of the handicap principle

based on optimal communication without using the theory of games. Pro-

vided we have knowledge of the communication symbols, their cost and error

characteristics, the present formalism would give the optimal use of symbols

according to signal quality and cost-eﬃciency.

It is interesting to discuss the limits of the theoretical framework. First,

we have assumed that errors and cost are the only constraints of the com-

munication system. Although these constraints are universal, particular sys-

tems might have extra constraints. However, even in the presence of new

constraints, the eﬀect of errors would be to shift the signalling code to higher

cost. Second, we have argued that in biological communication systems the

15

errors that are produced with highest probability are those of the lowest am-

plitude and therefore of the lowest cost. But this need not always be the

case. For example, processing of the signals at the receiver cell might fail

more frequently for the most complex incoming signals, typically those with

highest cost. In this case, there would be an extra penalisation of the high

cost signals and the decay of the distribution would be faster than exponen-

tial. There is partial experimental evidence for this type of code in (?) (see

their Figure 4(f,g)). Other types of codes are possible with diﬀerent error

properties that can still be predicted from the general relation (6).

Acknowledgements

Dennis Bray, William Bialek, Fabrizio Gabbiani, John Hopﬁeld, Rufus Joh-

stone, and Amotz Zahavi are acknowledged for fruitful discussions.

I am

especially indebted to Simon Laughlin for many discussions and critical com-

ments on the manuscript. I am also very grateful to Vijay Balasubramanian

and Michael J. Berry for discussing their independent results on metabolic

eﬃciency prior to publication. I am thankful to Stephano Panzeri for sending

me the data for Figure 1 and for discussing the results in (?). This research

16

has been supported by a Wellcome Trust Fellowship in Mathematical Biology.

17

FIGURE CAPTIONS

Figure 1. The probability distribution of rate usage for visual cortex

neurons follows the optimal distribution in equation (7) (solid line) with the

predicted exponential tail (dashed line) for high rates and the underutilisation

at low costs. The exponential tail makes visual cortex neurons cost eﬃcient

and the underutilisation of the low cost signals protects their signal quality

against errors while remaining cost eﬃcient. The errors are responsible for a

shift to higher cost signals, with a maximum at a rate of value of 10 spikes

in the 400 ms window instead of at a rate of 1 spike if there were no errors

present. The experimental data have been taken from the two visual cortex

neurons labelled as (a) ba001 − 01 and (b) ay102 − 02 in (?).

18

)
y
t
i
l
i
b
a
b
o
r
p
(
g
o
L

)
y
t
i
l
i
b
a
b
o
r
p
(
g
o
L

-

3

-

5

-

7

-

2

-4

-

6

-8

a

50
Rate

b

10

20

30

40

5

10

15

20

25
Rate

Figure 1.

Errors drive the evolution of biological 
signalling to costly codes

G.G. de Polavieja

